[2022-01-20 14:46:55,774][train][INFO][train.py>_log] ==> #0          Total Loss: 35.448   [weighted Loss:35.448   Policy Loss: 9.891    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 1175       Buffer Size: 1175       Transition Number: 5.961   k Batch Size: 256        Lr: 0.00000 
[2022-01-20 14:48:43,744][train][INFO][train.py>_log] ==> #1000       Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 9.495    Value Loss: 5.233    Reward Loss: 1.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 4386       Buffer Size: 4386       Transition Number: 22.080  k Batch Size: 256        Lr: 0.00500 
[2022-01-20 14:50:32,286][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 8.082    Value Loss: 3.270    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 7195       Buffer Size: 7195       Transition Number: 36.152  k Batch Size: 256        Lr: 0.01000 
[2022-01-20 14:52:18,730][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 7.980    Value Loss: 2.858    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 9536       Buffer Size: 9536       Transition Number: 48.300  k Batch Size: 256        Lr: 0.01500 
[2022-01-20 14:54:05,318][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 9.045    Value Loss: 2.888    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 12108      Buffer Size: 12108      Transition Number: 60.506  k Batch Size: 256        Lr: 0.02000 
[2022-01-20 14:55:52,132][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 8.605    Value Loss: 2.948    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 14731      Buffer Size: 14731      Transition Number: 73.261  k Batch Size: 256        Lr: 0.02500 
[2022-01-20 14:57:37,458][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 8.003    Value Loss: 2.793    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 16801      Buffer Size: 16801      Transition Number: 85.347  k Batch Size: 256        Lr: 0.03000 
[2022-01-20 14:59:22,802][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 6.950    Value Loss: 2.605    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 18133      Buffer Size: 18133      Transition Number: 97.045  k Batch Size: 256        Lr: 0.03500 
[2022-01-20 15:01:09,412][train][INFO][train.py>_log] ==> #8000       Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 6.528    Value Loss: 2.605    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 19274      Buffer Size: 19274      Transition Number: 109.101 k Batch Size: 256        Lr: 0.04000 
[2022-01-20 15:02:56,557][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 5.943    Value Loss: 2.428    Reward Loss: 0.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 20164      Buffer Size: 20164      Transition Number: 120.422 k Batch Size: 256        Lr: 0.04500 
[2022-01-20 15:04:42,670][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 5.616    Value Loss: 2.715    Reward Loss: 0.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 20860      Buffer Size: 20860      Transition Number: 131.405 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 15:06:28,554][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 5.266    Value Loss: 2.666    Reward Loss: 0.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 21508      Buffer Size: 21508      Transition Number: 143.038 k Batch Size: 256        Lr: 0.05500 
[2022-01-20 15:08:16,471][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 4.373    Value Loss: 2.618    Reward Loss: 0.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 22096      Buffer Size: 22096      Transition Number: 154.108 k Batch Size: 256        Lr: 0.06000 
[2022-01-20 15:10:04,477][train][INFO][train.py>_log] ==> #13000      Total Loss: 0.930    [weighted Loss:0.930    Policy Loss: 4.671    Value Loss: 2.848    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 22665      Buffer Size: 22665      Transition Number: 166.049 k Batch Size: 256        Lr: 0.06500 
[2022-01-20 15:11:52,477][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 3.853    Value Loss: 2.972    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 23182      Buffer Size: 23182      Transition Number: 178.224 k Batch Size: 256        Lr: 0.07000 
[2022-01-20 15:13:39,643][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.466    [weighted Loss:1.466    Policy Loss: 3.724    Value Loss: 2.935    Reward Loss: 0.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 23691      Buffer Size: 23691      Transition Number: 190.346 k Batch Size: 256        Lr: 0.07500 
[2022-01-20 15:15:28,977][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.457    [weighted Loss:1.457    Policy Loss: 3.807    Value Loss: 2.980    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 24187      Buffer Size: 24187      Transition Number: 202.636 k Batch Size: 256        Lr: 0.08000 
[2022-01-20 15:17:19,313][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.012    [weighted Loss:1.012    Policy Loss: 3.504    Value Loss: 3.261    Reward Loss: 0.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 24725      Buffer Size: 24725      Transition Number: 215.479 k Batch Size: 256        Lr: 0.08500 
[2022-01-20 15:19:07,679][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 3.274    Value Loss: 2.983    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 25224      Buffer Size: 25224      Transition Number: 227.673 k Batch Size: 256        Lr: 0.09000 
[2022-01-20 15:20:52,531][train][INFO][train.py>_log] ==> #19000      Total Loss: 0.748    [weighted Loss:0.748    Policy Loss: 3.255    Value Loss: 3.092    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 25713      Buffer Size: 25713      Transition Number: 239.514 k Batch Size: 256        Lr: 0.09500 
[2022-01-20 15:22:40,652][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.536    [weighted Loss:1.536    Policy Loss: 3.200    Value Loss: 3.411    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 26221      Buffer Size: 26221      Transition Number: 251.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:24:29,769][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.189    [weighted Loss:1.189    Policy Loss: 3.498    Value Loss: 3.341    Reward Loss: 0.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 26712      Buffer Size: 26712      Transition Number: 263.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:26:19,245][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.186    [weighted Loss:1.186    Policy Loss: 3.209    Value Loss: 3.478    Reward Loss: 0.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 27235      Buffer Size: 27235      Transition Number: 276.283 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:28:06,165][train][INFO][train.py>_log] ==> #23000      Total Loss: 0.806    [weighted Loss:0.806    Policy Loss: 2.928    Value Loss: 3.466    Reward Loss: 0.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 27762      Buffer Size: 27762      Transition Number: 289.028 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:29:54,206][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 3.190    Value Loss: 3.790    Reward Loss: 0.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 28261      Buffer Size: 28261      Transition Number: 300.726 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:31:43,343][train][INFO][train.py>_log] ==> #25000      Total Loss: 0.776    [weighted Loss:0.776    Policy Loss: 3.158    Value Loss: 3.761    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 28748      Buffer Size: 28748      Transition Number: 312.707 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:33:32,247][train][INFO][train.py>_log] ==> #26000      Total Loss: 0.837    [weighted Loss:0.837    Policy Loss: 3.075    Value Loss: 3.875    Reward Loss: 0.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 29255      Buffer Size: 29255      Transition Number: 324.701 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:35:18,868][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 3.014    Value Loss: 3.755    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 29748      Buffer Size: 29748      Transition Number: 336.421 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:37:06,561][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.025    [weighted Loss:1.025    Policy Loss: 3.501    Value Loss: 3.857    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 30275      Buffer Size: 30275      Transition Number: 348.563 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:38:55,267][train][INFO][train.py>_log] ==> #29000      Total Loss: 0.772    [weighted Loss:0.772    Policy Loss: 3.567    Value Loss: 3.654    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 30823      Buffer Size: 30823      Transition Number: 359.827 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:40:43,903][train][INFO][train.py>_log] ==> #30000      Total Loss: 0.879    [weighted Loss:0.879    Policy Loss: 3.221    Value Loss: 3.886    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 31402      Buffer Size: 31402      Transition Number: 372.106 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:42:34,683][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 3.674    Value Loss: 3.773    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 31960      Buffer Size: 31960      Transition Number: 383.452 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:44:22,000][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 3.378    Value Loss: 4.032    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 32553      Buffer Size: 32553      Transition Number: 395.688 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:46:09,632][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.054    [weighted Loss:1.054    Policy Loss: 3.551    Value Loss: 4.070    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 33101      Buffer Size: 33101      Transition Number: 407.638 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:47:57,767][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 3.776    Value Loss: 4.203    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 33632      Buffer Size: 33632      Transition Number: 419.015 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:49:46,104][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 3.211    Value Loss: 3.916    Reward Loss: 0.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 34171      Buffer Size: 34171      Transition Number: 430.817 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:51:34,907][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.101    [weighted Loss:1.101    Policy Loss: 3.317    Value Loss: 4.117    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 34715      Buffer Size: 34715      Transition Number: 442.105 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:53:21,895][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.402    [weighted Loss:1.402    Policy Loss: 3.457    Value Loss: 4.509    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 35254      Buffer Size: 35254      Transition Number: 454.211 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:55:09,853][train][INFO][train.py>_log] ==> #38000      Total Loss: 0.974    [weighted Loss:0.974    Policy Loss: 3.213    Value Loss: 3.895    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 35788      Buffer Size: 35788      Transition Number: 465.849 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:56:58,057][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.124    [weighted Loss:1.124    Policy Loss: 3.481    Value Loss: 4.070    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 36345      Buffer Size: 36345      Transition Number: 477.663 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 15:58:46,279][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 3.505    Value Loss: 4.369    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 36866      Buffer Size: 36866      Transition Number: 488.834 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:00:33,398][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.084    [weighted Loss:1.084    Policy Loss: 2.942    Value Loss: 4.098    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 37435      Buffer Size: 37435      Transition Number: 500.969 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:02:23,267][train][INFO][train.py>_log] ==> #42000      Total Loss: 0.559    [weighted Loss:0.559    Policy Loss: 3.143    Value Loss: 4.263    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 37968      Buffer Size: 37968      Transition Number: 512.712 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:04:11,796][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.238    [weighted Loss:1.238    Policy Loss: 3.194    Value Loss: 4.325    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 38520      Buffer Size: 38520      Transition Number: 524.926 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:05:59,038][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 3.585    Value Loss: 4.202    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 39050      Buffer Size: 39050      Transition Number: 536.295 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:07:45,331][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.029    [weighted Loss:1.029    Policy Loss: 3.285    Value Loss: 4.015    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 39601      Buffer Size: 39601      Transition Number: 548.073 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:09:34,126][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.411    [weighted Loss:1.411    Policy Loss: 4.174    Value Loss: 4.467    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 40135      Buffer Size: 40135      Transition Number: 559.281 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:11:22,923][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 4.273    Value Loss: 4.346    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 40697      Buffer Size: 40697      Transition Number: 571.294 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:13:12,823][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.552    [weighted Loss:1.552    Policy Loss: 4.411    Value Loss: 4.850    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 41293      Buffer Size: 41293      Transition Number: 583.285 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:15:01,975][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.830    [weighted Loss:1.830    Policy Loss: 4.100    Value Loss: 4.707    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 41892      Buffer Size: 41892      Transition Number: 594.878 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:16:54,264][train][INFO][train.py>_log] ==> #50000      Total Loss: 0.994    [weighted Loss:0.994    Policy Loss: 4.252    Value Loss: 4.442    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 42491      Buffer Size: 40974      Transition Number: 599.995 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:18:48,113][train][INFO][train.py>_log] ==> #51000      Total Loss: 0.887    [weighted Loss:0.887    Policy Loss: 4.492    Value Loss: 4.537    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 43151      Buffer Size: 39125      Transition Number: 600.018 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:20:41,595][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 4.292    Value Loss: 4.506    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 43807      Buffer Size: 37263      Transition Number: 600.022 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:22:34,709][train][INFO][train.py>_log] ==> #53000      Total Loss: 0.988    [weighted Loss:0.988    Policy Loss: 4.229    Value Loss: 4.991    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 44402      Buffer Size: 35489      Transition Number: 600.000 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:24:26,353][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 4.711    Value Loss: 4.773    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 45002      Buffer Size: 33592      Transition Number: 599.989 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:26:21,128][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 4.348    Value Loss: 4.746    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 45624      Buffer Size: 31569      Transition Number: 600.046 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:28:15,967][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 5.281    Value Loss: 4.729    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 46195      Buffer Size: 29964      Transition Number: 599.989 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:30:08,588][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.081    [weighted Loss:1.081    Policy Loss: 4.263    Value Loss: 4.980    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 46806      Buffer Size: 28923      Transition Number: 599.999 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:32:01,041][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 4.348    Value Loss: 5.303    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 47406      Buffer Size: 28296      Transition Number: 599.978 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:33:54,440][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.513    [weighted Loss:1.513    Policy Loss: 4.135    Value Loss: 4.921    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 48034      Buffer Size: 27950      Transition Number: 600.027 k Batch Size: 256        Lr: 0.05000 
[2022-01-20 16:35:46,108][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 4.392    Value Loss: 5.219    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 48674      Buffer Size: 27783      Transition Number: 599.998 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:37:39,922][train][INFO][train.py>_log] ==> #61000      Total Loss: 0.824    [weighted Loss:0.824    Policy Loss: 3.969    Value Loss: 4.899    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 49299      Buffer Size: 27701      Transition Number: 600.053 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:39:34,533][train][INFO][train.py>_log] ==> #62000      Total Loss: 0.494    [weighted Loss:0.494    Policy Loss: 4.013    Value Loss: 4.719    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 49910      Buffer Size: 27661      Transition Number: 599.998 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:41:28,451][train][INFO][train.py>_log] ==> #63000      Total Loss: 0.776    [weighted Loss:0.776    Policy Loss: 4.166    Value Loss: 4.782    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 50524      Buffer Size: 27688      Transition Number: 599.993 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:43:22,318][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.771    [weighted Loss:1.771    Policy Loss: 4.230    Value Loss: 5.007    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 51110      Buffer Size: 27747      Transition Number: 600.042 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:45:16,862][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.403    [weighted Loss:1.403    Policy Loss: 4.423    Value Loss: 5.135    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 51724      Buffer Size: 27836      Transition Number: 599.981 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:47:09,988][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.247    [weighted Loss:1.247    Policy Loss: 4.493    Value Loss: 4.746    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 52332      Buffer Size: 27921      Transition Number: 599.995 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:49:02,405][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 5.138    Value Loss: 5.263    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 52922      Buffer Size: 28003      Transition Number: 599.993 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:50:54,624][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 4.856    Value Loss: 5.124    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 53546      Buffer Size: 28112      Transition Number: 599.991 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:52:49,692][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 5.050    Value Loss: 4.914    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 54218      Buffer Size: 28251      Transition Number: 599.975 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:54:44,662][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 5.287    Value Loss: 5.025    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 54881      Buffer Size: 28386      Transition Number: 599.977 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:56:37,022][train][INFO][train.py>_log] ==> #71000      Total Loss: 0.806    [weighted Loss:0.806    Policy Loss: 5.462    Value Loss: 5.231    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 55517      Buffer Size: 28509      Transition Number: 599.992 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 16:58:29,023][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.391    [weighted Loss:1.391    Policy Loss: 5.200    Value Loss: 5.490    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 56162      Buffer Size: 28627      Transition Number: 599.975 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 17:00:21,530][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.636    [weighted Loss:1.636    Policy Loss: 5.097    Value Loss: 5.239    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 56785      Buffer Size: 28724      Transition Number: 599.996 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 17:02:13,494][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 4.969    Value Loss: 5.423    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 57392      Buffer Size: 28812      Transition Number: 600.000 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 17:04:07,327][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.157    [weighted Loss:1.157    Policy Loss: 5.186    Value Loss: 5.208    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 58027      Buffer Size: 28929      Transition Number: 599.980 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 17:06:03,157][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.939    [weighted Loss:1.939    Policy Loss: 4.724    Value Loss: 5.060    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 58678      Buffer Size: 29040      Transition Number: 600.004 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 17:07:57,501][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 5.367    Value Loss: 5.150    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 59296      Buffer Size: 29110      Transition Number: 600.040 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 17:09:50,992][train][INFO][train.py>_log] ==> #78000      Total Loss: 0.464    [weighted Loss:0.464    Policy Loss: 4.507    Value Loss: 5.375    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 59959      Buffer Size: 29159      Transition Number: 600.011 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 17:11:44,516][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 5.352    Value Loss: 5.201    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 60617      Buffer Size: 29208      Transition Number: 599.993 k Batch Size: 256        Lr: 0.02500 
[2022-01-20 17:13:38,918][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 4.967    Value Loss: 5.311    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 61301      Buffer Size: 29258      Transition Number: 599.982 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:15:31,178][train][INFO][train.py>_log] ==> #81000      Total Loss: 0.894    [weighted Loss:0.894    Policy Loss: 4.675    Value Loss: 5.064    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 61957      Buffer Size: 29276      Transition Number: 599.999 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:17:25,380][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 4.645    Value Loss: 5.333    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 62602      Buffer Size: 29324      Transition Number: 600.000 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:19:18,596][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.118    [weighted Loss:1.118    Policy Loss: 4.468    Value Loss: 5.342    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 63233      Buffer Size: 29365      Transition Number: 599.992 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:21:11,195][train][INFO][train.py>_log] ==> #84000      Total Loss: 0.866    [weighted Loss:0.866    Policy Loss: 4.621    Value Loss: 5.198    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 63870      Buffer Size: 29408      Transition Number: 599.984 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:23:06,155][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.711    [weighted Loss:1.711    Policy Loss: 4.678    Value Loss: 5.393    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 64500      Buffer Size: 29435      Transition Number: 600.024 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:24:59,871][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 4.405    Value Loss: 5.245    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 65154      Buffer Size: 29484      Transition Number: 599.997 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:26:53,521][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 4.760    Value Loss: 5.322    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 65792      Buffer Size: 29512      Transition Number: 599.987 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:28:45,972][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.465    [weighted Loss:1.465    Policy Loss: 4.669    Value Loss: 4.921    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 66416      Buffer Size: 29535      Transition Number: 600.009 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:30:41,456][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.343    [weighted Loss:1.343    Policy Loss: 4.622    Value Loss: 5.397    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 67067      Buffer Size: 29562      Transition Number: 600.046 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:32:35,300][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.086    [weighted Loss:1.086    Policy Loss: 4.548    Value Loss: 5.298    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 67720      Buffer Size: 29624      Transition Number: 599.999 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:34:30,188][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.105    [weighted Loss:1.105    Policy Loss: 4.469    Value Loss: 5.044    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 68364      Buffer Size: 29660      Transition Number: 600.022 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:36:24,378][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 4.246    Value Loss: 5.213    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 69017      Buffer Size: 29673      Transition Number: 599.996 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:38:18,588][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 4.507    Value Loss: 5.170    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 69654      Buffer Size: 29675      Transition Number: 599.986 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:40:13,415][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 4.654    Value Loss: 5.043    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 70279      Buffer Size: 29689      Transition Number: 600.032 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:42:09,039][train][INFO][train.py>_log] ==> #95000      Total Loss: 1.205    [weighted Loss:1.205    Policy Loss: 4.410    Value Loss: 5.242    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 70914      Buffer Size: 29669      Transition Number: 600.012 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:44:03,285][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 4.652    Value Loss: 5.034    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 71556      Buffer Size: 29624      Transition Number: 599.993 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:45:57,328][train][INFO][train.py>_log] ==> #97000      Total Loss: 0.830    [weighted Loss:0.830    Policy Loss: 4.318    Value Loss: 5.203    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 72200      Buffer Size: 29621      Transition Number: 600.026 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:47:53,184][train][INFO][train.py>_log] ==> #98000      Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 4.525    Value Loss: 5.303    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 72861      Buffer Size: 29566      Transition Number: 599.994 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:49:47,823][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 4.640    Value Loss: 5.499    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 73522      Buffer Size: 29548      Transition Number: 599.996 k Batch Size: 256        Lr: 0.01250 
[2022-01-20 17:51:42,741][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 4.340    Value Loss: 5.073    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 74155      Buffer Size: 29542      Transition Number: 599.989 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 17:53:39,726][train][INFO][train.py>_log] ==> #101000     Total Loss: 0.997    [weighted Loss:0.997    Policy Loss: 4.479    Value Loss: 4.684    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 74835      Buffer Size: 29541      Transition Number: 599.994 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 17:55:37,289][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 4.673    Value Loss: 5.212    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 75505      Buffer Size: 29543      Transition Number: 599.990 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 17:57:33,588][train][INFO][train.py>_log] ==> #103000     Total Loss: 0.823    [weighted Loss:0.823    Policy Loss: 4.529    Value Loss: 5.060    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 76161      Buffer Size: 29545      Transition Number: 600.069 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 17:59:27,062][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.222    [weighted Loss:1.222    Policy Loss: 4.467    Value Loss: 5.011    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 76819      Buffer Size: 29565      Transition Number: 600.001 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:01:22,346][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.518    [weighted Loss:1.518    Policy Loss: 4.637    Value Loss: 5.231    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 77458      Buffer Size: 29533      Transition Number: 599.991 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:03:18,452][train][INFO][train.py>_log] ==> #106000     Total Loss: 0.914    [weighted Loss:0.914    Policy Loss: 4.626    Value Loss: 4.637    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 78104      Buffer Size: 29498      Transition Number: 599.983 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:05:14,618][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 4.557    Value Loss: 5.069    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 78743      Buffer Size: 29464      Transition Number: 600.040 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:07:11,831][train][INFO][train.py>_log] ==> #108000     Total Loss: 0.926    [weighted Loss:0.926    Policy Loss: 4.559    Value Loss: 5.019    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 79423      Buffer Size: 29450      Transition Number: 600.035 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:09:06,854][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 4.595    Value Loss: 5.246    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 80075      Buffer Size: 29473      Transition Number: 600.038 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:11:01,586][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 4.910    Value Loss: 5.268    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 80726      Buffer Size: 29485      Transition Number: 600.037 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:12:57,120][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.511    [weighted Loss:1.511    Policy Loss: 4.552    Value Loss: 5.216    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 81378      Buffer Size: 29480      Transition Number: 599.978 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:14:51,800][train][INFO][train.py>_log] ==> #112000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 4.700    Value Loss: 5.303    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 82028      Buffer Size: 29489      Transition Number: 600.015 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:16:48,587][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 4.464    Value Loss: 5.357    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 82672      Buffer Size: 29470      Transition Number: 600.002 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:18:44,418][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.549    [weighted Loss:1.549    Policy Loss: 4.673    Value Loss: 5.318    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 83342      Buffer Size: 29434      Transition Number: 600.003 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:20:40,316][train][INFO][train.py>_log] ==> #115000     Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 4.542    Value Loss: 5.140    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 83983      Buffer Size: 29369      Transition Number: 599.999 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:22:36,508][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.035    [weighted Loss:1.035    Policy Loss: 5.189    Value Loss: 5.175    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 84643      Buffer Size: 29326      Transition Number: 599.978 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:24:33,820][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.577    [weighted Loss:1.577    Policy Loss: 4.684    Value Loss: 5.571    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 85310      Buffer Size: 29297      Transition Number: 600.001 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:26:30,374][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.492    [weighted Loss:1.492    Policy Loss: 4.609    Value Loss: 5.078    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 85983      Buffer Size: 29264      Transition Number: 599.999 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:28:26,112][train][INFO][train.py>_log] ==> #119000     Total Loss: 0.678    [weighted Loss:0.678    Policy Loss: 4.927    Value Loss: 5.056    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 86633      Buffer Size: 29242      Transition Number: 600.005 k Batch Size: 256        Lr: 0.00625 
[2022-01-20 18:30:23,169][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.086    [weighted Loss:1.086    Policy Loss: 5.053    Value Loss: 4.781    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 87303      Buffer Size: 29220      Transition Number: 599.993 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:32:19,680][train][INFO][train.py>_log] ==> #121000     Total Loss: 1.188    [weighted Loss:1.188    Policy Loss: 4.746    Value Loss: 5.172    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 87985      Buffer Size: 29207      Transition Number: 600.012 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:34:16,542][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.083    [weighted Loss:1.083    Policy Loss: 4.874    Value Loss: 5.143    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 88632      Buffer Size: 29183      Transition Number: 600.009 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:36:12,852][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 4.751    Value Loss: 5.262    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 89308      Buffer Size: 29145      Transition Number: 599.979 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:38:07,771][train][INFO][train.py>_log] ==> #124000     Total Loss: 0.701    [weighted Loss:0.701    Policy Loss: 5.047    Value Loss: 5.328    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 89952      Buffer Size: 29093      Transition Number: 599.994 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:40:05,780][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.113    [weighted Loss:1.113    Policy Loss: 4.939    Value Loss: 4.872    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 90616      Buffer Size: 29056      Transition Number: 599.992 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:41:59,714][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.326    [weighted Loss:1.326    Policy Loss: 4.783    Value Loss: 4.835    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 91282      Buffer Size: 29021      Transition Number: 600.038 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:43:56,413][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.083    [weighted Loss:1.083    Policy Loss: 4.967    Value Loss: 5.126    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 91964      Buffer Size: 29007      Transition Number: 599.996 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:45:51,736][train][INFO][train.py>_log] ==> #128000     Total Loss: 0.799    [weighted Loss:0.799    Policy Loss: 4.845    Value Loss: 5.327    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 92625      Buffer Size: 28991      Transition Number: 600.017 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:47:48,565][train][INFO][train.py>_log] ==> #129000     Total Loss: 0.865    [weighted Loss:0.865    Policy Loss: 4.963    Value Loss: 5.436    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 93285      Buffer Size: 28979      Transition Number: 600.017 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:49:45,023][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.306    [weighted Loss:1.306    Policy Loss: 4.796    Value Loss: 5.385    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 93968      Buffer Size: 28964      Transition Number: 600.001 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:51:41,690][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.160    [weighted Loss:1.160    Policy Loss: 4.701    Value Loss: 5.365    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 94625      Buffer Size: 28959      Transition Number: 599.988 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:53:36,980][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.310    [weighted Loss:1.310    Policy Loss: 4.469    Value Loss: 5.099    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 95289      Buffer Size: 28969      Transition Number: 600.016 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:55:32,036][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.463    [weighted Loss:1.463    Policy Loss: 4.688    Value Loss: 5.151    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 95960      Buffer Size: 28963      Transition Number: 599.982 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:57:31,127][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.561    [weighted Loss:1.561    Policy Loss: 4.805    Value Loss: 5.127    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 96618      Buffer Size: 28929      Transition Number: 600.016 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 18:59:26,109][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 4.981    Value Loss: 5.293    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 97290      Buffer Size: 28931      Transition Number: 599.999 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 19:01:21,654][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.331    [weighted Loss:1.331    Policy Loss: 4.912    Value Loss: 5.570    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 97960      Buffer Size: 28930      Transition Number: 600.010 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 19:03:20,090][train][INFO][train.py>_log] ==> #137000     Total Loss: 0.688    [weighted Loss:0.688    Policy Loss: 4.851    Value Loss: 5.262    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 98630      Buffer Size: 28945      Transition Number: 599.987 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 19:05:16,399][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.410    [weighted Loss:1.410    Policy Loss: 4.928    Value Loss: 5.260    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 99301      Buffer Size: 28953      Transition Number: 599.976 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 19:07:12,861][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.182    [weighted Loss:1.182    Policy Loss: 4.776    Value Loss: 5.466    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 99945      Buffer Size: 28956      Transition Number: 599.999 k Batch Size: 256        Lr: 0.00313 
[2022-01-20 19:09:08,611][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.355    [weighted Loss:1.355    Policy Loss: 4.686    Value Loss: 5.559    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 100630     Buffer Size: 28970      Transition Number: 599.983 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:11:05,782][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.273    [weighted Loss:1.273    Policy Loss: 4.850    Value Loss: 5.468    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 101298     Buffer Size: 28980      Transition Number: 600.016 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:13:00,165][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.138    [weighted Loss:1.138    Policy Loss: 4.796    Value Loss: 5.322    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 101955     Buffer Size: 28959      Transition Number: 599.994 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:14:57,615][train][INFO][train.py>_log] ==> #143000     Total Loss: 0.561    [weighted Loss:0.561    Policy Loss: 4.712    Value Loss: 5.258    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 102617     Buffer Size: 28928      Transition Number: 599.991 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:16:54,999][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.050    [weighted Loss:1.050    Policy Loss: 4.976    Value Loss: 5.235    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 103279     Buffer Size: 28915      Transition Number: 599.999 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:18:52,634][train][INFO][train.py>_log] ==> #145000     Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 4.871    Value Loss: 5.721    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 103971     Buffer Size: 28914      Transition Number: 599.999 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:20:50,149][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.232    [weighted Loss:1.232    Policy Loss: 4.657    Value Loss: 5.774    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 104631     Buffer Size: 28902      Transition Number: 600.000 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:22:47,487][train][INFO][train.py>_log] ==> #147000     Total Loss: 0.856    [weighted Loss:0.856    Policy Loss: 4.845    Value Loss: 5.106    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 105306     Buffer Size: 28911      Transition Number: 600.008 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:24:46,820][train][INFO][train.py>_log] ==> #148000     Total Loss: 0.651    [weighted Loss:0.651    Policy Loss: 4.912    Value Loss: 5.521    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 105992     Buffer Size: 28896      Transition Number: 599.985 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:26:41,378][train][INFO][train.py>_log] ==> #149000     Total Loss: 0.804    [weighted Loss:0.804    Policy Loss: 4.969    Value Loss: 5.290    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 106657     Buffer Size: 28877      Transition Number: 599.989 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:28:37,939][train][INFO][train.py>_log] ==> #150000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 4.797    Value Loss: 5.519    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 107311     Buffer Size: 28869      Transition Number: 600.041 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:30:36,813][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.751    [weighted Loss:1.751    Policy Loss: 4.975    Value Loss: 5.160    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 108007     Buffer Size: 28879      Transition Number: 600.012 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:32:36,375][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 4.566    Value Loss: 5.563    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 108674     Buffer Size: 28871      Transition Number: 599.992 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:34:31,240][train][INFO][train.py>_log] ==> #153000     Total Loss: 0.756    [weighted Loss:0.756    Policy Loss: 4.829    Value Loss: 5.503    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 109339     Buffer Size: 28869      Transition Number: 599.986 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:36:26,452][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 4.607    Value Loss: 5.323    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 109983     Buffer Size: 28861      Transition Number: 599.998 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:38:23,897][train][INFO][train.py>_log] ==> #155000     Total Loss: 0.496    [weighted Loss:0.496    Policy Loss: 4.883    Value Loss: 5.848    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 110667     Buffer Size: 28853      Transition Number: 599.997 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:40:20,979][train][INFO][train.py>_log] ==> #156000     Total Loss: 0.471    [weighted Loss:0.471    Policy Loss: 4.858    Value Loss: 5.253    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 111343     Buffer Size: 28861      Transition Number: 600.048 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:42:18,781][train][INFO][train.py>_log] ==> #157000     Total Loss: 0.911    [weighted Loss:0.911    Policy Loss: 4.973    Value Loss: 5.510    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 112032     Buffer Size: 28854      Transition Number: 599.992 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:44:17,081][train][INFO][train.py>_log] ==> #158000     Total Loss: 0.762    [weighted Loss:0.762    Policy Loss: 4.775    Value Loss: 5.204    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 112719     Buffer Size: 28861      Transition Number: 600.015 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:46:13,971][train][INFO][train.py>_log] ==> #159000     Total Loss: 0.932    [weighted Loss:0.932    Policy Loss: 4.934    Value Loss: 5.482    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 113399     Buffer Size: 28847      Transition Number: 599.983 k Batch Size: 256        Lr: 0.00156 
[2022-01-20 19:48:10,249][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 5.016    Value Loss: 5.463    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 114066     Buffer Size: 28851      Transition Number: 599.986 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 19:50:08,688][train][INFO][train.py>_log] ==> #161000     Total Loss: 0.791    [weighted Loss:0.791    Policy Loss: 4.803    Value Loss: 5.461    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 114761     Buffer Size: 28846      Transition Number: 600.035 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 19:52:06,596][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.217    [weighted Loss:1.217    Policy Loss: 4.847    Value Loss: 4.959    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 115447     Buffer Size: 28858      Transition Number: 600.007 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 19:54:03,291][train][INFO][train.py>_log] ==> #163000     Total Loss: 1.254    [weighted Loss:1.254    Policy Loss: 4.627    Value Loss: 5.532    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 116130     Buffer Size: 28842      Transition Number: 599.982 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 19:56:01,058][train][INFO][train.py>_log] ==> #164000     Total Loss: 0.373    [weighted Loss:0.373    Policy Loss: 4.429    Value Loss: 5.421    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 116837     Buffer Size: 28831      Transition Number: 599.993 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 19:58:01,127][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 4.822    Value Loss: 5.386    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 117520     Buffer Size: 28833      Transition Number: 599.991 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 19:59:59,788][train][INFO][train.py>_log] ==> #166000     Total Loss: 0.624    [weighted Loss:0.624    Policy Loss: 4.757    Value Loss: 5.247    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 118212     Buffer Size: 28815      Transition Number: 600.003 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:01:56,831][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.756    [weighted Loss:1.756    Policy Loss: 4.936    Value Loss: 5.554    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 118905     Buffer Size: 28821      Transition Number: 600.021 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:03:56,270][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.117    [weighted Loss:1.117    Policy Loss: 4.561    Value Loss: 5.565    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 119596     Buffer Size: 28815      Transition Number: 600.020 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:05:53,977][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.381    [weighted Loss:1.381    Policy Loss: 4.701    Value Loss: 5.577    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 120283     Buffer Size: 28821      Transition Number: 599.989 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:07:51,496][train][INFO][train.py>_log] ==> #170000     Total Loss: 0.924    [weighted Loss:0.924    Policy Loss: 4.891    Value Loss: 5.508    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 120975     Buffer Size: 28835      Transition Number: 599.996 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:09:48,901][train][INFO][train.py>_log] ==> #171000     Total Loss: 0.769    [weighted Loss:0.769    Policy Loss: 4.629    Value Loss: 5.451    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 121662     Buffer Size: 28832      Transition Number: 600.070 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:11:46,719][train][INFO][train.py>_log] ==> #172000     Total Loss: 0.702    [weighted Loss:0.702    Policy Loss: 4.610    Value Loss: 5.580    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 122365     Buffer Size: 28825      Transition Number: 599.982 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:13:45,048][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.175    [weighted Loss:1.175    Policy Loss: 4.946    Value Loss: 5.598    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 123040     Buffer Size: 28814      Transition Number: 599.986 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:15:42,744][train][INFO][train.py>_log] ==> #174000     Total Loss: 0.926    [weighted Loss:0.926    Policy Loss: 4.632    Value Loss: 5.681    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 123719     Buffer Size: 28795      Transition Number: 600.014 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:17:41,591][train][INFO][train.py>_log] ==> #175000     Total Loss: 0.710    [weighted Loss:0.710    Policy Loss: 4.907    Value Loss: 5.378    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 124410     Buffer Size: 28777      Transition Number: 599.992 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:19:39,205][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.122    [weighted Loss:1.122    Policy Loss: 4.760    Value Loss: 5.601    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 125092     Buffer Size: 28778      Transition Number: 599.989 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:21:36,237][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.597    [weighted Loss:1.597    Policy Loss: 4.900    Value Loss: 5.349    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 125778     Buffer Size: 28790      Transition Number: 599.997 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:23:33,305][train][INFO][train.py>_log] ==> #178000     Total Loss: 0.309    [weighted Loss:0.309    Policy Loss: 4.824    Value Loss: 5.481    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 126460     Buffer Size: 28777      Transition Number: 599.992 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:25:32,156][train][INFO][train.py>_log] ==> #179000     Total Loss: 0.917    [weighted Loss:0.917    Policy Loss: 4.760    Value Loss: 5.707    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 127151     Buffer Size: 28752      Transition Number: 599.980 k Batch Size: 256        Lr: 0.00078 
[2022-01-20 20:27:30,356][train][INFO][train.py>_log] ==> #180000     Total Loss: 0.865    [weighted Loss:0.865    Policy Loss: 4.788    Value Loss: 5.400    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 127832     Buffer Size: 28754      Transition Number: 600.029 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:29:28,271][train][INFO][train.py>_log] ==> #181000     Total Loss: 0.689    [weighted Loss:0.689    Policy Loss: 4.810    Value Loss: 5.283    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 128534     Buffer Size: 28744      Transition Number: 600.021 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:31:26,724][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.232    [weighted Loss:1.232    Policy Loss: 4.625    Value Loss: 5.346    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 129238     Buffer Size: 28757      Transition Number: 600.022 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:33:23,499][train][INFO][train.py>_log] ==> #183000     Total Loss: 1.153    [weighted Loss:1.153    Policy Loss: 4.869    Value Loss: 4.774    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 129928     Buffer Size: 28769      Transition Number: 599.976 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:35:22,107][train][INFO][train.py>_log] ==> #184000     Total Loss: 0.711    [weighted Loss:0.711    Policy Loss: 5.009    Value Loss: 5.654    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 130610     Buffer Size: 28755      Transition Number: 599.997 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:37:22,911][train][INFO][train.py>_log] ==> #185000     Total Loss: 0.469    [weighted Loss:0.469    Policy Loss: 4.875    Value Loss: 6.025    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 131318     Buffer Size: 28769      Transition Number: 600.006 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:39:21,946][train][INFO][train.py>_log] ==> #186000     Total Loss: 0.414    [weighted Loss:0.414    Policy Loss: 4.651    Value Loss: 6.020    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 132026     Buffer Size: 28781      Transition Number: 599.981 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:41:20,148][train][INFO][train.py>_log] ==> #187000     Total Loss: 1.044    [weighted Loss:1.044    Policy Loss: 4.682    Value Loss: 5.606    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 132729     Buffer Size: 28788      Transition Number: 599.991 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:43:19,541][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.384    [weighted Loss:1.384    Policy Loss: 4.685    Value Loss: 5.844    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 133426     Buffer Size: 28800      Transition Number: 599.986 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:45:18,252][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.002    [weighted Loss:1.002    Policy Loss: 4.882    Value Loss: 5.861    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 134132     Buffer Size: 28797      Transition Number: 600.027 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:47:18,133][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.627    [weighted Loss:1.627    Policy Loss: 4.916    Value Loss: 5.326    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 134825     Buffer Size: 28782      Transition Number: 599.984 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:49:17,910][train][INFO][train.py>_log] ==> #191000     Total Loss: 1.271    [weighted Loss:1.271    Policy Loss: 4.918    Value Loss: 5.765    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 135552     Buffer Size: 28792      Transition Number: 600.027 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:51:16,750][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 4.587    Value Loss: 5.476    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 136260     Buffer Size: 28827      Transition Number: 599.983 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:53:17,215][train][INFO][train.py>_log] ==> #193000     Total Loss: 0.320    [weighted Loss:0.320    Policy Loss: 4.670    Value Loss: 5.535    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 136977     Buffer Size: 28817      Transition Number: 599.982 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:55:16,098][train][INFO][train.py>_log] ==> #194000     Total Loss: 0.955    [weighted Loss:0.955    Policy Loss: 4.684    Value Loss: 5.201    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 137674     Buffer Size: 28822      Transition Number: 600.044 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:57:15,749][train][INFO][train.py>_log] ==> #195000     Total Loss: 1.049    [weighted Loss:1.049    Policy Loss: 4.598    Value Loss: 5.665    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 138378     Buffer Size: 28821      Transition Number: 599.993 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 20:59:15,159][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.194    [weighted Loss:1.194    Policy Loss: 4.601    Value Loss: 5.866    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 139094     Buffer Size: 28839      Transition Number: 599.998 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 21:01:15,231][train][INFO][train.py>_log] ==> #197000     Total Loss: 1.080    [weighted Loss:1.080    Policy Loss: 4.799    Value Loss: 5.412    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 139811     Buffer Size: 28853      Transition Number: 599.988 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 21:03:14,613][train][INFO][train.py>_log] ==> #198000     Total Loss: 0.808    [weighted Loss:0.808    Policy Loss: 4.663    Value Loss: 5.253    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 140499     Buffer Size: 28844      Transition Number: 600.019 k Batch Size: 256        Lr: 0.00039 
[2022-01-20 21:05:12,672][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.289    [weighted Loss:1.289    Policy Loss: 5.004    Value Loss: 5.469    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 141207     Buffer Size: 28840      Transition Number: 599.979 k Batch Size: 256        Lr: 0.00039 
