[2022-01-21 19:50:48,963][train][INFO][train.py>_log] ==> #0          Total Loss: 35.910   [weighted Loss:35.910   Policy Loss: 10.354   Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 1048       Buffer Size: 1048       Transition Number: 5.379   k Batch Size: 256        Lr: 0.00000 
[2022-01-21 19:52:41,010][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.931    [weighted Loss:3.931    Policy Loss: 9.661    Value Loss: 5.006    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 4495       Buffer Size: 4495       Transition Number: 22.744  k Batch Size: 256        Lr: 0.00500 
[2022-01-21 19:54:32,238][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.538    [weighted Loss:4.538    Policy Loss: 9.150    Value Loss: 3.529    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 7731       Buffer Size: 7731       Transition Number: 38.363  k Batch Size: 256        Lr: 0.01000 
[2022-01-21 19:56:20,187][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 7.797    Value Loss: 3.287    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 10690      Buffer Size: 10690      Transition Number: 51.410  k Batch Size: 256        Lr: 0.01500 
[2022-01-21 19:58:08,590][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 8.905    Value Loss: 3.251    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 13217      Buffer Size: 13217      Transition Number: 63.483  k Batch Size: 256        Lr: 0.02000 
[2022-01-21 19:59:59,004][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.112    [weighted Loss:3.112    Policy Loss: 8.070    Value Loss: 2.972    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 15566      Buffer Size: 15566      Transition Number: 76.028  k Batch Size: 256        Lr: 0.02500 
[2022-01-21 20:01:48,535][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.336    [weighted Loss:3.336    Policy Loss: 7.242    Value Loss: 2.696    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 17315      Buffer Size: 17315      Transition Number: 88.508  k Batch Size: 256        Lr: 0.03000 
[2022-01-21 20:03:37,095][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.149    [weighted Loss:2.149    Policy Loss: 6.071    Value Loss: 2.644    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 18798      Buffer Size: 18798      Transition Number: 100.796 k Batch Size: 256        Lr: 0.03500 
[2022-01-21 20:05:27,988][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.854    [weighted Loss:2.854    Policy Loss: 5.490    Value Loss: 2.707    Reward Loss: 0.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 19978      Buffer Size: 19978      Transition Number: 113.828 k Batch Size: 256        Lr: 0.04000 
[2022-01-21 20:07:15,445][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 5.133    Value Loss: 2.664    Reward Loss: 0.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 20790      Buffer Size: 20790      Transition Number: 125.826 k Batch Size: 256        Lr: 0.04500 
[2022-01-21 20:09:06,182][train][INFO][train.py>_log] ==> #10000      Total Loss: 1.011    [weighted Loss:1.011    Policy Loss: 4.523    Value Loss: 2.706    Reward Loss: 0.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 21564      Buffer Size: 21564      Transition Number: 138.599 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 20:10:57,306][train][INFO][train.py>_log] ==> #11000      Total Loss: 0.938    [weighted Loss:0.938    Policy Loss: 4.412    Value Loss: 2.860    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 22206      Buffer Size: 22206      Transition Number: 151.184 k Batch Size: 256        Lr: 0.05500 
[2022-01-21 20:12:45,991][train][INFO][train.py>_log] ==> #12000      Total Loss: 1.202    [weighted Loss:1.202    Policy Loss: 3.771    Value Loss: 2.877    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 22832      Buffer Size: 22832      Transition Number: 164.022 k Batch Size: 256        Lr: 0.06000 
[2022-01-21 20:14:36,198][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.041    [weighted Loss:2.041    Policy Loss: 3.802    Value Loss: 2.971    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 23446      Buffer Size: 23446      Transition Number: 176.734 k Batch Size: 256        Lr: 0.06500 
[2022-01-21 20:16:25,640][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.393    [weighted Loss:1.393    Policy Loss: 3.527    Value Loss: 3.066    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 23997      Buffer Size: 23997      Transition Number: 189.162 k Batch Size: 256        Lr: 0.07000 
[2022-01-21 20:18:15,262][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 3.451    Value Loss: 3.619    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 24567      Buffer Size: 24567      Transition Number: 201.730 k Batch Size: 256        Lr: 0.07500 
[2022-01-21 20:20:05,123][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.191    [weighted Loss:1.191    Policy Loss: 3.092    Value Loss: 3.144    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 25122      Buffer Size: 25122      Transition Number: 213.716 k Batch Size: 256        Lr: 0.08000 
[2022-01-21 20:21:56,812][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.253    [weighted Loss:1.253    Policy Loss: 3.056    Value Loss: 3.418    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 25695      Buffer Size: 25695      Transition Number: 226.690 k Batch Size: 256        Lr: 0.08500 
[2022-01-21 20:23:46,721][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 2.770    Value Loss: 3.372    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 26265      Buffer Size: 26265      Transition Number: 239.960 k Batch Size: 256        Lr: 0.09000 
[2022-01-21 20:25:35,322][train][INFO][train.py>_log] ==> #19000      Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 2.760    Value Loss: 3.285    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 26785      Buffer Size: 26785      Transition Number: 252.405 k Batch Size: 256        Lr: 0.09500 
[2022-01-21 20:27:24,144][train][INFO][train.py>_log] ==> #20000      Total Loss: 0.943    [weighted Loss:0.943    Policy Loss: 2.695    Value Loss: 3.447    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 27326      Buffer Size: 27326      Transition Number: 265.162 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:29:12,331][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 3.024    Value Loss: 3.517    Reward Loss: 0.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 27868      Buffer Size: 27868      Transition Number: 277.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:31:05,728][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.487    [weighted Loss:1.487    Policy Loss: 3.335    Value Loss: 3.618    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 28423      Buffer Size: 28423      Transition Number: 291.075 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:32:57,572][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.402    [weighted Loss:1.402    Policy Loss: 3.481    Value Loss: 3.410    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 28970      Buffer Size: 28970      Transition Number: 303.841 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:34:45,479][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 3.285    Value Loss: 3.831    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 29544      Buffer Size: 29544      Transition Number: 316.394 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:36:38,026][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 3.795    Value Loss: 3.818    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 30080      Buffer Size: 30080      Transition Number: 328.548 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:38:25,691][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.184    [weighted Loss:1.184    Policy Loss: 3.600    Value Loss: 3.760    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 30641      Buffer Size: 30641      Transition Number: 340.742 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:40:13,966][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.008    [weighted Loss:1.008    Policy Loss: 3.626    Value Loss: 3.903    Reward Loss: 0.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 31188      Buffer Size: 31188      Transition Number: 352.894 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:42:02,289][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.158    [weighted Loss:1.158    Policy Loss: 3.565    Value Loss: 4.300    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 31727      Buffer Size: 31727      Transition Number: 364.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:43:50,088][train][INFO][train.py>_log] ==> #29000      Total Loss: 0.944    [weighted Loss:0.944    Policy Loss: 3.523    Value Loss: 4.252    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 32305      Buffer Size: 32305      Transition Number: 377.303 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:45:37,473][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.379    [weighted Loss:1.379    Policy Loss: 3.467    Value Loss: 3.960    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 32840      Buffer Size: 32840      Transition Number: 388.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:47:25,878][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 2.715    Value Loss: 4.314    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 33396      Buffer Size: 33396      Transition Number: 401.102 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:49:15,673][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 2.842    Value Loss: 4.445    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 33954      Buffer Size: 33954      Transition Number: 413.621 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:51:04,105][train][INFO][train.py>_log] ==> #33000      Total Loss: 0.956    [weighted Loss:0.956    Policy Loss: 3.085    Value Loss: 4.341    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 34544      Buffer Size: 34544      Transition Number: 426.269 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:52:53,352][train][INFO][train.py>_log] ==> #34000      Total Loss: 0.971    [weighted Loss:0.971    Policy Loss: 3.033    Value Loss: 4.262    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 35136      Buffer Size: 35136      Transition Number: 438.507 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:54:40,674][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.184    [weighted Loss:1.184    Policy Loss: 3.351    Value Loss: 4.595    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 35687      Buffer Size: 35687      Transition Number: 450.527 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:56:29,327][train][INFO][train.py>_log] ==> #36000      Total Loss: 0.752    [weighted Loss:0.752    Policy Loss: 3.130    Value Loss: 4.193    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 36253      Buffer Size: 36253      Transition Number: 463.128 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:58:15,794][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.612    [weighted Loss:1.612    Policy Loss: 3.325    Value Loss: 4.508    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 36795      Buffer Size: 36795      Transition Number: 474.899 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:00:04,396][train][INFO][train.py>_log] ==> #38000      Total Loss: 0.747    [weighted Loss:0.747    Policy Loss: 3.021    Value Loss: 4.332    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 37361      Buffer Size: 37361      Transition Number: 486.894 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:01:52,559][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 2.923    Value Loss: 4.729    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 37926      Buffer Size: 37926      Transition Number: 499.133 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:03:41,832][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 2.955    Value Loss: 4.707    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 38488      Buffer Size: 38488      Transition Number: 511.632 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:05:31,764][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 2.998    Value Loss: 4.552    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 39067      Buffer Size: 39067      Transition Number: 524.201 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:07:22,355][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.140    [weighted Loss:1.140    Policy Loss: 2.942    Value Loss: 4.752    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 39629      Buffer Size: 39629      Transition Number: 536.447 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:09:10,517][train][INFO][train.py>_log] ==> #43000      Total Loss: 0.819    [weighted Loss:0.819    Policy Loss: 2.918    Value Loss: 4.455    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 40179      Buffer Size: 40179      Transition Number: 548.193 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:11:00,536][train][INFO][train.py>_log] ==> #44000      Total Loss: 0.451    [weighted Loss:0.451    Policy Loss: 3.209    Value Loss: 4.634    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 40777      Buffer Size: 40777      Transition Number: 560.907 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:12:50,309][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.390    [weighted Loss:1.390    Policy Loss: 3.383    Value Loss: 4.609    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 41363      Buffer Size: 41363      Transition Number: 573.669 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:14:40,873][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 3.205    Value Loss: 4.441    Reward Loss: 0.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 41938      Buffer Size: 41938      Transition Number: 586.084 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:16:32,315][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.002    [weighted Loss:1.002    Policy Loss: 3.132    Value Loss: 4.535    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 42559      Buffer Size: 42559      Transition Number: 599.053 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:18:24,576][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.205    [weighted Loss:1.205    Policy Loss: 3.206    Value Loss: 4.884    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 43178      Buffer Size: 43178      Transition Number: 611.806 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:20:17,859][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.100    [weighted Loss:1.100    Policy Loss: 2.716    Value Loss: 4.494    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 43763      Buffer Size: 43763      Transition Number: 624.358 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:22:10,658][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.433    [weighted Loss:1.433    Policy Loss: 2.909    Value Loss: 4.494    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 44390      Buffer Size: 44390      Transition Number: 637.665 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:24:05,847][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 2.753    Value Loss: 4.727    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 44997      Buffer Size: 44997      Transition Number: 650.991 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:26:02,172][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.563    [weighted Loss:1.563    Policy Loss: 2.810    Value Loss: 4.398    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 45615      Buffer Size: 45615      Transition Number: 664.534 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:27:58,880][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.449    [weighted Loss:1.449    Policy Loss: 2.972    Value Loss: 4.814    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 46249      Buffer Size: 46249      Transition Number: 678.180 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:29:54,894][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.669    [weighted Loss:1.669    Policy Loss: 3.230    Value Loss: 4.955    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 46898      Buffer Size: 46898      Transition Number: 692.646 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:31:52,862][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.083    [weighted Loss:1.083    Policy Loss: 3.073    Value Loss: 4.639    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 47537      Buffer Size: 47537      Transition Number: 706.404 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:33:51,495][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 3.140    Value Loss: 4.761    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 48159      Buffer Size: 48159      Transition Number: 719.804 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:35:51,329][train][INFO][train.py>_log] ==> #57000      Total Loss: 0.547    [weighted Loss:0.547    Policy Loss: 3.028    Value Loss: 4.667    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 48830      Buffer Size: 48830      Transition Number: 734.206 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:37:52,447][train][INFO][train.py>_log] ==> #58000      Total Loss: 0.902    [weighted Loss:0.902    Policy Loss: 2.792    Value Loss: 4.591    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 49510      Buffer Size: 49510      Transition Number: 748.853 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:39:54,332][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.010    [weighted Loss:1.010    Policy Loss: 3.034    Value Loss: 4.968    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 50188      Buffer Size: 50188      Transition Number: 763.417 k Batch Size: 256        Lr: 0.05000 
[2022-01-21 21:41:59,068][train][INFO][train.py>_log] ==> #60000      Total Loss: 0.883    [weighted Loss:0.883    Policy Loss: 2.957    Value Loss: 4.713    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 50911      Buffer Size: 50911      Transition Number: 778.908 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 21:44:04,023][train][INFO][train.py>_log] ==> #61000      Total Loss: 0.745    [weighted Loss:0.745    Policy Loss: 2.712    Value Loss: 5.299    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 51607      Buffer Size: 51607      Transition Number: 793.879 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 21:46:07,036][train][INFO][train.py>_log] ==> #62000      Total Loss: 0.591    [weighted Loss:0.591    Policy Loss: 2.694    Value Loss: 4.798    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 52285      Buffer Size: 52285      Transition Number: 808.620 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 21:48:13,407][train][INFO][train.py>_log] ==> #63000      Total Loss: 0.766    [weighted Loss:0.766    Policy Loss: 2.914    Value Loss: 4.960    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 53030      Buffer Size: 53030      Transition Number: 824.490 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 21:50:18,678][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 3.288    Value Loss: 5.186    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 53741      Buffer Size: 53741      Transition Number: 839.368 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 21:52:26,185][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.309    [weighted Loss:1.309    Policy Loss: 2.923    Value Loss: 4.375    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 54476      Buffer Size: 54476      Transition Number: 854.935 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 21:54:32,719][train][INFO][train.py>_log] ==> #66000      Total Loss: 0.765    [weighted Loss:0.765    Policy Loss: 3.180    Value Loss: 4.580    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 55190      Buffer Size: 55190      Transition Number: 870.153 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 21:56:47,005][train][INFO][train.py>_log] ==> #67000      Total Loss: 0.966    [weighted Loss:0.966    Policy Loss: 3.208    Value Loss: 4.939    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 55977      Buffer Size: 55977      Transition Number: 886.613 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 21:58:55,430][train][INFO][train.py>_log] ==> #68000      Total Loss: 0.887    [weighted Loss:0.887    Policy Loss: 3.027    Value Loss: 4.938    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 56722      Buffer Size: 56722      Transition Number: 902.282 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:01:05,847][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 2.838    Value Loss: 4.965    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 57495      Buffer Size: 57495      Transition Number: 918.372 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:03:22,341][train][INFO][train.py>_log] ==> #70000      Total Loss: 0.589    [weighted Loss:0.589    Policy Loss: 2.922    Value Loss: 4.823    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 58300      Buffer Size: 58300      Transition Number: 935.038 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:05:34,907][train][INFO][train.py>_log] ==> #71000      Total Loss: 0.544    [weighted Loss:0.544    Policy Loss: 3.059    Value Loss: 4.945    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 59099      Buffer Size: 59099      Transition Number: 951.356 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:07:49,392][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.253    [weighted Loss:1.253    Policy Loss: 3.028    Value Loss: 4.942    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 59893      Buffer Size: 59893      Transition Number: 967.801 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:10:07,517][train][INFO][train.py>_log] ==> #73000      Total Loss: 0.850    [weighted Loss:0.850    Policy Loss: 3.154    Value Loss: 4.699    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 60725      Buffer Size: 60725      Transition Number: 985.051 k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:12:26,516][train][INFO][train.py>_log] ==> #74000      Total Loss: 0.628    [weighted Loss:0.628    Policy Loss: 3.036    Value Loss: 4.985    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 61564      Buffer Size: 61564      Transition Number: 1002.346k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:14:46,371][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 3.117    Value Loss: 5.266    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 62412      Buffer Size: 62412      Transition Number: 1019.763k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:17:05,378][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.101    [weighted Loss:1.101    Policy Loss: 2.854    Value Loss: 5.004    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 63277      Buffer Size: 63277      Transition Number: 1037.394k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:19:25,941][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.222    [weighted Loss:1.222    Policy Loss: 3.020    Value Loss: 5.030    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 64108      Buffer Size: 64108      Transition Number: 1054.721k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:21:47,434][train][INFO][train.py>_log] ==> #78000      Total Loss: 0.852    [weighted Loss:0.852    Policy Loss: 2.980    Value Loss: 4.749    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 64954      Buffer Size: 64954      Transition Number: 1072.465k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:24:09,304][train][INFO][train.py>_log] ==> #79000      Total Loss: 0.770    [weighted Loss:0.770    Policy Loss: 3.026    Value Loss: 4.882    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 65830      Buffer Size: 65830      Transition Number: 1090.629k Batch Size: 256        Lr: 0.02500 
[2022-01-21 22:26:32,244][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.403    [weighted Loss:1.403    Policy Loss: 2.992    Value Loss: 4.821    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 66676      Buffer Size: 66676      Transition Number: 1108.415k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:28:56,058][train][INFO][train.py>_log] ==> #81000      Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 2.861    Value Loss: 4.821    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 67578      Buffer Size: 67578      Transition Number: 1127.044k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:31:21,256][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 2.999    Value Loss: 5.320    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 68490      Buffer Size: 68490      Transition Number: 1146.025k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:33:47,979][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 2.999    Value Loss: 5.187    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 69394      Buffer Size: 69394      Transition Number: 1164.694k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:36:20,364][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.098    [weighted Loss:1.098    Policy Loss: 2.944    Value Loss: 4.836    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 70350      Buffer Size: 70350      Transition Number: 1184.605k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:38:51,013][train][INFO][train.py>_log] ==> #85000      Total Loss: 0.677    [weighted Loss:0.677    Policy Loss: 2.728    Value Loss: 5.042    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 71316      Buffer Size: 70411      Transition Number: 1199.998k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:41:26,840][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.063    [weighted Loss:1.063    Policy Loss: 3.024    Value Loss: 5.143    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 72300      Buffer Size: 67288      Transition Number: 1199.997k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:44:02,170][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.066    [weighted Loss:1.066    Policy Loss: 3.075    Value Loss: 5.098    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 73243      Buffer Size: 64084      Transition Number: 1199.996k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:46:41,190][train][INFO][train.py>_log] ==> #88000      Total Loss: 0.619    [weighted Loss:0.619    Policy Loss: 3.273    Value Loss: 5.323    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 74243      Buffer Size: 60661      Transition Number: 1199.992k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:49:20,436][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.053    [weighted Loss:1.053    Policy Loss: 2.966    Value Loss: 5.307    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 75262      Buffer Size: 58227      Transition Number: 1200.007k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:51:58,839][train][INFO][train.py>_log] ==> #90000      Total Loss: 0.895    [weighted Loss:0.895    Policy Loss: 3.053    Value Loss: 4.826    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 76299      Buffer Size: 56925      Transition Number: 1200.046k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:54:34,834][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.406    [weighted Loss:1.406    Policy Loss: 3.514    Value Loss: 5.485    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 77263      Buffer Size: 56342      Transition Number: 1200.089k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:57:09,308][train][INFO][train.py>_log] ==> #92000      Total Loss: 0.697    [weighted Loss:0.697    Policy Loss: 3.067    Value Loss: 4.887    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 78217      Buffer Size: 56163      Transition Number: 1199.992k Batch Size: 256        Lr: 0.01250 
[2022-01-21 22:59:45,595][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 3.282    Value Loss: 5.060    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 79170      Buffer Size: 56128      Transition Number: 1200.015k Batch Size: 256        Lr: 0.01250 
[2022-01-21 23:02:21,873][train][INFO][train.py>_log] ==> #94000      Total Loss: 0.913    [weighted Loss:0.913    Policy Loss: 3.234    Value Loss: 5.210    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 80176      Buffer Size: 56164      Transition Number: 1200.002k Batch Size: 256        Lr: 0.01250 
[2022-01-21 23:04:59,246][train][INFO][train.py>_log] ==> #95000      Total Loss: 0.297    [weighted Loss:0.297    Policy Loss: 3.398    Value Loss: 5.038    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 81162      Buffer Size: 56217      Transition Number: 1199.988k Batch Size: 256        Lr: 0.01250 
[2022-01-21 23:07:37,324][train][INFO][train.py>_log] ==> #96000      Total Loss: 0.851    [weighted Loss:0.851    Policy Loss: 3.179    Value Loss: 5.044    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 82143      Buffer Size: 56286      Transition Number: 1200.043k Batch Size: 256        Lr: 0.01250 
[2022-01-21 23:10:14,875][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.285    [weighted Loss:1.285    Policy Loss: 3.221    Value Loss: 5.507    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 83166      Buffer Size: 56416      Transition Number: 1200.013k Batch Size: 256        Lr: 0.01250 
[2022-01-21 23:12:51,609][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.280    [weighted Loss:1.280    Policy Loss: 3.484    Value Loss: 5.379    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 84132      Buffer Size: 56506      Transition Number: 1200.019k Batch Size: 256        Lr: 0.01250 
[2022-01-21 23:15:26,265][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.009    [weighted Loss:1.009    Policy Loss: 3.438    Value Loss: 5.038    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 85094      Buffer Size: 56624      Transition Number: 1199.979k Batch Size: 256        Lr: 0.01250 
[2022-01-21 23:18:03,259][train][INFO][train.py>_log] ==> #100000     Total Loss: 0.464    [weighted Loss:0.464    Policy Loss: 3.323    Value Loss: 5.325    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 86074      Buffer Size: 56689      Transition Number: 1199.977k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:20:38,475][train][INFO][train.py>_log] ==> #101000     Total Loss: 0.614    [weighted Loss:0.614    Policy Loss: 3.163    Value Loss: 4.671    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 87044      Buffer Size: 56759      Transition Number: 1199.996k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:23:16,781][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 3.538    Value Loss: 5.340    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 88062      Buffer Size: 56828      Transition Number: 1200.015k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:25:53,196][train][INFO][train.py>_log] ==> #103000     Total Loss: 0.324    [weighted Loss:0.324    Policy Loss: 3.361    Value Loss: 4.701    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 89053      Buffer Size: 56891      Transition Number: 1199.998k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:28:28,759][train][INFO][train.py>_log] ==> #104000     Total Loss: 0.738    [weighted Loss:0.738    Policy Loss: 3.151    Value Loss: 5.150    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 90041      Buffer Size: 56931      Transition Number: 1199.999k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:31:04,323][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 3.304    Value Loss: 4.927    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 91020      Buffer Size: 56993      Transition Number: 1200.028k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:33:37,558][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 3.535    Value Loss: 4.729    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 91987      Buffer Size: 57002      Transition Number: 1200.004k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:36:11,681][train][INFO][train.py>_log] ==> #107000     Total Loss: 0.460    [weighted Loss:0.460    Policy Loss: 3.398    Value Loss: 5.169    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 92934      Buffer Size: 57039      Transition Number: 1200.001k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:38:46,891][train][INFO][train.py>_log] ==> #108000     Total Loss: 0.725    [weighted Loss:0.725    Policy Loss: 3.557    Value Loss: 5.164    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 93913      Buffer Size: 57094      Transition Number: 1200.034k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:41:25,109][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.456    [weighted Loss:1.456    Policy Loss: 3.555    Value Loss: 4.744    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 94929      Buffer Size: 57135      Transition Number: 1199.997k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:44:00,251][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 3.598    Value Loss: 5.008    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 95936      Buffer Size: 57191      Transition Number: 1199.987k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:46:35,875][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.141    [weighted Loss:1.141    Policy Loss: 3.461    Value Loss: 4.818    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 96910      Buffer Size: 57245      Transition Number: 1199.982k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:49:11,525][train][INFO][train.py>_log] ==> #112000     Total Loss: 0.630    [weighted Loss:0.630    Policy Loss: 3.665    Value Loss: 4.801    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 97897      Buffer Size: 57259      Transition Number: 1199.995k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:51:49,976][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 3.717    Value Loss: 4.792    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 98915      Buffer Size: 57308      Transition Number: 1200.023k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:54:25,764][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.618    Value Loss: 4.953    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 99917      Buffer Size: 57328      Transition Number: 1200.017k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:57:01,633][train][INFO][train.py>_log] ==> #115000     Total Loss: 0.593    [weighted Loss:0.593    Policy Loss: 3.708    Value Loss: 4.925    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 100936     Buffer Size: 57353      Transition Number: 1199.999k Batch Size: 256        Lr: 0.00625 
[2022-01-21 23:59:38,380][train][INFO][train.py>_log] ==> #116000     Total Loss: 0.885    [weighted Loss:0.885    Policy Loss: 3.450    Value Loss: 4.899    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 101940     Buffer Size: 57390      Transition Number: 1200.071k Batch Size: 256        Lr: 0.00625 
[2022-01-22 00:02:15,019][train][INFO][train.py>_log] ==> #117000     Total Loss: 0.696    [weighted Loss:0.696    Policy Loss: 3.785    Value Loss: 5.186    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 102946     Buffer Size: 57464      Transition Number: 1200.029k Batch Size: 256        Lr: 0.00625 
[2022-01-22 00:04:50,179][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.442    [weighted Loss:1.442    Policy Loss: 3.799    Value Loss: 5.050    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 103960     Buffer Size: 57525      Transition Number: 1200.005k Batch Size: 256        Lr: 0.00625 
[2022-01-22 00:07:25,998][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.243    [weighted Loss:1.243    Policy Loss: 3.816    Value Loss: 5.071    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 104965     Buffer Size: 57593      Transition Number: 1200.028k Batch Size: 256        Lr: 0.00625 
[2022-01-22 00:10:05,526][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.012    [weighted Loss:1.012    Policy Loss: 3.598    Value Loss: 5.127    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 105986     Buffer Size: 57652      Transition Number: 1200.006k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:12:42,039][train][INFO][train.py>_log] ==> #121000     Total Loss: 0.590    [weighted Loss:0.590    Policy Loss: 3.765    Value Loss: 4.577    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 106961     Buffer Size: 57675      Transition Number: 1200.003k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:15:22,026][train][INFO][train.py>_log] ==> #122000     Total Loss: 0.740    [weighted Loss:0.740    Policy Loss: 3.838    Value Loss: 5.589    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 107983     Buffer Size: 57712      Transition Number: 1199.999k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:17:59,856][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.353    [weighted Loss:1.353    Policy Loss: 3.688    Value Loss: 5.333    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 108994     Buffer Size: 57758      Transition Number: 1200.024k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:20:38,114][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.239    [weighted Loss:1.239    Policy Loss: 3.646    Value Loss: 4.951    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 110002     Buffer Size: 57793      Transition Number: 1199.999k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:23:16,823][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.008    [weighted Loss:1.008    Policy Loss: 3.985    Value Loss: 5.268    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 111024     Buffer Size: 57828      Transition Number: 1199.996k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:25:55,470][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.383    [weighted Loss:1.383    Policy Loss: 3.887    Value Loss: 4.827    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 112036     Buffer Size: 57845      Transition Number: 1199.983k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:28:34,458][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.895    [weighted Loss:1.895    Policy Loss: 3.851    Value Loss: 5.115    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 113070     Buffer Size: 57875      Transition Number: 1200.009k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:31:14,326][train][INFO][train.py>_log] ==> #128000     Total Loss: 0.627    [weighted Loss:0.627    Policy Loss: 3.753    Value Loss: 4.945    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 114085     Buffer Size: 57893      Transition Number: 1199.983k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:33:50,940][train][INFO][train.py>_log] ==> #129000     Total Loss: 1.059    [weighted Loss:1.059    Policy Loss: 3.910    Value Loss: 4.958    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 115109     Buffer Size: 57913      Transition Number: 1199.992k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:36:28,832][train][INFO][train.py>_log] ==> #130000     Total Loss: 0.471    [weighted Loss:0.471    Policy Loss: 4.018    Value Loss: 5.538    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 116149     Buffer Size: 57930      Transition Number: 1200.009k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:39:08,931][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.249    [weighted Loss:1.249    Policy Loss: 3.780    Value Loss: 5.253    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 117195     Buffer Size: 57927      Transition Number: 1200.007k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:41:48,392][train][INFO][train.py>_log] ==> #132000     Total Loss: 0.679    [weighted Loss:0.679    Policy Loss: 3.968    Value Loss: 4.685    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 118229     Buffer Size: 57937      Transition Number: 1200.003k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:44:28,773][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.221    [weighted Loss:1.221    Policy Loss: 3.995    Value Loss: 4.803    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 119261     Buffer Size: 57926      Transition Number: 1199.983k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:47:07,713][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.744    [weighted Loss:1.744    Policy Loss: 4.091    Value Loss: 4.593    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 120302     Buffer Size: 57933      Transition Number: 1199.983k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:49:45,921][train][INFO][train.py>_log] ==> #135000     Total Loss: 0.769    [weighted Loss:0.769    Policy Loss: 4.136    Value Loss: 5.049    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 121328     Buffer Size: 57936      Transition Number: 1200.021k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:52:23,050][train][INFO][train.py>_log] ==> #136000     Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 3.676    Value Loss: 4.796    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 122336     Buffer Size: 57953      Transition Number: 1199.992k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:55:03,736][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.212    [weighted Loss:1.212    Policy Loss: 3.830    Value Loss: 5.527    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 123378     Buffer Size: 57958      Transition Number: 1200.025k Batch Size: 256        Lr: 0.00313 
[2022-01-22 00:57:42,620][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.298    [weighted Loss:1.298    Policy Loss: 3.771    Value Loss: 4.939    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 124428     Buffer Size: 57987      Transition Number: 1200.013k Batch Size: 256        Lr: 0.00313 
[2022-01-22 01:00:20,232][train][INFO][train.py>_log] ==> #139000     Total Loss: 0.408    [weighted Loss:0.408    Policy Loss: 4.062    Value Loss: 5.564    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 125456     Buffer Size: 58000      Transition Number: 1199.981k Batch Size: 256        Lr: 0.00313 
[2022-01-22 01:03:00,389][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.026    [weighted Loss:1.026    Policy Loss: 3.944    Value Loss: 5.492    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 126476     Buffer Size: 58006      Transition Number: 1200.020k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:05:40,553][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.024    [weighted Loss:1.024    Policy Loss: 3.920    Value Loss: 5.293    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 127545     Buffer Size: 58027      Transition Number: 1200.020k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:08:18,158][train][INFO][train.py>_log] ==> #142000     Total Loss: 0.943    [weighted Loss:0.943    Policy Loss: 4.028    Value Loss: 5.119    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 128588     Buffer Size: 58042      Transition Number: 1200.000k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:10:59,228][train][INFO][train.py>_log] ==> #143000     Total Loss: 0.895    [weighted Loss:0.895    Policy Loss: 3.937    Value Loss: 5.003    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 129621     Buffer Size: 58042      Transition Number: 1200.027k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:13:40,608][train][INFO][train.py>_log] ==> #144000     Total Loss: 0.687    [weighted Loss:0.687    Policy Loss: 4.009    Value Loss: 5.064    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 130651     Buffer Size: 58041      Transition Number: 1199.992k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:16:22,345][train][INFO][train.py>_log] ==> #145000     Total Loss: 1.112    [weighted Loss:1.112    Policy Loss: 3.799    Value Loss: 5.122    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 131706     Buffer Size: 58050      Transition Number: 1200.000k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:19:03,627][train][INFO][train.py>_log] ==> #146000     Total Loss: 0.797    [weighted Loss:0.797    Policy Loss: 3.973    Value Loss: 5.284    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 132778     Buffer Size: 58059      Transition Number: 1199.989k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:21:47,941][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.043    [weighted Loss:1.043    Policy Loss: 3.873    Value Loss: 5.243    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 133858     Buffer Size: 58065      Transition Number: 1199.991k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:24:27,059][train][INFO][train.py>_log] ==> #148000     Total Loss: 0.825    [weighted Loss:0.825    Policy Loss: 3.640    Value Loss: 5.170    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 134867     Buffer Size: 58062      Transition Number: 1200.028k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:27:10,066][train][INFO][train.py>_log] ==> #149000     Total Loss: 0.356    [weighted Loss:0.356    Policy Loss: 3.955    Value Loss: 5.139    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 135915     Buffer Size: 58074      Transition Number: 1199.979k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:29:49,734][train][INFO][train.py>_log] ==> #150000     Total Loss: 0.985    [weighted Loss:0.985    Policy Loss: 3.890    Value Loss: 5.338    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 136936     Buffer Size: 58114      Transition Number: 1199.991k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:32:29,579][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 3.927    Value Loss: 5.280    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 137984     Buffer Size: 58128      Transition Number: 1200.047k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:35:10,575][train][INFO][train.py>_log] ==> #152000     Total Loss: 0.895    [weighted Loss:0.895    Policy Loss: 3.833    Value Loss: 4.762    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 139037     Buffer Size: 58147      Transition Number: 1200.001k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:37:50,773][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.250    [weighted Loss:1.250    Policy Loss: 3.920    Value Loss: 4.998    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 140057     Buffer Size: 58148      Transition Number: 1199.996k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:40:32,340][train][INFO][train.py>_log] ==> #154000     Total Loss: 0.156    [weighted Loss:0.156    Policy Loss: 3.969    Value Loss: 4.679    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 141101     Buffer Size: 58172      Transition Number: 1200.015k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:43:14,576][train][INFO][train.py>_log] ==> #155000     Total Loss: 1.193    [weighted Loss:1.193    Policy Loss: 3.868    Value Loss: 5.227    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 142190     Buffer Size: 58200      Transition Number: 1199.986k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:45:57,718][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.006    [weighted Loss:1.006    Policy Loss: 3.839    Value Loss: 5.308    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 143256     Buffer Size: 58216      Transition Number: 1200.020k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:48:37,942][train][INFO][train.py>_log] ==> #157000     Total Loss: 0.989    [weighted Loss:0.989    Policy Loss: 3.842    Value Loss: 5.397    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 144286     Buffer Size: 58240      Transition Number: 1199.977k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:51:18,207][train][INFO][train.py>_log] ==> #158000     Total Loss: 0.927    [weighted Loss:0.927    Policy Loss: 3.874    Value Loss: 5.067    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 145330     Buffer Size: 58243      Transition Number: 1200.013k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:54:00,103][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 4.013    Value Loss: 5.362    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 146382     Buffer Size: 58258      Transition Number: 1200.028k Batch Size: 256        Lr: 0.00156 
[2022-01-22 01:56:42,795][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.007    [weighted Loss:1.007    Policy Loss: 3.777    Value Loss: 5.345    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 147469     Buffer Size: 58264      Transition Number: 1199.993k Batch Size: 256        Lr: 0.00078 
[2022-01-22 01:59:24,454][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 3.809    Value Loss: 4.947    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 148515     Buffer Size: 58277      Transition Number: 1199.983k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:02:06,519][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.256    [weighted Loss:1.256    Policy Loss: 3.851    Value Loss: 5.076    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 149577     Buffer Size: 58271      Transition Number: 1199.985k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:04:49,571][train][INFO][train.py>_log] ==> #163000     Total Loss: 0.943    [weighted Loss:0.943    Policy Loss: 3.987    Value Loss: 5.202    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 150633     Buffer Size: 58294      Transition Number: 1199.983k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:07:29,339][train][INFO][train.py>_log] ==> #164000     Total Loss: 0.429    [weighted Loss:0.429    Policy Loss: 3.887    Value Loss: 5.390    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 151704     Buffer Size: 58327      Transition Number: 1200.007k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:10:10,429][train][INFO][train.py>_log] ==> #165000     Total Loss: 0.893    [weighted Loss:0.893    Policy Loss: 3.746    Value Loss: 5.112    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 152756     Buffer Size: 58347      Transition Number: 1200.006k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:12:51,992][train][INFO][train.py>_log] ==> #166000     Total Loss: 0.933    [weighted Loss:0.933    Policy Loss: 3.944    Value Loss: 5.646    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 153817     Buffer Size: 58351      Transition Number: 1200.006k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:15:32,852][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.079    [weighted Loss:1.079    Policy Loss: 3.803    Value Loss: 5.454    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 154876     Buffer Size: 58358      Transition Number: 1199.988k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:18:12,661][train][INFO][train.py>_log] ==> #168000     Total Loss: 0.217    [weighted Loss:0.217    Policy Loss: 3.790    Value Loss: 5.680    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 155932     Buffer Size: 58359      Transition Number: 1199.990k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:20:55,721][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 3.953    Value Loss: 5.105    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 157003     Buffer Size: 58390      Transition Number: 1199.982k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:23:36,134][train][INFO][train.py>_log] ==> #170000     Total Loss: 0.822    [weighted Loss:0.822    Policy Loss: 3.959    Value Loss: 5.299    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 158054     Buffer Size: 58382      Transition Number: 1200.047k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:26:15,739][train][INFO][train.py>_log] ==> #171000     Total Loss: 0.833    [weighted Loss:0.833    Policy Loss: 3.829    Value Loss: 5.231    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 159109     Buffer Size: 58407      Transition Number: 1200.029k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:28:56,916][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.461    [weighted Loss:1.461    Policy Loss: 3.948    Value Loss: 5.607    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 160181     Buffer Size: 58398      Transition Number: 1200.032k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:31:39,720][train][INFO][train.py>_log] ==> #173000     Total Loss: 0.764    [weighted Loss:0.764    Policy Loss: 3.901    Value Loss: 5.457    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 161240     Buffer Size: 58393      Transition Number: 1199.991k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:34:18,902][train][INFO][train.py>_log] ==> #174000     Total Loss: 0.595    [weighted Loss:0.595    Policy Loss: 4.005    Value Loss: 5.350    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 162294     Buffer Size: 58377      Transition Number: 1200.003k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:37:00,659][train][INFO][train.py>_log] ==> #175000     Total Loss: 0.319    [weighted Loss:0.319    Policy Loss: 4.000    Value Loss: 4.991    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 163357     Buffer Size: 58360      Transition Number: 1199.995k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:39:41,795][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.217    [weighted Loss:1.217    Policy Loss: 4.055    Value Loss: 4.839    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 164413     Buffer Size: 58349      Transition Number: 1199.997k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:42:23,142][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.202    [weighted Loss:1.202    Policy Loss: 4.120    Value Loss: 4.688    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 165483     Buffer Size: 58382      Transition Number: 1200.009k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:45:06,182][train][INFO][train.py>_log] ==> #178000     Total Loss: 0.779    [weighted Loss:0.779    Policy Loss: 3.936    Value Loss: 5.357    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 166556     Buffer Size: 58395      Transition Number: 1200.039k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:47:47,325][train][INFO][train.py>_log] ==> #179000     Total Loss: 0.546    [weighted Loss:0.546    Policy Loss: 3.962    Value Loss: 5.526    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 167618     Buffer Size: 58408      Transition Number: 1199.998k Batch Size: 256        Lr: 0.00078 
[2022-01-22 02:50:29,398][train][INFO][train.py>_log] ==> #180000     Total Loss: 0.616    [weighted Loss:0.616    Policy Loss: 3.810    Value Loss: 5.517    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 168700     Buffer Size: 58413      Transition Number: 1200.024k Batch Size: 256        Lr: 0.00039 
[2022-01-22 02:53:10,254][train][INFO][train.py>_log] ==> #181000     Total Loss: 0.846    [weighted Loss:0.846    Policy Loss: 3.640    Value Loss: 5.519    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 169752     Buffer Size: 58411      Transition Number: 1200.022k Batch Size: 256        Lr: 0.00039 
[2022-01-22 02:55:51,516][train][INFO][train.py>_log] ==> #182000     Total Loss: 0.996    [weighted Loss:0.996    Policy Loss: 3.769    Value Loss: 5.208    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 170823     Buffer Size: 58427      Transition Number: 1199.999k Batch Size: 256        Lr: 0.00039 
[2022-01-22 02:58:34,256][train][INFO][train.py>_log] ==> #183000     Total Loss: 0.576    [weighted Loss:0.576    Policy Loss: 3.677    Value Loss: 5.092    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 171914     Buffer Size: 58446      Transition Number: 1199.988k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:01:17,006][train][INFO][train.py>_log] ==> #184000     Total Loss: 0.320    [weighted Loss:0.320    Policy Loss: 3.869    Value Loss: 5.533    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 172976     Buffer Size: 58450      Transition Number: 1200.063k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:04:00,399][train][INFO][train.py>_log] ==> #185000     Total Loss: 0.738    [weighted Loss:0.738    Policy Loss: 3.840    Value Loss: 5.194    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 174076     Buffer Size: 58454      Transition Number: 1200.010k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:06:42,412][train][INFO][train.py>_log] ==> #186000     Total Loss: 0.380    [weighted Loss:0.380    Policy Loss: 4.183    Value Loss: 5.266    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 175151     Buffer Size: 58457      Transition Number: 1199.980k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:09:23,370][train][INFO][train.py>_log] ==> #187000     Total Loss: 0.857    [weighted Loss:0.857    Policy Loss: 4.057    Value Loss: 5.154    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 176231     Buffer Size: 58471      Transition Number: 1199.980k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:12:04,807][train][INFO][train.py>_log] ==> #188000     Total Loss: 0.906    [weighted Loss:0.906    Policy Loss: 3.907    Value Loss: 5.353    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 177268     Buffer Size: 58472      Transition Number: 1199.979k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:14:50,550][train][INFO][train.py>_log] ==> #189000     Total Loss: 0.408    [weighted Loss:0.408    Policy Loss: 3.658    Value Loss: 4.803    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 178361     Buffer Size: 58467      Transition Number: 1199.996k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:17:32,329][train][INFO][train.py>_log] ==> #190000     Total Loss: 0.542    [weighted Loss:0.542    Policy Loss: 3.868    Value Loss: 5.674    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 179431     Buffer Size: 58455      Transition Number: 1200.008k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:20:14,678][train][INFO][train.py>_log] ==> #191000     Total Loss: 1.065    [weighted Loss:1.065    Policy Loss: 3.678    Value Loss: 4.895    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 180496     Buffer Size: 58472      Transition Number: 1199.998k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:22:55,081][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.011    [weighted Loss:1.011    Policy Loss: 4.048    Value Loss: 5.370    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 181581     Buffer Size: 58475      Transition Number: 1200.000k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:25:35,336][train][INFO][train.py>_log] ==> #193000     Total Loss: 0.820    [weighted Loss:0.820    Policy Loss: 3.840    Value Loss: 5.218    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 182641     Buffer Size: 58489      Transition Number: 1200.004k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:28:19,716][train][INFO][train.py>_log] ==> #194000     Total Loss: 0.829    [weighted Loss:0.829    Policy Loss: 3.865    Value Loss: 5.564    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 183761     Buffer Size: 58485      Transition Number: 1199.995k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:31:00,132][train][INFO][train.py>_log] ==> #195000     Total Loss: 0.644    [weighted Loss:0.644    Policy Loss: 4.012    Value Loss: 5.241    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 184807     Buffer Size: 58485      Transition Number: 1199.992k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:33:45,594][train][INFO][train.py>_log] ==> #196000     Total Loss: 0.527    [weighted Loss:0.527    Policy Loss: 3.783    Value Loss: 5.730    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 185924     Buffer Size: 58478      Transition Number: 1199.995k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:36:27,271][train][INFO][train.py>_log] ==> #197000     Total Loss: 1.095    [weighted Loss:1.095    Policy Loss: 4.130    Value Loss: 5.084    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 186991     Buffer Size: 58478      Transition Number: 1199.985k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:39:09,255][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.311    [weighted Loss:1.311    Policy Loss: 3.896    Value Loss: 5.193    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 188072     Buffer Size: 58489      Transition Number: 1200.042k Batch Size: 256        Lr: 0.00039 
[2022-01-22 03:41:51,700][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.070    [weighted Loss:1.070    Policy Loss: 3.726    Value Loss: 5.372    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 189126     Buffer Size: 58497      Transition Number: 1199.999k Batch Size: 256        Lr: 0.00039 
