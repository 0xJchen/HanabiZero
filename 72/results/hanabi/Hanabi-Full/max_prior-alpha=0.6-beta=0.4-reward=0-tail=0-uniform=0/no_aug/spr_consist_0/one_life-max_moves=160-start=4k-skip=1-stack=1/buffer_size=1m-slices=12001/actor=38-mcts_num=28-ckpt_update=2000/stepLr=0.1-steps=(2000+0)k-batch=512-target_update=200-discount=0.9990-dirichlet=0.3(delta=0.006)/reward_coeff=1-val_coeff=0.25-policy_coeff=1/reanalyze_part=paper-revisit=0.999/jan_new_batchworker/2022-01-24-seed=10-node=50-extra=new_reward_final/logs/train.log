[2022-01-24 15:06:06,308][train][INFO][train.py>_log] ==> #0          Total Loss: 47.672   [weighted Loss:47.672   Policy Loss: 13.200   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1350       Buffer Size: 1350       Transition Number: 13.750  k Batch Size: 512        Lr: 0.00000 
[2022-01-24 15:09:29,080][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.830    [weighted Loss:3.830    Policy Loss: 12.437   Value Loss: 4.548    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 15593      Buffer Size: 15593      Transition Number: 192.992 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:12:51,166][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.688    [weighted Loss:3.688    Policy Loss: 11.326   Value Loss: 4.169    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 29945      Buffer Size: 29945      Transition Number: 371.905 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:16:11,150][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 6.570    Value Loss: 3.899    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 49180      Buffer Size: 49180      Transition Number: 556.545 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:19:43,995][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 5.184    Value Loss: 3.913    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 69938      Buffer Size: 69938      Transition Number: 752.894 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:23:14,739][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 4.052    Value Loss: 4.010    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 79140      Buffer Size: 79140      Transition Number: 920.326 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:27:05,133][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 4.503    Value Loss: 4.077    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 89562      Buffer Size: 89562      Transition Number: 1119.675k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:30:48,383][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 3.533    Value Loss: 4.112    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 92990      Buffer Size: 86644      Transition Number: 1200.302k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:34:41,868][train][INFO][train.py>_log] ==> #8000       Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 3.484    Value Loss: 3.884    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 96880      Buffer Size: 75337      Transition Number: 1199.974k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:38:33,104][train][INFO][train.py>_log] ==> #9000       Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 3.607    Value Loss: 3.866    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 100050     Buffer Size: 62593      Transition Number: 1200.072k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:42:30,175][train][INFO][train.py>_log] ==> #10000      Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 3.897    Value Loss: 3.979    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 103294     Buffer Size: 46243      Transition Number: 1200.126k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:46:26,041][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 3.685    Value Loss: 4.001    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 106421     Buffer Size: 32482      Transition Number: 1200.048k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:50:17,501][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 4.254    Value Loss: 4.059    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 109494     Buffer Size: 25861      Transition Number: 1200.109k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:54:12,122][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 4.376    Value Loss: 4.248    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 112490     Buffer Size: 21156      Transition Number: 1200.056k Batch Size: 512        Lr: 0.10000 
[2022-01-24 15:58:01,162][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 4.431    Value Loss: 4.215    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 115443     Buffer Size: 20359      Transition Number: 1199.994k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:01:50,149][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 4.310    Value Loss: 4.345    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 118283     Buffer Size: 19590      Transition Number: 1200.041k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:05:43,355][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 4.868    Value Loss: 4.392    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 121194     Buffer Size: 19165      Transition Number: 1200.167k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:09:36,590][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 4.676    Value Loss: 4.447    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 124028     Buffer Size: 18656      Transition Number: 1199.999k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:13:31,203][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 4.989    Value Loss: 4.120    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 126895     Buffer Size: 18221      Transition Number: 1200.042k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:17:26,518][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 5.026    Value Loss: 4.331    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 129783     Buffer Size: 17918      Transition Number: 1199.964k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:21:18,399][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 4.418    Value Loss: 4.341    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 132632     Buffer Size: 17625      Transition Number: 1200.227k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:25:10,932][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 4.360    Value Loss: 4.411    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 135371     Buffer Size: 17447      Transition Number: 1200.044k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:29:03,464][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.942    [weighted Loss:1.942    Policy Loss: 4.522    Value Loss: 4.664    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 138126     Buffer Size: 17292      Transition Number: 1200.406k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:33:00,523][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 3.919    Value Loss: 4.697    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 141057     Buffer Size: 17353      Transition Number: 1200.095k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:36:53,504][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 3.612    Value Loss: 4.868    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 143951     Buffer Size: 17471      Transition Number: 1200.184k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:40:48,674][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 3.932    Value Loss: 4.827    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 146751     Buffer Size: 17498      Transition Number: 1199.978k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:44:41,746][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 3.720    Value Loss: 4.934    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 149670     Buffer Size: 17502      Transition Number: 1200.838k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:48:35,674][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.122    [weighted Loss:2.122    Policy Loss: 3.697    Value Loss: 5.305    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 152631     Buffer Size: 17623      Transition Number: 1200.317k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:52:28,406][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 4.008    Value Loss: 5.078    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 155636     Buffer Size: 17779      Transition Number: 1200.033k Batch Size: 512        Lr: 0.10000 
[2022-01-24 16:56:24,510][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 3.753    Value Loss: 4.969    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 158675     Buffer Size: 17850      Transition Number: 1200.119k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:00:21,760][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.130    [weighted Loss:2.130    Policy Loss: 3.998    Value Loss: 4.726    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 161676     Buffer Size: 17890      Transition Number: 1200.161k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:04:17,250][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.485    [weighted Loss:1.485    Policy Loss: 4.259    Value Loss: 4.643    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 164651     Buffer Size: 17945      Transition Number: 1200.012k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:08:12,206][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.859    [weighted Loss:1.859    Policy Loss: 4.306    Value Loss: 4.664    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 167704     Buffer Size: 18021      Transition Number: 1200.042k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:12:10,058][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 4.028    Value Loss: 4.600    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 170742     Buffer Size: 17835      Transition Number: 1200.084k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:16:03,635][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 4.980    Value Loss: 4.432    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 173809     Buffer Size: 17635      Transition Number: 1200.139k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:20:04,286][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 4.985    Value Loss: 4.428    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 176994     Buffer Size: 17390      Transition Number: 1199.956k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:24:00,574][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 4.844    Value Loss: 4.121    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 180073     Buffer Size: 17221      Transition Number: 1200.482k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:28:01,804][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 4.464    Value Loss: 4.185    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 183326     Buffer Size: 17052      Transition Number: 1200.068k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:31:58,585][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 4.545    Value Loss: 4.330    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 186579     Buffer Size: 16953      Transition Number: 1199.954k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:35:57,442][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 5.307    Value Loss: 4.161    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 189788     Buffer Size: 16896      Transition Number: 1200.748k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:39:58,125][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.990    [weighted Loss:2.990    Policy Loss: 5.724    Value Loss: 4.405    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 193098     Buffer Size: 16829      Transition Number: 1200.226k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:43:57,329][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 5.059    Value Loss: 4.215    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 196414     Buffer Size: 16849      Transition Number: 1200.555k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:47:56,152][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 4.045    Value Loss: 4.348    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 199607     Buffer Size: 16875      Transition Number: 1200.220k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:51:58,862][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 4.994    Value Loss: 4.344    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 202974     Buffer Size: 16816      Transition Number: 1200.168k Batch Size: 512        Lr: 0.10000 
[2022-01-24 17:55:59,065][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.430    [weighted Loss:1.430    Policy Loss: 4.752    Value Loss: 4.262    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 206198     Buffer Size: 16800      Transition Number: 1200.512k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:00:00,813][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 4.683    Value Loss: 4.131    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 209485     Buffer Size: 16750      Transition Number: 1200.595k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:04:01,164][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 4.629    Value Loss: 4.199    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 212807     Buffer Size: 16619      Transition Number: 1200.048k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:08:02,414][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 4.430    Value Loss: 4.439    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 216184     Buffer Size: 16589      Transition Number: 1200.236k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:12:07,072][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.034    [weighted Loss:2.034    Policy Loss: 4.754    Value Loss: 4.511    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 219505     Buffer Size: 16642      Transition Number: 1200.041k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:16:07,889][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 4.339    Value Loss: 4.325    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 222727     Buffer Size: 16722      Transition Number: 1200.717k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:20:06,629][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 4.410    Value Loss: 4.583    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 226046     Buffer Size: 16837      Transition Number: 1200.124k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:24:10,702][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 4.273    Value Loss: 4.599    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 229434     Buffer Size: 17016      Transition Number: 1200.537k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:28:10,705][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 4.371    Value Loss: 4.453    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 232667     Buffer Size: 17097      Transition Number: 1199.939k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:32:13,156][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 4.402    Value Loss: 4.709    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 236016     Buffer Size: 17148      Transition Number: 1200.091k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:36:14,903][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.462    Value Loss: 4.592    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 239372     Buffer Size: 17189      Transition Number: 1200.512k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:40:18,896][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 4.505    Value Loss: 4.428    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 242723     Buffer Size: 17143      Transition Number: 1199.989k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:44:18,800][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 4.056    Value Loss: 4.390    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 246027     Buffer Size: 17071      Transition Number: 1200.533k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:48:22,402][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 4.119    Value Loss: 4.297    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 249314     Buffer Size: 16958      Transition Number: 1200.034k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:52:26,763][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.640    [weighted Loss:1.640    Policy Loss: 4.150    Value Loss: 4.536    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 252643     Buffer Size: 16854      Transition Number: 1200.722k Batch Size: 512        Lr: 0.10000 
[2022-01-24 18:56:29,898][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 4.436    Value Loss: 4.308    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 256216     Buffer Size: 16806      Transition Number: 1200.061k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:00:34,132][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 4.685    Value Loss: 4.522    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 259689     Buffer Size: 16823      Transition Number: 1200.038k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:04:38,026][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 4.390    Value Loss: 4.499    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 263051     Buffer Size: 16863      Transition Number: 1199.996k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:08:41,358][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.257    [weighted Loss:1.257    Policy Loss: 3.806    Value Loss: 4.385    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 266436     Buffer Size: 16943      Transition Number: 1200.056k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:12:42,387][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 4.035    Value Loss: 4.521    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 269804     Buffer Size: 17020      Transition Number: 1200.630k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:16:46,604][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 5.022    Value Loss: 4.677    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 273243     Buffer Size: 16998      Transition Number: 1200.071k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:20:49,610][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.914    [weighted Loss:1.914    Policy Loss: 4.381    Value Loss: 4.391    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 276627     Buffer Size: 17023      Transition Number: 1200.015k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:24:57,380][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.939    [weighted Loss:1.939    Policy Loss: 4.532    Value Loss: 4.440    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 280039     Buffer Size: 17085      Transition Number: 1200.644k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:29:01,224][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.010    [weighted Loss:1.010    Policy Loss: 4.344    Value Loss: 4.504    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 283491     Buffer Size: 17067      Transition Number: 1200.011k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:33:07,357][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 4.327    Value Loss: 4.569    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 286926     Buffer Size: 17068      Transition Number: 1200.015k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:37:12,884][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.693    [weighted Loss:1.693    Policy Loss: 4.029    Value Loss: 4.319    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 290370     Buffer Size: 17110      Transition Number: 1200.365k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:41:20,071][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 4.626    Value Loss: 4.376    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 293872     Buffer Size: 17094      Transition Number: 1200.278k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:45:25,480][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.222    [weighted Loss:2.222    Policy Loss: 4.379    Value Loss: 4.375    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 297350     Buffer Size: 17082      Transition Number: 1200.015k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:49:33,011][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 4.236    Value Loss: 4.215    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 300865     Buffer Size: 17112      Transition Number: 1200.550k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:53:39,523][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.501    [weighted Loss:2.501    Policy Loss: 4.733    Value Loss: 4.213    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 304384     Buffer Size: 17167      Transition Number: 1199.950k Batch Size: 512        Lr: 0.10000 
[2022-01-24 19:57:44,075][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 5.084    Value Loss: 4.374    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 307806     Buffer Size: 17182      Transition Number: 1199.953k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:01:50,034][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 4.833    Value Loss: 4.353    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 311273     Buffer Size: 17200      Transition Number: 1200.170k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:05:54,682][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 4.861    Value Loss: 4.277    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 314778     Buffer Size: 17192      Transition Number: 1200.292k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:10:01,710][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.590    [weighted Loss:1.590    Policy Loss: 4.592    Value Loss: 4.285    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 318353     Buffer Size: 17162      Transition Number: 1200.396k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:14:10,979][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.127    [weighted Loss:1.127    Policy Loss: 5.103    Value Loss: 4.104    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 321990     Buffer Size: 17142      Transition Number: 1199.935k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:18:17,979][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 4.518    Value Loss: 4.315    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 325481     Buffer Size: 17251      Transition Number: 1200.185k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:22:23,485][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 4.689    Value Loss: 4.823    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 329032     Buffer Size: 17334      Transition Number: 1199.953k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:26:30,351][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 4.749    Value Loss: 4.816    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 332966     Buffer Size: 17863      Transition Number: 1200.469k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:30:39,142][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 4.815    Value Loss: 4.954    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 336745     Buffer Size: 18416      Transition Number: 1200.205k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:34:46,958][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 4.763    Value Loss: 5.083    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 340434     Buffer Size: 18795      Transition Number: 1200.261k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:38:53,230][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 4.443    Value Loss: 5.063    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 344222     Buffer Size: 19114      Transition Number: 1200.014k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:42:58,553][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 4.260    Value Loss: 4.924    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 347657     Buffer Size: 19030      Transition Number: 1200.074k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:47:04,349][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 3.908    Value Loss: 4.725    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 351147     Buffer Size: 18484      Transition Number: 1200.011k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:51:17,849][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 3.954    Value Loss: 4.783    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 354733     Buffer Size: 17814      Transition Number: 1199.977k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:55:26,001][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 4.190    Value Loss: 4.316    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 358299     Buffer Size: 17300      Transition Number: 1199.982k Batch Size: 512        Lr: 0.10000 
[2022-01-24 20:59:38,172][train][INFO][train.py>_log] ==> #89000      Total Loss: 0.927    [weighted Loss:0.927    Policy Loss: 4.315    Value Loss: 4.129    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 361860     Buffer Size: 16874      Transition Number: 1200.017k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:03:49,359][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.515    [weighted Loss:2.515    Policy Loss: 5.109    Value Loss: 4.507    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 365475     Buffer Size: 16850      Transition Number: 1201.054k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:07:57,966][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 4.106    Value Loss: 4.179    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 369033     Buffer Size: 16803      Transition Number: 1199.962k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:12:08,558][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 4.764    Value Loss: 4.122    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 372572     Buffer Size: 16820      Transition Number: 1200.168k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:16:15,436][train][INFO][train.py>_log] ==> #93000      Total Loss: 0.843    [weighted Loss:0.843    Policy Loss: 5.069    Value Loss: 4.106    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 376044     Buffer Size: 16849      Transition Number: 1200.322k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:20:26,686][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.511    [weighted Loss:1.511    Policy Loss: 4.943    Value Loss: 4.176    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 379597     Buffer Size: 16856      Transition Number: 1200.163k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:24:32,697][train][INFO][train.py>_log] ==> #95000      Total Loss: 1.240    [weighted Loss:1.240    Policy Loss: 4.986    Value Loss: 4.766    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 383547     Buffer Size: 17343      Transition Number: 1200.164k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:28:39,710][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 4.844    Value Loss: 4.879    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 387376     Buffer Size: 17863      Transition Number: 1200.084k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:32:50,418][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 4.786    Value Loss: 4.713    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 390847     Buffer Size: 17976      Transition Number: 1200.024k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:37:01,347][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.800    [weighted Loss:1.800    Policy Loss: 4.654    Value Loss: 4.798    Reward Loss: 1.270    Consistency Loss: 0.000    ] Replay Episodes Collected: 394394     Buffer Size: 18028      Transition Number: 1200.004k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:41:10,895][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 4.340    Value Loss: 4.451    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 397937     Buffer Size: 17913      Transition Number: 1200.055k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:45:21,850][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 4.481    Value Loss: 4.332    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 401586     Buffer Size: 17220      Transition Number: 1200.043k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:49:29,933][train][INFO][train.py>_log] ==> #101000     Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 3.827    Value Loss: 4.132    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 405107     Buffer Size: 16686      Transition Number: 1200.208k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:53:39,693][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 3.716    Value Loss: 4.146    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 408783     Buffer Size: 16507      Transition Number: 1200.094k Batch Size: 512        Lr: 0.10000 
[2022-01-24 21:57:50,966][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 4.627    Value Loss: 4.077    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 412267     Buffer Size: 16423      Transition Number: 1200.337k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:02:03,374][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.744    [weighted Loss:2.744    Policy Loss: 5.377    Value Loss: 4.210    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 415901     Buffer Size: 16445      Transition Number: 1200.401k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:06:12,701][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.244    [weighted Loss:1.244    Policy Loss: 4.276    Value Loss: 4.303    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 419551     Buffer Size: 16620      Transition Number: 1200.097k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:10:21,981][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 5.211    Value Loss: 4.281    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 423057     Buffer Size: 16802      Transition Number: 1200.597k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:14:30,048][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.841    [weighted Loss:2.841    Policy Loss: 5.157    Value Loss: 4.650    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 426606     Buffer Size: 17194      Transition Number: 1199.963k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:18:39,535][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.102    [weighted Loss:2.102    Policy Loss: 4.895    Value Loss: 4.907    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 430123     Buffer Size: 17587      Transition Number: 1200.243k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:22:50,473][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 4.594    Value Loss: 4.914    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 433587     Buffer Size: 17847      Transition Number: 1200.235k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:27:00,636][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.335    [weighted Loss:1.335    Policy Loss: 4.199    Value Loss: 4.932    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 437114     Buffer Size: 17960      Transition Number: 1199.954k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:31:09,762][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 4.588    Value Loss: 4.586    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 440593     Buffer Size: 17866      Transition Number: 1200.140k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:35:22,676][train][INFO][train.py>_log] ==> #112000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 4.593    Value Loss: 4.292    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 444120     Buffer Size: 17516      Transition Number: 1200.418k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:39:32,107][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 4.917    Value Loss: 4.463    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 447665     Buffer Size: 17160      Transition Number: 1200.768k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:43:43,056][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.805    [weighted Loss:2.805    Policy Loss: 4.518    Value Loss: 4.157    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 451191     Buffer Size: 16921      Transition Number: 1200.120k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:47:52,602][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 4.602    Value Loss: 4.095    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 454955     Buffer Size: 16955      Transition Number: 1200.123k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:52:01,885][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.642    [weighted Loss:1.642    Policy Loss: 5.434    Value Loss: 4.489    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 458419     Buffer Size: 17184      Transition Number: 1199.948k Batch Size: 512        Lr: 0.10000 
[2022-01-24 22:56:14,623][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 5.958    Value Loss: 4.765    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 462734     Buffer Size: 18113      Transition Number: 1200.056k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:00:25,360][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 5.058    Value Loss: 5.132    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 466969     Buffer Size: 19102      Transition Number: 1200.393k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:04:33,376][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 5.053    Value Loss: 4.898    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 470687     Buffer Size: 19555      Transition Number: 1200.306k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:08:42,302][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 4.706    Value Loss: 5.249    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 474499     Buffer Size: 19794      Transition Number: 1200.116k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:12:54,789][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 4.652    Value Loss: 4.805    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 477975     Buffer Size: 19655      Transition Number: 1200.202k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:17:05,229][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 4.879    Value Loss: 4.734    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 481599     Buffer Size: 18779      Transition Number: 1199.932k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:21:18,625][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 4.955    Value Loss: 4.619    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 485404     Buffer Size: 17935      Transition Number: 1200.272k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:25:30,642][train][INFO][train.py>_log] ==> #124000     Total Loss: 0.693    [weighted Loss:0.693    Policy Loss: 4.818    Value Loss: 4.290    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 489014     Buffer Size: 17700      Transition Number: 1200.176k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:29:42,945][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 4.806    Value Loss: 4.380    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 492635     Buffer Size: 17486      Transition Number: 1200.165k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:33:54,554][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 4.978    Value Loss: 4.155    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 496280     Buffer Size: 17598      Transition Number: 1200.616k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:38:08,621][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 5.429    Value Loss: 4.419    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 499932     Buffer Size: 17686      Transition Number: 1200.107k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:42:22,052][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 6.194    Value Loss: 4.620    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 503540     Buffer Size: 17668      Transition Number: 1200.228k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:46:32,840][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 5.718    Value Loss: 4.673    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 507378     Buffer Size: 17897      Transition Number: 1200.148k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:50:48,894][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.000    [weighted Loss:3.000    Policy Loss: 5.914    Value Loss: 5.153    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 511178     Buffer Size: 18148      Transition Number: 1200.311k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:55:00,557][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 5.391    Value Loss: 5.218    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 515183     Buffer Size: 18657      Transition Number: 1200.255k Batch Size: 512        Lr: 0.10000 
[2022-01-24 23:59:10,032][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 5.381    Value Loss: 5.402    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 519135     Buffer Size: 19201      Transition Number: 1200.004k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:03:22,060][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 5.124    Value Loss: 5.153    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 522709     Buffer Size: 19261      Transition Number: 1200.076k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:07:34,136][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 5.384    Value Loss: 4.957    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 526391     Buffer Size: 19024      Transition Number: 1200.403k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:11:47,630][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 5.048    Value Loss: 5.277    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 530261     Buffer Size: 19105      Transition Number: 1200.270k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:15:58,930][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 4.963    Value Loss: 5.119    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 534038     Buffer Size: 18929      Transition Number: 1200.067k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:20:12,216][train][INFO][train.py>_log] ==> #137000     Total Loss: 0.946    [weighted Loss:0.946    Policy Loss: 5.334    Value Loss: 4.747    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 537717     Buffer Size: 18445      Transition Number: 1200.351k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:24:23,576][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 4.816    Value Loss: 4.967    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 541381     Buffer Size: 18454      Transition Number: 1200.047k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:28:36,469][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.623    [weighted Loss:2.623    Policy Loss: 5.144    Value Loss: 4.685    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 544958     Buffer Size: 18369      Transition Number: 1200.317k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:32:48,340][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 5.791    Value Loss: 4.602    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 548706     Buffer Size: 17913      Transition Number: 1200.262k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:37:02,137][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.796    [weighted Loss:2.796    Policy Loss: 5.302    Value Loss: 4.265    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 552229     Buffer Size: 17463      Transition Number: 1200.089k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:41:16,711][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 5.344    Value Loss: 4.315    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 556049     Buffer Size: 17226      Transition Number: 1200.272k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:45:30,889][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 5.779    Value Loss: 4.512    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 560061     Buffer Size: 17597      Transition Number: 1200.401k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:49:44,194][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 6.621    Value Loss: 5.164    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 563865     Buffer Size: 18158      Transition Number: 1200.197k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:54:00,578][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 6.155    Value Loss: 6.326    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 571910     Buffer Size: 22591      Transition Number: 1200.222k Batch Size: 512        Lr: 0.10000 
[2022-01-25 00:58:15,267][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 4.455    Value Loss: 6.547    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 579918     Buffer Size: 27200      Transition Number: 1200.168k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:02:24,028][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.326    [weighted Loss:2.326    Policy Loss: 4.246    Value Loss: 6.429    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 584435     Buffer Size: 28501      Transition Number: 1200.126k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:06:34,457][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 3.991    Value Loss: 6.037    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 588991     Buffer Size: 29217      Transition Number: 1200.012k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:10:43,455][train][INFO][train.py>_log] ==> #149000     Total Loss: 1.967    [weighted Loss:1.967    Policy Loss: 3.864    Value Loss: 5.652    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 592502     Buffer Size: 28550      Transition Number: 1200.249k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:14:57,310][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 3.962    Value Loss: 5.306    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 596219     Buffer Size: 23655      Transition Number: 1200.072k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:19:12,636][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.191    [weighted Loss:1.191    Policy Loss: 4.471    Value Loss: 4.385    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 599766     Buffer Size: 18956      Transition Number: 1200.176k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:23:26,501][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 4.510    Value Loss: 4.197    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 603440     Buffer Size: 17450      Transition Number: 1200.025k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:27:40,804][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 4.843    Value Loss: 4.017    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 607064     Buffer Size: 16549      Transition Number: 1200.157k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:31:51,548][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 5.299    Value Loss: 4.096    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 610659     Buffer Size: 16541      Transition Number: 1200.120k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:36:01,080][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.515    [weighted Loss:2.515    Policy Loss: 5.567    Value Loss: 4.658    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 614274     Buffer Size: 16652      Transition Number: 1200.210k Batch Size: 512        Lr: 0.10000 
[2022-01-25 01:40:12,256][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.140    [weighted Loss:2.140    Policy Loss: 5.660    Value Loss: 4.830    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 617799     Buffer Size: 16830      Transition Number: 1200.320k Batch Size: 512        Lr: 0.10000 
