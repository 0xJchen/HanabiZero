[2021-11-07 07:57:54,611][train][INFO][train.py>_log] ==> #0          Total Loss: 44.345   [weighted Loss:44.345   Policy Loss: 14.347   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 50         Buffer Size: 50         Transition Number: 0.540   k Batch Size: 128        Lr: 0.000   
[2021-11-07 08:00:21,677][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.966    [weighted Loss:4.966    Policy Loss: 14.581   Value Loss: 5.128    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 343        Buffer Size: 343        Transition Number: 4.180   k Batch Size: 128        Lr: 0.010   
[2021-11-07 08:03:03,387][train][INFO][train.py>_log] ==> #2000       Total Loss: 8.389    [weighted Loss:8.389    Policy Loss: 14.512   Value Loss: 3.534    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 699        Buffer Size: 699        Transition Number: 7.681   k Batch Size: 128        Lr: 0.020   
[2021-11-07 08:05:47,013][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.529    [weighted Loss:4.529    Policy Loss: 13.564   Value Loss: 2.977    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1023       Buffer Size: 1023       Transition Number: 11.116  k Batch Size: 128        Lr: 0.030   
[2021-11-07 08:08:34,440][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.933    [weighted Loss:6.933    Policy Loss: 12.502   Value Loss: 2.824    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1337       Buffer Size: 1337       Transition Number: 14.707  k Batch Size: 128        Lr: 0.040   
[2021-11-07 08:11:23,669][train][INFO][train.py>_log] ==> #5000       Total Loss: 6.180    [weighted Loss:6.180    Policy Loss: 13.784   Value Loss: 2.923    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1672       Buffer Size: 1672       Transition Number: 18.295  k Batch Size: 128        Lr: 0.050   
[2021-11-07 08:14:19,287][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.916    [weighted Loss:3.916    Policy Loss: 13.517   Value Loss: 2.767    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 2029       Buffer Size: 2029       Transition Number: 22.049  k Batch Size: 128        Lr: 0.060   
[2021-11-07 08:17:09,538][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.004    [weighted Loss:5.004    Policy Loss: 13.045   Value Loss: 2.831    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 2348       Buffer Size: 2348       Transition Number: 25.728  k Batch Size: 128        Lr: 0.070   
[2021-11-07 08:19:59,314][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.322    [weighted Loss:5.322    Policy Loss: 13.007   Value Loss: 2.688    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 2751       Buffer Size: 2751       Transition Number: 29.556  k Batch Size: 128        Lr: 0.080   
[2021-11-07 08:22:50,095][train][INFO][train.py>_log] ==> #9000       Total Loss: 6.316    [weighted Loss:6.316    Policy Loss: 13.311   Value Loss: 2.664    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 3094       Buffer Size: 3094       Transition Number: 33.234  k Batch Size: 128        Lr: 0.090   
[2021-11-07 08:25:41,763][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.564    [weighted Loss:5.564    Policy Loss: 13.580   Value Loss: 2.988    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 3442       Buffer Size: 3442       Transition Number: 37.049  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:28:34,084][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.891    [weighted Loss:4.891    Policy Loss: 12.433   Value Loss: 2.507    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 3781       Buffer Size: 3781       Transition Number: 40.760  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:31:26,954][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.186    [weighted Loss:5.186    Policy Loss: 11.921   Value Loss: 2.902    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 4221       Buffer Size: 4221       Transition Number: 44.783  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:34:19,421][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.979    [weighted Loss:3.979    Policy Loss: 10.902   Value Loss: 2.564    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 4736       Buffer Size: 4736       Transition Number: 48.712  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:37:09,973][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.867    [weighted Loss:4.867    Policy Loss: 12.762   Value Loss: 2.650    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 5171       Buffer Size: 5171       Transition Number: 52.521  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:40:00,110][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.961    [weighted Loss:3.961    Policy Loss: 13.383   Value Loss: 2.582    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 5523       Buffer Size: 5523       Transition Number: 56.062  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:42:53,476][train][INFO][train.py>_log] ==> #16000      Total Loss: 6.135    [weighted Loss:6.135    Policy Loss: 13.221   Value Loss: 2.816    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 6039       Buffer Size: 6039       Transition Number: 59.981  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:45:45,388][train][INFO][train.py>_log] ==> #17000      Total Loss: 6.509    [weighted Loss:6.509    Policy Loss: 12.788   Value Loss: 2.546    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 6465       Buffer Size: 6465       Transition Number: 63.614  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:48:37,838][train][INFO][train.py>_log] ==> #18000      Total Loss: 6.004    [weighted Loss:6.004    Policy Loss: 12.803   Value Loss: 2.631    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 6868       Buffer Size: 6868       Transition Number: 67.514  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:51:33,932][train][INFO][train.py>_log] ==> #19000      Total Loss: 6.096    [weighted Loss:6.096    Policy Loss: 12.742   Value Loss: 2.624    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 7274       Buffer Size: 7274       Transition Number: 71.270  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:54:31,140][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.425    [weighted Loss:2.425    Policy Loss: 12.977   Value Loss: 2.673    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 7669       Buffer Size: 7669       Transition Number: 75.280  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:57:26,228][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.269    [weighted Loss:4.269    Policy Loss: 13.201   Value Loss: 2.625    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 8021       Buffer Size: 8021       Transition Number: 78.937  k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:00:22,749][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.865    [weighted Loss:4.865    Policy Loss: 13.128   Value Loss: 2.522    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 8385       Buffer Size: 8385       Transition Number: 82.901  k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:03:20,771][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 12.903   Value Loss: 2.665    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 8800       Buffer Size: 8800       Transition Number: 86.829  k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:06:18,434][train][INFO][train.py>_log] ==> #24000      Total Loss: 6.643    [weighted Loss:6.643    Policy Loss: 13.800   Value Loss: 2.660    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 9129       Buffer Size: 9129       Transition Number: 90.691  k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:09:21,365][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.360    [weighted Loss:5.360    Policy Loss: 12.340   Value Loss: 2.506    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 9431       Buffer Size: 9431       Transition Number: 94.525  k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:12:20,605][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.698    [weighted Loss:5.698    Policy Loss: 12.497   Value Loss: 2.621    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 9795       Buffer Size: 9795       Transition Number: 98.481  k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:15:22,270][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.682    [weighted Loss:3.682    Policy Loss: 13.454   Value Loss: 2.742    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 10084      Buffer Size: 10084      Transition Number: 102.283 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:18:23,945][train][INFO][train.py>_log] ==> #28000      Total Loss: 6.676    [weighted Loss:6.676    Policy Loss: 13.037   Value Loss: 2.537    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 10411      Buffer Size: 10411      Transition Number: 106.336 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:21:27,345][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.858    [weighted Loss:3.858    Policy Loss: 12.745   Value Loss: 2.658    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 10733      Buffer Size: 10733      Transition Number: 110.211 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:24:40,302][train][INFO][train.py>_log] ==> #30000      Total Loss: 5.929    [weighted Loss:5.929    Policy Loss: 12.011   Value Loss: 2.802    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 11073      Buffer Size: 11073      Transition Number: 114.477 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:27:57,169][train][INFO][train.py>_log] ==> #31000      Total Loss: 5.019    [weighted Loss:5.019    Policy Loss: 10.818   Value Loss: 2.896    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 11568      Buffer Size: 11568      Transition Number: 118.817 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:31:17,389][train][INFO][train.py>_log] ==> #32000      Total Loss: 6.080    [weighted Loss:6.080    Policy Loss: 11.696   Value Loss: 3.124    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 12182      Buffer Size: 12182      Transition Number: 123.680 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:34:38,732][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.116    [weighted Loss:4.116    Policy Loss: 10.562   Value Loss: 2.858    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 12776      Buffer Size: 12776      Transition Number: 128.245 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:37:57,404][train][INFO][train.py>_log] ==> #34000      Total Loss: 6.129    [weighted Loss:6.129    Policy Loss: 11.525   Value Loss: 2.883    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 13340      Buffer Size: 13340      Transition Number: 132.876 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:41:18,300][train][INFO][train.py>_log] ==> #35000      Total Loss: 5.476    [weighted Loss:5.476    Policy Loss: 11.002   Value Loss: 2.890    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 13830      Buffer Size: 13830      Transition Number: 137.438 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:44:29,461][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.857    [weighted Loss:3.857    Policy Loss: 10.108   Value Loss: 2.968    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 14371      Buffer Size: 14371      Transition Number: 141.823 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:47:40,473][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.337    [weighted Loss:4.337    Policy Loss: 9.459    Value Loss: 2.798    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 14883      Buffer Size: 14883      Transition Number: 145.934 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:51:04,409][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 11.022   Value Loss: 3.319    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 15464      Buffer Size: 15464      Transition Number: 150.732 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:54:18,532][train][INFO][train.py>_log] ==> #39000      Total Loss: 4.106    [weighted Loss:4.106    Policy Loss: 10.914   Value Loss: 3.057    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 15972      Buffer Size: 15972      Transition Number: 155.131 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:57:30,522][train][INFO][train.py>_log] ==> #40000      Total Loss: 5.514    [weighted Loss:5.514    Policy Loss: 9.562    Value Loss: 3.017    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 16471      Buffer Size: 16471      Transition Number: 159.409 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:00:45,003][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.464    [weighted Loss:4.464    Policy Loss: 11.502   Value Loss: 3.015    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 16937      Buffer Size: 16937      Transition Number: 163.429 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:04:12,297][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 12.073   Value Loss: 3.128    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 17236      Buffer Size: 17236      Transition Number: 167.478 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:07:44,663][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 11.603   Value Loss: 3.061    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 17557      Buffer Size: 17557      Transition Number: 171.715 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:11:22,384][train][INFO][train.py>_log] ==> #44000      Total Loss: 4.822    [weighted Loss:4.822    Policy Loss: 12.164   Value Loss: 3.197    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 17926      Buffer Size: 17926      Transition Number: 176.410 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:15:00,286][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.352    [weighted Loss:4.352    Policy Loss: 11.799   Value Loss: 3.135    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 18219      Buffer Size: 18219      Transition Number: 180.514 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:18:45,445][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.404    [weighted Loss:4.404    Policy Loss: 11.281   Value Loss: 2.989    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 18442      Buffer Size: 18442      Transition Number: 184.893 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:22:41,036][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.466    [weighted Loss:3.466    Policy Loss: 11.023   Value Loss: 3.406    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 18611      Buffer Size: 18611      Transition Number: 189.114 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:26:35,888][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 11.347   Value Loss: 3.304    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 18852      Buffer Size: 18852      Transition Number: 192.375 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:30:49,379][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 10.281   Value Loss: 3.536    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 19062      Buffer Size: 19062      Transition Number: 195.476 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:35:09,753][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 8.949    Value Loss: 3.567    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 19375      Buffer Size: 19375      Transition Number: 200.241 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:39:19,766][train][INFO][train.py>_log] ==> #51000      Total Loss: 4.063    [weighted Loss:4.063    Policy Loss: 8.708    Value Loss: 3.209    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 19925      Buffer Size: 19925      Transition Number: 205.035 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:43:36,757][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.217    [weighted Loss:3.217    Policy Loss: 6.966    Value Loss: 3.200    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 20390      Buffer Size: 20390      Transition Number: 209.604 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:48:00,042][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 6.663    Value Loss: 3.306    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 20744      Buffer Size: 20744      Transition Number: 214.016 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:52:26,538][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 6.089    Value Loss: 3.714    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 21107      Buffer Size: 21107      Transition Number: 218.732 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:56:58,613][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 4.714    Value Loss: 3.840    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 21368      Buffer Size: 21368      Transition Number: 223.769 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:01:49,179][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 3.789    Value Loss: 3.700    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 21641      Buffer Size: 21641      Transition Number: 229.483 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:06:49,888][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 5.451    Value Loss: 3.832    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 21912      Buffer Size: 21912      Transition Number: 235.312 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:11:47,599][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.738    [weighted Loss:2.738    Policy Loss: 5.369    Value Loss: 3.695    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 22300      Buffer Size: 22300      Transition Number: 240.978 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:16:57,187][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.728    [weighted Loss:1.728    Policy Loss: 3.730    Value Loss: 3.814    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 22606      Buffer Size: 22606      Transition Number: 246.326 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:22:11,866][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 3.174    Value Loss: 3.975    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 22787      Buffer Size: 22787      Transition Number: 251.755 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:27:42,217][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 2.582    Value Loss: 3.929    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 22978      Buffer Size: 22978      Transition Number: 258.239 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:33:16,936][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 2.962    Value Loss: 3.812    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 23250      Buffer Size: 23250      Transition Number: 264.836 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:38:34,704][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 2.422    Value Loss: 3.789    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 23470      Buffer Size: 23470      Transition Number: 270.545 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:44:17,953][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.564    [weighted Loss:1.564    Policy Loss: 2.835    Value Loss: 3.961    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 23686      Buffer Size: 23686      Transition Number: 278.024 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:49:54,884][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 3.197    Value Loss: 3.876    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 23949      Buffer Size: 23949      Transition Number: 284.554 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:55:36,895][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.117    [weighted Loss:1.117    Policy Loss: 2.683    Value Loss: 4.035    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 24261      Buffer Size: 24261      Transition Number: 290.796 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:01:08,654][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 2.768    Value Loss: 4.055    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 24484      Buffer Size: 24484      Transition Number: 296.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:06:55,721][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 2.621    Value Loss: 3.783    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 24762      Buffer Size: 24762      Transition Number: 304.800 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:13:12,791][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.583    [weighted Loss:1.583    Policy Loss: 2.652    Value Loss: 4.238    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 24946      Buffer Size: 24946      Transition Number: 313.302 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:19:36,111][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 2.979    Value Loss: 4.014    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 25193      Buffer Size: 25193      Transition Number: 321.500 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:25:53,844][train][INFO][train.py>_log] ==> #71000      Total Loss: 0.936    [weighted Loss:0.936    Policy Loss: 2.885    Value Loss: 4.005    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 25636      Buffer Size: 25636      Transition Number: 328.864 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:32:02,185][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 3.446    Value Loss: 4.225    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 26573      Buffer Size: 26573      Transition Number: 337.180 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:37:57,207][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 3.135    Value Loss: 4.197    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 27114      Buffer Size: 27114      Transition Number: 344.322 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:44:06,024][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.296    [weighted Loss:4.296    Policy Loss: 8.657    Value Loss: 4.192    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 27497      Buffer Size: 27497      Transition Number: 351.865 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:50:21,445][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 2.627    Value Loss: 3.972    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 27940      Buffer Size: 27940      Transition Number: 358.081 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:56:26,381][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.898    [weighted Loss:1.898    Policy Loss: 2.393    Value Loss: 3.943    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 28710      Buffer Size: 28710      Transition Number: 365.165 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:02:35,038][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 3.847    Value Loss: 4.040    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 29469      Buffer Size: 29469      Transition Number: 372.147 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:09:03,962][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 3.362    Value Loss: 4.167    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 29766      Buffer Size: 29766      Transition Number: 380.295 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:15:21,646][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.764    [weighted Loss:1.764    Policy Loss: 2.505    Value Loss: 4.096    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 30347      Buffer Size: 30347      Transition Number: 388.049 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:21:49,174][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.100    [weighted Loss:1.100    Policy Loss: 2.641    Value Loss: 3.898    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 30919      Buffer Size: 30919      Transition Number: 396.180 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:28:08,113][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.733    [weighted Loss:4.733    Policy Loss: 7.892    Value Loss: 4.108    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 31938      Buffer Size: 31466      Transition Number: 400.019 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:34:31,447][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 3.793    Value Loss: 3.957    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 32966      Buffer Size: 31633      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:40:47,699][train][INFO][train.py>_log] ==> #83000      Total Loss: 0.858    [weighted Loss:0.858    Policy Loss: 2.241    Value Loss: 4.104    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 33499      Buffer Size: 31444      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:47:04,985][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 4.111    Value Loss: 4.185    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 33958      Buffer Size: 31133      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:53:39,568][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 2.456    Value Loss: 4.032    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 34428      Buffer Size: 30813      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:00:25,886][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.490    [weighted Loss:1.490    Policy Loss: 1.874    Value Loss: 4.156    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 34812      Buffer Size: 30184      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:07:22,283][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 1.895    Value Loss: 4.729    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 35224      Buffer Size: 29583      Transition Number: 400.016 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:14:03,024][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.341    [weighted Loss:1.341    Policy Loss: 2.103    Value Loss: 4.236    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 35665      Buffer Size: 29019      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:20:42,956][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 2.491    Value Loss: 4.148    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 35980      Buffer Size: 28488      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:27:30,438][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 4.032    Value Loss: 4.278    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 36333      Buffer Size: 28047      Transition Number: 400.031 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:34:19,092][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 2.819    Value Loss: 4.406    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 36832      Buffer Size: 27735      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:41:04,718][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 2.839    Value Loss: 3.966    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 38030      Buffer Size: 28115      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:47:46,228][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 2.653    Value Loss: 4.363    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 39140      Buffer Size: 28489      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:54:29,133][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 2.624    Value Loss: 4.683    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 39768      Buffer Size: 28260      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:01:15,509][train][INFO][train.py>_log] ==> #95000      Total Loss: 0.904    [weighted Loss:0.904    Policy Loss: 2.118    Value Loss: 4.676    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 40606      Buffer Size: 27907      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:07:57,030][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 4.645    Value Loss: 4.565    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 41185      Buffer Size: 27520      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:14:43,833][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 5.992    Value Loss: 4.595    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 41799      Buffer Size: 27078      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:21:35,304][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.720    [weighted Loss:1.720    Policy Loss: 3.151    Value Loss: 4.457    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 42487      Buffer Size: 26675      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:28:21,058][train][INFO][train.py>_log] ==> #99000      Total Loss: 0.760    [weighted Loss:0.760    Policy Loss: 2.544    Value Loss: 4.192    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 42993      Buffer Size: 26214      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:35:16,810][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 4.397    Value Loss: 4.579    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 43688      Buffer Size: 26170      Transition Number: 400.021 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:42:20,469][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.896    [weighted Loss:3.896    Policy Loss: 7.321    Value Loss: 4.559    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 44343      Buffer Size: 26107      Transition Number: 400.001 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:49:17,115][train][INFO][train.py>_log] ==> #102000     Total Loss: 4.333    [weighted Loss:4.333    Policy Loss: 7.142    Value Loss: 4.650    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 44981      Buffer Size: 26330      Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:56:14,256][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.921    [weighted Loss:3.921    Policy Loss: 8.309    Value Loss: 4.626    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 45277      Buffer Size: 26022      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:03:27,284][train][INFO][train.py>_log] ==> #104000     Total Loss: 4.699    [weighted Loss:4.699    Policy Loss: 8.079    Value Loss: 4.196    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 46070      Buffer Size: 25847      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:10:20,019][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 7.437    Value Loss: 4.741    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 46609      Buffer Size: 25710      Transition Number: 399.934 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:17:13,045][train][INFO][train.py>_log] ==> #106000     Total Loss: 4.382    [weighted Loss:4.382    Policy Loss: 8.896    Value Loss: 4.560    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 47975      Buffer Size: 26520      Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:24:05,635][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 8.359    Value Loss: 4.585    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 48332      Buffer Size: 26505      Transition Number: 400.020 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:31:09,521][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.004    [weighted Loss:4.004    Policy Loss: 8.727    Value Loss: 4.960    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 48660      Buffer Size: 26319      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:38:19,842][train][INFO][train.py>_log] ==> #109000     Total Loss: 4.459    [weighted Loss:4.459    Policy Loss: 8.622    Value Loss: 4.514    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 48897      Buffer Size: 26132      Transition Number: 399.931 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:45:30,317][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.421    [weighted Loss:3.421    Policy Loss: 8.746    Value Loss: 4.132    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 49286      Buffer Size: 26220      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:52:45,919][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.277    [weighted Loss:3.277    Policy Loss: 8.445    Value Loss: 4.255    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 49523      Buffer Size: 26125      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:00:03,773][train][INFO][train.py>_log] ==> #112000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 10.248   Value Loss: 4.988    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 49974      Buffer Size: 26313      Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:07:11,554][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 7.821    Value Loss: 4.925    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 50225      Buffer Size: 26206      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:14:45,547][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.601    [weighted Loss:3.601    Policy Loss: 7.568    Value Loss: 4.961    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 50488      Buffer Size: 26029      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:22:03,285][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.543    [weighted Loss:4.543    Policy Loss: 9.067    Value Loss: 4.730    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 50729      Buffer Size: 25960      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:29:41,506][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.316    [weighted Loss:3.316    Policy Loss: 8.503    Value Loss: 5.061    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 50950      Buffer Size: 25941      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:37:15,572][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 9.114    Value Loss: 4.710    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 51176      Buffer Size: 25750      Transition Number: 399.937 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:45:00,473][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 7.320    Value Loss: 4.791    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 51565      Buffer Size: 25199      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:52:40,980][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.585    [weighted Loss:3.585    Policy Loss: 6.163    Value Loss: 4.911    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 51899      Buffer Size: 24740      Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:00:07,762][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.371    [weighted Loss:3.371    Policy Loss: 6.207    Value Loss: 4.905    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 52205      Buffer Size: 24510      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:07:44,185][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.773    [weighted Loss:3.773    Policy Loss: 6.648    Value Loss: 4.955    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 52477      Buffer Size: 23850      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:15:05,113][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.873    [weighted Loss:3.873    Policy Loss: 6.637    Value Loss: 5.037    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 52753      Buffer Size: 23209      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:22:47,652][train][INFO][train.py>_log] ==> #123000     Total Loss: 4.174    [weighted Loss:4.174    Policy Loss: 7.002    Value Loss: 5.365    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 53051      Buffer Size: 22991      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:30:30,460][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.309    [weighted Loss:4.309    Policy Loss: 5.948    Value Loss: 5.207    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 53289      Buffer Size: 22480      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:38:14,433][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.830    [weighted Loss:1.830    Policy Loss: 5.076    Value Loss: 5.017    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 53538      Buffer Size: 21653      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:46:09,138][train][INFO][train.py>_log] ==> #126000     Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 5.902    Value Loss: 5.338    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 53816      Buffer Size: 20735      Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:54:14,334][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.853    [weighted Loss:2.853    Policy Loss: 6.534    Value Loss: 4.846    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 54073      Buffer Size: 20274      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:02:37,566][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 5.948    Value Loss: 5.011    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 54332      Buffer Size: 19900      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:10:43,079][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 6.199    Value Loss: 5.234    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 54573      Buffer Size: 19695      Transition Number: 399.934 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:18:50,472][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 6.231    Value Loss: 5.159    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 54797      Buffer Size: 19317      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:27:23,588][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 5.331    Value Loss: 5.142    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 55005      Buffer Size: 18987      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:36:00,876][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.996    [weighted Loss:2.996    Policy Loss: 5.380    Value Loss: 4.831    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 55232      Buffer Size: 18580      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:44:51,512][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 5.154    Value Loss: 5.140    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 55455      Buffer Size: 17356      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:54:40,062][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 4.798    Value Loss: 4.862    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 55705      Buffer Size: 16089      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:04:06,217][train][INFO][train.py>_log] ==> #135000     Total Loss: 4.050    [weighted Loss:4.050    Policy Loss: 7.317    Value Loss: 5.115    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 55963      Buffer Size: 15196      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:13:56,924][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 5.316    Value Loss: 5.197    Reward Loss: 1.064    Consistency Loss: 0.000    ] Replay Episodes Collected: 56292      Buffer Size: 14565      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:23:34,433][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.559    [weighted Loss:2.559    Policy Loss: 5.711    Value Loss: 5.767    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 56579      Buffer Size: 13879      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:33:22,872][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.799    [weighted Loss:2.799    Policy Loss: 6.793    Value Loss: 5.138    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 56862      Buffer Size: 13158      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:43:13,233][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.508    [weighted Loss:2.508    Policy Loss: 5.758    Value Loss: 5.463    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 57128      Buffer Size: 12400      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:53:46,172][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 5.592    Value Loss: 4.893    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 57435      Buffer Size: 11811      Transition Number: 400.044 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:04:14,346][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 4.389    Value Loss: 4.663    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 57745      Buffer Size: 10794      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:14:56,817][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 4.857    Value Loss: 5.029    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 58036      Buffer Size: 9639       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:25:40,703][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 4.727    Value Loss: 5.395    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 58340      Buffer Size: 9441       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:36:18,314][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 4.806    Value Loss: 5.233    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 58661      Buffer Size: 9172       Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:46:56,911][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 5.046    Value Loss: 5.167    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 58964      Buffer Size: 8856       Transition Number: 400.009 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:57:40,419][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.519    [weighted Loss:2.519    Policy Loss: 5.072    Value Loss: 5.360    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 59242      Buffer Size: 8684       Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:08:38,553][train][INFO][train.py>_log] ==> #147000     Total Loss: 3.495    [weighted Loss:3.495    Policy Loss: 5.614    Value Loss: 4.816    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 59542      Buffer Size: 8576       Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:19:28,223][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.293    [weighted Loss:3.293    Policy Loss: 8.529    Value Loss: 5.003    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 59878      Buffer Size: 8441       Transition Number: 399.929 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:30:18,445][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.162    [weighted Loss:3.162    Policy Loss: 5.386    Value Loss: 5.031    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 60348      Buffer Size: 8354       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:40:46,954][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 6.199    Value Loss: 5.530    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 60779      Buffer Size: 8366       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:51:51,329][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 5.361    Value Loss: 5.252    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 61090      Buffer Size: 8216       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:02:45,518][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 5.368    Value Loss: 4.848    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 61404      Buffer Size: 8111       Transition Number: 400.001 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:13:37,069][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 4.846    Value Loss: 5.280    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 61677      Buffer Size: 8011       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:24:51,615][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.290    [weighted Loss:1.290    Policy Loss: 4.531    Value Loss: 5.144    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 61994      Buffer Size: 7905       Transition Number: 399.928 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:36:30,724][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 5.078    Value Loss: 5.406    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 62310      Buffer Size: 7849       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:48:04,318][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 5.676    Value Loss: 5.640    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 62629      Buffer Size: 7820       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:59:26,425][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 4.878    Value Loss: 5.158    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 62940      Buffer Size: 7855       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:10:40,164][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 4.766    Value Loss: 4.675    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 63247      Buffer Size: 7875       Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:22:01,163][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 4.684    Value Loss: 4.674    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 63543      Buffer Size: 7911       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:33:03,185][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 4.785    Value Loss: 5.311    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 63845      Buffer Size: 7908       Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:43:49,484][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.660    [weighted Loss:2.660    Policy Loss: 4.597    Value Loss: 5.249    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 64411      Buffer Size: 8122       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:54:14,427][train][INFO][train.py>_log] ==> #162000     Total Loss: 3.208    [weighted Loss:3.208    Policy Loss: 5.981    Value Loss: 5.247    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 64878      Buffer Size: 8299       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:04:46,150][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 5.086    Value Loss: 5.487    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 65240      Buffer Size: 8376       Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:15:32,804][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.939    [weighted Loss:1.939    Policy Loss: 4.679    Value Loss: 5.114    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 65516      Buffer Size: 8351       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:26:37,991][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 6.377    Value Loss: 5.191    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 65818      Buffer Size: 8357       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:37:13,546][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 6.389    Value Loss: 5.305    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 66220      Buffer Size: 8472       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:47:51,941][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 5.318    Value Loss: 5.341    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 66633      Buffer Size: 8621       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:58:33,205][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.562    [weighted Loss:1.562    Policy Loss: 7.425    Value Loss: 5.328    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 66995      Buffer Size: 8696       Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:09:08,502][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 8.234    Value Loss: 5.139    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 67278      Buffer Size: 8677       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:19:53,560][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.649    [weighted Loss:2.649    Policy Loss: 7.776    Value Loss: 5.335    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 67571      Buffer Size: 8662       Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:31:09,855][train][INFO][train.py>_log] ==> #171000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 7.224    Value Loss: 5.036    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 67873      Buffer Size: 8668       Transition Number: 399.928 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:42:18,839][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 6.511    Value Loss: 5.120    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 68418      Buffer Size: 8940       Transition Number: 400.016 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:52:39,915][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 5.723    Value Loss: 5.529    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 68909      Buffer Size: 9150       Transition Number: 399.935 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:02:47,156][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.475    [weighted Loss:2.475    Policy Loss: 5.137    Value Loss: 5.432    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 69395      Buffer Size: 9273       Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:13:12,518][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.185    [weighted Loss:2.185    Policy Loss: 5.859    Value Loss: 5.274    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 69890      Buffer Size: 9323       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:23:34,060][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 6.555    Value Loss: 5.515    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 70345      Buffer Size: 9426       Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:33:53,789][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 6.892    Value Loss: 5.212    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 70641      Buffer Size: 9444       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:44:13,433][train][INFO][train.py>_log] ==> #178000     Total Loss: 4.086    [weighted Loss:4.086    Policy Loss: 7.832    Value Loss: 5.117    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 70914      Buffer Size: 9428       Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:54:47,647][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 7.205    Value Loss: 5.478    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 71199      Buffer Size: 9443       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:05:23,529][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.746    [weighted Loss:1.746    Policy Loss: 6.823    Value Loss: 5.521    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 71536      Buffer Size: 9497       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:15:49,299][train][INFO][train.py>_log] ==> #181000     Total Loss: 4.323    [weighted Loss:4.323    Policy Loss: 8.482    Value Loss: 5.794    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 71832      Buffer Size: 9516       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:26:03,328][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 7.226    Value Loss: 5.024    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 72123      Buffer Size: 9537       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:36:35,573][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 6.379    Value Loss: 6.096    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 72413      Buffer Size: 9547       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:47:37,721][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 6.311    Value Loss: 5.141    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 72739      Buffer Size: 9579       Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:58:15,994][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 5.298    Value Loss: 5.333    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 73072      Buffer Size: 9627       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:08:32,014][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 7.682    Value Loss: 5.382    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 73596      Buffer Size: 9880       Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:18:26,115][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 5.824    Value Loss: 5.479    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 74058      Buffer Size: 9977       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:28:51,070][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.383    [weighted Loss:1.383    Policy Loss: 6.800    Value Loss: 5.243    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 74365      Buffer Size: 9756       Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:38:52,162][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 6.930    Value Loss: 5.362    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 74688      Buffer Size: 9637       Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:49:23,819][train][INFO][train.py>_log] ==> #190000     Total Loss: 2.881    [weighted Loss:2.881    Policy Loss: 6.006    Value Loss: 5.526    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 75004      Buffer Size: 9649       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:59:40,494][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 5.158    Value Loss: 5.324    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 75371      Buffer Size: 9769       Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:09:41,859][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.695    [weighted Loss:2.695    Policy Loss: 5.609    Value Loss: 6.188    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 76202      Buffer Size: 10293      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:19:47,840][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.977    [weighted Loss:3.977    Policy Loss: 5.790    Value Loss: 5.489    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 76634      Buffer Size: 10344      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:30:04,935][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.379    [weighted Loss:3.379    Policy Loss: 7.154    Value Loss: 5.683    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 77098      Buffer Size: 10397      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:40:10,996][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 8.211    Value Loss: 5.974    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 77502      Buffer Size: 10476      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:50:10,377][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.894    [weighted Loss:3.894    Policy Loss: 8.330    Value Loss: 6.128    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 77971      Buffer Size: 10685      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:59:46,472][train][INFO][train.py>_log] ==> #197000     Total Loss: 4.066    [weighted Loss:4.066    Policy Loss: 7.465    Value Loss: 5.208    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 78513      Buffer Size: 10963      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:09:34,711][train][INFO][train.py>_log] ==> #198000     Total Loss: 4.296    [weighted Loss:4.296    Policy Loss: 7.710    Value Loss: 5.706    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 79179      Buffer Size: 11372      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:19:08,805][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 7.623    Value Loss: 5.554    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 79689      Buffer Size: 11484      Transition Number: 400.016 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:28:36,063][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.924    [weighted Loss:2.924    Policy Loss: 8.010    Value Loss: 5.345    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 79984      Buffer Size: 11332      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:38:43,946][train][INFO][train.py>_log] ==> #201000     Total Loss: 3.377    [weighted Loss:3.377    Policy Loss: 6.918    Value Loss: 5.550    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 80289      Buffer Size: 11135      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:48:59,749][train][INFO][train.py>_log] ==> #202000     Total Loss: 4.072    [weighted Loss:4.072    Policy Loss: 7.708    Value Loss: 5.426    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 80632      Buffer Size: 10981      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:59:23,635][train][INFO][train.py>_log] ==> #203000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 8.230    Value Loss: 5.441    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 80987      Buffer Size: 10877      Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:09:27,089][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 8.423    Value Loss: 5.505    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 81309      Buffer Size: 10807      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:19:45,793][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 8.289    Value Loss: 5.668    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 81605      Buffer Size: 10831      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:30:11,243][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 6.912    Value Loss: 5.342    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 81923      Buffer Size: 10890      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:40:33,398][train][INFO][train.py>_log] ==> #207000     Total Loss: 3.815    [weighted Loss:3.815    Policy Loss: 7.319    Value Loss: 5.414    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 82196      Buffer Size: 10859      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:51:02,127][train][INFO][train.py>_log] ==> #208000     Total Loss: 3.372    [weighted Loss:3.372    Policy Loss: 9.680    Value Loss: 5.383    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 82500      Buffer Size: 10848      Transition Number: 400.112 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:01:17,066][train][INFO][train.py>_log] ==> #209000     Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 6.730    Value Loss: 5.655    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 82843      Buffer Size: 10902      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:11:31,784][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.561    [weighted Loss:3.561    Policy Loss: 7.849    Value Loss: 6.042    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 83216      Buffer Size: 10984      Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:21:41,376][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.125    [weighted Loss:2.125    Policy Loss: 5.405    Value Loss: 5.442    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 83544      Buffer Size: 11056      Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:31:36,110][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.460    [weighted Loss:2.460    Policy Loss: 5.636    Value Loss: 5.663    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 83849      Buffer Size: 11076      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:41:24,073][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 8.196    Value Loss: 5.797    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 84140      Buffer Size: 11070      Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:51:19,729][train][INFO][train.py>_log] ==> #214000     Total Loss: 4.084    [weighted Loss:4.084    Policy Loss: 7.128    Value Loss: 5.973    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 84414      Buffer Size: 10856      Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:01:21,405][train][INFO][train.py>_log] ==> #215000     Total Loss: 4.731    [weighted Loss:4.731    Policy Loss: 6.979    Value Loss: 5.909    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 84699      Buffer Size: 10672      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:11:20,564][train][INFO][train.py>_log] ==> #216000     Total Loss: 3.591    [weighted Loss:3.591    Policy Loss: 8.245    Value Loss: 6.332    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 85028      Buffer Size: 10700      Transition Number: 399.948 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:21:28,195][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.832    [weighted Loss:2.832    Policy Loss: 8.633    Value Loss: 5.929    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 85423      Buffer Size: 10781      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:31:25,390][train][INFO][train.py>_log] ==> #218000     Total Loss: 3.747    [weighted Loss:3.747    Policy Loss: 6.559    Value Loss: 5.786    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 85772      Buffer Size: 10836      Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:41:19,290][train][INFO][train.py>_log] ==> #219000     Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 7.639    Value Loss: 5.482    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 86135      Buffer Size: 10863      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:51:28,831][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 7.797    Value Loss: 5.764    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 86781      Buffer Size: 10761      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:01:39,921][train][INFO][train.py>_log] ==> #221000     Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 7.696    Value Loss: 5.884    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 87202      Buffer Size: 10674      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:11:52,564][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 7.657    Value Loss: 5.590    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 87552      Buffer Size: 10584      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:22:04,607][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 7.393    Value Loss: 5.965    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 87916      Buffer Size: 10529      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:32:11,673][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 5.827    Value Loss: 5.803    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 88305      Buffer Size: 10444      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:42:25,175][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.904    [weighted Loss:1.904    Policy Loss: 7.487    Value Loss: 5.432    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 88699      Buffer Size: 10278      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:52:46,415][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 8.160    Value Loss: 5.801    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 89082      Buffer Size: 10017      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:03:05,594][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 7.384    Value Loss: 5.521    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 89482      Buffer Size: 9853       Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:13:27,825][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 7.147    Value Loss: 5.253    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 89796      Buffer Size: 9812       Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:24:05,971][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.309    Value Loss: 5.614    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 90096      Buffer Size: 9795       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:34:49,934][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 6.530    Value Loss: 5.560    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 90453      Buffer Size: 9789       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:45:20,094][train][INFO][train.py>_log] ==> #231000     Total Loss: 4.035    [weighted Loss:4.035    Policy Loss: 7.120    Value Loss: 5.807    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 90752      Buffer Size: 9718       Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:55:53,695][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 6.640    Value Loss: 5.909    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 91098      Buffer Size: 9718       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-08 13:06:10,615][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 7.127    Value Loss: 6.090    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 91483      Buffer Size: 9817       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-08 13:16:36,956][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.333    [weighted Loss:2.333    Policy Loss: 7.752    Value Loss: 5.549    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 91926      Buffer Size: 9939       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-08 13:26:36,233][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 7.561    Value Loss: 5.590    Reward Loss: 0.952    Consistency Loss: 0.000    ] Replay Episodes Collected: 92340      Buffer Size: 10102      Transition Number: 399.933 k Batch Size: 128        Lr: 0.100   
[2021-11-08 13:36:26,612][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 7.205    Value Loss: 6.061    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 92769      Buffer Size: 10256      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-08 13:46:14,472][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 7.476    Value Loss: 5.951    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 93104      Buffer Size: 10284      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-08 13:56:12,021][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 6.325    Value Loss: 5.836    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 93439      Buffer Size: 10275      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-08 14:05:55,785][train][INFO][train.py>_log] ==> #239000     Total Loss: 3.738    [weighted Loss:3.738    Policy Loss: 6.537    Value Loss: 6.151    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 93847      Buffer Size: 10353      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-08 14:15:57,077][train][INFO][train.py>_log] ==> #240000     Total Loss: 4.832    [weighted Loss:4.832    Policy Loss: 7.209    Value Loss: 5.922    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 94227      Buffer Size: 10416      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-08 14:26:12,387][train][INFO][train.py>_log] ==> #241000     Total Loss: 1.653    [weighted Loss:1.653    Policy Loss: 6.132    Value Loss: 5.809    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 94552      Buffer Size: 10447      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-08 14:36:17,268][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.695    [weighted Loss:2.695    Policy Loss: 6.013    Value Loss: 6.017    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 94851      Buffer Size: 10455      Transition Number: 399.960 k Batch Size: 128        Lr: 0.100   
[2021-11-08 14:46:31,436][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 5.482    Value Loss: 5.527    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 95115      Buffer Size: 10425      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-08 14:56:32,495][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 4.977    Value Loss: 6.107    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 95887      Buffer Size: 10862      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-08 15:06:43,657][train][INFO][train.py>_log] ==> #245000     Total Loss: 3.115    [weighted Loss:3.115    Policy Loss: 6.395    Value Loss: 5.530    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 96591      Buffer Size: 11157      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-08 15:16:42,890][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 6.706    Value Loss: 5.264    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 97064      Buffer Size: 11246      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-08 15:26:43,023][train][INFO][train.py>_log] ==> #247000     Total Loss: 4.145    [weighted Loss:4.145    Policy Loss: 7.796    Value Loss: 6.030    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 97492      Buffer Size: 11274      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-08 15:36:29,141][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 6.989    Value Loss: 6.213    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 97918      Buffer Size: 11139      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-08 15:46:27,330][train][INFO][train.py>_log] ==> #249000     Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 7.644    Value Loss: 5.568    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 98354      Buffer Size: 11158      Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-08 15:56:23,380][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 6.837    Value Loss: 5.174    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 98654      Buffer Size: 11098      Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:06:34,048][train][INFO][train.py>_log] ==> #251000     Total Loss: 3.205    [weighted Loss:3.205    Policy Loss: 6.630    Value Loss: 5.570    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 98917      Buffer Size: 10987      Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:16:38,857][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.539    [weighted Loss:1.539    Policy Loss: 6.755    Value Loss: 5.785    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 99219      Buffer Size: 10930      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:26:55,820][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.571    [weighted Loss:2.571    Policy Loss: 5.939    Value Loss: 6.168    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 99603      Buffer Size: 10932      Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:37:07,210][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 6.491    Value Loss: 5.559    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 99970      Buffer Size: 10934      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:47:08,324][train][INFO][train.py>_log] ==> #255000     Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 7.375    Value Loss: 5.311    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 100295     Buffer Size: 10868      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:57:15,099][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 4.955    Value Loss: 5.557    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 100587     Buffer Size: 10841      Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:07:23,603][train][INFO][train.py>_log] ==> #257000     Total Loss: 4.027    [weighted Loss:4.027    Policy Loss: 6.666    Value Loss: 5.965    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 100987     Buffer Size: 10955      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:17:39,719][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.330    [weighted Loss:1.330    Policy Loss: 7.638    Value Loss: 5.267    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 101331     Buffer Size: 10984      Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:27:29,171][train][INFO][train.py>_log] ==> #259000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 6.727    Value Loss: 5.887    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 101607     Buffer Size: 10951      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:37:31,735][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.228    [weighted Loss:1.228    Policy Loss: 7.294    Value Loss: 5.696    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 101906     Buffer Size: 10946      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:47:43,779][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 6.910    Value Loss: 5.654    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 102237     Buffer Size: 10928      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:58:11,323][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 6.456    Value Loss: 5.462    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 102525     Buffer Size: 10789      Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:08:29,969][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.783    [weighted Loss:2.783    Policy Loss: 6.357    Value Loss: 5.737    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 102867     Buffer Size: 10712      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:18:32,232][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.103    [weighted Loss:3.103    Policy Loss: 6.452    Value Loss: 5.671    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 103177     Buffer Size: 10586      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:29:16,617][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 5.887    Value Loss: 5.729    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 103484     Buffer Size: 10462      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:39:36,881][train][INFO][train.py>_log] ==> #266000     Total Loss: 3.008    [weighted Loss:3.008    Policy Loss: 8.036    Value Loss: 5.710    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 103842     Buffer Size: 10460      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:50:02,944][train][INFO][train.py>_log] ==> #267000     Total Loss: 3.253    [weighted Loss:3.253    Policy Loss: 7.715    Value Loss: 5.973    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 104213     Buffer Size: 10378      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:00:18,748][train][INFO][train.py>_log] ==> #268000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 6.702    Value Loss: 5.679    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 104588     Buffer Size: 10378      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:10:31,266][train][INFO][train.py>_log] ==> #269000     Total Loss: 3.446    [weighted Loss:3.446    Policy Loss: 7.469    Value Loss: 6.105    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 104891     Buffer Size: 10344      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:20:53,971][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.112    [weighted Loss:3.112    Policy Loss: 6.172    Value Loss: 5.602    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 105201     Buffer Size: 10342      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:31:22,938][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 7.203    Value Loss: 5.924    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 105598     Buffer Size: 10446      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:41:43,220][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 6.756    Value Loss: 5.663    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 105979     Buffer Size: 10029      Transition Number: 399.937 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:51:54,911][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 8.092    Value Loss: 6.212    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 106259     Buffer Size: 9605       Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:02:20,693][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 6.518    Value Loss: 5.475    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 106533     Buffer Size: 9395       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:13:03,912][train][INFO][train.py>_log] ==> #275000     Total Loss: 1.753    [weighted Loss:1.753    Policy Loss: 6.302    Value Loss: 5.623    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 106825     Buffer Size: 9170       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:23:40,586][train][INFO][train.py>_log] ==> #276000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 5.693    Value Loss: 4.960    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 107122     Buffer Size: 8989       Transition Number: 400.048 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:34:52,653][train][INFO][train.py>_log] ==> #277000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 5.702    Value Loss: 5.706    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 107414     Buffer Size: 8846       Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:46:18,665][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.674    [weighted Loss:2.674    Policy Loss: 5.856    Value Loss: 5.417    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 107722     Buffer Size: 8830       Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:57:32,995][train][INFO][train.py>_log] ==> #279000     Total Loss: 2.102    [weighted Loss:2.102    Policy Loss: 6.191    Value Loss: 5.508    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 108056     Buffer Size: 8773       Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:08:28,498][train][INFO][train.py>_log] ==> #280000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 6.415    Value Loss: 5.307    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 108455     Buffer Size: 8737       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:19:11,552][train][INFO][train.py>_log] ==> #281000     Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 5.748    Value Loss: 5.792    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 108888     Buffer Size: 8802       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:29:59,602][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 5.598    Value Loss: 5.414    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 109274     Buffer Size: 8861       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:40:57,352][train][INFO][train.py>_log] ==> #283000     Total Loss: 1.264    [weighted Loss:1.264    Policy Loss: 8.603    Value Loss: 5.751    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 109605     Buffer Size: 8830       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:51:45,715][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 6.338    Value Loss: 6.322    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 109950     Buffer Size: 8760       Transition Number: 400.028 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:02:43,520][train][INFO][train.py>_log] ==> #285000     Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 7.739    Value Loss: 5.490    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 110364     Buffer Size: 8835       Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:13:03,528][train][INFO][train.py>_log] ==> #286000     Total Loss: 1.444    [weighted Loss:1.444    Policy Loss: 6.371    Value Loss: 5.622    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 110807     Buffer Size: 8973       Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:23:30,038][train][INFO][train.py>_log] ==> #287000     Total Loss: 3.908    [weighted Loss:3.908    Policy Loss: 7.961    Value Loss: 6.027    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 111253     Buffer Size: 9087       Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:33:48,042][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.092    [weighted Loss:1.092    Policy Loss: 7.479    Value Loss: 5.771    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 111793     Buffer Size: 9322       Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:44:06,668][train][INFO][train.py>_log] ==> #289000     Total Loss: 3.896    [weighted Loss:3.896    Policy Loss: 7.404    Value Loss: 5.386    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 112314     Buffer Size: 9504       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:54:26,724][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.708    [weighted Loss:3.708    Policy Loss: 7.379    Value Loss: 5.714    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 112744     Buffer Size: 9620       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:04:25,353][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 7.897    Value Loss: 5.817    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 113199     Buffer Size: 9790       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:14:32,839][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.921    [weighted Loss:2.921    Policy Loss: 7.673    Value Loss: 5.958    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 113618     Buffer Size: 9870       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:24:38,081][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 8.070    Value Loss: 5.812    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 113998     Buffer Size: 9905       Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:34:55,236][train][INFO][train.py>_log] ==> #294000     Total Loss: 4.192    [weighted Loss:4.192    Policy Loss: 7.159    Value Loss: 5.966    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 114332     Buffer Size: 9861       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:45:11,296][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 6.291    Value Loss: 5.539    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 114601     Buffer Size: 9794       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:55:32,437][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 6.015    Value Loss: 5.522    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 114917     Buffer Size: 9809       Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:06:16,709][train][INFO][train.py>_log] ==> #297000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 6.033    Value Loss: 5.237    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 115229     Buffer Size: 9736       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:16:52,190][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 5.581    Value Loss: 5.547    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 115536     Buffer Size: 9633       Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:27:52,750][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 5.615    Value Loss: 5.713    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 115821     Buffer Size: 9590       Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:38:25,581][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 5.481    Value Loss: 5.644    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 116105     Buffer Size: 9599       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:48:37,622][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.291    [weighted Loss:3.291    Policy Loss: 6.065    Value Loss: 5.551    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 116391     Buffer Size: 9606       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:59:04,117][train][INFO][train.py>_log] ==> #302000     Total Loss: 0.998    [weighted Loss:0.998    Policy Loss: 7.097    Value Loss: 5.668    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 116701     Buffer Size: 9628       Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:09:26,434][train][INFO][train.py>_log] ==> #303000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 5.950    Value Loss: 5.644    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 117001     Buffer Size: 9678       Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:20:16,812][train][INFO][train.py>_log] ==> #304000     Total Loss: 3.060    [weighted Loss:3.060    Policy Loss: 5.877    Value Loss: 5.931    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 117325     Buffer Size: 9720       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:30:41,269][train][INFO][train.py>_log] ==> #305000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 5.859    Value Loss: 5.414    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 117710     Buffer Size: 9824       Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:40:22,948][train][INFO][train.py>_log] ==> #306000     Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 6.757    Value Loss: 5.577    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 118370     Buffer Size: 10175      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:49:47,177][train][INFO][train.py>_log] ==> #307000     Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 5.997    Value Loss: 5.921    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 118905     Buffer Size: 10360      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:59:10,166][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 5.593    Value Loss: 5.836    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 119260     Buffer Size: 10328      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:08:24,976][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 5.935    Value Loss: 5.925    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 119587     Buffer Size: 10326      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:18:28,810][train][INFO][train.py>_log] ==> #310000     Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 4.965    Value Loss: 5.565    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 119942     Buffer Size: 10382      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:28:46,779][train][INFO][train.py>_log] ==> #311000     Total Loss: 1.593    [weighted Loss:1.593    Policy Loss: 6.278    Value Loss: 5.593    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 120270     Buffer Size: 10402      Transition Number: 399.930 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:38:54,807][train][INFO][train.py>_log] ==> #312000     Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 5.699    Value Loss: 5.585    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 120573     Buffer Size: 10340      Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:49:36,371][train][INFO][train.py>_log] ==> #313000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 5.811    Value Loss: 5.981    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 120868     Buffer Size: 10197      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:59:27,761][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.815    [weighted Loss:2.815    Policy Loss: 5.747    Value Loss: 5.382    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 121141     Buffer Size: 10054      Transition Number: 400.034 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:08:58,790][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 5.108    Value Loss: 6.192    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 121414     Buffer Size: 9877       Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:18:47,753][train][INFO][train.py>_log] ==> #316000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 5.667    Value Loss: 5.436    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 121705     Buffer Size: 9672       Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:28:24,400][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 5.357    Value Loss: 5.315    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 121992     Buffer Size: 9515       Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:39:09,418][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.377    [weighted Loss:1.377    Policy Loss: 4.664    Value Loss: 5.430    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 122312     Buffer Size: 9373       Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:49:59,060][train][INFO][train.py>_log] ==> #319000     Total Loss: 1.938    [weighted Loss:1.938    Policy Loss: 4.582    Value Loss: 5.776    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 122612     Buffer Size: 9183       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:00:37,111][train][INFO][train.py>_log] ==> #320000     Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 4.497    Value Loss: 5.106    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 122933     Buffer Size: 9065       Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:11:33,926][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 4.817    Value Loss: 5.455    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 123224     Buffer Size: 8957       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:21:52,157][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 4.713    Value Loss: 5.661    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 123491     Buffer Size: 8919       Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:32:25,530][train][INFO][train.py>_log] ==> #323000     Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 4.592    Value Loss: 5.788    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 123761     Buffer Size: 8870       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:43:10,971][train][INFO][train.py>_log] ==> #324000     Total Loss: 3.705    [weighted Loss:3.705    Policy Loss: 7.817    Value Loss: 6.199    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 124096     Buffer Size: 8882       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:53:58,806][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.726    [weighted Loss:2.726    Policy Loss: 5.293    Value Loss: 6.010    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 124401     Buffer Size: 8892       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:03:58,655][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 5.288    Value Loss: 5.574    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 124672     Buffer Size: 8899       Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:14:07,427][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 4.639    Value Loss: 5.914    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 124950     Buffer Size: 8911       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:24:35,821][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 5.265    Value Loss: 5.605    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 125284     Buffer Size: 8967       Transition Number: 399.960 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:34:26,928][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 5.558    Value Loss: 5.937    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 125601     Buffer Size: 9005       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:44:15,668][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.112    [weighted Loss:2.112    Policy Loss: 6.736    Value Loss: 5.269    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 125894     Buffer Size: 9004       Transition Number: 399.935 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:54:29,261][train][INFO][train.py>_log] ==> #331000     Total Loss: 1.478    [weighted Loss:1.478    Policy Loss: 4.881    Value Loss: 5.806    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 126166     Buffer Size: 8978       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:05:22,114][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 4.348    Value Loss: 5.909    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 126471     Buffer Size: 8886       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:16:18,499][train][INFO][train.py>_log] ==> #333000     Total Loss: 1.376    [weighted Loss:1.376    Policy Loss: 4.244    Value Loss: 5.090    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 126746     Buffer Size: 8505       Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:27:12,963][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 4.735    Value Loss: 5.647    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 127037     Buffer Size: 8111       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:37:52,816][train][INFO][train.py>_log] ==> #335000     Total Loss: 0.769    [weighted Loss:0.769    Policy Loss: 5.581    Value Loss: 5.508    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 127316     Buffer Size: 7967       Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:48:19,793][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 4.999    Value Loss: 5.266    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 127643     Buffer Size: 7912       Transition Number: 400.120 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:58:39,563][train][INFO][train.py>_log] ==> #337000     Total Loss: 1.881    [weighted Loss:1.881    Policy Loss: 5.366    Value Loss: 6.020    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 128018     Buffer Size: 7925       Transition Number: 399.935 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:08:57,591][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 6.209    Value Loss: 5.576    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 128386     Buffer Size: 7978       Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:19:10,714][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 4.694    Value Loss: 5.504    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 128692     Buffer Size: 7991       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:29:29,315][train][INFO][train.py>_log] ==> #340000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 5.442    Value Loss: 5.702    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 129006     Buffer Size: 8015       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:39:52,405][train][INFO][train.py>_log] ==> #341000     Total Loss: 0.943    [weighted Loss:0.943    Policy Loss: 5.477    Value Loss: 4.973    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 129306     Buffer Size: 8025       Transition Number: 400.060 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:50:10,052][train][INFO][train.py>_log] ==> #342000     Total Loss: 1.922    [weighted Loss:1.922    Policy Loss: 5.933    Value Loss: 5.772    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 129620     Buffer Size: 8048       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:00:34,202][train][INFO][train.py>_log] ==> #343000     Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 4.284    Value Loss: 5.735    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 129905     Buffer Size: 8024       Transition Number: 400.059 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:10:59,073][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 4.709    Value Loss: 5.435    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 130223     Buffer Size: 8007       Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:21:44,379][train][INFO][train.py>_log] ==> #345000     Total Loss: 1.386    [weighted Loss:1.386    Policy Loss: 6.600    Value Loss: 5.208    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 130591     Buffer Size: 8088       Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:31:56,339][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 5.453    Value Loss: 5.632    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 131059     Buffer Size: 8260       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:41:58,813][train][INFO][train.py>_log] ==> #347000     Total Loss: 1.399    [weighted Loss:1.399    Policy Loss: 4.431    Value Loss: 5.512    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 131370     Buffer Size: 8316       Transition Number: 400.177 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:51:59,030][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 4.346    Value Loss: 5.643    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 131674     Buffer Size: 8371       Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:01:59,472][train][INFO][train.py>_log] ==> #349000     Total Loss: 1.469    [weighted Loss:1.469    Policy Loss: 4.372    Value Loss: 5.649    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 131992     Buffer Size: 8448       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:12:03,647][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 5.433    Value Loss: 5.663    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 132282     Buffer Size: 8485       Transition Number: 400.116 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:22:20,642][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.209    [weighted Loss:3.209    Policy Loss: 5.206    Value Loss: 5.584    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 132650     Buffer Size: 8533       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:32:39,494][train][INFO][train.py>_log] ==> #352000     Total Loss: 1.251    [weighted Loss:1.251    Policy Loss: 5.910    Value Loss: 5.719    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 133261     Buffer Size: 8845       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:43:04,280][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 5.942    Value Loss: 5.571    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 134117     Buffer Size: 9415       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:52:54,092][train][INFO][train.py>_log] ==> #354000     Total Loss: 1.728    [weighted Loss:1.728    Policy Loss: 5.725    Value Loss: 5.292    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 134537     Buffer Size: 9573       Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:02:43,091][train][INFO][train.py>_log] ==> #355000     Total Loss: 1.402    [weighted Loss:1.402    Policy Loss: 5.322    Value Loss: 5.420    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 134925     Buffer Size: 9655       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:12:30,221][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 7.398    Value Loss: 5.356    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 135281     Buffer Size: 9692       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:22:14,125][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 5.043    Value Loss: 5.981    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 135601     Buffer Size: 9736       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:31:51,865][train][INFO][train.py>_log] ==> #358000     Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 5.362    Value Loss: 5.484    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 135947     Buffer Size: 9828       Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:41:17,469][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 5.362    Value Loss: 5.934    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 136454     Buffer Size: 10096      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:50:33,187][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 7.169    Value Loss: 5.725    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 136884     Buffer Size: 10295      Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:59:54,472][train][INFO][train.py>_log] ==> #361000     Total Loss: 3.812    [weighted Loss:3.812    Policy Loss: 6.656    Value Loss: 5.896    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 137199     Buffer Size: 10398      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:09:20,039][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 5.559    Value Loss: 5.593    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 137457     Buffer Size: 10423      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:18:48,161][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 5.823    Value Loss: 5.671    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 137704     Buffer Size: 10428      Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:28:27,491][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 6.609    Value Loss: 5.794    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 138065     Buffer Size: 10516      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:37:47,457][train][INFO][train.py>_log] ==> #365000     Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 6.235    Value Loss: 6.119    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 138361     Buffer Size: 10529      Transition Number: 400.045 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:46:50,536][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.606    [weighted Loss:2.606    Policy Loss: 6.883    Value Loss: 5.989    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 139019     Buffer Size: 10827      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:55:54,414][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 5.982    Value Loss: 5.956    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 139530     Buffer Size: 11037      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-09 12:04:40,945][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.708    [weighted Loss:3.708    Policy Loss: 7.066    Value Loss: 6.105    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 140133     Buffer Size: 11348      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-09 12:13:21,442][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 7.526    Value Loss: 5.758    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 140565     Buffer Size: 11526      Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-09 12:21:55,632][train][INFO][train.py>_log] ==> #370000     Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 7.675    Value Loss: 5.493    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 140981     Buffer Size: 11685      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-09 12:30:27,789][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 7.579    Value Loss: 5.876    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 141339     Buffer Size: 11780      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-09 12:39:12,631][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 7.351    Value Loss: 5.653    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 141674     Buffer Size: 11871      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-09 12:48:00,720][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 7.659    Value Loss: 6.118    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 141992     Buffer Size: 11963      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-09 12:56:36,497][train][INFO][train.py>_log] ==> #374000     Total Loss: 3.991    [weighted Loss:3.991    Policy Loss: 7.300    Value Loss: 6.266    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 142299     Buffer Size: 12007      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-09 13:05:06,998][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 7.677    Value Loss: 6.002    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 142599     Buffer Size: 12006      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 13:13:45,279][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.799    [weighted Loss:2.799    Policy Loss: 6.944    Value Loss: 5.773    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 142904     Buffer Size: 11926      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 13:22:26,311][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.971    [weighted Loss:2.971    Policy Loss: 7.093    Value Loss: 5.975    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 143187     Buffer Size: 11916      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-09 13:31:52,949][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.626    [weighted Loss:2.626    Policy Loss: 7.243    Value Loss: 6.213    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 143498     Buffer Size: 11937      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-09 13:40:55,303][train][INFO][train.py>_log] ==> #379000     Total Loss: 4.183    [weighted Loss:4.183    Policy Loss: 6.828    Value Loss: 5.940    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 143779     Buffer Size: 11948      Transition Number: 399.934 k Batch Size: 128        Lr: 0.100   
[2021-11-09 13:49:42,570][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 6.930    Value Loss: 6.167    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 144064     Buffer Size: 11963      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-09 13:58:51,551][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 6.547    Value Loss: 6.052    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 144345     Buffer Size: 11990      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-09 14:07:53,639][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 8.027    Value Loss: 5.691    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 144622     Buffer Size: 11933      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-09 14:16:40,017][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 6.555    Value Loss: 6.220    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 144923     Buffer Size: 11762      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-09 14:25:21,490][train][INFO][train.py>_log] ==> #384000     Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 8.164    Value Loss: 5.971    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 145211     Buffer Size: 11370      Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-09 14:34:05,042][train][INFO][train.py>_log] ==> #385000     Total Loss: 3.067    [weighted Loss:3.067    Policy Loss: 7.774    Value Loss: 6.274    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 145465     Buffer Size: 11143      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-09 14:43:48,848][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 7.098    Value Loss: 6.181    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 145751     Buffer Size: 11043      Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-09 14:53:48,282][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.462    [weighted Loss:1.462    Policy Loss: 5.870    Value Loss: 6.126    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 146060     Buffer Size: 10968      Transition Number: 399.948 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:03:52,396][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 7.313    Value Loss: 6.239    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 146372     Buffer Size: 10946      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:13:45,705][train][INFO][train.py>_log] ==> #389000     Total Loss: 1.580    [weighted Loss:1.580    Policy Loss: 6.601    Value Loss: 5.862    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 146734     Buffer Size: 10968      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:23:17,684][train][INFO][train.py>_log] ==> #390000     Total Loss: 4.404    [weighted Loss:4.404    Policy Loss: 7.603    Value Loss: 6.407    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 147138     Buffer Size: 10927      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:32:29,642][train][INFO][train.py>_log] ==> #391000     Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 7.149    Value Loss: 6.027    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 147470     Buffer Size: 10829      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:41:17,765][train][INFO][train.py>_log] ==> #392000     Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 5.969    Value Loss: 6.104    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 147818     Buffer Size: 10816      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:50:06,545][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 5.864    Value Loss: 6.152    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 148132     Buffer Size: 10858      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:58:57,337][train][INFO][train.py>_log] ==> #394000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 6.102    Value Loss: 5.916    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 148462     Buffer Size: 10957      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:07:45,345][train][INFO][train.py>_log] ==> #395000     Total Loss: 1.510    [weighted Loss:1.510    Policy Loss: 6.329    Value Loss: 6.509    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 148803     Buffer Size: 11084      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:16:43,880][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 6.391    Value Loss: 5.755    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 149075     Buffer Size: 11012      Transition Number: 399.935 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:25:44,211][train][INFO][train.py>_log] ==> #397000     Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 7.243    Value Loss: 6.175    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 149309     Buffer Size: 10944      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:34:42,058][train][INFO][train.py>_log] ==> #398000     Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 5.079    Value Loss: 5.730    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 149553     Buffer Size: 10566      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:43:49,812][train][INFO][train.py>_log] ==> #399000     Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 5.935    Value Loss: 5.972    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 149815     Buffer Size: 10300      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:53:04,184][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 5.346    Value Loss: 5.401    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 150072     Buffer Size: 9993       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:02:28,235][train][INFO][train.py>_log] ==> #401000     Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 5.813    Value Loss: 6.213    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 150339     Buffer Size: 9770       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:11:47,267][train][INFO][train.py>_log] ==> #402000     Total Loss: 1.653    [weighted Loss:1.653    Policy Loss: 5.449    Value Loss: 5.297    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 150609     Buffer Size: 9607       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:21:18,401][train][INFO][train.py>_log] ==> #403000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 5.689    Value Loss: 5.737    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 150930     Buffer Size: 9552       Transition Number: 400.087 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:30:39,362][train][INFO][train.py>_log] ==> #404000     Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 5.188    Value Loss: 6.115    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 151267     Buffer Size: 9532       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:40:07,393][train][INFO][train.py>_log] ==> #405000     Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 6.637    Value Loss: 5.467    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 151614     Buffer Size: 9527       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:49:33,111][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 6.431    Value Loss: 6.007    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 151935     Buffer Size: 9514       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:58:54,978][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.750    [weighted Loss:2.750    Policy Loss: 6.447    Value Loss: 5.893    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 152242     Buffer Size: 9492       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:08:16,567][train][INFO][train.py>_log] ==> #408000     Total Loss: 3.816    [weighted Loss:3.816    Policy Loss: 6.868    Value Loss: 5.567    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 152565     Buffer Size: 9514       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:17:44,432][train][INFO][train.py>_log] ==> #409000     Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 6.475    Value Loss: 5.914    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 152925     Buffer Size: 9554       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:27:06,875][train][INFO][train.py>_log] ==> #410000     Total Loss: 1.203    [weighted Loss:1.203    Policy Loss: 6.280    Value Loss: 6.230    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 153256     Buffer Size: 9587       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:36:21,231][train][INFO][train.py>_log] ==> #411000     Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 6.111    Value Loss: 6.179    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 153590     Buffer Size: 9624       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:45:33,449][train][INFO][train.py>_log] ==> #412000     Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 7.009    Value Loss: 6.304    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 154009     Buffer Size: 9749       Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:54:43,368][train][INFO][train.py>_log] ==> #413000     Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 6.819    Value Loss: 5.808    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 154415     Buffer Size: 9859       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:03:36,968][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 7.085    Value Loss: 6.169    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 155168     Buffer Size: 10276      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:12:26,323][train][INFO][train.py>_log] ==> #415000     Total Loss: 4.181    [weighted Loss:4.181    Policy Loss: 7.958    Value Loss: 6.496    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 155619     Buffer Size: 10446      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:21:23,636][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 6.214    Value Loss: 6.251    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 155973     Buffer Size: 10529      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:30:18,334][train][INFO][train.py>_log] ==> #417000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 7.858    Value Loss: 6.126    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 156278     Buffer Size: 10590      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:39:20,418][train][INFO][train.py>_log] ==> #418000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 6.976    Value Loss: 5.979    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 156577     Buffer Size: 10613      Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:48:16,528][train][INFO][train.py>_log] ==> #419000     Total Loss: 1.348    [weighted Loss:1.348    Policy Loss: 6.619    Value Loss: 6.007    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 156847     Buffer Size: 10613      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:57:18,019][train][INFO][train.py>_log] ==> #420000     Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 7.669    Value Loss: 6.378    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 157147     Buffer Size: 10606      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:06:09,336][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.856    [weighted Loss:2.856    Policy Loss: 6.116    Value Loss: 6.064    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 157492     Buffer Size: 10613      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:15:06,202][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 5.894    Value Loss: 6.570    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 157811     Buffer Size: 10569      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:24:02,551][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 6.247    Value Loss: 6.141    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 158142     Buffer Size: 10564      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:32:54,611][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 6.830    Value Loss: 6.186    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 158496     Buffer Size: 10560      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:41:48,328][train][INFO][train.py>_log] ==> #425000     Total Loss: 2.741    [weighted Loss:2.741    Policy Loss: 7.662    Value Loss: 6.091    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 158895     Buffer Size: 10638      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:50:33,533][train][INFO][train.py>_log] ==> #426000     Total Loss: 3.732    [weighted Loss:3.732    Policy Loss: 8.134    Value Loss: 6.038    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 159281     Buffer Size: 10687      Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:59:22,524][train][INFO][train.py>_log] ==> #427000     Total Loss: 3.513    [weighted Loss:3.513    Policy Loss: 6.470    Value Loss: 5.979    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 159647     Buffer Size: 10734      Transition Number: 400.010 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:08:24,045][train][INFO][train.py>_log] ==> #428000     Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 5.846    Value Loss: 5.731    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 159896     Buffer Size: 10723      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:17:27,424][train][INFO][train.py>_log] ==> #429000     Total Loss: 3.324    [weighted Loss:3.324    Policy Loss: 6.438    Value Loss: 5.993    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 160135     Buffer Size: 10715      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:26:31,863][train][INFO][train.py>_log] ==> #430000     Total Loss: 2.509    [weighted Loss:2.509    Policy Loss: 6.030    Value Loss: 6.191    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 160377     Buffer Size: 10705      Transition Number: 399.960 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:35:40,549][train][INFO][train.py>_log] ==> #431000     Total Loss: 1.239    [weighted Loss:1.239    Policy Loss: 4.880    Value Loss: 5.976    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 160612     Buffer Size: 10672      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:44:50,802][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.255    [weighted Loss:1.255    Policy Loss: 5.484    Value Loss: 5.629    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 160866     Buffer Size: 10680      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:53:55,643][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 5.569    Value Loss: 5.884    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 161148     Buffer Size: 10702      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:02:55,453][train][INFO][train.py>_log] ==> #434000     Total Loss: 2.032    [weighted Loss:2.032    Policy Loss: 5.109    Value Loss: 5.879    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 161481     Buffer Size: 10751      Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:11:47,292][train][INFO][train.py>_log] ==> #435000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 5.404    Value Loss: 6.008    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 161771     Buffer Size: 10729      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:20:44,433][train][INFO][train.py>_log] ==> #436000     Total Loss: 0.902    [weighted Loss:0.902    Policy Loss: 6.141    Value Loss: 6.202    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 162047     Buffer Size: 10682      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:29:46,537][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 5.810    Value Loss: 5.726    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 162315     Buffer Size: 10625      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:38:49,873][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 5.887    Value Loss: 5.877    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 162570     Buffer Size: 10576      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:47:55,975][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 5.191    Value Loss: 5.603    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 162834     Buffer Size: 10532      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:56:56,893][train][INFO][train.py>_log] ==> #440000     Total Loss: 2.785    [weighted Loss:2.785    Policy Loss: 5.938    Value Loss: 6.009    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 163143     Buffer Size: 10513      Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:05:58,113][train][INFO][train.py>_log] ==> #441000     Total Loss: 2.658    [weighted Loss:2.658    Policy Loss: 6.385    Value Loss: 5.915    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 163426     Buffer Size: 10463      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:16:01,389][train][INFO][train.py>_log] ==> #442000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 6.525    Value Loss: 6.576    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 163795     Buffer Size: 10484      Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:25:03,315][train][INFO][train.py>_log] ==> #443000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 6.818    Value Loss: 6.111    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 164146     Buffer Size: 10484      Transition Number: 400.042 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:34:02,401][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 6.374    Value Loss: 5.956    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 164468     Buffer Size: 10398      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:43:00,843][train][INFO][train.py>_log] ==> #445000     Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 5.870    Value Loss: 5.894    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 164984     Buffer Size: 10498      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:51:55,495][train][INFO][train.py>_log] ==> #446000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 5.325    Value Loss: 6.232    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 165527     Buffer Size: 10365      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:00:56,349][train][INFO][train.py>_log] ==> #447000     Total Loss: 1.720    [weighted Loss:1.720    Policy Loss: 5.684    Value Loss: 6.203    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 165790     Buffer Size: 10150      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:10:07,573][train][INFO][train.py>_log] ==> #448000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 5.501    Value Loss: 5.781    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 166053     Buffer Size: 10036      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:19:30,655][train][INFO][train.py>_log] ==> #449000     Total Loss: 1.297    [weighted Loss:1.297    Policy Loss: 7.679    Value Loss: 6.025    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 166301     Buffer Size: 9939       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:28:51,755][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 4.930    Value Loss: 6.170    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 166605     Buffer Size: 9936       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:38:06,316][train][INFO][train.py>_log] ==> #451000     Total Loss: 1.472    [weighted Loss:1.472    Policy Loss: 5.175    Value Loss: 5.790    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 166917     Buffer Size: 9962       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:47:24,370][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 5.296    Value Loss: 5.881    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 167173     Buffer Size: 9892       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:56:49,350][train][INFO][train.py>_log] ==> #453000     Total Loss: 1.253    [weighted Loss:1.253    Policy Loss: 5.153    Value Loss: 5.949    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 167431     Buffer Size: 9783       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:06:18,608][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 5.612    Value Loss: 6.138    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 167760     Buffer Size: 9765       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:15:39,911][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 5.689    Value Loss: 5.835    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 168064     Buffer Size: 9700       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:25:07,543][train][INFO][train.py>_log] ==> #456000     Total Loss: 3.574    [weighted Loss:3.574    Policy Loss: 7.804    Value Loss: 6.262    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 168397     Buffer Size: 9621       Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:34:40,014][train][INFO][train.py>_log] ==> #457000     Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 5.393    Value Loss: 5.711    Reward Loss: 1.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 168687     Buffer Size: 9479       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:44:17,825][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 5.546    Value Loss: 5.560    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 168982     Buffer Size: 9376       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:53:55,825][train][INFO][train.py>_log] ==> #459000     Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 6.062    Value Loss: 6.184    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 169307     Buffer Size: 9419       Transition Number: 399.934 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:03:26,412][train][INFO][train.py>_log] ==> #460000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 6.692    Value Loss: 5.876    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 169677     Buffer Size: 9546       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:12:49,005][train][INFO][train.py>_log] ==> #461000     Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 7.635    Value Loss: 6.115    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 170036     Buffer Size: 9658       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:22:03,100][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 6.823    Value Loss: 5.585    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 170361     Buffer Size: 9762       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:31:13,243][train][INFO][train.py>_log] ==> #463000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 6.563    Value Loss: 6.079    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 170762     Buffer Size: 9902       Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:40:19,799][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 6.742    Value Loss: 6.245    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 171379     Buffer Size: 10225      Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:49:03,266][train][INFO][train.py>_log] ==> #465000     Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 6.726    Value Loss: 6.094    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 171974     Buffer Size: 10479      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:57:49,361][train][INFO][train.py>_log] ==> #466000     Total Loss: 3.063    [weighted Loss:3.063    Policy Loss: 7.757    Value Loss: 6.207    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 172573     Buffer Size: 10761      Transition Number: 400.010 k Batch Size: 128        Lr: 0.100   
[2021-11-10 03:06:34,545][train][INFO][train.py>_log] ==> #467000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 7.106    Value Loss: 5.881    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 172916     Buffer Size: 10848      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 03:15:20,849][train][INFO][train.py>_log] ==> #468000     Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 7.228    Value Loss: 5.836    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 173328     Buffer Size: 10971      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-10 03:24:06,447][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.806    [weighted Loss:2.806    Policy Loss: 7.756    Value Loss: 6.096    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 173754     Buffer Size: 11147      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-10 03:32:45,114][train][INFO][train.py>_log] ==> #470000     Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 7.292    Value Loss: 6.015    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 174128     Buffer Size: 11272      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-10 03:41:17,008][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 7.207    Value Loss: 5.794    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 174512     Buffer Size: 11363      Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-10 03:49:50,652][train][INFO][train.py>_log] ==> #472000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 7.056    Value Loss: 5.982    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 174917     Buffer Size: 11480      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-10 03:58:29,404][train][INFO][train.py>_log] ==> #473000     Total Loss: 1.771    [weighted Loss:1.771    Policy Loss: 6.628    Value Loss: 5.562    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 175215     Buffer Size: 11471      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-10 04:07:17,824][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.859    [weighted Loss:2.859    Policy Loss: 6.133    Value Loss: 6.392    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 175469     Buffer Size: 11380      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-10 04:16:09,081][train][INFO][train.py>_log] ==> #475000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 5.287    Value Loss: 5.835    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 175786     Buffer Size: 11386      Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-10 04:24:58,014][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 5.729    Value Loss: 5.967    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 176147     Buffer Size: 11280      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-10 04:33:53,180][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 6.565    Value Loss: 5.753    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 176502     Buffer Size: 11104      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-10 04:42:47,369][train][INFO][train.py>_log] ==> #478000     Total Loss: 3.571    [weighted Loss:3.571    Policy Loss: 5.770    Value Loss: 5.861    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 176800     Buffer Size: 11084      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-10 04:51:44,819][train][INFO][train.py>_log] ==> #479000     Total Loss: 2.767    [weighted Loss:2.767    Policy Loss: 5.801    Value Loss: 6.123    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 177114     Buffer Size: 11152      Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:00:40,434][train][INFO][train.py>_log] ==> #480000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 6.265    Value Loss: 5.255    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 177440     Buffer Size: 11244      Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:09:28,376][train][INFO][train.py>_log] ==> #481000     Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 6.470    Value Loss: 6.216    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 177818     Buffer Size: 11381      Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:18:12,578][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 6.565    Value Loss: 6.187    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 178237     Buffer Size: 11514      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:26:50,791][train][INFO][train.py>_log] ==> #483000     Total Loss: 3.430    [weighted Loss:3.430    Policy Loss: 7.808    Value Loss: 5.983    Reward Loss: 1.093    Consistency Loss: 0.000    ] Replay Episodes Collected: 178571     Buffer Size: 11562      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:35:33,110][train][INFO][train.py>_log] ==> #484000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 6.659    Value Loss: 6.396    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 178923     Buffer Size: 11688      Transition Number: 400.017 k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:44:17,892][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 5.709    Value Loss: 5.717    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 179229     Buffer Size: 11761      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:53:01,345][train][INFO][train.py>_log] ==> #486000     Total Loss: 3.236    [weighted Loss:3.236    Policy Loss: 5.561    Value Loss: 6.113    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 179522     Buffer Size: 11747      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:01:42,910][train][INFO][train.py>_log] ==> #487000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 5.784    Value Loss: 6.404    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 179811     Buffer Size: 11764      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:10:21,455][train][INFO][train.py>_log] ==> #488000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 6.469    Value Loss: 6.564    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 180167     Buffer Size: 11804      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:19:05,137][train][INFO][train.py>_log] ==> #489000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 6.550    Value Loss: 5.935    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 180512     Buffer Size: 11883      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:27:51,221][train][INFO][train.py>_log] ==> #490000     Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 6.606    Value Loss: 5.572    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 180778     Buffer Size: 11880      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:36:35,282][train][INFO][train.py>_log] ==> #491000     Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 6.291    Value Loss: 6.340    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 181068     Buffer Size: 11890      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:45:29,344][train][INFO][train.py>_log] ==> #492000     Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 5.834    Value Loss: 5.692    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 181582     Buffer Size: 12058      Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:54:02,861][train][INFO][train.py>_log] ==> #493000     Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 6.391    Value Loss: 5.997    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 181988     Buffer Size: 12146      Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:02:31,947][train][INFO][train.py>_log] ==> #494000     Total Loss: 2.571    [weighted Loss:2.571    Policy Loss: 6.197    Value Loss: 6.212    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 182415     Buffer Size: 12237      Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:10:59,066][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 5.399    Value Loss: 5.835    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 182749     Buffer Size: 12266      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:19:33,344][train][INFO][train.py>_log] ==> #496000     Total Loss: 1.472    [weighted Loss:1.472    Policy Loss: 4.922    Value Loss: 6.056    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 183018     Buffer Size: 12137      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:28:22,830][train][INFO][train.py>_log] ==> #497000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 5.836    Value Loss: 6.448    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 183285     Buffer Size: 11864      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:37:09,426][train][INFO][train.py>_log] ==> #498000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 5.904    Value Loss: 6.350    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 183537     Buffer Size: 11531      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:46:10,359][train][INFO][train.py>_log] ==> #499000     Total Loss: 0.858    [weighted Loss:0.858    Policy Loss: 5.935    Value Loss: 5.775    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 183778     Buffer Size: 11205      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:55:23,500][train][INFO][train.py>_log] ==> #500000     Total Loss: 1.919    [weighted Loss:1.919    Policy Loss: 5.516    Value Loss: 5.679    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 184024     Buffer Size: 11066      Transition Number: 400.024 k Batch Size: 128        Lr: 0.100   
[2021-11-10 08:04:34,289][train][INFO][train.py>_log] ==> #501000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 6.285    Value Loss: 6.007    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 184301     Buffer Size: 10945      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-10 08:13:45,923][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 6.005    Value Loss: 5.676    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 184564     Buffer Size: 10777      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-10 08:23:01,579][train][INFO][train.py>_log] ==> #503000     Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 6.006    Value Loss: 6.301    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 184860     Buffer Size: 10677      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-10 08:32:19,735][train][INFO][train.py>_log] ==> #504000     Total Loss: 2.465    [weighted Loss:2.465    Policy Loss: 6.237    Value Loss: 6.142    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 185179     Buffer Size: 10574      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-10 08:41:34,235][train][INFO][train.py>_log] ==> #505000     Total Loss: 1.282    [weighted Loss:1.282    Policy Loss: 5.824    Value Loss: 5.447    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 185509     Buffer Size: 10526      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-10 08:50:53,402][train][INFO][train.py>_log] ==> #506000     Total Loss: 2.736    [weighted Loss:2.736    Policy Loss: 6.293    Value Loss: 6.135    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 185783     Buffer Size: 10493      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-10 09:00:18,216][train][INFO][train.py>_log] ==> #507000     Total Loss: 1.463    [weighted Loss:1.463    Policy Loss: 5.655    Value Loss: 5.869    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 186061     Buffer Size: 10477      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-10 09:09:34,987][train][INFO][train.py>_log] ==> #508000     Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 5.744    Value Loss: 6.000    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 186384     Buffer Size: 10452      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-10 09:18:52,821][train][INFO][train.py>_log] ==> #509000     Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 7.650    Value Loss: 6.066    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 186687     Buffer Size: 10381      Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-10 09:27:59,847][train][INFO][train.py>_log] ==> #510000     Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 6.167    Value Loss: 5.594    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 187357     Buffer Size: 10691      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-10 09:36:54,333][train][INFO][train.py>_log] ==> #511000     Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 6.652    Value Loss: 5.710    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 187963     Buffer Size: 10968      Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-10 09:45:35,163][train][INFO][train.py>_log] ==> #512000     Total Loss: 3.103    [weighted Loss:3.103    Policy Loss: 7.346    Value Loss: 6.179    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 188672     Buffer Size: 11345      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 09:54:04,982][train][INFO][train.py>_log] ==> #513000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 6.987    Value Loss: 6.101    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 189534     Buffer Size: 11803      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-10 10:02:40,922][train][INFO][train.py>_log] ==> #514000     Total Loss: 1.152    [weighted Loss:1.152    Policy Loss: 7.866    Value Loss: 6.323    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 189888     Buffer Size: 11767      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-10 10:11:24,713][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 6.634    Value Loss: 6.058    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 190258     Buffer Size: 11767      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-10 10:20:05,622][train][INFO][train.py>_log] ==> #516000     Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 6.892    Value Loss: 5.817    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 190602     Buffer Size: 11797      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-10 10:28:48,116][train][INFO][train.py>_log] ==> #517000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 6.188    Value Loss: 6.150    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 190937     Buffer Size: 11788      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-10 10:37:28,752][train][INFO][train.py>_log] ==> #518000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 6.570    Value Loss: 5.910    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 191385     Buffer Size: 11939      Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-10 10:46:02,078][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 6.158    Value Loss: 5.831    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 191736     Buffer Size: 12005      Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-10 10:54:35,902][train][INFO][train.py>_log] ==> #520000     Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 8.012    Value Loss: 6.461    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 192113     Buffer Size: 12053      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:03:08,955][train][INFO][train.py>_log] ==> #521000     Total Loss: 3.550    [weighted Loss:3.550    Policy Loss: 8.242    Value Loss: 5.976    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 192530     Buffer Size: 12127      Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:11:37,711][train][INFO][train.py>_log] ==> #522000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 7.046    Value Loss: 6.165    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 192845     Buffer Size: 12161      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:20:04,277][train][INFO][train.py>_log] ==> #523000     Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 7.361    Value Loss: 6.365    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 193249     Buffer Size: 12302      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:28:30,114][train][INFO][train.py>_log] ==> #524000     Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 6.629    Value Loss: 5.957    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 193605     Buffer Size: 12253      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:36:53,127][train][INFO][train.py>_log] ==> #525000     Total Loss: 1.422    [weighted Loss:1.422    Policy Loss: 7.627    Value Loss: 6.359    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 193955     Buffer Size: 12185      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:45:10,359][train][INFO][train.py>_log] ==> #526000     Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 8.634    Value Loss: 6.188    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 194560     Buffer Size: 12353      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:53:32,424][train][INFO][train.py>_log] ==> #527000     Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 6.848    Value Loss: 5.898    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 195137     Buffer Size: 12545      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:01:48,878][train][INFO][train.py>_log] ==> #528000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 8.111    Value Loss: 5.852    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 195568     Buffer Size: 12676      Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:10:10,776][train][INFO][train.py>_log] ==> #529000     Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 7.569    Value Loss: 5.893    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 195859     Buffer Size: 12706      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:18:29,199][train][INFO][train.py>_log] ==> #530000     Total Loss: 2.769    [weighted Loss:2.769    Policy Loss: 7.739    Value Loss: 6.212    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 196166     Buffer Size: 12753      Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:26:46,707][train][INFO][train.py>_log] ==> #531000     Total Loss: 3.002    [weighted Loss:3.002    Policy Loss: 7.581    Value Loss: 6.062    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 196464     Buffer Size: 12836      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:35:01,569][train][INFO][train.py>_log] ==> #532000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 8.432    Value Loss: 6.178    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 196762     Buffer Size: 12934      Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:43:10,640][train][INFO][train.py>_log] ==> #533000     Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 6.841    Value Loss: 6.352    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 197036     Buffer Size: 13001      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:51:20,081][train][INFO][train.py>_log] ==> #534000     Total Loss: 1.074    [weighted Loss:1.074    Policy Loss: 6.315    Value Loss: 5.900    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 197316     Buffer Size: 13037      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:59:32,386][train][INFO][train.py>_log] ==> #535000     Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 6.131    Value Loss: 6.179    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 197589     Buffer Size: 13072      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:07:41,105][train][INFO][train.py>_log] ==> #536000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 6.089    Value Loss: 6.133    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 197872     Buffer Size: 13103      Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:15:55,347][train][INFO][train.py>_log] ==> #537000     Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 6.351    Value Loss: 5.707    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 198088     Buffer Size: 13041      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:24:20,268][train][INFO][train.py>_log] ==> #538000     Total Loss: 0.829    [weighted Loss:0.829    Policy Loss: 5.847    Value Loss: 5.984    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 198325     Buffer Size: 12977      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:32:40,099][train][INFO][train.py>_log] ==> #539000     Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 5.775    Value Loss: 5.628    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 198737     Buffer Size: 13108      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:40:39,475][train][INFO][train.py>_log] ==> #540000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 6.067    Value Loss: 6.089    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 199134     Buffer Size: 13278      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:48:46,886][train][INFO][train.py>_log] ==> #541000     Total Loss: 0.712    [weighted Loss:0.712    Policy Loss: 6.706    Value Loss: 6.193    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 199377     Buffer Size: 13283      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:56:53,357][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 5.331    Value Loss: 5.772    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 199638     Buffer Size: 13270      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:05:06,287][train][INFO][train.py>_log] ==> #543000     Total Loss: 3.148    [weighted Loss:3.148    Policy Loss: 5.901    Value Loss: 6.008    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 199882     Buffer Size: 13250      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:13:23,815][train][INFO][train.py>_log] ==> #544000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 5.992    Value Loss: 5.503    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 200149     Buffer Size: 12998      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:21:49,471][train][INFO][train.py>_log] ==> #545000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 7.110    Value Loss: 6.508    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 200389     Buffer Size: 12659      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:30:16,959][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 6.110    Value Loss: 5.908    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 200658     Buffer Size: 12304      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:38:52,834][train][INFO][train.py>_log] ==> #547000     Total Loss: 3.643    [weighted Loss:3.643    Policy Loss: 7.151    Value Loss: 5.752    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 200961     Buffer Size: 11936      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:47:42,978][train][INFO][train.py>_log] ==> #548000     Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 5.447    Value Loss: 5.752    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 201256     Buffer Size: 11608      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:56:32,182][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 6.351    Value Loss: 6.014    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 201536     Buffer Size: 11532      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:05:18,485][train][INFO][train.py>_log] ==> #550000     Total Loss: 4.364    [weighted Loss:4.364    Policy Loss: 7.914    Value Loss: 6.270    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 201892     Buffer Size: 11516      Transition Number: 400.057 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:14:03,163][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.441    [weighted Loss:3.441    Policy Loss: 5.728    Value Loss: 6.136    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 202243     Buffer Size: 11526      Transition Number: 400.037 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:22:50,614][train][INFO][train.py>_log] ==> #552000     Total Loss: 3.298    [weighted Loss:3.298    Policy Loss: 7.658    Value Loss: 6.155    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 202518     Buffer Size: 11450      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:31:49,418][train][INFO][train.py>_log] ==> #553000     Total Loss: 1.784    [weighted Loss:1.784    Policy Loss: 5.457    Value Loss: 5.868    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 202845     Buffer Size: 11350      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:40:38,704][train][INFO][train.py>_log] ==> #554000     Total Loss: 0.864    [weighted Loss:0.864    Policy Loss: 6.402    Value Loss: 6.046    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 203216     Buffer Size: 11360      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:49:32,403][train][INFO][train.py>_log] ==> #555000     Total Loss: 2.704    [weighted Loss:2.704    Policy Loss: 5.964    Value Loss: 6.118    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 203501     Buffer Size: 11225      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:58:29,441][train][INFO][train.py>_log] ==> #556000     Total Loss: 1.698    [weighted Loss:1.698    Policy Loss: 6.875    Value Loss: 6.015    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 203814     Buffer Size: 11155      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-10 16:07:22,588][train][INFO][train.py>_log] ==> #557000     Total Loss: 0.965    [weighted Loss:0.965    Policy Loss: 6.805    Value Loss: 5.857    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 204257     Buffer Size: 11210      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 16:16:16,050][train][INFO][train.py>_log] ==> #558000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 7.522    Value Loss: 6.021    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 204583     Buffer Size: 11152      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-10 16:25:15,337][train][INFO][train.py>_log] ==> #559000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 7.712    Value Loss: 5.923    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 204898     Buffer Size: 11092      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 16:34:15,192][train][INFO][train.py>_log] ==> #560000     Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 6.404    Value Loss: 5.691    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 205214     Buffer Size: 10905      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-10 16:43:17,289][train][INFO][train.py>_log] ==> #561000     Total Loss: 1.057    [weighted Loss:1.057    Policy Loss: 5.937    Value Loss: 5.663    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 205491     Buffer Size: 10570      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 16:52:30,984][train][INFO][train.py>_log] ==> #562000     Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 6.752    Value Loss: 6.101    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 205848     Buffer Size: 10383      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-10 17:01:43,162][train][INFO][train.py>_log] ==> #563000     Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 5.843    Value Loss: 5.751    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 206184     Buffer Size: 10368      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 17:10:51,454][train][INFO][train.py>_log] ==> #564000     Total Loss: 3.727    [weighted Loss:3.727    Policy Loss: 7.406    Value Loss: 6.003    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 206508     Buffer Size: 10353      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-10 17:20:00,779][train][INFO][train.py>_log] ==> #565000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 6.409    Value Loss: 6.216    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 206816     Buffer Size: 10334      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-10 17:29:14,104][train][INFO][train.py>_log] ==> #566000     Total Loss: 2.589    [weighted Loss:2.589    Policy Loss: 7.703    Value Loss: 6.290    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 207124     Buffer Size: 10297      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-10 17:38:26,710][train][INFO][train.py>_log] ==> #567000     Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 7.089    Value Loss: 5.735    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 207487     Buffer Size: 10334      Transition Number: 400.003 k Batch Size: 128        Lr: 0.100   
[2021-11-10 17:47:24,170][train][INFO][train.py>_log] ==> #568000     Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 8.003    Value Loss: 6.712    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 208286     Buffer Size: 10784      Transition Number: 400.031 k Batch Size: 128        Lr: 0.100   
[2021-11-10 17:56:03,487][train][INFO][train.py>_log] ==> #569000     Total Loss: 3.067    [weighted Loss:3.067    Policy Loss: 7.521    Value Loss: 6.123    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 208863     Buffer Size: 11018      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:04:38,045][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 7.318    Value Loss: 6.176    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 209334     Buffer Size: 11248      Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:13:12,289][train][INFO][train.py>_log] ==> #571000     Total Loss: 2.320    [weighted Loss:2.320    Policy Loss: 7.845    Value Loss: 6.133    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 209702     Buffer Size: 11378      Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:21:51,472][train][INFO][train.py>_log] ==> #572000     Total Loss: 2.143    [weighted Loss:2.143    Policy Loss: 6.275    Value Loss: 5.611    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 210030     Buffer Size: 11289      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:30:38,885][train][INFO][train.py>_log] ==> #573000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 7.235    Value Loss: 6.370    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 210330     Buffer Size: 11172      Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:39:33,328][train][INFO][train.py>_log] ==> #574000     Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 7.468    Value Loss: 6.082    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 210668     Buffer Size: 11224      Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:48:23,602][train][INFO][train.py>_log] ==> #575000     Total Loss: 2.877    [weighted Loss:2.877    Policy Loss: 7.742    Value Loss: 6.068    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 210933     Buffer Size: 11215      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:57:16,303][train][INFO][train.py>_log] ==> #576000     Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 6.216    Value Loss: 5.710    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 211218     Buffer Size: 11230      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:06:07,976][train][INFO][train.py>_log] ==> #577000     Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 7.311    Value Loss: 6.277    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 211486     Buffer Size: 11242      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:14:55,811][train][INFO][train.py>_log] ==> #578000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 6.866    Value Loss: 5.673    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 211895     Buffer Size: 11367      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:23:45,262][train][INFO][train.py>_log] ==> #579000     Total Loss: 2.372    [weighted Loss:2.372    Policy Loss: 6.369    Value Loss: 5.919    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 212195     Buffer Size: 11384      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:32:37,326][train][INFO][train.py>_log] ==> #580000     Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 5.891    Value Loss: 5.887    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 212620     Buffer Size: 11493      Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:41:14,167][train][INFO][train.py>_log] ==> #581000     Total Loss: 2.918    [weighted Loss:2.918    Policy Loss: 6.135    Value Loss: 5.905    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 213061     Buffer Size: 11637      Transition Number: 399.932 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:49:49,009][train][INFO][train.py>_log] ==> #582000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 6.822    Value Loss: 5.672    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 213415     Buffer Size: 11686      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:58:24,376][train][INFO][train.py>_log] ==> #583000     Total Loss: 3.248    [weighted Loss:3.248    Policy Loss: 6.644    Value Loss: 6.314    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 213753     Buffer Size: 11667      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:06:58,113][train][INFO][train.py>_log] ==> #584000     Total Loss: 0.751    [weighted Loss:0.751    Policy Loss: 5.619    Value Loss: 5.743    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 214178     Buffer Size: 11768      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:15:23,045][train][INFO][train.py>_log] ==> #585000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 6.250    Value Loss: 6.073    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 214639     Buffer Size: 11949      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:23:37,281][train][INFO][train.py>_log] ==> #586000     Total Loss: 2.582    [weighted Loss:2.582    Policy Loss: 8.035    Value Loss: 6.551    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 215194     Buffer Size: 12147      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:31:40,682][train][INFO][train.py>_log] ==> #587000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 7.956    Value Loss: 6.179    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 215961     Buffer Size: 12571      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:39:37,158][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 7.169    Value Loss: 5.862    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 216495     Buffer Size: 12838      Transition Number: 400.088 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:47:36,143][train][INFO][train.py>_log] ==> #589000     Total Loss: 1.533    [weighted Loss:1.533    Policy Loss: 7.627    Value Loss: 6.007    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 216808     Buffer Size: 12854      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:55:44,325][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 7.177    Value Loss: 6.070    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 217080     Buffer Size: 12739      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:04:04,333][train][INFO][train.py>_log] ==> #591000     Total Loss: 2.736    [weighted Loss:2.736    Policy Loss: 7.509    Value Loss: 5.998    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 217338     Buffer Size: 12705      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:12:23,222][train][INFO][train.py>_log] ==> #592000     Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 7.690    Value Loss: 6.159    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 217671     Buffer Size: 12748      Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:20:40,793][train][INFO][train.py>_log] ==> #593000     Total Loss: 3.264    [weighted Loss:3.264    Policy Loss: 7.180    Value Loss: 5.846    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 218014     Buffer Size: 12796      Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:28:53,790][train][INFO][train.py>_log] ==> #594000     Total Loss: 1.073    [weighted Loss:1.073    Policy Loss: 6.959    Value Loss: 6.148    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 218344     Buffer Size: 12866      Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:37:07,378][train][INFO][train.py>_log] ==> #595000     Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 6.994    Value Loss: 5.846    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 218667     Buffer Size: 12874      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:45:14,568][train][INFO][train.py>_log] ==> #596000     Total Loss: 1.860    [weighted Loss:1.860    Policy Loss: 7.366    Value Loss: 6.203    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 218998     Buffer Size: 12916      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:53:19,734][train][INFO][train.py>_log] ==> #597000     Total Loss: 3.725    [weighted Loss:3.725    Policy Loss: 8.790    Value Loss: 5.981    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 219257     Buffer Size: 12907      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:01:31,047][train][INFO][train.py>_log] ==> #598000     Total Loss: 1.442    [weighted Loss:1.442    Policy Loss: 7.474    Value Loss: 6.023    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 219492     Buffer Size: 12870      Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:09:54,720][train][INFO][train.py>_log] ==> #599000     Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 8.101    Value Loss: 6.234    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 219741     Buffer Size: 12831      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:18:04,710][train][INFO][train.py>_log] ==> #600000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 7.504    Value Loss: 6.252    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 220064     Buffer Size: 12869      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:26:05,932][train][INFO][train.py>_log] ==> #601000     Total Loss: 0.922    [weighted Loss:0.922    Policy Loss: 8.035    Value Loss: 6.174    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 220403     Buffer Size: 12849      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:34:03,459][train][INFO][train.py>_log] ==> #602000     Total Loss: 2.243    [weighted Loss:2.243    Policy Loss: 7.834    Value Loss: 5.895    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 220746     Buffer Size: 12565      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:42:13,103][train][INFO][train.py>_log] ==> #603000     Total Loss: 1.843    [weighted Loss:1.843    Policy Loss: 8.004    Value Loss: 6.028    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 221070     Buffer Size: 12371      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:50:33,588][train][INFO][train.py>_log] ==> #604000     Total Loss: 1.475    [weighted Loss:1.475    Policy Loss: 7.753    Value Loss: 6.258    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 221334     Buffer Size: 12158      Transition Number: 400.113 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:59:07,449][train][INFO][train.py>_log] ==> #605000     Total Loss: 3.103    [weighted Loss:3.103    Policy Loss: 7.288    Value Loss: 5.906    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 221587     Buffer Size: 12035      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:07:45,832][train][INFO][train.py>_log] ==> #606000     Total Loss: 1.837    [weighted Loss:1.837    Policy Loss: 6.995    Value Loss: 6.122    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 221871     Buffer Size: 11952      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:16:22,399][train][INFO][train.py>_log] ==> #607000     Total Loss: 1.095    [weighted Loss:1.095    Policy Loss: 7.224    Value Loss: 6.130    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 222126     Buffer Size: 11906      Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:24:51,921][train][INFO][train.py>_log] ==> #608000     Total Loss: 1.222    [weighted Loss:1.222    Policy Loss: 7.757    Value Loss: 6.418    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 222514     Buffer Size: 11976      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:33:11,232][train][INFO][train.py>_log] ==> #609000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 7.312    Value Loss: 5.753    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 223001     Buffer Size: 12173      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:41:13,506][train][INFO][train.py>_log] ==> #610000     Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 7.119    Value Loss: 5.880    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 223553     Buffer Size: 12451      Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:49:17,717][train][INFO][train.py>_log] ==> #611000     Total Loss: 0.406    [weighted Loss:0.406    Policy Loss: 6.731    Value Loss: 6.379    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 224016     Buffer Size: 12657      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:57:21,101][train][INFO][train.py>_log] ==> #612000     Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 7.370    Value Loss: 5.921    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 224426     Buffer Size: 12766      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:05:14,346][train][INFO][train.py>_log] ==> #613000     Total Loss: 3.087    [weighted Loss:3.087    Policy Loss: 7.768    Value Loss: 6.643    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 224847     Buffer Size: 12845      Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:13:18,525][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 7.899    Value Loss: 5.946    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 225237     Buffer Size: 12924      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:21:19,068][train][INFO][train.py>_log] ==> #615000     Total Loss: 1.479    [weighted Loss:1.479    Policy Loss: 7.495    Value Loss: 5.997    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 225619     Buffer Size: 12905      Transition Number: 400.017 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:29:14,053][train][INFO][train.py>_log] ==> #616000     Total Loss: 1.565    [weighted Loss:1.565    Policy Loss: 7.498    Value Loss: 6.364    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 225975     Buffer Size: 12880      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:37:04,445][train][INFO][train.py>_log] ==> #617000     Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 7.372    Value Loss: 5.934    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 226345     Buffer Size: 12932      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:45:01,422][train][INFO][train.py>_log] ==> #618000     Total Loss: 1.829    [weighted Loss:1.829    Policy Loss: 8.044    Value Loss: 5.901    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 226631     Buffer Size: 12915      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:53:06,443][train][INFO][train.py>_log] ==> #619000     Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 7.192    Value Loss: 5.664    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 226936     Buffer Size: 12835      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:01:10,712][train][INFO][train.py>_log] ==> #620000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 7.253    Value Loss: 5.932    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 227245     Buffer Size: 12711      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:09:14,831][train][INFO][train.py>_log] ==> #621000     Total Loss: 0.812    [weighted Loss:0.812    Policy Loss: 8.168    Value Loss: 6.199    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 227563     Buffer Size: 12567      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:17:25,227][train][INFO][train.py>_log] ==> #622000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 8.299    Value Loss: 6.112    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 227923     Buffer Size: 12301      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:25:40,999][train][INFO][train.py>_log] ==> #623000     Total Loss: 1.602    [weighted Loss:1.602    Policy Loss: 6.949    Value Loss: 6.146    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 228165     Buffer Size: 11955      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:34:11,937][train][INFO][train.py>_log] ==> #624000     Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 8.001    Value Loss: 6.065    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 228490     Buffer Size: 11815      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:42:41,355][train][INFO][train.py>_log] ==> #625000     Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 6.066    Value Loss: 6.171    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 228882     Buffer Size: 11879      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:51:09,026][train][INFO][train.py>_log] ==> #626000     Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 6.408    Value Loss: 6.296    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 229201     Buffer Size: 11932      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:59:22,716][train][INFO][train.py>_log] ==> #627000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 6.192    Value Loss: 6.218    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 229597     Buffer Size: 12019      Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-11 02:07:47,401][train][INFO][train.py>_log] ==> #628000     Total Loss: 3.020    [weighted Loss:3.020    Policy Loss: 6.465    Value Loss: 5.831    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 229886     Buffer Size: 11952      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 02:16:19,132][train][INFO][train.py>_log] ==> #629000     Total Loss: 1.443    [weighted Loss:1.443    Policy Loss: 6.099    Value Loss: 6.037    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 230172     Buffer Size: 11901      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-11 02:24:50,360][train][INFO][train.py>_log] ==> #630000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 6.388    Value Loss: 5.932    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 230475     Buffer Size: 11869      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-11 02:33:26,300][train][INFO][train.py>_log] ==> #631000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 5.487    Value Loss: 5.755    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 230750     Buffer Size: 11790      Transition Number: 400.134 k Batch Size: 128        Lr: 0.100   
[2021-11-11 02:42:11,374][train][INFO][train.py>_log] ==> #632000     Total Loss: 2.239    [weighted Loss:2.239    Policy Loss: 5.554    Value Loss: 6.381    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 231051     Buffer Size: 11771      Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-11 02:50:48,302][train][INFO][train.py>_log] ==> #633000     Total Loss: 1.255    [weighted Loss:1.255    Policy Loss: 5.976    Value Loss: 5.968    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 231347     Buffer Size: 11833      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-11 02:59:09,317][train][INFO][train.py>_log] ==> #634000     Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 5.793    Value Loss: 5.547    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 232108     Buffer Size: 12306      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-11 03:07:22,296][train][INFO][train.py>_log] ==> #635000     Total Loss: 1.151    [weighted Loss:1.151    Policy Loss: 5.382    Value Loss: 5.966    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 232590     Buffer Size: 12463      Transition Number: 400.033 k Batch Size: 128        Lr: 0.100   
[2021-11-11 03:15:32,705][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 5.640    Value Loss: 6.149    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 232934     Buffer Size: 12472      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-11 03:23:53,913][train][INFO][train.py>_log] ==> #637000     Total Loss: 3.215    [weighted Loss:3.215    Policy Loss: 6.422    Value Loss: 5.864    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 233317     Buffer Size: 12498      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-11 03:32:09,325][train][INFO][train.py>_log] ==> #638000     Total Loss: 2.815    [weighted Loss:2.815    Policy Loss: 7.217    Value Loss: 6.157    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 233659     Buffer Size: 12534      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-11 03:40:21,430][train][INFO][train.py>_log] ==> #639000     Total Loss: 1.861    [weighted Loss:1.861    Policy Loss: 7.536    Value Loss: 6.653    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 234001     Buffer Size: 12633      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-11 03:48:28,653][train][INFO][train.py>_log] ==> #640000     Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 7.230    Value Loss: 6.794    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 234327     Buffer Size: 12733      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-11 03:56:40,784][train][INFO][train.py>_log] ==> #641000     Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 6.113    Value Loss: 6.034    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 234623     Buffer Size: 12772      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-11 04:05:02,663][train][INFO][train.py>_log] ==> #642000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 5.538    Value Loss: 6.426    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 234859     Buffer Size: 12760      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-11 04:13:24,790][train][INFO][train.py>_log] ==> #643000     Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 5.607    Value Loss: 5.970    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 235083     Buffer Size: 12627      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 04:21:46,194][train][INFO][train.py>_log] ==> #644000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 7.512    Value Loss: 6.401    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 235734     Buffer Size: 12796      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-11 04:29:47,408][train][INFO][train.py>_log] ==> #645000     Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 7.400    Value Loss: 5.984    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 236333     Buffer Size: 12863      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 04:37:57,663][train][INFO][train.py>_log] ==> #646000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 7.475    Value Loss: 6.289    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 236673     Buffer Size: 12728      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-11 04:46:14,085][train][INFO][train.py>_log] ==> #647000     Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 6.609    Value Loss: 6.398    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 237025     Buffer Size: 12663      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-11 04:54:37,719][train][INFO][train.py>_log] ==> #648000     Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 7.055    Value Loss: 5.749    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 237411     Buffer Size: 12633      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-11 05:02:57,032][train][INFO][train.py>_log] ==> #649000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 7.076    Value Loss: 6.355    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 237789     Buffer Size: 12621      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-11 05:11:20,235][train][INFO][train.py>_log] ==> #650000     Total Loss: 0.714    [weighted Loss:0.714    Policy Loss: 6.282    Value Loss: 6.216    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 238117     Buffer Size: 12555      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-11 05:19:35,168][train][INFO][train.py>_log] ==> #651000     Total Loss: 0.813    [weighted Loss:0.813    Policy Loss: 6.319    Value Loss: 5.943    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 238650     Buffer Size: 12696      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-11 05:27:51,600][train][INFO][train.py>_log] ==> #652000     Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 6.474    Value Loss: 6.569    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 238992     Buffer Size: 12641      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 05:36:05,892][train][INFO][train.py>_log] ==> #653000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 6.859    Value Loss: 6.060    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 239336     Buffer Size: 12693      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-11 05:44:28,813][train][INFO][train.py>_log] ==> #654000     Total Loss: 1.061    [weighted Loss:1.061    Policy Loss: 6.556    Value Loss: 6.202    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 239604     Buffer Size: 12622      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-11 05:53:07,394][train][INFO][train.py>_log] ==> #655000     Total Loss: 1.768    [weighted Loss:1.768    Policy Loss: 6.794    Value Loss: 6.485    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 239887     Buffer Size: 12576      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 06:01:36,702][train][INFO][train.py>_log] ==> #656000     Total Loss: 1.973    [weighted Loss:1.973    Policy Loss: 6.401    Value Loss: 6.320    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 240205     Buffer Size: 12541      Transition Number: 400.050 k Batch Size: 128        Lr: 0.100   
[2021-11-11 06:10:06,761][train][INFO][train.py>_log] ==> #657000     Total Loss: 0.929    [weighted Loss:0.929    Policy Loss: 6.462    Value Loss: 5.792    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 240568     Buffer Size: 12558      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-11 06:18:37,696][train][INFO][train.py>_log] ==> #658000     Total Loss: 1.282    [weighted Loss:1.282    Policy Loss: 6.578    Value Loss: 5.910    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 240908     Buffer Size: 12627      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-11 06:26:55,845][train][INFO][train.py>_log] ==> #659000     Total Loss: 1.872    [weighted Loss:1.872    Policy Loss: 5.570    Value Loss: 6.395    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 241256     Buffer Size: 12660      Transition Number: 400.200 k Batch Size: 128        Lr: 0.100   
[2021-11-11 06:35:14,656][train][INFO][train.py>_log] ==> #660000     Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 6.987    Value Loss: 6.324    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 241597     Buffer Size: 12645      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 06:43:37,251][train][INFO][train.py>_log] ==> #661000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 7.123    Value Loss: 6.149    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 241972     Buffer Size: 12688      Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-11 06:51:54,173][train][INFO][train.py>_log] ==> #662000     Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 7.000    Value Loss: 5.879    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 242314     Buffer Size: 12645      Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-11 07:00:15,338][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 6.623    Value Loss: 5.865    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 242636     Buffer Size: 12694      Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-11 07:08:38,161][train][INFO][train.py>_log] ==> #664000     Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 7.828    Value Loss: 6.715    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 242988     Buffer Size: 12756      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-11 07:16:58,889][train][INFO][train.py>_log] ==> #665000     Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 6.946    Value Loss: 6.029    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 243316     Buffer Size: 12800      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-11 07:25:11,168][train][INFO][train.py>_log] ==> #666000     Total Loss: 1.266    [weighted Loss:1.266    Policy Loss: 5.442    Value Loss: 6.129    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 243726     Buffer Size: 12954      Transition Number: 399.931 k Batch Size: 128        Lr: 0.100   
[2021-11-11 07:33:17,715][train][INFO][train.py>_log] ==> #667000     Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 7.364    Value Loss: 6.233    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 244127     Buffer Size: 13076      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-11 07:41:18,893][train][INFO][train.py>_log] ==> #668000     Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 7.146    Value Loss: 6.079    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 244558     Buffer Size: 13216      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-11 07:49:15,503][train][INFO][train.py>_log] ==> #669000     Total Loss: 1.572    [weighted Loss:1.572    Policy Loss: 6.757    Value Loss: 5.962    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 244942     Buffer Size: 12948      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-11 07:57:16,037][train][INFO][train.py>_log] ==> #670000     Total Loss: 1.411    [weighted Loss:1.411    Policy Loss: 7.269    Value Loss: 5.912    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 245330     Buffer Size: 12822      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-11 08:05:19,714][train][INFO][train.py>_log] ==> #671000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 7.343    Value Loss: 5.929    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 245692     Buffer Size: 12830      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-11 08:13:31,344][train][INFO][train.py>_log] ==> #672000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 7.428    Value Loss: 5.933    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 245955     Buffer Size: 12719      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-11 08:21:52,306][train][INFO][train.py>_log] ==> #673000     Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 6.830    Value Loss: 6.682    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 246225     Buffer Size: 12611      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-11 08:30:16,279][train][INFO][train.py>_log] ==> #674000     Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 7.292    Value Loss: 6.045    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 246478     Buffer Size: 12508      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 08:38:35,900][train][INFO][train.py>_log] ==> #675000     Total Loss: 0.770    [weighted Loss:0.770    Policy Loss: 7.372    Value Loss: 5.942    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 246766     Buffer Size: 12436      Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-11 08:47:00,554][train][INFO][train.py>_log] ==> #676000     Total Loss: 3.028    [weighted Loss:3.028    Policy Loss: 6.972    Value Loss: 6.475    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 247054     Buffer Size: 12420      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-11 08:55:23,618][train][INFO][train.py>_log] ==> #677000     Total Loss: 2.191    [weighted Loss:2.191    Policy Loss: 8.100    Value Loss: 6.189    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 247317     Buffer Size: 12433      Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-11 09:03:45,055][train][INFO][train.py>_log] ==> #678000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 8.975    Value Loss: 6.145    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 247616     Buffer Size: 12483      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-11 09:11:58,001][train][INFO][train.py>_log] ==> #679000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.595    Value Loss: 6.408    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 248018     Buffer Size: 12258      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 09:20:16,582][train][INFO][train.py>_log] ==> #680000     Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 6.473    Value Loss: 5.892    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 248317     Buffer Size: 11975      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-11 09:28:42,524][train][INFO][train.py>_log] ==> #681000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 8.446    Value Loss: 5.829    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 248622     Buffer Size: 11932      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-11 09:37:16,111][train][INFO][train.py>_log] ==> #682000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 7.696    Value Loss: 5.759    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 248870     Buffer Size: 11797      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-11 09:45:51,142][train][INFO][train.py>_log] ==> #683000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 5.336    Value Loss: 6.476    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 249121     Buffer Size: 11655      Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-11 09:54:36,500][train][INFO][train.py>_log] ==> #684000     Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 6.764    Value Loss: 5.996    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 249476     Buffer Size: 11594      Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-11 10:03:09,910][train][INFO][train.py>_log] ==> #685000     Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 8.473    Value Loss: 5.949    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 249833     Buffer Size: 11558      Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-11 10:11:41,964][train][INFO][train.py>_log] ==> #686000     Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 6.832    Value Loss: 6.108    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 250183     Buffer Size: 11410      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-11 10:20:11,262][train][INFO][train.py>_log] ==> #687000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 6.851    Value Loss: 6.020    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 250539     Buffer Size: 11400      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-11 10:28:40,250][train][INFO][train.py>_log] ==> #688000     Total Loss: 1.571    [weighted Loss:1.571    Policy Loss: 7.349    Value Loss: 6.357    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 250871     Buffer Size: 11400      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 10:37:10,867][train][INFO][train.py>_log] ==> #689000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 8.130    Value Loss: 6.353    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 251211     Buffer Size: 11492      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-11 10:45:53,512][train][INFO][train.py>_log] ==> #690000     Total Loss: 1.567    [weighted Loss:1.567    Policy Loss: 7.786    Value Loss: 6.388    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 251581     Buffer Size: 11531      Transition Number: 400.023 k Batch Size: 128        Lr: 0.100   
[2021-11-11 10:54:24,367][train][INFO][train.py>_log] ==> #691000     Total Loss: 3.248    [weighted Loss:3.248    Policy Loss: 7.435    Value Loss: 6.205    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 251929     Buffer Size: 11535      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-11 11:02:41,982][train][INFO][train.py>_log] ==> #692000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 7.816    Value Loss: 6.033    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 252505     Buffer Size: 11739      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-11 11:10:50,974][train][INFO][train.py>_log] ==> #693000     Total Loss: 2.154    [weighted Loss:2.154    Policy Loss: 8.152    Value Loss: 6.224    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 253052     Buffer Size: 11921      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-11 11:18:55,161][train][INFO][train.py>_log] ==> #694000     Total Loss: 2.119    [weighted Loss:2.119    Policy Loss: 8.667    Value Loss: 6.062    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 253974     Buffer Size: 12466      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-11 11:26:49,634][train][INFO][train.py>_log] ==> #695000     Total Loss: 3.410    [weighted Loss:3.410    Policy Loss: 8.452    Value Loss: 6.254    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 254971     Buffer Size: 13095      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-11 11:34:40,768][train][INFO][train.py>_log] ==> #696000     Total Loss: 1.637    [weighted Loss:1.637    Policy Loss: 8.831    Value Loss: 5.972    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 256028     Buffer Size: 13809      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-11 11:42:27,444][train][INFO][train.py>_log] ==> #697000     Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 7.969    Value Loss: 6.145    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 256675     Buffer Size: 14148      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-11 11:50:15,789][train][INFO][train.py>_log] ==> #698000     Total Loss: 1.859    [weighted Loss:1.859    Policy Loss: 7.914    Value Loss: 6.204    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 257231     Buffer Size: 14388      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-11 11:58:02,281][train][INFO][train.py>_log] ==> #699000     Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 7.307    Value Loss: 6.396    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 257670     Buffer Size: 14504      Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-11 12:05:44,004][train][INFO][train.py>_log] ==> #700000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 6.116    Value Loss: 6.019    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 258317     Buffer Size: 14742      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-11 12:13:19,655][train][INFO][train.py>_log] ==> #701000     Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 7.937    Value Loss: 6.502    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 259058     Buffer Size: 15074      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-11 12:20:43,234][train][INFO][train.py>_log] ==> #702000     Total Loss: 3.482    [weighted Loss:3.482    Policy Loss: 7.909    Value Loss: 5.969    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 259787     Buffer Size: 15372      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-11 12:28:03,666][train][INFO][train.py>_log] ==> #703000     Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 8.013    Value Loss: 5.990    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 260261     Buffer Size: 15459      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-11 12:35:28,225][train][INFO][train.py>_log] ==> #704000     Total Loss: 1.180    [weighted Loss:1.180    Policy Loss: 8.827    Value Loss: 5.819    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 260732     Buffer Size: 15542      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 12:42:59,638][train][INFO][train.py>_log] ==> #705000     Total Loss: 2.561    [weighted Loss:2.561    Policy Loss: 7.907    Value Loss: 6.005    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 261147     Buffer Size: 15598      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-11 12:50:29,775][train][INFO][train.py>_log] ==> #706000     Total Loss: 1.131    [weighted Loss:1.131    Policy Loss: 7.843    Value Loss: 6.207    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 261439     Buffer Size: 15605      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-11 12:58:00,251][train][INFO][train.py>_log] ==> #707000     Total Loss: 1.154    [weighted Loss:1.154    Policy Loss: 7.823    Value Loss: 5.854    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 261774     Buffer Size: 15718      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-11 13:05:28,046][train][INFO][train.py>_log] ==> #708000     Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 8.562    Value Loss: 6.119    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 262082     Buffer Size: 15800      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-11 13:12:53,283][train][INFO][train.py>_log] ==> #709000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 8.131    Value Loss: 6.118    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 262355     Buffer Size: 15870      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-11 13:20:16,158][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.723    [weighted Loss:2.723    Policy Loss: 8.209    Value Loss: 5.920    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 262701     Buffer Size: 15945      Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-11 13:27:45,166][train][INFO][train.py>_log] ==> #711000     Total Loss: 2.648    [weighted Loss:2.648    Policy Loss: 7.403    Value Loss: 6.044    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 262982     Buffer Size: 15974      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-11 13:35:14,120][train][INFO][train.py>_log] ==> #712000     Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 7.477    Value Loss: 6.077    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 263286     Buffer Size: 16042      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-11 13:42:37,795][train][INFO][train.py>_log] ==> #713000     Total Loss: 1.146    [weighted Loss:1.146    Policy Loss: 7.925    Value Loss: 5.997    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 263583     Buffer Size: 16097      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-11 13:49:55,319][train][INFO][train.py>_log] ==> #714000     Total Loss: 1.142    [weighted Loss:1.142    Policy Loss: 7.073    Value Loss: 6.310    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 263899     Buffer Size: 16109      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-11 13:57:21,221][train][INFO][train.py>_log] ==> #715000     Total Loss: 0.906    [weighted Loss:0.906    Policy Loss: 6.025    Value Loss: 5.900    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 264233     Buffer Size: 16117      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-11 14:04:48,736][train][INFO][train.py>_log] ==> #716000     Total Loss: 1.941    [weighted Loss:1.941    Policy Loss: 6.185    Value Loss: 5.929    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 264561     Buffer Size: 16160      Transition Number: 400.051 k Batch Size: 128        Lr: 0.100   
[2021-11-11 14:12:13,995][train][INFO][train.py>_log] ==> #717000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 8.011    Value Loss: 6.266    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 264834     Buffer Size: 16179      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-11 14:19:41,144][train][INFO][train.py>_log] ==> #718000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 8.527    Value Loss: 6.039    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 265079     Buffer Size: 16227      Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-11 14:27:06,275][train][INFO][train.py>_log] ==> #719000     Total Loss: 3.176    [weighted Loss:3.176    Policy Loss: 8.078    Value Loss: 6.039    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 265299     Buffer Size: 16236      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-11 14:34:35,176][train][INFO][train.py>_log] ==> #720000     Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 7.611    Value Loss: 5.644    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 265542     Buffer Size: 16224      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-11 14:42:09,703][train][INFO][train.py>_log] ==> #721000     Total Loss: 3.417    [weighted Loss:3.417    Policy Loss: 8.237    Value Loss: 5.921    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 265801     Buffer Size: 16169      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-11 14:49:30,551][train][INFO][train.py>_log] ==> #722000     Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 8.874    Value Loss: 6.014    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 266184     Buffer Size: 16235      Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-11 14:56:55,983][train][INFO][train.py>_log] ==> #723000     Total Loss: 4.178    [weighted Loss:4.178    Policy Loss: 8.963    Value Loss: 5.989    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 266574     Buffer Size: 16317      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-11 15:04:16,178][train][INFO][train.py>_log] ==> #724000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 7.834    Value Loss: 6.027    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 266847     Buffer Size: 16297      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-11 15:11:38,525][train][INFO][train.py>_log] ==> #725000     Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 8.315    Value Loss: 6.154    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 267184     Buffer Size: 16346      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-11 15:18:57,264][train][INFO][train.py>_log] ==> #726000     Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 8.612    Value Loss: 6.000    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 267568     Buffer Size: 16456      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-11 15:26:14,535][train][INFO][train.py>_log] ==> #727000     Total Loss: 1.528    [weighted Loss:1.528    Policy Loss: 8.102    Value Loss: 5.927    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 267942     Buffer Size: 16546      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-11 15:33:36,708][train][INFO][train.py>_log] ==> #728000     Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 8.396    Value Loss: 6.105    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 268310     Buffer Size: 16594      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-11 15:40:43,047][train][INFO][train.py>_log] ==> #729000     Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 8.163    Value Loss: 6.101    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 269189     Buffer Size: 17110      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-11 15:47:53,682][train][INFO][train.py>_log] ==> #730000     Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 8.351    Value Loss: 6.093    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 269529     Buffer Size: 16994      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-11 15:55:07,217][train][INFO][train.py>_log] ==> #731000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 7.923    Value Loss: 6.135    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 269997     Buffer Size: 16958      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-11 16:02:19,219][train][INFO][train.py>_log] ==> #732000     Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 8.282    Value Loss: 5.768    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 270618     Buffer Size: 16786      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-11 16:09:44,687][train][INFO][train.py>_log] ==> #733000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 9.798    Value Loss: 5.917    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 270906     Buffer Size: 16265      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-11 16:17:18,791][train][INFO][train.py>_log] ==> #734000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 7.665    Value Loss: 6.021    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 271196     Buffer Size: 15569      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-11 16:24:54,118][train][INFO][train.py>_log] ==> #735000     Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 7.191    Value Loss: 6.185    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 271485     Buffer Size: 15071      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 16:32:27,535][train][INFO][train.py>_log] ==> #736000     Total Loss: 0.928    [weighted Loss:0.928    Policy Loss: 9.005    Value Loss: 5.840    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 271742     Buffer Size: 14774      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 16:40:01,240][train][INFO][train.py>_log] ==> #737000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 6.904    Value Loss: 5.682    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 272187     Buffer Size: 14741      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-11 16:47:37,894][train][INFO][train.py>_log] ==> #738000     Total Loss: 2.867    [weighted Loss:2.867    Policy Loss: 7.758    Value Loss: 6.139    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 272774     Buffer Size: 14826      Transition Number: 400.068 k Batch Size: 128        Lr: 0.100   
[2021-11-11 16:55:05,372][train][INFO][train.py>_log] ==> #739000     Total Loss: 0.809    [weighted Loss:0.809    Policy Loss: 6.982    Value Loss: 6.616    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 273292     Buffer Size: 14708      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-11 17:02:31,617][train][INFO][train.py>_log] ==> #740000     Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 7.273    Value Loss: 5.993    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 274069     Buffer Size: 14801      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-11 17:09:54,810][train][INFO][train.py>_log] ==> #741000     Total Loss: 3.223    [weighted Loss:3.223    Policy Loss: 8.241    Value Loss: 5.703    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 275164     Buffer Size: 15250      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-11 17:17:24,848][train][INFO][train.py>_log] ==> #742000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 7.279    Value Loss: 6.183    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 275657     Buffer Size: 15276      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 17:24:57,091][train][INFO][train.py>_log] ==> #743000     Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 6.698    Value Loss: 6.073    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 276061     Buffer Size: 15249      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-11 17:32:34,843][train][INFO][train.py>_log] ==> #744000     Total Loss: 3.840    [weighted Loss:3.840    Policy Loss: 7.333    Value Loss: 5.856    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 276434     Buffer Size: 15222      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-11 17:40:16,709][train][INFO][train.py>_log] ==> #745000     Total Loss: 1.565    [weighted Loss:1.565    Policy Loss: 6.587    Value Loss: 5.731    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 276692     Buffer Size: 15198      Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-11 17:48:00,768][train][INFO][train.py>_log] ==> #746000     Total Loss: 1.160    [weighted Loss:1.160    Policy Loss: 5.600    Value Loss: 6.015    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 276952     Buffer Size: 15105      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-11 17:55:43,795][train][INFO][train.py>_log] ==> #747000     Total Loss: 0.480    [weighted Loss:0.480    Policy Loss: 5.406    Value Loss: 6.101    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 277335     Buffer Size: 15168      Transition Number: 400.024 k Batch Size: 128        Lr: 0.100   
[2021-11-11 18:03:22,945][train][INFO][train.py>_log] ==> #748000     Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 5.969    Value Loss: 5.581    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 277836     Buffer Size: 15308      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-11 18:10:49,010][train][INFO][train.py>_log] ==> #749000     Total Loss: 1.281    [weighted Loss:1.281    Policy Loss: 6.012    Value Loss: 6.006    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 278268     Buffer Size: 15427      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-11 18:19:00,672][train][INFO][train.py>_log] ==> #750000     Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 6.564    Value Loss: 6.001    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 278511     Buffer Size: 15350      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-11 18:26:44,502][train][INFO][train.py>_log] ==> #751000     Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 6.715    Value Loss: 5.885    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 278747     Buffer Size: 15291      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-11 18:34:28,834][train][INFO][train.py>_log] ==> #752000     Total Loss: 2.395    [weighted Loss:2.395    Policy Loss: 7.084    Value Loss: 6.167    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 278986     Buffer Size: 15220      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-11 18:42:12,717][train][INFO][train.py>_log] ==> #753000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 6.036    Value Loss: 6.096    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 279361     Buffer Size: 15250      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-11 18:49:57,222][train][INFO][train.py>_log] ==> #754000     Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 7.059    Value Loss: 5.999    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 279688     Buffer Size: 15238      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-11 18:57:39,049][train][INFO][train.py>_log] ==> #755000     Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 7.411    Value Loss: 6.248    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 280008     Buffer Size: 15270      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-11 19:05:23,140][train][INFO][train.py>_log] ==> #756000     Total Loss: 1.484    [weighted Loss:1.484    Policy Loss: 7.610    Value Loss: 6.417    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 280319     Buffer Size: 15302      Transition Number: 400.028 k Batch Size: 128        Lr: 0.100   
[2021-11-11 19:13:09,180][train][INFO][train.py>_log] ==> #757000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 7.540    Value Loss: 5.927    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 280664     Buffer Size: 15414      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 19:20:43,960][train][INFO][train.py>_log] ==> #758000     Total Loss: 1.231    [weighted Loss:1.231    Policy Loss: 6.927    Value Loss: 6.129    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 281026     Buffer Size: 15519      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-11 19:28:16,818][train][INFO][train.py>_log] ==> #759000     Total Loss: 1.351    [weighted Loss:1.351    Policy Loss: 7.269    Value Loss: 6.102    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 281363     Buffer Size: 15620      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-11 19:35:48,298][train][INFO][train.py>_log] ==> #760000     Total Loss: 0.969    [weighted Loss:0.969    Policy Loss: 6.865    Value Loss: 5.639    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 281720     Buffer Size: 15602      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-11 19:43:19,235][train][INFO][train.py>_log] ==> #761000     Total Loss: 1.009    [weighted Loss:1.009    Policy Loss: 7.414    Value Loss: 5.712    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 282028     Buffer Size: 15556      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-11 19:51:02,283][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 7.527    Value Loss: 5.584    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 282357     Buffer Size: 15562      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-11 19:58:41,430][train][INFO][train.py>_log] ==> #763000     Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 7.227    Value Loss: 6.168    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 282674     Buffer Size: 15565      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-11 20:06:22,502][train][INFO][train.py>_log] ==> #764000     Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 6.340    Value Loss: 6.210    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 283110     Buffer Size: 15604      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-11 20:13:54,055][train][INFO][train.py>_log] ==> #765000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 7.619    Value Loss: 6.195    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 283595     Buffer Size: 15686      Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-11 20:21:26,042][train][INFO][train.py>_log] ==> #766000     Total Loss: 1.064    [weighted Loss:1.064    Policy Loss: 6.526    Value Loss: 5.850    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 283997     Buffer Size: 15698      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-11 20:28:53,523][train][INFO][train.py>_log] ==> #767000     Total Loss: 1.323    [weighted Loss:1.323    Policy Loss: 7.574    Value Loss: 5.693    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 284644     Buffer Size: 15478      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-11 20:36:20,547][train][INFO][train.py>_log] ==> #768000     Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 7.754    Value Loss: 6.437    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 285282     Buffer Size: 15715      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-11 20:43:52,953][train][INFO][train.py>_log] ==> #769000     Total Loss: 1.275    [weighted Loss:1.275    Policy Loss: 7.614    Value Loss: 5.779    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 285559     Buffer Size: 15549      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-11 20:51:29,873][train][INFO][train.py>_log] ==> #770000     Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 8.164    Value Loss: 6.336    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 285858     Buffer Size: 15257      Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-11 20:59:12,866][train][INFO][train.py>_log] ==> #771000     Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 7.841    Value Loss: 6.191    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 286100     Buffer Size: 15187      Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-11 21:07:00,705][train][INFO][train.py>_log] ==> #772000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 8.204    Value Loss: 6.352    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 286350     Buffer Size: 15167      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-11 21:14:42,810][train][INFO][train.py>_log] ==> #773000     Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 6.826    Value Loss: 5.733    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 286635     Buffer Size: 15173      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-11 21:22:26,396][train][INFO][train.py>_log] ==> #774000     Total Loss: 1.032    [weighted Loss:1.032    Policy Loss: 7.568    Value Loss: 5.976    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 286869     Buffer Size: 15135      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 21:30:08,418][train][INFO][train.py>_log] ==> #775000     Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 7.109    Value Loss: 5.865    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 287220     Buffer Size: 15040      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-11 21:37:49,189][train][INFO][train.py>_log] ==> #776000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 6.740    Value Loss: 5.650    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 287520     Buffer Size: 14769      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-11 21:45:34,798][train][INFO][train.py>_log] ==> #777000     Total Loss: 2.359    [weighted Loss:2.359    Policy Loss: 8.906    Value Loss: 6.106    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 287766     Buffer Size: 14527      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-11 21:53:30,282][train][INFO][train.py>_log] ==> #778000     Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 6.031    Value Loss: 6.117    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 288046     Buffer Size: 14035      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-11 22:01:29,627][train][INFO][train.py>_log] ==> #779000     Total Loss: 1.590    [weighted Loss:1.590    Policy Loss: 7.785    Value Loss: 6.219    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 288355     Buffer Size: 13355      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-11 22:09:24,387][train][INFO][train.py>_log] ==> #780000     Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 7.573    Value Loss: 6.232    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 288710     Buffer Size: 13086      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-11 22:17:22,052][train][INFO][train.py>_log] ==> #781000     Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 6.698    Value Loss: 6.022    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 289048     Buffer Size: 13019      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-11 22:25:20,591][train][INFO][train.py>_log] ==> #782000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 6.653    Value Loss: 5.772    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 289402     Buffer Size: 12973      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-11 22:33:34,696][train][INFO][train.py>_log] ==> #783000     Total Loss: 1.471    [weighted Loss:1.471    Policy Loss: 7.151    Value Loss: 6.263    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 289696     Buffer Size: 12960      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-11 22:41:36,161][train][INFO][train.py>_log] ==> #784000     Total Loss: 1.352    [weighted Loss:1.352    Policy Loss: 6.094    Value Loss: 5.712    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 290006     Buffer Size: 12956      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-11 22:49:31,213][train][INFO][train.py>_log] ==> #785000     Total Loss: 1.163    [weighted Loss:1.163    Policy Loss: 8.350    Value Loss: 6.149    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 290489     Buffer Size: 13002      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 22:57:18,513][train][INFO][train.py>_log] ==> #786000     Total Loss: 0.704    [weighted Loss:0.704    Policy Loss: 6.335    Value Loss: 6.085    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 291117     Buffer Size: 13107      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-11 23:04:59,997][train][INFO][train.py>_log] ==> #787000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 7.522    Value Loss: 6.072    Reward Loss: 1.270    Consistency Loss: 0.000    ] Replay Episodes Collected: 291813     Buffer Size: 13422      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-11 23:12:37,093][train][INFO][train.py>_log] ==> #788000     Total Loss: 0.665    [weighted Loss:0.665    Policy Loss: 8.054    Value Loss: 5.714    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 292656     Buffer Size: 14009      Transition Number: 400.028 k Batch Size: 128        Lr: 0.100   
[2021-11-11 23:20:02,159][train][INFO][train.py>_log] ==> #789000     Total Loss: 1.171    [weighted Loss:1.171    Policy Loss: 8.604    Value Loss: 6.058    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 293383     Buffer Size: 14459      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-11 23:27:29,125][train][INFO][train.py>_log] ==> #790000     Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 8.951    Value Loss: 5.972    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 293793     Buffer Size: 14538      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-11 23:34:59,152][train][INFO][train.py>_log] ==> #791000     Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 9.024    Value Loss: 6.194    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 294205     Buffer Size: 14627      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-11 23:42:34,103][train][INFO][train.py>_log] ==> #792000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 8.250    Value Loss: 6.219    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 294523     Buffer Size: 14611      Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-11 23:50:13,550][train][INFO][train.py>_log] ==> #793000     Total Loss: 2.137    [weighted Loss:2.137    Policy Loss: 7.990    Value Loss: 6.012    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 294828     Buffer Size: 14609      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-11 23:57:55,312][train][INFO][train.py>_log] ==> #794000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 7.705    Value Loss: 6.148    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 295106     Buffer Size: 14554      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-12 00:05:37,945][train][INFO][train.py>_log] ==> #795000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 7.091    Value Loss: 5.842    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 295374     Buffer Size: 14469      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-12 00:13:17,703][train][INFO][train.py>_log] ==> #796000     Total Loss: 1.518    [weighted Loss:1.518    Policy Loss: 8.089    Value Loss: 6.147    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 295658     Buffer Size: 14406      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-12 00:21:02,829][train][INFO][train.py>_log] ==> #797000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 7.853    Value Loss: 6.299    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 295975     Buffer Size: 14379      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-12 00:28:41,437][train][INFO][train.py>_log] ==> #798000     Total Loss: 1.211    [weighted Loss:1.211    Policy Loss: 7.805    Value Loss: 6.184    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 296451     Buffer Size: 14483      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-12 00:36:18,700][train][INFO][train.py>_log] ==> #799000     Total Loss: 1.280    [weighted Loss:1.280    Policy Loss: 8.360    Value Loss: 5.862    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 296967     Buffer Size: 14667      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-12 00:43:47,158][train][INFO][train.py>_log] ==> #800000     Total Loss: 1.533    [weighted Loss:1.533    Policy Loss: 9.234    Value Loss: 6.159    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 297381     Buffer Size: 14760      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-12 00:51:18,666][train][INFO][train.py>_log] ==> #801000     Total Loss: 1.227    [weighted Loss:1.227    Policy Loss: 9.226    Value Loss: 6.187    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 297792     Buffer Size: 14754      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-12 00:58:45,425][train][INFO][train.py>_log] ==> #802000     Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 8.650    Value Loss: 6.223    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 298404     Buffer Size: 14876      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-12 01:06:13,966][train][INFO][train.py>_log] ==> #803000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 8.678    Value Loss: 6.009    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 298769     Buffer Size: 14854      Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-12 01:13:52,949][train][INFO][train.py>_log] ==> #804000     Total Loss: 2.125    [weighted Loss:2.125    Policy Loss: 7.286    Value Loss: 5.966    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 299067     Buffer Size: 14596      Transition Number: 400.006 k Batch Size: 128        Lr: 0.100   
[2021-11-12 01:21:36,127][train][INFO][train.py>_log] ==> #805000     Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 7.400    Value Loss: 6.439    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 299420     Buffer Size: 14352      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-12 01:29:14,917][train][INFO][train.py>_log] ==> #806000     Total Loss: 0.882    [weighted Loss:0.882    Policy Loss: 5.923    Value Loss: 6.002    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 299805     Buffer Size: 14322      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-12 01:36:40,867][train][INFO][train.py>_log] ==> #807000     Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 6.370    Value Loss: 5.936    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 300432     Buffer Size: 14637      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 01:44:01,181][train][INFO][train.py>_log] ==> #808000     Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 8.600    Value Loss: 6.302    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 300970     Buffer Size: 14909      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-12 01:51:19,113][train][INFO][train.py>_log] ==> #809000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 6.563    Value Loss: 5.704    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 301314     Buffer Size: 15007      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-12 01:58:47,262][train][INFO][train.py>_log] ==> #810000     Total Loss: 2.843    [weighted Loss:2.843    Policy Loss: 8.249    Value Loss: 6.252    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 301649     Buffer Size: 15062      Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-12 02:06:17,857][train][INFO][train.py>_log] ==> #811000     Total Loss: 1.140    [weighted Loss:1.140    Policy Loss: 6.058    Value Loss: 6.248    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 301908     Buffer Size: 15083      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-12 02:13:35,308][train][INFO][train.py>_log] ==> #812000     Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 7.629    Value Loss: 6.355    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 302881     Buffer Size: 15727      Transition Number: 400.002 k Batch Size: 128        Lr: 0.100   
[2021-11-12 02:20:44,304][train][INFO][train.py>_log] ==> #813000     Total Loss: 1.959    [weighted Loss:1.959    Policy Loss: 7.141    Value Loss: 5.916    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 303329     Buffer Size: 15873      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-12 02:28:02,316][train][INFO][train.py>_log] ==> #814000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 9.630    Value Loss: 6.331    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 303591     Buffer Size: 15893      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-12 02:35:26,544][train][INFO][train.py>_log] ==> #815000     Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 8.164    Value Loss: 6.155    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 303851     Buffer Size: 15905      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-12 02:42:46,381][train][INFO][train.py>_log] ==> #816000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 6.622    Value Loss: 6.230    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 304130     Buffer Size: 15910      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-12 02:50:04,237][train][INFO][train.py>_log] ==> #817000     Total Loss: 1.687    [weighted Loss:1.687    Policy Loss: 7.188    Value Loss: 5.871    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 304628     Buffer Size: 16100      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-12 02:57:17,791][train][INFO][train.py>_log] ==> #818000     Total Loss: 0.607    [weighted Loss:0.607    Policy Loss: 6.828    Value Loss: 5.974    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 305310     Buffer Size: 16419      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-12 03:04:23,689][train][INFO][train.py>_log] ==> #819000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 7.183    Value Loss: 5.969    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 305812     Buffer Size: 16612      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-12 03:11:29,512][train][INFO][train.py>_log] ==> #820000     Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 7.921    Value Loss: 6.296    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 306268     Buffer Size: 16762      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-12 03:18:29,236][train][INFO][train.py>_log] ==> #821000     Total Loss: 1.854    [weighted Loss:1.854    Policy Loss: 8.537    Value Loss: 6.125    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 306702     Buffer Size: 16953      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-12 03:25:33,530][train][INFO][train.py>_log] ==> #822000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 8.618    Value Loss: 5.891    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 306980     Buffer Size: 16979      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-12 03:32:44,156][train][INFO][train.py>_log] ==> #823000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 9.146    Value Loss: 6.319    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 307365     Buffer Size: 16966      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-12 03:39:55,194][train][INFO][train.py>_log] ==> #824000     Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 8.892    Value Loss: 5.954    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 307763     Buffer Size: 16910      Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-12 03:47:07,494][train][INFO][train.py>_log] ==> #825000     Total Loss: 0.853    [weighted Loss:0.853    Policy Loss: 8.659    Value Loss: 5.914    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 308139     Buffer Size: 16704      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-12 03:54:27,213][train][INFO][train.py>_log] ==> #826000     Total Loss: 1.425    [weighted Loss:1.425    Policy Loss: 8.528    Value Loss: 6.447    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 308365     Buffer Size: 16335      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-12 04:01:54,564][train][INFO][train.py>_log] ==> #827000     Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 7.468    Value Loss: 5.922    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 308609     Buffer Size: 15815      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-12 04:09:25,192][train][INFO][train.py>_log] ==> #828000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 8.787    Value Loss: 6.056    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 308858     Buffer Size: 15440      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-12 04:17:01,541][train][INFO][train.py>_log] ==> #829000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 8.045    Value Loss: 6.372    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 309129     Buffer Size: 15320      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-12 04:24:40,854][train][INFO][train.py>_log] ==> #830000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 7.826    Value Loss: 6.104    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 309384     Buffer Size: 15154      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-12 04:32:22,901][train][INFO][train.py>_log] ==> #831000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 7.676    Value Loss: 6.199    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 309657     Buffer Size: 15111      Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-12 04:40:04,468][train][INFO][train.py>_log] ==> #832000     Total Loss: 0.474    [weighted Loss:0.474    Policy Loss: 7.232    Value Loss: 6.006    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 309990     Buffer Size: 15121      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-12 04:47:37,461][train][INFO][train.py>_log] ==> #833000     Total Loss: 0.656    [weighted Loss:0.656    Policy Loss: 7.460    Value Loss: 6.033    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 310330     Buffer Size: 15189      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-12 04:55:12,431][train][INFO][train.py>_log] ==> #834000     Total Loss: 1.119    [weighted Loss:1.119    Policy Loss: 7.949    Value Loss: 6.207    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 310660     Buffer Size: 15236      Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-12 05:02:46,266][train][INFO][train.py>_log] ==> #835000     Total Loss: 1.829    [weighted Loss:1.829    Policy Loss: 7.650    Value Loss: 6.183    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 311000     Buffer Size: 15280      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-12 05:10:26,033][train][INFO][train.py>_log] ==> #836000     Total Loss: 1.259    [weighted Loss:1.259    Policy Loss: 7.584    Value Loss: 5.720    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 311366     Buffer Size: 15290      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-12 05:18:01,192][train][INFO][train.py>_log] ==> #837000     Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 7.816    Value Loss: 5.847    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 311733     Buffer Size: 15188      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-12 05:25:34,585][train][INFO][train.py>_log] ==> #838000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 8.615    Value Loss: 6.167    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 312190     Buffer Size: 15146      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-12 05:33:06,088][train][INFO][train.py>_log] ==> #839000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 7.317    Value Loss: 6.033    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 312593     Buffer Size: 15157      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-12 05:40:42,340][train][INFO][train.py>_log] ==> #840000     Total Loss: 1.602    [weighted Loss:1.602    Policy Loss: 6.722    Value Loss: 5.839    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 312922     Buffer Size: 15052      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 05:48:24,261][train][INFO][train.py>_log] ==> #841000     Total Loss: 0.987    [weighted Loss:0.987    Policy Loss: 7.865    Value Loss: 5.983    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 313309     Buffer Size: 14847      Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-12 05:56:05,222][train][INFO][train.py>_log] ==> #842000     Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 6.612    Value Loss: 5.874    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 313652     Buffer Size: 14814      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-12 06:03:45,978][train][INFO][train.py>_log] ==> #843000     Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 7.228    Value Loss: 5.854    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 313981     Buffer Size: 14829      Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-12 06:11:24,426][train][INFO][train.py>_log] ==> #844000     Total Loss: 1.533    [weighted Loss:1.533    Policy Loss: 7.552    Value Loss: 5.901    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 314434     Buffer Size: 14907      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-12 06:19:05,943][train][INFO][train.py>_log] ==> #845000     Total Loss: 1.400    [weighted Loss:1.400    Policy Loss: 7.296    Value Loss: 6.317    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 314669     Buffer Size: 14687      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-12 06:26:55,076][train][INFO][train.py>_log] ==> #846000     Total Loss: 1.338    [weighted Loss:1.338    Policy Loss: 7.827    Value Loss: 6.090    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 315180     Buffer Size: 14600      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-12 06:34:33,032][train][INFO][train.py>_log] ==> #847000     Total Loss: 0.879    [weighted Loss:0.879    Policy Loss: 7.455    Value Loss: 6.151    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 316054     Buffer Size: 14940      Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-12 06:42:02,436][train][INFO][train.py>_log] ==> #848000     Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 7.123    Value Loss: 6.256    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 316611     Buffer Size: 15113      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-12 06:49:29,748][train][INFO][train.py>_log] ==> #849000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 8.019    Value Loss: 6.383    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 317171     Buffer Size: 15355      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-12 06:56:59,767][train][INFO][train.py>_log] ==> #850000     Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 6.505    Value Loss: 5.833    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 317907     Buffer Size: 15271      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-12 07:04:16,088][train][INFO][train.py>_log] ==> #851000     Total Loss: 1.773    [weighted Loss:1.773    Policy Loss: 6.282    Value Loss: 6.053    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 318424     Buffer Size: 15173      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-12 07:11:38,405][train][INFO][train.py>_log] ==> #852000     Total Loss: 1.428    [weighted Loss:1.428    Policy Loss: 6.781    Value Loss: 5.974    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 318866     Buffer Size: 15289      Transition Number: 399.932 k Batch Size: 128        Lr: 0.100   
[2021-11-12 07:18:54,586][train][INFO][train.py>_log] ==> #853000     Total Loss: 1.382    [weighted Loss:1.382    Policy Loss: 6.774    Value Loss: 6.098    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 319271     Buffer Size: 15428      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-12 07:26:12,341][train][INFO][train.py>_log] ==> #854000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 8.038    Value Loss: 6.548    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 319715     Buffer Size: 15570      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-12 07:33:32,510][train][INFO][train.py>_log] ==> #855000     Total Loss: 0.373    [weighted Loss:0.373    Policy Loss: 8.177    Value Loss: 6.077    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 320050     Buffer Size: 15421      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-12 07:40:56,496][train][INFO][train.py>_log] ==> #856000     Total Loss: 1.423    [weighted Loss:1.423    Policy Loss: 7.813    Value Loss: 6.678    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 320462     Buffer Size: 15202      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-12 07:48:27,674][train][INFO][train.py>_log] ==> #857000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 7.464    Value Loss: 6.342    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 320773     Buffer Size: 15001      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-12 07:55:59,152][train][INFO][train.py>_log] ==> #858000     Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 8.812    Value Loss: 5.999    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 321122     Buffer Size: 14897      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-12 08:03:39,000][train][INFO][train.py>_log] ==> #859000     Total Loss: 1.637    [weighted Loss:1.637    Policy Loss: 6.607    Value Loss: 5.945    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 321448     Buffer Size: 14745      Transition Number: 400.023 k Batch Size: 128        Lr: 0.100   
[2021-11-12 08:11:25,526][train][INFO][train.py>_log] ==> #860000     Total Loss: 1.933    [weighted Loss:1.933    Policy Loss: 8.623    Value Loss: 5.901    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 321969     Buffer Size: 14898      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-12 08:19:01,198][train][INFO][train.py>_log] ==> #861000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 6.782    Value Loss: 5.857    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 322310     Buffer Size: 14829      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-12 08:26:37,803][train][INFO][train.py>_log] ==> #862000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 7.449    Value Loss: 6.177    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 322655     Buffer Size: 14755      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-12 08:34:09,440][train][INFO][train.py>_log] ==> #863000     Total Loss: 1.026    [weighted Loss:1.026    Policy Loss: 7.502    Value Loss: 5.796    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 323274     Buffer Size: 15029      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-12 08:41:33,557][train][INFO][train.py>_log] ==> #864000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 7.002    Value Loss: 6.060    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 323800     Buffer Size: 15313      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-12 08:48:55,577][train][INFO][train.py>_log] ==> #865000     Total Loss: 1.826    [weighted Loss:1.826    Policy Loss: 6.848    Value Loss: 6.203    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 324218     Buffer Size: 15477      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-12 08:56:19,726][train][INFO][train.py>_log] ==> #866000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 7.036    Value Loss: 6.530    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 324540     Buffer Size: 15541      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-12 09:03:46,950][train][INFO][train.py>_log] ==> #867000     Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 6.694    Value Loss: 5.799    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 324861     Buffer Size: 15620      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-12 09:11:02,881][train][INFO][train.py>_log] ==> #868000     Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 7.490    Value Loss: 6.240    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 325325     Buffer Size: 15815      Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-12 09:18:14,717][train][INFO][train.py>_log] ==> #869000     Total Loss: 1.469    [weighted Loss:1.469    Policy Loss: 9.728    Value Loss: 6.186    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 325743     Buffer Size: 15954      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-12 09:25:22,841][train][INFO][train.py>_log] ==> #870000     Total Loss: 1.403    [weighted Loss:1.403    Policy Loss: 6.144    Value Loss: 5.854    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 326173     Buffer Size: 16053      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-12 09:32:29,724][train][INFO][train.py>_log] ==> #871000     Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 10.464   Value Loss: 6.315    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 326828     Buffer Size: 16363      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-12 09:39:28,518][train][INFO][train.py>_log] ==> #872000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 6.829    Value Loss: 5.912    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 327726     Buffer Size: 16918      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-12 09:46:25,820][train][INFO][train.py>_log] ==> #873000     Total Loss: 1.231    [weighted Loss:1.231    Policy Loss: 6.692    Value Loss: 6.015    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 328058     Buffer Size: 16954      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-12 09:53:27,387][train][INFO][train.py>_log] ==> #874000     Total Loss: 0.933    [weighted Loss:0.933    Policy Loss: 6.358    Value Loss: 5.661    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 328447     Buffer Size: 17007      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:00:29,429][train][INFO][train.py>_log] ==> #875000     Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 7.507    Value Loss: 6.114    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 328841     Buffer Size: 17074      Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:07:27,539][train][INFO][train.py>_log] ==> #876000     Total Loss: 1.537    [weighted Loss:1.537    Policy Loss: 7.496    Value Loss: 6.219    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 329568     Buffer Size: 17359      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:14:20,395][train][INFO][train.py>_log] ==> #877000     Total Loss: 1.321    [weighted Loss:1.321    Policy Loss: 7.121    Value Loss: 5.951    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 330257     Buffer Size: 17648      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:21:24,173][train][INFO][train.py>_log] ==> #878000     Total Loss: 1.201    [weighted Loss:1.201    Policy Loss: 6.796    Value Loss: 6.018    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 330485     Buffer Size: 17580      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:28:36,382][train][INFO][train.py>_log] ==> #879000     Total Loss: 0.902    [weighted Loss:0.902    Policy Loss: 6.637    Value Loss: 6.130    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 330748     Buffer Size: 17484      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:35:53,116][train][INFO][train.py>_log] ==> #880000     Total Loss: 1.011    [weighted Loss:1.011    Policy Loss: 8.121    Value Loss: 5.873    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 330999     Buffer Size: 17411      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:43:11,191][train][INFO][train.py>_log] ==> #881000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 6.312    Value Loss: 6.171    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 331230     Buffer Size: 17315      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:50:24,043][train][INFO][train.py>_log] ==> #882000     Total Loss: 1.570    [weighted Loss:1.570    Policy Loss: 6.178    Value Loss: 5.801    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 331771     Buffer Size: 17435      Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-12 10:57:23,438][train][INFO][train.py>_log] ==> #883000     Total Loss: 1.026    [weighted Loss:1.026    Policy Loss: 6.773    Value Loss: 6.424    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 332920     Buffer Size: 18308      Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-12 11:04:16,923][train][INFO][train.py>_log] ==> #884000     Total Loss: 0.908    [weighted Loss:0.908    Policy Loss: 7.496    Value Loss: 5.890    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 333858     Buffer Size: 18831      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 11:11:16,464][train][INFO][train.py>_log] ==> #885000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 6.314    Value Loss: 5.794    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 334096     Buffer Size: 18522      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-12 11:18:27,615][train][INFO][train.py>_log] ==> #886000     Total Loss: 0.850    [weighted Loss:0.850    Policy Loss: 6.143    Value Loss: 6.716    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 334351     Buffer Size: 18131      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-12 11:25:32,526][train][INFO][train.py>_log] ==> #887000     Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 9.074    Value Loss: 6.218    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 335452     Buffer Size: 18722      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 11:32:33,710][train][INFO][train.py>_log] ==> #888000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 8.262    Value Loss: 5.736    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 336593     Buffer Size: 19341      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-12 11:39:27,058][train][INFO][train.py>_log] ==> #889000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 7.303    Value Loss: 6.299    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 337259     Buffer Size: 19394      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-12 11:46:20,147][train][INFO][train.py>_log] ==> #890000     Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 7.787    Value Loss: 6.105    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 338613     Buffer Size: 20205      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-12 11:53:15,179][train][INFO][train.py>_log] ==> #891000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 7.814    Value Loss: 5.697    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 339101     Buffer Size: 20321      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:00:18,643][train][INFO][train.py>_log] ==> #892000     Total Loss: 3.787    [weighted Loss:3.787    Policy Loss: 7.392    Value Loss: 5.714    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 339361     Buffer Size: 20201      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:07:27,450][train][INFO][train.py>_log] ==> #893000     Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 7.755    Value Loss: 5.975    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 339734     Buffer Size: 20186      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:14:29,345][train][INFO][train.py>_log] ==> #894000     Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 6.587    Value Loss: 5.684    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 340199     Buffer Size: 20286      Transition Number: 400.056 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:21:30,646][train][INFO][train.py>_log] ==> #895000     Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 6.545    Value Loss: 6.030    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 340593     Buffer Size: 20299      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:28:31,650][train][INFO][train.py>_log] ==> #896000     Total Loss: 0.526    [weighted Loss:0.526    Policy Loss: 7.192    Value Loss: 5.697    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 340953     Buffer Size: 20318      Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:35:35,571][train][INFO][train.py>_log] ==> #897000     Total Loss: 0.700    [weighted Loss:0.700    Policy Loss: 6.620    Value Loss: 5.803    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 341220     Buffer Size: 20288      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:42:45,266][train][INFO][train.py>_log] ==> #898000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 6.636    Value Loss: 5.950    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 341471     Buffer Size: 20222      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:49:55,341][train][INFO][train.py>_log] ==> #899000     Total Loss: 1.527    [weighted Loss:1.527    Policy Loss: 6.247    Value Loss: 6.248    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 341727     Buffer Size: 20111      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-12 12:57:13,890][train][INFO][train.py>_log] ==> #900000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 5.938    Value Loss: 6.109    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 341943     Buffer Size: 19897      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-12 13:04:37,320][train][INFO][train.py>_log] ==> #901000     Total Loss: 1.105    [weighted Loss:1.105    Policy Loss: 6.615    Value Loss: 6.090    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 342167     Buffer Size: 19802      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-12 13:12:00,650][train][INFO][train.py>_log] ==> #902000     Total Loss: 0.659    [weighted Loss:0.659    Policy Loss: 5.892    Value Loss: 5.920    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 342397     Buffer Size: 19674      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-12 13:19:35,524][train][INFO][train.py>_log] ==> #903000     Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 5.702    Value Loss: 5.655    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 342661     Buffer Size: 19348      Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-12 13:26:59,532][train][INFO][train.py>_log] ==> #904000     Total Loss: 1.157    [weighted Loss:1.157    Policy Loss: 6.157    Value Loss: 6.005    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 342980     Buffer Size: 19176      Transition Number: 399.948 k Batch Size: 128        Lr: 0.100   
[2021-11-12 13:34:22,557][train][INFO][train.py>_log] ==> #905000     Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 5.435    Value Loss: 6.321    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 343285     Buffer Size: 19075      Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-12 13:41:46,578][train][INFO][train.py>_log] ==> #906000     Total Loss: 1.615    [weighted Loss:1.615    Policy Loss: 5.840    Value Loss: 6.066    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 343644     Buffer Size: 19091      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-12 13:49:08,160][train][INFO][train.py>_log] ==> #907000     Total Loss: 0.867    [weighted Loss:0.867    Policy Loss: 6.571    Value Loss: 5.795    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 344038     Buffer Size: 19173      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-12 13:56:31,470][train][INFO][train.py>_log] ==> #908000     Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 6.627    Value Loss: 6.385    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 344328     Buffer Size: 18991      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-12 14:03:59,918][train][INFO][train.py>_log] ==> #909000     Total Loss: 1.246    [weighted Loss:1.246    Policy Loss: 6.256    Value Loss: 6.451    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 344595     Buffer Size: 18872      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 14:11:30,538][train][INFO][train.py>_log] ==> #910000     Total Loss: 0.842    [weighted Loss:0.842    Policy Loss: 5.468    Value Loss: 5.997    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 344838     Buffer Size: 18663      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-12 14:19:02,776][train][INFO][train.py>_log] ==> #911000     Total Loss: 0.321    [weighted Loss:0.321    Policy Loss: 5.220    Value Loss: 6.151    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 345185     Buffer Size: 18359      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-12 14:26:28,597][train][INFO][train.py>_log] ==> #912000     Total Loss: 0.924    [weighted Loss:0.924    Policy Loss: 6.057    Value Loss: 5.864    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 345885     Buffer Size: 18187      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-12 14:33:49,705][train][INFO][train.py>_log] ==> #913000     Total Loss: 1.075    [weighted Loss:1.075    Policy Loss: 5.825    Value Loss: 5.726    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 346559     Buffer Size: 18473      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-12 14:41:05,307][train][INFO][train.py>_log] ==> #914000     Total Loss: 0.623    [weighted Loss:0.623    Policy Loss: 7.332    Value Loss: 5.749    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 347317     Buffer Size: 18771      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-12 14:48:19,979][train][INFO][train.py>_log] ==> #915000     Total Loss: 3.034    [weighted Loss:3.034    Policy Loss: 5.868    Value Loss: 5.739    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 347643     Buffer Size: 18701      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-12 14:55:41,848][train][INFO][train.py>_log] ==> #916000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 6.456    Value Loss: 5.822    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 348001     Buffer Size: 18320      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 15:03:08,081][train][INFO][train.py>_log] ==> #917000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 7.597    Value Loss: 6.079    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 348412     Buffer Size: 18109      Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-12 15:10:38,936][train][INFO][train.py>_log] ==> #918000     Total Loss: 1.381    [weighted Loss:1.381    Policy Loss: 5.815    Value Loss: 6.081    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 348735     Buffer Size: 18192      Transition Number: 400.022 k Batch Size: 128        Lr: 0.100   
[2021-11-12 15:18:03,455][train][INFO][train.py>_log] ==> #919000     Total Loss: 0.837    [weighted Loss:0.837    Policy Loss: 5.679    Value Loss: 6.241    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 349083     Buffer Size: 18276      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-12 15:25:32,761][train][INFO][train.py>_log] ==> #920000     Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 6.063    Value Loss: 5.682    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 349412     Buffer Size: 18355      Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-12 15:32:57,084][train][INFO][train.py>_log] ==> #921000     Total Loss: 1.101    [weighted Loss:1.101    Policy Loss: 4.935    Value Loss: 6.037    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 349712     Buffer Size: 18365      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-12 15:40:22,826][train][INFO][train.py>_log] ==> #922000     Total Loss: 1.461    [weighted Loss:1.461    Policy Loss: 5.474    Value Loss: 6.220    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 350422     Buffer Size: 18388      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 15:47:44,706][train][INFO][train.py>_log] ==> #923000     Total Loss: 1.522    [weighted Loss:1.522    Policy Loss: 6.087    Value Loss: 6.201    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 351255     Buffer Size: 18110      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-12 15:55:20,435][train][INFO][train.py>_log] ==> #924000     Total Loss: 1.151    [weighted Loss:1.151    Policy Loss: 5.705    Value Loss: 5.846    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 351558     Buffer Size: 17617      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:02:55,508][train][INFO][train.py>_log] ==> #925000     Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 5.106    Value Loss: 5.994    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 351844     Buffer Size: 17636      Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:10:30,335][train][INFO][train.py>_log] ==> #926000     Total Loss: 1.264    [weighted Loss:1.264    Policy Loss: 5.209    Value Loss: 5.973    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 352212     Buffer Size: 17324      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:17:53,853][train][INFO][train.py>_log] ==> #927000     Total Loss: 2.173    [weighted Loss:2.173    Policy Loss: 6.839    Value Loss: 6.733    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 353024     Buffer Size: 16950      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:25:21,461][train][INFO][train.py>_log] ==> #928000     Total Loss: 2.802    [weighted Loss:2.802    Policy Loss: 5.799    Value Loss: 6.144    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 353369     Buffer Size: 16383      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:32:55,670][train][INFO][train.py>_log] ==> #929000     Total Loss: 1.110    [weighted Loss:1.110    Policy Loss: 5.433    Value Loss: 6.089    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 353719     Buffer Size: 15794      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:40:33,648][train][INFO][train.py>_log] ==> #930000     Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 6.631    Value Loss: 6.096    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 354178     Buffer Size: 15269      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:48:14,202][train][INFO][train.py>_log] ==> #931000     Total Loss: 1.026    [weighted Loss:1.026    Policy Loss: 5.063    Value Loss: 5.966    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 354679     Buffer Size: 15385      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:55:40,349][train][INFO][train.py>_log] ==> #932000     Total Loss: 1.974    [weighted Loss:1.974    Policy Loss: 6.007    Value Loss: 6.435    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 355582     Buffer Size: 15874      Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:03:09,725][train][INFO][train.py>_log] ==> #933000     Total Loss: 0.516    [weighted Loss:0.516    Policy Loss: 7.240    Value Loss: 6.313    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 355992     Buffer Size: 15795      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:10:46,987][train][INFO][train.py>_log] ==> #934000     Total Loss: 0.851    [weighted Loss:0.851    Policy Loss: 7.210    Value Loss: 6.026    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 356292     Buffer Size: 15675      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:18:26,375][train][INFO][train.py>_log] ==> #935000     Total Loss: 1.041    [weighted Loss:1.041    Policy Loss: 6.120    Value Loss: 6.072    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 356758     Buffer Size: 15758      Transition Number: 400.010 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:25:58,596][train][INFO][train.py>_log] ==> #936000     Total Loss: 1.445    [weighted Loss:1.445    Policy Loss: 7.232    Value Loss: 6.117    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 357477     Buffer Size: 16175      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:33:25,698][train][INFO][train.py>_log] ==> #937000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 6.158    Value Loss: 6.223    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 358156     Buffer Size: 16581      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:40:44,496][train][INFO][train.py>_log] ==> #938000     Total Loss: 1.379    [weighted Loss:1.379    Policy Loss: 6.787    Value Loss: 5.833    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 358823     Buffer Size: 17001      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:48:03,763][train][INFO][train.py>_log] ==> #939000     Total Loss: 1.587    [weighted Loss:1.587    Policy Loss: 7.076    Value Loss: 6.468    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 359305     Buffer Size: 17251      Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:55:17,321][train][INFO][train.py>_log] ==> #940000     Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 6.909    Value Loss: 5.892    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 359889     Buffer Size: 17592      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-12 18:02:24,925][train][INFO][train.py>_log] ==> #941000     Total Loss: 1.633    [weighted Loss:1.633    Policy Loss: 6.782    Value Loss: 5.821    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 360342     Buffer Size: 17797      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-12 18:09:29,869][train][INFO][train.py>_log] ==> #942000     Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 7.630    Value Loss: 5.962    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 360750     Buffer Size: 17906      Transition Number: 400.011 k Batch Size: 128        Lr: 0.100   
[2021-11-12 18:16:38,516][train][INFO][train.py>_log] ==> #943000     Total Loss: 0.624    [weighted Loss:0.624    Policy Loss: 7.359    Value Loss: 5.692    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 361126     Buffer Size: 17968      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-12 18:23:47,018][train][INFO][train.py>_log] ==> #944000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 7.197    Value Loss: 6.334    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 361467     Buffer Size: 17990      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-12 18:31:02,928][train][INFO][train.py>_log] ==> #945000     Total Loss: 2.494    [weighted Loss:2.494    Policy Loss: 8.086    Value Loss: 6.511    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 361710     Buffer Size: 17906      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-12 18:38:22,444][train][INFO][train.py>_log] ==> #946000     Total Loss: 0.481    [weighted Loss:0.481    Policy Loss: 7.807    Value Loss: 6.105    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 362017     Buffer Size: 17862      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-12 18:45:43,362][train][INFO][train.py>_log] ==> #947000     Total Loss: 1.078    [weighted Loss:1.078    Policy Loss: 6.299    Value Loss: 6.061    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 362238     Buffer Size: 17805      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-12 18:53:07,852][train][INFO][train.py>_log] ==> #948000     Total Loss: 0.875    [weighted Loss:0.875    Policy Loss: 5.980    Value Loss: 6.544    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 362513     Buffer Size: 17811      Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:00:12,700][train][INFO][train.py>_log] ==> #949000     Total Loss: 1.106    [weighted Loss:1.106    Policy Loss: 5.910    Value Loss: 5.481    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 364196     Buffer Size: 19165      Transition Number: 400.039 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:06:53,011][train][INFO][train.py>_log] ==> #950000     Total Loss: 1.314    [weighted Loss:1.314    Policy Loss: 6.466    Value Loss: 6.060    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 365893     Buffer Size: 20302      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:13:32,158][train][INFO][train.py>_log] ==> #951000     Total Loss: 1.508    [weighted Loss:1.508    Policy Loss: 7.917    Value Loss: 6.092    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 366652     Buffer Size: 20402      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:20:17,769][train][INFO][train.py>_log] ==> #952000     Total Loss: 0.796    [weighted Loss:0.796    Policy Loss: 6.600    Value Loss: 6.156    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 367276     Buffer Size: 20343      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:27:02,603][train][INFO][train.py>_log] ==> #953000     Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 6.872    Value Loss: 6.227    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 367875     Buffer Size: 20398      Transition Number: 400.013 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:33:49,360][train][INFO][train.py>_log] ==> #954000     Total Loss: 1.746    [weighted Loss:1.746    Policy Loss: 6.097    Value Loss: 6.032    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 368415     Buffer Size: 20583      Transition Number: 400.009 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:40:38,114][train][INFO][train.py>_log] ==> #955000     Total Loss: 0.754    [weighted Loss:0.754    Policy Loss: 7.103    Value Loss: 6.339    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 368846     Buffer Size: 20682      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:47:31,774][train][INFO][train.py>_log] ==> #956000     Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 6.862    Value Loss: 6.110    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 369216     Buffer Size: 20689      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-12 19:54:26,347][train][INFO][train.py>_log] ==> #957000     Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 6.505    Value Loss: 5.710    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 369545     Buffer Size: 20720      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:01:19,922][train][INFO][train.py>_log] ==> #958000     Total Loss: 1.123    [weighted Loss:1.123    Policy Loss: 6.702    Value Loss: 6.372    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 369880     Buffer Size: 20744      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:08:18,310][train][INFO][train.py>_log] ==> #959000     Total Loss: 0.381    [weighted Loss:0.381    Policy Loss: 6.628    Value Loss: 5.872    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 370184     Buffer Size: 20745      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:15:16,481][train][INFO][train.py>_log] ==> #960000     Total Loss: 1.666    [weighted Loss:1.666    Policy Loss: 5.449    Value Loss: 5.758    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 370477     Buffer Size: 20747      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:22:10,428][train][INFO][train.py>_log] ==> #961000     Total Loss: 1.443    [weighted Loss:1.443    Policy Loss: 8.879    Value Loss: 5.969    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 370906     Buffer Size: 20499      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:29:09,381][train][INFO][train.py>_log] ==> #962000     Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 7.076    Value Loss: 6.276    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 371237     Buffer Size: 20054      Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:36:03,398][train][INFO][train.py>_log] ==> #963000     Total Loss: 1.692    [weighted Loss:1.692    Policy Loss: 7.293    Value Loss: 6.492    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 371827     Buffer Size: 20305      Transition Number: 400.022 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:42:44,264][train][INFO][train.py>_log] ==> #964000     Total Loss: 1.318    [weighted Loss:1.318    Policy Loss: 9.074    Value Loss: 6.636    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 372492     Buffer Size: 20676      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:49:21,731][train][INFO][train.py>_log] ==> #965000     Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 8.618    Value Loss: 6.303    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 372949     Buffer Size: 20823      Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:55:58,112][train][INFO][train.py>_log] ==> #966000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 8.897    Value Loss: 6.112    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 373284     Buffer Size: 20567      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:02:41,404][train][INFO][train.py>_log] ==> #967000     Total Loss: 0.860    [weighted Loss:0.860    Policy Loss: 8.452    Value Loss: 6.053    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 373596     Buffer Size: 20386      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:09:26,142][train][INFO][train.py>_log] ==> #968000     Total Loss: 1.636    [weighted Loss:1.636    Policy Loss: 9.649    Value Loss: 6.254    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 373916     Buffer Size: 20390      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:15:56,263][train][INFO][train.py>_log] ==> #969000     Total Loss: 1.932    [weighted Loss:1.932    Policy Loss: 9.663    Value Loss: 6.279    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 375407     Buffer Size: 21468      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:22:23,351][train][INFO][train.py>_log] ==> #970000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 8.837    Value Loss: 6.112    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 375814     Buffer Size: 21470      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:28:54,548][train][INFO][train.py>_log] ==> #971000     Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 9.039    Value Loss: 6.231    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 376136     Buffer Size: 21330      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:35:27,965][train][INFO][train.py>_log] ==> #972000     Total Loss: 3.114    [weighted Loss:3.114    Policy Loss: 8.355    Value Loss: 6.218    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 376465     Buffer Size: 20924      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:42:01,534][train][INFO][train.py>_log] ==> #973000     Total Loss: 1.568    [weighted Loss:1.568    Policy Loss: 9.284    Value Loss: 6.007    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 376769     Buffer Size: 20859      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:48:35,556][train][INFO][train.py>_log] ==> #974000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 8.644    Value Loss: 5.774    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 377074     Buffer Size: 20881      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:55:11,793][train][INFO][train.py>_log] ==> #975000     Total Loss: 1.113    [weighted Loss:1.113    Policy Loss: 8.805    Value Loss: 6.437    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 377382     Buffer Size: 20875      Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:01:55,120][train][INFO][train.py>_log] ==> #976000     Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 7.481    Value Loss: 6.166    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 377631     Buffer Size: 20668      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:08:43,058][train][INFO][train.py>_log] ==> #977000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 7.853    Value Loss: 5.894    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 377855     Buffer Size: 20342      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:16:32,149][train][INFO][train.py>_log] ==> #978000     Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 9.377    Value Loss: 5.943    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 378152     Buffer Size: 19911      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:23:54,902][train][INFO][train.py>_log] ==> #979000     Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 7.259    Value Loss: 6.331    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 378622     Buffer Size: 19697      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:31:27,911][train][INFO][train.py>_log] ==> #980000     Total Loss: 0.990    [weighted Loss:0.990    Policy Loss: 8.165    Value Loss: 6.019    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 378976     Buffer Size: 19541      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:39:02,212][train][INFO][train.py>_log] ==> #981000     Total Loss: 1.445    [weighted Loss:1.445    Policy Loss: 7.727    Value Loss: 6.035    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 379385     Buffer Size: 19357      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:46:25,480][train][INFO][train.py>_log] ==> #982000     Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 7.362    Value Loss: 6.510    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 379762     Buffer Size: 19289      Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:53:39,375][train][INFO][train.py>_log] ==> #983000     Total Loss: 0.600    [weighted Loss:0.600    Policy Loss: 6.727    Value Loss: 6.026    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 380022     Buffer Size: 19175      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:00:48,815][train][INFO][train.py>_log] ==> #984000     Total Loss: 0.916    [weighted Loss:0.916    Policy Loss: 6.830    Value Loss: 5.933    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 380327     Buffer Size: 19124      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:08:05,870][train][INFO][train.py>_log] ==> #985000     Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 6.419    Value Loss: 5.998    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 380632     Buffer Size: 19077      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:15:33,000][train][INFO][train.py>_log] ==> #986000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 6.087    Value Loss: 6.182    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 380887     Buffer Size: 19059      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:23:04,325][train][INFO][train.py>_log] ==> #987000     Total Loss: 1.156    [weighted Loss:1.156    Policy Loss: 5.157    Value Loss: 6.185    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 381135     Buffer Size: 19015      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:30:37,204][train][INFO][train.py>_log] ==> #988000     Total Loss: 0.441    [weighted Loss:0.441    Policy Loss: 5.069    Value Loss: 5.171    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 381412     Buffer Size: 19039      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:38:08,059][train][INFO][train.py>_log] ==> #989000     Total Loss: 0.253    [weighted Loss:0.253    Policy Loss: 5.527    Value Loss: 5.900    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 381770     Buffer Size: 18543      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:45:43,798][train][INFO][train.py>_log] ==> #990000     Total Loss: 1.607    [weighted Loss:1.607    Policy Loss: 5.774    Value Loss: 6.059    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 382021     Buffer Size: 17361      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:53:07,641][train][INFO][train.py>_log] ==> #991000     Total Loss: 0.715    [weighted Loss:0.715    Policy Loss: 5.981    Value Loss: 6.255    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 382384     Buffer Size: 16305      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:00:46,155][train][INFO][train.py>_log] ==> #992000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 6.581    Value Loss: 6.406    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 382777     Buffer Size: 15918      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:08:19,404][train][INFO][train.py>_log] ==> #993000     Total Loss: 1.247    [weighted Loss:1.247    Policy Loss: 6.002    Value Loss: 6.269    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 383150     Buffer Size: 15662      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:15:52,910][train][INFO][train.py>_log] ==> #994000     Total Loss: 1.333    [weighted Loss:1.333    Policy Loss: 7.214    Value Loss: 6.208    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 383404     Buffer Size: 15322      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:23:42,108][train][INFO][train.py>_log] ==> #995000     Total Loss: 1.151    [weighted Loss:1.151    Policy Loss: 7.507    Value Loss: 6.505    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 383665     Buffer Size: 15045      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:31:31,579][train][INFO][train.py>_log] ==> #996000     Total Loss: 1.112    [weighted Loss:1.112    Policy Loss: 5.840    Value Loss: 6.047    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 383919     Buffer Size: 14859      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:39:20,191][train][INFO][train.py>_log] ==> #997000     Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 5.535    Value Loss: 6.303    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 384358     Buffer Size: 14887      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:47:01,829][train][INFO][train.py>_log] ==> #998000     Total Loss: 1.162    [weighted Loss:1.162    Policy Loss: 5.468    Value Loss: 5.958    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 384811     Buffer Size: 14921      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:54:31,964][train][INFO][train.py>_log] ==> #999000     Total Loss: 0.757    [weighted Loss:0.757    Policy Loss: 6.187    Value Loss: 6.353    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 385227     Buffer Size: 15020      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:01:59,535][train][INFO][train.py>_log] ==> #1000000    Total Loss: 0.938    [weighted Loss:0.938    Policy Loss: 7.118    Value Loss: 6.441    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 385658     Buffer Size: 15097      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
