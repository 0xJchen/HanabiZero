[2021-11-06 18:46:52,119][train][INFO][train.py>_log] ==> #0          Total Loss: 44.298   [weighted Loss:44.298   Policy Loss: 14.300   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 52         Buffer Size: 52         Transition Number: 0.596   k Batch Size: 128        Lr: 0.000   
[2021-11-06 18:49:19,207][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.429    [weighted Loss:6.429    Policy Loss: 12.708   Value Loss: 4.386    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 358        Buffer Size: 358        Transition Number: 4.351   k Batch Size: 128        Lr: 0.010   
[2021-11-06 18:52:00,471][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.462    [weighted Loss:5.462    Policy Loss: 13.918   Value Loss: 3.225    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 720        Buffer Size: 720        Transition Number: 7.814   k Batch Size: 128        Lr: 0.020   
[2021-11-06 18:54:44,433][train][INFO][train.py>_log] ==> #3000       Total Loss: 7.367    [weighted Loss:7.367    Policy Loss: 13.850   Value Loss: 3.064    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 1087       Buffer Size: 1087       Transition Number: 11.269  k Batch Size: 128        Lr: 0.030   
[2021-11-06 18:57:29,135][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.294    [weighted Loss:6.294    Policy Loss: 12.948   Value Loss: 3.020    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1473       Buffer Size: 1473       Transition Number: 14.721  k Batch Size: 128        Lr: 0.040   
[2021-11-06 19:00:13,587][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.419    [weighted Loss:5.419    Policy Loss: 12.638   Value Loss: 2.809    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 1872       Buffer Size: 1872       Transition Number: 18.291  k Batch Size: 128        Lr: 0.050   
[2021-11-06 19:03:00,041][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.084    [weighted Loss:4.084    Policy Loss: 11.907   Value Loss: 2.431    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 2425       Buffer Size: 2425       Transition Number: 21.969  k Batch Size: 128        Lr: 0.060   
[2021-11-06 19:05:45,339][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.206    [weighted Loss:5.206    Policy Loss: 13.753   Value Loss: 2.771    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 2721       Buffer Size: 2721       Transition Number: 25.354  k Batch Size: 128        Lr: 0.070   
[2021-11-06 19:08:33,542][train][INFO][train.py>_log] ==> #8000       Total Loss: 6.098    [weighted Loss:6.098    Policy Loss: 13.554   Value Loss: 2.852    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 3063       Buffer Size: 3063       Transition Number: 29.031  k Batch Size: 128        Lr: 0.080   
[2021-11-06 19:11:20,807][train][INFO][train.py>_log] ==> #9000       Total Loss: 6.911    [weighted Loss:6.911    Policy Loss: 14.235   Value Loss: 2.838    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 3397       Buffer Size: 3397       Transition Number: 32.574  k Batch Size: 128        Lr: 0.090   
[2021-11-06 19:14:05,603][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.378    [weighted Loss:5.378    Policy Loss: 13.035   Value Loss: 2.832    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 3730       Buffer Size: 3730       Transition Number: 36.061  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:16:51,916][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.575    [weighted Loss:5.575    Policy Loss: 12.771   Value Loss: 2.513    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 4104       Buffer Size: 4104       Transition Number: 39.635  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:19:38,251][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.160    [weighted Loss:4.160    Policy Loss: 13.583   Value Loss: 2.572    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 4445       Buffer Size: 4445       Transition Number: 43.162  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:22:25,611][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.451    [weighted Loss:4.451    Policy Loss: 13.745   Value Loss: 2.760    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 4820       Buffer Size: 4820       Transition Number: 46.799  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:25:16,202][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.648    [weighted Loss:4.648    Policy Loss: 12.901   Value Loss: 2.649    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 5220       Buffer Size: 5220       Transition Number: 50.521  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:28:03,320][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.069    [weighted Loss:4.069    Policy Loss: 13.342   Value Loss: 2.700    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 5577       Buffer Size: 5577       Transition Number: 54.046  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:30:50,193][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.500    [weighted Loss:5.500    Policy Loss: 12.840   Value Loss: 2.881    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 6017       Buffer Size: 6017       Transition Number: 57.716  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:33:37,415][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.998    [weighted Loss:3.998    Policy Loss: 11.387   Value Loss: 2.788    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 6429       Buffer Size: 6429       Transition Number: 61.274  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:36:25,658][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.275    [weighted Loss:5.275    Policy Loss: 12.253   Value Loss: 2.483    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 6771       Buffer Size: 6771       Transition Number: 64.861  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:39:21,592][train][INFO][train.py>_log] ==> #19000      Total Loss: 6.425    [weighted Loss:6.425    Policy Loss: 12.306   Value Loss: 2.566    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 7140       Buffer Size: 7140       Transition Number: 68.522  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:42:12,224][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.226    [weighted Loss:5.226    Policy Loss: 12.637   Value Loss: 2.807    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 7499       Buffer Size: 7499       Transition Number: 72.213  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:45:01,681][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.401    [weighted Loss:3.401    Policy Loss: 12.573   Value Loss: 2.418    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 7865       Buffer Size: 7865       Transition Number: 75.652  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:47:51,449][train][INFO][train.py>_log] ==> #22000      Total Loss: 6.563    [weighted Loss:6.563    Policy Loss: 12.389   Value Loss: 2.939    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 8255       Buffer Size: 8255       Transition Number: 79.357  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:50:42,174][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.464    [weighted Loss:4.464    Policy Loss: 12.716   Value Loss: 2.574    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 8686       Buffer Size: 8686       Transition Number: 83.122  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:53:34,518][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.745    [weighted Loss:4.745    Policy Loss: 12.583   Value Loss: 2.737    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 9143       Buffer Size: 9143       Transition Number: 86.899  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:56:24,595][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.324    [weighted Loss:3.324    Policy Loss: 12.323   Value Loss: 2.811    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 9523       Buffer Size: 9523       Transition Number: 90.545  k Batch Size: 128        Lr: 0.100   
[2021-11-06 19:59:15,365][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.575    [weighted Loss:5.575    Policy Loss: 13.047   Value Loss: 2.566    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 9863       Buffer Size: 9863       Transition Number: 94.265  k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:02:08,890][train][INFO][train.py>_log] ==> #27000      Total Loss: 6.296    [weighted Loss:6.296    Policy Loss: 13.010   Value Loss: 2.559    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 10150      Buffer Size: 10150      Transition Number: 97.733  k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:04:58,724][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.612    [weighted Loss:3.612    Policy Loss: 12.951   Value Loss: 2.725    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 10441      Buffer Size: 10441      Transition Number: 101.309 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:07:51,241][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.959    [weighted Loss:4.959    Policy Loss: 12.841   Value Loss: 2.713    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 10703      Buffer Size: 10703      Transition Number: 104.796 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:10:45,046][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.664    [weighted Loss:3.664    Policy Loss: 13.270   Value Loss: 2.871    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 11005      Buffer Size: 11005      Transition Number: 108.747 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:13:37,772][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 10.863   Value Loss: 2.736    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 11314      Buffer Size: 11314      Transition Number: 112.263 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:16:29,989][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.661    [weighted Loss:4.661    Policy Loss: 12.839   Value Loss: 2.701    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 11760      Buffer Size: 11760      Transition Number: 116.029 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:19:29,041][train][INFO][train.py>_log] ==> #33000      Total Loss: 5.839    [weighted Loss:5.839    Policy Loss: 12.657   Value Loss: 2.797    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 12101      Buffer Size: 12101      Transition Number: 119.796 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:22:30,476][train][INFO][train.py>_log] ==> #34000      Total Loss: 5.415    [weighted Loss:5.415    Policy Loss: 12.870   Value Loss: 2.976    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 12428      Buffer Size: 12428      Transition Number: 123.727 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:25:33,596][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.995    [weighted Loss:3.995    Policy Loss: 12.641   Value Loss: 2.808    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 12763      Buffer Size: 12763      Transition Number: 127.628 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:28:45,105][train][INFO][train.py>_log] ==> #36000      Total Loss: 5.152    [weighted Loss:5.152    Policy Loss: 12.870   Value Loss: 3.165    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 13103      Buffer Size: 13103      Transition Number: 131.849 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:31:49,830][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.764    [weighted Loss:4.764    Policy Loss: 12.022   Value Loss: 2.912    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 13390      Buffer Size: 13390      Transition Number: 135.741 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:35:08,646][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.758    [weighted Loss:3.758    Policy Loss: 10.941   Value Loss: 2.869    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 13695      Buffer Size: 13695      Transition Number: 139.972 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:38:35,641][train][INFO][train.py>_log] ==> #39000      Total Loss: 5.210    [weighted Loss:5.210    Policy Loss: 12.388   Value Loss: 2.878    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 14058      Buffer Size: 14058      Transition Number: 144.542 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:41:35,448][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.319    [weighted Loss:4.319    Policy Loss: 13.175   Value Loss: 2.958    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 14324      Buffer Size: 14324      Transition Number: 148.356 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:44:45,866][train][INFO][train.py>_log] ==> #41000      Total Loss: 5.884    [weighted Loss:5.884    Policy Loss: 12.912   Value Loss: 3.169    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 14596      Buffer Size: 14596      Transition Number: 152.317 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:48:04,812][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 11.634   Value Loss: 2.895    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 14795      Buffer Size: 14795      Transition Number: 156.175 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:51:21,437][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.820    [weighted Loss:3.820    Policy Loss: 11.307   Value Loss: 2.880    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 14970      Buffer Size: 14970      Transition Number: 159.908 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:54:31,661][train][INFO][train.py>_log] ==> #44000      Total Loss: 4.526    [weighted Loss:4.526    Policy Loss: 11.718   Value Loss: 3.292    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 15187      Buffer Size: 15187      Transition Number: 163.813 k Batch Size: 128        Lr: 0.100   
[2021-11-06 20:57:56,480][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.339    [weighted Loss:4.339    Policy Loss: 10.740   Value Loss: 3.291    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 15371      Buffer Size: 15371      Transition Number: 167.376 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:01:33,695][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 10.175   Value Loss: 3.357    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 15512      Buffer Size: 15512      Transition Number: 171.485 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:05:27,014][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.412    [weighted Loss:3.412    Policy Loss: 9.343    Value Loss: 3.346    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 15679      Buffer Size: 15679      Transition Number: 175.443 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:09:34,554][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.543    [weighted Loss:3.543    Policy Loss: 9.738    Value Loss: 3.215    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 15888      Buffer Size: 15888      Transition Number: 180.412 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:13:38,871][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.708    [weighted Loss:3.708    Policy Loss: 9.631    Value Loss: 3.224    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 16114      Buffer Size: 16114      Transition Number: 184.701 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:17:57,436][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 8.599    Value Loss: 3.194    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 16418      Buffer Size: 16418      Transition Number: 189.787 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:22:06,475][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 9.375    Value Loss: 3.365    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 16682      Buffer Size: 16682      Transition Number: 194.220 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:26:14,618][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.167    [weighted Loss:3.167    Policy Loss: 9.093    Value Loss: 3.296    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 16988      Buffer Size: 16988      Transition Number: 198.835 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:30:32,716][train][INFO][train.py>_log] ==> #53000      Total Loss: 5.312    [weighted Loss:5.312    Policy Loss: 9.331    Value Loss: 3.183    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 17210      Buffer Size: 17210      Transition Number: 203.310 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:34:50,055][train][INFO][train.py>_log] ==> #54000      Total Loss: 5.715    [weighted Loss:5.715    Policy Loss: 8.827    Value Loss: 3.373    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 17426      Buffer Size: 17426      Transition Number: 207.795 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:39:02,688][train][INFO][train.py>_log] ==> #55000      Total Loss: 4.029    [weighted Loss:4.029    Policy Loss: 8.574    Value Loss: 3.294    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 17705      Buffer Size: 17705      Transition Number: 212.874 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:43:14,311][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 7.842    Value Loss: 3.450    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 17953      Buffer Size: 17953      Transition Number: 217.779 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:47:37,312][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.223    [weighted Loss:4.223    Policy Loss: 7.229    Value Loss: 3.717    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 18146      Buffer Size: 18146      Transition Number: 222.506 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:52:02,602][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 6.080    Value Loss: 3.311    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 18323      Buffer Size: 18323      Transition Number: 227.562 k Batch Size: 128        Lr: 0.100   
[2021-11-06 21:56:43,210][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 6.336    Value Loss: 3.502    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 18491      Buffer Size: 18491      Transition Number: 232.648 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:01:31,510][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 6.483    Value Loss: 3.579    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 18689      Buffer Size: 18689      Transition Number: 237.715 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:06:20,381][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.718    [weighted Loss:1.718    Policy Loss: 5.842    Value Loss: 3.880    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 18863      Buffer Size: 18863      Transition Number: 243.238 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:11:22,690][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.516    [weighted Loss:3.516    Policy Loss: 5.242    Value Loss: 3.595    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 19012      Buffer Size: 19012      Transition Number: 249.283 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:16:46,736][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 5.466    Value Loss: 3.654    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 19139      Buffer Size: 19139      Transition Number: 256.173 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:22:24,243][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.434    [weighted Loss:1.434    Policy Loss: 6.384    Value Loss: 3.521    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 19266      Buffer Size: 19266      Transition Number: 263.518 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:28:07,528][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 5.418    Value Loss: 3.378    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 19419      Buffer Size: 19419      Transition Number: 270.634 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:34:07,557][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 3.772    Value Loss: 3.608    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 19574      Buffer Size: 19574      Transition Number: 279.185 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:40:19,362][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.340    [weighted Loss:1.340    Policy Loss: 4.067    Value Loss: 4.115    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 19725      Buffer Size: 19725      Transition Number: 287.606 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:46:27,771][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 3.911    Value Loss: 3.876    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 19880      Buffer Size: 19880      Transition Number: 295.871 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:52:42,164][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 3.853    Value Loss: 4.102    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 20121      Buffer Size: 20121      Transition Number: 303.861 k Batch Size: 128        Lr: 0.100   
[2021-11-06 22:58:59,707][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 3.682    Value Loss: 4.083    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 20321      Buffer Size: 20321      Transition Number: 311.644 k Batch Size: 128        Lr: 0.100   
[2021-11-06 23:05:19,131][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.257    [weighted Loss:2.257    Policy Loss: 3.631    Value Loss: 3.737    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 20490      Buffer Size: 20490      Transition Number: 318.802 k Batch Size: 128        Lr: 0.100   
[2021-11-06 23:11:46,654][train][INFO][train.py>_log] ==> #72000      Total Loss: 0.821    [weighted Loss:0.821    Policy Loss: 3.476    Value Loss: 3.857    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 20681      Buffer Size: 20681      Transition Number: 326.747 k Batch Size: 128        Lr: 0.100   
[2021-11-06 23:18:27,656][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.043    [weighted Loss:1.043    Policy Loss: 2.986    Value Loss: 3.824    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 20842      Buffer Size: 20842      Transition Number: 335.691 k Batch Size: 128        Lr: 0.100   
[2021-11-06 23:25:22,169][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 3.073    Value Loss: 4.310    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 21003      Buffer Size: 21003      Transition Number: 344.477 k Batch Size: 128        Lr: 0.100   
[2021-11-06 23:32:15,477][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.563    [weighted Loss:1.563    Policy Loss: 2.245    Value Loss: 3.797    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 21150      Buffer Size: 21150      Transition Number: 352.741 k Batch Size: 128        Lr: 0.100   
[2021-11-06 23:39:12,123][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.133    [weighted Loss:1.133    Policy Loss: 2.542    Value Loss: 4.007    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 21316      Buffer Size: 21316      Transition Number: 361.608 k Batch Size: 128        Lr: 0.100   
[2021-11-06 23:46:15,313][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.011    [weighted Loss:1.011    Policy Loss: 2.786    Value Loss: 4.222    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 21463      Buffer Size: 21463      Transition Number: 370.277 k Batch Size: 128        Lr: 0.100   
[2021-11-06 23:53:21,116][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 2.971    Value Loss: 4.474    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 21627      Buffer Size: 21627      Transition Number: 378.681 k Batch Size: 128        Lr: 0.100   
[2021-11-07 00:00:35,418][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 2.712    Value Loss: 3.879    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 21774      Buffer Size: 21774      Transition Number: 388.615 k Batch Size: 128        Lr: 0.100   
[2021-11-07 00:07:51,801][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.488    [weighted Loss:1.488    Policy Loss: 3.317    Value Loss: 4.254    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 21946      Buffer Size: 21946      Transition Number: 398.307 k Batch Size: 128        Lr: 0.100   
[2021-11-07 00:15:18,481][train][INFO][train.py>_log] ==> #81000      Total Loss: 1.271    [weighted Loss:1.271    Policy Loss: 2.814    Value Loss: 4.042    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 22113      Buffer Size: 22113      Transition Number: 408.206 k Batch Size: 128        Lr: 0.100   
[2021-11-07 00:22:50,405][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 1.943    Value Loss: 3.890    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 22276      Buffer Size: 22276      Transition Number: 418.977 k Batch Size: 128        Lr: 0.100   
[2021-11-07 00:30:30,990][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.164    [weighted Loss:1.164    Policy Loss: 2.477    Value Loss: 4.296    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 22440      Buffer Size: 22440      Transition Number: 429.778 k Batch Size: 128        Lr: 0.100   
[2021-11-07 00:38:16,262][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 3.038    Value Loss: 4.094    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 22606      Buffer Size: 22606      Transition Number: 439.682 k Batch Size: 128        Lr: 0.100   
[2021-11-07 00:46:05,517][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.219    [weighted Loss:1.219    Policy Loss: 3.441    Value Loss: 4.040    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 22750      Buffer Size: 22750      Transition Number: 449.031 k Batch Size: 128        Lr: 0.100   
[2021-11-07 00:54:03,151][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.398    [weighted Loss:1.398    Policy Loss: 3.019    Value Loss: 3.839    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 22951      Buffer Size: 22951      Transition Number: 460.483 k Batch Size: 128        Lr: 0.100   
[2021-11-07 01:02:03,068][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 3.230    Value Loss: 3.858    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 23131      Buffer Size: 23131      Transition Number: 471.612 k Batch Size: 128        Lr: 0.100   
[2021-11-07 01:10:06,617][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 2.836    Value Loss: 3.918    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 23325      Buffer Size: 23325      Transition Number: 483.111 k Batch Size: 128        Lr: 0.100   
[2021-11-07 01:18:13,918][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 3.003    Value Loss: 4.079    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 23512      Buffer Size: 23512      Transition Number: 494.505 k Batch Size: 128        Lr: 0.100   
[2021-11-07 01:26:30,420][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.486    [weighted Loss:1.486    Policy Loss: 3.081    Value Loss: 3.953    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 23719      Buffer Size: 23056      Transition Number: 499.993 k Batch Size: 128        Lr: 0.100   
[2021-11-07 01:34:58,894][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 2.783    Value Loss: 4.155    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 23928      Buffer Size: 21736      Transition Number: 500.063 k Batch Size: 128        Lr: 0.100   
[2021-11-07 01:43:36,037][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 3.314    Value Loss: 4.222    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 24147      Buffer Size: 20649      Transition Number: 499.983 k Batch Size: 128        Lr: 0.100   
[2021-11-07 01:52:18,015][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 3.008    Value Loss: 4.121    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 24376      Buffer Size: 19634      Transition Number: 499.994 k Batch Size: 128        Lr: 0.100   
[2021-11-07 02:01:09,810][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 3.090    Value Loss: 3.879    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 24602      Buffer Size: 18451      Transition Number: 499.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 02:10:08,789][train][INFO][train.py>_log] ==> #95000      Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 3.387    Value Loss: 4.126    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 24815      Buffer Size: 17350      Transition Number: 499.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 02:19:11,464][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 3.744    Value Loss: 4.029    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 25069      Buffer Size: 16157      Transition Number: 500.000 k Batch Size: 128        Lr: 0.100   
[2021-11-07 02:28:20,322][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 3.941    Value Loss: 4.203    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 25335      Buffer Size: 15180      Transition Number: 499.987 k Batch Size: 128        Lr: 0.100   
[2021-11-07 02:37:36,825][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.199    [weighted Loss:1.199    Policy Loss: 3.910    Value Loss: 4.343    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 25593      Buffer Size: 14382      Transition Number: 499.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 02:47:10,643][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 2.776    Value Loss: 4.302    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 25825      Buffer Size: 13214      Transition Number: 499.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 02:56:51,909][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 3.274    Value Loss: 4.233    Reward Loss: 0.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 26065      Buffer Size: 12277      Transition Number: 499.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 03:06:46,790][train][INFO][train.py>_log] ==> #101000     Total Loss: 1.522    [weighted Loss:1.522    Policy Loss: 3.198    Value Loss: 3.955    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 26316      Buffer Size: 11471      Transition Number: 499.992 k Batch Size: 128        Lr: 0.100   
[2021-11-07 03:16:48,295][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 3.994    Value Loss: 4.340    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 26568      Buffer Size: 10989      Transition Number: 500.079 k Batch Size: 128        Lr: 0.100   
[2021-11-07 03:26:56,565][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 5.100    Value Loss: 4.172    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 26819      Buffer Size: 10480      Transition Number: 499.996 k Batch Size: 128        Lr: 0.100   
[2021-11-07 03:37:14,078][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.035    [weighted Loss:2.035    Policy Loss: 4.253    Value Loss: 4.346    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 27101      Buffer Size: 9839       Transition Number: 499.985 k Batch Size: 128        Lr: 0.100   
[2021-11-07 03:47:42,638][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 3.987    Value Loss: 4.372    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 27381      Buffer Size: 9353       Transition Number: 499.994 k Batch Size: 128        Lr: 0.100   
