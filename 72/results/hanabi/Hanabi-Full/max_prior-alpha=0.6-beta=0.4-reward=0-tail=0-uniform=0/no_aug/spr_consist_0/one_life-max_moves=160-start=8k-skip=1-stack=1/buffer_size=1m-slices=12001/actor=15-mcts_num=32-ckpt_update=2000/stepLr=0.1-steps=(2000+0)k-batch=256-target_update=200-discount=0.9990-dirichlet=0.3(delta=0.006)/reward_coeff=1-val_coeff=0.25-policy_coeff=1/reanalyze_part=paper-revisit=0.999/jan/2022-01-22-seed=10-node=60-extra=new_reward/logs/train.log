[2022-01-22 06:52:55,901][train][INFO][train.py>_log] ==> #0          Total Loss: 48.386   [weighted Loss:48.386   Policy Loss: 13.914   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 935        Buffer Size: 935        Transition Number: 10.511  k Batch Size: 256        Lr: 0.00000 
[2022-01-22 06:56:52,185][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.643    [weighted Loss:6.643    Policy Loss: 13.887   Value Loss: 3.597    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 5934       Buffer Size: 5934       Transition Number: 73.895  k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:00:48,331][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.862    [weighted Loss:5.862    Policy Loss: 13.753   Value Loss: 3.215    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 10955      Buffer Size: 10955      Transition Number: 136.797 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:04:44,786][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.398    [weighted Loss:4.398    Policy Loss: 14.095   Value Loss: 3.271    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 15880      Buffer Size: 15880      Transition Number: 199.036 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:08:39,755][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.971    [weighted Loss:4.971    Policy Loss: 13.672   Value Loss: 3.185    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 20778      Buffer Size: 20778      Transition Number: 260.887 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:12:33,653][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.602    [weighted Loss:4.602    Policy Loss: 13.172   Value Loss: 3.044    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 25975      Buffer Size: 25975      Transition Number: 322.487 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:16:29,169][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.460    [weighted Loss:4.460    Policy Loss: 12.515   Value Loss: 2.866    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 31119      Buffer Size: 31119      Transition Number: 384.379 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:20:21,188][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.729    [weighted Loss:4.729    Policy Loss: 12.133   Value Loss: 3.019    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 38332      Buffer Size: 38332      Transition Number: 448.173 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:24:18,357][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.974    [weighted Loss:5.974    Policy Loss: 12.721   Value Loss: 3.076    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 45439      Buffer Size: 45439      Transition Number: 511.063 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:28:14,441][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.182    [weighted Loss:4.182    Policy Loss: 12.288   Value Loss: 2.769    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 50529      Buffer Size: 50529      Transition Number: 573.363 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:32:11,747][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.984    [weighted Loss:4.984    Policy Loss: 12.660   Value Loss: 2.718    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 55604      Buffer Size: 55604      Transition Number: 635.206 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:36:07,149][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.535    [weighted Loss:4.535    Policy Loss: 12.262   Value Loss: 3.112    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 61075      Buffer Size: 61075      Transition Number: 698.180 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:40:04,823][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.832    [weighted Loss:4.832    Policy Loss: 12.208   Value Loss: 3.019    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 66544      Buffer Size: 66544      Transition Number: 760.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:44:01,179][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.302    [weighted Loss:5.302    Policy Loss: 11.734   Value Loss: 3.016    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 73338      Buffer Size: 73338      Transition Number: 825.749 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:47:58,902][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.025    [weighted Loss:5.025    Policy Loss: 11.765   Value Loss: 2.768    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 80082      Buffer Size: 80082      Transition Number: 888.912 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:51:56,052][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.599    [weighted Loss:3.599    Policy Loss: 12.141   Value Loss: 2.972    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 85298      Buffer Size: 85298      Transition Number: 949.464 k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:55:52,447][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.727    [weighted Loss:3.727    Policy Loss: 11.740   Value Loss: 2.908    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 90451      Buffer Size: 90451      Transition Number: 1010.937k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:59:49,506][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.299    [weighted Loss:4.299    Policy Loss: 11.645   Value Loss: 2.928    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 95534      Buffer Size: 95534      Transition Number: 1071.135k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:03:46,794][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.177    [weighted Loss:4.177    Policy Loss: 11.231   Value Loss: 3.286    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 100612     Buffer Size: 100612     Transition Number: 1131.627k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:07:46,869][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.197    [weighted Loss:3.197    Policy Loss: 10.657   Value Loss: 3.077    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 107041     Buffer Size: 107041     Transition Number: 1196.046k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:12:11,097][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.278    [weighted Loss:4.278    Policy Loss: 11.726   Value Loss: 3.243    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 114283     Buffer Size: 109014     Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:16:10,936][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.757    [weighted Loss:3.757    Policy Loss: 10.782   Value Loss: 3.259    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 118385     Buffer Size: 108680     Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:20:22,083][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.607    [weighted Loss:3.607    Policy Loss: 9.413    Value Loss: 3.516    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 122171     Buffer Size: 107719     Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:24:23,904][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.412    [weighted Loss:3.412    Policy Loss: 7.688    Value Loss: 3.597    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 124176     Buffer Size: 105551     Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:28:26,389][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 5.968    Value Loss: 3.630    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 126044     Buffer Size: 102978     Transition Number: 1200.024k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:32:25,880][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 5.244    Value Loss: 3.429    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 127085     Buffer Size: 99713      Transition Number: 1200.044k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:36:23,080][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.092    [weighted Loss:2.092    Policy Loss: 4.693    Value Loss: 3.543    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 128182     Buffer Size: 95795      Transition Number: 1200.028k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:40:21,591][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 4.716    Value Loss: 3.596    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 129115     Buffer Size: 90147      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:44:21,547][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 3.635    Value Loss: 3.655    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 130028     Buffer Size: 84606      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:48:18,735][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 3.499    Value Loss: 3.658    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 130943     Buffer Size: 80799      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:52:17,243][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 3.450    Value Loss: 3.668    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 131889     Buffer Size: 76882      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:56:20,174][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.819    [weighted Loss:1.819    Policy Loss: 3.845    Value Loss: 3.972    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 132950     Buffer Size: 72930      Transition Number: 1200.071k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:00:25,050][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 3.187    Value Loss: 4.058    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 134021     Buffer Size: 68759      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:04:34,840][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.651    [weighted Loss:1.651    Policy Loss: 3.144    Value Loss: 3.892    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 134977     Buffer Size: 64004      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:08:42,877][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.444    [weighted Loss:1.444    Policy Loss: 3.442    Value Loss: 4.160    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 135983     Buffer Size: 58695      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:12:50,565][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 2.657    Value Loss: 4.035    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 136923     Buffer Size: 53761      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:16:58,990][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.755    [weighted Loss:1.755    Policy Loss: 2.815    Value Loss: 4.137    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 137895     Buffer Size: 49403      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:20:59,287][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.776    [weighted Loss:1.776    Policy Loss: 2.896    Value Loss: 4.269    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 138790     Buffer Size: 45189      Transition Number: 1200.075k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:25:00,457][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.515    [weighted Loss:1.515    Policy Loss: 2.722    Value Loss: 4.116    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 139668     Buffer Size: 41094      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:29:00,694][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 3.222    Value Loss: 4.030    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 140572     Buffer Size: 36631      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:32:58,723][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.049    [weighted Loss:1.049    Policy Loss: 2.912    Value Loss: 4.080    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 141521     Buffer Size: 31142      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:36:59,173][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 3.100    Value Loss: 4.077    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 142387     Buffer Size: 26382      Transition Number: 1200.296k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:40:54,811][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.146    [weighted Loss:1.146    Policy Loss: 3.304    Value Loss: 4.378    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 143303     Buffer Size: 23318      Transition Number: 1200.053k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:44:49,705][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 2.853    Value Loss: 4.013    Reward Loss: 0.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 144156     Buffer Size: 20996      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:48:47,911][train][INFO][train.py>_log] ==> #44000      Total Loss: 0.861    [weighted Loss:0.861    Policy Loss: 2.767    Value Loss: 3.924    Reward Loss: 0.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 145052     Buffer Size: 19873      Transition Number: 1200.116k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:52:43,878][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 3.431    Value Loss: 4.138    Reward Loss: 0.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 145878     Buffer Size: 19178      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:56:39,630][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.330    [weighted Loss:1.330    Policy Loss: 2.983    Value Loss: 3.974    Reward Loss: 0.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 146713     Buffer Size: 18887      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:00:36,045][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 3.944    Value Loss: 4.240    Reward Loss: 0.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 147641     Buffer Size: 18701      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:04:31,066][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.114    [weighted Loss:1.114    Policy Loss: 3.789    Value Loss: 4.016    Reward Loss: 0.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 148501     Buffer Size: 18602      Transition Number: 1200.380k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:08:24,995][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 4.238    Value Loss: 3.952    Reward Loss: 0.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 149572     Buffer Size: 18763      Transition Number: 1200.238k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:12:19,558][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 4.148    Value Loss: 4.133    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 150588     Buffer Size: 18961      Transition Number: 1200.067k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:16:14,785][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 4.047    Value Loss: 3.961    Reward Loss: 0.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 151615     Buffer Size: 19034      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:20:12,015][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.257    [weighted Loss:2.257    Policy Loss: 4.161    Value Loss: 3.980    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 152645     Buffer Size: 19038      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:24:07,051][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 3.743    Value Loss: 4.233    Reward Loss: 0.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 153529     Buffer Size: 18966      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:28:02,036][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 3.746    Value Loss: 3.928    Reward Loss: 0.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 154406     Buffer Size: 18908      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:31:58,013][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 3.524    Value Loss: 4.184    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 155300     Buffer Size: 18880      Transition Number: 1200.079k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:35:55,329][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 3.810    Value Loss: 4.122    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 156195     Buffer Size: 18885      Transition Number: 1200.028k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:39:50,309][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 3.720    Value Loss: 4.575    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 157094     Buffer Size: 18948      Transition Number: 1200.120k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:43:44,358][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 3.657    Value Loss: 4.207    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 157965     Buffer Size: 18993      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:47:38,685][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 4.998    Value Loss: 4.299    Reward Loss: 0.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 158917     Buffer Size: 19030      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:51:31,988][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 3.874    Value Loss: 4.135    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 159767     Buffer Size: 19087      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:55:28,096][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.286    [weighted Loss:1.286    Policy Loss: 3.719    Value Loss: 4.244    Reward Loss: 0.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 160711     Buffer Size: 19191      Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:59:22,713][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 3.992    Value Loss: 4.513    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 161657     Buffer Size: 19288      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:03:16,447][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 3.946    Value Loss: 4.537    Reward Loss: 0.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 162546     Buffer Size: 19347      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:07:12,027][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 3.118    Value Loss: 4.435    Reward Loss: 0.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 163434     Buffer Size: 19391      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:11:05,407][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 3.805    Value Loss: 4.460    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 164276     Buffer Size: 19380      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:15:00,328][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 3.255    Value Loss: 4.342    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 165124     Buffer Size: 19364      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:18:56,916][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.614    [weighted Loss:1.614    Policy Loss: 3.300    Value Loss: 4.560    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 165952     Buffer Size: 19345      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:22:52,470][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.529    [weighted Loss:1.529    Policy Loss: 3.080    Value Loss: 4.260    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 166823     Buffer Size: 19326      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:26:48,893][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.471    [weighted Loss:1.471    Policy Loss: 3.155    Value Loss: 4.314    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 167737     Buffer Size: 19328      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:30:43,529][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 2.562    Value Loss: 4.246    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 168638     Buffer Size: 19113      Transition Number: 1200.056k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:34:35,790][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.434    [weighted Loss:1.434    Policy Loss: 2.498    Value Loss: 4.496    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 169453     Buffer Size: 18851      Transition Number: 1201.080k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:38:30,493][train][INFO][train.py>_log] ==> #72000      Total Loss: 0.849    [weighted Loss:0.849    Policy Loss: 2.921    Value Loss: 4.267    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 170264     Buffer Size: 18629      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:42:24,699][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 2.994    Value Loss: 4.468    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 171196     Buffer Size: 18455      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:46:19,454][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.192    [weighted Loss:1.192    Policy Loss: 2.760    Value Loss: 4.322    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 172087     Buffer Size: 18430      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:50:14,879][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 2.902    Value Loss: 4.416    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 172992     Buffer Size: 18369      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:54:09,984][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 2.588    Value Loss: 4.550    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 173841     Buffer Size: 18315      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:58:03,928][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.161    [weighted Loss:1.161    Policy Loss: 2.746    Value Loss: 4.069    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 174836     Buffer Size: 18372      Transition Number: 1199.941k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:02:02,284][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 2.860    Value Loss: 4.415    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 175839     Buffer Size: 18464      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:05:57,176][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 2.727    Value Loss: 4.293    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 176827     Buffer Size: 18480      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:09:51,602][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 2.746    Value Loss: 4.224    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 177742     Buffer Size: 18483      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:13:46,955][train][INFO][train.py>_log] ==> #81000      Total Loss: 1.485    [weighted Loss:1.485    Policy Loss: 2.630    Value Loss: 4.086    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 178558     Buffer Size: 18436      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:17:41,993][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 2.598    Value Loss: 4.104    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 179428     Buffer Size: 18323      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:21:37,007][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 3.132    Value Loss: 3.742    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 180374     Buffer Size: 18186      Transition Number: 1199.931k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:25:33,006][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 3.148    Value Loss: 3.871    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 181326     Buffer Size: 18102      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:29:29,049][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 3.143    Value Loss: 3.834    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 182197     Buffer Size: 18077      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:33:27,037][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 3.296    Value Loss: 3.976    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 183046     Buffer Size: 18076      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:37:21,855][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 3.224    Value Loss: 4.071    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 184041     Buffer Size: 18171      Transition Number: 1200.028k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:41:16,791][train][INFO][train.py>_log] ==> #88000      Total Loss: 0.982    [weighted Loss:0.982    Policy Loss: 3.372    Value Loss: 4.069    Reward Loss: 0.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 184957     Buffer Size: 18271      Transition Number: 1200.530k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:45:13,299][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.248    [weighted Loss:1.248    Policy Loss: 3.160    Value Loss: 4.109    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 185868     Buffer Size: 18280      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:49:08,407][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 3.143    Value Loss: 3.842    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 186712     Buffer Size: 18288      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:53:05,291][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 3.308    Value Loss: 4.078    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 187639     Buffer Size: 18272      Transition Number: 1199.952k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:57:02,548][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 3.762    Value Loss: 3.591    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 188594     Buffer Size: 18251      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:00:58,618][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 4.047    Value Loss: 3.887    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 189501     Buffer Size: 18191      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:04:57,198][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.577    [weighted Loss:1.577    Policy Loss: 3.798    Value Loss: 3.948    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 190416     Buffer Size: 18143      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:08:54,558][train][INFO][train.py>_log] ==> #95000      Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 3.431    Value Loss: 3.995    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 191292     Buffer Size: 18138      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:12:50,670][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 3.288    Value Loss: 3.800    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 192196     Buffer Size: 18115      Transition Number: 1199.937k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:16:47,547][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 3.213    Value Loss: 3.891    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 193108     Buffer Size: 17962      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:20:43,019][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.623    [weighted Loss:1.623    Policy Loss: 3.105    Value Loss: 3.833    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 193976     Buffer Size: 17826      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:24:37,157][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 2.853    Value Loss: 3.895    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 194871     Buffer Size: 17731      Transition Number: 1200.362k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:28:33,838][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.589    [weighted Loss:1.589    Policy Loss: 3.081    Value Loss: 3.693    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 195810     Buffer Size: 17654      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:32:29,401][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 3.276    Value Loss: 3.645    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 196771     Buffer Size: 17650      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:36:25,691][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.832    [weighted Loss:1.832    Policy Loss: 2.992    Value Loss: 4.166    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 197665     Buffer Size: 17656      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:40:20,544][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 3.605    Value Loss: 3.759    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 198733     Buffer Size: 17878      Transition Number: 1200.069k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:44:16,772][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 3.264    Value Loss: 3.927    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 199812     Buffer Size: 18107      Transition Number: 1200.030k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:48:12,244][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 3.163    Value Loss: 4.262    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 200682     Buffer Size: 18145      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:52:07,662][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.261    [weighted Loss:1.261    Policy Loss: 3.130    Value Loss: 4.305    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 201635     Buffer Size: 18178      Transition Number: 1199.944k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:56:04,710][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 3.054    Value Loss: 3.882    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 202537     Buffer Size: 18113      Transition Number: 1200.695k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:00:01,129][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 2.871    Value Loss: 3.925    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 203418     Buffer Size: 18047      Transition Number: 1200.099k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:04:00,034][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.351    [weighted Loss:1.351    Policy Loss: 3.061    Value Loss: 3.912    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 204375     Buffer Size: 18105      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:07:55,393][train][INFO][train.py>_log] ==> #110000     Total Loss: 0.844    [weighted Loss:0.844    Policy Loss: 3.206    Value Loss: 4.039    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 205361     Buffer Size: 18184      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:11:51,051][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 3.166    Value Loss: 4.291    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 206268     Buffer Size: 18246      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:15:49,910][train][INFO][train.py>_log] ==> #112000     Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 2.887    Value Loss: 4.186    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 207171     Buffer Size: 18303      Transition Number: 1200.312k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:19:45,268][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.425    [weighted Loss:1.425    Policy Loss: 3.102    Value Loss: 4.041    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 208094     Buffer Size: 18332      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:23:41,056][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 3.315    Value Loss: 4.080    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 209054     Buffer Size: 18349      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:27:37,004][train][INFO][train.py>_log] ==> #115000     Total Loss: 1.677    [weighted Loss:1.677    Policy Loss: 3.103    Value Loss: 4.051    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 209921     Buffer Size: 18371      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:31:34,932][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 3.159    Value Loss: 3.995    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 210826     Buffer Size: 18381      Transition Number: 1199.935k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:35:31,525][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.627    [weighted Loss:1.627    Policy Loss: 3.343    Value Loss: 4.020    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 211767     Buffer Size: 18401      Transition Number: 1200.012k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:39:27,924][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.994    [weighted Loss:1.994    Policy Loss: 3.684    Value Loss: 4.237    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 212699     Buffer Size: 18407      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:43:23,959][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 3.507    Value Loss: 3.974    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 213662     Buffer Size: 18440      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:47:20,468][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 4.089    Value Loss: 4.141    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 214576     Buffer Size: 18471      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:51:15,665][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 3.850    Value Loss: 4.126    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 215484     Buffer Size: 18525      Transition Number: 1200.171k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:55:10,050][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 3.779    Value Loss: 4.079    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 216393     Buffer Size: 18571      Transition Number: 1200.617k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:59:06,765][train][INFO][train.py>_log] ==> #123000     Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 3.964    Value Loss: 4.333    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 217285     Buffer Size: 18457      Transition Number: 1200.244k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:03:06,096][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.255    [weighted Loss:1.255    Policy Loss: 3.121    Value Loss: 4.383    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 218260     Buffer Size: 18328      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:07:03,417][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 3.023    Value Loss: 4.180    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 219188     Buffer Size: 18340      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:11:00,220][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 2.923    Value Loss: 4.090    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 220103     Buffer Size: 18336      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:14:58,029][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 3.262    Value Loss: 4.134    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 220999     Buffer Size: 18348      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:18:56,455][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 2.995    Value Loss: 4.021    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 221903     Buffer Size: 18362      Transition Number: 1200.263k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:22:53,780][train][INFO][train.py>_log] ==> #129000     Total Loss: 1.092    [weighted Loss:1.092    Policy Loss: 3.288    Value Loss: 4.113    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 222832     Buffer Size: 18281      Transition Number: 1199.931k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:26:51,406][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.549    [weighted Loss:1.549    Policy Loss: 3.585    Value Loss: 4.034    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 223703     Buffer Size: 18230      Transition Number: 1200.820k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:30:51,564][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 3.138    Value Loss: 4.193    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 224590     Buffer Size: 18186      Transition Number: 1200.140k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:34:49,363][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.602    [weighted Loss:1.602    Policy Loss: 2.964    Value Loss: 3.885    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 225542     Buffer Size: 18156      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:38:50,670][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 3.394    Value Loss: 4.207    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 226495     Buffer Size: 18156      Transition Number: 1200.020k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:42:48,773][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.626    [weighted Loss:1.626    Policy Loss: 3.319    Value Loss: 3.950    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 227443     Buffer Size: 18160      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:46:47,031][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 3.147    Value Loss: 4.051    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 228399     Buffer Size: 18182      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:50:43,308][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.245    [weighted Loss:1.245    Policy Loss: 3.080    Value Loss: 3.729    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 229363     Buffer Size: 18207      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:54:42,181][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 3.176    Value Loss: 3.900    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 230280     Buffer Size: 18223      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:58:42,885][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.511    [weighted Loss:1.511    Policy Loss: 3.086    Value Loss: 4.208    Reward Loss: 0.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 231249     Buffer Size: 18240      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:02:41,203][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.632    [weighted Loss:1.632    Policy Loss: 3.109    Value Loss: 4.125    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 232224     Buffer Size: 18232      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:06:41,458][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.696    [weighted Loss:1.696    Policy Loss: 3.593    Value Loss: 4.091    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 233175     Buffer Size: 18223      Transition Number: 1200.341k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:10:36,367][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 3.210    Value Loss: 4.087    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 234085     Buffer Size: 18198      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:14:32,674][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.231    [weighted Loss:1.231    Policy Loss: 3.857    Value Loss: 4.225    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 235001     Buffer Size: 18166      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:18:28,946][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 3.188    Value Loss: 4.319    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 235958     Buffer Size: 18148      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:22:25,961][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 3.891    Value Loss: 4.210    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 236849     Buffer Size: 18173      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:26:22,046][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 4.381    Value Loss: 4.412    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 238791     Buffer Size: 19173      Transition Number: 1200.064k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:30:21,212][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 3.998    Value Loss: 4.266    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 240616     Buffer Size: 20094      Transition Number: 1200.061k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:34:22,233][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.574    [weighted Loss:1.574    Policy Loss: 3.632    Value Loss: 4.556    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 241559     Buffer Size: 20176      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:38:19,153][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 3.942    Value Loss: 4.388    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 242546     Buffer Size: 20229      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:42:18,644][train][INFO][train.py>_log] ==> #149000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 4.096    Value Loss: 4.078    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 243493     Buffer Size: 20275      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:46:17,109][train][INFO][train.py>_log] ==> #150000     Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 3.623    Value Loss: 4.251    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 244396     Buffer Size: 20341      Transition Number: 1200.730k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:50:13,846][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 3.490    Value Loss: 4.131    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 245306     Buffer Size: 20356      Transition Number: 1200.095k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:54:15,104][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 3.318    Value Loss: 4.170    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 246269     Buffer Size: 20382      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:58:13,038][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 3.424    Value Loss: 4.252    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 247185     Buffer Size: 20407      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:02:11,575][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.381    [weighted Loss:1.381    Policy Loss: 3.150    Value Loss: 4.095    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 248109     Buffer Size: 20407      Transition Number: 1199.930k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:06:10,722][train][INFO][train.py>_log] ==> #155000     Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 3.562    Value Loss: 4.263    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 249083     Buffer Size: 20489      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:10:09,475][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 3.408    Value Loss: 4.369    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 250128     Buffer Size: 20581      Transition Number: 1199.946k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:14:07,771][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 3.430    Value Loss: 4.264    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 251085     Buffer Size: 20607      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:18:09,858][train][INFO][train.py>_log] ==> #158000     Total Loss: 1.615    [weighted Loss:1.615    Policy Loss: 3.236    Value Loss: 4.350    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 252045     Buffer Size: 20620      Transition Number: 1200.112k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:22:09,924][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.618    [weighted Loss:1.618    Policy Loss: 3.425    Value Loss: 4.358    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 253010     Buffer Size: 20624      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:26:08,879][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.616    [weighted Loss:1.616    Policy Loss: 3.610    Value Loss: 4.266    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 253956     Buffer Size: 20632      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:30:07,529][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.575    [weighted Loss:1.575    Policy Loss: 3.169    Value Loss: 4.275    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 254898     Buffer Size: 20602      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:34:04,683][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.661    [weighted Loss:1.661    Policy Loss: 3.103    Value Loss: 4.213    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 255856     Buffer Size: 20597      Transition Number: 1200.060k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:38:04,328][train][INFO][train.py>_log] ==> #163000     Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 3.132    Value Loss: 4.295    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 256785     Buffer Size: 20530      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:42:03,729][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.687    [weighted Loss:1.687    Policy Loss: 3.387    Value Loss: 4.237    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 257718     Buffer Size: 20086      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:46:02,799][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 3.251    Value Loss: 4.242    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 258683     Buffer Size: 19005      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:50:01,482][train][INFO][train.py>_log] ==> #166000     Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 3.574    Value Loss: 4.067    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 259658     Buffer Size: 18466      Transition Number: 1200.723k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:54:00,059][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 4.078    Value Loss: 4.340    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 260613     Buffer Size: 18416      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:57:59,354][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.477    [weighted Loss:1.477    Policy Loss: 2.960    Value Loss: 4.077    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 261579     Buffer Size: 18371      Transition Number: 1200.018k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:02:01,123][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.391    [weighted Loss:1.391    Policy Loss: 3.197    Value Loss: 4.189    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 262543     Buffer Size: 18338      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:06:02,921][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.997    [weighted Loss:1.997    Policy Loss: 3.693    Value Loss: 3.897    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 263514     Buffer Size: 18321      Transition Number: 1200.350k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:10:00,725][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.452    [weighted Loss:1.452    Policy Loss: 3.626    Value Loss: 3.881    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 264498     Buffer Size: 18388      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:13:59,298][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.377    [weighted Loss:1.377    Policy Loss: 3.393    Value Loss: 3.983    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 265501     Buffer Size: 18459      Transition Number: 1200.101k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:17:58,909][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 3.252    Value Loss: 4.313    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 266463     Buffer Size: 18498      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:21:57,338][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 3.353    Value Loss: 4.219    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 267441     Buffer Size: 18473      Transition Number: 1200.031k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:25:56,321][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 3.354    Value Loss: 4.250    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 268384     Buffer Size: 18374      Transition Number: 1199.944k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:29:54,986][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 3.390    Value Loss: 4.106    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 269350     Buffer Size: 18339      Transition Number: 1200.235k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:33:53,267][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.974    [weighted Loss:1.974    Policy Loss: 3.534    Value Loss: 4.234    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 270230     Buffer Size: 18343      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:37:50,760][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.825    [weighted Loss:1.825    Policy Loss: 3.303    Value Loss: 3.913    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 271139     Buffer Size: 18368      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:41:47,216][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 3.455    Value Loss: 3.956    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 272047     Buffer Size: 18383      Transition Number: 1200.070k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:45:47,949][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 3.224    Value Loss: 4.102    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 272971     Buffer Size: 18404      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:49:47,622][train][INFO][train.py>_log] ==> #181000     Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 3.019    Value Loss: 3.946    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 273936     Buffer Size: 18393      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:53:47,014][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.852    [weighted Loss:1.852    Policy Loss: 3.703    Value Loss: 4.131    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 274908     Buffer Size: 18397      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:57:48,565][train][INFO][train.py>_log] ==> #183000     Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 3.517    Value Loss: 4.246    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 275841     Buffer Size: 18417      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:01:48,054][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 3.217    Value Loss: 4.109    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 276815     Buffer Size: 18438      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:05:44,771][train][INFO][train.py>_log] ==> #185000     Total Loss: 1.265    [weighted Loss:1.265    Policy Loss: 3.376    Value Loss: 4.046    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 277789     Buffer Size: 18467      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:09:44,868][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 3.778    Value Loss: 4.189    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 278749     Buffer Size: 18495      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:13:41,554][train][INFO][train.py>_log] ==> #187000     Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 3.534    Value Loss: 4.536    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 279727     Buffer Size: 18608      Transition Number: 1200.004k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:17:38,156][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 3.354    Value Loss: 4.740    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 280738     Buffer Size: 18708      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:21:38,351][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 3.239    Value Loss: 4.299    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 281686     Buffer Size: 18743      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:25:35,269][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.565    [weighted Loss:1.565    Policy Loss: 3.525    Value Loss: 4.542    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 282626     Buffer Size: 18723      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:29:33,648][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 3.430    Value Loss: 4.299    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 283578     Buffer Size: 18660      Transition Number: 1199.952k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:33:30,266][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.372    Value Loss: 4.360    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 284474     Buffer Size: 18641      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:37:28,211][train][INFO][train.py>_log] ==> #193000     Total Loss: 0.915    [weighted Loss:0.915    Policy Loss: 3.368    Value Loss: 4.227    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 285351     Buffer Size: 18604      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:41:26,523][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 3.372    Value Loss: 4.395    Reward Loss: 0.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 286259     Buffer Size: 18566      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:45:24,401][train][INFO][train.py>_log] ==> #195000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 3.391    Value Loss: 4.206    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 287194     Buffer Size: 18555      Transition Number: 1200.010k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:49:23,839][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.552    [weighted Loss:1.552    Policy Loss: 3.375    Value Loss: 4.227    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 288165     Buffer Size: 18526      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:53:20,493][train][INFO][train.py>_log] ==> #197000     Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 3.310    Value Loss: 4.331    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 289081     Buffer Size: 18518      Transition Number: 1200.240k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:57:17,645][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 3.129    Value Loss: 4.019    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 290013     Buffer Size: 18512      Transition Number: 1199.936k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:01:12,724][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.235    [weighted Loss:1.235    Policy Loss: 3.232    Value Loss: 4.220    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 290969     Buffer Size: 18576      Transition Number: 1200.037k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:05:08,436][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 3.131    Value Loss: 4.390    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 291893     Buffer Size: 18632      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:09:05,364][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 3.926    Value Loss: 4.231    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 292843     Buffer Size: 18671      Transition Number: 1199.932k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:13:03,284][train][INFO][train.py>_log] ==> #202000     Total Loss: 0.717    [weighted Loss:0.717    Policy Loss: 3.519    Value Loss: 4.429    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 293832     Buffer Size: 18705      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:17:02,494][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 3.635    Value Loss: 4.183    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 294774     Buffer Size: 18762      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:20:58,207][train][INFO][train.py>_log] ==> #204000     Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 3.534    Value Loss: 4.554    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 295735     Buffer Size: 18804      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:24:55,165][train][INFO][train.py>_log] ==> #205000     Total Loss: 1.173    [weighted Loss:1.173    Policy Loss: 2.956    Value Loss: 4.391    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 296610     Buffer Size: 18817      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:28:53,220][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 3.195    Value Loss: 4.929    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 297550     Buffer Size: 18813      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:32:50,913][train][INFO][train.py>_log] ==> #207000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 2.943    Value Loss: 4.426    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 298478     Buffer Size: 18717      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:36:47,323][train][INFO][train.py>_log] ==> #208000     Total Loss: 0.861    [weighted Loss:0.861    Policy Loss: 3.003    Value Loss: 4.314    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 299424     Buffer Size: 18632      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:40:45,094][train][INFO][train.py>_log] ==> #209000     Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 3.191    Value Loss: 4.520    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 300293     Buffer Size: 18633      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:44:44,071][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.112    [weighted Loss:1.112    Policy Loss: 3.004    Value Loss: 4.211    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 301178     Buffer Size: 18624      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:48:41,147][train][INFO][train.py>_log] ==> #211000     Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 3.070    Value Loss: 4.252    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 302113     Buffer Size: 18610      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:52:38,614][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 3.302    Value Loss: 4.442    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 303068     Buffer Size: 18597      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:56:35,630][train][INFO][train.py>_log] ==> #213000     Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 3.560    Value Loss: 4.241    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 304008     Buffer Size: 18614      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:00:32,389][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 3.581    Value Loss: 4.390    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 304951     Buffer Size: 18659      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:04:28,116][train][INFO][train.py>_log] ==> #215000     Total Loss: 1.297    [weighted Loss:1.297    Policy Loss: 3.155    Value Loss: 4.547    Reward Loss: 0.952    Consistency Loss: 0.000    ] Replay Episodes Collected: 305890     Buffer Size: 18684      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:08:24,585][train][INFO][train.py>_log] ==> #216000     Total Loss: 1.787    [weighted Loss:1.787    Policy Loss: 3.284    Value Loss: 4.268    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 306809     Buffer Size: 18709      Transition Number: 1200.099k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:12:24,157][train][INFO][train.py>_log] ==> #217000     Total Loss: 1.144    [weighted Loss:1.144    Policy Loss: 3.460    Value Loss: 4.072    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 307717     Buffer Size: 18708      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:16:23,859][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 3.355    Value Loss: 4.468    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 308678     Buffer Size: 18696      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:20:21,338][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 3.247    Value Loss: 4.191    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 309561     Buffer Size: 18632      Transition Number: 1199.953k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:24:18,898][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 3.120    Value Loss: 4.386    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 310469     Buffer Size: 18571      Transition Number: 1200.187k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:28:16,278][train][INFO][train.py>_log] ==> #221000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.287    Value Loss: 4.122    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 311520     Buffer Size: 18633      Transition Number: 1200.094k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:32:14,880][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 3.720    Value Loss: 3.967    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 312524     Buffer Size: 18701      Transition Number: 1200.004k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:36:12,315][train][INFO][train.py>_log] ==> #223000     Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 3.665    Value Loss: 4.311    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 313681     Buffer Size: 18932      Transition Number: 1200.147k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:40:07,928][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.856    [weighted Loss:1.856    Policy Loss: 3.291    Value Loss: 4.674    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 314875     Buffer Size: 19186      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:44:04,338][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 3.876    Value Loss: 4.275    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 315836     Buffer Size: 19230      Transition Number: 1200.232k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:48:03,515][train][INFO][train.py>_log] ==> #226000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 3.387    Value Loss: 4.252    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 316776     Buffer Size: 19256      Transition Number: 1199.930k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:52:04,580][train][INFO][train.py>_log] ==> #227000     Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 3.313    Value Loss: 4.386    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 317720     Buffer Size: 19265      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:56:00,937][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 3.584    Value Loss: 4.500    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 318685     Buffer Size: 19278      Transition Number: 1200.404k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:59:59,917][train][INFO][train.py>_log] ==> #229000     Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 3.786    Value Loss: 4.725    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 319617     Buffer Size: 19344      Transition Number: 1200.073k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:03:56,570][train][INFO][train.py>_log] ==> #230000     Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 3.220    Value Loss: 4.386    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 320594     Buffer Size: 19428      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:07:53,584][train][INFO][train.py>_log] ==> #231000     Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 3.557    Value Loss: 4.612    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 321484     Buffer Size: 19454      Transition Number: 1200.490k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:11:53,705][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.693    [weighted Loss:1.693    Policy Loss: 3.171    Value Loss: 4.414    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 322450     Buffer Size: 19461      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:15:49,607][train][INFO][train.py>_log] ==> #233000     Total Loss: 1.258    [weighted Loss:1.258    Policy Loss: 3.937    Value Loss: 4.437    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 323386     Buffer Size: 19471      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:19:51,438][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.185    [weighted Loss:1.185    Policy Loss: 3.630    Value Loss: 4.640    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 324305     Buffer Size: 19455      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:23:49,623][train][INFO][train.py>_log] ==> #235000     Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 3.568    Value Loss: 4.501    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 325246     Buffer Size: 19460      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:27:46,224][train][INFO][train.py>_log] ==> #236000     Total Loss: 1.462    [weighted Loss:1.462    Policy Loss: 3.478    Value Loss: 4.271    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 326164     Buffer Size: 19479      Transition Number: 1200.076k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:31:43,200][train][INFO][train.py>_log] ==> #237000     Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 3.607    Value Loss: 4.220    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 327088     Buffer Size: 19492      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:35:40,317][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 3.886    Value Loss: 4.289    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 328021     Buffer Size: 19497      Transition Number: 1200.282k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:39:37,544][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 3.634    Value Loss: 4.694    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 328894     Buffer Size: 19512      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:43:32,651][train][INFO][train.py>_log] ==> #240000     Total Loss: 1.254    [weighted Loss:1.254    Policy Loss: 3.712    Value Loss: 4.334    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 329861     Buffer Size: 19538      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:47:28,201][train][INFO][train.py>_log] ==> #241000     Total Loss: 0.979    [weighted Loss:0.979    Policy Loss: 3.356    Value Loss: 4.139    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 330839     Buffer Size: 19495      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:51:24,935][train][INFO][train.py>_log] ==> #242000     Total Loss: 1.276    [weighted Loss:1.276    Policy Loss: 3.598    Value Loss: 4.394    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 331741     Buffer Size: 19447      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:55:22,608][train][INFO][train.py>_log] ==> #243000     Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 3.354    Value Loss: 4.357    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 332662     Buffer Size: 19238      Transition Number: 1200.030k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:59:20,176][train][INFO][train.py>_log] ==> #244000     Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 3.456    Value Loss: 4.120    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 333596     Buffer Size: 18962      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:03:18,792][train][INFO][train.py>_log] ==> #245000     Total Loss: 1.715    [weighted Loss:1.715    Policy Loss: 3.847    Value Loss: 4.158    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 334515     Buffer Size: 18853      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:07:15,630][train][INFO][train.py>_log] ==> #246000     Total Loss: 1.744    [weighted Loss:1.744    Policy Loss: 3.667    Value Loss: 4.030    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 335432     Buffer Size: 18844      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:11:14,146][train][INFO][train.py>_log] ==> #247000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 4.115    Value Loss: 4.432    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 336485     Buffer Size: 18971      Transition Number: 1200.128k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:15:11,082][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.452    [weighted Loss:1.452    Policy Loss: 4.025    Value Loss: 4.475    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 337542     Buffer Size: 19113      Transition Number: 1200.065k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:19:07,332][train][INFO][train.py>_log] ==> #249000     Total Loss: 1.515    [weighted Loss:1.515    Policy Loss: 3.932    Value Loss: 4.666    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 338548     Buffer Size: 19203      Transition Number: 1200.275k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:23:04,326][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 4.005    Value Loss: 4.632    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 339584     Buffer Size: 19283      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:27:00,291][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 3.777    Value Loss: 4.674    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 340511     Buffer Size: 19332      Transition Number: 1200.215k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:30:56,566][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.124    [weighted Loss:1.124    Policy Loss: 3.362    Value Loss: 4.943    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 341489     Buffer Size: 19384      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:34:55,377][train][INFO][train.py>_log] ==> #253000     Total Loss: 1.338    [weighted Loss:1.338    Policy Loss: 3.730    Value Loss: 4.417    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 342429     Buffer Size: 19405      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:38:55,465][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.525    [weighted Loss:1.525    Policy Loss: 3.219    Value Loss: 4.187    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 343382     Buffer Size: 19423      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:42:55,358][train][INFO][train.py>_log] ==> #255000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 3.476    Value Loss: 4.349    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 344345     Buffer Size: 19431      Transition Number: 1199.950k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:46:51,875][train][INFO][train.py>_log] ==> #256000     Total Loss: 1.429    [weighted Loss:1.429    Policy Loss: 3.581    Value Loss: 4.804    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 345300     Buffer Size: 19434      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:50:48,194][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 3.804    Value Loss: 4.682    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 346293     Buffer Size: 19511      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:54:45,266][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.528    [weighted Loss:1.528    Policy Loss: 3.264    Value Loss: 4.465    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 347246     Buffer Size: 19591      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:58:41,466][train][INFO][train.py>_log] ==> #259000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 3.465    Value Loss: 4.705    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 348189     Buffer Size: 19647      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:02:37,031][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.669    [weighted Loss:1.669    Policy Loss: 3.688    Value Loss: 4.432    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 349115     Buffer Size: 19693      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:06:35,061][train][INFO][train.py>_log] ==> #261000     Total Loss: 1.232    [weighted Loss:1.232    Policy Loss: 3.590    Value Loss: 4.796    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 350053     Buffer Size: 19701      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:10:30,798][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 3.657    Value Loss: 4.754    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 350902     Buffer Size: 19713      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:14:27,779][train][INFO][train.py>_log] ==> #263000     Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 4.053    Value Loss: 4.849    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 351824     Buffer Size: 19712      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:18:24,113][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.173    [weighted Loss:1.173    Policy Loss: 3.670    Value Loss: 4.799    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 352770     Buffer Size: 19723      Transition Number: 1200.479k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:22:22,066][train][INFO][train.py>_log] ==> #265000     Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 3.567    Value Loss: 4.860    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 353808     Buffer Size: 19801      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:26:19,473][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 3.472    Value Loss: 4.833    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 354797     Buffer Size: 19909      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:30:15,833][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 3.799    Value Loss: 4.887    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 355741     Buffer Size: 19911      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:34:11,953][train][INFO][train.py>_log] ==> #268000     Total Loss: 1.856    [weighted Loss:1.856    Policy Loss: 3.629    Value Loss: 4.585    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 356636     Buffer Size: 19828      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:38:09,813][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 3.465    Value Loss: 4.386    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 357578     Buffer Size: 19720      Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:42:06,915][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.335    [weighted Loss:2.335    Policy Loss: 3.613    Value Loss: 4.498    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 358541     Buffer Size: 19611      Transition Number: 1199.952k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:46:03,645][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 3.527    Value Loss: 4.190    Reward Loss: 0.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 359475     Buffer Size: 19481      Transition Number: 1200.332k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:50:00,858][train][INFO][train.py>_log] ==> #272000     Total Loss: 1.477    [weighted Loss:1.477    Policy Loss: 3.477    Value Loss: 4.521    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 360355     Buffer Size: 19421      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:53:56,778][train][INFO][train.py>_log] ==> #273000     Total Loss: 1.753    [weighted Loss:1.753    Policy Loss: 4.466    Value Loss: 4.562    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 361381     Buffer Size: 19467      Transition Number: 1200.201k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:57:52,558][train][INFO][train.py>_log] ==> #274000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 4.326    Value Loss: 4.448    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 362337     Buffer Size: 19547      Transition Number: 1199.953k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:01:48,803][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.228    [weighted Loss:2.228    Policy Loss: 4.190    Value Loss: 4.442    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 363301     Buffer Size: 19582      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:05:45,134][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 4.183    Value Loss: 4.367    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 364277     Buffer Size: 19620      Transition Number: 1200.041k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:09:43,064][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 3.721    Value Loss: 4.479    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 365149     Buffer Size: 19654      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:13:40,449][train][INFO][train.py>_log] ==> #278000     Total Loss: 1.428    [weighted Loss:1.428    Policy Loss: 3.869    Value Loss: 4.493    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 366106     Buffer Size: 19613      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:17:37,080][train][INFO][train.py>_log] ==> #279000     Total Loss: 1.475    [weighted Loss:1.475    Policy Loss: 3.848    Value Loss: 4.537    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 366995     Buffer Size: 19565      Transition Number: 1200.091k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:21:35,802][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 3.684    Value Loss: 4.617    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 367914     Buffer Size: 19523      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:25:33,020][train][INFO][train.py>_log] ==> #281000     Total Loss: 1.854    [weighted Loss:1.854    Policy Loss: 3.957    Value Loss: 4.688    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 368879     Buffer Size: 19493      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:29:31,981][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 3.929    Value Loss: 4.890    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 369813     Buffer Size: 19468      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:33:29,027][train][INFO][train.py>_log] ==> #283000     Total Loss: 1.943    [weighted Loss:1.943    Policy Loss: 4.490    Value Loss: 4.571    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 370820     Buffer Size: 19510      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:37:24,529][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 4.321    Value Loss: 4.419    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 371792     Buffer Size: 19577      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:41:18,107][train][INFO][train.py>_log] ==> #285000     Total Loss: 1.913    [weighted Loss:1.913    Policy Loss: 4.287    Value Loss: 4.644    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 372917     Buffer Size: 19827      Transition Number: 1200.018k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:45:13,469][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 4.173    Value Loss: 5.138    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 374066     Buffer Size: 20004      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:49:10,896][train][INFO][train.py>_log] ==> #287000     Total Loss: 1.263    [weighted Loss:1.263    Policy Loss: 4.142    Value Loss: 4.548    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 375017     Buffer Size: 19974      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:53:07,969][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.304    [weighted Loss:1.304    Policy Loss: 3.513    Value Loss: 4.722    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 376010     Buffer Size: 19986      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:57:06,683][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.922    [weighted Loss:1.922    Policy Loss: 3.991    Value Loss: 5.157    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 376975     Buffer Size: 19950      Transition Number: 1200.132k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:01:09,018][train][INFO][train.py>_log] ==> #290000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 4.621    Value Loss: 4.781    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 377937     Buffer Size: 19927      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:05:06,169][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 4.607    Value Loss: 4.580    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 378927     Buffer Size: 19985      Transition Number: 1200.086k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:09:04,058][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.354    [weighted Loss:1.354    Policy Loss: 3.884    Value Loss: 5.052    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 379939     Buffer Size: 20065      Transition Number: 1200.174k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:12:59,453][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 3.824    Value Loss: 4.499    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 380989     Buffer Size: 20171      Transition Number: 1200.096k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:16:55,794][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.990    [weighted Loss:1.990    Policy Loss: 4.376    Value Loss: 4.786    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 381998     Buffer Size: 20239      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:20:53,224][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 3.868    Value Loss: 4.817    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 383016     Buffer Size: 20318      Transition Number: 1200.125k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:24:50,302][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 3.475    Value Loss: 5.061    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 384058     Buffer Size: 20462      Transition Number: 1200.059k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:28:46,438][train][INFO][train.py>_log] ==> #297000     Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 3.684    Value Loss: 5.214    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 385042     Buffer Size: 20470      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:32:42,612][train][INFO][train.py>_log] ==> #298000     Total Loss: 1.881    [weighted Loss:1.881    Policy Loss: 3.656    Value Loss: 4.857    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 386025     Buffer Size: 20474      Transition Number: 1200.214k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:36:39,140][train][INFO][train.py>_log] ==> #299000     Total Loss: 1.861    [weighted Loss:1.861    Policy Loss: 3.799    Value Loss: 4.608    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 386936     Buffer Size: 20513      Transition Number: 1200.226k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:40:35,895][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 4.118    Value Loss: 4.774    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 387887     Buffer Size: 20558      Transition Number: 1200.121k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:44:31,746][train][INFO][train.py>_log] ==> #301000     Total Loss: 1.807    [weighted Loss:1.807    Policy Loss: 3.768    Value Loss: 5.164    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 388869     Buffer Size: 20605      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:48:29,619][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 3.551    Value Loss: 4.949    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 389778     Buffer Size: 20663      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:52:26,869][train][INFO][train.py>_log] ==> #303000     Total Loss: 1.215    [weighted Loss:1.215    Policy Loss: 3.821    Value Loss: 4.887    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 390747     Buffer Size: 20684      Transition Number: 1200.177k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:56:24,705][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 3.842    Value Loss: 4.634    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 391660     Buffer Size: 20635      Transition Number: 1200.061k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:00:24,101][train][INFO][train.py>_log] ==> #305000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 3.496    Value Loss: 4.841    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 392613     Buffer Size: 20544      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:04:20,271][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 3.590    Value Loss: 4.905    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 393515     Buffer Size: 20317      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:08:18,760][train][INFO][train.py>_log] ==> #307000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 4.279    Value Loss: 4.807    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 394349     Buffer Size: 20132      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:12:13,828][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 4.083    Value Loss: 4.824    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 395274     Buffer Size: 20134      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:16:10,532][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 4.954    Value Loss: 4.915    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 396345     Buffer Size: 20224      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:20:06,415][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 4.125    Value Loss: 4.934    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 397453     Buffer Size: 20373      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:24:03,811][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.549    [weighted Loss:2.549    Policy Loss: 3.868    Value Loss: 5.008    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 398443     Buffer Size: 20421      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:28:00,851][train][INFO][train.py>_log] ==> #312000     Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 3.546    Value Loss: 4.954    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 399416     Buffer Size: 20387      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:31:58,351][train][INFO][train.py>_log] ==> #313000     Total Loss: 1.297    [weighted Loss:1.297    Policy Loss: 4.085    Value Loss: 4.771    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 400199     Buffer Size: 20328      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:35:55,605][train][INFO][train.py>_log] ==> #314000     Total Loss: 1.950    [weighted Loss:1.950    Policy Loss: 3.836    Value Loss: 4.642    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 401115     Buffer Size: 20198      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:39:53,055][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 3.851    Value Loss: 4.609    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 402077     Buffer Size: 20052      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:43:49,592][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 4.037    Value Loss: 4.682    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 403022     Buffer Size: 19923      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:47:50,771][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 3.981    Value Loss: 4.666    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 403966     Buffer Size: 19763      Transition Number: 1200.266k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:51:52,571][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.042    [weighted Loss:1.042    Policy Loss: 4.723    Value Loss: 4.511    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 404887     Buffer Size: 19719      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:55:49,620][train][INFO][train.py>_log] ==> #319000     Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 4.266    Value Loss: 4.915    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 405974     Buffer Size: 19803      Transition Number: 1199.941k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:59:48,976][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.887    [weighted Loss:1.887    Policy Loss: 4.191    Value Loss: 4.778    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 407079     Buffer Size: 19901      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:03:45,256][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.478    [weighted Loss:2.478    Policy Loss: 4.441    Value Loss: 4.809    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 408134     Buffer Size: 20000      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:07:42,627][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.615    [weighted Loss:1.615    Policy Loss: 3.795    Value Loss: 4.989    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 409219     Buffer Size: 20071      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:11:41,089][train][INFO][train.py>_log] ==> #323000     Total Loss: 1.049    [weighted Loss:1.049    Policy Loss: 3.490    Value Loss: 5.182    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 410145     Buffer Size: 20052      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:15:38,054][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 3.947    Value Loss: 4.901    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 411062     Buffer Size: 20073      Transition Number: 1200.032k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:19:35,755][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 3.553    Value Loss: 4.573    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 411973     Buffer Size: 20089      Transition Number: 1200.047k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:23:35,067][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 4.084    Value Loss: 4.504    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 412918     Buffer Size: 20101      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:27:35,052][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 4.428    Value Loss: 4.590    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 413863     Buffer Size: 20110      Transition Number: 1199.937k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:31:33,079][train][INFO][train.py>_log] ==> #328000     Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 4.678    Value Loss: 4.972    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 414779     Buffer Size: 20114      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:35:31,434][train][INFO][train.py>_log] ==> #329000     Total Loss: 1.010    [weighted Loss:1.010    Policy Loss: 3.942    Value Loss: 4.781    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 415710     Buffer Size: 20097      Transition Number: 1199.952k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:39:28,117][train][INFO][train.py>_log] ==> #330000     Total Loss: 1.826    [weighted Loss:1.826    Policy Loss: 4.284    Value Loss: 4.588    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 416629     Buffer Size: 19970      Transition Number: 1200.127k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:43:26,608][train][INFO][train.py>_log] ==> #331000     Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 4.068    Value Loss: 4.673    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 417520     Buffer Size: 19875      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:47:24,694][train][INFO][train.py>_log] ==> #332000     Total Loss: 1.485    [weighted Loss:1.485    Policy Loss: 4.112    Value Loss: 4.797    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 418474     Buffer Size: 19868      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:51:21,538][train][INFO][train.py>_log] ==> #333000     Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 4.122    Value Loss: 4.922    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 419591     Buffer Size: 20069      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:55:18,651][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 4.377    Value Loss: 5.068    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 420703     Buffer Size: 20288      Transition Number: 1200.081k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:59:15,009][train][INFO][train.py>_log] ==> #335000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 4.619    Value Loss: 4.978    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 421707     Buffer Size: 20382      Transition Number: 1200.018k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:03:14,717][train][INFO][train.py>_log] ==> #336000     Total Loss: 0.856    [weighted Loss:0.856    Policy Loss: 4.281    Value Loss: 5.188    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 422667     Buffer Size: 20443      Transition Number: 1200.134k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:07:12,303][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 3.889    Value Loss: 4.558    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 423558     Buffer Size: 20459      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:11:10,871][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 4.042    Value Loss: 4.812    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 424523     Buffer Size: 20496      Transition Number: 1199.937k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:15:06,486][train][INFO][train.py>_log] ==> #339000     Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 4.392    Value Loss: 5.143    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 425663     Buffer Size: 20760      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:19:02,765][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 3.869    Value Loss: 4.922    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 426826     Buffer Size: 20943      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:23:01,922][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 4.318    Value Loss: 4.868    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 427747     Buffer Size: 20881      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:27:00,757][train][INFO][train.py>_log] ==> #342000     Total Loss: 1.485    [weighted Loss:1.485    Policy Loss: 4.627    Value Loss: 4.813    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 428719     Buffer Size: 20785      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:30:59,158][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 4.962    Value Loss: 4.727    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 429731     Buffer Size: 20767      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:34:55,077][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 4.866    Value Loss: 5.076    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 430708     Buffer Size: 20821      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:38:50,532][train][INFO][train.py>_log] ==> #345000     Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 4.878    Value Loss: 4.891    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 431738     Buffer Size: 20913      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:42:45,803][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 4.257    Value Loss: 5.021    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 432756     Buffer Size: 21025      Transition Number: 1200.180k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:46:46,105][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.660    [weighted Loss:2.660    Policy Loss: 4.967    Value Loss: 5.043    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 433685     Buffer Size: 21028      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:50:44,039][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 4.796    Value Loss: 4.669    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 434576     Buffer Size: 21027      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:54:42,708][train][INFO][train.py>_log] ==> #349000     Total Loss: 2.356    [weighted Loss:2.356    Policy Loss: 5.158    Value Loss: 5.333    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 435584     Buffer Size: 21076      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:58:39,518][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 5.377    Value Loss: 4.971    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 436568     Buffer Size: 21136      Transition Number: 1200.232k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:02:36,368][train][INFO][train.py>_log] ==> #351000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 4.383    Value Loss: 5.007    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 437556     Buffer Size: 21216      Transition Number: 1200.144k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:06:32,128][train][INFO][train.py>_log] ==> #352000     Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 4.126    Value Loss: 5.094    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 438554     Buffer Size: 21304      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:10:32,211][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 4.123    Value Loss: 5.029    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 439508     Buffer Size: 21335      Transition Number: 1200.024k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:14:29,906][train][INFO][train.py>_log] ==> #354000     Total Loss: 0.945    [weighted Loss:0.945    Policy Loss: 4.097    Value Loss: 4.991    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 440471     Buffer Size: 21228      Transition Number: 1200.112k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:18:30,772][train][INFO][train.py>_log] ==> #355000     Total Loss: 1.433    [weighted Loss:1.433    Policy Loss: 3.967    Value Loss: 4.839    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 441433     Buffer Size: 21029      Transition Number: 1200.243k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:22:29,617][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.941    [weighted Loss:1.941    Policy Loss: 4.544    Value Loss: 4.883    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 442384     Buffer Size: 20927      Transition Number: 1200.382k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:26:27,105][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 5.184    Value Loss: 4.629    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 443364     Buffer Size: 20927      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:30:25,467][train][INFO][train.py>_log] ==> #358000     Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 4.308    Value Loss: 4.568    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 444386     Buffer Size: 20963      Transition Number: 1200.004k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:34:24,144][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 5.001    Value Loss: 5.111    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 445368     Buffer Size: 20983      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:38:26,933][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.269    [weighted Loss:1.269    Policy Loss: 4.968    Value Loss: 5.311    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 446372     Buffer Size: 20797      Transition Number: 1200.102k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:42:25,324][train][INFO][train.py>_log] ==> #361000     Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 4.569    Value Loss: 5.056    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 447368     Buffer Size: 20574      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:46:23,391][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 4.442    Value Loss: 5.122    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 448364     Buffer Size: 20559      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:50:21,022][train][INFO][train.py>_log] ==> #363000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 4.348    Value Loss: 5.102    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 449268     Buffer Size: 20560      Transition Number: 1200.186k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:54:20,431][train][INFO][train.py>_log] ==> #364000     Total Loss: 0.688    [weighted Loss:0.688    Policy Loss: 4.618    Value Loss: 5.254    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 450213     Buffer Size: 20515      Transition Number: 1200.417k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:58:19,004][train][INFO][train.py>_log] ==> #365000     Total Loss: 2.010    [weighted Loss:2.010    Policy Loss: 4.992    Value Loss: 4.831    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 451253     Buffer Size: 20506      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:02:16,218][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 4.362    Value Loss: 5.022    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 452292     Buffer Size: 20484      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:06:11,998][train][INFO][train.py>_log] ==> #367000     Total Loss: 1.049    [weighted Loss:1.049    Policy Loss: 4.125    Value Loss: 5.271    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 453272     Buffer Size: 20420      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:10:08,466][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 4.708    Value Loss: 5.118    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 454219     Buffer Size: 20470      Transition Number: 1200.390k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:14:06,192][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 4.654    Value Loss: 5.004    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 455151     Buffer Size: 20463      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:18:07,220][train][INFO][train.py>_log] ==> #370000     Total Loss: 0.657    [weighted Loss:0.657    Policy Loss: 4.780    Value Loss: 4.977    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 456059     Buffer Size: 20400      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:22:03,148][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 5.281    Value Loss: 5.225    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 457459     Buffer Size: 20761      Transition Number: 1200.092k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:26:00,914][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.185    [weighted Loss:2.185    Policy Loss: 6.067    Value Loss: 5.130    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 458795     Buffer Size: 21108      Transition Number: 1200.039k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:29:57,579][train][INFO][train.py>_log] ==> #373000     Total Loss: 1.110    [weighted Loss:1.110    Policy Loss: 4.700    Value Loss: 4.877    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 459784     Buffer Size: 21108      Transition Number: 1200.214k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:33:53,998][train][INFO][train.py>_log] ==> #374000     Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 4.097    Value Loss: 5.280    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 460715     Buffer Size: 21131      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:37:51,134][train][INFO][train.py>_log] ==> #375000     Total Loss: 0.935    [weighted Loss:0.935    Policy Loss: 4.021    Value Loss: 5.211    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 461640     Buffer Size: 21129      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:41:46,351][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.932    [weighted Loss:1.932    Policy Loss: 4.348    Value Loss: 5.164    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 462584     Buffer Size: 21153      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:45:44,311][train][INFO][train.py>_log] ==> #377000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 3.903    Value Loss: 4.794    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 463521     Buffer Size: 21132      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:49:44,013][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 4.968    Value Loss: 4.890    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 464464     Buffer Size: 21056      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:53:41,234][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 4.452    Value Loss: 4.833    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 465403     Buffer Size: 21008      Transition Number: 1200.083k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:57:39,690][train][INFO][train.py>_log] ==> #380000     Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 4.974    Value Loss: 4.956    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 466362     Buffer Size: 20963      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:01:34,853][train][INFO][train.py>_log] ==> #381000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 4.426    Value Loss: 5.063    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 467324     Buffer Size: 20939      Transition Number: 1200.051k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:05:32,477][train][INFO][train.py>_log] ==> #382000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 4.743    Value Loss: 4.794    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 468215     Buffer Size: 20934      Transition Number: 1199.953k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:09:31,606][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 4.970    Value Loss: 4.926    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 469128     Buffer Size: 20919      Transition Number: 1200.142k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:13:28,720][train][INFO][train.py>_log] ==> #384000     Total Loss: 0.976    [weighted Loss:0.976    Policy Loss: 3.978    Value Loss: 5.171    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 470075     Buffer Size: 20918      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:17:27,533][train][INFO][train.py>_log] ==> #385000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 4.776    Value Loss: 4.963    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 471271     Buffer Size: 21118      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:21:22,539][train][INFO][train.py>_log] ==> #386000     Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 4.661    Value Loss: 5.419    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 472430     Buffer Size: 21268      Transition Number: 1199.946k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:25:19,480][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 4.650    Value Loss: 5.271    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 473481     Buffer Size: 21300      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:29:19,450][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 5.092    Value Loss: 5.209    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 474477     Buffer Size: 21361      Transition Number: 1200.116k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:33:16,243][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.487    [weighted Loss:2.487    Policy Loss: 5.067    Value Loss: 5.054    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 475466     Buffer Size: 21343      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:37:16,500][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.162    [weighted Loss:2.162    Policy Loss: 5.322    Value Loss: 5.166    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 476388     Buffer Size: 21361      Transition Number: 1200.125k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:41:12,698][train][INFO][train.py>_log] ==> #391000     Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 4.864    Value Loss: 5.127    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 477323     Buffer Size: 21378      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:45:10,555][train][INFO][train.py>_log] ==> #392000     Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 4.521    Value Loss: 5.007    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 478247     Buffer Size: 21088      Transition Number: 1199.937k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:49:08,719][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.372    [weighted Loss:2.372    Policy Loss: 4.906    Value Loss: 4.888    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 479181     Buffer Size: 20628      Transition Number: 1200.092k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:53:09,628][train][INFO][train.py>_log] ==> #394000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 4.520    Value Loss: 5.148    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 480137     Buffer Size: 20487      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-23 08:57:07,366][train][INFO][train.py>_log] ==> #395000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 4.955    Value Loss: 4.690    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 481056     Buffer Size: 20433      Transition Number: 1200.062k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:01:05,448][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 5.055    Value Loss: 4.736    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 482009     Buffer Size: 20408      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:05:04,322][train][INFO][train.py>_log] ==> #397000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 5.103    Value Loss: 4.998    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 482950     Buffer Size: 20434      Transition Number: 1200.356k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:09:00,922][train][INFO][train.py>_log] ==> #398000     Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 4.974    Value Loss: 4.941    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 483868     Buffer Size: 20479      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:12:57,691][train][INFO][train.py>_log] ==> #399000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 5.150    Value Loss: 4.933    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 484929     Buffer Size: 20599      Transition Number: 1200.118k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:16:55,390][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 4.772    Value Loss: 5.084    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 485981     Buffer Size: 20689      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:20:53,153][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 4.625    Value Loss: 4.903    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 486952     Buffer Size: 20752      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:24:48,634][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 5.035    Value Loss: 5.199    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 487917     Buffer Size: 20785      Transition Number: 1200.043k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:28:47,043][train][INFO][train.py>_log] ==> #403000     Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 4.706    Value Loss: 5.016    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 488848     Buffer Size: 20775      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:32:43,255][train][INFO][train.py>_log] ==> #404000     Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 4.392    Value Loss: 4.953    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 489815     Buffer Size: 20750      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:36:40,964][train][INFO][train.py>_log] ==> #405000     Total Loss: 1.963    [weighted Loss:1.963    Policy Loss: 4.575    Value Loss: 4.991    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 490763     Buffer Size: 20747      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:40:39,430][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 4.082    Value Loss: 5.193    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 491631     Buffer Size: 20610      Transition Number: 1200.039k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:44:35,640][train][INFO][train.py>_log] ==> #407000     Total Loss: 1.251    [weighted Loss:1.251    Policy Loss: 4.993    Value Loss: 4.770    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 492611     Buffer Size: 20364      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:48:33,629][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.711    [weighted Loss:1.711    Policy Loss: 4.477    Value Loss: 4.959    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 493543     Buffer Size: 20229      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:52:33,382][train][INFO][train.py>_log] ==> #409000     Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 4.593    Value Loss: 5.595    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 494736     Buffer Size: 20359      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-23 09:56:30,013][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 5.931    Value Loss: 4.811    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 495924     Buffer Size: 20614      Transition Number: 1200.288k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:00:29,419][train][INFO][train.py>_log] ==> #411000     Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 4.927    Value Loss: 4.993    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 496934     Buffer Size: 20692      Transition Number: 1200.072k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:04:27,998][train][INFO][train.py>_log] ==> #412000     Total Loss: 1.326    [weighted Loss:1.326    Policy Loss: 5.327    Value Loss: 5.191    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 497964     Buffer Size: 20756      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:08:28,044][train][INFO][train.py>_log] ==> #413000     Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 4.869    Value Loss: 4.726    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 498923     Buffer Size: 20777      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:12:29,166][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 4.894    Value Loss: 5.424    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 499854     Buffer Size: 20805      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:16:28,571][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 5.419    Value Loss: 4.628    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 500828     Buffer Size: 20816      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:20:27,169][train][INFO][train.py>_log] ==> #416000     Total Loss: 2.239    [weighted Loss:2.239    Policy Loss: 5.587    Value Loss: 5.007    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 501788     Buffer Size: 20839      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:24:24,481][train][INFO][train.py>_log] ==> #417000     Total Loss: 1.851    [weighted Loss:1.851    Policy Loss: 5.463    Value Loss: 5.295    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 502961     Buffer Size: 21053      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:28:21,697][train][INFO][train.py>_log] ==> #418000     Total Loss: 3.048    [weighted Loss:3.048    Policy Loss: 5.959    Value Loss: 4.802    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 504069     Buffer Size: 21203      Transition Number: 1199.946k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:32:22,199][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 5.833    Value Loss: 5.016    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 505055     Buffer Size: 21215      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:36:20,639][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 5.282    Value Loss: 4.929    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 506052     Buffer Size: 21173      Transition Number: 1200.039k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:40:20,514][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 6.046    Value Loss: 4.845    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 507086     Buffer Size: 21176      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:44:17,858][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 5.463    Value Loss: 5.012    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 508107     Buffer Size: 21227      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:48:15,714][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 5.254    Value Loss: 4.972    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 509009     Buffer Size: 21187      Transition Number: 1199.946k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:52:16,412][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 6.203    Value Loss: 4.910    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 509879     Buffer Size: 21184      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-23 10:56:14,105][train][INFO][train.py>_log] ==> #425000     Total Loss: 0.660    [weighted Loss:0.660    Policy Loss: 4.821    Value Loss: 5.018    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 510872     Buffer Size: 21211      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:00:12,464][train][INFO][train.py>_log] ==> #426000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 6.232    Value Loss: 5.197    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 511852     Buffer Size: 21219      Transition Number: 1200.462k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:04:11,262][train][INFO][train.py>_log] ==> #427000     Total Loss: 2.437    [weighted Loss:2.437    Policy Loss: 5.480    Value Loss: 5.267    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 512859     Buffer Size: 21316      Transition Number: 1200.187k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:08:12,197][train][INFO][train.py>_log] ==> #428000     Total Loss: 1.829    [weighted Loss:1.829    Policy Loss: 5.558    Value Loss: 5.217    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 513937     Buffer Size: 21454      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:12:09,314][train][INFO][train.py>_log] ==> #429000     Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 5.570    Value Loss: 5.264    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 515010     Buffer Size: 21575      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:16:09,510][train][INFO][train.py>_log] ==> #430000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 5.166    Value Loss: 5.730    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 516053     Buffer Size: 21492      Transition Number: 1200.075k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:20:08,448][train][INFO][train.py>_log] ==> #431000     Total Loss: 1.335    [weighted Loss:1.335    Policy Loss: 5.099    Value Loss: 5.040    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 517047     Buffer Size: 21238      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:24:07,544][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.569    [weighted Loss:1.569    Policy Loss: 5.024    Value Loss: 5.320    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 518026     Buffer Size: 21139      Transition Number: 1200.108k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:28:06,932][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 4.523    Value Loss: 5.101    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 518939     Buffer Size: 21071      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:32:07,774][train][INFO][train.py>_log] ==> #434000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 5.857    Value Loss: 4.803    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 519921     Buffer Size: 21055      Transition Number: 1200.053k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:36:07,695][train][INFO][train.py>_log] ==> #435000     Total Loss: 1.919    [weighted Loss:1.919    Policy Loss: 4.848    Value Loss: 4.989    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 520900     Buffer Size: 21053      Transition Number: 1199.950k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:40:06,152][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 5.521    Value Loss: 4.958    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 521877     Buffer Size: 21097      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:44:04,005][train][INFO][train.py>_log] ==> #437000     Total Loss: 1.930    [weighted Loss:1.930    Policy Loss: 5.705    Value Loss: 4.869    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 522855     Buffer Size: 21125      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:48:03,793][train][INFO][train.py>_log] ==> #438000     Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 6.047    Value Loss: 5.053    Reward Loss: 1.093    Consistency Loss: 0.000    ] Replay Episodes Collected: 523848     Buffer Size: 21007      Transition Number: 1200.087k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:52:02,339][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.546    [weighted Loss:2.546    Policy Loss: 5.650    Value Loss: 5.233    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 524757     Buffer Size: 20885      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:56:00,299][train][INFO][train.py>_log] ==> #440000     Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 6.267    Value Loss: 5.135    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 525769     Buffer Size: 20856      Transition Number: 1200.018k Batch Size: 256        Lr: 0.10000 
[2022-01-23 11:59:59,903][train][INFO][train.py>_log] ==> #441000     Total Loss: 1.437    [weighted Loss:1.437    Policy Loss: 6.871    Value Loss: 5.041    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 526763     Buffer Size: 20835      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:03:57,041][train][INFO][train.py>_log] ==> #442000     Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 5.880    Value Loss: 4.902    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 527748     Buffer Size: 20791      Transition Number: 1200.471k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:07:55,272][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.121    [weighted Loss:3.121    Policy Loss: 6.010    Value Loss: 4.792    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 528657     Buffer Size: 20684      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:11:53,467][train][INFO][train.py>_log] ==> #444000     Total Loss: 3.003    [weighted Loss:3.003    Policy Loss: 6.329    Value Loss: 4.862    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 529560     Buffer Size: 20670      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:15:53,110][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 6.660    Value Loss: 5.099    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 530510     Buffer Size: 20694      Transition Number: 1200.148k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:19:52,390][train][INFO][train.py>_log] ==> #446000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 5.647    Value Loss: 5.145    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 531467     Buffer Size: 20683      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:23:53,144][train][INFO][train.py>_log] ==> #447000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 6.235    Value Loss: 4.921    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 532571     Buffer Size: 20820      Transition Number: 1200.067k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:27:54,031][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 6.904    Value Loss: 5.064    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 533648     Buffer Size: 20863      Transition Number: 1200.052k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:31:52,810][train][INFO][train.py>_log] ==> #449000     Total Loss: 3.007    [weighted Loss:3.007    Policy Loss: 6.181    Value Loss: 4.733    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 534633     Buffer Size: 20824      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:35:52,379][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.627    [weighted Loss:2.627    Policy Loss: 6.039    Value Loss: 5.202    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 535676     Buffer Size: 20789      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:39:49,665][train][INFO][train.py>_log] ==> #451000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 6.598    Value Loss: 4.870    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 536916     Buffer Size: 20923      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:43:45,829][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.390    [weighted Loss:1.390    Policy Loss: 6.322    Value Loss: 5.205    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 538050     Buffer Size: 21098      Transition Number: 1200.131k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:47:44,011][train][INFO][train.py>_log] ==> #453000     Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 7.369    Value Loss: 5.187    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 539137     Buffer Size: 21268      Transition Number: 1200.085k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:51:43,365][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 6.768    Value Loss: 5.326    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 540280     Buffer Size: 21466      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:55:40,005][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.456    [weighted Loss:2.456    Policy Loss: 6.511    Value Loss: 5.380    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 541357     Buffer Size: 21598      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-23 12:59:37,090][train][INFO][train.py>_log] ==> #456000     Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 6.492    Value Loss: 5.146    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 542438     Buffer Size: 21751      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:03:33,020][train][INFO][train.py>_log] ==> #457000     Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 5.950    Value Loss: 5.275    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 543455     Buffer Size: 21850      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:07:29,802][train][INFO][train.py>_log] ==> #458000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 5.973    Value Loss: 5.220    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 544486     Buffer Size: 21970      Transition Number: 1199.983k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:11:25,878][train][INFO][train.py>_log] ==> #459000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 6.338    Value Loss: 5.427    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 545677     Buffer Size: 22159      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:15:22,020][train][INFO][train.py>_log] ==> #460000     Total Loss: 3.115    [weighted Loss:3.115    Policy Loss: 6.197    Value Loss: 5.487    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 546828     Buffer Size: 22336      Transition Number: 1200.057k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:19:18,703][train][INFO][train.py>_log] ==> #461000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 6.611    Value Loss: 5.414    Reward Loss: 1.064    Consistency Loss: 0.000    ] Replay Episodes Collected: 547887     Buffer Size: 22470      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:23:14,903][train][INFO][train.py>_log] ==> #462000     Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 5.445    Value Loss: 5.421    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 548918     Buffer Size: 22570      Transition Number: 1200.143k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:27:12,619][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 6.155    Value Loss: 5.430    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 549928     Buffer Size: 22668      Transition Number: 1200.031k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:31:10,885][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 6.296    Value Loss: 5.748    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 551006     Buffer Size: 22760      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:35:05,866][train][INFO][train.py>_log] ==> #465000     Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 6.362    Value Loss: 5.643    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 551982     Buffer Size: 22860      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:39:02,453][train][INFO][train.py>_log] ==> #466000     Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 5.906    Value Loss: 5.550    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 552980     Buffer Size: 22937      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:43:00,040][train][INFO][train.py>_log] ==> #467000     Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 5.272    Value Loss: 5.266    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 554066     Buffer Size: 23063      Transition Number: 1200.112k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:46:56,259][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 4.963    Value Loss: 5.317    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 555125     Buffer Size: 23130      Transition Number: 1200.059k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:50:53,503][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 4.894    Value Loss: 5.759    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 556221     Buffer Size: 23169      Transition Number: 1200.279k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:54:50,107][train][INFO][train.py>_log] ==> #470000     Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 4.865    Value Loss: 5.637    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 557278     Buffer Size: 23246      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-23 13:58:49,217][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.409    [weighted Loss:2.409    Policy Loss: 5.696    Value Loss: 5.444    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 558333     Buffer Size: 23365      Transition Number: 1200.019k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:02:45,717][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 5.547    Value Loss: 5.638    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 559455     Buffer Size: 23460      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:06:43,020][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.989    Value Loss: 5.493    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 560458     Buffer Size: 23289      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:10:43,268][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.270    [weighted Loss:2.270    Policy Loss: 4.936    Value Loss: 5.847    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 561465     Buffer Size: 23161      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:14:38,789][train][INFO][train.py>_log] ==> #475000     Total Loss: 2.492    [weighted Loss:2.492    Policy Loss: 5.142    Value Loss: 5.552    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 562440     Buffer Size: 23026      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:18:38,828][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 4.868    Value Loss: 5.927    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 563383     Buffer Size: 22861      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:22:35,292][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 4.780    Value Loss: 5.161    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 564372     Buffer Size: 22750      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:26:36,397][train][INFO][train.py>_log] ==> #478000     Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 4.554    Value Loss: 5.600    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 565302     Buffer Size: 22660      Transition Number: 1200.105k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:30:37,602][train][INFO][train.py>_log] ==> #479000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.651    Value Loss: 5.298    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 566300     Buffer Size: 22587      Transition Number: 1200.010k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:34:36,608][train][INFO][train.py>_log] ==> #480000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 4.958    Value Loss: 5.175    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 567345     Buffer Size: 22520      Transition Number: 1200.202k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:38:34,882][train][INFO][train.py>_log] ==> #481000     Total Loss: 1.353    [weighted Loss:1.353    Policy Loss: 4.885    Value Loss: 5.404    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 568274     Buffer Size: 22312      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:42:33,091][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 5.282    Value Loss: 5.233    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 569253     Buffer Size: 22150      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:46:31,027][train][INFO][train.py>_log] ==> #483000     Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 5.402    Value Loss: 5.146    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 570183     Buffer Size: 22083      Transition Number: 1200.177k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:50:27,921][train][INFO][train.py>_log] ==> #484000     Total Loss: 1.973    [weighted Loss:1.973    Policy Loss: 6.266    Value Loss: 5.272    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 571207     Buffer Size: 21980      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:54:24,694][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.879    [weighted Loss:2.879    Policy Loss: 6.841    Value Loss: 5.465    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 572838     Buffer Size: 22481      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-23 14:58:23,935][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 6.443    Value Loss: 5.855    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 574434     Buffer Size: 23002      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:02:19,338][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 5.710    Value Loss: 5.506    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 575647     Buffer Size: 23214      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:06:18,138][train][INFO][train.py>_log] ==> #488000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 6.055    Value Loss: 5.878    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 576861     Buffer Size: 23389      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:10:19,413][train][INFO][train.py>_log] ==> #489000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 5.599    Value Loss: 5.887    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 577856     Buffer Size: 23304      Transition Number: 1200.163k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:14:17,021][train][INFO][train.py>_log] ==> #490000     Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 5.184    Value Loss: 5.372    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 578812     Buffer Size: 23200      Transition Number: 1200.028k Batch Size: 256        Lr: 0.10000 
