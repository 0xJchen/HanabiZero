[2022-01-24 10:16:35,796][train][INFO][train.py>_log] ==> #0          Total Loss: 48.351   [weighted Loss:48.351   Policy Loss: 13.879   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1489       Buffer Size: 1489       Transition Number: 16.721  k Batch Size: 256        Lr: 0.00000 
[2022-01-24 10:20:37,620][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.479    [weighted Loss:6.479    Policy Loss: 13.136   Value Loss: 4.840    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 13048      Buffer Size: 13048      Transition Number: 161.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:24:31,987][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.555    [weighted Loss:5.555    Policy Loss: 11.034   Value Loss: 4.025    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 24421      Buffer Size: 24421      Transition Number: 304.068 k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:28:22,489][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.542    [weighted Loss:4.542    Policy Loss: 8.057    Value Loss: 3.869    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 43196      Buffer Size: 43196      Transition Number: 456.271 k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:32:14,120][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.818    [weighted Loss:3.818    Policy Loss: 8.870    Value Loss: 3.707    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 62634      Buffer Size: 62635      Transition Number: 610.159 k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:36:08,032][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.797    [weighted Loss:3.797    Policy Loss: 8.978    Value Loss: 3.950    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 78583      Buffer Size: 78583      Transition Number: 765.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:40:02,151][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.912    [weighted Loss:3.912    Policy Loss: 7.773    Value Loss: 3.751    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 95043      Buffer Size: 95043      Transition Number: 928.464 k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:43:55,114][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.179    [weighted Loss:4.179    Policy Loss: 6.855    Value Loss: 4.240    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 107924     Buffer Size: 107924     Transition Number: 1090.533k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:47:54,281][train][INFO][train.py>_log] ==> #8000       Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 5.531    Value Loss: 4.208    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 121033     Buffer Size: 121033     Transition Number: 1256.755k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:52:11,328][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 4.727    Value Loss: 4.078    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 132295     Buffer Size: 129422     Transition Number: 1400.208k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:57:01,894][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 5.747    Value Loss: 4.010    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 144986     Buffer Size: 125924     Transition Number: 1400.029k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:01:24,025][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.168    [weighted Loss:3.168    Policy Loss: 5.423    Value Loss: 4.170    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 152745     Buffer Size: 115129     Transition Number: 1400.504k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:05:35,488][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.527    [weighted Loss:2.527    Policy Loss: 7.195    Value Loss: 3.727    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 160300     Buffer Size: 100833     Transition Number: 1400.222k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:09:29,382][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.714    [weighted Loss:3.714    Policy Loss: 6.362    Value Loss: 3.987    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 166235     Buffer Size: 90482      Transition Number: 1400.226k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:13:24,240][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.979    [weighted Loss:3.979    Policy Loss: 7.048    Value Loss: 3.974    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 172160     Buffer Size: 81037      Transition Number: 1400.557k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:17:19,388][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.369    [weighted Loss:3.369    Policy Loss: 6.410    Value Loss: 3.986    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 178160     Buffer Size: 73891      Transition Number: 1400.140k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:21:11,883][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 6.957    Value Loss: 4.130    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 183996     Buffer Size: 67766      Transition Number: 1400.073k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:25:04,187][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.915    [weighted Loss:4.915    Policy Loss: 7.922    Value Loss: 4.233    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 189020     Buffer Size: 62518      Transition Number: 1400.386k Batch Size: 256        Lr: 0.10000 
