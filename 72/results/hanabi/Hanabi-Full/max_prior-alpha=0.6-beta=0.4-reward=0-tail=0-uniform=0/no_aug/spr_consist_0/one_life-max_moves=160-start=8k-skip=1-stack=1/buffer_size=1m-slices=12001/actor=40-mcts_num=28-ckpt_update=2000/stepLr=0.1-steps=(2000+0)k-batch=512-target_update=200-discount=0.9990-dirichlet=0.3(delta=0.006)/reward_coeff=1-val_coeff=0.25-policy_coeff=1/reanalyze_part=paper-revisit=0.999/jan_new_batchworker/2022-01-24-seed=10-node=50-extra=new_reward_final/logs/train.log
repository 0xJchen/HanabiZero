[2022-01-24 12:05:47,622][train][INFO][train.py>_log] ==> #0          Total Loss: 48.058   [weighted Loss:48.058   Policy Loss: 13.586   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1810       Buffer Size: 1810       Transition Number: 19.153  k Batch Size: 512        Lr: 0.00000 
[2022-01-24 12:09:07,920][train][INFO][train.py>_log] ==> #1000       Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 13.472   Value Loss: 4.676    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 16603      Buffer Size: 16603      Transition Number: 205.601 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:12:30,172][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.516    [weighted Loss:4.516    Policy Loss: 10.172   Value Loss: 4.156    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 31530      Buffer Size: 31530      Transition Number: 391.602 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:15:52,336][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.944    [weighted Loss:4.944    Policy Loss: 8.850    Value Loss: 3.960    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 52975      Buffer Size: 52975      Transition Number: 582.352 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:19:32,783][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 6.755    Value Loss: 3.524    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 76821      Buffer Size: 76821      Transition Number: 789.173 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:23:03,451][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.481    [weighted Loss:3.481    Policy Loss: 7.532    Value Loss: 3.899    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 87400      Buffer Size: 87400      Transition Number: 967.027 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:26:56,909][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 6.472    Value Loss: 4.102    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 99232      Buffer Size: 99232      Transition Number: 1176.169k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:30:49,779][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 4.411    Value Loss: 3.947    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 105076     Buffer Size: 105076     Transition Number: 1362.601k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:35:02,877][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 4.230    Value Loss: 3.955    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 111460     Buffer Size: 105591     Transition Number: 1500.483k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:39:19,756][train][INFO][train.py>_log] ==> #9000       Total Loss: 1.614    [weighted Loss:1.614    Policy Loss: 4.156    Value Loss: 3.754    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 116709     Buffer Size: 94149      Transition Number: 1500.260k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:43:38,893][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.210    [weighted Loss:2.210    Policy Loss: 3.919    Value Loss: 4.039    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 121942     Buffer Size: 79275      Transition Number: 1500.058k Batch Size: 512        Lr: 0.10000 
[2022-01-24 12:47:54,246][train][INFO][train.py>_log] ==> #11000      Total Loss: 0.978    [weighted Loss:0.978    Policy Loss: 4.064    Value Loss: 3.913    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 125859     Buffer Size: 59842      Transition Number: 1500.037k Batch Size: 512        Lr: 0.10000 
