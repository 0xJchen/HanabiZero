[2022-01-23 15:18:02,470][train][INFO][train.py>_log] ==> #0          Total Loss: 48.257   [weighted Loss:48.257   Policy Loss: 13.785   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1079       Buffer Size: 1079       Transition Number: 11.950  k Batch Size: 256        Lr: 0.00000 
[2022-01-23 15:21:37,028][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.851    [weighted Loss:4.851    Policy Loss: 14.129   Value Loss: 4.472    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 7515       Buffer Size: 7515       Transition Number: 92.829  k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:25:13,297][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.690    [weighted Loss:7.690    Policy Loss: 13.184   Value Loss: 4.240    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 14059      Buffer Size: 14059      Transition Number: 174.088 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:28:49,134][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 10.948   Value Loss: 4.183    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 21862      Buffer Size: 21862      Transition Number: 257.314 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:32:24,498][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.448    [weighted Loss:4.448    Policy Loss: 10.517   Value Loss: 4.014    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 29574      Buffer Size: 29574      Transition Number: 339.335 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:35:58,594][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.413    [weighted Loss:5.413    Policy Loss: 8.972    Value Loss: 3.891    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 35089      Buffer Size: 35089      Transition Number: 419.426 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:39:32,311][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.695    [weighted Loss:3.695    Policy Loss: 7.661    Value Loss: 4.022    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 40363      Buffer Size: 40363      Transition Number: 500.084 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:43:08,491][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 6.401    Value Loss: 4.206    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 43779      Buffer Size: 43779      Transition Number: 576.087 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:46:43,427][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 5.707    Value Loss: 3.992    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 47234      Buffer Size: 47234      Transition Number: 655.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:50:17,073][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 5.159    Value Loss: 4.081    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 50283      Buffer Size: 50283      Transition Number: 731.389 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:53:52,107][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.736    [weighted Loss:3.736    Policy Loss: 5.381    Value Loss: 3.956    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 53369      Buffer Size: 53369      Transition Number: 808.091 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 15:57:26,581][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 5.258    Value Loss: 3.892    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 56548      Buffer Size: 56548      Transition Number: 885.089 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:01:00,840][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.518    [weighted Loss:3.518    Policy Loss: 5.768    Value Loss: 3.857    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 59805      Buffer Size: 59805      Transition Number: 962.656 k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:04:35,576][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.588    [weighted Loss:3.588    Policy Loss: 5.716    Value Loss: 4.034    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 63867      Buffer Size: 63867      Transition Number: 1043.237k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:08:09,715][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 5.760    Value Loss: 4.133    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 67960      Buffer Size: 67960      Transition Number: 1122.848k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:11:44,491][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.585    [weighted Loss:3.585    Policy Loss: 5.884    Value Loss: 3.777    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 71321      Buffer Size: 71321      Transition Number: 1198.758k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:15:19,212][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.949    [weighted Loss:2.949    Policy Loss: 7.448    Value Loss: 4.205    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 74742      Buffer Size: 74742      Transition Number: 1276.977k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:18:51,942][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.219    [weighted Loss:3.219    Policy Loss: 6.502    Value Loss: 4.106    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 77515      Buffer Size: 77515      Transition Number: 1350.777k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:22:27,368][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 6.256    Value Loss: 4.256    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 80286      Buffer Size: 78136      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:26:03,345][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.693    [weighted Loss:3.693    Policy Loss: 6.982    Value Loss: 4.382    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 82771      Buffer Size: 74669      Transition Number: 1400.108k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:29:39,866][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.541    [weighted Loss:3.541    Policy Loss: 5.884    Value Loss: 4.557    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 85323      Buffer Size: 71118      Transition Number: 1400.042k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:33:16,271][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.883    [weighted Loss:3.883    Policy Loss: 6.363    Value Loss: 4.413    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 87002      Buffer Size: 66302      Transition Number: 1399.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:36:51,718][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.411    [weighted Loss:3.411    Policy Loss: 6.002    Value Loss: 4.629    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 88653      Buffer Size: 61284      Transition Number: 1400.194k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:40:25,961][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 5.702    Value Loss: 4.597    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 90224      Buffer Size: 57468      Transition Number: 1400.220k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:44:01,145][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 5.968    Value Loss: 4.650    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 91781      Buffer Size: 54355      Transition Number: 1400.014k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:47:35,040][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.052    [weighted Loss:3.052    Policy Loss: 4.905    Value Loss: 4.864    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 93481      Buffer Size: 51801      Transition Number: 1400.015k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:51:12,755][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.085    [weighted Loss:3.085    Policy Loss: 5.345    Value Loss: 5.112    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 95272      Buffer Size: 50464      Transition Number: 1400.135k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:54:48,004][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 5.175    Value Loss: 5.069    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 96697      Buffer Size: 48664      Transition Number: 1399.973k Batch Size: 256        Lr: 0.10000 
[2022-01-23 16:58:22,176][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.350    [weighted Loss:3.350    Policy Loss: 4.838    Value Loss: 5.222    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 98128      Buffer Size: 47157      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:01:57,492][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 4.285    Value Loss: 5.223    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 99522      Buffer Size: 45702      Transition Number: 1399.993k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:05:32,902][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 4.390    Value Loss: 5.316    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 100945     Buffer Size: 44174      Transition Number: 1400.142k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:09:08,228][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 4.531    Value Loss: 5.609    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 102301     Buffer Size: 42507      Transition Number: 1400.082k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:12:42,630][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 4.113    Value Loss: 5.420    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 103683     Buffer Size: 40214      Transition Number: 1400.112k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:16:17,810][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 3.662    Value Loss: 5.331    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 104978     Buffer Size: 37947      Transition Number: 1400.054k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:19:51,539][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 3.490    Value Loss: 5.597    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 106293     Buffer Size: 35991      Transition Number: 1400.354k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:23:25,661][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 3.282    Value Loss: 5.329    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 107552     Buffer Size: 34028      Transition Number: 1400.280k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:26:59,939][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 3.465    Value Loss: 5.586    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 108830     Buffer Size: 32294      Transition Number: 1400.443k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:30:35,737][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.515    [weighted Loss:2.515    Policy Loss: 3.825    Value Loss: 5.545    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 109938     Buffer Size: 30673      Transition Number: 1400.138k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:34:13,226][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.478    [weighted Loss:2.478    Policy Loss: 3.720    Value Loss: 5.244    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 111116     Buffer Size: 29110      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:37:49,060][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 3.852    Value Loss: 5.329    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 112306     Buffer Size: 27646      Transition Number: 1400.115k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:41:26,781][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 3.583    Value Loss: 5.143    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 113433     Buffer Size: 26711      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:45:01,371][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.720    [weighted Loss:1.720    Policy Loss: 4.124    Value Loss: 5.044    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 114540     Buffer Size: 26113      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:48:37,273][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 3.984    Value Loss: 5.214    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 115716     Buffer Size: 25491      Transition Number: 1400.195k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:52:13,244][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 3.316    Value Loss: 4.900    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 116874     Buffer Size: 24834      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:55:48,287][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 3.663    Value Loss: 4.988    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 118058     Buffer Size: 24079      Transition Number: 1399.965k Batch Size: 256        Lr: 0.10000 
[2022-01-23 17:59:25,225][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 3.843    Value Loss: 4.887    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 119209     Buffer Size: 23328      Transition Number: 1399.948k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:03:01,321][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 3.431    Value Loss: 4.643    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 120302     Buffer Size: 22933      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:06:38,541][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 3.254    Value Loss: 4.867    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 121557     Buffer Size: 22393      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:10:15,832][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 3.327    Value Loss: 4.747    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 122713     Buffer Size: 21913      Transition Number: 1400.058k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:13:52,189][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.569    [weighted Loss:1.569    Policy Loss: 3.661    Value Loss: 4.524    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 123861     Buffer Size: 21493      Transition Number: 1400.437k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:17:29,936][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.228    [weighted Loss:2.228    Policy Loss: 3.845    Value Loss: 4.488    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 125186     Buffer Size: 20988      Transition Number: 1399.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:21:07,630][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 4.006    Value Loss: 4.715    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 126365     Buffer Size: 20600      Transition Number: 1400.452k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:24:47,011][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 3.610    Value Loss: 4.665    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 127549     Buffer Size: 20248      Transition Number: 1400.276k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:28:24,750][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.105    [weighted Loss:1.105    Policy Loss: 4.352    Value Loss: 4.415    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 128825     Buffer Size: 19931      Transition Number: 1400.021k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:32:03,910][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.243    [weighted Loss:2.243    Policy Loss: 4.018    Value Loss: 4.538    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 130013     Buffer Size: 19820      Transition Number: 1399.934k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:35:40,257][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 5.017    Value Loss: 4.471    Reward Loss: 0.952    Consistency Loss: 0.000    ] Replay Episodes Collected: 131313     Buffer Size: 19727      Transition Number: 1400.019k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:39:17,467][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 4.279    Value Loss: 4.728    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 132496     Buffer Size: 19670      Transition Number: 1399.974k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:42:55,013][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 4.860    Value Loss: 4.351    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 133632     Buffer Size: 19662      Transition Number: 1400.051k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:46:30,679][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 4.927    Value Loss: 4.515    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 134926     Buffer Size: 19627      Transition Number: 1399.939k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:50:08,801][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 4.501    Value Loss: 4.548    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 136142     Buffer Size: 19679      Transition Number: 1400.006k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:53:45,870][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 4.751    Value Loss: 4.869    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 137322     Buffer Size: 19774      Transition Number: 1399.979k Batch Size: 256        Lr: 0.10000 
[2022-01-23 18:57:22,877][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 5.187    Value Loss: 4.439    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 138553     Buffer Size: 19833      Transition Number: 1400.573k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:00:59,577][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.384    [weighted Loss:2.384    Policy Loss: 4.697    Value Loss: 4.861    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 139805     Buffer Size: 19899      Transition Number: 1400.023k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:04:36,109][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 4.533    Value Loss: 4.656    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 140976     Buffer Size: 19996      Transition Number: 1399.985k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:08:12,829][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 4.744    Value Loss: 4.680    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 142224     Buffer Size: 20120      Transition Number: 1400.003k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:11:47,736][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 4.984    Value Loss: 5.086    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 143468     Buffer Size: 20261      Transition Number: 1399.927k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:15:23,038][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 4.833    Value Loss: 4.748    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 144668     Buffer Size: 20412      Transition Number: 1400.119k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:18:59,878][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.380    [weighted Loss:2.380    Policy Loss: 4.560    Value Loss: 4.859    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 145870     Buffer Size: 20501      Transition Number: 1400.038k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:22:37,476][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.659    [weighted Loss:1.659    Policy Loss: 4.606    Value Loss: 4.834    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 147110     Buffer Size: 20591      Transition Number: 1400.803k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:26:13,154][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 4.693    Value Loss: 5.066    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 148375     Buffer Size: 20723      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:29:47,688][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.776    [weighted Loss:1.776    Policy Loss: 4.146    Value Loss: 5.004    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 149521     Buffer Size: 20863      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:33:24,657][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.722    [weighted Loss:1.722    Policy Loss: 4.282    Value Loss: 4.811    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 150734     Buffer Size: 20975      Transition Number: 1400.247k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:36:59,052][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 4.466    Value Loss: 4.711    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 151978     Buffer Size: 21068      Transition Number: 1399.938k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:40:36,229][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 4.194    Value Loss: 4.768    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 153159     Buffer Size: 21159      Transition Number: 1400.347k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:44:13,262][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.986    [weighted Loss:2.986    Policy Loss: 4.187    Value Loss: 5.028    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 154393     Buffer Size: 21233      Transition Number: 1400.131k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:47:49,332][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.337    Value Loss: 5.282    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 155593     Buffer Size: 21267      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:51:27,321][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.597    [weighted Loss:2.597    Policy Loss: 4.114    Value Loss: 4.847    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 156782     Buffer Size: 21295      Transition Number: 1400.407k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:55:03,048][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 3.789    Value Loss: 5.003    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 158008     Buffer Size: 21276      Transition Number: 1399.973k Batch Size: 256        Lr: 0.10000 
[2022-01-23 19:58:38,947][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 3.804    Value Loss: 4.636    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 159275     Buffer Size: 21317      Transition Number: 1399.949k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:02:17,080][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.652    [weighted Loss:1.652    Policy Loss: 4.297    Value Loss: 4.686    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 160492     Buffer Size: 21319      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:05:54,108][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 4.162    Value Loss: 4.431    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 161735     Buffer Size: 21322      Transition Number: 1400.143k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:09:31,744][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 4.315    Value Loss: 4.734    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 162994     Buffer Size: 21293      Transition Number: 1399.955k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:13:09,695][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.256    [weighted Loss:1.256    Policy Loss: 4.302    Value Loss: 4.597    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 164226     Buffer Size: 21245      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:16:46,654][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 5.052    Value Loss: 5.072    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 165541     Buffer Size: 21307      Transition Number: 1400.028k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:20:21,802][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 4.182    Value Loss: 4.916    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 166870     Buffer Size: 21442      Transition Number: 1400.203k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:23:58,745][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 4.665    Value Loss: 4.800    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 168060     Buffer Size: 21516      Transition Number: 1399.983k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:27:34,474][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 5.065    Value Loss: 5.387    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 169280     Buffer Size: 21520      Transition Number: 1399.937k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:31:12,256][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 4.947    Value Loss: 5.216    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 170552     Buffer Size: 21496      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:34:49,257][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 5.692    Value Loss: 4.831    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 171774     Buffer Size: 21481      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:38:28,460][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.513    [weighted Loss:2.513    Policy Loss: 5.637    Value Loss: 4.423    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 173078     Buffer Size: 21558      Transition Number: 1399.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:42:04,182][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.960    [weighted Loss:2.960    Policy Loss: 5.142    Value Loss: 5.121    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 174378     Buffer Size: 21644      Transition Number: 1399.933k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:45:41,445][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.632    [weighted Loss:2.632    Policy Loss: 4.967    Value Loss: 4.934    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 175592     Buffer Size: 21724      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:49:18,092][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.683    [weighted Loss:2.683    Policy Loss: 5.209    Value Loss: 4.881    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 176853     Buffer Size: 21788      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:52:54,804][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.462    [weighted Loss:2.462    Policy Loss: 4.934    Value Loss: 5.061    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 178095     Buffer Size: 21825      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-23 20:56:31,484][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 4.945    Value Loss: 4.785    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 179409     Buffer Size: 21855      Transition Number: 1400.347k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:00:08,522][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.967    [weighted Loss:2.967    Policy Loss: 5.242    Value Loss: 4.806    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 180600     Buffer Size: 21867      Transition Number: 1400.119k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:03:45,686][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 5.613    Value Loss: 5.072    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 181935     Buffer Size: 21890      Transition Number: 1400.048k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:07:21,419][train][INFO][train.py>_log] ==> #97000      Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 5.280    Value Loss: 4.716    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 183155     Buffer Size: 21970      Transition Number: 1400.049k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:10:57,911][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 5.442    Value Loss: 5.282    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 184432     Buffer Size: 22063      Transition Number: 1399.966k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:14:35,262][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 5.887    Value Loss: 5.246    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 185807     Buffer Size: 22186      Transition Number: 1399.951k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:18:10,785][train][INFO][train.py>_log] ==> #100000     Total Loss: 0.986    [weighted Loss:0.986    Policy Loss: 5.523    Value Loss: 5.243    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 187005     Buffer Size: 22291      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:21:46,260][train][INFO][train.py>_log] ==> #101000     Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 5.473    Value Loss: 5.091    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 188350     Buffer Size: 22283      Transition Number: 1399.936k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:25:21,743][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 5.130    Value Loss: 4.882    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 189647     Buffer Size: 22263      Transition Number: 1399.967k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:28:57,840][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 4.531    Value Loss: 4.907    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 190871     Buffer Size: 22300      Transition Number: 1400.111k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:32:33,881][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 5.297    Value Loss: 5.078    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 192093     Buffer Size: 22355      Transition Number: 1399.953k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:36:10,933][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 5.160    Value Loss: 4.912    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 193392     Buffer Size: 22403      Transition Number: 1399.934k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:39:48,510][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.492    [weighted Loss:2.492    Policy Loss: 5.759    Value Loss: 4.893    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 194687     Buffer Size: 22433      Transition Number: 1400.053k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:43:26,575][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 4.848    Value Loss: 5.158    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 196081     Buffer Size: 22502      Transition Number: 1400.330k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:47:01,458][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.143    [weighted Loss:2.143    Policy Loss: 4.966    Value Loss: 5.189    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 197452     Buffer Size: 22574      Transition Number: 1400.021k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:50:38,339][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.801    [weighted Loss:2.801    Policy Loss: 4.541    Value Loss: 4.946    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 198693     Buffer Size: 22608      Transition Number: 1399.951k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:54:16,780][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 4.825    Value Loss: 4.941    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 200029     Buffer Size: 22677      Transition Number: 1400.455k Batch Size: 256        Lr: 0.10000 
[2022-01-23 21:57:54,537][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.801    [weighted Loss:2.801    Policy Loss: 5.131    Value Loss: 4.959    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 201264     Buffer Size: 22711      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:01:31,563][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.437    [weighted Loss:2.437    Policy Loss: 5.213    Value Loss: 5.020    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 202617     Buffer Size: 22749      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:05:08,234][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 5.308    Value Loss: 5.128    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 203898     Buffer Size: 22806      Transition Number: 1400.003k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:08:42,835][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 5.382    Value Loss: 5.354    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 205192     Buffer Size: 22848      Transition Number: 1400.283k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:12:21,901][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 4.873    Value Loss: 4.949    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 206482     Buffer Size: 22903      Transition Number: 1399.980k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:15:58,110][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 4.811    Value Loss: 4.949    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 207844     Buffer Size: 22932      Transition Number: 1400.554k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:19:35,349][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.069    [weighted Loss:3.069    Policy Loss: 4.728    Value Loss: 4.970    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 209154     Buffer Size: 22931      Transition Number: 1399.990k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:23:11,892][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.104    [weighted Loss:3.104    Policy Loss: 5.054    Value Loss: 5.256    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 210518     Buffer Size: 22934      Transition Number: 1400.373k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:26:46,493][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 5.583    Value Loss: 5.429    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 211799     Buffer Size: 23013      Transition Number: 1400.090k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:30:22,899][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 5.105    Value Loss: 5.177    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 213126     Buffer Size: 23127      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:33:59,585][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 5.698    Value Loss: 5.435    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 214595     Buffer Size: 23328      Transition Number: 1399.939k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:37:35,976][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 5.121    Value Loss: 5.473    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 216016     Buffer Size: 23552      Transition Number: 1399.964k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:41:10,211][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 4.855    Value Loss: 5.728    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 217323     Buffer Size: 23662      Transition Number: 1399.949k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:44:46,189][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 4.972    Value Loss: 5.311    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 218634     Buffer Size: 23755      Transition Number: 1400.232k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:48:24,428][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 5.105    Value Loss: 5.269    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 219961     Buffer Size: 23705      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:52:00,273][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.693    [weighted Loss:2.693    Policy Loss: 5.029    Value Loss: 5.202    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 221289     Buffer Size: 23674      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:55:36,292][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 5.203    Value Loss: 5.005    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 222587     Buffer Size: 23761      Transition Number: 1400.059k Batch Size: 256        Lr: 0.10000 
[2022-01-23 22:59:13,300][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.741    [weighted Loss:2.741    Policy Loss: 5.151    Value Loss: 5.597    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 223974     Buffer Size: 23824      Transition Number: 1400.118k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:02:48,646][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.789    [weighted Loss:2.789    Policy Loss: 5.180    Value Loss: 5.361    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 225269     Buffer Size: 23910      Transition Number: 1399.981k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:06:24,563][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 4.918    Value Loss: 5.041    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 226583     Buffer Size: 23994      Transition Number: 1400.307k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:10:01,195][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 5.155    Value Loss: 5.138    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 227952     Buffer Size: 23984      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:13:37,288][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 4.892    Value Loss: 5.049    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 229249     Buffer Size: 24008      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:17:13,701][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 5.137    Value Loss: 5.124    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 230578     Buffer Size: 24085      Transition Number: 1400.125k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:20:50,929][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.236    [weighted Loss:1.236    Policy Loss: 4.382    Value Loss: 5.489    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 231937     Buffer Size: 24161      Transition Number: 1400.029k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:24:31,020][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 5.044    Value Loss: 5.139    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 233289     Buffer Size: 24106      Transition Number: 1400.053k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:28:08,685][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 4.678    Value Loss: 5.535    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 234578     Buffer Size: 24071      Transition Number: 1400.125k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:31:47,822][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 5.036    Value Loss: 5.174    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 235860     Buffer Size: 23890      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:35:27,522][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 4.403    Value Loss: 5.430    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 237048     Buffer Size: 23749      Transition Number: 1399.937k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:39:04,134][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 4.983    Value Loss: 5.711    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 238382     Buffer Size: 23488      Transition Number: 1400.073k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:42:43,233][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 4.826    Value Loss: 5.072    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 239664     Buffer Size: 23307      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:46:19,554][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 4.436    Value Loss: 5.107    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 240936     Buffer Size: 23208      Transition Number: 1399.996k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:49:55,803][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 4.719    Value Loss: 5.159    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 242188     Buffer Size: 23128      Transition Number: 1400.148k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:53:31,914][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.430    [weighted Loss:1.430    Policy Loss: 4.220    Value Loss: 5.458    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 243462     Buffer Size: 23104      Transition Number: 1399.962k Batch Size: 256        Lr: 0.10000 
[2022-01-23 23:57:07,471][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.860    [weighted Loss:1.860    Policy Loss: 4.947    Value Loss: 4.949    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 244791     Buffer Size: 23069      Transition Number: 1399.952k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:00:44,503][train][INFO][train.py>_log] ==> #145000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 4.453    Value Loss: 5.253    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 246097     Buffer Size: 22962      Transition Number: 1400.325k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:04:20,921][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.498    [weighted Loss:3.498    Policy Loss: 5.071    Value Loss: 4.709    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 247413     Buffer Size: 22888      Transition Number: 1400.136k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:07:58,081][train][INFO][train.py>_log] ==> #147000     Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 4.847    Value Loss: 4.673    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 248673     Buffer Size: 22788      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:11:35,855][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 4.951    Value Loss: 4.970    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 249923     Buffer Size: 22735      Transition Number: 1399.990k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:15:11,297][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 4.539    Value Loss: 4.757    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 251252     Buffer Size: 22738      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:18:49,238][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.735    [weighted Loss:2.735    Policy Loss: 4.610    Value Loss: 5.043    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 252595     Buffer Size: 22699      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:22:27,085][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 5.248    Value Loss: 5.002    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 253837     Buffer Size: 22636      Transition Number: 1400.016k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:26:03,581][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 4.697    Value Loss: 4.703    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 255216     Buffer Size: 22620      Transition Number: 1399.985k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:29:40,108][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.811    [weighted Loss:1.811    Policy Loss: 4.630    Value Loss: 5.114    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 256510     Buffer Size: 22616      Transition Number: 1400.048k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:33:19,878][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 4.297    Value Loss: 5.136    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 257725     Buffer Size: 22583      Transition Number: 1399.957k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:36:56,135][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 4.927    Value Loss: 4.767    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 259082     Buffer Size: 22608      Transition Number: 1399.951k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:40:33,095][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.405    [weighted Loss:2.405    Policy Loss: 4.298    Value Loss: 4.787    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 260316     Buffer Size: 22607      Transition Number: 1399.965k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:44:09,358][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.639    [weighted Loss:2.639    Policy Loss: 4.448    Value Loss: 4.763    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 261670     Buffer Size: 22615      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:47:46,384][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 4.096    Value Loss: 5.041    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 262891     Buffer Size: 22606      Transition Number: 1399.943k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:51:23,036][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 4.246    Value Loss: 4.910    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 264108     Buffer Size: 22616      Transition Number: 1399.996k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:55:00,854][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.936    [weighted Loss:2.936    Policy Loss: 4.676    Value Loss: 5.084    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 265483     Buffer Size: 22608      Transition Number: 1400.467k Batch Size: 256        Lr: 0.10000 
[2022-01-24 00:58:38,993][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.741    [weighted Loss:2.741    Policy Loss: 5.272    Value Loss: 5.044    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 266787     Buffer Size: 22574      Transition Number: 1400.038k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:02:16,637][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 4.996    Value Loss: 4.718    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 268025     Buffer Size: 22552      Transition Number: 1400.096k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:05:53,329][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 4.856    Value Loss: 4.997    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 269358     Buffer Size: 22568      Transition Number: 1400.035k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:09:30,072][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 5.589    Value Loss: 4.855    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 270645     Buffer Size: 22614      Transition Number: 1400.354k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:13:09,181][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.110    [weighted Loss:3.110    Policy Loss: 4.656    Value Loss: 4.945    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 271984     Buffer Size: 22668      Transition Number: 1399.950k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:16:46,554][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 4.521    Value Loss: 5.097    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 273325     Buffer Size: 22671      Transition Number: 1400.044k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:20:22,436][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 4.654    Value Loss: 4.719    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 274570     Buffer Size: 22662      Transition Number: 1399.979k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:24:01,283][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.849    [weighted Loss:2.849    Policy Loss: 5.131    Value Loss: 4.681    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 275851     Buffer Size: 22610      Transition Number: 1400.010k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:27:41,238][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 4.325    Value Loss: 5.058    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 277257     Buffer Size: 22548      Transition Number: 1399.933k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:31:20,207][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 4.993    Value Loss: 4.615    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 278517     Buffer Size: 22524      Transition Number: 1399.985k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:34:57,443][train][INFO][train.py>_log] ==> #171000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 4.819    Value Loss: 5.099    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 279811     Buffer Size: 22522      Transition Number: 1399.974k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:38:34,825][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 4.804    Value Loss: 5.210    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 281052     Buffer Size: 22528      Transition Number: 1400.136k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:42:11,348][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 4.883    Value Loss: 5.472    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 282409     Buffer Size: 22567      Transition Number: 1400.623k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:45:49,886][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.111    [weighted Loss:1.111    Policy Loss: 4.479    Value Loss: 5.475    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 283675     Buffer Size: 22615      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:49:25,225][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.162    [weighted Loss:2.162    Policy Loss: 4.792    Value Loss: 5.601    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 284939     Buffer Size: 22622      Transition Number: 1399.982k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:53:02,616][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 4.408    Value Loss: 5.471    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 286285     Buffer Size: 22606      Transition Number: 1400.324k Batch Size: 256        Lr: 0.10000 
[2022-01-24 01:56:39,932][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.887    [weighted Loss:1.887    Policy Loss: 4.816    Value Loss: 5.077    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 287501     Buffer Size: 22591      Transition Number: 1399.972k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:00:17,848][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 5.006    Value Loss: 4.757    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 288718     Buffer Size: 22562      Transition Number: 1400.283k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:03:53,636][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.693    [weighted Loss:1.693    Policy Loss: 5.108    Value Loss: 5.616    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 290359     Buffer Size: 22870      Transition Number: 1399.952k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:07:31,234][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.649    [weighted Loss:2.649    Policy Loss: 4.860    Value Loss: 5.454    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 291967     Buffer Size: 23186      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:11:06,519][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 4.684    Value Loss: 5.341    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 293230     Buffer Size: 23191      Transition Number: 1400.134k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:14:43,987][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 4.463    Value Loss: 5.267    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 294590     Buffer Size: 23152      Transition Number: 1400.397k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:18:20,820][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 4.608    Value Loss: 4.975    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 295749     Buffer Size: 23143      Transition Number: 1399.957k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:21:58,078][train][INFO][train.py>_log] ==> #184000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 4.655    Value Loss: 5.246    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 297153     Buffer Size: 23130      Transition Number: 1400.338k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:25:36,697][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 4.512    Value Loss: 4.920    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 298341     Buffer Size: 23106      Transition Number: 1400.056k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:29:14,462][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.802    [weighted Loss:2.802    Policy Loss: 4.735    Value Loss: 5.420    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 299672     Buffer Size: 23095      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:32:50,740][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 4.831    Value Loss: 5.212    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 300994     Buffer Size: 23180      Transition Number: 1399.982k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:36:27,819][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 4.618    Value Loss: 5.289    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 302308     Buffer Size: 23292      Transition Number: 1399.978k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:40:05,050][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 4.186    Value Loss: 5.373    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 303571     Buffer Size: 23313      Transition Number: 1400.074k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:43:45,263][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 4.114    Value Loss: 5.156    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 304956     Buffer Size: 23291      Transition Number: 1400.223k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:47:21,652][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 4.538    Value Loss: 4.972    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 306082     Buffer Size: 23237      Transition Number: 1400.053k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:50:58,414][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 4.204    Value Loss: 5.011    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 307473     Buffer Size: 23185      Transition Number: 1399.999k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:54:35,780][train][INFO][train.py>_log] ==> #193000     Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 4.068    Value Loss: 4.960    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 308659     Buffer Size: 23178      Transition Number: 1400.074k Batch Size: 256        Lr: 0.10000 
[2022-01-24 02:58:13,149][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 4.622    Value Loss: 5.322    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 310002     Buffer Size: 23182      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:01:50,747][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 4.708    Value Loss: 4.989    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 311174     Buffer Size: 23165      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:05:27,236][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 4.581    Value Loss: 4.634    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 312493     Buffer Size: 23010      Transition Number: 1399.966k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:09:04,434][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 4.557    Value Loss: 4.883    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 313711     Buffer Size: 22639      Transition Number: 1399.937k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:12:40,782][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.267    [weighted Loss:3.267    Policy Loss: 4.847    Value Loss: 5.195    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 315029     Buffer Size: 22388      Transition Number: 1399.942k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:16:16,490][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 5.232    Value Loss: 4.998    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 316222     Buffer Size: 22381      Transition Number: 1399.943k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:19:54,771][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 5.341    Value Loss: 5.304    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 317506     Buffer Size: 22356      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:23:32,760][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.478    [weighted Loss:2.478    Policy Loss: 4.551    Value Loss: 4.989    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 318745     Buffer Size: 22308      Transition Number: 1400.012k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:27:10,956][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 4.272    Value Loss: 4.895    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 320067     Buffer Size: 22290      Transition Number: 1399.982k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:30:46,830][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 4.867    Value Loss: 5.186    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 321302     Buffer Size: 22264      Transition Number: 1400.256k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:34:24,335][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 4.829    Value Loss: 4.953    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 322607     Buffer Size: 22193      Transition Number: 1399.976k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:38:02,115][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 4.623    Value Loss: 4.980    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 323860     Buffer Size: 22045      Transition Number: 1400.009k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:41:40,715][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 4.165    Value Loss: 4.882    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 325136     Buffer Size: 21972      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:45:19,246][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 4.587    Value Loss: 5.002    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 326365     Buffer Size: 21967      Transition Number: 1399.965k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:48:58,879][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 4.562    Value Loss: 4.940    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 327675     Buffer Size: 21965      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:52:36,115][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 5.193    Value Loss: 4.834    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 329022     Buffer Size: 21996      Transition Number: 1400.069k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:56:12,903][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.860    [weighted Loss:1.860    Policy Loss: 4.634    Value Loss: 4.863    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 330308     Buffer Size: 21996      Transition Number: 1400.213k Batch Size: 256        Lr: 0.10000 
[2022-01-24 03:59:49,958][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 4.769    Value Loss: 4.728    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 331480     Buffer Size: 22023      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:03:25,681][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.081    [weighted Loss:2.081    Policy Loss: 4.579    Value Loss: 4.843    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 332755     Buffer Size: 22042      Transition Number: 1400.146k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:07:00,899][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 5.274    Value Loss: 5.114    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 334071     Buffer Size: 22070      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:10:38,160][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 4.906    Value Loss: 5.123    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 335378     Buffer Size: 22107      Transition Number: 1400.066k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:14:13,721][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 5.947    Value Loss: 5.249    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 336619     Buffer Size: 22115      Transition Number: 1399.951k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:17:50,463][train][INFO][train.py>_log] ==> #216000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 4.848    Value Loss: 5.076    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 337905     Buffer Size: 22094      Transition Number: 1399.937k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:21:28,636][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 5.065    Value Loss: 4.947    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 339161     Buffer Size: 22077      Transition Number: 1399.986k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:25:06,109][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 4.624    Value Loss: 4.705    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 340436     Buffer Size: 22059      Transition Number: 1400.025k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:28:42,312][train][INFO][train.py>_log] ==> #219000     Total Loss: 2.974    [weighted Loss:2.974    Policy Loss: 4.652    Value Loss: 5.329    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 341696     Buffer Size: 22040      Transition Number: 1399.968k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:32:17,616][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 4.783    Value Loss: 4.903    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 342928     Buffer Size: 22040      Transition Number: 1399.940k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:35:54,588][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 4.479    Value Loss: 4.799    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 344216     Buffer Size: 22040      Transition Number: 1399.943k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:39:30,814][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 4.147    Value Loss: 5.114    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 345434     Buffer Size: 22035      Transition Number: 1400.106k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:43:06,782][train][INFO][train.py>_log] ==> #223000     Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 4.752    Value Loss: 4.696    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 346646     Buffer Size: 22040      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:46:43,800][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 4.969    Value Loss: 4.916    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 347857     Buffer Size: 22038      Transition Number: 1400.107k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:50:19,697][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.865    [weighted Loss:1.865    Policy Loss: 5.147    Value Loss: 5.062    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 349255     Buffer Size: 22056      Transition Number: 1399.964k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:53:55,793][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.505    [weighted Loss:3.505    Policy Loss: 4.775    Value Loss: 5.002    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 350487     Buffer Size: 22065      Transition Number: 1399.970k Batch Size: 256        Lr: 0.10000 
[2022-01-24 04:57:32,504][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.317    [weighted Loss:3.317    Policy Loss: 5.083    Value Loss: 5.090    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 351799     Buffer Size: 22185      Transition Number: 1400.199k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:01:07,892][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.457    [weighted Loss:1.457    Policy Loss: 4.462    Value Loss: 4.942    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 353151     Buffer Size: 22295      Transition Number: 1400.601k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:04:42,576][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.843    [weighted Loss:2.843    Policy Loss: 5.042    Value Loss: 4.974    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 354407     Buffer Size: 22303      Transition Number: 1399.979k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:08:20,835][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 4.707    Value Loss: 5.025    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 355723     Buffer Size: 22319      Transition Number: 1399.993k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:11:58,082][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 5.555    Value Loss: 5.157    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 357014     Buffer Size: 22293      Transition Number: 1400.077k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:15:35,923][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 5.575    Value Loss: 5.048    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 358225     Buffer Size: 22277      Transition Number: 1399.940k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:19:12,224][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.085    [weighted Loss:2.085    Policy Loss: 4.744    Value Loss: 4.911    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 359515     Buffer Size: 22331      Transition Number: 1400.024k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:22:48,886][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 5.797    Value Loss: 5.099    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 360943     Buffer Size: 22381      Transition Number: 1399.958k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:26:26,353][train][INFO][train.py>_log] ==> #235000     Total Loss: 1.312    [weighted Loss:1.312    Policy Loss: 4.816    Value Loss: 5.041    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 362180     Buffer Size: 22497      Transition Number: 1400.035k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:30:03,400][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 5.649    Value Loss: 4.872    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 363526     Buffer Size: 22633      Transition Number: 1400.050k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:33:41,223][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.427    [weighted Loss:3.427    Policy Loss: 5.324    Value Loss: 5.123    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 364897     Buffer Size: 22708      Transition Number: 1400.087k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:37:18,725][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.128    [weighted Loss:3.128    Policy Loss: 5.196    Value Loss: 5.060    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 366192     Buffer Size: 22763      Transition Number: 1400.018k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:40:55,676][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 5.091    Value Loss: 5.332    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 367543     Buffer Size: 22922      Transition Number: 1400.040k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:44:31,413][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.699    [weighted Loss:3.699    Policy Loss: 5.427    Value Loss: 5.183    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 368873     Buffer Size: 23103      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:48:08,025][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 5.103    Value Loss: 5.964    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 370217     Buffer Size: 23243      Transition Number: 1400.047k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:51:43,152][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 4.449    Value Loss: 5.360    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 371513     Buffer Size: 23374      Transition Number: 1400.054k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:55:21,105][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 4.784    Value Loss: 5.436    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 372753     Buffer Size: 23393      Transition Number: 1400.015k Batch Size: 256        Lr: 0.10000 
[2022-01-24 05:58:57,571][train][INFO][train.py>_log] ==> #244000     Total Loss: 1.435    [weighted Loss:1.435    Policy Loss: 4.741    Value Loss: 5.103    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 374015     Buffer Size: 23375      Transition Number: 1399.978k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:02:34,135][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 4.785    Value Loss: 5.578    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 375322     Buffer Size: 23238      Transition Number: 1399.956k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:06:09,696][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 4.111    Value Loss: 5.107    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 376525     Buffer Size: 23141      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:09:47,444][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 4.253    Value Loss: 5.334    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 377764     Buffer Size: 23131      Transition Number: 1400.195k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:13:23,560][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.046    [weighted Loss:2.046    Policy Loss: 4.948    Value Loss: 5.171    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 379031     Buffer Size: 23110      Transition Number: 1400.266k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:16:59,123][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 4.582    Value Loss: 5.105    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 380175     Buffer Size: 23100      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:20:35,347][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 4.556    Value Loss: 5.694    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 381422     Buffer Size: 23102      Transition Number: 1400.128k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:24:13,377][train][INFO][train.py>_log] ==> #251000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 4.583    Value Loss: 5.198    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 382696     Buffer Size: 23037      Transition Number: 1400.063k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:27:50,623][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 4.677    Value Loss: 5.098    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 383969     Buffer Size: 22978      Transition Number: 1399.956k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:31:27,146][train][INFO][train.py>_log] ==> #253000     Total Loss: 1.261    [weighted Loss:1.261    Policy Loss: 4.600    Value Loss: 5.447    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 385177     Buffer Size: 22869      Transition Number: 1400.053k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:35:04,865][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 4.723    Value Loss: 4.898    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 386449     Buffer Size: 22743      Transition Number: 1400.654k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:38:40,689][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 4.539    Value Loss: 5.091    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 387735     Buffer Size: 22723      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:42:15,647][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.179    [weighted Loss:3.179    Policy Loss: 4.856    Value Loss: 4.695    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 388969     Buffer Size: 22729      Transition Number: 1400.279k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:45:53,128][train][INFO][train.py>_log] ==> #257000     Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 5.018    Value Loss: 5.138    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 390290     Buffer Size: 22615      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:49:31,212][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.604    [weighted Loss:2.604    Policy Loss: 4.647    Value Loss: 5.267    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 391612     Buffer Size: 22511      Transition Number: 1399.983k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:53:08,041][train][INFO][train.py>_log] ==> #259000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 4.538    Value Loss: 5.095    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 392801     Buffer Size: 22429      Transition Number: 1399.958k Batch Size: 256        Lr: 0.10000 
[2022-01-24 06:56:44,444][train][INFO][train.py>_log] ==> #260000     Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 4.655    Value Loss: 5.349    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 394135     Buffer Size: 22358      Transition Number: 1400.123k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:00:22,352][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 4.910    Value Loss: 4.928    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 395443     Buffer Size: 22349      Transition Number: 1400.222k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:03:59,419][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.604    [weighted Loss:2.604    Policy Loss: 4.755    Value Loss: 5.232    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 396702     Buffer Size: 22346      Transition Number: 1400.147k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:07:36,123][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 4.897    Value Loss: 4.754    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 397998     Buffer Size: 22348      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:11:12,684][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 4.779    Value Loss: 5.022    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 399215     Buffer Size: 22355      Transition Number: 1400.001k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:14:50,611][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 4.733    Value Loss: 5.023    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 400511     Buffer Size: 22329      Transition Number: 1400.064k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:18:25,719][train][INFO][train.py>_log] ==> #266000     Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 5.162    Value Loss: 5.215    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 401803     Buffer Size: 22314      Transition Number: 1400.275k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:22:00,793][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.333    [weighted Loss:2.333    Policy Loss: 4.452    Value Loss: 4.882    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 403016     Buffer Size: 22343      Transition Number: 1399.970k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:25:36,511][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 4.500    Value Loss: 4.461    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 404264     Buffer Size: 22360      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:29:12,210][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 4.714    Value Loss: 5.014    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 405501     Buffer Size: 22387      Transition Number: 1399.966k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:32:48,909][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.041    [weighted Loss:2.041    Policy Loss: 4.730    Value Loss: 5.274    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 406788     Buffer Size: 22411      Transition Number: 1400.067k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:36:25,590][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 4.765    Value Loss: 5.461    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 408076     Buffer Size: 22477      Transition Number: 1400.206k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:40:01,603][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 4.839    Value Loss: 5.129    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 409368     Buffer Size: 22525      Transition Number: 1400.029k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:43:39,301][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 4.735    Value Loss: 5.175    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 410590     Buffer Size: 22512      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:47:16,707][train][INFO][train.py>_log] ==> #274000     Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 4.699    Value Loss: 5.249    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 411892     Buffer Size: 22495      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:50:52,405][train][INFO][train.py>_log] ==> #275000     Total Loss: 1.590    [weighted Loss:1.590    Policy Loss: 5.253    Value Loss: 5.369    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 413245     Buffer Size: 22591      Transition Number: 1399.931k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:54:28,182][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.147    [weighted Loss:1.147    Policy Loss: 4.927    Value Loss: 5.481    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 414652     Buffer Size: 22719      Transition Number: 1399.996k Batch Size: 256        Lr: 0.10000 
[2022-01-24 07:58:05,304][train][INFO][train.py>_log] ==> #277000     Total Loss: 2.805    [weighted Loss:2.805    Policy Loss: 5.587    Value Loss: 5.594    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 415863     Buffer Size: 22778      Transition Number: 1399.980k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:01:41,109][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 4.266    Value Loss: 5.674    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 417171     Buffer Size: 22860      Transition Number: 1400.020k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:05:16,640][train][INFO][train.py>_log] ==> #279000     Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 4.951    Value Loss: 5.433    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 418488     Buffer Size: 22862      Transition Number: 1400.189k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:08:52,644][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 4.969    Value Loss: 5.275    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 419716     Buffer Size: 22864      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:12:28,012][train][INFO][train.py>_log] ==> #281000     Total Loss: 1.963    [weighted Loss:1.963    Policy Loss: 4.611    Value Loss: 5.327    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 420930     Buffer Size: 22842      Transition Number: 1400.257k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:16:05,012][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 4.848    Value Loss: 5.008    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 422158     Buffer Size: 22801      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:19:43,924][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 4.557    Value Loss: 4.979    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 423394     Buffer Size: 22798      Transition Number: 1399.961k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:23:20,661][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 4.806    Value Loss: 5.373    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 424729     Buffer Size: 22790      Transition Number: 1400.114k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:26:59,368][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 5.013    Value Loss: 5.390    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 425974     Buffer Size: 22737      Transition Number: 1399.981k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:30:36,655][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 4.624    Value Loss: 5.498    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 427245     Buffer Size: 22690      Transition Number: 1399.972k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:34:15,647][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.046    [weighted Loss:2.046    Policy Loss: 4.773    Value Loss: 4.985    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 428513     Buffer Size: 22684      Transition Number: 1399.974k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:37:53,487][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 4.743    Value Loss: 5.074    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 429803     Buffer Size: 22677      Transition Number: 1400.190k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:41:30,558][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.948    [weighted Loss:1.948    Policy Loss: 4.693    Value Loss: 5.348    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 431020     Buffer Size: 22601      Transition Number: 1400.285k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:45:08,230][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 5.351    Value Loss: 5.094    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 432295     Buffer Size: 22552      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:48:44,590][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 5.274    Value Loss: 5.076    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 433633     Buffer Size: 22483      Transition Number: 1400.131k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:52:20,631][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 4.929    Value Loss: 4.844    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 434812     Buffer Size: 22381      Transition Number: 1400.230k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:55:56,965][train][INFO][train.py>_log] ==> #293000     Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 5.151    Value Loss: 4.991    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 436091     Buffer Size: 22187      Transition Number: 1400.198k Batch Size: 256        Lr: 0.10000 
[2022-01-24 08:59:33,570][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 4.661    Value Loss: 4.808    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 437307     Buffer Size: 22042      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:03:09,429][train][INFO][train.py>_log] ==> #295000     Total Loss: 1.364    [weighted Loss:1.364    Policy Loss: 4.930    Value Loss: 4.953    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 438538     Buffer Size: 21979      Transition Number: 1399.966k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:06:48,504][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 4.697    Value Loss: 5.091    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 439901     Buffer Size: 21929      Transition Number: 1399.983k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:10:25,581][train][INFO][train.py>_log] ==> #297000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 5.616    Value Loss: 5.000    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 441162     Buffer Size: 21952      Transition Number: 1399.990k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:14:01,677][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.140    [weighted Loss:2.140    Policy Loss: 5.917    Value Loss: 4.914    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 442431     Buffer Size: 21995      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:17:39,558][train][INFO][train.py>_log] ==> #299000     Total Loss: 1.734    [weighted Loss:1.734    Policy Loss: 4.814    Value Loss: 5.272    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 443844     Buffer Size: 22128      Transition Number: 1399.985k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:21:16,716][train][INFO][train.py>_log] ==> #300000     Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 6.173    Value Loss: 5.109    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 445176     Buffer Size: 22256      Transition Number: 1400.143k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:24:53,308][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 5.442    Value Loss: 5.522    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 446425     Buffer Size: 22339      Transition Number: 1400.378k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:28:28,969][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.601    [weighted Loss:2.601    Policy Loss: 5.302    Value Loss: 5.090    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 447748     Buffer Size: 22424      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:32:05,354][train][INFO][train.py>_log] ==> #303000     Total Loss: 3.006    [weighted Loss:3.006    Policy Loss: 5.535    Value Loss: 5.501    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 449007     Buffer Size: 22458      Transition Number: 1400.018k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:35:41,605][train][INFO][train.py>_log] ==> #304000     Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 4.976    Value Loss: 5.161    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 450270     Buffer Size: 22487      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:39:18,090][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 4.562    Value Loss: 5.331    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 451469     Buffer Size: 22462      Transition Number: 1399.937k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:42:52,334][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 4.380    Value Loss: 5.055    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 452635     Buffer Size: 22441      Transition Number: 1400.005k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:46:29,289][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 4.400    Value Loss: 4.854    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 453926     Buffer Size: 22408      Transition Number: 1399.940k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:50:05,314][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 4.547    Value Loss: 4.995    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 455151     Buffer Size: 22387      Transition Number: 1400.089k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:53:43,520][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 5.428    Value Loss: 5.043    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 456508     Buffer Size: 22486      Transition Number: 1400.242k Batch Size: 256        Lr: 0.10000 
[2022-01-24 09:57:20,484][train][INFO][train.py>_log] ==> #310000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 4.583    Value Loss: 5.245    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 457774     Buffer Size: 22584      Transition Number: 1399.986k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:00:57,265][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 5.051    Value Loss: 5.046    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 459080     Buffer Size: 22669      Transition Number: 1400.095k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:04:32,418][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 4.981    Value Loss: 5.234    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 460361     Buffer Size: 22781      Transition Number: 1400.207k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:08:10,116][train][INFO][train.py>_log] ==> #313000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 4.701    Value Loss: 4.853    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 461570     Buffer Size: 22754      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:11:47,735][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 4.656    Value Loss: 5.148    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 462828     Buffer Size: 22736      Transition Number: 1399.960k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:15:24,182][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.845    [weighted Loss:1.845    Policy Loss: 4.696    Value Loss: 5.242    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 464111     Buffer Size: 22790      Transition Number: 1399.974k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:18:59,645][train][INFO][train.py>_log] ==> #316000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 4.364    Value Loss: 5.325    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 465459     Buffer Size: 22852      Transition Number: 1400.065k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:22:35,869][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 4.210    Value Loss: 5.769    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 466716     Buffer Size: 22841      Transition Number: 1400.017k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:26:10,783][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 4.533    Value Loss: 5.140    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 467936     Buffer Size: 22843      Transition Number: 1400.044k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:29:48,800][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 4.263    Value Loss: 5.342    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 469158     Buffer Size: 22807      Transition Number: 1400.088k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:33:24,668][train][INFO][train.py>_log] ==> #320000     Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 4.599    Value Loss: 5.261    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 470468     Buffer Size: 22758      Transition Number: 1400.002k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:36:59,977][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.137    [weighted Loss:2.137    Policy Loss: 4.476    Value Loss: 5.212    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 471698     Buffer Size: 22775      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:40:36,900][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 4.375    Value Loss: 5.167    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 473010     Buffer Size: 22780      Transition Number: 1400.079k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:44:15,625][train][INFO][train.py>_log] ==> #323000     Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 4.820    Value Loss: 5.061    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 474229     Buffer Size: 22810      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:47:52,189][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.076    [weighted Loss:1.076    Policy Loss: 4.584    Value Loss: 4.945    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 475446     Buffer Size: 22853      Transition Number: 1399.992k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:51:28,949][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.647    [weighted Loss:2.647    Policy Loss: 4.728    Value Loss: 5.544    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 476705     Buffer Size: 22927      Transition Number: 1400.270k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:55:05,878][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 4.886    Value Loss: 5.152    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 477988     Buffer Size: 22988      Transition Number: 1399.942k Batch Size: 256        Lr: 0.10000 
[2022-01-24 10:58:42,516][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.440    [weighted Loss:2.440    Policy Loss: 4.907    Value Loss: 5.083    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 479276     Buffer Size: 22934      Transition Number: 1400.244k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:02:20,042][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 5.217    Value Loss: 5.251    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 480486     Buffer Size: 22858      Transition Number: 1400.179k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:05:56,688][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 5.176    Value Loss: 5.524    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 481725     Buffer Size: 22741      Transition Number: 1400.035k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:09:33,469][train][INFO][train.py>_log] ==> #330000     Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 4.863    Value Loss: 4.977    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 483023     Buffer Size: 22607      Transition Number: 1400.228k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:13:10,246][train][INFO][train.py>_log] ==> #331000     Total Loss: 1.021    [weighted Loss:1.021    Policy Loss: 4.726    Value Loss: 4.917    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 484236     Buffer Size: 22573      Transition Number: 1399.990k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:16:49,176][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.129    [weighted Loss:2.129    Policy Loss: 4.843    Value Loss: 4.819    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 485491     Buffer Size: 22532      Transition Number: 1400.130k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:20:25,050][train][INFO][train.py>_log] ==> #333000     Total Loss: 1.964    [weighted Loss:1.964    Policy Loss: 4.172    Value Loss: 5.205    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 486744     Buffer Size: 22400      Transition Number: 1399.982k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:24:03,406][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.140    [weighted Loss:2.140    Policy Loss: 4.499    Value Loss: 4.799    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 487968     Buffer Size: 22229      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:27:40,654][train][INFO][train.py>_log] ==> #335000     Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 4.943    Value Loss: 5.125    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 489319     Buffer Size: 22094      Transition Number: 1399.992k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:31:16,243][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 4.776    Value Loss: 4.943    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 490527     Buffer Size: 21983      Transition Number: 1399.948k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:34:54,166][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 5.183    Value Loss: 5.235    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 491853     Buffer Size: 22034      Transition Number: 1400.200k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:38:29,873][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 5.196    Value Loss: 5.233    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 493099     Buffer Size: 22088      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:42:06,708][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 5.239    Value Loss: 5.387    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 494438     Buffer Size: 22106      Transition Number: 1400.199k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:45:42,374][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.799    [weighted Loss:2.799    Policy Loss: 5.496    Value Loss: 5.168    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 495668     Buffer Size: 22157      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:49:17,723][train][INFO][train.py>_log] ==> #341000     Total Loss: 3.141    [weighted Loss:3.141    Policy Loss: 5.920    Value Loss: 5.361    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 497011     Buffer Size: 22307      Transition Number: 1400.326k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:52:53,962][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 5.020    Value Loss: 5.837    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 498428     Buffer Size: 22493      Transition Number: 1399.948k Batch Size: 256        Lr: 0.10000 
[2022-01-24 11:56:31,424][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 4.828    Value Loss: 5.276    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 499690     Buffer Size: 22521      Transition Number: 1400.189k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:00:07,492][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 4.939    Value Loss: 5.155    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 501018     Buffer Size: 22554      Transition Number: 1400.121k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:03:44,673][train][INFO][train.py>_log] ==> #345000     Total Loss: 1.999    [weighted Loss:1.999    Policy Loss: 4.715    Value Loss: 5.046    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 502169     Buffer Size: 22554      Transition Number: 1399.967k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:07:21,378][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 4.966    Value Loss: 5.235    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 503455     Buffer Size: 22553      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:10:58,691][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 4.769    Value Loss: 5.185    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 504761     Buffer Size: 22613      Transition Number: 1399.960k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:14:34,726][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 5.146    Value Loss: 5.839    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 506036     Buffer Size: 22656      Transition Number: 1400.191k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:18:10,330][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.235    [weighted Loss:3.235    Policy Loss: 5.236    Value Loss: 5.088    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 507252     Buffer Size: 22699      Transition Number: 1399.948k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:21:48,165][train][INFO][train.py>_log] ==> #350000     Total Loss: 3.024    [weighted Loss:3.024    Policy Loss: 6.355    Value Loss: 5.399    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 508453     Buffer Size: 22723      Transition Number: 1399.966k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:25:25,972][train][INFO][train.py>_log] ==> #351000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 4.696    Value Loss: 5.451    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 509771     Buffer Size: 22779      Transition Number: 1399.943k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:29:02,666][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 5.370    Value Loss: 5.372    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 511057     Buffer Size: 22852      Transition Number: 1400.068k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:32:39,066][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 5.751    Value Loss: 5.312    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 512399     Buffer Size: 22988      Transition Number: 1400.033k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:36:14,165][train][INFO][train.py>_log] ==> #354000     Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 4.536    Value Loss: 5.220    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 513685     Buffer Size: 23130      Transition Number: 1400.195k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:39:50,734][train][INFO][train.py>_log] ==> #355000     Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 5.140    Value Loss: 5.051    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 514958     Buffer Size: 23135      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:43:27,685][train][INFO][train.py>_log] ==> #356000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 4.964    Value Loss: 5.099    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 516291     Buffer Size: 23120      Transition Number: 1399.985k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:47:05,540][train][INFO][train.py>_log] ==> #357000     Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 4.618    Value Loss: 5.267    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 517529     Buffer Size: 23061      Transition Number: 1400.167k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:50:43,212][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 5.175    Value Loss: 5.640    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 518809     Buffer Size: 22954      Transition Number: 1399.976k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:54:20,215][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.940    [weighted Loss:2.940    Policy Loss: 4.868    Value Loss: 4.893    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 520125     Buffer Size: 22772      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-24 12:57:55,486][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 5.283    Value Loss: 4.809    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 521348     Buffer Size: 22585      Transition Number: 1399.949k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:01:30,990][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 4.964    Value Loss: 5.192    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 522563     Buffer Size: 22533      Transition Number: 1400.237k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:05:07,692][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 5.288    Value Loss: 4.785    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 523874     Buffer Size: 22483      Transition Number: 1399.948k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:08:43,820][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 4.672    Value Loss: 5.351    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 525041     Buffer Size: 22490      Transition Number: 1400.082k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:12:21,368][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.110    [weighted Loss:2.110    Policy Loss: 5.000    Value Loss: 4.842    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 526311     Buffer Size: 22469      Transition Number: 1400.407k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:15:57,697][train][INFO][train.py>_log] ==> #365000     Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 5.139    Value Loss: 5.124    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 527599     Buffer Size: 22431      Transition Number: 1400.058k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:19:36,298][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 5.233    Value Loss: 4.870    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 528846     Buffer Size: 22402      Transition Number: 1400.278k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:23:13,218][train][INFO][train.py>_log] ==> #367000     Total Loss: 1.906    [weighted Loss:1.906    Policy Loss: 4.961    Value Loss: 4.882    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 530101     Buffer Size: 22377      Transition Number: 1400.101k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:26:51,173][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.084    [weighted Loss:2.084    Policy Loss: 4.795    Value Loss: 4.932    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 531368     Buffer Size: 22360      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:30:27,695][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.779    [weighted Loss:2.779    Policy Loss: 5.619    Value Loss: 5.218    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 532729     Buffer Size: 22416      Transition Number: 1399.978k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:34:05,152][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 4.870    Value Loss: 4.965    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 533984     Buffer Size: 22434      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:37:40,843][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 5.130    Value Loss: 5.399    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 535333     Buffer Size: 22337      Transition Number: 1399.937k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:41:20,134][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.830    [weighted Loss:1.830    Policy Loss: 5.044    Value Loss: 5.329    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 536569     Buffer Size: 22253      Transition Number: 1400.064k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:44:58,350][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 4.767    Value Loss: 4.602    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 537856     Buffer Size: 22184      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:48:35,487][train][INFO][train.py>_log] ==> #374000     Total Loss: 1.418    [weighted Loss:1.418    Policy Loss: 4.653    Value Loss: 4.992    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 539151     Buffer Size: 22149      Transition Number: 1399.935k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:52:11,040][train][INFO][train.py>_log] ==> #375000     Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 4.808    Value Loss: 5.299    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 540439     Buffer Size: 22222      Transition Number: 1400.246k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:55:46,257][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 4.920    Value Loss: 4.933    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 541670     Buffer Size: 22259      Transition Number: 1399.980k Batch Size: 256        Lr: 0.10000 
[2022-01-24 13:59:21,835][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 5.171    Value Loss: 4.979    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 542918     Buffer Size: 22266      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:02:59,687][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 5.505    Value Loss: 4.981    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 544184     Buffer Size: 22267      Transition Number: 1400.007k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:06:38,584][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 5.000    Value Loss: 5.396    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 545461     Buffer Size: 22302      Transition Number: 1400.268k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:10:15,255][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 5.311    Value Loss: 4.935    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 546799     Buffer Size: 22322      Transition Number: 1400.065k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:13:53,721][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 5.447    Value Loss: 4.996    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 548107     Buffer Size: 22400      Transition Number: 1400.148k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:17:30,650][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 5.175    Value Loss: 5.333    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 549372     Buffer Size: 22483      Transition Number: 1400.012k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:21:07,607][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 5.242    Value Loss: 5.019    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 550729     Buffer Size: 22569      Transition Number: 1399.962k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:24:43,934][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 4.896    Value Loss: 5.114    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 552053     Buffer Size: 22655      Transition Number: 1400.164k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:28:21,123][train][INFO][train.py>_log] ==> #385000     Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 4.766    Value Loss: 5.141    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 553314     Buffer Size: 22723      Transition Number: 1400.425k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:31:57,166][train][INFO][train.py>_log] ==> #386000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 5.287    Value Loss: 5.348    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 554663     Buffer Size: 22721      Transition Number: 1400.010k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:35:34,269][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.755    [weighted Loss:1.755    Policy Loss: 5.559    Value Loss: 5.440    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 556011     Buffer Size: 22731      Transition Number: 1400.012k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:39:11,783][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 5.032    Value Loss: 5.149    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 557313     Buffer Size: 22760      Transition Number: 1400.082k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:42:48,605][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.549    [weighted Loss:2.549    Policy Loss: 5.576    Value Loss: 5.135    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 558634     Buffer Size: 22806      Transition Number: 1400.115k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:46:28,483][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 5.419    Value Loss: 5.332    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 559906     Buffer Size: 22833      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:50:07,322][train][INFO][train.py>_log] ==> #391000     Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 5.923    Value Loss: 4.957    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 561215     Buffer Size: 22853      Transition Number: 1399.972k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:53:43,747][train][INFO][train.py>_log] ==> #392000     Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 5.483    Value Loss: 4.899    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 562459     Buffer Size: 22867      Transition Number: 1400.356k Batch Size: 256        Lr: 0.10000 
[2022-01-24 14:57:20,777][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 5.103    Value Loss: 5.200    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 563785     Buffer Size: 22883      Transition Number: 1400.124k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:00:56,327][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 5.397    Value Loss: 4.759    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 565101     Buffer Size: 22942      Transition Number: 1400.253k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:04:34,496][train][INFO][train.py>_log] ==> #395000     Total Loss: 1.898    [weighted Loss:1.898    Policy Loss: 5.732    Value Loss: 4.599    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 566334     Buffer Size: 22955      Transition Number: 1399.948k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:08:11,891][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 6.313    Value Loss: 4.906    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 567642     Buffer Size: 22973      Transition Number: 1400.542k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:11:50,943][train][INFO][train.py>_log] ==> #397000     Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 5.520    Value Loss: 5.268    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 568961     Buffer Size: 22932      Transition Number: 1399.962k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:15:27,939][train][INFO][train.py>_log] ==> #398000     Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 5.270    Value Loss: 4.989    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 570194     Buffer Size: 22885      Transition Number: 1400.073k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:19:05,558][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 6.094    Value Loss: 4.967    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 571565     Buffer Size: 22850      Transition Number: 1400.069k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:22:44,820][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 6.418    Value Loss: 5.366    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 572802     Buffer Size: 22822      Transition Number: 1399.980k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:26:22,226][train][INFO][train.py>_log] ==> #401000     Total Loss: 1.937    [weighted Loss:1.937    Policy Loss: 5.503    Value Loss: 4.879    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 574190     Buffer Size: 22785      Transition Number: 1400.047k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:30:00,752][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 6.088    Value Loss: 4.956    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 575462     Buffer Size: 22758      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:33:37,414][train][INFO][train.py>_log] ==> #403000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 6.180    Value Loss: 5.250    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 576756     Buffer Size: 22759      Transition Number: 1400.057k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:37:13,790][train][INFO][train.py>_log] ==> #404000     Total Loss: 1.939    [weighted Loss:1.939    Policy Loss: 5.651    Value Loss: 5.686    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 578059     Buffer Size: 22750      Transition Number: 1399.979k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:40:51,162][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.058    [weighted Loss:2.058    Policy Loss: 5.307    Value Loss: 5.003    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 579298     Buffer Size: 22645      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:44:28,340][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 6.222    Value Loss: 4.716    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 580563     Buffer Size: 22560      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:48:07,079][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 5.308    Value Loss: 5.348    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 581862     Buffer Size: 22461      Transition Number: 1399.951k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:51:43,820][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.615    [weighted Loss:1.615    Policy Loss: 6.906    Value Loss: 5.216    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 583073     Buffer Size: 22402      Transition Number: 1400.411k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:55:21,282][train][INFO][train.py>_log] ==> #409000     Total Loss: 0.822    [weighted Loss:0.822    Policy Loss: 5.911    Value Loss: 4.994    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 584334     Buffer Size: 22339      Transition Number: 1399.962k Batch Size: 256        Lr: 0.10000 
[2022-01-24 15:59:00,879][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.938    [weighted Loss:2.938    Policy Loss: 5.945    Value Loss: 4.880    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 585555     Buffer Size: 22256      Transition Number: 1400.157k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:02:39,350][train][INFO][train.py>_log] ==> #411000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 6.822    Value Loss: 4.798    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 586960     Buffer Size: 22221      Transition Number: 1399.941k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:06:17,365][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.315    [weighted Loss:3.315    Policy Loss: 7.430    Value Loss: 4.908    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 588260     Buffer Size: 22207      Transition Number: 1400.067k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:09:55,864][train][INFO][train.py>_log] ==> #413000     Total Loss: 2.243    [weighted Loss:2.243    Policy Loss: 6.431    Value Loss: 5.491    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 589668     Buffer Size: 22373      Transition Number: 1399.996k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:13:32,642][train][INFO][train.py>_log] ==> #414000     Total Loss: 1.214    [weighted Loss:1.214    Policy Loss: 6.742    Value Loss: 5.190    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 591077     Buffer Size: 22558      Transition Number: 1400.123k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:17:08,671][train][INFO][train.py>_log] ==> #415000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 6.292    Value Loss: 5.471    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 592488     Buffer Size: 22661      Transition Number: 1400.131k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:20:47,188][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.359    [weighted Loss:1.359    Policy Loss: 5.962    Value Loss: 5.337    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 593810     Buffer Size: 22717      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:24:25,772][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 5.306    Value Loss: 5.149    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 595164     Buffer Size: 22721      Transition Number: 1400.012k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:28:04,071][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 5.873    Value Loss: 5.618    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 596399     Buffer Size: 22723      Transition Number: 1399.982k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:31:41,902][train][INFO][train.py>_log] ==> #419000     Total Loss: 1.563    [weighted Loss:1.563    Policy Loss: 5.488    Value Loss: 5.514    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 597818     Buffer Size: 22751      Transition Number: 1399.950k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:35:18,350][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.853    [weighted Loss:2.853    Policy Loss: 5.757    Value Loss: 5.087    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 599062     Buffer Size: 22789      Transition Number: 1399.983k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:38:56,119][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 5.699    Value Loss: 5.187    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 600329     Buffer Size: 22733      Transition Number: 1400.121k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:42:32,904][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 5.471    Value Loss: 5.167    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 601606     Buffer Size: 22714      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:46:09,622][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 5.746    Value Loss: 5.280    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 602850     Buffer Size: 22713      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:49:48,239][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 5.452    Value Loss: 5.430    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 604152     Buffer Size: 22726      Transition Number: 1399.962k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:53:25,409][train][INFO][train.py>_log] ==> #425000     Total Loss: 1.677    [weighted Loss:1.677    Policy Loss: 6.242    Value Loss: 5.280    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 605410     Buffer Size: 22766      Transition Number: 1399.934k Batch Size: 256        Lr: 0.10000 
[2022-01-24 16:57:01,280][train][INFO][train.py>_log] ==> #426000     Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 6.274    Value Loss: 5.410    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 606641     Buffer Size: 22804      Transition Number: 1400.064k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:00:39,226][train][INFO][train.py>_log] ==> #427000     Total Loss: 2.877    [weighted Loss:2.877    Policy Loss: 6.696    Value Loss: 5.073    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 607925     Buffer Size: 22857      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:04:16,432][train][INFO][train.py>_log] ==> #428000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 6.214    Value Loss: 5.102    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 609212     Buffer Size: 22853      Transition Number: 1399.934k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:07:53,456][train][INFO][train.py>_log] ==> #429000     Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 6.755    Value Loss: 5.166    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 610402     Buffer Size: 22835      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:11:31,129][train][INFO][train.py>_log] ==> #430000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 6.303    Value Loss: 5.429    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 611704     Buffer Size: 22740      Transition Number: 1400.046k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:15:09,568][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 6.289    Value Loss: 5.229    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 613044     Buffer Size: 22551      Transition Number: 1400.094k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:18:48,134][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 6.019    Value Loss: 5.218    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 614303     Buffer Size: 22413      Transition Number: 1400.047k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:22:26,555][train][INFO][train.py>_log] ==> #433000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 6.614    Value Loss: 5.594    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 615734     Buffer Size: 22477      Transition Number: 1399.953k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:26:05,614][train][INFO][train.py>_log] ==> #434000     Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 6.261    Value Loss: 5.379    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 617156     Buffer Size: 22608      Transition Number: 1400.031k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:29:41,679][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 7.104    Value Loss: 5.038    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 618459     Buffer Size: 22611      Transition Number: 1400.143k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:33:18,656][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.164    [weighted Loss:2.164    Policy Loss: 7.609    Value Loss: 5.078    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 619778     Buffer Size: 22581      Transition Number: 1400.201k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:36:55,070][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 5.906    Value Loss: 5.318    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 620994     Buffer Size: 22548      Transition Number: 1400.211k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:40:33,115][train][INFO][train.py>_log] ==> #438000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 7.063    Value Loss: 4.986    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 622352     Buffer Size: 22557      Transition Number: 1400.349k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:44:09,899][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 6.834    Value Loss: 5.009    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 623660     Buffer Size: 22610      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:47:49,622][train][INFO][train.py>_log] ==> #440000     Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 7.168    Value Loss: 5.159    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 624987     Buffer Size: 22659      Transition Number: 1399.968k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:51:27,442][train][INFO][train.py>_log] ==> #441000     Total Loss: 3.383    [weighted Loss:3.383    Policy Loss: 6.631    Value Loss: 5.792    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 626263     Buffer Size: 22669      Transition Number: 1399.978k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:55:06,042][train][INFO][train.py>_log] ==> #442000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 7.261    Value Loss: 4.837    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 627556     Buffer Size: 22672      Transition Number: 1400.209k Batch Size: 256        Lr: 0.10000 
[2022-01-24 17:58:43,774][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 7.154    Value Loss: 5.211    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 628840     Buffer Size: 22668      Transition Number: 1399.966k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:02:21,877][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 6.336    Value Loss: 4.909    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 630173     Buffer Size: 22670      Transition Number: 1400.101k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:05:59,441][train][INFO][train.py>_log] ==> #445000     Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 7.303    Value Loss: 4.755    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 631400     Buffer Size: 22687      Transition Number: 1400.011k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:09:38,380][train][INFO][train.py>_log] ==> #446000     Total Loss: 2.292    [weighted Loss:2.292    Policy Loss: 6.630    Value Loss: 5.017    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 632758     Buffer Size: 22686      Transition Number: 1400.051k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:13:16,448][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 7.388    Value Loss: 5.197    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 634060     Buffer Size: 22738      Transition Number: 1400.350k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:16:54,149][train][INFO][train.py>_log] ==> #448000     Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 7.895    Value Loss: 5.353    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 635389     Buffer Size: 22801      Transition Number: 1399.956k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:20:33,155][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 7.785    Value Loss: 5.560    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 636715     Buffer Size: 22877      Transition Number: 1400.025k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:24:10,468][train][INFO][train.py>_log] ==> #450000     Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 7.208    Value Loss: 5.105    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 638062     Buffer Size: 22865      Transition Number: 1400.306k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:27:47,537][train][INFO][train.py>_log] ==> #451000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 6.814    Value Loss: 5.851    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 639377     Buffer Size: 22748      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:31:24,990][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 6.826    Value Loss: 5.043    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 640700     Buffer Size: 22718      Transition Number: 1399.999k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:35:02,022][train][INFO][train.py>_log] ==> #453000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 6.626    Value Loss: 5.101    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 642018     Buffer Size: 22791      Transition Number: 1400.314k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:38:40,349][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 6.412    Value Loss: 5.360    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 643392     Buffer Size: 22882      Transition Number: 1399.953k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:42:18,940][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 7.485    Value Loss: 5.586    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 644714     Buffer Size: 22893      Transition Number: 1400.248k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:45:55,239][train][INFO][train.py>_log] ==> #456000     Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 7.231    Value Loss: 5.190    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 645993     Buffer Size: 22883      Transition Number: 1400.248k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:49:33,001][train][INFO][train.py>_log] ==> #457000     Total Loss: 3.135    [weighted Loss:3.135    Policy Loss: 7.851    Value Loss: 5.119    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 647456     Buffer Size: 23033      Transition Number: 1399.959k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:53:10,555][train][INFO][train.py>_log] ==> #458000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 7.322    Value Loss: 5.110    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 648889     Buffer Size: 23199      Transition Number: 1399.942k Batch Size: 256        Lr: 0.10000 
[2022-01-24 18:56:46,708][train][INFO][train.py>_log] ==> #459000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 6.676    Value Loss: 5.769    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 650356     Buffer Size: 23408      Transition Number: 1400.337k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:00:23,978][train][INFO][train.py>_log] ==> #460000     Total Loss: 3.587    [weighted Loss:3.587    Policy Loss: 7.410    Value Loss: 5.790    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 651702     Buffer Size: 23594      Transition Number: 1400.005k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:04:00,674][train][INFO][train.py>_log] ==> #461000     Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 6.849    Value Loss: 5.910    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 653014     Buffer Size: 23668      Transition Number: 1400.369k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:07:38,681][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.742    [weighted Loss:2.742    Policy Loss: 6.926    Value Loss: 5.701    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 654347     Buffer Size: 23735      Transition Number: 1399.931k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:11:15,602][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 7.692    Value Loss: 5.817    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 655605     Buffer Size: 23777      Transition Number: 1400.003k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:14:52,595][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 7.273    Value Loss: 5.242    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 656926     Buffer Size: 23785      Transition Number: 1399.938k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:18:30,100][train][INFO][train.py>_log] ==> #465000     Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 6.366    Value Loss: 5.600    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 658299     Buffer Size: 23872      Transition Number: 1400.070k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:22:08,497][train][INFO][train.py>_log] ==> #466000     Total Loss: 3.880    [weighted Loss:3.880    Policy Loss: 7.533    Value Loss: 5.671    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 659655     Buffer Size: 23933      Transition Number: 1400.014k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:25:44,747][train][INFO][train.py>_log] ==> #467000     Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 6.313    Value Loss: 5.905    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 661571     Buffer Size: 24496      Transition Number: 1400.215k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:29:22,148][train][INFO][train.py>_log] ==> #468000     Total Loss: 3.346    [weighted Loss:3.346    Policy Loss: 6.218    Value Loss: 5.751    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 663495     Buffer Size: 25097      Transition Number: 1400.049k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:32:56,836][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.460    [weighted Loss:2.460    Policy Loss: 7.058    Value Loss: 5.315    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 664818     Buffer Size: 25222      Transition Number: 1400.192k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:36:32,538][train][INFO][train.py>_log] ==> #470000     Total Loss: 2.935    [weighted Loss:2.935    Policy Loss: 7.002    Value Loss: 5.831    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 666199     Buffer Size: 25288      Transition Number: 1399.945k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:40:07,087][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.756    [weighted Loss:2.756    Policy Loss: 6.470    Value Loss: 5.733    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 667507     Buffer Size: 25264      Transition Number: 1400.026k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:43:44,904][train][INFO][train.py>_log] ==> #472000     Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 6.429    Value Loss: 5.439    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 668745     Buffer Size: 25224      Transition Number: 1400.074k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:47:24,971][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 6.265    Value Loss: 5.577    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 670073     Buffer Size: 25201      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:51:02,021][train][INFO][train.py>_log] ==> #474000     Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 6.630    Value Loss: 5.397    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 671294     Buffer Size: 25189      Transition Number: 1400.034k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:54:39,811][train][INFO][train.py>_log] ==> #475000     Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 6.808    Value Loss: 5.099    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 672629     Buffer Size: 24986      Transition Number: 1400.294k Batch Size: 256        Lr: 0.10000 
[2022-01-24 19:58:19,587][train][INFO][train.py>_log] ==> #476000     Total Loss: 3.445    [weighted Loss:3.445    Policy Loss: 6.542    Value Loss: 5.030    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 673957     Buffer Size: 24802      Transition Number: 1400.544k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:01:56,884][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 6.863    Value Loss: 5.065    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 675235     Buffer Size: 24624      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:05:33,108][train][INFO][train.py>_log] ==> #478000     Total Loss: 3.121    [weighted Loss:3.121    Policy Loss: 6.598    Value Loss: 5.158    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 676492     Buffer Size: 24511      Transition Number: 1401.025k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:09:09,601][train][INFO][train.py>_log] ==> #479000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 6.983    Value Loss: 5.029    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 677820     Buffer Size: 24464      Transition Number: 1399.979k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:12:45,678][train][INFO][train.py>_log] ==> #480000     Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 6.542    Value Loss: 5.245    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 679061     Buffer Size: 24445      Transition Number: 1399.965k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:16:22,487][train][INFO][train.py>_log] ==> #481000     Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 7.007    Value Loss: 5.185    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 680387     Buffer Size: 24426      Transition Number: 1399.982k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:19:58,971][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 6.508    Value Loss: 5.263    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 681601     Buffer Size: 24410      Transition Number: 1400.031k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:23:35,008][train][INFO][train.py>_log] ==> #483000     Total Loss: 3.815    [weighted Loss:3.815    Policy Loss: 7.094    Value Loss: 4.946    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 682848     Buffer Size: 24330      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:27:12,904][train][INFO][train.py>_log] ==> #484000     Total Loss: 3.189    [weighted Loss:3.189    Policy Loss: 6.897    Value Loss: 5.408    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 684178     Buffer Size: 24141      Transition Number: 1400.177k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:30:49,015][train][INFO][train.py>_log] ==> #485000     Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 6.643    Value Loss: 5.277    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 685452     Buffer Size: 23493      Transition Number: 1399.964k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:34:25,538][train][INFO][train.py>_log] ==> #486000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 6.996    Value Loss: 4.974    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 686731     Buffer Size: 22957      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:38:04,712][train][INFO][train.py>_log] ==> #487000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 7.081    Value Loss: 4.823    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 688048     Buffer Size: 22876      Transition Number: 1400.016k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:41:45,165][train][INFO][train.py>_log] ==> #488000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 7.598    Value Loss: 5.334    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 689393     Buffer Size: 22817      Transition Number: 1400.015k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:45:22,807][train][INFO][train.py>_log] ==> #489000     Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 6.974    Value Loss: 5.097    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 690826     Buffer Size: 22897      Transition Number: 1400.027k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:49:01,146][train][INFO][train.py>_log] ==> #490000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 7.751    Value Loss: 5.240    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 692227     Buffer Size: 22980      Transition Number: 1400.082k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:52:36,686][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.848    [weighted Loss:2.848    Policy Loss: 7.680    Value Loss: 5.030    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 693906     Buffer Size: 23400      Transition Number: 1400.106k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:56:12,666][train][INFO][train.py>_log] ==> #492000     Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 7.044    Value Loss: 5.726    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 695568     Buffer Size: 23849      Transition Number: 1400.023k Batch Size: 256        Lr: 0.10000 
[2022-01-24 20:59:47,154][train][INFO][train.py>_log] ==> #493000     Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 6.397    Value Loss: 5.373    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 696963     Buffer Size: 23998      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:03:24,017][train][INFO][train.py>_log] ==> #494000     Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 7.205    Value Loss: 5.536    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 698323     Buffer Size: 24142      Transition Number: 1399.943k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:06:59,870][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.850    [weighted Loss:2.850    Policy Loss: 7.064    Value Loss: 5.508    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 699650     Buffer Size: 24231      Transition Number: 1400.359k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:10:37,456][train][INFO][train.py>_log] ==> #496000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 7.024    Value Loss: 5.517    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 700988     Buffer Size: 24287      Transition Number: 1400.207k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:14:14,626][train][INFO][train.py>_log] ==> #497000     Total Loss: 1.387    [weighted Loss:1.387    Policy Loss: 6.829    Value Loss: 5.605    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 702362     Buffer Size: 24319      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:17:51,408][train][INFO][train.py>_log] ==> #498000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 6.366    Value Loss: 5.622    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 703621     Buffer Size: 24373      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:21:29,142][train][INFO][train.py>_log] ==> #499000     Total Loss: 1.687    [weighted Loss:1.687    Policy Loss: 6.465    Value Loss: 5.719    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 705166     Buffer Size: 24567      Transition Number: 1400.249k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:25:06,815][train][INFO][train.py>_log] ==> #500000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 6.206    Value Loss: 5.650    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 706583     Buffer Size: 24744      Transition Number: 1400.018k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:28:44,941][train][INFO][train.py>_log] ==> #501000     Total Loss: 2.583    [weighted Loss:2.583    Policy Loss: 6.478    Value Loss: 5.729    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 707981     Buffer Size: 24832      Transition Number: 1400.207k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:32:21,858][train][INFO][train.py>_log] ==> #502000     Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 6.910    Value Loss: 5.600    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 709383     Buffer Size: 24898      Transition Number: 1399.970k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:36:00,535][train][INFO][train.py>_log] ==> #503000     Total Loss: 1.671    [weighted Loss:1.671    Policy Loss: 6.485    Value Loss: 5.582    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 710600     Buffer Size: 24906      Transition Number: 1400.312k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:39:39,208][train][INFO][train.py>_log] ==> #504000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 7.362    Value Loss: 5.480    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 711891     Buffer Size: 24910      Transition Number: 1399.940k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:43:18,805][train][INFO][train.py>_log] ==> #505000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 6.161    Value Loss: 5.118    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 713256     Buffer Size: 24830      Transition Number: 1399.985k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:46:58,648][train][INFO][train.py>_log] ==> #506000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 7.461    Value Loss: 5.487    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 714555     Buffer Size: 24756      Transition Number: 1400.006k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:50:36,099][train][INFO][train.py>_log] ==> #507000     Total Loss: 2.597    [weighted Loss:2.597    Policy Loss: 6.679    Value Loss: 5.050    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 715899     Buffer Size: 24641      Transition Number: 1399.993k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:54:14,312][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 7.000    Value Loss: 5.320    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 717172     Buffer Size: 24501      Transition Number: 1399.941k Batch Size: 256        Lr: 0.10000 
[2022-01-24 21:57:49,713][train][INFO][train.py>_log] ==> #509000     Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 6.526    Value Loss: 5.571    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 718504     Buffer Size: 24207      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:01:28,127][train][INFO][train.py>_log] ==> #510000     Total Loss: 2.959    [weighted Loss:2.959    Policy Loss: 7.230    Value Loss: 4.841    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 719902     Buffer Size: 23917      Transition Number: 1400.012k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:05:07,398][train][INFO][train.py>_log] ==> #511000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 7.057    Value Loss: 5.459    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 721184     Buffer Size: 23803      Transition Number: 1399.968k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:08:47,261][train][INFO][train.py>_log] ==> #512000     Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 6.359    Value Loss: 5.193    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 722519     Buffer Size: 23707      Transition Number: 1399.951k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:12:24,685][train][INFO][train.py>_log] ==> #513000     Total Loss: 2.891    [weighted Loss:2.891    Policy Loss: 7.543    Value Loss: 5.248    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 723900     Buffer Size: 23633      Transition Number: 1400.028k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:16:02,207][train][INFO][train.py>_log] ==> #514000     Total Loss: 0.808    [weighted Loss:0.808    Policy Loss: 8.237    Value Loss: 5.047    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 725156     Buffer Size: 23613      Transition Number: 1400.070k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:19:38,177][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.779    [weighted Loss:2.779    Policy Loss: 7.059    Value Loss: 5.631    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 726895     Buffer Size: 23933      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:23:15,094][train][INFO][train.py>_log] ==> #516000     Total Loss: 3.597    [weighted Loss:3.597    Policy Loss: 7.606    Value Loss: 5.851    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 728605     Buffer Size: 24257      Transition Number: 1399.970k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:26:52,067][train][INFO][train.py>_log] ==> #517000     Total Loss: 3.867    [weighted Loss:3.867    Policy Loss: 7.358    Value Loss: 5.541    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 730053     Buffer Size: 24246      Transition Number: 1400.047k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:30:29,151][train][INFO][train.py>_log] ==> #518000     Total Loss: 3.284    [weighted Loss:3.284    Policy Loss: 7.505    Value Loss: 5.409    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 731552     Buffer Size: 24239      Transition Number: 1399.958k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:34:07,834][train][INFO][train.py>_log] ==> #519000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 7.657    Value Loss: 5.204    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 732776     Buffer Size: 24182      Transition Number: 1400.012k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:37:44,743][train][INFO][train.py>_log] ==> #520000     Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 7.923    Value Loss: 5.635    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 734066     Buffer Size: 24157      Transition Number: 1400.026k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:41:21,040][train][INFO][train.py>_log] ==> #521000     Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 8.265    Value Loss: 5.814    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 735491     Buffer Size: 24199      Transition Number: 1400.068k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:44:58,834][train][INFO][train.py>_log] ==> #522000     Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 7.818    Value Loss: 5.325    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 736736     Buffer Size: 24268      Transition Number: 1399.950k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:48:36,153][train][INFO][train.py>_log] ==> #523000     Total Loss: 2.519    [weighted Loss:2.519    Policy Loss: 8.276    Value Loss: 5.706    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 738213     Buffer Size: 24407      Transition Number: 1399.999k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:52:13,158][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.158    [weighted Loss:2.158    Policy Loss: 7.120    Value Loss: 6.084    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 739590     Buffer Size: 24531      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:55:48,221][train][INFO][train.py>_log] ==> #525000     Total Loss: 3.835    [weighted Loss:3.835    Policy Loss: 8.337    Value Loss: 5.743    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 740913     Buffer Size: 24572      Transition Number: 1400.112k Batch Size: 256        Lr: 0.10000 
[2022-01-24 22:59:24,671][train][INFO][train.py>_log] ==> #526000     Total Loss: 3.185    [weighted Loss:3.185    Policy Loss: 7.915    Value Loss: 5.340    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 742287     Buffer Size: 24592      Transition Number: 1399.993k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:03:01,720][train][INFO][train.py>_log] ==> #527000     Total Loss: 0.653    [weighted Loss:0.653    Policy Loss: 6.846    Value Loss: 5.446    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 743643     Buffer Size: 24587      Transition Number: 1400.040k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:06:41,169][train][INFO][train.py>_log] ==> #528000     Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 8.067    Value Loss: 5.544    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 745118     Buffer Size: 24623      Transition Number: 1400.061k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:10:18,410][train][INFO][train.py>_log] ==> #529000     Total Loss: 3.137    [weighted Loss:3.137    Policy Loss: 8.332    Value Loss: 5.897    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 746563     Buffer Size: 24839      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:13:53,459][train][INFO][train.py>_log] ==> #530000     Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 7.761    Value Loss: 5.481    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 748069     Buffer Size: 25062      Transition Number: 1400.154k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:17:29,968][train][INFO][train.py>_log] ==> #531000     Total Loss: 2.619    [weighted Loss:2.619    Policy Loss: 8.322    Value Loss: 5.442    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 749404     Buffer Size: 25205      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:21:07,291][train][INFO][train.py>_log] ==> #532000     Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 7.668    Value Loss: 5.664    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 750840     Buffer Size: 25285      Transition Number: 1400.061k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:24:45,105][train][INFO][train.py>_log] ==> #533000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 7.229    Value Loss: 5.403    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 752234     Buffer Size: 24834      Transition Number: 1399.996k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:28:21,399][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.425    [weighted Loss:2.425    Policy Loss: 7.123    Value Loss: 5.627    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 753492     Buffer Size: 24525      Transition Number: 1399.951k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:32:00,969][train][INFO][train.py>_log] ==> #535000     Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 7.067    Value Loss: 5.302    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 754753     Buffer Size: 24414      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:35:37,613][train][INFO][train.py>_log] ==> #536000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 6.508    Value Loss: 5.483    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 756108     Buffer Size: 24279      Transition Number: 1400.288k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:39:13,626][train][INFO][train.py>_log] ==> #537000     Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 6.897    Value Loss: 5.782    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 757456     Buffer Size: 24340      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:42:49,950][train][INFO][train.py>_log] ==> #538000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 6.636    Value Loss: 5.521    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 758781     Buffer Size: 24425      Transition Number: 1399.946k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:46:25,364][train][INFO][train.py>_log] ==> #539000     Total Loss: 2.786    [weighted Loss:2.786    Policy Loss: 6.942    Value Loss: 5.643    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 760449     Buffer Size: 24774      Transition Number: 1399.950k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:50:01,838][train][INFO][train.py>_log] ==> #540000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 7.167    Value Loss: 5.659    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 762066     Buffer Size: 25091      Transition Number: 1400.162k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:53:39,990][train][INFO][train.py>_log] ==> #541000     Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 7.202    Value Loss: 5.883    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 763656     Buffer Size: 25299      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-24 23:57:17,241][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 6.927    Value Loss: 5.920    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 765245     Buffer Size: 25534      Transition Number: 1400.114k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:00:54,683][train][INFO][train.py>_log] ==> #543000     Total Loss: 1.714    [weighted Loss:1.714    Policy Loss: 6.641    Value Loss: 5.630    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 766654     Buffer Size: 25628      Transition Number: 1399.999k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:04:31,560][train][INFO][train.py>_log] ==> #544000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 6.431    Value Loss: 5.749    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 768065     Buffer Size: 25703      Transition Number: 1400.097k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:08:09,426][train][INFO][train.py>_log] ==> #545000     Total Loss: 3.970    [weighted Loss:3.970    Policy Loss: 7.352    Value Loss: 5.764    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 769440     Buffer Size: 25717      Transition Number: 1400.108k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:11:47,735][train][INFO][train.py>_log] ==> #546000     Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 6.408    Value Loss: 5.413    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 770849     Buffer Size: 25714      Transition Number: 1400.146k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:15:23,424][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 7.448    Value Loss: 5.466    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 772129     Buffer Size: 25557      Transition Number: 1400.049k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:19:00,385][train][INFO][train.py>_log] ==> #548000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 6.844    Value Loss: 5.811    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 773319     Buffer Size: 25417      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:22:36,969][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 6.566    Value Loss: 5.716    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 774693     Buffer Size: 25342      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:26:13,932][train][INFO][train.py>_log] ==> #550000     Total Loss: 3.770    [weighted Loss:3.770    Policy Loss: 7.085    Value Loss: 5.627    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 776059     Buffer Size: 25283      Transition Number: 1400.049k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:29:51,226][train][INFO][train.py>_log] ==> #551000     Total Loss: 1.612    [weighted Loss:1.612    Policy Loss: 6.458    Value Loss: 5.484    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 777366     Buffer Size: 25292      Transition Number: 1400.096k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:33:26,961][train][INFO][train.py>_log] ==> #552000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 6.869    Value Loss: 5.219    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 778612     Buffer Size: 25315      Transition Number: 1399.944k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:37:02,609][train][INFO][train.py>_log] ==> #553000     Total Loss: 2.627    [weighted Loss:2.627    Policy Loss: 6.449    Value Loss: 6.088    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 780027     Buffer Size: 25483      Transition Number: 1400.089k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:40:37,848][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 6.758    Value Loss: 6.083    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 781453     Buffer Size: 25648      Transition Number: 1400.019k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:44:14,662][train][INFO][train.py>_log] ==> #555000     Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 6.545    Value Loss: 5.809    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 782756     Buffer Size: 25619      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:47:50,584][train][INFO][train.py>_log] ==> #556000     Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 6.387    Value Loss: 5.793    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 784080     Buffer Size: 25594      Transition Number: 1400.258k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:51:30,354][train][INFO][train.py>_log] ==> #557000     Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 6.848    Value Loss: 5.602    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 785377     Buffer Size: 25290      Transition Number: 1400.107k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:55:07,675][train][INFO][train.py>_log] ==> #558000     Total Loss: 3.034    [weighted Loss:3.034    Policy Loss: 6.146    Value Loss: 5.303    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 786653     Buffer Size: 24980      Transition Number: 1399.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 00:58:43,987][train][INFO][train.py>_log] ==> #559000     Total Loss: 2.714    [weighted Loss:2.714    Policy Loss: 6.959    Value Loss: 5.438    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 787975     Buffer Size: 24724      Transition Number: 1400.051k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:02:20,024][train][INFO][train.py>_log] ==> #560000     Total Loss: 0.919    [weighted Loss:0.919    Policy Loss: 7.153    Value Loss: 5.375    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 789323     Buffer Size: 24462      Transition Number: 1400.133k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:05:55,137][train][INFO][train.py>_log] ==> #561000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 7.166    Value Loss: 5.754    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 790741     Buffer Size: 24434      Transition Number: 1400.113k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:09:30,741][train][INFO][train.py>_log] ==> #562000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 6.884    Value Loss: 5.254    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 792089     Buffer Size: 24493      Transition Number: 1400.035k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:13:07,735][train][INFO][train.py>_log] ==> #563000     Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 7.154    Value Loss: 6.019    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 793423     Buffer Size: 24518      Transition Number: 1399.960k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:16:44,672][train][INFO][train.py>_log] ==> #564000     Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 7.251    Value Loss: 6.029    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 794776     Buffer Size: 24563      Transition Number: 1399.960k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:20:21,529][train][INFO][train.py>_log] ==> #565000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 7.166    Value Loss: 5.600    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 796338     Buffer Size: 24802      Transition Number: 1400.052k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:23:58,223][train][INFO][train.py>_log] ==> #566000     Total Loss: 2.443    [weighted Loss:2.443    Policy Loss: 6.511    Value Loss: 5.657    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 797892     Buffer Size: 25083      Transition Number: 1400.059k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:27:32,678][train][INFO][train.py>_log] ==> #567000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 6.788    Value Loss: 5.624    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 799224     Buffer Size: 25109      Transition Number: 1399.993k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:31:09,788][train][INFO][train.py>_log] ==> #568000     Total Loss: 2.683    [weighted Loss:2.683    Policy Loss: 6.907    Value Loss: 5.434    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 800568     Buffer Size: 25133      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:34:44,637][train][INFO][train.py>_log] ==> #569000     Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 7.458    Value Loss: 5.325    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 802004     Buffer Size: 25310      Transition Number: 1400.073k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:38:21,080][train][INFO][train.py>_log] ==> #570000     Total Loss: 3.156    [weighted Loss:3.156    Policy Loss: 6.894    Value Loss: 5.927    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 803474     Buffer Size: 25481      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:41:56,513][train][INFO][train.py>_log] ==> #571000     Total Loss: 3.938    [weighted Loss:3.938    Policy Loss: 7.039    Value Loss: 5.951    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 805160     Buffer Size: 25790      Transition Number: 1400.092k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:45:32,657][train][INFO][train.py>_log] ==> #572000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 6.804    Value Loss: 6.250    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 806880     Buffer Size: 26042      Transition Number: 1400.053k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:49:09,436][train][INFO][train.py>_log] ==> #573000     Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 6.432    Value Loss: 5.884    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 808198     Buffer Size: 26024      Transition Number: 1400.018k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:52:46,588][train][INFO][train.py>_log] ==> #574000     Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 6.364    Value Loss: 5.993    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 809586     Buffer Size: 26054      Transition Number: 1400.096k Batch Size: 256        Lr: 0.10000 
[2022-01-25 01:56:23,310][train][INFO][train.py>_log] ==> #575000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 6.692    Value Loss: 5.726    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 810827     Buffer Size: 26077      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:00:00,077][train][INFO][train.py>_log] ==> #576000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 7.038    Value Loss: 5.568    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 812177     Buffer Size: 26085      Transition Number: 1400.153k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:03:36,265][train][INFO][train.py>_log] ==> #577000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 6.813    Value Loss: 5.690    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 813477     Buffer Size: 26055      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:07:13,672][train][INFO][train.py>_log] ==> #578000     Total Loss: 2.143    [weighted Loss:2.143    Policy Loss: 7.118    Value Loss: 5.394    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 814792     Buffer Size: 26055      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:10:50,814][train][INFO][train.py>_log] ==> #579000     Total Loss: 3.082    [weighted Loss:3.082    Policy Loss: 6.172    Value Loss: 5.628    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 816156     Buffer Size: 25991      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:14:26,904][train][INFO][train.py>_log] ==> #580000     Total Loss: 3.134    [weighted Loss:3.134    Policy Loss: 6.538    Value Loss: 5.580    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 817522     Buffer Size: 25905      Transition Number: 1399.969k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:18:05,426][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.185    [weighted Loss:3.185    Policy Loss: 6.396    Value Loss: 5.607    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 818899     Buffer Size: 25869      Transition Number: 1400.011k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:21:43,216][train][INFO][train.py>_log] ==> #582000     Total Loss: 2.412    [weighted Loss:2.412    Policy Loss: 7.139    Value Loss: 5.485    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 820286     Buffer Size: 25832      Transition Number: 1400.074k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:25:21,196][train][INFO][train.py>_log] ==> #583000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 6.896    Value Loss: 5.625    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 821600     Buffer Size: 25684      Transition Number: 1399.982k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:28:57,324][train][INFO][train.py>_log] ==> #584000     Total Loss: 3.818    [weighted Loss:3.818    Policy Loss: 7.067    Value Loss: 5.927    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 822936     Buffer Size: 25454      Transition Number: 1400.044k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:32:34,552][train][INFO][train.py>_log] ==> #585000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 6.297    Value Loss: 5.612    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 824405     Buffer Size: 25456      Transition Number: 1400.123k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:36:10,289][train][INFO][train.py>_log] ==> #586000     Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 6.063    Value Loss: 5.793    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 825815     Buffer Size: 25522      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:39:46,537][train][INFO][train.py>_log] ==> #587000     Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 6.910    Value Loss: 5.495    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 827096     Buffer Size: 25359      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:43:25,075][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.846    [weighted Loss:2.846    Policy Loss: 7.740    Value Loss: 6.035    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 828426     Buffer Size: 25157      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:47:02,587][train][INFO][train.py>_log] ==> #589000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 7.079    Value Loss: 5.371    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 829733     Buffer Size: 24824      Transition Number: 1399.967k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:50:38,860][train][INFO][train.py>_log] ==> #590000     Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 7.295    Value Loss: 5.284    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 831040     Buffer Size: 24452      Transition Number: 1399.947k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:54:14,091][train][INFO][train.py>_log] ==> #591000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 7.004    Value Loss: 5.318    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 832587     Buffer Size: 24599      Transition Number: 1400.409k Batch Size: 256        Lr: 0.10000 
[2022-01-25 02:57:51,942][train][INFO][train.py>_log] ==> #592000     Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 7.253    Value Loss: 5.521    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 834154     Buffer Size: 24783      Transition Number: 1400.014k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:01:28,365][train][INFO][train.py>_log] ==> #593000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 7.791    Value Loss: 5.489    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 835584     Buffer Size: 24911      Transition Number: 1399.957k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:05:02,820][train][INFO][train.py>_log] ==> #594000     Total Loss: 1.779    [weighted Loss:1.779    Policy Loss: 6.602    Value Loss: 5.817    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 837022     Buffer Size: 25058      Transition Number: 1399.937k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:08:39,510][train][INFO][train.py>_log] ==> #595000     Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 6.802    Value Loss: 5.785    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 838445     Buffer Size: 25164      Transition Number: 1400.116k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:12:14,922][train][INFO][train.py>_log] ==> #596000     Total Loss: 2.670    [weighted Loss:2.670    Policy Loss: 6.750    Value Loss: 5.735    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 839774     Buffer Size: 25251      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:15:51,549][train][INFO][train.py>_log] ==> #597000     Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 6.417    Value Loss: 5.722    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 841079     Buffer Size: 25260      Transition Number: 1399.981k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:19:27,317][train][INFO][train.py>_log] ==> #598000     Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 6.971    Value Loss: 6.020    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 842463     Buffer Size: 25245      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:23:03,096][train][INFO][train.py>_log] ==> #599000     Total Loss: 2.084    [weighted Loss:2.084    Policy Loss: 6.451    Value Loss: 5.697    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 843910     Buffer Size: 25334      Transition Number: 1400.076k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:26:36,949][train][INFO][train.py>_log] ==> #600000     Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 6.398    Value Loss: 5.584    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 845388     Buffer Size: 25460      Transition Number: 1400.074k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:30:12,670][train][INFO][train.py>_log] ==> #601000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 6.418    Value Loss: 5.946    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 846770     Buffer Size: 25483      Transition Number: 1400.083k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:33:49,672][train][INFO][train.py>_log] ==> #602000     Total Loss: 2.614    [weighted Loss:2.614    Policy Loss: 6.571    Value Loss: 5.638    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 848154     Buffer Size: 25510      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:37:24,452][train][INFO][train.py>_log] ==> #603000     Total Loss: 2.597    [weighted Loss:2.597    Policy Loss: 6.803    Value Loss: 5.702    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 849448     Buffer Size: 25481      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:41:01,904][train][INFO][train.py>_log] ==> #604000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 7.019    Value Loss: 5.716    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 850745     Buffer Size: 25386      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:44:37,697][train][INFO][train.py>_log] ==> #605000     Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 6.449    Value Loss: 5.869    Reward Loss: 1.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 852241     Buffer Size: 25493      Transition Number: 1400.159k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:48:12,391][train][INFO][train.py>_log] ==> #606000     Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 6.830    Value Loss: 6.336    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 853673     Buffer Size: 25618      Transition Number: 1399.947k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:51:46,843][train][INFO][train.py>_log] ==> #607000     Total Loss: 2.758    [weighted Loss:2.758    Policy Loss: 6.531    Value Loss: 5.637    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 855068     Buffer Size: 25722      Transition Number: 1400.052k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:55:23,659][train][INFO][train.py>_log] ==> #608000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 6.789    Value Loss: 5.932    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 856490     Buffer Size: 25847      Transition Number: 1399.979k Batch Size: 256        Lr: 0.10000 
[2022-01-25 03:59:02,110][train][INFO][train.py>_log] ==> #609000     Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 6.955    Value Loss: 6.108    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 857730     Buffer Size: 25733      Transition Number: 1399.993k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:02:39,885][train][INFO][train.py>_log] ==> #610000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 6.638    Value Loss: 5.691    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 859063     Buffer Size: 25530      Transition Number: 1400.079k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:06:15,556][train][INFO][train.py>_log] ==> #611000     Total Loss: 1.838    [weighted Loss:1.838    Policy Loss: 6.581    Value Loss: 5.850    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 860443     Buffer Size: 25421      Transition Number: 1400.056k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:09:50,417][train][INFO][train.py>_log] ==> #612000     Total Loss: 2.756    [weighted Loss:2.756    Policy Loss: 6.954    Value Loss: 5.835    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 861824     Buffer Size: 25347      Transition Number: 1400.002k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:13:25,878][train][INFO][train.py>_log] ==> #613000     Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 6.334    Value Loss: 5.812    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 863213     Buffer Size: 25328      Transition Number: 1400.020k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:17:00,019][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.735    [weighted Loss:2.735    Policy Loss: 6.375    Value Loss: 5.779    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 864569     Buffer Size: 25343      Transition Number: 1400.033k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:20:34,397][train][INFO][train.py>_log] ==> #615000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 6.502    Value Loss: 6.139    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 866181     Buffer Size: 25552      Transition Number: 1399.979k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:24:08,220][train][INFO][train.py>_log] ==> #616000     Total Loss: 3.438    [weighted Loss:3.438    Policy Loss: 7.068    Value Loss: 5.860    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 867731     Buffer Size: 25790      Transition Number: 1399.986k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:27:45,078][train][INFO][train.py>_log] ==> #617000     Total Loss: 0.995    [weighted Loss:0.995    Policy Loss: 6.661    Value Loss: 6.021    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 869293     Buffer Size: 25961      Transition Number: 1399.980k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:31:20,814][train][INFO][train.py>_log] ==> #618000     Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 6.501    Value Loss: 5.945    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 870832     Buffer Size: 26060      Transition Number: 1400.028k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:34:58,036][train][INFO][train.py>_log] ==> #619000     Total Loss: 2.651    [weighted Loss:2.651    Policy Loss: 6.405    Value Loss: 6.058    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 872287     Buffer Size: 26033      Transition Number: 1399.974k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:38:34,681][train][INFO][train.py>_log] ==> #620000     Total Loss: 2.819    [weighted Loss:2.819    Policy Loss: 8.251    Value Loss: 5.623    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 873681     Buffer Size: 26072      Transition Number: 1400.299k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:42:10,618][train][INFO][train.py>_log] ==> #621000     Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 6.684    Value Loss: 5.872    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 875268     Buffer Size: 26177      Transition Number: 1400.087k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:45:46,398][train][INFO][train.py>_log] ==> #622000     Total Loss: 2.897    [weighted Loss:2.897    Policy Loss: 6.335    Value Loss: 5.971    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 876781     Buffer Size: 26334      Transition Number: 1400.022k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:49:21,371][train][INFO][train.py>_log] ==> #623000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 6.618    Value Loss: 5.862    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 878218     Buffer Size: 26430      Transition Number: 1399.957k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:52:55,572][train][INFO][train.py>_log] ==> #624000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 6.757    Value Loss: 6.100    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 879671     Buffer Size: 26529      Transition Number: 1400.204k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:56:32,121][train][INFO][train.py>_log] ==> #625000     Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 7.239    Value Loss: 5.768    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 881080     Buffer Size: 26460      Transition Number: 1400.125k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:00:08,990][train][INFO][train.py>_log] ==> #626000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 5.859    Value Loss: 5.903    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 882360     Buffer Size: 26420      Transition Number: 1400.052k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:03:45,107][train][INFO][train.py>_log] ==> #627000     Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 6.838    Value Loss: 5.868    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 883776     Buffer Size: 26442      Transition Number: 1400.151k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:07:21,601][train][INFO][train.py>_log] ==> #628000     Total Loss: 3.285    [weighted Loss:3.285    Policy Loss: 6.426    Value Loss: 6.180    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 885183     Buffer Size: 26512      Transition Number: 1399.980k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:10:58,858][train][INFO][train.py>_log] ==> #629000     Total Loss: 3.340    [weighted Loss:3.340    Policy Loss: 6.713    Value Loss: 6.165    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 886510     Buffer Size: 26589      Transition Number: 1400.077k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:14:35,660][train][INFO][train.py>_log] ==> #630000     Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 5.753    Value Loss: 6.283    Reward Loss: 1.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 887935     Buffer Size: 26627      Transition Number: 1400.028k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:18:13,224][train][INFO][train.py>_log] ==> #631000     Total Loss: 2.054    [weighted Loss:2.054    Policy Loss: 6.669    Value Loss: 5.942    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 889272     Buffer Size: 26537      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:21:48,687][train][INFO][train.py>_log] ==> #632000     Total Loss: 1.807    [weighted Loss:1.807    Policy Loss: 6.898    Value Loss: 5.632    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 890573     Buffer Size: 26463      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:25:25,809][train][INFO][train.py>_log] ==> #633000     Total Loss: 3.446    [weighted Loss:3.446    Policy Loss: 6.416    Value Loss: 5.863    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 892035     Buffer Size: 26381      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:29:01,408][train][INFO][train.py>_log] ==> #634000     Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 7.596    Value Loss: 5.909    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 893411     Buffer Size: 26259      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:32:36,672][train][INFO][train.py>_log] ==> #635000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 6.835    Value Loss: 6.100    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 894931     Buffer Size: 26219      Transition Number: 1399.983k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:36:11,754][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 6.469    Value Loss: 5.673    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 896497     Buffer Size: 26227      Transition Number: 1399.938k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:39:47,471][train][INFO][train.py>_log] ==> #637000     Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 6.652    Value Loss: 5.847    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 898004     Buffer Size: 26245      Transition Number: 1400.017k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:43:24,609][train][INFO][train.py>_log] ==> #638000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 6.571    Value Loss: 6.011    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 899452     Buffer Size: 26364      Transition Number: 1400.144k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:47:01,470][train][INFO][train.py>_log] ==> #639000     Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 6.672    Value Loss: 6.055    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 900870     Buffer Size: 26285      Transition Number: 1400.038k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:50:39,153][train][INFO][train.py>_log] ==> #640000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 6.809    Value Loss: 6.109    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 902250     Buffer Size: 26205      Transition Number: 1400.049k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:54:15,111][train][INFO][train.py>_log] ==> #641000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 6.131    Value Loss: 6.028    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 903605     Buffer Size: 26077      Transition Number: 1399.966k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:57:51,969][train][INFO][train.py>_log] ==> #642000     Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 7.015    Value Loss: 5.994    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 904966     Buffer Size: 25924      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:01:26,921][train][INFO][train.py>_log] ==> #643000     Total Loss: 2.035    [weighted Loss:2.035    Policy Loss: 5.858    Value Loss: 5.726    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 906625     Buffer Size: 26154      Transition Number: 1400.204k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:05:03,795][train][INFO][train.py>_log] ==> #644000     Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 6.670    Value Loss: 6.137    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 908281     Buffer Size: 26437      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:08:38,258][train][INFO][train.py>_log] ==> #645000     Total Loss: 3.206    [weighted Loss:3.206    Policy Loss: 7.230    Value Loss: 6.107    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 909884     Buffer Size: 26710      Transition Number: 1400.069k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:12:12,644][train][INFO][train.py>_log] ==> #646000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 6.362    Value Loss: 6.125    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 911505     Buffer Size: 26976      Transition Number: 1400.076k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:15:48,167][train][INFO][train.py>_log] ==> #647000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 6.529    Value Loss: 6.690    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 913496     Buffer Size: 27545      Transition Number: 1400.135k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:19:23,239][train][INFO][train.py>_log] ==> #648000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 5.807    Value Loss: 6.865    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 915530     Buffer Size: 28136      Transition Number: 1400.159k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:22:58,646][train][INFO][train.py>_log] ==> #649000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 6.115    Value Loss: 6.621    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 916954     Buffer Size: 28256      Transition Number: 1400.083k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:26:33,395][train][INFO][train.py>_log] ==> #650000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 5.934    Value Loss: 6.276    Reward Loss: 1.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 918473     Buffer Size: 28380      Transition Number: 1400.118k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:30:08,255][train][INFO][train.py>_log] ==> #651000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 5.981    Value Loss: 6.381    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 919772     Buffer Size: 28399      Transition Number: 1400.030k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:33:43,213][train][INFO][train.py>_log] ==> #652000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 5.716    Value Loss: 6.156    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 921084     Buffer Size: 28361      Transition Number: 1400.044k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:37:19,659][train][INFO][train.py>_log] ==> #653000     Total Loss: 0.799    [weighted Loss:0.799    Policy Loss: 6.570    Value Loss: 5.888    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 922592     Buffer Size: 28337      Transition Number: 1399.976k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:40:56,367][train][INFO][train.py>_log] ==> #654000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 6.555    Value Loss: 6.244    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 924080     Buffer Size: 28295      Transition Number: 1400.317k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:44:31,398][train][INFO][train.py>_log] ==> #655000     Total Loss: 1.157    [weighted Loss:1.157    Policy Loss: 6.862    Value Loss: 6.267    Reward Loss: 1.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 925702     Buffer Size: 28388      Transition Number: 1400.009k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:48:04,850][train][INFO][train.py>_log] ==> #656000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 6.462    Value Loss: 6.825    Reward Loss: 1.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 927320     Buffer Size: 28482      Transition Number: 1400.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:51:40,300][train][INFO][train.py>_log] ==> #657000     Total Loss: 1.703    [weighted Loss:1.703    Policy Loss: 6.806    Value Loss: 6.325    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 928740     Buffer Size: 28541      Transition Number: 1400.031k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:55:16,814][train][INFO][train.py>_log] ==> #658000     Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 6.640    Value Loss: 6.548    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 930110     Buffer Size: 28632      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:58:53,504][train][INFO][train.py>_log] ==> #659000     Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 5.980    Value Loss: 6.693    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 931559     Buffer Size: 28728      Transition Number: 1400.049k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:02:28,257][train][INFO][train.py>_log] ==> #660000     Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 6.329    Value Loss: 6.236    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 933021     Buffer Size: 28842      Transition Number: 1400.390k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:06:03,118][train][INFO][train.py>_log] ==> #661000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 5.666    Value Loss: 6.426    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 934661     Buffer Size: 28994      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:09:38,736][train][INFO][train.py>_log] ==> #662000     Total Loss: 2.305    [weighted Loss:2.305    Policy Loss: 5.569    Value Loss: 6.389    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 936253     Buffer Size: 28975      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:13:13,501][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 5.638    Value Loss: 6.597    Reward Loss: 1.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 937685     Buffer Size: 28798      Transition Number: 1400.021k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:16:47,463][train][INFO][train.py>_log] ==> #664000     Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 6.538    Value Loss: 6.358    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 939137     Buffer Size: 28602      Transition Number: 1399.953k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:20:23,361][train][INFO][train.py>_log] ==> #665000     Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 5.868    Value Loss: 6.147    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 940551     Buffer Size: 28388      Transition Number: 1400.028k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:23:58,117][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 5.136    Value Loss: 6.012    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 941980     Buffer Size: 27930      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:27:35,242][train][INFO][train.py>_log] ==> #667000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 5.753    Value Loss: 6.411    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 943284     Buffer Size: 27446      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:31:10,444][train][INFO][train.py>_log] ==> #668000     Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 6.009    Value Loss: 6.359    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 944604     Buffer Size: 27375      Transition Number: 1400.161k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:34:45,037][train][INFO][train.py>_log] ==> #669000     Total Loss: 1.362    [weighted Loss:1.362    Policy Loss: 6.136    Value Loss: 6.050    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 946215     Buffer Size: 27479      Transition Number: 1400.168k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:38:20,012][train][INFO][train.py>_log] ==> #670000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 6.007    Value Loss: 5.850    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 947785     Buffer Size: 27683      Transition Number: 1400.027k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:41:55,526][train][INFO][train.py>_log] ==> #671000     Total Loss: 2.530    [weighted Loss:2.530    Policy Loss: 5.598    Value Loss: 6.392    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 949727     Buffer Size: 28235      Transition Number: 1400.042k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:45:30,247][train][INFO][train.py>_log] ==> #672000     Total Loss: 2.395    [weighted Loss:2.395    Policy Loss: 5.322    Value Loss: 6.430    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 951597     Buffer Size: 28653      Transition Number: 1400.029k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:49:05,382][train][INFO][train.py>_log] ==> #673000     Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 5.670    Value Loss: 6.443    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 953078     Buffer Size: 28654      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:52:41,296][train][INFO][train.py>_log] ==> #674000     Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 5.681    Value Loss: 6.419    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 954532     Buffer Size: 28453      Transition Number: 1399.940k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:56:17,588][train][INFO][train.py>_log] ==> #675000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 5.506    Value Loss: 6.258    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 955817     Buffer Size: 28234      Transition Number: 1400.441k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:59:52,935][train][INFO][train.py>_log] ==> #676000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 5.315    Value Loss: 6.584    Reward Loss: 1.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 957227     Buffer Size: 28102      Transition Number: 1400.026k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:03:30,292][train][INFO][train.py>_log] ==> #677000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 6.214    Value Loss: 6.243    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 958478     Buffer Size: 27929      Transition Number: 1399.962k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:07:08,106][train][INFO][train.py>_log] ==> #678000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 5.889    Value Loss: 6.285    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 959778     Buffer Size: 27721      Transition Number: 1399.992k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:10:43,928][train][INFO][train.py>_log] ==> #679000     Total Loss: 2.931    [weighted Loss:2.931    Policy Loss: 5.907    Value Loss: 6.463    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 961302     Buffer Size: 27669      Transition Number: 1400.201k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:14:22,607][train][INFO][train.py>_log] ==> #680000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 5.768    Value Loss: 5.650    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 962806     Buffer Size: 27433      Transition Number: 1399.990k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:17:59,530][train][INFO][train.py>_log] ==> #681000     Total Loss: 2.326    [weighted Loss:2.326    Policy Loss: 5.656    Value Loss: 6.161    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 964572     Buffer Size: 27596      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:21:35,173][train][INFO][train.py>_log] ==> #682000     Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 5.720    Value Loss: 6.278    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 966343     Buffer Size: 27858      Transition Number: 1399.972k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:25:10,508][train][INFO][train.py>_log] ==> #683000     Total Loss: 2.010    [weighted Loss:2.010    Policy Loss: 5.568    Value Loss: 6.161    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 967707     Buffer Size: 27792      Transition Number: 1399.990k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:28:48,445][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 5.507    Value Loss: 6.330    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 969114     Buffer Size: 27676      Transition Number: 1399.969k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:32:25,435][train][INFO][train.py>_log] ==> #685000     Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 6.002    Value Loss: 6.188    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 970518     Buffer Size: 27653      Transition Number: 1400.037k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:36:01,763][train][INFO][train.py>_log] ==> #686000     Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 6.121    Value Loss: 6.345    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 971924     Buffer Size: 27680      Transition Number: 1400.077k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:39:38,931][train][INFO][train.py>_log] ==> #687000     Total Loss: 1.256    [weighted Loss:1.256    Policy Loss: 6.086    Value Loss: 5.769    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 973270     Buffer Size: 27479      Transition Number: 1399.990k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:43:14,288][train][INFO][train.py>_log] ==> #688000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 6.258    Value Loss: 5.652    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 974605     Buffer Size: 27180      Transition Number: 1400.024k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:46:49,922][train][INFO][train.py>_log] ==> #689000     Total Loss: 1.593    [weighted Loss:1.593    Policy Loss: 7.236    Value Loss: 5.877    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 976891     Buffer Size: 27491      Transition Number: 1399.969k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:50:23,824][train][INFO][train.py>_log] ==> #690000     Total Loss: 3.208    [weighted Loss:3.208    Policy Loss: 6.336    Value Loss: 6.281    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 979162     Buffer Size: 27767      Transition Number: 1399.967k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:53:57,613][train][INFO][train.py>_log] ==> #691000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 6.487    Value Loss: 6.203    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 980739     Buffer Size: 27876      Transition Number: 1400.004k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:57:33,649][train][INFO][train.py>_log] ==> #692000     Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 6.178    Value Loss: 6.268    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 982376     Buffer Size: 28096      Transition Number: 1400.147k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:01:09,838][train][INFO][train.py>_log] ==> #693000     Total Loss: 1.073    [weighted Loss:1.073    Policy Loss: 5.312    Value Loss: 6.593    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 983878     Buffer Size: 28190      Transition Number: 1399.986k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:04:46,858][train][INFO][train.py>_log] ==> #694000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 6.305    Value Loss: 6.159    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 985343     Buffer Size: 28262      Transition Number: 1400.039k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:08:22,314][train][INFO][train.py>_log] ==> #695000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 5.976    Value Loss: 6.257    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 986714     Buffer Size: 28386      Transition Number: 1399.978k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:12:00,500][train][INFO][train.py>_log] ==> #696000     Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 6.049    Value Loss: 6.452    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 988095     Buffer Size: 28478      Transition Number: 1399.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:15:37,409][train][INFO][train.py>_log] ==> #697000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 5.808    Value Loss: 6.141    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 989439     Buffer Size: 28383      Transition Number: 1400.065k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:19:14,020][train][INFO][train.py>_log] ==> #698000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 5.989    Value Loss: 5.881    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 990792     Buffer Size: 28238      Transition Number: 1400.046k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:22:49,951][train][INFO][train.py>_log] ==> #699000     Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 6.591    Value Loss: 5.980    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 992133     Buffer Size: 27896      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:26:25,699][train][INFO][train.py>_log] ==> #700000     Total Loss: 2.713    [weighted Loss:2.713    Policy Loss: 5.736    Value Loss: 6.108    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 993418     Buffer Size: 27537      Transition Number: 1400.122k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:30:01,426][train][INFO][train.py>_log] ==> #701000     Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 6.671    Value Loss: 6.129    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 994814     Buffer Size: 27453      Transition Number: 1400.102k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:33:35,589][train][INFO][train.py>_log] ==> #702000     Total Loss: 2.465    [weighted Loss:2.465    Policy Loss: 6.140    Value Loss: 5.885    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 996252     Buffer Size: 27495      Transition Number: 1399.972k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:37:10,828][train][INFO][train.py>_log] ==> #703000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.092    Value Loss: 6.060    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 997591     Buffer Size: 27458      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:40:45,219][train][INFO][train.py>_log] ==> #704000     Total Loss: 2.041    [weighted Loss:2.041    Policy Loss: 6.583    Value Loss: 5.939    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 998900     Buffer Size: 27408      Transition Number: 1399.999k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:44:21,303][train][INFO][train.py>_log] ==> #705000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 6.898    Value Loss: 6.120    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000418    Buffer Size: 27529      Transition Number: 1400.183k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:47:57,882][train][INFO][train.py>_log] ==> #706000     Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 7.053    Value Loss: 6.114    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1001915    Buffer Size: 27698      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:51:32,948][train][INFO][train.py>_log] ==> #707000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 7.248    Value Loss: 6.093    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1003410    Buffer Size: 27335      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:55:09,039][train][INFO][train.py>_log] ==> #708000     Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 6.507    Value Loss: 6.105    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1004876    Buffer Size: 26538      Transition Number: 1400.479k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:58:45,865][train][INFO][train.py>_log] ==> #709000     Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 6.112    Value Loss: 6.188    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 1006303    Buffer Size: 26103      Transition Number: 1400.010k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:02:22,616][train][INFO][train.py>_log] ==> #710000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 6.050    Value Loss: 6.295    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1007709    Buffer Size: 25852      Transition Number: 1400.028k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:05:58,313][train][INFO][train.py>_log] ==> #711000     Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 6.530    Value Loss: 6.046    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1009134    Buffer Size: 25766      Transition Number: 1400.166k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:09:34,092][train][INFO][train.py>_log] ==> #712000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 6.492    Value Loss: 5.991    Reward Loss: 1.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 1010541    Buffer Size: 25756      Transition Number: 1400.110k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:13:09,510][train][INFO][train.py>_log] ==> #713000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 6.723    Value Loss: 6.381    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1012000    Buffer Size: 25799      Transition Number: 1399.961k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:16:46,415][train][INFO][train.py>_log] ==> #714000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 6.575    Value Loss: 6.006    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013467    Buffer Size: 25908      Transition Number: 1399.968k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:20:23,124][train][INFO][train.py>_log] ==> #715000     Total Loss: 2.796    [weighted Loss:2.796    Policy Loss: 6.438    Value Loss: 6.168    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 1015173    Buffer Size: 26246      Transition Number: 1400.321k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:23:59,972][train][INFO][train.py>_log] ==> #716000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 6.375    Value Loss: 6.303    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1016855    Buffer Size: 26581      Transition Number: 1400.052k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:27:35,719][train][INFO][train.py>_log] ==> #717000     Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 6.313    Value Loss: 6.355    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1018429    Buffer Size: 26843      Transition Number: 1400.214k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:31:12,467][train][INFO][train.py>_log] ==> #718000     Total Loss: 3.267    [weighted Loss:3.267    Policy Loss: 5.693    Value Loss: 6.060    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 1019935    Buffer Size: 27058      Transition Number: 1400.031k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:34:48,081][train][INFO][train.py>_log] ==> #719000     Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 5.945    Value Loss: 6.409    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 1021330    Buffer Size: 27073      Transition Number: 1400.065k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:38:23,451][train][INFO][train.py>_log] ==> #720000     Total Loss: 2.854    [weighted Loss:2.854    Policy Loss: 6.611    Value Loss: 5.995    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 1022667    Buffer Size: 27072      Transition Number: 1400.014k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:42:00,632][train][INFO][train.py>_log] ==> #721000     Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 6.282    Value Loss: 5.987    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1024121    Buffer Size: 27143      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:45:36,201][train][INFO][train.py>_log] ==> #722000     Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 6.446    Value Loss: 6.527    Reward Loss: 1.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025654    Buffer Size: 27264      Transition Number: 1400.077k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:49:13,398][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 5.737    Value Loss: 6.376    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1027213    Buffer Size: 27408      Transition Number: 1400.249k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:52:48,846][train][INFO][train.py>_log] ==> #724000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 6.287    Value Loss: 6.334    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 1028793    Buffer Size: 27530      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:56:24,595][train][INFO][train.py>_log] ==> #725000     Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 6.100    Value Loss: 6.311    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030574    Buffer Size: 27814      Transition Number: 1400.106k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:59:59,869][train][INFO][train.py>_log] ==> #726000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 5.654    Value Loss: 5.850    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032408    Buffer Size: 28146      Transition Number: 1400.239k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:03:36,376][train][INFO][train.py>_log] ==> #727000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 5.295    Value Loss: 6.314    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1033700    Buffer Size: 28115      Transition Number: 1400.060k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:07:11,700][train][INFO][train.py>_log] ==> #728000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 5.709    Value Loss: 6.396    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035044    Buffer Size: 28069      Transition Number: 1400.194k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:10:48,299][train][INFO][train.py>_log] ==> #729000     Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 5.970    Value Loss: 6.445    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1036824    Buffer Size: 28389      Transition Number: 1400.057k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:14:24,698][train][INFO][train.py>_log] ==> #730000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 5.956    Value Loss: 6.691    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1038600    Buffer Size: 28679      Transition Number: 1399.992k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:18:01,457][train][INFO][train.py>_log] ==> #731000     Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 6.296    Value Loss: 6.735    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1040116    Buffer Size: 28767      Transition Number: 1400.041k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:21:37,182][train][INFO][train.py>_log] ==> #732000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 6.157    Value Loss: 6.415    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1041564    Buffer Size: 28760      Transition Number: 1400.039k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:25:14,193][train][INFO][train.py>_log] ==> #733000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 5.766    Value Loss: 6.431    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 1042907    Buffer Size: 28572      Transition Number: 1399.962k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:28:51,225][train][INFO][train.py>_log] ==> #734000     Total Loss: 1.584    [weighted Loss:1.584    Policy Loss: 6.367    Value Loss: 6.647    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1044278    Buffer Size: 28266      Transition Number: 1399.976k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:32:28,644][train][INFO][train.py>_log] ==> #735000     Total Loss: 1.084    [weighted Loss:1.084    Policy Loss: 6.236    Value Loss: 6.025    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1045751    Buffer Size: 28166      Transition Number: 1400.039k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:36:04,296][train][INFO][train.py>_log] ==> #736000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 6.247    Value Loss: 6.200    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1047239    Buffer Size: 28087      Transition Number: 1400.119k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:39:40,656][train][INFO][train.py>_log] ==> #737000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 6.153    Value Loss: 6.284    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048770    Buffer Size: 28111      Transition Number: 1399.941k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:43:16,313][train][INFO][train.py>_log] ==> #738000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 6.102    Value Loss: 6.418    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1050203    Buffer Size: 28208      Transition Number: 1399.969k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:46:50,657][train][INFO][train.py>_log] ==> #739000     Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 5.827    Value Loss: 6.289    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1051887    Buffer Size: 28474      Transition Number: 1400.362k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:50:26,436][train][INFO][train.py>_log] ==> #740000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 6.782    Value Loss: 6.235    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1053579    Buffer Size: 28694      Transition Number: 1400.062k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:54:02,318][train][INFO][train.py>_log] ==> #741000     Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 6.783    Value Loss: 6.585    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1055299    Buffer Size: 28873      Transition Number: 1400.033k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:57:37,464][train][INFO][train.py>_log] ==> #742000     Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 6.784    Value Loss: 6.377    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1056956    Buffer Size: 29001      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:01:12,868][train][INFO][train.py>_log] ==> #743000     Total Loss: 2.513    [weighted Loss:2.513    Policy Loss: 7.183    Value Loss: 6.787    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1058698    Buffer Size: 29067      Transition Number: 1400.020k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:04:47,830][train][INFO][train.py>_log] ==> #744000     Total Loss: 1.298    [weighted Loss:1.298    Policy Loss: 6.411    Value Loss: 6.913    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1060451    Buffer Size: 28968      Transition Number: 1400.126k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:08:24,210][train][INFO][train.py>_log] ==> #745000     Total Loss: 2.561    [weighted Loss:2.561    Policy Loss: 6.080    Value Loss: 6.708    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1062047    Buffer Size: 29015      Transition Number: 1399.986k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:11:58,530][train][INFO][train.py>_log] ==> #746000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 5.848    Value Loss: 6.287    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063609    Buffer Size: 29280      Transition Number: 1400.074k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:15:32,303][train][INFO][train.py>_log] ==> #747000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 5.705    Value Loss: 6.736    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1064972    Buffer Size: 29184      Transition Number: 1400.266k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:19:07,592][train][INFO][train.py>_log] ==> #748000     Total Loss: 2.990    [weighted Loss:2.990    Policy Loss: 5.970    Value Loss: 6.288    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 1066448    Buffer Size: 28825      Transition Number: 1399.985k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:22:42,120][train][INFO][train.py>_log] ==> #749000     Total Loss: 2.527    [weighted Loss:2.527    Policy Loss: 5.960    Value Loss: 6.659    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 1068141    Buffer Size: 28897      Transition Number: 1399.974k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:26:16,899][train][INFO][train.py>_log] ==> #750000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 5.856    Value Loss: 6.523    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069866    Buffer Size: 29159      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:29:52,537][train][INFO][train.py>_log] ==> #751000     Total Loss: 1.164    [weighted Loss:1.164    Policy Loss: 6.679    Value Loss: 6.361    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1071549    Buffer Size: 29413      Transition Number: 1400.193k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:33:27,619][train][INFO][train.py>_log] ==> #752000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 6.349    Value Loss: 6.419    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1073227    Buffer Size: 29716      Transition Number: 1400.023k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:37:02,025][train][INFO][train.py>_log] ==> #753000     Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 6.785    Value Loss: 6.159    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 1074684    Buffer Size: 29805      Transition Number: 1399.947k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:40:37,685][train][INFO][train.py>_log] ==> #754000     Total Loss: 1.201    [weighted Loss:1.201    Policy Loss: 5.680    Value Loss: 6.674    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076137    Buffer Size: 29817      Transition Number: 1400.024k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:44:11,935][train][INFO][train.py>_log] ==> #755000     Total Loss: 3.555    [weighted Loss:3.555    Policy Loss: 6.966    Value Loss: 6.578    Reward Loss: 1.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 1077633    Buffer Size: 29764      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:47:46,345][train][INFO][train.py>_log] ==> #756000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 7.037    Value Loss: 6.411    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 1079102    Buffer Size: 29767      Transition Number: 1400.015k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:51:22,490][train][INFO][train.py>_log] ==> #757000     Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 6.338    Value Loss: 6.774    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1081092    Buffer Size: 30223      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:54:57,087][train][INFO][train.py>_log] ==> #758000     Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 6.480    Value Loss: 6.641    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1083048    Buffer Size: 30465      Transition Number: 1400.230k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:58:31,921][train][INFO][train.py>_log] ==> #759000     Total Loss: 2.960    [weighted Loss:2.960    Policy Loss: 6.244    Value Loss: 6.875    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1084654    Buffer Size: 30458      Transition Number: 1400.166k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:02:08,802][train][INFO][train.py>_log] ==> #760000     Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 5.650    Value Loss: 6.429    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1086325    Buffer Size: 30423      Transition Number: 1400.314k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:05:44,083][train][INFO][train.py>_log] ==> #761000     Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 5.925    Value Loss: 6.744    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1087835    Buffer Size: 30267      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:09:18,900][train][INFO][train.py>_log] ==> #762000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 5.797    Value Loss: 6.456    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089370    Buffer Size: 30043      Transition Number: 1399.958k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:12:54,388][train][INFO][train.py>_log] ==> #763000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 5.328    Value Loss: 6.514    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1090905    Buffer Size: 29952      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:16:28,868][train][INFO][train.py>_log] ==> #764000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 5.519    Value Loss: 6.081    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092457    Buffer Size: 29947      Transition Number: 1400.127k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:20:05,230][train][INFO][train.py>_log] ==> #765000     Total Loss: 1.718    [weighted Loss:1.718    Policy Loss: 5.630    Value Loss: 6.604    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1093909    Buffer Size: 29867      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:23:40,562][train][INFO][train.py>_log] ==> #766000     Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 5.850    Value Loss: 6.323    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1095421    Buffer Size: 29965      Transition Number: 1399.956k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:27:15,608][train][INFO][train.py>_log] ==> #767000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 5.445    Value Loss: 6.243    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1096956    Buffer Size: 29994      Transition Number: 1400.059k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:30:51,462][train][INFO][train.py>_log] ==> #768000     Total Loss: 0.896    [weighted Loss:0.896    Policy Loss: 5.809    Value Loss: 6.768    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098504    Buffer Size: 29794      Transition Number: 1399.957k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:34:27,246][train][INFO][train.py>_log] ==> #769000     Total Loss: 1.419    [weighted Loss:1.419    Policy Loss: 5.743    Value Loss: 6.072    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1099844    Buffer Size: 29423      Transition Number: 1400.049k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:38:04,856][train][INFO][train.py>_log] ==> #770000     Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 6.396    Value Loss: 5.926    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 1101229    Buffer Size: 29089      Transition Number: 1400.151k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:41:40,276][train][INFO][train.py>_log] ==> #771000     Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 6.119    Value Loss: 6.560    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103832    Buffer Size: 30024      Transition Number: 1400.163k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:45:15,619][train][INFO][train.py>_log] ==> #772000     Total Loss: 2.708    [weighted Loss:2.708    Policy Loss: 6.057    Value Loss: 6.516    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1106374    Buffer Size: 31095      Transition Number: 1400.036k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:48:51,285][train][INFO][train.py>_log] ==> #773000     Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 6.124    Value Loss: 6.425    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 1108050    Buffer Size: 31333      Transition Number: 1400.066k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:52:25,727][train][INFO][train.py>_log] ==> #774000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 5.989    Value Loss: 6.738    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 1109800    Buffer Size: 31595      Transition Number: 1400.048k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:56:02,124][train][INFO][train.py>_log] ==> #775000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 5.369    Value Loss: 6.408    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111447    Buffer Size: 31567      Transition Number: 1399.936k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:59:35,920][train][INFO][train.py>_log] ==> #776000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 5.679    Value Loss: 6.761    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113066    Buffer Size: 31228      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:03:11,971][train][INFO][train.py>_log] ==> #777000     Total Loss: 1.529    [weighted Loss:1.529    Policy Loss: 6.242    Value Loss: 6.394    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1114454    Buffer Size: 30799      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:06:48,582][train][INFO][train.py>_log] ==> #778000     Total Loss: 2.448    [weighted Loss:2.448    Policy Loss: 5.784    Value Loss: 6.425    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 1115929    Buffer Size: 30485      Transition Number: 1399.935k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:10:23,366][train][INFO][train.py>_log] ==> #779000     Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 6.282    Value Loss: 6.366    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117290    Buffer Size: 30277      Transition Number: 1399.970k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:13:58,599][train][INFO][train.py>_log] ==> #780000     Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 5.756    Value Loss: 5.876    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1118617    Buffer Size: 30162      Transition Number: 1399.970k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:17:35,271][train][INFO][train.py>_log] ==> #781000     Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 5.734    Value Loss: 6.661    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 1119940    Buffer Size: 29974      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:21:10,606][train][INFO][train.py>_log] ==> #782000     Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 6.066    Value Loss: 6.067    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1121253    Buffer Size: 29743      Transition Number: 1399.995k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:24:46,963][train][INFO][train.py>_log] ==> #783000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 6.129    Value Loss: 7.036    Reward Loss: 1.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 1123670    Buffer Size: 30448      Transition Number: 1399.967k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:28:22,101][train][INFO][train.py>_log] ==> #784000     Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 5.725    Value Loss: 6.600    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1125981    Buffer Size: 31237      Transition Number: 1400.151k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:31:58,199][train][INFO][train.py>_log] ==> #785000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 5.814    Value Loss: 6.561    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 1127578    Buffer Size: 31402      Transition Number: 1400.177k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:35:34,981][train][INFO][train.py>_log] ==> #786000     Total Loss: 2.600    [weighted Loss:2.600    Policy Loss: 5.938    Value Loss: 6.070    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1129247    Buffer Size: 31559      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:39:10,601][train][INFO][train.py>_log] ==> #787000     Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 5.532    Value Loss: 6.411    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1130815    Buffer Size: 31633      Transition Number: 1400.012k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:42:45,841][train][INFO][train.py>_log] ==> #788000     Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 5.581    Value Loss: 6.359    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1132370    Buffer Size: 31869      Transition Number: 1400.222k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:46:22,050][train][INFO][train.py>_log] ==> #789000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 5.834    Value Loss: 6.898    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133835    Buffer Size: 31472      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:49:57,680][train][INFO][train.py>_log] ==> #790000     Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 5.846    Value Loss: 6.587    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135306    Buffer Size: 30329      Transition Number: 1400.419k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:53:33,645][train][INFO][train.py>_log] ==> #791000     Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 5.061    Value Loss: 6.798    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 1136648    Buffer Size: 29501      Transition Number: 1400.003k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:57:11,375][train][INFO][train.py>_log] ==> #792000     Total Loss: 2.359    [weighted Loss:2.359    Policy Loss: 7.009    Value Loss: 6.578    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1137986    Buffer Size: 29131      Transition Number: 1399.986k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:00:46,660][train][INFO][train.py>_log] ==> #793000     Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 5.372    Value Loss: 6.064    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139715    Buffer Size: 29103      Transition Number: 1400.191k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:04:22,301][train][INFO][train.py>_log] ==> #794000     Total Loss: 2.869    [weighted Loss:2.869    Policy Loss: 5.776    Value Loss: 6.178    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1141422    Buffer Size: 29157      Transition Number: 1399.980k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:07:58,152][train][INFO][train.py>_log] ==> #795000     Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 5.605    Value Loss: 6.577    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1142870    Buffer Size: 29118      Transition Number: 1400.080k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:11:33,086][train][INFO][train.py>_log] ==> #796000     Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 5.753    Value Loss: 6.051    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144351    Buffer Size: 29173      Transition Number: 1400.278k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:15:09,742][train][INFO][train.py>_log] ==> #797000     Total Loss: 1.686    [weighted Loss:1.686    Policy Loss: 5.634    Value Loss: 6.474    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1145730    Buffer Size: 29152      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:18:45,952][train][INFO][train.py>_log] ==> #798000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 6.035    Value Loss: 6.295    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147103    Buffer Size: 29126      Transition Number: 1400.005k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:22:21,896][train][INFO][train.py>_log] ==> #799000     Total Loss: 1.402    [weighted Loss:1.402    Policy Loss: 5.575    Value Loss: 6.778    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1148776    Buffer Size: 29377      Transition Number: 1400.105k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:25:57,621][train][INFO][train.py>_log] ==> #800000     Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 5.206    Value Loss: 6.048    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 1150411    Buffer Size: 29675      Transition Number: 1400.167k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:29:33,350][train][INFO][train.py>_log] ==> #801000     Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 5.276    Value Loss: 6.638    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152182    Buffer Size: 29562      Transition Number: 1400.245k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:33:09,144][train][INFO][train.py>_log] ==> #802000     Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 5.923    Value Loss: 6.466    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1153960    Buffer Size: 28966      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:36:46,266][train][INFO][train.py>_log] ==> #803000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 5.890    Value Loss: 6.256    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1155550    Buffer Size: 28599      Transition Number: 1400.070k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:40:21,015][train][INFO][train.py>_log] ==> #804000     Total Loss: 1.162    [weighted Loss:1.162    Policy Loss: 6.229    Value Loss: 6.436    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 1157131    Buffer Size: 28509      Transition Number: 1400.174k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:43:56,890][train][INFO][train.py>_log] ==> #805000     Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 5.726    Value Loss: 6.721    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1158703    Buffer Size: 28469      Transition Number: 1400.019k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:47:32,071][train][INFO][train.py>_log] ==> #806000     Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 5.182    Value Loss: 6.516    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 1160236    Buffer Size: 28420      Transition Number: 1400.020k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:51:07,523][train][INFO][train.py>_log] ==> #807000     Total Loss: 1.714    [weighted Loss:1.714    Policy Loss: 5.441    Value Loss: 6.426    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1161910    Buffer Size: 28560      Transition Number: 1400.054k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:54:43,052][train][INFO][train.py>_log] ==> #808000     Total Loss: 1.318    [weighted Loss:1.318    Policy Loss: 5.246    Value Loss: 6.542    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 1163555    Buffer Size: 28778      Transition Number: 1400.040k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:58:19,086][train][INFO][train.py>_log] ==> #809000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 5.516    Value Loss: 6.208    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 1164969    Buffer Size: 28771      Transition Number: 1399.946k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:01:56,863][train][INFO][train.py>_log] ==> #810000     Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 5.673    Value Loss: 6.388    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1166333    Buffer Size: 28829      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:05:32,578][train][INFO][train.py>_log] ==> #811000     Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 6.317    Value Loss: 6.506    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1167682    Buffer Size: 28619      Transition Number: 1399.961k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:09:07,438][train][INFO][train.py>_log] ==> #812000     Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 5.939    Value Loss: 6.207    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 1169077    Buffer Size: 28282      Transition Number: 1399.969k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:12:42,945][train][INFO][train.py>_log] ==> #813000     Total Loss: 1.572    [weighted Loss:1.572    Policy Loss: 5.757    Value Loss: 6.286    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1170361    Buffer Size: 28030      Transition Number: 1399.959k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:16:18,927][train][INFO][train.py>_log] ==> #814000     Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 5.748    Value Loss: 6.367    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1171622    Buffer Size: 27871      Transition Number: 1400.065k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:19:54,812][train][INFO][train.py>_log] ==> #815000     Total Loss: 1.475    [weighted Loss:1.475    Policy Loss: 6.192    Value Loss: 6.241    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 1173072    Buffer Size: 27890      Transition Number: 1399.999k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:23:30,776][train][INFO][train.py>_log] ==> #816000     Total Loss: 1.525    [weighted Loss:1.525    Policy Loss: 6.258    Value Loss: 5.539    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1174580    Buffer Size: 27944      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:27:06,878][train][INFO][train.py>_log] ==> #817000     Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 6.306    Value Loss: 6.338    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 1176713    Buffer Size: 28410      Transition Number: 1399.968k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:30:42,135][train][INFO][train.py>_log] ==> #818000     Total Loss: 2.864    [weighted Loss:2.864    Policy Loss: 5.902    Value Loss: 6.856    Reward Loss: 1.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 1178810    Buffer Size: 28749      Transition Number: 1400.087k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:34:18,090][train][INFO][train.py>_log] ==> #819000     Total Loss: 1.908    [weighted Loss:1.908    Policy Loss: 5.273    Value Loss: 6.587    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1180305    Buffer Size: 28555      Transition Number: 1400.028k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:37:54,872][train][INFO][train.py>_log] ==> #820000     Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 5.591    Value Loss: 6.188    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1181759    Buffer Size: 28304      Transition Number: 1399.946k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:41:32,739][train][INFO][train.py>_log] ==> #821000     Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 5.541    Value Loss: 6.192    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1183079    Buffer Size: 27989      Transition Number: 1399.950k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:45:09,587][train][INFO][train.py>_log] ==> #822000     Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 5.759    Value Loss: 6.365    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1184426    Buffer Size: 27704      Transition Number: 1400.110k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:48:46,460][train][INFO][train.py>_log] ==> #823000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 5.762    Value Loss: 5.894    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1185728    Buffer Size: 27440      Transition Number: 1399.990k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:52:22,257][train][INFO][train.py>_log] ==> #824000     Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 5.907    Value Loss: 6.323    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1187045    Buffer Size: 27175      Transition Number: 1399.955k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:55:56,700][train][INFO][train.py>_log] ==> #825000     Total Loss: 1.421    [weighted Loss:1.421    Policy Loss: 5.907    Value Loss: 6.262    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 1188815    Buffer Size: 27254      Transition Number: 1400.104k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:59:32,592][train][INFO][train.py>_log] ==> #826000     Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 6.098    Value Loss: 5.847    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1190581    Buffer Size: 27282      Transition Number: 1400.250k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:03:09,221][train][INFO][train.py>_log] ==> #827000     Total Loss: 2.478    [weighted Loss:2.478    Policy Loss: 6.018    Value Loss: 5.943    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1192017    Buffer Size: 27257      Transition Number: 1400.088k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:06:46,912][train][INFO][train.py>_log] ==> #828000     Total Loss: 2.546    [weighted Loss:2.546    Policy Loss: 5.796    Value Loss: 5.854    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1193469    Buffer Size: 27289      Transition Number: 1399.958k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:10:24,720][train][INFO][train.py>_log] ==> #829000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 5.397    Value Loss: 5.796    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1194814    Buffer Size: 27260      Transition Number: 1399.952k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:14:02,128][train][INFO][train.py>_log] ==> #830000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 5.760    Value Loss: 6.037    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1196173    Buffer Size: 27230      Transition Number: 1400.267k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:17:38,372][train][INFO][train.py>_log] ==> #831000     Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 5.103    Value Loss: 5.975    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1197658    Buffer Size: 27366      Transition Number: 1400.141k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:21:14,619][train][INFO][train.py>_log] ==> #832000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 6.547    Value Loss: 6.363    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1199143    Buffer Size: 27504      Transition Number: 1400.086k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:24:48,585][train][INFO][train.py>_log] ==> #833000     Total Loss: 1.314    [weighted Loss:1.314    Policy Loss: 6.184    Value Loss: 6.278    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1201741    Buffer Size: 28570      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:28:23,497][train][INFO][train.py>_log] ==> #834000     Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 5.969    Value Loss: 6.614    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 1204354    Buffer Size: 29658      Transition Number: 1400.249k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:31:58,953][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.507    [weighted Loss:2.507    Policy Loss: 5.602    Value Loss: 6.544    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1206132    Buffer Size: 29480      Transition Number: 1400.065k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:35:34,776][train][INFO][train.py>_log] ==> #836000     Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 5.882    Value Loss: 6.541    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1207942    Buffer Size: 29329      Transition Number: 1399.952k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:39:09,747][train][INFO][train.py>_log] ==> #837000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 5.560    Value Loss: 6.236    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 1209392    Buffer Size: 29245      Transition Number: 1399.976k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:42:44,866][train][INFO][train.py>_log] ==> #838000     Total Loss: 1.494    [weighted Loss:1.494    Policy Loss: 5.160    Value Loss: 6.272    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 1210872    Buffer Size: 29274      Transition Number: 1400.070k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:46:21,458][train][INFO][train.py>_log] ==> #839000     Total Loss: 2.741    [weighted Loss:2.741    Policy Loss: 5.349    Value Loss: 6.327    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1212291    Buffer Size: 29311      Transition Number: 1400.082k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:49:58,507][train][INFO][train.py>_log] ==> #840000     Total Loss: 1.667    [weighted Loss:1.667    Policy Loss: 5.478    Value Loss: 5.921    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1213700    Buffer Size: 29378      Transition Number: 1399.972k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:53:34,923][train][INFO][train.py>_log] ==> #841000     Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 5.311    Value Loss: 6.137    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 1214988    Buffer Size: 29414      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:57:11,027][train][INFO][train.py>_log] ==> #842000     Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 5.581    Value Loss: 6.536    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216286    Buffer Size: 29430      Transition Number: 1400.097k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:00:47,020][train][INFO][train.py>_log] ==> #843000     Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 5.140    Value Loss: 6.354    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 1217721    Buffer Size: 29177      Transition Number: 1400.211k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:04:23,685][train][INFO][train.py>_log] ==> #844000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 5.244    Value Loss: 6.254    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 1219073    Buffer Size: 28819      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:07:59,865][train][INFO][train.py>_log] ==> #845000     Total Loss: 1.080    [weighted Loss:1.080    Policy Loss: 5.319    Value Loss: 5.934    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 1220315    Buffer Size: 28612      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:11:35,897][train][INFO][train.py>_log] ==> #846000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 5.665    Value Loss: 6.275    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1221626    Buffer Size: 28475      Transition Number: 1399.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:15:13,355][train][INFO][train.py>_log] ==> #847000     Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 4.714    Value Loss: 6.222    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1222912    Buffer Size: 28370      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:18:51,170][train][INFO][train.py>_log] ==> #848000     Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 5.516    Value Loss: 6.029    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 1224234    Buffer Size: 28283      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:22:27,665][train][INFO][train.py>_log] ==> #849000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 5.484    Value Loss: 6.057    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225699    Buffer Size: 28181      Transition Number: 1400.145k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:26:03,900][train][INFO][train.py>_log] ==> #850000     Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 6.256    Value Loss: 6.010    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1226986    Buffer Size: 28096      Transition Number: 1400.163k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:29:41,011][train][INFO][train.py>_log] ==> #851000     Total Loss: 1.042    [weighted Loss:1.042    Policy Loss: 5.765    Value Loss: 5.710    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1228323    Buffer Size: 27105      Transition Number: 1400.095k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:33:15,872][train][INFO][train.py>_log] ==> #852000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 5.444    Value Loss: 5.707    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1229645    Buffer Size: 25959      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:36:51,233][train][INFO][train.py>_log] ==> #853000     Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 5.556    Value Loss: 6.022    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 1231100    Buffer Size: 25431      Transition Number: 1400.027k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:40:26,199][train][INFO][train.py>_log] ==> #854000     Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 5.548    Value Loss: 5.868    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 1232519    Buffer Size: 25149      Transition Number: 1400.170k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:44:01,223][train][INFO][train.py>_log] ==> #855000     Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 6.190    Value Loss: 5.933    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1233959    Buffer Size: 24972      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:47:36,377][train][INFO][train.py>_log] ==> #856000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 6.336    Value Loss: 6.420    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 1235353    Buffer Size: 24876      Transition Number: 1400.219k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:51:11,964][train][INFO][train.py>_log] ==> #857000     Total Loss: 3.211    [weighted Loss:3.211    Policy Loss: 7.049    Value Loss: 5.949    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236814    Buffer Size: 24959      Transition Number: 1400.120k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:54:49,130][train][INFO][train.py>_log] ==> #858000     Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 5.804    Value Loss: 5.887    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 1238335    Buffer Size: 25082      Transition Number: 1400.027k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:58:24,713][train][INFO][train.py>_log] ==> #859000     Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 6.791    Value Loss: 5.920    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 1240130    Buffer Size: 25492      Transition Number: 1400.145k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:02:00,550][train][INFO][train.py>_log] ==> #860000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 5.452    Value Loss: 6.192    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241887    Buffer Size: 25935      Transition Number: 1400.024k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:05:36,522][train][INFO][train.py>_log] ==> #861000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 6.056    Value Loss: 6.204    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1243309    Buffer Size: 26005      Transition Number: 1400.285k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:09:10,580][train][INFO][train.py>_log] ==> #862000     Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 5.647    Value Loss: 6.235    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1244741    Buffer Size: 26031      Transition Number: 1400.018k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:12:46,360][train][INFO][train.py>_log] ==> #863000     Total Loss: 1.682    [weighted Loss:1.682    Policy Loss: 6.430    Value Loss: 5.957    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 1246160    Buffer Size: 26137      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:16:22,100][train][INFO][train.py>_log] ==> #864000     Total Loss: 1.193    [weighted Loss:1.193    Policy Loss: 5.954    Value Loss: 6.127    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1247609    Buffer Size: 26273      Transition Number: 1399.956k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:19:55,300][train][INFO][train.py>_log] ==> #865000     Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 6.286    Value Loss: 6.005    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 1249159    Buffer Size: 26543      Transition Number: 1400.050k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:23:32,079][train][INFO][train.py>_log] ==> #866000     Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 6.344    Value Loss: 6.171    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 1250665    Buffer Size: 26819      Transition Number: 1400.058k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:27:06,057][train][INFO][train.py>_log] ==> #867000     Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 6.502    Value Loss: 6.098    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252906    Buffer Size: 27708      Transition Number: 1400.170k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:30:42,313][train][INFO][train.py>_log] ==> #868000     Total Loss: 2.336    [weighted Loss:2.336    Policy Loss: 5.601    Value Loss: 6.625    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 1255173    Buffer Size: 28624      Transition Number: 1399.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:34:18,328][train][INFO][train.py>_log] ==> #869000     Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 5.103    Value Loss: 6.575    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1256670    Buffer Size: 28869      Transition Number: 1400.031k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:37:53,324][train][INFO][train.py>_log] ==> #870000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 5.560    Value Loss: 6.729    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1258323    Buffer Size: 29037      Transition Number: 1399.965k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:41:28,548][train][INFO][train.py>_log] ==> #871000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 5.129    Value Loss: 6.195    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 1259888    Buffer Size: 29211      Transition Number: 1400.063k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:45:04,445][train][INFO][train.py>_log] ==> #872000     Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 5.738    Value Loss: 6.525    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1261529    Buffer Size: 29312      Transition Number: 1400.034k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:48:40,516][train][INFO][train.py>_log] ==> #873000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 5.482    Value Loss: 6.193    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1263044    Buffer Size: 29430      Transition Number: 1400.107k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:52:17,427][train][INFO][train.py>_log] ==> #874000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 5.274    Value Loss: 6.417    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1264573    Buffer Size: 29579      Transition Number: 1399.945k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:55:50,365][train][INFO][train.py>_log] ==> #875000     Total Loss: 0.833    [weighted Loss:0.833    Policy Loss: 5.210    Value Loss: 6.349    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266090    Buffer Size: 29672      Transition Number: 1400.071k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:59:25,084][train][INFO][train.py>_log] ==> #876000     Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 5.298    Value Loss: 6.430    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1267676    Buffer Size: 29703      Transition Number: 1400.116k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:03:01,973][train][INFO][train.py>_log] ==> #877000     Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 5.260    Value Loss: 6.427    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 1269088    Buffer Size: 29429      Transition Number: 1400.122k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:06:37,921][train][INFO][train.py>_log] ==> #878000     Total Loss: 1.315    [weighted Loss:1.315    Policy Loss: 5.016    Value Loss: 6.011    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1270436    Buffer Size: 29069      Transition Number: 1400.045k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:10:14,752][train][INFO][train.py>_log] ==> #879000     Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 4.392    Value Loss: 6.169    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 1271708    Buffer Size: 28812      Transition Number: 1399.959k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:13:52,130][train][INFO][train.py>_log] ==> #880000     Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 5.096    Value Loss: 6.046    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 1272929    Buffer Size: 28649      Transition Number: 1400.062k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:17:27,758][train][INFO][train.py>_log] ==> #881000     Total Loss: 1.693    [weighted Loss:1.693    Policy Loss: 4.989    Value Loss: 6.374    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1274362    Buffer Size: 28513      Transition Number: 1400.127k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:21:05,072][train][INFO][train.py>_log] ==> #882000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 4.851    Value Loss: 6.421    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1275663    Buffer Size: 28434      Transition Number: 1400.101k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:24:42,431][train][INFO][train.py>_log] ==> #883000     Total Loss: 2.386    [weighted Loss:2.386    Policy Loss: 6.057    Value Loss: 6.325    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1277204    Buffer Size: 28408      Transition Number: 1400.252k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:28:17,962][train][INFO][train.py>_log] ==> #884000     Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 6.146    Value Loss: 6.344    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1278709    Buffer Size: 28382      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:31:52,501][train][INFO][train.py>_log] ==> #885000     Total Loss: 1.693    [weighted Loss:1.693    Policy Loss: 5.001    Value Loss: 5.860    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 1281410    Buffer Size: 28935      Transition Number: 1400.322k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:35:26,632][train][INFO][train.py>_log] ==> #886000     Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 6.026    Value Loss: 6.549    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1284060    Buffer Size: 29324      Transition Number: 1400.096k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:39:02,413][train][INFO][train.py>_log] ==> #887000     Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 5.328    Value Loss: 6.703    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1285872    Buffer Size: 29456      Transition Number: 1400.548k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:42:37,749][train][INFO][train.py>_log] ==> #888000     Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 6.026    Value Loss: 6.075    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1287663    Buffer Size: 29697      Transition Number: 1400.033k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:46:13,889][train][INFO][train.py>_log] ==> #889000     Total Loss: 1.298    [weighted Loss:1.298    Policy Loss: 5.821    Value Loss: 6.259    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1289505    Buffer Size: 29980      Transition Number: 1400.085k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:49:48,976][train][INFO][train.py>_log] ==> #890000     Total Loss: 1.232    [weighted Loss:1.232    Policy Loss: 5.239    Value Loss: 6.220    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1291325    Buffer Size: 30189      Transition Number: 1400.106k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:53:24,426][train][INFO][train.py>_log] ==> #891000     Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 4.913    Value Loss: 6.445    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1292975    Buffer Size: 30254      Transition Number: 1400.098k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:57:00,721][train][INFO][train.py>_log] ==> #892000     Total Loss: 0.931    [weighted Loss:0.931    Policy Loss: 5.499    Value Loss: 6.431    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1294677    Buffer Size: 30370      Transition Number: 1400.225k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:00:40,220][train][INFO][train.py>_log] ==> #893000     Total Loss: 1.268    [weighted Loss:1.268    Policy Loss: 5.358    Value Loss: 6.449    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1296163    Buffer Size: 30290      Transition Number: 1400.063k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:04:18,810][train][INFO][train.py>_log] ==> #894000     Total Loss: 1.994    [weighted Loss:1.994    Policy Loss: 6.314    Value Loss: 6.572    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 1297655    Buffer Size: 30210      Transition Number: 1400.287k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:07:54,235][train][INFO][train.py>_log] ==> #895000     Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 5.714    Value Loss: 6.549    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299206    Buffer Size: 30328      Transition Number: 1400.073k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:11:30,553][train][INFO][train.py>_log] ==> #896000     Total Loss: 1.349    [weighted Loss:1.349    Policy Loss: 4.732    Value Loss: 6.738    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1300688    Buffer Size: 30496      Transition Number: 1400.144k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:15:07,316][train][INFO][train.py>_log] ==> #897000     Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 6.157    Value Loss: 6.203    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 1302110    Buffer Size: 30644      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:18:43,607][train][INFO][train.py>_log] ==> #898000     Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 5.395    Value Loss: 6.207    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 1303583    Buffer Size: 30798      Transition Number: 1400.040k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:22:19,926][train][INFO][train.py>_log] ==> #899000     Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 5.470    Value Loss: 6.503    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304936    Buffer Size: 30880      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:25:55,721][train][INFO][train.py>_log] ==> #900000     Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 5.791    Value Loss: 5.918    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 1306351    Buffer Size: 30977      Transition Number: 1399.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:29:32,799][train][INFO][train.py>_log] ==> #901000     Total Loss: 1.642    [weighted Loss:1.642    Policy Loss: 5.193    Value Loss: 6.074    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1307702    Buffer Size: 30840      Transition Number: 1399.970k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:33:08,261][train][INFO][train.py>_log] ==> #902000     Total Loss: 2.891    [weighted Loss:2.891    Policy Loss: 5.476    Value Loss: 6.030    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1309000    Buffer Size: 30639      Transition Number: 1399.986k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:36:43,825][train][INFO][train.py>_log] ==> #903000     Total Loss: 0.914    [weighted Loss:0.914    Policy Loss: 5.361    Value Loss: 6.081    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 1310251    Buffer Size: 29674      Transition Number: 1400.071k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:40:21,071][train][INFO][train.py>_log] ==> #904000     Total Loss: 1.281    [weighted Loss:1.281    Policy Loss: 6.292    Value Loss: 5.985    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 1311501    Buffer Size: 28347      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:43:56,798][train][INFO][train.py>_log] ==> #905000     Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 5.634    Value Loss: 6.371    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1313052    Buffer Size: 27736      Transition Number: 1399.938k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:47:32,815][train][INFO][train.py>_log] ==> #906000     Total Loss: 2.165    [weighted Loss:2.165    Policy Loss: 5.720    Value Loss: 6.378    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 1314570    Buffer Size: 27458      Transition Number: 1400.003k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:51:07,202][train][INFO][train.py>_log] ==> #907000     Total Loss: 0.279    [weighted Loss:0.279    Policy Loss: 5.491    Value Loss: 6.382    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1316136    Buffer Size: 27285      Transition Number: 1400.042k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:54:41,861][train][INFO][train.py>_log] ==> #908000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 5.417    Value Loss: 6.050    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 1317758    Buffer Size: 27084      Transition Number: 1400.068k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:58:16,515][train][INFO][train.py>_log] ==> #909000     Total Loss: 1.077    [weighted Loss:1.077    Policy Loss: 5.176    Value Loss: 6.128    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 1319655    Buffer Size: 27274      Transition Number: 1400.164k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:01:52,449][train][INFO][train.py>_log] ==> #910000     Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 5.980    Value Loss: 6.357    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1321610    Buffer Size: 27592      Transition Number: 1400.014k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:05:28,363][train][INFO][train.py>_log] ==> #911000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 6.550    Value Loss: 6.507    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1323021    Buffer Size: 27507      Transition Number: 1400.126k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:09:03,697][train][INFO][train.py>_log] ==> #912000     Total Loss: 1.290    [weighted Loss:1.290    Policy Loss: 5.064    Value Loss: 6.478    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1324445    Buffer Size: 27473      Transition Number: 1400.156k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:12:38,521][train][INFO][train.py>_log] ==> #913000     Total Loss: 1.107    [weighted Loss:1.107    Policy Loss: 5.700    Value Loss: 6.324    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1325852    Buffer Size: 27396      Transition Number: 1399.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:16:14,822][train][INFO][train.py>_log] ==> #914000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 7.752    Value Loss: 6.649    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1327322    Buffer Size: 27276      Transition Number: 1400.114k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:19:50,131][train][INFO][train.py>_log] ==> #915000     Total Loss: 1.330    [weighted Loss:1.330    Policy Loss: 6.099    Value Loss: 6.640    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1329685    Buffer Size: 28109      Transition Number: 1400.083k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:23:26,333][train][INFO][train.py>_log] ==> #916000     Total Loss: 2.713    [weighted Loss:2.713    Policy Loss: 6.381    Value Loss: 6.861    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332095    Buffer Size: 29085      Transition Number: 1399.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:27:03,912][train][INFO][train.py>_log] ==> #917000     Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 5.961    Value Loss: 6.619    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1334328    Buffer Size: 29867      Transition Number: 1400.231k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:30:40,838][train][INFO][train.py>_log] ==> #918000     Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 5.345    Value Loss: 6.706    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 1336551    Buffer Size: 30602      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:34:18,077][train][INFO][train.py>_log] ==> #919000     Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 5.213    Value Loss: 6.241    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1338081    Buffer Size: 30751      Transition Number: 1400.109k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:37:55,518][train][INFO][train.py>_log] ==> #920000     Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 5.610    Value Loss: 5.928    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1339604    Buffer Size: 30900      Transition Number: 1399.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:41:31,695][train][INFO][train.py>_log] ==> #921000     Total Loss: 0.502    [weighted Loss:0.502    Policy Loss: 5.381    Value Loss: 6.300    Reward Loss: 1.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 1340968    Buffer Size: 31027      Transition Number: 1400.013k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:45:08,181][train][INFO][train.py>_log] ==> #922000     Total Loss: 1.854    [weighted Loss:1.854    Policy Loss: 4.875    Value Loss: 6.773    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 1342325    Buffer Size: 31159      Transition Number: 1399.978k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:48:44,340][train][INFO][train.py>_log] ==> #923000     Total Loss: 1.606    [weighted Loss:1.606    Policy Loss: 5.088    Value Loss: 6.223    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1343644    Buffer Size: 30973      Transition Number: 1400.096k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:52:22,364][train][INFO][train.py>_log] ==> #924000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 4.791    Value Loss: 6.088    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1344928    Buffer Size: 30707      Transition Number: 1400.362k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:56:00,209][train][INFO][train.py>_log] ==> #925000     Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 4.460    Value Loss: 6.212    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 1346267    Buffer Size: 30324      Transition Number: 1399.964k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:59:36,744][train][INFO][train.py>_log] ==> #926000     Total Loss: 1.672    [weighted Loss:1.672    Policy Loss: 4.438    Value Loss: 6.055    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 1347504    Buffer Size: 29938      Transition Number: 1400.173k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:03:13,937][train][INFO][train.py>_log] ==> #927000     Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 4.905    Value Loss: 6.053    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 1348978    Buffer Size: 29466      Transition Number: 1400.144k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:06:51,871][train][INFO][train.py>_log] ==> #928000     Total Loss: 1.590    [weighted Loss:1.590    Policy Loss: 4.987    Value Loss: 6.016    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350414    Buffer Size: 28963      Transition Number: 1400.352k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:10:29,044][train][INFO][train.py>_log] ==> #929000     Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 5.155    Value Loss: 5.676    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 1351822    Buffer Size: 28707      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:14:07,630][train][INFO][train.py>_log] ==> #930000     Total Loss: 1.258    [weighted Loss:1.258    Policy Loss: 5.023    Value Loss: 5.801    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1353118    Buffer Size: 28577      Transition Number: 1400.041k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:17:45,346][train][INFO][train.py>_log] ==> #931000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 4.803    Value Loss: 5.778    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1354370    Buffer Size: 28407      Transition Number: 1400.011k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:21:22,325][train][INFO][train.py>_log] ==> #932000     Total Loss: 1.159    [weighted Loss:1.159    Policy Loss: 4.518    Value Loss: 6.039    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 1355764    Buffer Size: 28064      Transition Number: 1399.964k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:24:59,617][train][INFO][train.py>_log] ==> #933000     Total Loss: 2.053    [weighted Loss:2.053    Policy Loss: 5.017    Value Loss: 5.681    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1357010    Buffer Size: 26929      Transition Number: 1399.945k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:28:37,793][train][INFO][train.py>_log] ==> #934000     Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 5.758    Value Loss: 6.084    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1358316    Buffer Size: 25788      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:32:15,531][train][INFO][train.py>_log] ==> #935000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 6.419    Value Loss: 5.667    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1359806    Buffer Size: 25072      Transition Number: 1399.977k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:35:51,184][train][INFO][train.py>_log] ==> #936000     Total Loss: 1.349    [weighted Loss:1.349    Policy Loss: 5.753    Value Loss: 5.698    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1361326    Buffer Size: 24486      Transition Number: 1400.073k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:39:28,653][train][INFO][train.py>_log] ==> #937000     Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 6.035    Value Loss: 5.577    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1362840    Buffer Size: 24401      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:43:05,170][train][INFO][train.py>_log] ==> #938000     Total Loss: 1.153    [weighted Loss:1.153    Policy Loss: 5.990    Value Loss: 5.661    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 1364233    Buffer Size: 24343      Transition Number: 1399.992k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:46:42,096][train][INFO][train.py>_log] ==> #939000     Total Loss: 1.365    [weighted Loss:1.365    Policy Loss: 5.475    Value Loss: 5.660    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 1365831    Buffer Size: 24571      Transition Number: 1400.112k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:50:19,377][train][INFO][train.py>_log] ==> #940000     Total Loss: 1.964    [weighted Loss:1.964    Policy Loss: 6.193    Value Loss: 5.908    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1367500    Buffer Size: 24841      Transition Number: 1400.043k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:53:54,726][train][INFO][train.py>_log] ==> #941000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 5.840    Value Loss: 5.931    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1369494    Buffer Size: 25461      Transition Number: 1399.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:57:30,505][train][INFO][train.py>_log] ==> #942000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 6.576    Value Loss: 6.035    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1371442    Buffer Size: 26082      Transition Number: 1400.055k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:01:05,811][train][INFO][train.py>_log] ==> #943000     Total Loss: 1.577    [weighted Loss:1.577    Policy Loss: 5.384    Value Loss: 5.794    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 1372979    Buffer Size: 26365      Transition Number: 1400.098k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:04:42,585][train][INFO][train.py>_log] ==> #944000     Total Loss: 1.392    [weighted Loss:1.392    Policy Loss: 6.553    Value Loss: 6.103    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 1374456    Buffer Size: 26575      Transition Number: 1399.944k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:08:21,043][train][INFO][train.py>_log] ==> #945000     Total Loss: 0.807    [weighted Loss:0.807    Policy Loss: 5.647    Value Loss: 5.783    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375837    Buffer Size: 26555      Transition Number: 1399.950k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:11:56,483][train][INFO][train.py>_log] ==> #946000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 5.742    Value Loss: 5.858    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 1377303    Buffer Size: 26516      Transition Number: 1399.991k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:15:34,409][train][INFO][train.py>_log] ==> #947000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 5.267    Value Loss: 6.609    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 1378656    Buffer Size: 26520      Transition Number: 1399.960k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:19:12,561][train][INFO][train.py>_log] ==> #948000     Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 5.576    Value Loss: 6.013    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 1380034    Buffer Size: 26540      Transition Number: 1399.994k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:22:50,159][train][INFO][train.py>_log] ==> #949000     Total Loss: 1.615    [weighted Loss:1.615    Policy Loss: 5.462    Value Loss: 6.341    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1381301    Buffer Size: 26582      Transition Number: 1400.419k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:26:29,370][train][INFO][train.py>_log] ==> #950000     Total Loss: 1.017    [weighted Loss:1.017    Policy Loss: 4.761    Value Loss: 5.690    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1382641    Buffer Size: 26622      Transition Number: 1400.043k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:30:05,903][train][INFO][train.py>_log] ==> #951000     Total Loss: 1.959    [weighted Loss:1.959    Policy Loss: 5.160    Value Loss: 5.898    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 1384069    Buffer Size: 26732      Transition Number: 1400.000k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:33:43,179][train][INFO][train.py>_log] ==> #952000     Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 4.833    Value Loss: 5.688    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1385375    Buffer Size: 26827      Transition Number: 1399.974k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:37:20,777][train][INFO][train.py>_log] ==> #953000     Total Loss: 3.259    [weighted Loss:3.259    Policy Loss: 5.157    Value Loss: 6.437    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1386685    Buffer Size: 26701      Transition Number: 1400.050k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:40:56,663][train][INFO][train.py>_log] ==> #954000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 4.944    Value Loss: 5.671    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 1388091    Buffer Size: 26557      Transition Number: 1399.941k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:44:36,372][train][INFO][train.py>_log] ==> #955000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 6.431    Value Loss: 6.123    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 1389390    Buffer Size: 26434      Transition Number: 1400.048k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:48:13,569][train][INFO][train.py>_log] ==> #956000     Total Loss: 1.083    [weighted Loss:1.083    Policy Loss: 5.117    Value Loss: 5.961    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1390726    Buffer Size: 26244      Transition Number: 1400.238k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:51:50,309][train][INFO][train.py>_log] ==> #957000     Total Loss: 0.812    [weighted Loss:0.812    Policy Loss: 4.745    Value Loss: 6.179    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 1392035    Buffer Size: 25920      Transition Number: 1400.033k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:55:28,651][train][INFO][train.py>_log] ==> #958000     Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 5.667    Value Loss: 6.024    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 1393429    Buffer Size: 25502      Transition Number: 1399.972k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:59:06,536][train][INFO][train.py>_log] ==> #959000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 5.458    Value Loss: 6.039    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1394824    Buffer Size: 24916      Transition Number: 1399.968k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:02:44,824][train][INFO][train.py>_log] ==> #960000     Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 5.661    Value Loss: 5.935    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1396168    Buffer Size: 24420      Transition Number: 1400.096k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:06:23,248][train][INFO][train.py>_log] ==> #961000     Total Loss: 0.993    [weighted Loss:0.993    Policy Loss: 5.145    Value Loss: 5.491    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 1397594    Buffer Size: 24302      Transition Number: 1399.978k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:10:00,531][train][INFO][train.py>_log] ==> #962000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 6.088    Value Loss: 5.445    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1399091    Buffer Size: 24203      Transition Number: 1400.182k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:13:37,455][train][INFO][train.py>_log] ==> #963000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 6.144    Value Loss: 5.537    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 1400756    Buffer Size: 24387      Transition Number: 1399.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:17:13,197][train][INFO][train.py>_log] ==> #964000     Total Loss: 0.995    [weighted Loss:0.995    Policy Loss: 5.765    Value Loss: 5.634    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 1402366    Buffer Size: 24620      Transition Number: 1400.039k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:20:52,288][train][INFO][train.py>_log] ==> #965000     Total Loss: 0.582    [weighted Loss:0.582    Policy Loss: 6.497    Value Loss: 5.837    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 1403958    Buffer Size: 24867      Transition Number: 1400.188k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:24:29,613][train][INFO][train.py>_log] ==> #966000     Total Loss: 2.115    [weighted Loss:2.115    Policy Loss: 5.765    Value Loss: 5.852    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1405527    Buffer Size: 25138      Transition Number: 1400.211k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:28:05,466][train][INFO][train.py>_log] ==> #967000     Total Loss: 1.973    [weighted Loss:1.973    Policy Loss: 5.932    Value Loss: 5.561    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 1407025    Buffer Size: 25273      Transition Number: 1399.993k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:31:41,475][train][INFO][train.py>_log] ==> #968000     Total Loss: 1.861    [weighted Loss:1.861    Policy Loss: 5.371    Value Loss: 5.953    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1408457    Buffer Size: 25352      Transition Number: 1399.964k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:35:18,856][train][INFO][train.py>_log] ==> #969000     Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 6.617    Value Loss: 5.766    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1410095    Buffer Size: 25559      Transition Number: 1400.223k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:38:55,453][train][INFO][train.py>_log] ==> #970000     Total Loss: 0.831    [weighted Loss:0.831    Policy Loss: 5.972    Value Loss: 5.730    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411637    Buffer Size: 25760      Transition Number: 1400.055k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:42:31,934][train][INFO][train.py>_log] ==> #971000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 5.492    Value Loss: 6.524    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1413198    Buffer Size: 25972      Transition Number: 1400.103k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:46:07,658][train][INFO][train.py>_log] ==> #972000     Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 5.847    Value Loss: 6.216    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 1414728    Buffer Size: 26215      Transition Number: 1400.116k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:49:45,173][train][INFO][train.py>_log] ==> #973000     Total Loss: 1.128    [weighted Loss:1.128    Policy Loss: 5.616    Value Loss: 5.903    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1416647    Buffer Size: 26794      Transition Number: 1400.031k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:53:22,554][train][INFO][train.py>_log] ==> #974000     Total Loss: 2.559    [weighted Loss:2.559    Policy Loss: 6.589    Value Loss: 6.119    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 1418633    Buffer Size: 27398      Transition Number: 1400.071k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:57:00,024][train][INFO][train.py>_log] ==> #975000     Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 5.435    Value Loss: 6.404    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1420066    Buffer Size: 27578      Transition Number: 1400.005k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:00:37,527][train][INFO][train.py>_log] ==> #976000     Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 4.694    Value Loss: 5.781    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 1421681    Buffer Size: 27723      Transition Number: 1400.274k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:04:15,974][train][INFO][train.py>_log] ==> #977000     Total Loss: 1.565    [weighted Loss:1.565    Policy Loss: 5.002    Value Loss: 6.083    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 1422973    Buffer Size: 27670      Transition Number: 1400.045k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:07:53,490][train][INFO][train.py>_log] ==> #978000     Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 5.190    Value Loss: 6.305    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424318    Buffer Size: 27590      Transition Number: 1399.984k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:11:30,233][train][INFO][train.py>_log] ==> #979000     Total Loss: 2.041    [weighted Loss:2.041    Policy Loss: 5.688    Value Loss: 6.339    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 1425888    Buffer Size: 27768      Transition Number: 1399.987k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:15:06,152][train][INFO][train.py>_log] ==> #980000     Total Loss: 1.934    [weighted Loss:1.934    Policy Loss: 6.038    Value Loss: 6.352    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 1427487    Buffer Size: 27896      Transition Number: 1400.052k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:18:42,134][train][INFO][train.py>_log] ==> #981000     Total Loss: 1.665    [weighted Loss:1.665    Policy Loss: 5.397    Value Loss: 5.994    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 1429125    Buffer Size: 27894      Transition Number: 1400.157k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:22:17,531][train][INFO][train.py>_log] ==> #982000     Total Loss: 1.836    [weighted Loss:1.836    Policy Loss: 5.378    Value Loss: 5.937    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 1430717    Buffer Size: 27888      Transition Number: 1400.050k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:25:53,296][train][INFO][train.py>_log] ==> #983000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 5.375    Value Loss: 5.895    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1432162    Buffer Size: 27798      Transition Number: 1399.983k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:29:30,330][train][INFO][train.py>_log] ==> #984000     Total Loss: 1.477    [weighted Loss:1.477    Policy Loss: 4.713    Value Loss: 5.605    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1433556    Buffer Size: 27691      Transition Number: 1399.981k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:33:07,267][train][INFO][train.py>_log] ==> #985000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 5.355    Value Loss: 6.179    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435000    Buffer Size: 27707      Transition Number: 1399.943k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:36:45,727][train][INFO][train.py>_log] ==> #986000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 5.271    Value Loss: 6.174    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 1436483    Buffer Size: 27726      Transition Number: 1399.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:40:22,544][train][INFO][train.py>_log] ==> #987000     Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 6.472    Value Loss: 5.691    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 1438025    Buffer Size: 27551      Transition Number: 1400.025k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:43:59,931][train][INFO][train.py>_log] ==> #988000     Total Loss: 0.872    [weighted Loss:0.872    Policy Loss: 6.027    Value Loss: 5.810    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 1439490    Buffer Size: 27398      Transition Number: 1400.068k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:47:38,145][train][INFO][train.py>_log] ==> #989000     Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 6.704    Value Loss: 5.889    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440929    Buffer Size: 27290      Transition Number: 1399.963k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:51:15,514][train][INFO][train.py>_log] ==> #990000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 6.786    Value Loss: 5.951    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1442414    Buffer Size: 27175      Transition Number: 1400.095k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:54:51,396][train][INFO][train.py>_log] ==> #991000     Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 6.696    Value Loss: 6.024    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1444048    Buffer Size: 26891      Transition Number: 1400.078k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:58:28,644][train][INFO][train.py>_log] ==> #992000     Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 6.146    Value Loss: 5.781    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 1445685    Buffer Size: 26704      Transition Number: 1400.089k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:02:04,069][train][INFO][train.py>_log] ==> #993000     Total Loss: 1.682    [weighted Loss:1.682    Policy Loss: 5.583    Value Loss: 6.015    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1447162    Buffer Size: 26769      Transition Number: 1399.933k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:05:40,821][train][INFO][train.py>_log] ==> #994000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 5.763    Value Loss: 6.214    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1448670    Buffer Size: 26794      Transition Number: 1399.954k Batch Size: 256        Lr: 0.10000 
