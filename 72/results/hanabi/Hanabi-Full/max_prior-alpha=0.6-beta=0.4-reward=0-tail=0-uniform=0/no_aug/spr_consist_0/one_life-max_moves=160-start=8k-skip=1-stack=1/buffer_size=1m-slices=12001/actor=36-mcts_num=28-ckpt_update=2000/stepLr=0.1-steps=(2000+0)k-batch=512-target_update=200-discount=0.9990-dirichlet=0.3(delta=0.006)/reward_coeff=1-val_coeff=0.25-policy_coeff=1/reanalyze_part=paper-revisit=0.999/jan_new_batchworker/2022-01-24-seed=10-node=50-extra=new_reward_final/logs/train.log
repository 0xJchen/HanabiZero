[2022-01-24 13:08:01,019][train][INFO][train.py>_log] ==> #0          Total Loss: 48.234   [weighted Loss:48.234   Policy Loss: 13.762   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1836       Buffer Size: 1836       Transition Number: 20.006  k Batch Size: 512        Lr: 0.00000 
[2022-01-24 13:11:34,996][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.926    [weighted Loss:4.926    Policy Loss: 12.304   Value Loss: 4.509    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 16116      Buffer Size: 16116      Transition Number: 200.064 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 13:15:06,370][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.636    [weighted Loss:4.636    Policy Loss: 11.591   Value Loss: 4.176    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 30381      Buffer Size: 30381      Transition Number: 376.321 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 13:18:36,735][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.633    [weighted Loss:3.633    Policy Loss: 10.079   Value Loss: 4.031    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 49067      Buffer Size: 49067      Transition Number: 561.668 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 13:22:07,725][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.468    [weighted Loss:4.468    Policy Loss: 9.115    Value Loss: 3.860    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 68039      Buffer Size: 68039      Transition Number: 747.384 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 13:25:45,675][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 7.234    Value Loss: 3.862    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 81353      Buffer Size: 81353      Transition Number: 933.153 k Batch Size: 512        Lr: 0.10000 
[2022-01-24 13:29:47,834][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.137    [weighted Loss:2.137    Policy Loss: 5.491    Value Loss: 3.976    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 96570      Buffer Size: 96570      Transition Number: 1148.173k Batch Size: 512        Lr: 0.10000 
[2022-01-24 13:34:03,223][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 4.775    Value Loss: 3.991    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 108681     Buffer Size: 108681     Transition Number: 1371.124k Batch Size: 512        Lr: 0.10000 
[2022-01-24 13:38:50,275][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 4.737    Value Loss: 3.984    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 122439     Buffer Size: 122439     Transition Number: 1623.268k Batch Size: 512        Lr: 0.10000 
