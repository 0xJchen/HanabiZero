[2021-11-04 02:05:34,312][train][INFO][train.py>_log] ==> #0          Total Loss: 51.278   [weighted Loss:51.278   Policy Loss: 8.028    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 519        Buffer Size: 519        Transition Number: 2.074   k Batch Size: 256        Lr: 0.000   
[2021-11-04 02:08:03,379][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 8.016    Value Loss: 3.233    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 1222       Buffer Size: 1222       Transition Number: 4.740   k Batch Size: 256        Lr: 0.010   
[2021-11-04 02:10:49,490][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 7.706    Value Loss: 2.059    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 2023       Buffer Size: 2023       Transition Number: 7.726   k Batch Size: 256        Lr: 0.020   
[2021-11-04 02:14:00,331][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 7.128    Value Loss: 1.856    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2989       Buffer Size: 2989       Transition Number: 10.776  k Batch Size: 256        Lr: 0.030   
[2021-11-04 02:17:30,313][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 6.052    Value Loss: 1.597    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 3982       Buffer Size: 3982       Transition Number: 14.169  k Batch Size: 256        Lr: 0.040   
[2021-11-04 02:21:04,439][train][INFO][train.py>_log] ==> #5000       Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 5.559    Value Loss: 1.515    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 4959       Buffer Size: 4959       Transition Number: 17.560  k Batch Size: 256        Lr: 0.050   
[2021-11-04 02:24:47,565][train][INFO][train.py>_log] ==> #6000       Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 5.779    Value Loss: 1.586    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 5882       Buffer Size: 5882       Transition Number: 21.085  k Batch Size: 256        Lr: 0.060   
[2021-11-04 02:28:46,489][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 5.882    Value Loss: 1.560    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 6693       Buffer Size: 6693       Transition Number: 24.832  k Batch Size: 256        Lr: 0.070   
[2021-11-04 02:32:43,592][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.640    [weighted Loss:2.640    Policy Loss: 6.138    Value Loss: 1.641    Reward Loss: 0.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 7543       Buffer Size: 7543       Transition Number: 28.547  k Batch Size: 256        Lr: 0.080   
[2021-11-04 02:36:57,842][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 5.677    Value Loss: 1.462    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 8528       Buffer Size: 8528       Transition Number: 32.497  k Batch Size: 256        Lr: 0.090   
[2021-11-04 02:41:02,386][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 6.021    Value Loss: 1.468    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 9340       Buffer Size: 9340       Transition Number: 36.385  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:45:34,299][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 5.823    Value Loss: 1.456    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 10158      Buffer Size: 10158      Transition Number: 40.578  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:50:08,927][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 5.663    Value Loss: 1.428    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 11103      Buffer Size: 11103      Transition Number: 44.856  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:54:57,324][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 6.067    Value Loss: 1.367    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 12002      Buffer Size: 12002      Transition Number: 49.403  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:59:56,480][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.794    [weighted Loss:1.794    Policy Loss: 6.025    Value Loss: 1.393    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 13018      Buffer Size: 13018      Transition Number: 54.132  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:05:11,295][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 5.969    Value Loss: 1.310    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 14030      Buffer Size: 14030      Transition Number: 59.071  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:10:28,478][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 5.869    Value Loss: 1.353    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 15160      Buffer Size: 15160      Transition Number: 64.133  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:15:54,163][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 6.215    Value Loss: 1.432    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 16139      Buffer Size: 16139      Transition Number: 69.153  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:21:10,928][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 5.785    Value Loss: 1.407    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 16989      Buffer Size: 16989      Transition Number: 73.994  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:26:38,713][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 6.499    Value Loss: 1.374    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 17978      Buffer Size: 17978      Transition Number: 79.182  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:32:09,121][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 5.994    Value Loss: 1.464    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 19106      Buffer Size: 19106      Transition Number: 84.404  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:38:08,387][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 6.490    Value Loss: 1.397    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 20032      Buffer Size: 20032      Transition Number: 89.944  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:43:48,628][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 6.493    Value Loss: 1.717    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 21205      Buffer Size: 21205      Transition Number: 95.361  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:49:39,998][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.994    [weighted Loss:2.994    Policy Loss: 6.388    Value Loss: 1.466    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 22243      Buffer Size: 22243      Transition Number: 100.677 k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:55:40,632][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 6.719    Value Loss: 1.622    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 23294      Buffer Size: 23294      Transition Number: 106.334 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:01:45,295][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 6.473    Value Loss: 1.586    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 24428      Buffer Size: 24428      Transition Number: 112.129 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:07:50,344][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.616    [weighted Loss:3.616    Policy Loss: 6.882    Value Loss: 1.713    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 25629      Buffer Size: 25629      Transition Number: 117.955 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:13:58,448][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 6.891    Value Loss: 1.556    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 26674      Buffer Size: 26674      Transition Number: 123.626 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:20:19,223][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 6.475    Value Loss: 1.607    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 27732      Buffer Size: 27732      Transition Number: 129.678 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:26:46,437][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 6.556    Value Loss: 1.598    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 28786      Buffer Size: 28786      Transition Number: 135.610 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:34:13,726][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 6.820    Value Loss: 1.586    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 30141      Buffer Size: 30141      Transition Number: 142.556 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:40:58,554][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 6.550    Value Loss: 1.580    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 31253      Buffer Size: 31253      Transition Number: 148.874 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:47:59,962][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 6.761    Value Loss: 1.469    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 32386      Buffer Size: 30977      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:55:05,172][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 6.809    Value Loss: 1.536    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 33585      Buffer Size: 30190      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:02:15,607][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 6.607    Value Loss: 1.606    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 34687      Buffer Size: 29426      Transition Number: 150.001 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:09:59,458][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.565    [weighted Loss:3.565    Policy Loss: 6.821    Value Loss: 1.647    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 35895      Buffer Size: 28936      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:18:13,816][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 6.875    Value Loss: 1.565    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 37217      Buffer Size: 28365      Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:26:51,560][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 7.046    Value Loss: 1.579    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 38568      Buffer Size: 28093      Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:34:26,813][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.295    [weighted Loss:1.295    Policy Loss: 6.348    Value Loss: 1.315    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 39675      Buffer Size: 27758      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:42:21,191][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 6.706    Value Loss: 1.468    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 40803      Buffer Size: 27333      Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:49:59,240][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.513    [weighted Loss:3.513    Policy Loss: 7.252    Value Loss: 1.599    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 41863      Buffer Size: 26878      Transition Number: 150.020 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:57:59,890][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 7.137    Value Loss: 1.628    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 42868      Buffer Size: 26471      Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:06:23,642][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 6.576    Value Loss: 1.383    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 43974      Buffer Size: 26153      Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:14:42,489][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 6.914    Value Loss: 1.795    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 44969      Buffer Size: 25645      Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:23:14,954][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 7.185    Value Loss: 1.446    Reward Loss: 0.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 46104      Buffer Size: 25274      Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:32:06,173][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 7.074    Value Loss: 1.731    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 47105      Buffer Size: 24784      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:40:45,735][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 7.161    Value Loss: 1.853    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 48090      Buffer Size: 24270      Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:49:56,055][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.004    Value Loss: 1.484    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 49169      Buffer Size: 23728      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:58:51,835][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 6.820    Value Loss: 1.595    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 50156      Buffer Size: 23265      Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:07:27,962][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 7.199    Value Loss: 1.853    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 51047      Buffer Size: 22865      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:16:47,218][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.768    [weighted Loss:3.768    Policy Loss: 6.920    Value Loss: 1.793    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 51971      Buffer Size: 22295      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:26:50,140][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 7.196    Value Loss: 2.073    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 52953      Buffer Size: 21756      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:36:37,430][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 7.359    Value Loss: 2.513    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 53853      Buffer Size: 21201      Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:47:13,305][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 6.831    Value Loss: 2.413    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 54776      Buffer Size: 20599      Transition Number: 150.031 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:58:19,512][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 7.563    Value Loss: 2.592    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 55578      Buffer Size: 19841      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:09:44,308][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 7.366    Value Loss: 2.564    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 56320      Buffer Size: 19054      Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:21:45,797][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 6.786    Value Loss: 2.722    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 57167      Buffer Size: 18278      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:34:17,249][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.446    [weighted Loss:4.446    Policy Loss: 7.132    Value Loss: 2.979    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 57958      Buffer Size: 17488      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:47:15,832][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 7.045    Value Loss: 3.125    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 58766      Buffer Size: 16702      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:01:13,335][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.674    [weighted Loss:3.674    Policy Loss: 6.513    Value Loss: 3.546    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 59493      Buffer Size: 15812      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:15:18,474][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.723    [weighted Loss:3.723    Policy Loss: 7.040    Value Loss: 3.483    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 60132      Buffer Size: 14801      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:29:50,915][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 6.809    Value Loss: 3.525    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 60790      Buffer Size: 13794      Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:44:38,455][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.655    [weighted Loss:3.655    Policy Loss: 6.641    Value Loss: 3.745    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 61448      Buffer Size: 12874      Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:59:58,009][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 6.523    Value Loss: 3.834    Reward Loss: 0.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 62004      Buffer Size: 11751      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 10:15:40,681][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 6.257    Value Loss: 3.856    Reward Loss: 0.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 62588      Buffer Size: 10769      Transition Number: 150.021 k Batch Size: 256        Lr: 0.100   
[2021-11-04 10:31:35,891][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 6.068    Value Loss: 4.198    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 63197      Buffer Size: 9877       Transition Number: 150.024 k Batch Size: 256        Lr: 0.100   
[2021-11-04 10:47:50,743][train][INFO][train.py>_log] ==> #66000      Total Loss: 4.166    [weighted Loss:4.166    Policy Loss: 6.083    Value Loss: 4.298    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 63777      Buffer Size: 8963       Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-11-04 11:04:22,458][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 5.766    Value Loss: 4.300    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 64354      Buffer Size: 8355       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-04 11:21:19,361][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.681    [weighted Loss:4.681    Policy Loss: 5.968    Value Loss: 4.444    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 64930      Buffer Size: 7690       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-11-04 11:38:25,417][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 5.465    Value Loss: 4.020    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 65504      Buffer Size: 7090       Transition Number: 150.100 k Batch Size: 256        Lr: 0.100   
[2021-11-04 11:55:33,016][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 5.636    Value Loss: 4.332    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 66064      Buffer Size: 6705       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-04 12:12:45,202][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.725    [weighted Loss:3.725    Policy Loss: 5.599    Value Loss: 4.492    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 66641      Buffer Size: 6469       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-04 12:30:02,457][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.850    [weighted Loss:2.850    Policy Loss: 5.467    Value Loss: 4.370    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 67218      Buffer Size: 6252       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-11-04 12:47:21,591][train][INFO][train.py>_log] ==> #73000      Total Loss: 4.351    [weighted Loss:4.351    Policy Loss: 5.648    Value Loss: 4.555    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 67799      Buffer Size: 6119       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-11-04 13:04:42,284][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.991    [weighted Loss:4.991    Policy Loss: 5.762    Value Loss: 4.510    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 68346      Buffer Size: 6037       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 13:22:41,456][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 5.658    Value Loss: 4.679    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 68940      Buffer Size: 5913       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-04 13:40:07,435][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 5.704    Value Loss: 4.619    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 69516      Buffer Size: 5855       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 13:57:32,043][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.456    [weighted Loss:4.456    Policy Loss: 5.688    Value Loss: 4.572    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 70072      Buffer Size: 5817       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 14:15:00,046][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.006    [weighted Loss:4.006    Policy Loss: 5.226    Value Loss: 4.215    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 70626      Buffer Size: 5771       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 14:32:24,014][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 5.440    Value Loss: 4.413    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 71201      Buffer Size: 5766       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 14:49:42,046][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 5.243    Value Loss: 4.320    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 71780      Buffer Size: 5771       Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-11-04 15:07:03,044][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.888    [weighted Loss:3.888    Policy Loss: 5.329    Value Loss: 4.623    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 72338      Buffer Size: 5765       Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-11-04 15:24:35,064][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 5.160    Value Loss: 4.550    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 72899      Buffer Size: 5724       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 15:42:00,282][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 5.197    Value Loss: 4.458    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 73464      Buffer Size: 5678       Transition Number: 150.025 k Batch Size: 256        Lr: 0.100   
[2021-11-04 15:59:24,680][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 5.381    Value Loss: 4.843    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 74023      Buffer Size: 5677       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-11-04 16:16:59,383][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.333    [weighted Loss:3.333    Policy Loss: 5.298    Value Loss: 4.317    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 74589      Buffer Size: 5662       Transition Number: 150.043 k Batch Size: 256        Lr: 0.100   
[2021-11-04 16:34:31,426][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.278    [weighted Loss:3.278    Policy Loss: 5.265    Value Loss: 4.465    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 75153      Buffer Size: 5639       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-11-04 16:52:05,631][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 5.030    Value Loss: 4.150    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 75718      Buffer Size: 5619       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-04 17:09:36,465][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 5.411    Value Loss: 4.239    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 76305      Buffer Size: 5649       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-11-04 17:27:19,335][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.385    [weighted Loss:2.385    Policy Loss: 5.096    Value Loss: 4.408    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 76891      Buffer Size: 5643       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-04 17:44:51,213][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 4.791    Value Loss: 4.520    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 77484      Buffer Size: 5641       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-04 18:02:20,468][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.406    [weighted Loss:3.406    Policy Loss: 5.375    Value Loss: 4.457    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 78082      Buffer Size: 5657       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 18:19:47,822][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 4.741    Value Loss: 4.087    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 78667      Buffer Size: 5664       Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-11-04 18:37:18,785][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.985    [weighted Loss:3.985    Policy Loss: 5.242    Value Loss: 4.438    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 79257      Buffer Size: 5673       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-04 18:54:40,245][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.496    [weighted Loss:2.496    Policy Loss: 5.258    Value Loss: 4.287    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 79835      Buffer Size: 5693       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-11-04 19:11:59,223][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 5.152    Value Loss: 4.435    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 80411      Buffer Size: 5721       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 19:29:21,632][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 5.342    Value Loss: 4.437    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 80987      Buffer Size: 5737       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-04 19:46:47,144][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 5.187    Value Loss: 4.668    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 81563      Buffer Size: 5750       Transition Number: 149.972 k Batch Size: 256        Lr: 0.100   
[2021-11-04 20:04:12,391][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.451    [weighted Loss:4.451    Policy Loss: 5.278    Value Loss: 4.505    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 82135      Buffer Size: 5732       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-04 20:21:36,730][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 4.917    Value Loss: 4.775    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 82700      Buffer Size: 5724       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-04 20:39:01,934][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.924    [weighted Loss:3.924    Policy Loss: 4.960    Value Loss: 4.759    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 83274      Buffer Size: 5703       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-11-04 20:56:28,614][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 5.123    Value Loss: 4.331    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 83869      Buffer Size: 5708       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-11-04 21:13:55,498][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.967    [weighted Loss:3.967    Policy Loss: 5.224    Value Loss: 4.675    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 84425      Buffer Size: 5698       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-11-04 21:31:24,965][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.845    [weighted Loss:3.845    Policy Loss: 4.936    Value Loss: 4.234    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 84986      Buffer Size: 5672       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 21:48:49,761][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 4.840    Value Loss: 4.790    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 85558      Buffer Size: 5662       Transition Number: 150.104 k Batch Size: 256        Lr: 0.100   
[2021-11-04 22:06:17,852][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.132    [weighted Loss:4.132    Policy Loss: 4.634    Value Loss: 4.339    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 86128      Buffer Size: 5639       Transition Number: 150.034 k Batch Size: 256        Lr: 0.100   
[2021-11-04 22:23:47,876][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.813    [weighted Loss:2.813    Policy Loss: 5.138    Value Loss: 4.717    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 86706      Buffer Size: 5630       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-11-04 22:41:21,377][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 4.701    Value Loss: 4.677    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 87286      Buffer Size: 5624       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 22:59:00,328][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.083    [weighted Loss:3.083    Policy Loss: 4.869    Value Loss: 4.176    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 87877      Buffer Size: 5633       Transition Number: 150.045 k Batch Size: 256        Lr: 0.100   
[2021-11-04 23:16:38,142][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 4.655    Value Loss: 4.447    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 88448      Buffer Size: 5615       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-11-04 23:34:06,528][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.327    [weighted Loss:3.327    Policy Loss: 4.848    Value Loss: 4.477    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 89028      Buffer Size: 5606       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-04 23:51:35,038][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 4.706    Value Loss: 4.279    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 89604      Buffer Size: 5586       Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-11-05 00:09:06,857][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 4.960    Value Loss: 4.112    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 90196      Buffer Size: 5603       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-05 00:26:36,224][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 4.633    Value Loss: 4.412    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 90769      Buffer Size: 5613       Transition Number: 149.975 k Batch Size: 256        Lr: 0.100   
[2021-11-05 00:44:04,413][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 4.338    Value Loss: 4.196    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 91346      Buffer Size: 5619       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-05 01:01:33,053][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 4.799    Value Loss: 4.232    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 91917      Buffer Size: 5606       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-05 01:19:05,672][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 4.499    Value Loss: 4.445    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 92498      Buffer Size: 5606       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-11-05 01:36:39,569][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 4.553    Value Loss: 4.419    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 93073      Buffer Size: 5602       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-11-05 01:54:12,591][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 4.525    Value Loss: 4.404    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 93647      Buffer Size: 5592       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-05 02:11:49,338][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 4.266    Value Loss: 4.391    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 94214      Buffer Size: 5573       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-05 02:29:19,825][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.817    [weighted Loss:2.817    Policy Loss: 4.262    Value Loss: 4.078    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 94788      Buffer Size: 5569       Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-11-05 02:46:53,028][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 4.428    Value Loss: 4.586    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 95385      Buffer Size: 5581       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-05 03:04:29,271][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.670    [weighted Loss:2.670    Policy Loss: 4.426    Value Loss: 4.307    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 95961      Buffer Size: 5577       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-05 03:21:56,931][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.444    [weighted Loss:3.444    Policy Loss: 4.620    Value Loss: 4.279    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 96543      Buffer Size: 5589       Transition Number: 150.051 k Batch Size: 256        Lr: 0.100   
[2021-11-05 03:39:23,124][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.744    [weighted Loss:3.744    Policy Loss: 4.345    Value Loss: 4.508    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 97134      Buffer Size: 5593       Transition Number: 149.974 k Batch Size: 256        Lr: 0.100   
[2021-11-05 03:56:50,736][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 4.591    Value Loss: 4.401    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 97713      Buffer Size: 5604       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-05 04:14:22,949][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 4.522    Value Loss: 4.409    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 98278      Buffer Size: 5585       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-11-05 04:31:58,396][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 4.086    Value Loss: 4.537    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 98865      Buffer Size: 5598       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-05 04:49:31,411][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 4.078    Value Loss: 4.490    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 99438      Buffer Size: 5583       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-11-05 05:06:59,549][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 4.384    Value Loss: 4.471    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 100036     Buffer Size: 5612       Transition Number: 150.033 k Batch Size: 256        Lr: 0.100   
[2021-11-05 05:24:37,129][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 4.434    Value Loss: 4.261    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 100610     Buffer Size: 5596       Transition Number: 150.071 k Batch Size: 256        Lr: 0.100   
[2021-11-05 05:42:14,831][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 4.250    Value Loss: 4.670    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 101178     Buffer Size: 5572       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-05 05:59:45,587][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 4.285    Value Loss: 4.461    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 101746     Buffer Size: 5569       Transition Number: 149.973 k Batch Size: 256        Lr: 0.100   
[2021-11-05 06:17:11,897][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 3.934    Value Loss: 4.248    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 102313     Buffer Size: 5548       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-05 06:34:41,339][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 4.161    Value Loss: 4.566    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 102869     Buffer Size: 5518       Transition Number: 150.023 k Batch Size: 256        Lr: 0.100   
[2021-11-05 06:52:15,754][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.623    [weighted Loss:3.623    Policy Loss: 4.128    Value Loss: 4.693    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 103442     Buffer Size: 5516       Transition Number: 150.023 k Batch Size: 256        Lr: 0.100   
[2021-11-05 07:09:46,630][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 4.198    Value Loss: 4.375    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 104021     Buffer Size: 5522       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-05 07:27:19,731][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 3.987    Value Loss: 4.311    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 104591     Buffer Size: 5509       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-05 07:44:51,404][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.001    [weighted Loss:3.001    Policy Loss: 3.980    Value Loss: 4.624    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 105169     Buffer Size: 5529       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-11-05 08:02:33,817][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 4.261    Value Loss: 4.225    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 105753     Buffer Size: 5519       Transition Number: 150.025 k Batch Size: 256        Lr: 0.100   
[2021-11-05 08:20:05,683][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 4.220    Value Loss: 4.614    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 106326     Buffer Size: 5527       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-05 08:37:36,841][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.799    [weighted Loss:2.799    Policy Loss: 4.208    Value Loss: 4.337    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 106912     Buffer Size: 5547       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-11-05 08:55:09,479][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 4.317    Value Loss: 4.687    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 107496     Buffer Size: 5546       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-05 09:12:44,196][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 4.106    Value Loss: 4.275    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 108067     Buffer Size: 5554       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-11-05 09:30:29,458][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.130    Value Loss: 4.129    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 108648     Buffer Size: 5568       Transition Number: 150.038 k Batch Size: 256        Lr: 0.100   
[2021-11-05 09:48:04,634][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 4.212    Value Loss: 4.275    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 109229     Buffer Size: 5559       Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-11-05 10:05:48,202][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.475    [weighted Loss:1.475    Policy Loss: 3.911    Value Loss: 4.594    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 109812     Buffer Size: 5545       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-05 10:23:26,452][train][INFO][train.py>_log] ==> #147000     Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 4.068    Value Loss: 4.329    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 110384     Buffer Size: 5548       Transition Number: 149.973 k Batch Size: 256        Lr: 0.100   
[2021-11-05 10:41:03,549][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 3.908    Value Loss: 4.435    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 110963     Buffer Size: 5557       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-11-05 10:58:54,275][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 3.977    Value Loss: 4.496    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 111555     Buffer Size: 5562       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-05 11:16:26,693][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 3.973    Value Loss: 4.231    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 112159     Buffer Size: 5584       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-11-05 11:34:02,341][train][INFO][train.py>_log] ==> #151000     Total Loss: 4.097    [weighted Loss:4.097    Policy Loss: 3.823    Value Loss: 4.608    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 112748     Buffer Size: 5595       Transition Number: 150.077 k Batch Size: 256        Lr: 0.100   
[2021-11-05 11:51:28,386][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.123    [weighted Loss:1.123    Policy Loss: 3.797    Value Loss: 4.345    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 113317     Buffer Size: 5599       Transition Number: 150.056 k Batch Size: 256        Lr: 0.100   
[2021-11-05 12:08:56,597][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 3.777    Value Loss: 4.467    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 113914     Buffer Size: 5623       Transition Number: 150.081 k Batch Size: 256        Lr: 0.100   
[2021-11-05 12:26:23,028][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.701    [weighted Loss:2.701    Policy Loss: 3.826    Value Loss: 4.533    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 114507     Buffer Size: 5629       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-05 12:43:50,866][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.380    [weighted Loss:2.380    Policy Loss: 3.732    Value Loss: 4.421    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 115075     Buffer Size: 5633       Transition Number: 150.002 k Batch Size: 256        Lr: 0.100   
[2021-11-05 13:01:24,086][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 4.038    Value Loss: 4.181    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 115649     Buffer Size: 5649       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-05 13:18:51,418][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 3.692    Value Loss: 4.359    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 116239     Buffer Size: 5662       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-05 13:36:21,889][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 3.717    Value Loss: 4.447    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 116810     Buffer Size: 5667       Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-11-05 13:53:51,546][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.645    [weighted Loss:3.645    Policy Loss: 3.959    Value Loss: 4.412    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 117402     Buffer Size: 5675       Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-11-05 14:11:19,102][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 3.937    Value Loss: 4.572    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 117984     Buffer Size: 5657       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-11-05 14:28:46,610][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 3.810    Value Loss: 4.366    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 118579     Buffer Size: 5669       Transition Number: 150.002 k Batch Size: 256        Lr: 0.100   
[2021-11-05 14:46:07,675][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 3.942    Value Loss: 4.285    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 119157     Buffer Size: 5678       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-05 15:03:35,541][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.328    [weighted Loss:3.328    Policy Loss: 3.824    Value Loss: 4.529    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 119724     Buffer Size: 5653       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-05 15:21:01,562][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 3.984    Value Loss: 4.173    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 120297     Buffer Size: 5659       Transition Number: 150.042 k Batch Size: 256        Lr: 0.100   
[2021-11-05 15:38:26,377][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 3.850    Value Loss: 4.459    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 120883     Buffer Size: 5667       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-11-05 15:55:45,592][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 3.756    Value Loss: 4.613    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 121459     Buffer Size: 5673       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-05 16:13:08,363][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.320    [weighted Loss:2.320    Policy Loss: 3.902    Value Loss: 4.407    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 122036     Buffer Size: 5676       Transition Number: 150.043 k Batch Size: 256        Lr: 0.100   
[2021-11-05 16:30:29,118][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.715    [weighted Loss:2.715    Policy Loss: 4.002    Value Loss: 4.499    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 122617     Buffer Size: 5686       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-05 16:47:49,919][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 3.717    Value Loss: 4.432    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 123197     Buffer Size: 5678       Transition Number: 149.972 k Batch Size: 256        Lr: 0.100   
[2021-11-05 17:05:15,378][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 3.761    Value Loss: 4.598    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 123782     Buffer Size: 5680       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-05 17:23:14,581][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 3.786    Value Loss: 4.061    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 124381     Buffer Size: 5673       Transition Number: 150.044 k Batch Size: 256        Lr: 0.100   
[2021-11-05 17:40:40,207][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 3.924    Value Loss: 4.140    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 124959     Buffer Size: 5666       Transition Number: 150.022 k Batch Size: 256        Lr: 0.100   
[2021-11-05 17:58:05,881][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.886    [weighted Loss:2.886    Policy Loss: 3.918    Value Loss: 4.380    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 125536     Buffer Size: 5668       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-11-05 18:15:30,563][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.673    [weighted Loss:1.673    Policy Loss: 3.890    Value Loss: 4.174    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 126117     Buffer Size: 5680       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-05 18:32:54,262][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.666    [weighted Loss:1.666    Policy Loss: 4.020    Value Loss: 4.445    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 126686     Buffer Size: 5669       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-05 18:50:19,380][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.676    [weighted Loss:2.676    Policy Loss: 3.659    Value Loss: 4.501    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 127278     Buffer Size: 5680       Transition Number: 149.981 k Batch Size: 256        Lr: 0.100   
[2021-11-05 19:07:46,131][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.170    [weighted Loss:3.170    Policy Loss: 4.010    Value Loss: 4.092    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 127856     Buffer Size: 5675       Transition Number: 150.020 k Batch Size: 256        Lr: 0.100   
[2021-11-05 19:25:13,353][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 3.579    Value Loss: 4.855    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 128432     Buffer Size: 5674       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-11-05 19:42:31,712][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 3.905    Value Loss: 4.330    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 129030     Buffer Size: 5687       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-05 19:59:53,965][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 3.640    Value Loss: 4.390    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 129603     Buffer Size: 5689       Transition Number: 149.970 k Batch Size: 256        Lr: 0.100   
[2021-11-05 20:17:15,191][train][INFO][train.py>_log] ==> #181000     Total Loss: 3.525    [weighted Loss:3.525    Policy Loss: 3.966    Value Loss: 4.464    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 130183     Buffer Size: 5692       Transition Number: 150.004 k Batch Size: 256        Lr: 0.100   
[2021-11-05 20:34:31,378][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 3.672    Value Loss: 4.446    Reward Loss: 0.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 130757     Buffer Size: 5697       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-05 20:51:44,896][train][INFO][train.py>_log] ==> #183000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 3.870    Value Loss: 4.336    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 131326     Buffer Size: 5712       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-11-05 21:09:21,931][train][INFO][train.py>_log] ==> #184000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 3.654    Value Loss: 4.192    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 131918     Buffer Size: 5723       Transition Number: 149.970 k Batch Size: 256        Lr: 0.100   
[2021-11-05 21:26:39,536][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.164    [weighted Loss:2.164    Policy Loss: 3.699    Value Loss: 4.348    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 132509     Buffer Size: 5737       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-11-05 21:43:54,325][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 3.771    Value Loss: 4.615    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 133069     Buffer Size: 5740       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-11-05 22:01:07,652][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 3.870    Value Loss: 4.042    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 133628     Buffer Size: 5739       Transition Number: 150.060 k Batch Size: 256        Lr: 0.100   
[2021-11-05 22:18:37,032][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 3.797    Value Loss: 4.638    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 134197     Buffer Size: 5718       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-11-05 22:36:00,024][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.726    [weighted Loss:2.726    Policy Loss: 3.622    Value Loss: 4.582    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 134767     Buffer Size: 5693       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-05 22:53:27,710][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.015    [weighted Loss:1.015    Policy Loss: 3.703    Value Loss: 4.834    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 135349     Buffer Size: 5690       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-11-05 23:11:01,580][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 3.637    Value Loss: 4.599    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 135918     Buffer Size: 5683       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-05 23:28:29,138][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 3.821    Value Loss: 4.639    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 136496     Buffer Size: 5687       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-11-05 23:46:02,729][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.193    [weighted Loss:3.193    Policy Loss: 3.547    Value Loss: 4.519    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 137073     Buffer Size: 5687       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-06 00:03:42,588][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 3.963    Value Loss: 4.562    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 137656     Buffer Size: 5684       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-11-06 00:21:08,340][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 3.941    Value Loss: 4.575    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 138247     Buffer Size: 5679       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-06 00:38:30,192][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.295    [weighted Loss:3.295    Policy Loss: 4.059    Value Loss: 4.513    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 138817     Buffer Size: 5677       Transition Number: 150.091 k Batch Size: 256        Lr: 0.100   
[2021-11-06 00:55:51,928][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.153    [weighted Loss:3.153    Policy Loss: 3.946    Value Loss: 4.399    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 139390     Buffer Size: 5686       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-11-06 01:13:19,869][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 3.546    Value Loss: 4.539    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 139981     Buffer Size: 5701       Transition Number: 149.975 k Batch Size: 256        Lr: 0.100   
[2021-11-06 01:30:35,919][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.379    [weighted Loss:3.379    Policy Loss: 3.851    Value Loss: 4.420    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 140569     Buffer Size: 5722       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-06 01:47:52,961][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 3.536    Value Loss: 4.488    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 141164     Buffer Size: 5747       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-11-06 02:05:07,709][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 3.853    Value Loss: 4.403    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 141754     Buffer Size: 5765       Transition Number: 150.106 k Batch Size: 256        Lr: 0.100   
[2021-11-06 02:22:22,961][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 3.983    Value Loss: 4.656    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 142342     Buffer Size: 5775       Transition Number: 150.050 k Batch Size: 256        Lr: 0.100   
[2021-11-06 02:39:43,973][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 3.779    Value Loss: 4.206    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 142929     Buffer Size: 5784       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-06 02:57:01,225][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.130    [weighted Loss:2.130    Policy Loss: 3.762    Value Loss: 4.290    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 143516     Buffer Size: 5790       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-06 03:14:15,721][train][INFO][train.py>_log] ==> #205000     Total Loss: 1.199    [weighted Loss:1.199    Policy Loss: 3.919    Value Loss: 4.643    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 144103     Buffer Size: 5799       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-11-06 03:31:25,894][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.265    [weighted Loss:1.265    Policy Loss: 3.619    Value Loss: 4.501    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 144671     Buffer Size: 5807       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-11-06 03:48:31,404][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 3.534    Value Loss: 4.480    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 145252     Buffer Size: 5821       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-11-06 04:05:37,865][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 3.768    Value Loss: 4.596    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 145817     Buffer Size: 5819       Transition Number: 150.014 k Batch Size: 256        Lr: 0.100   
[2021-11-06 04:22:45,442][train][INFO][train.py>_log] ==> #209000     Total Loss: 3.206    [weighted Loss:3.206    Policy Loss: 3.619    Value Loss: 4.366    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 146393     Buffer Size: 5810       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-06 04:39:50,789][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 3.647    Value Loss: 4.546    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 146958     Buffer Size: 5790       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-06 04:57:00,853][train][INFO][train.py>_log] ==> #211000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 3.868    Value Loss: 4.598    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 147542     Buffer Size: 5797       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-11-06 05:14:09,825][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.496    [weighted Loss:2.496    Policy Loss: 3.845    Value Loss: 4.482    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 148113     Buffer Size: 5789       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-06 05:31:21,285][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 3.775    Value Loss: 4.319    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 148702     Buffer Size: 5804       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-06 05:48:36,454][train][INFO][train.py>_log] ==> #214000     Total Loss: 4.266    [weighted Loss:4.266    Policy Loss: 3.712    Value Loss: 4.399    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 149294     Buffer Size: 5809       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-06 06:05:43,044][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 3.906    Value Loss: 4.501    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 149867     Buffer Size: 5804       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-11-06 06:22:48,843][train][INFO][train.py>_log] ==> #216000     Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 3.698    Value Loss: 4.313    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 150445     Buffer Size: 5814       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-11-06 06:40:03,645][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 3.579    Value Loss: 4.289    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 151014     Buffer Size: 5803       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-06 06:57:12,401][train][INFO][train.py>_log] ==> #218000     Total Loss: 3.336    [weighted Loss:3.336    Policy Loss: 3.665    Value Loss: 4.509    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 151567     Buffer Size: 5789       Transition Number: 149.973 k Batch Size: 256        Lr: 0.100   
[2021-11-06 07:14:25,957][train][INFO][train.py>_log] ==> #219000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 3.696    Value Loss: 4.451    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 152155     Buffer Size: 5814       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-06 07:31:31,892][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.195    [weighted Loss:3.195    Policy Loss: 3.911    Value Loss: 4.405    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 152745     Buffer Size: 5830       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-11-06 07:48:44,865][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 4.016    Value Loss: 4.357    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 153314     Buffer Size: 5814       Transition Number: 150.033 k Batch Size: 256        Lr: 0.100   
[2021-11-06 08:06:02,880][train][INFO][train.py>_log] ==> #222000     Total Loss: 3.463    [weighted Loss:3.463    Policy Loss: 3.928    Value Loss: 4.380    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 153886     Buffer Size: 5816       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-06 08:23:13,639][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 3.738    Value Loss: 4.680    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 154460     Buffer Size: 5799       Transition Number: 149.973 k Batch Size: 256        Lr: 0.100   
[2021-11-06 08:40:28,284][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.962    [weighted Loss:2.962    Policy Loss: 3.941    Value Loss: 4.279    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 155039     Buffer Size: 5790       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-06 08:57:50,729][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 4.038    Value Loss: 3.973    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 155624     Buffer Size: 5781       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-11-06 09:15:09,727][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.158    [weighted Loss:3.158    Policy Loss: 3.806    Value Loss: 4.642    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 156207     Buffer Size: 5787       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-06 09:32:23,398][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 3.789    Value Loss: 4.511    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 156767     Buffer Size: 5777       Transition Number: 150.143 k Batch Size: 256        Lr: 0.100   
[2021-11-06 09:49:39,422][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.275    [weighted Loss:1.275    Policy Loss: 3.962    Value Loss: 4.359    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 157338     Buffer Size: 5782       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-06 10:06:54,131][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 3.961    Value Loss: 4.549    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 157927     Buffer Size: 5771       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-11-06 10:24:08,526][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.524    [weighted Loss:2.524    Policy Loss: 4.040    Value Loss: 4.356    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 158490     Buffer Size: 5765       Transition Number: 150.040 k Batch Size: 256        Lr: 0.100   
[2021-11-06 10:41:23,009][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 3.924    Value Loss: 4.240    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 159065     Buffer Size: 5780       Transition Number: 150.065 k Batch Size: 256        Lr: 0.100   
[2021-11-06 10:58:37,757][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.343    [weighted Loss:1.343    Policy Loss: 3.882    Value Loss: 4.688    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 159654     Buffer Size: 5779       Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-11-06 11:15:52,557][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 3.649    Value Loss: 4.277    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 160226     Buffer Size: 5771       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-06 11:33:09,147][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 3.690    Value Loss: 4.698    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 160791     Buffer Size: 5759       Transition Number: 150.029 k Batch Size: 256        Lr: 0.100   
[2021-11-06 11:50:26,557][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 3.813    Value Loss: 4.595    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 161353     Buffer Size: 5761       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-11-06 12:07:46,133][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.647    [weighted Loss:2.647    Policy Loss: 3.796    Value Loss: 4.547    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 161925     Buffer Size: 5748       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-06 12:25:00,386][train][INFO][train.py>_log] ==> #237000     Total Loss: 1.345    [weighted Loss:1.345    Policy Loss: 3.723    Value Loss: 4.689    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 162519     Buffer Size: 5790       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-06 12:42:16,990][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 3.714    Value Loss: 4.558    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 163098     Buffer Size: 5786       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-06 12:59:33,397][train][INFO][train.py>_log] ==> #239000     Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 3.527    Value Loss: 4.326    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 163666     Buffer Size: 5770       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-06 13:16:47,952][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 3.905    Value Loss: 4.527    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 164254     Buffer Size: 5779       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-11-06 13:33:58,815][train][INFO][train.py>_log] ==> #241000     Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 3.914    Value Loss: 4.728    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 164839     Buffer Size: 5797       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-06 13:51:14,667][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.034    [weighted Loss:3.034    Policy Loss: 3.553    Value Loss: 4.718    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 165414     Buffer Size: 5791       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-11-06 14:08:30,390][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 3.615    Value Loss: 4.529    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 165996     Buffer Size: 5793       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-11-06 14:25:42,721][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 3.864    Value Loss: 4.519    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 166576     Buffer Size: 5815       Transition Number: 150.044 k Batch Size: 256        Lr: 0.100   
[2021-11-06 14:43:02,650][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 3.692    Value Loss: 4.298    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 167147     Buffer Size: 5816       Transition Number: 150.056 k Batch Size: 256        Lr: 0.100   
[2021-11-06 15:00:12,538][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 3.748    Value Loss: 4.803    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 167734     Buffer Size: 5825       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-11-06 15:17:34,064][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 3.650    Value Loss: 4.586    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 168316     Buffer Size: 5815       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-06 15:34:41,126][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.733    [weighted Loss:2.733    Policy Loss: 3.815    Value Loss: 4.793    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 168883     Buffer Size: 5816       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-11-06 15:51:43,753][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 3.571    Value Loss: 4.466    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 169467     Buffer Size: 5843       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-11-06 16:08:54,784][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.718    [weighted Loss:1.718    Policy Loss: 3.645    Value Loss: 4.617    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 170036     Buffer Size: 5825       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-06 16:26:06,640][train][INFO][train.py>_log] ==> #251000     Total Loss: 2.469    [weighted Loss:2.469    Policy Loss: 3.633    Value Loss: 4.292    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 170609     Buffer Size: 5795       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-11-06 16:43:21,085][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 3.626    Value Loss: 4.525    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 171180     Buffer Size: 5799       Transition Number: 150.056 k Batch Size: 256        Lr: 0.100   
[2021-11-06 17:00:38,426][train][INFO][train.py>_log] ==> #253000     Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 3.722    Value Loss: 4.463    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 171741     Buffer Size: 5786       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-06 17:17:53,258][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 3.678    Value Loss: 4.775    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 172331     Buffer Size: 5793       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-06 17:35:00,815][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 3.804    Value Loss: 4.443    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 172905     Buffer Size: 5797       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-11-06 17:52:12,896][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 3.712    Value Loss: 4.329    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 173492     Buffer Size: 5800       Transition Number: 150.076 k Batch Size: 256        Lr: 0.100   
[2021-11-06 18:09:25,439][train][INFO][train.py>_log] ==> #257000     Total Loss: 0.667    [weighted Loss:0.667    Policy Loss: 3.585    Value Loss: 4.323    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 174058     Buffer Size: 5792       Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
