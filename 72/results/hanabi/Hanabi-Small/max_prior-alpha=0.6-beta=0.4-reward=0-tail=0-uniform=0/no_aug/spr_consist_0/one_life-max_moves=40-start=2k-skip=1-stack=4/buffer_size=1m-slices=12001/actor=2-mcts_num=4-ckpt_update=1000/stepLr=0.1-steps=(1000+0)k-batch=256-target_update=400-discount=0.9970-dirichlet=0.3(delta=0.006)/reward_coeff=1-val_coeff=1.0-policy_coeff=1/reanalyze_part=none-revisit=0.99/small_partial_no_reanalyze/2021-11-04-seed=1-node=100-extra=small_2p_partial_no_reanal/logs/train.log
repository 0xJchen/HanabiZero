[2021-11-04 02:05:34,312][train][INFO][train.py>_log] ==> #0          Total Loss: 51.278   [weighted Loss:51.278   Policy Loss: 8.028    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 519        Buffer Size: 519        Transition Number: 2.074   k Batch Size: 256        Lr: 0.000   
[2021-11-04 02:08:03,379][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 8.016    Value Loss: 3.233    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 1222       Buffer Size: 1222       Transition Number: 4.740   k Batch Size: 256        Lr: 0.010   
[2021-11-04 02:10:49,490][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 7.706    Value Loss: 2.059    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 2023       Buffer Size: 2023       Transition Number: 7.726   k Batch Size: 256        Lr: 0.020   
[2021-11-04 02:14:00,331][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 7.128    Value Loss: 1.856    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2989       Buffer Size: 2989       Transition Number: 10.776  k Batch Size: 256        Lr: 0.030   
[2021-11-04 02:17:30,313][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 6.052    Value Loss: 1.597    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 3982       Buffer Size: 3982       Transition Number: 14.169  k Batch Size: 256        Lr: 0.040   
[2021-11-04 02:21:04,439][train][INFO][train.py>_log] ==> #5000       Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 5.559    Value Loss: 1.515    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 4959       Buffer Size: 4959       Transition Number: 17.560  k Batch Size: 256        Lr: 0.050   
[2021-11-04 02:24:47,565][train][INFO][train.py>_log] ==> #6000       Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 5.779    Value Loss: 1.586    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 5882       Buffer Size: 5882       Transition Number: 21.085  k Batch Size: 256        Lr: 0.060   
[2021-11-04 02:28:46,489][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 5.882    Value Loss: 1.560    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 6693       Buffer Size: 6693       Transition Number: 24.832  k Batch Size: 256        Lr: 0.070   
[2021-11-04 02:32:43,592][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.640    [weighted Loss:2.640    Policy Loss: 6.138    Value Loss: 1.641    Reward Loss: 0.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 7543       Buffer Size: 7543       Transition Number: 28.547  k Batch Size: 256        Lr: 0.080   
[2021-11-04 02:36:57,842][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 5.677    Value Loss: 1.462    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 8528       Buffer Size: 8528       Transition Number: 32.497  k Batch Size: 256        Lr: 0.090   
[2021-11-04 02:41:02,386][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 6.021    Value Loss: 1.468    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 9340       Buffer Size: 9340       Transition Number: 36.385  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:45:34,299][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 5.823    Value Loss: 1.456    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 10158      Buffer Size: 10158      Transition Number: 40.578  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:50:08,927][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 5.663    Value Loss: 1.428    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 11103      Buffer Size: 11103      Transition Number: 44.856  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:54:57,324][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 6.067    Value Loss: 1.367    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 12002      Buffer Size: 12002      Transition Number: 49.403  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:59:56,480][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.794    [weighted Loss:1.794    Policy Loss: 6.025    Value Loss: 1.393    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 13018      Buffer Size: 13018      Transition Number: 54.132  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:05:11,295][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 5.969    Value Loss: 1.310    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 14030      Buffer Size: 14030      Transition Number: 59.071  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:10:28,478][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 5.869    Value Loss: 1.353    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 15160      Buffer Size: 15160      Transition Number: 64.133  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:15:54,163][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 6.215    Value Loss: 1.432    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 16139      Buffer Size: 16139      Transition Number: 69.153  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:21:10,928][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 5.785    Value Loss: 1.407    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 16989      Buffer Size: 16989      Transition Number: 73.994  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:26:38,713][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 6.499    Value Loss: 1.374    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 17978      Buffer Size: 17978      Transition Number: 79.182  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:32:09,121][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 5.994    Value Loss: 1.464    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 19106      Buffer Size: 19106      Transition Number: 84.404  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:38:08,387][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 6.490    Value Loss: 1.397    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 20032      Buffer Size: 20032      Transition Number: 89.944  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:43:48,628][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 6.493    Value Loss: 1.717    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 21205      Buffer Size: 21205      Transition Number: 95.361  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:49:39,998][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.994    [weighted Loss:2.994    Policy Loss: 6.388    Value Loss: 1.466    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 22243      Buffer Size: 22243      Transition Number: 100.677 k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:55:40,632][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 6.719    Value Loss: 1.622    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 23294      Buffer Size: 23294      Transition Number: 106.334 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:01:45,295][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 6.473    Value Loss: 1.586    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 24428      Buffer Size: 24428      Transition Number: 112.129 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:07:50,344][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.616    [weighted Loss:3.616    Policy Loss: 6.882    Value Loss: 1.713    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 25629      Buffer Size: 25629      Transition Number: 117.955 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:13:58,448][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 6.891    Value Loss: 1.556    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 26674      Buffer Size: 26674      Transition Number: 123.626 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:20:19,223][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 6.475    Value Loss: 1.607    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 27732      Buffer Size: 27732      Transition Number: 129.678 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:26:46,437][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 6.556    Value Loss: 1.598    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 28786      Buffer Size: 28786      Transition Number: 135.610 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:34:13,726][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 6.820    Value Loss: 1.586    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 30141      Buffer Size: 30141      Transition Number: 142.556 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:40:58,554][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 6.550    Value Loss: 1.580    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 31253      Buffer Size: 31253      Transition Number: 148.874 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:47:59,962][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 6.761    Value Loss: 1.469    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 32386      Buffer Size: 30977      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:55:05,172][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 6.809    Value Loss: 1.536    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 33585      Buffer Size: 30190      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:02:15,607][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 6.607    Value Loss: 1.606    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 34687      Buffer Size: 29426      Transition Number: 150.001 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:09:59,458][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.565    [weighted Loss:3.565    Policy Loss: 6.821    Value Loss: 1.647    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 35895      Buffer Size: 28936      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:18:13,816][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 6.875    Value Loss: 1.565    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 37217      Buffer Size: 28365      Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:26:51,560][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 7.046    Value Loss: 1.579    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 38568      Buffer Size: 28093      Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:34:26,813][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.295    [weighted Loss:1.295    Policy Loss: 6.348    Value Loss: 1.315    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 39675      Buffer Size: 27758      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:42:21,191][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 6.706    Value Loss: 1.468    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 40803      Buffer Size: 27333      Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:49:59,240][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.513    [weighted Loss:3.513    Policy Loss: 7.252    Value Loss: 1.599    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 41863      Buffer Size: 26878      Transition Number: 150.020 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:57:59,890][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 7.137    Value Loss: 1.628    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 42868      Buffer Size: 26471      Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:06:23,642][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 6.576    Value Loss: 1.383    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 43974      Buffer Size: 26153      Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:14:42,489][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 6.914    Value Loss: 1.795    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 44969      Buffer Size: 25645      Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:23:14,954][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 7.185    Value Loss: 1.446    Reward Loss: 0.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 46104      Buffer Size: 25274      Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:32:06,173][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 7.074    Value Loss: 1.731    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 47105      Buffer Size: 24784      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:40:45,735][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 7.161    Value Loss: 1.853    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 48090      Buffer Size: 24270      Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:49:56,055][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.004    Value Loss: 1.484    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 49169      Buffer Size: 23728      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:58:51,835][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 6.820    Value Loss: 1.595    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 50156      Buffer Size: 23265      Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:07:27,962][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 7.199    Value Loss: 1.853    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 51047      Buffer Size: 22865      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:16:47,218][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.768    [weighted Loss:3.768    Policy Loss: 6.920    Value Loss: 1.793    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 51971      Buffer Size: 22295      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:26:50,140][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 7.196    Value Loss: 2.073    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 52953      Buffer Size: 21756      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:36:37,430][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 7.359    Value Loss: 2.513    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 53853      Buffer Size: 21201      Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:47:13,305][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 6.831    Value Loss: 2.413    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 54776      Buffer Size: 20599      Transition Number: 150.031 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:58:19,512][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 7.563    Value Loss: 2.592    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 55578      Buffer Size: 19841      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:09:44,308][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 7.366    Value Loss: 2.564    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 56320      Buffer Size: 19054      Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:21:45,797][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 6.786    Value Loss: 2.722    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 57167      Buffer Size: 18278      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:34:17,249][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.446    [weighted Loss:4.446    Policy Loss: 7.132    Value Loss: 2.979    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 57958      Buffer Size: 17488      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:47:15,832][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 7.045    Value Loss: 3.125    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 58766      Buffer Size: 16702      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:01:13,335][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.674    [weighted Loss:3.674    Policy Loss: 6.513    Value Loss: 3.546    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 59493      Buffer Size: 15812      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:15:18,474][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.723    [weighted Loss:3.723    Policy Loss: 7.040    Value Loss: 3.483    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 60132      Buffer Size: 14801      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:29:50,915][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 6.809    Value Loss: 3.525    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 60790      Buffer Size: 13794      Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:44:38,455][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.655    [weighted Loss:3.655    Policy Loss: 6.641    Value Loss: 3.745    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 61448      Buffer Size: 12874      Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:59:58,009][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 6.523    Value Loss: 3.834    Reward Loss: 0.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 62004      Buffer Size: 11751      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 10:15:40,681][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 6.257    Value Loss: 3.856    Reward Loss: 0.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 62588      Buffer Size: 10769      Transition Number: 150.021 k Batch Size: 256        Lr: 0.100   
[2021-11-04 10:31:35,891][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 6.068    Value Loss: 4.198    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 63197      Buffer Size: 9877       Transition Number: 150.024 k Batch Size: 256        Lr: 0.100   
[2021-11-04 10:47:50,743][train][INFO][train.py>_log] ==> #66000      Total Loss: 4.166    [weighted Loss:4.166    Policy Loss: 6.083    Value Loss: 4.298    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 63777      Buffer Size: 8963       Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-11-04 11:04:22,458][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 5.766    Value Loss: 4.300    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 64354      Buffer Size: 8355       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-04 11:21:19,361][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.681    [weighted Loss:4.681    Policy Loss: 5.968    Value Loss: 4.444    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 64930      Buffer Size: 7690       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-11-04 11:38:25,417][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 5.465    Value Loss: 4.020    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 65504      Buffer Size: 7090       Transition Number: 150.100 k Batch Size: 256        Lr: 0.100   
[2021-11-04 11:55:33,016][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 5.636    Value Loss: 4.332    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 66064      Buffer Size: 6705       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-04 12:12:45,202][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.725    [weighted Loss:3.725    Policy Loss: 5.599    Value Loss: 4.492    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 66641      Buffer Size: 6469       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-04 12:30:02,457][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.850    [weighted Loss:2.850    Policy Loss: 5.467    Value Loss: 4.370    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 67218      Buffer Size: 6252       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-11-04 12:47:21,591][train][INFO][train.py>_log] ==> #73000      Total Loss: 4.351    [weighted Loss:4.351    Policy Loss: 5.648    Value Loss: 4.555    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 67799      Buffer Size: 6119       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-11-04 13:04:42,284][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.991    [weighted Loss:4.991    Policy Loss: 5.762    Value Loss: 4.510    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 68346      Buffer Size: 6037       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 13:22:41,456][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 5.658    Value Loss: 4.679    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 68940      Buffer Size: 5913       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-04 13:40:07,435][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 5.704    Value Loss: 4.619    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 69516      Buffer Size: 5855       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 13:57:32,043][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.456    [weighted Loss:4.456    Policy Loss: 5.688    Value Loss: 4.572    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 70072      Buffer Size: 5817       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 14:15:00,046][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.006    [weighted Loss:4.006    Policy Loss: 5.226    Value Loss: 4.215    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 70626      Buffer Size: 5771       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 14:32:24,014][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 5.440    Value Loss: 4.413    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 71201      Buffer Size: 5766       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 14:49:42,046][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 5.243    Value Loss: 4.320    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 71780      Buffer Size: 5771       Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-11-04 15:07:03,044][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.888    [weighted Loss:3.888    Policy Loss: 5.329    Value Loss: 4.623    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 72338      Buffer Size: 5765       Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-11-04 15:24:35,064][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 5.160    Value Loss: 4.550    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 72899      Buffer Size: 5724       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 15:42:00,282][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 5.197    Value Loss: 4.458    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 73464      Buffer Size: 5678       Transition Number: 150.025 k Batch Size: 256        Lr: 0.100   
[2021-11-04 15:59:24,680][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 5.381    Value Loss: 4.843    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 74023      Buffer Size: 5677       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-11-04 16:16:59,383][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.333    [weighted Loss:3.333    Policy Loss: 5.298    Value Loss: 4.317    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 74589      Buffer Size: 5662       Transition Number: 150.043 k Batch Size: 256        Lr: 0.100   
[2021-11-04 16:34:31,426][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.278    [weighted Loss:3.278    Policy Loss: 5.265    Value Loss: 4.465    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 75153      Buffer Size: 5639       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-11-04 16:52:05,631][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 5.030    Value Loss: 4.150    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 75718      Buffer Size: 5619       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-04 17:09:36,465][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 5.411    Value Loss: 4.239    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 76305      Buffer Size: 5649       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-11-04 17:27:19,335][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.385    [weighted Loss:2.385    Policy Loss: 5.096    Value Loss: 4.408    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 76891      Buffer Size: 5643       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-04 17:44:51,213][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 4.791    Value Loss: 4.520    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 77484      Buffer Size: 5641       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-04 18:02:20,468][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.406    [weighted Loss:3.406    Policy Loss: 5.375    Value Loss: 4.457    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 78082      Buffer Size: 5657       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 18:19:47,822][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 4.741    Value Loss: 4.087    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 78667      Buffer Size: 5664       Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-11-04 18:37:18,785][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.985    [weighted Loss:3.985    Policy Loss: 5.242    Value Loss: 4.438    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 79257      Buffer Size: 5673       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-04 18:54:40,245][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.496    [weighted Loss:2.496    Policy Loss: 5.258    Value Loss: 4.287    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 79835      Buffer Size: 5693       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-11-04 19:11:59,223][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 5.152    Value Loss: 4.435    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 80411      Buffer Size: 5721       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 19:29:21,632][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 5.342    Value Loss: 4.437    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 80987      Buffer Size: 5737       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-04 19:46:47,144][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 5.187    Value Loss: 4.668    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 81563      Buffer Size: 5750       Transition Number: 149.972 k Batch Size: 256        Lr: 0.100   
[2021-11-04 20:04:12,391][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.451    [weighted Loss:4.451    Policy Loss: 5.278    Value Loss: 4.505    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 82135      Buffer Size: 5732       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-11-04 20:21:36,730][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 4.917    Value Loss: 4.775    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 82700      Buffer Size: 5724       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-04 20:39:01,934][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.924    [weighted Loss:3.924    Policy Loss: 4.960    Value Loss: 4.759    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 83274      Buffer Size: 5703       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-11-04 20:56:28,614][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 5.123    Value Loss: 4.331    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 83869      Buffer Size: 5708       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-11-04 21:13:55,498][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.967    [weighted Loss:3.967    Policy Loss: 5.224    Value Loss: 4.675    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 84425      Buffer Size: 5698       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-11-04 21:31:24,965][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.845    [weighted Loss:3.845    Policy Loss: 4.936    Value Loss: 4.234    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 84986      Buffer Size: 5672       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 21:48:49,761][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 4.840    Value Loss: 4.790    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 85558      Buffer Size: 5662       Transition Number: 150.104 k Batch Size: 256        Lr: 0.100   
[2021-11-04 22:06:17,852][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.132    [weighted Loss:4.132    Policy Loss: 4.634    Value Loss: 4.339    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 86128      Buffer Size: 5639       Transition Number: 150.034 k Batch Size: 256        Lr: 0.100   
[2021-11-04 22:23:47,876][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.813    [weighted Loss:2.813    Policy Loss: 5.138    Value Loss: 4.717    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 86706      Buffer Size: 5630       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-11-04 22:41:21,377][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 4.701    Value Loss: 4.677    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 87286      Buffer Size: 5624       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 22:59:00,328][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.083    [weighted Loss:3.083    Policy Loss: 4.869    Value Loss: 4.176    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 87877      Buffer Size: 5633       Transition Number: 150.045 k Batch Size: 256        Lr: 0.100   
[2021-11-04 23:16:38,142][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 4.655    Value Loss: 4.447    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 88448      Buffer Size: 5615       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-11-04 23:34:06,528][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.327    [weighted Loss:3.327    Policy Loss: 4.848    Value Loss: 4.477    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 89028      Buffer Size: 5606       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-04 23:51:35,038][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 4.706    Value Loss: 4.279    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 89604      Buffer Size: 5586       Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-11-05 00:09:06,857][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 4.960    Value Loss: 4.112    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 90196      Buffer Size: 5603       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-05 00:26:36,224][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 4.633    Value Loss: 4.412    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 90769      Buffer Size: 5613       Transition Number: 149.975 k Batch Size: 256        Lr: 0.100   
[2021-11-05 00:44:04,413][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 4.338    Value Loss: 4.196    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 91346      Buffer Size: 5619       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-11-05 01:01:33,053][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 4.799    Value Loss: 4.232    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 91917      Buffer Size: 5606       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-05 01:19:05,672][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 4.499    Value Loss: 4.445    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 92498      Buffer Size: 5606       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-11-05 01:36:39,569][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 4.553    Value Loss: 4.419    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 93073      Buffer Size: 5602       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-11-05 01:54:12,591][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 4.525    Value Loss: 4.404    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 93647      Buffer Size: 5592       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-11-05 02:11:49,338][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 4.266    Value Loss: 4.391    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 94214      Buffer Size: 5573       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-11-05 02:29:19,825][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.817    [weighted Loss:2.817    Policy Loss: 4.262    Value Loss: 4.078    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 94788      Buffer Size: 5569       Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-11-05 02:46:53,028][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 4.428    Value Loss: 4.586    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 95385      Buffer Size: 5581       Transition Number: 149.971 k Batch Size: 256        Lr: 0.100   
[2021-11-05 03:04:29,271][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.670    [weighted Loss:2.670    Policy Loss: 4.426    Value Loss: 4.307    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 95961      Buffer Size: 5577       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-05 03:21:56,931][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.444    [weighted Loss:3.444    Policy Loss: 4.620    Value Loss: 4.279    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 96543      Buffer Size: 5589       Transition Number: 150.051 k Batch Size: 256        Lr: 0.100   
