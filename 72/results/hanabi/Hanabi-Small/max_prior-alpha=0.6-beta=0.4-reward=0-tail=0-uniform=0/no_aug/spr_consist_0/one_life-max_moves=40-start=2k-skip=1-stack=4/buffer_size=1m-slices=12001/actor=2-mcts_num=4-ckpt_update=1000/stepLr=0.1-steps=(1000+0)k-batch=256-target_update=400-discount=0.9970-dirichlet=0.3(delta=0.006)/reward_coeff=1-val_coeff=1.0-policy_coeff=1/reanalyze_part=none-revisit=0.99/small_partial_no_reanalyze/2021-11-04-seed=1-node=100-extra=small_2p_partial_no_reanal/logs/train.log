[2021-11-04 02:05:34,312][train][INFO][train.py>_log] ==> #0          Total Loss: 51.278   [weighted Loss:51.278   Policy Loss: 8.028    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 519        Buffer Size: 519        Transition Number: 2.074   k Batch Size: 256        Lr: 0.000   
[2021-11-04 02:08:03,379][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 8.016    Value Loss: 3.233    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 1222       Buffer Size: 1222       Transition Number: 4.740   k Batch Size: 256        Lr: 0.010   
[2021-11-04 02:10:49,490][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 7.706    Value Loss: 2.059    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 2023       Buffer Size: 2023       Transition Number: 7.726   k Batch Size: 256        Lr: 0.020   
[2021-11-04 02:14:00,331][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 7.128    Value Loss: 1.856    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2989       Buffer Size: 2989       Transition Number: 10.776  k Batch Size: 256        Lr: 0.030   
[2021-11-04 02:17:30,313][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 6.052    Value Loss: 1.597    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 3982       Buffer Size: 3982       Transition Number: 14.169  k Batch Size: 256        Lr: 0.040   
[2021-11-04 02:21:04,439][train][INFO][train.py>_log] ==> #5000       Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 5.559    Value Loss: 1.515    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 4959       Buffer Size: 4959       Transition Number: 17.560  k Batch Size: 256        Lr: 0.050   
[2021-11-04 02:24:47,565][train][INFO][train.py>_log] ==> #6000       Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 5.779    Value Loss: 1.586    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 5882       Buffer Size: 5882       Transition Number: 21.085  k Batch Size: 256        Lr: 0.060   
[2021-11-04 02:28:46,489][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 5.882    Value Loss: 1.560    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 6693       Buffer Size: 6693       Transition Number: 24.832  k Batch Size: 256        Lr: 0.070   
[2021-11-04 02:32:43,592][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.640    [weighted Loss:2.640    Policy Loss: 6.138    Value Loss: 1.641    Reward Loss: 0.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 7543       Buffer Size: 7543       Transition Number: 28.547  k Batch Size: 256        Lr: 0.080   
[2021-11-04 02:36:57,842][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 5.677    Value Loss: 1.462    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 8528       Buffer Size: 8528       Transition Number: 32.497  k Batch Size: 256        Lr: 0.090   
[2021-11-04 02:41:02,386][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 6.021    Value Loss: 1.468    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 9340       Buffer Size: 9340       Transition Number: 36.385  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:45:34,299][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 5.823    Value Loss: 1.456    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 10158      Buffer Size: 10158      Transition Number: 40.578  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:50:08,927][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 5.663    Value Loss: 1.428    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 11103      Buffer Size: 11103      Transition Number: 44.856  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:54:57,324][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 6.067    Value Loss: 1.367    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 12002      Buffer Size: 12002      Transition Number: 49.403  k Batch Size: 256        Lr: 0.100   
[2021-11-04 02:59:56,480][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.794    [weighted Loss:1.794    Policy Loss: 6.025    Value Loss: 1.393    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 13018      Buffer Size: 13018      Transition Number: 54.132  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:05:11,295][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 5.969    Value Loss: 1.310    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 14030      Buffer Size: 14030      Transition Number: 59.071  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:10:28,478][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 5.869    Value Loss: 1.353    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 15160      Buffer Size: 15160      Transition Number: 64.133  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:15:54,163][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 6.215    Value Loss: 1.432    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 16139      Buffer Size: 16139      Transition Number: 69.153  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:21:10,928][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 5.785    Value Loss: 1.407    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 16989      Buffer Size: 16989      Transition Number: 73.994  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:26:38,713][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 6.499    Value Loss: 1.374    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 17978      Buffer Size: 17978      Transition Number: 79.182  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:32:09,121][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 5.994    Value Loss: 1.464    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 19106      Buffer Size: 19106      Transition Number: 84.404  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:38:08,387][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 6.490    Value Loss: 1.397    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 20032      Buffer Size: 20032      Transition Number: 89.944  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:43:48,628][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 6.493    Value Loss: 1.717    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 21205      Buffer Size: 21205      Transition Number: 95.361  k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:49:39,998][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.994    [weighted Loss:2.994    Policy Loss: 6.388    Value Loss: 1.466    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 22243      Buffer Size: 22243      Transition Number: 100.677 k Batch Size: 256        Lr: 0.100   
[2021-11-04 03:55:40,632][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 6.719    Value Loss: 1.622    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 23294      Buffer Size: 23294      Transition Number: 106.334 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:01:45,295][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 6.473    Value Loss: 1.586    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 24428      Buffer Size: 24428      Transition Number: 112.129 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:07:50,344][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.616    [weighted Loss:3.616    Policy Loss: 6.882    Value Loss: 1.713    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 25629      Buffer Size: 25629      Transition Number: 117.955 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:13:58,448][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 6.891    Value Loss: 1.556    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 26674      Buffer Size: 26674      Transition Number: 123.626 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:20:19,223][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 6.475    Value Loss: 1.607    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 27732      Buffer Size: 27732      Transition Number: 129.678 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:26:46,437][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 6.556    Value Loss: 1.598    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 28786      Buffer Size: 28786      Transition Number: 135.610 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:34:13,726][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 6.820    Value Loss: 1.586    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 30141      Buffer Size: 30141      Transition Number: 142.556 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:40:58,554][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 6.550    Value Loss: 1.580    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 31253      Buffer Size: 31253      Transition Number: 148.874 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:47:59,962][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 6.761    Value Loss: 1.469    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 32386      Buffer Size: 30977      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 04:55:05,172][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 6.809    Value Loss: 1.536    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 33585      Buffer Size: 30190      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:02:15,607][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 6.607    Value Loss: 1.606    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 34687      Buffer Size: 29426      Transition Number: 150.001 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:09:59,458][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.565    [weighted Loss:3.565    Policy Loss: 6.821    Value Loss: 1.647    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 35895      Buffer Size: 28936      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:18:13,816][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 6.875    Value Loss: 1.565    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 37217      Buffer Size: 28365      Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:26:51,560][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 7.046    Value Loss: 1.579    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 38568      Buffer Size: 28093      Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:34:26,813][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.295    [weighted Loss:1.295    Policy Loss: 6.348    Value Loss: 1.315    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 39675      Buffer Size: 27758      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:42:21,191][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 6.706    Value Loss: 1.468    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 40803      Buffer Size: 27333      Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:49:59,240][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.513    [weighted Loss:3.513    Policy Loss: 7.252    Value Loss: 1.599    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 41863      Buffer Size: 26878      Transition Number: 150.020 k Batch Size: 256        Lr: 0.100   
[2021-11-04 05:57:59,890][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 7.137    Value Loss: 1.628    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 42868      Buffer Size: 26471      Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:06:23,642][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 6.576    Value Loss: 1.383    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 43974      Buffer Size: 26153      Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:14:42,489][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 6.914    Value Loss: 1.795    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 44969      Buffer Size: 25645      Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:23:14,954][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 7.185    Value Loss: 1.446    Reward Loss: 0.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 46104      Buffer Size: 25274      Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:32:06,173][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 7.074    Value Loss: 1.731    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 47105      Buffer Size: 24784      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:40:45,735][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 7.161    Value Loss: 1.853    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 48090      Buffer Size: 24270      Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:49:56,055][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.004    Value Loss: 1.484    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 49169      Buffer Size: 23728      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 06:58:51,835][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 6.820    Value Loss: 1.595    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 50156      Buffer Size: 23265      Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:07:27,962][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 7.199    Value Loss: 1.853    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 51047      Buffer Size: 22865      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:16:47,218][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.768    [weighted Loss:3.768    Policy Loss: 6.920    Value Loss: 1.793    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 51971      Buffer Size: 22295      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:26:50,140][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 7.196    Value Loss: 2.073    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 52953      Buffer Size: 21756      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:36:37,430][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 7.359    Value Loss: 2.513    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 53853      Buffer Size: 21201      Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:47:13,305][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 6.831    Value Loss: 2.413    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 54776      Buffer Size: 20599      Transition Number: 150.031 k Batch Size: 256        Lr: 0.100   
[2021-11-04 07:58:19,512][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 7.563    Value Loss: 2.592    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 55578      Buffer Size: 19841      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:09:44,308][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 7.366    Value Loss: 2.564    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 56320      Buffer Size: 19054      Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:21:45,797][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 6.786    Value Loss: 2.722    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 57167      Buffer Size: 18278      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:34:17,249][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.446    [weighted Loss:4.446    Policy Loss: 7.132    Value Loss: 2.979    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 57958      Buffer Size: 17488      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-11-04 08:47:15,832][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 7.045    Value Loss: 3.125    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 58766      Buffer Size: 16702      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:01:13,335][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.674    [weighted Loss:3.674    Policy Loss: 6.513    Value Loss: 3.546    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 59493      Buffer Size: 15812      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-11-04 09:15:18,474][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.723    [weighted Loss:3.723    Policy Loss: 7.040    Value Loss: 3.483    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 60132      Buffer Size: 14801      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
