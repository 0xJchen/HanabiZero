[2022-01-14 02:03:31,129][train][INFO][train.py>_log] ==> #0          Total Loss: 56.045   [weighted Loss:56.045   Policy Loss: 14.944   Value Loss: 37.125   Reward Loss: 31.820   Consistency Loss: 0.000    ] Replay Episodes Collected: 585        Buffer Size: 585        Transition Number: 6.589   k Batch Size: 256        Lr: 0.00000 
[2022-01-14 02:06:01,639][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.913    [weighted Loss:6.913    Policy Loss: 14.905   Value Loss: 4.112    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 3937       Buffer Size: 3937       Transition Number: 48.934  k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:08:37,489][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.496    [weighted Loss:6.496    Policy Loss: 14.187   Value Loss: 3.358    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 7327       Buffer Size: 7327       Transition Number: 91.562  k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:11:07,514][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.666    [weighted Loss:4.666    Policy Loss: 13.212   Value Loss: 3.556    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 12025      Buffer Size: 12025      Transition Number: 133.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:13:36,504][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.895    [weighted Loss:4.895    Policy Loss: 13.440   Value Loss: 3.311    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 16735      Buffer Size: 16735      Transition Number: 176.242 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:16:06,099][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.541    [weighted Loss:4.541    Policy Loss: 13.766   Value Loss: 3.268    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 20416      Buffer Size: 20416      Transition Number: 215.413 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:18:35,004][train][INFO][train.py>_log] ==> #6000       Total Loss: 7.145    [weighted Loss:7.145    Policy Loss: 13.363   Value Loss: 3.375    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 24076      Buffer Size: 24076      Transition Number: 255.189 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:21:03,686][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.388    [weighted Loss:4.388    Policy Loss: 13.818   Value Loss: 3.298    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 25730      Buffer Size: 25730      Transition Number: 292.172 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:23:31,236][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.354    [weighted Loss:4.354    Policy Loss: 13.136   Value Loss: 2.912    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 27381      Buffer Size: 27381      Transition Number: 329.596 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:25:59,559][train][INFO][train.py>_log] ==> #9000       Total Loss: 6.315    [weighted Loss:6.315    Policy Loss: 13.317   Value Loss: 3.021    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 28898      Buffer Size: 28898      Transition Number: 363.772 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:28:27,251][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.346    [weighted Loss:5.346    Policy Loss: 12.630   Value Loss: 3.168    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 30432      Buffer Size: 30432      Transition Number: 401.444 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:30:54,872][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.510    [weighted Loss:5.510    Policy Loss: 13.961   Value Loss: 3.096    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 32076      Buffer Size: 32076      Transition Number: 438.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:33:23,044][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.970    [weighted Loss:4.970    Policy Loss: 12.862   Value Loss: 2.843    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 33750      Buffer Size: 33750      Transition Number: 475.539 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:35:51,962][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.734    [weighted Loss:4.734    Policy Loss: 12.663   Value Loss: 2.901    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 35316      Buffer Size: 35316      Transition Number: 512.001 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:38:20,881][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.567    [weighted Loss:4.567    Policy Loss: 12.894   Value Loss: 3.147    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 36837      Buffer Size: 36837      Transition Number: 549.651 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:40:48,599][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.461    [weighted Loss:4.461    Policy Loss: 12.439   Value Loss: 3.452    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 38699      Buffer Size: 38699      Transition Number: 584.619 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:43:18,547][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.106    [weighted Loss:5.106    Policy Loss: 12.703   Value Loss: 3.190    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 40628      Buffer Size: 40628      Transition Number: 622.473 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:45:46,446][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.283    [weighted Loss:4.283    Policy Loss: 11.462   Value Loss: 3.556    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 42285      Buffer Size: 42285      Transition Number: 658.493 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:48:14,766][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.340    [weighted Loss:4.340    Policy Loss: 10.933   Value Loss: 3.220    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 44061      Buffer Size: 44061      Transition Number: 691.890 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:50:45,135][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 9.614    Value Loss: 3.442    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 44818      Buffer Size: 44818      Transition Number: 718.814 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:53:15,383][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 7.735    Value Loss: 3.602    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 45623      Buffer Size: 45623      Transition Number: 754.019 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:55:46,792][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 8.128    Value Loss: 3.734    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 46148      Buffer Size: 46148      Transition Number: 780.123 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 02:58:15,368][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 6.373    Value Loss: 3.863    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 46691      Buffer Size: 46691      Transition Number: 809.490 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:00:45,528][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 6.330    Value Loss: 3.671    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 47113      Buffer Size: 47113      Transition Number: 839.048 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:03:18,741][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 5.022    Value Loss: 4.021    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 47561      Buffer Size: 47561      Transition Number: 869.905 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:05:52,810][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 6.269    Value Loss: 3.790    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 48052      Buffer Size: 48052      Transition Number: 901.340 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:08:24,164][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.773    [weighted Loss:1.773    Policy Loss: 4.960    Value Loss: 3.958    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 48514      Buffer Size: 48514      Transition Number: 930.089 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:10:58,155][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.542    [weighted Loss:1.542    Policy Loss: 4.329    Value Loss: 3.600    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 49004      Buffer Size: 49004      Transition Number: 961.270 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:13:29,171][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 4.137    Value Loss: 4.036    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 49505      Buffer Size: 49505      Transition Number: 993.577 k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:16:03,680][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 3.977    Value Loss: 4.214    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 49989      Buffer Size: 49989      Transition Number: 1024.961k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:18:38,903][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 5.136    Value Loss: 3.852    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 50513      Buffer Size: 50513      Transition Number: 1059.893k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:21:16,469][train][INFO][train.py>_log] ==> #31000      Total Loss: 0.785    [weighted Loss:0.785    Policy Loss: 4.742    Value Loss: 3.879    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 51043      Buffer Size: 51043      Transition Number: 1095.443k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:23:52,886][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 4.250    Value Loss: 4.256    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 51593      Buffer Size: 51593      Transition Number: 1131.836k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:26:29,104][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 4.049    Value Loss: 4.288    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 52084      Buffer Size: 52084      Transition Number: 1163.880k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:29:06,717][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.062    [weighted Loss:1.062    Policy Loss: 4.032    Value Loss: 4.294    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 52623      Buffer Size: 52623      Transition Number: 1199.729k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:31:48,110][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.182    Value Loss: 3.891    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 53200      Buffer Size: 53200      Transition Number: 1238.466k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:34:31,889][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 4.363    Value Loss: 4.308    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 53790      Buffer Size: 53790      Transition Number: 1278.518k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:37:17,581][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.283    [weighted Loss:1.283    Policy Loss: 4.235    Value Loss: 4.337    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 54396      Buffer Size: 54396      Transition Number: 1317.858k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:40:07,529][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 5.049    Value Loss: 4.132    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 55012      Buffer Size: 55012      Transition Number: 1358.285k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:43:02,485][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 4.383    Value Loss: 4.114    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 55845      Buffer Size: 55845      Transition Number: 1406.549k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:45:58,052][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 5.506    Value Loss: 4.412    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 56611      Buffer Size: 56611      Transition Number: 1450.074k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:48:56,805][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 4.979    Value Loss: 4.321    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 57294      Buffer Size: 57294      Transition Number: 1491.891k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:52:02,215][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 4.989    Value Loss: 4.397    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 58035      Buffer Size: 54890      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:55:09,460][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 4.904    Value Loss: 4.381    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 58811      Buffer Size: 51997      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-14 03:58:19,142][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 4.935    Value Loss: 4.466    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 59588      Buffer Size: 47753      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:01:29,592][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 4.401    Value Loss: 4.636    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 60380      Buffer Size: 43218      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:04:40,938][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 4.187    Value Loss: 4.399    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 61195      Buffer Size: 39384      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:07:52,035][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 4.293    Value Loss: 4.537    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 62042      Buffer Size: 36785      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:11:07,823][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 4.607    Value Loss: 4.731    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 62901      Buffer Size: 35426      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:14:18,736][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 4.351    Value Loss: 4.872    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 63687      Buffer Size: 34157      Transition Number: 1500.240k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:17:26,043][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 3.818    Value Loss: 4.803    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 64502      Buffer Size: 32859      Transition Number: 1500.054k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:20:36,428][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.397    [weighted Loss:1.397    Policy Loss: 3.813    Value Loss: 4.712    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 65369      Buffer Size: 31535      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:23:48,651][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 3.620    Value Loss: 5.013    Reward Loss: 0.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 66202      Buffer Size: 30333      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:27:00,327][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.838    [weighted Loss:1.838    Policy Loss: 3.952    Value Loss: 5.217    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 67107      Buffer Size: 29120      Transition Number: 1500.079k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:30:11,497][train][INFO][train.py>_log] ==> #54000      Total Loss: 0.705    [weighted Loss:0.705    Policy Loss: 3.934    Value Loss: 4.850    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 68052      Buffer Size: 27547      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:33:25,232][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 3.847    Value Loss: 5.128    Reward Loss: 0.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 68961      Buffer Size: 25924      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:36:40,619][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 3.580    Value Loss: 5.136    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 69880      Buffer Size: 24990      Transition Number: 1499.929k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:39:51,496][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 4.599    Value Loss: 5.165    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 70703      Buffer Size: 24798      Transition Number: 1500.080k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:43:04,309][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 3.570    Value Loss: 5.026    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 71578      Buffer Size: 24768      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:46:18,372][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 4.116    Value Loss: 4.998    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 72383      Buffer Size: 24849      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:49:30,795][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.565    [weighted Loss:1.565    Policy Loss: 4.462    Value Loss: 4.787    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 73175      Buffer Size: 24856      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:52:42,389][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 4.198    Value Loss: 5.243    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 73934      Buffer Size: 24853      Transition Number: 1499.919k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:55:54,778][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 5.388    Value Loss: 5.260    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 74704      Buffer Size: 24860      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 04:59:07,335][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 4.408    Value Loss: 5.316    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 75605      Buffer Size: 24997      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:02:19,489][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 4.242    Value Loss: 5.115    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 76480      Buffer Size: 25152      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:05:32,081][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.152    [weighted Loss:2.152    Policy Loss: 4.868    Value Loss: 5.144    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 77295      Buffer Size: 25221      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:08:43,117][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.694    [weighted Loss:2.694    Policy Loss: 4.314    Value Loss: 5.251    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 78136      Buffer Size: 25308      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:11:54,959][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 3.727    Value Loss: 5.396    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 78995      Buffer Size: 25401      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:15:07,793][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.539    [weighted Loss:2.539    Policy Loss: 4.576    Value Loss: 5.394    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 79856      Buffer Size: 25502      Transition Number: 1500.171k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:18:19,467][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 3.979    Value Loss: 5.251    Reward Loss: 0.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 80665      Buffer Size: 25575      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:21:31,216][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.447    [weighted Loss:1.447    Policy Loss: 4.348    Value Loss: 5.574    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 81495      Buffer Size: 25493      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:24:49,214][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 3.496    Value Loss: 5.275    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 84178      Buffer Size: 27265      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:28:05,527][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 3.290    Value Loss: 5.126    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 86834      Buffer Size: 29086      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:31:22,708][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 4.297    Value Loss: 5.279    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 89770      Buffer Size: 31229      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:34:42,610][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 4.202    Value Loss: 5.131    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 92841      Buffer Size: 33415      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:37:54,635][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 4.442    Value Loss: 4.975    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 93611      Buffer Size: 33376      Transition Number: 1500.109k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:41:08,716][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 3.510    Value Loss: 5.151    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 94404      Buffer Size: 33292      Transition Number: 1500.190k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:44:24,901][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 3.978    Value Loss: 4.976    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 95235      Buffer Size: 33260      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:47:37,790][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 4.595    Value Loss: 5.146    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 96048      Buffer Size: 33203      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:50:51,654][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 3.895    Value Loss: 5.076    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 96951      Buffer Size: 33276      Transition Number: 1499.930k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:54:05,501][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 3.516    Value Loss: 5.313    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 97832      Buffer Size: 33325      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-14 05:57:18,751][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.316    [weighted Loss:2.316    Policy Loss: 3.619    Value Loss: 5.333    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 98634      Buffer Size: 33260      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:00:31,233][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 3.630    Value Loss: 4.966    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 99422      Buffer Size: 33174      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:03:46,268][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 3.751    Value Loss: 5.239    Reward Loss: 0.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 100200     Buffer Size: 32949      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:07:01,368][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 3.819    Value Loss: 5.119    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 100966     Buffer Size: 32738      Transition Number: 1499.922k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:10:16,526][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.540    [weighted Loss:1.540    Policy Loss: 3.490    Value Loss: 5.444    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 101751     Buffer Size: 32560      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:13:31,710][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 3.978    Value Loss: 5.074    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 102538     Buffer Size: 32377      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:16:45,020][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 4.629    Value Loss: 5.289    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 103321     Buffer Size: 32262      Transition Number: 1500.130k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:20:00,929][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 4.124    Value Loss: 5.592    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 104102     Buffer Size: 32186      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:23:17,806][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 4.921    Value Loss: 5.066    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 104891     Buffer Size: 32178      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:26:31,207][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 3.958    Value Loss: 5.392    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 105710     Buffer Size: 32168      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:29:45,364][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 4.064    Value Loss: 5.385    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 106513     Buffer Size: 32169      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:33:00,888][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.191    [weighted Loss:2.191    Policy Loss: 4.111    Value Loss: 5.220    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 107343     Buffer Size: 32106      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:36:14,162][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.501    [weighted Loss:2.501    Policy Loss: 4.728    Value Loss: 5.452    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 108121     Buffer Size: 32031      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:39:29,698][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.913    [weighted Loss:1.913    Policy Loss: 4.080    Value Loss: 5.165    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 108936     Buffer Size: 31971      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:42:43,919][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 4.670    Value Loss: 5.849    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 109771     Buffer Size: 31958      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:45:57,026][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 4.419    Value Loss: 5.500    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 110597     Buffer Size: 31939      Transition Number: 1500.054k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:49:12,739][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 5.458    Value Loss: 5.583    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 111490     Buffer Size: 31974      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:52:28,342][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 5.104    Value Loss: 5.619    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 112340     Buffer Size: 32001      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:55:41,152][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.384    [weighted Loss:2.384    Policy Loss: 4.483    Value Loss: 5.379    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 113305     Buffer Size: 32143      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-14 06:58:55,314][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.759    [weighted Loss:2.759    Policy Loss: 5.089    Value Loss: 5.442    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 114280     Buffer Size: 31534      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:02:09,888][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.340    [weighted Loss:2.340    Policy Loss: 4.195    Value Loss: 5.675    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 115255     Buffer Size: 29933      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:05:27,865][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 4.305    Value Loss: 5.597    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 116270     Buffer Size: 28100      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:08:45,848][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 4.640    Value Loss: 5.734    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 117182     Buffer Size: 26168      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:12:02,338][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 4.606    Value Loss: 5.543    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 118110     Buffer Size: 24959      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:15:19,039][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.034    [weighted Loss:2.034    Policy Loss: 4.815    Value Loss: 5.313    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 118957     Buffer Size: 25079      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:18:35,106][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 4.456    Value Loss: 5.482    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 119819     Buffer Size: 25188      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:21:53,777][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 4.651    Value Loss: 5.534    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 120809     Buffer Size: 25343      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:25:12,561][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 4.365    Value Loss: 5.444    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 121778     Buffer Size: 25465      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:28:31,820][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 4.402    Value Loss: 5.829    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 122666     Buffer Size: 25448      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:31:47,747][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 5.102    Value Loss: 5.768    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 123531     Buffer Size: 25441      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:35:04,136][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 4.300    Value Loss: 5.302    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 124392     Buffer Size: 25488      Transition Number: 1500.266k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:38:20,138][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 4.926    Value Loss: 5.794    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 125223     Buffer Size: 25538      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:41:35,746][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 4.421    Value Loss: 5.530    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 126104     Buffer Size: 25682      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:44:52,345][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.773    [weighted Loss:2.773    Policy Loss: 5.038    Value Loss: 5.367    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 127029     Buffer Size: 25829      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:48:10,165][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 4.225    Value Loss: 5.294    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 127991     Buffer Size: 26023      Transition Number: 1500.229k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:51:24,563][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 4.707    Value Loss: 5.990    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 128906     Buffer Size: 26197      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:54:38,040][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 4.887    Value Loss: 5.982    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 129872     Buffer Size: 26447      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-14 07:57:56,620][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 4.276    Value Loss: 5.988    Reward Loss: 0.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 130910     Buffer Size: 26706      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:01:12,056][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 4.713    Value Loss: 5.672    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 131735     Buffer Size: 26750      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:04:27,831][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 4.672    Value Loss: 5.760    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 132582     Buffer Size: 26778      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:07:42,810][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 5.267    Value Loss: 5.781    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 133392     Buffer Size: 26785      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:10:58,814][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 4.419    Value Loss: 5.793    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 134217     Buffer Size: 26780      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:14:18,146][train][INFO][train.py>_log] ==> #123000     Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 5.074    Value Loss: 5.822    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 135084     Buffer Size: 26795      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:17:33,163][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 4.117    Value Loss: 5.844    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 135961     Buffer Size: 26848      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:20:49,825][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.041    [weighted Loss:2.041    Policy Loss: 4.732    Value Loss: 5.959    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 136837     Buffer Size: 26876      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:24:07,185][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 4.814    Value Loss: 6.156    Reward Loss: 0.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 137732     Buffer Size: 26901      Transition Number: 1500.175k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:27:23,995][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 4.557    Value Loss: 5.408    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 138880     Buffer Size: 27154      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:30:43,047][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 4.771    Value Loss: 5.955    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 140035     Buffer Size: 27391      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:33:58,647][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.844    [weighted Loss:2.844    Policy Loss: 4.864    Value Loss: 5.862    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 140852     Buffer Size: 27223      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:37:13,117][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.836    [weighted Loss:1.836    Policy Loss: 4.500    Value Loss: 5.877    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 141684     Buffer Size: 27022      Transition Number: 1500.141k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:40:31,168][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 4.845    Value Loss: 5.763    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 142637     Buffer Size: 26951      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:43:48,868][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 4.692    Value Loss: 5.641    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 143539     Buffer Size: 26882      Transition Number: 1500.067k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:47:07,538][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 4.682    Value Loss: 5.509    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 144500     Buffer Size: 26915      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:50:27,144][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 4.372    Value Loss: 5.561    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 145486     Buffer Size: 26961      Transition Number: 1500.270k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:53:43,628][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.895    [weighted Loss:1.895    Policy Loss: 4.795    Value Loss: 5.758    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 146357     Buffer Size: 26927      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-14 08:57:02,808][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 4.625    Value Loss: 5.545    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 147235     Buffer Size: 26860      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:00:22,194][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 4.920    Value Loss: 5.500    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 148046     Buffer Size: 26703      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:03:42,084][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.154    [weighted Loss:2.154    Policy Loss: 4.464    Value Loss: 5.731    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 148884     Buffer Size: 26587      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:07:01,179][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 4.279    Value Loss: 5.538    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 149760     Buffer Size: 26535      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:10:20,311][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.997    [weighted Loss:1.997    Policy Loss: 4.261    Value Loss: 5.539    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 150625     Buffer Size: 26500      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:13:38,503][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 4.596    Value Loss: 5.644    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 151500     Buffer Size: 26516      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:16:56,140][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 4.582    Value Loss: 5.260    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 152366     Buffer Size: 26467      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:20:13,066][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 4.649    Value Loss: 5.729    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 153305     Buffer Size: 26516      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:23:31,581][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 4.859    Value Loss: 5.612    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 154257     Buffer Size: 26529      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:26:49,893][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 5.202    Value Loss: 5.747    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 155159     Buffer Size: 26499      Transition Number: 1499.936k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:30:07,416][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.498    [weighted Loss:3.498    Policy Loss: 5.149    Value Loss: 5.626    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 156099     Buffer Size: 26429      Transition Number: 1500.159k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:33:27,116][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 5.119    Value Loss: 5.643    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 157001     Buffer Size: 26303      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:36:46,415][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.017    [weighted Loss:3.017    Policy Loss: 4.547    Value Loss: 5.571    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 157928     Buffer Size: 26319      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:40:08,519][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.169    [weighted Loss:3.169    Policy Loss: 5.325    Value Loss: 5.706    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 159634     Buffer Size: 27161      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:43:28,282][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 4.854    Value Loss: 5.968    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 161386     Buffer Size: 28087      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:46:46,532][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 4.664    Value Loss: 5.866    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 162534     Buffer Size: 28429      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:50:02,174][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 4.738    Value Loss: 5.686    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 163641     Buffer Size: 28703      Transition Number: 1499.931k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:53:18,238][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 4.438    Value Loss: 5.742    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 164475     Buffer Size: 28684      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:56:36,523][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 4.961    Value Loss: 5.729    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 165347     Buffer Size: 28668      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-14 09:59:53,985][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.239    [weighted Loss:2.239    Policy Loss: 4.941    Value Loss: 5.892    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 166212     Buffer Size: 28648      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:03:09,781][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.162    [weighted Loss:2.162    Policy Loss: 4.177    Value Loss: 6.195    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 167036     Buffer Size: 28460      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:06:29,418][train][INFO][train.py>_log] ==> #157000     Total Loss: 1.722    [weighted Loss:1.722    Policy Loss: 4.538    Value Loss: 5.786    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 167994     Buffer Size: 28260      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:09:49,717][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.324    [weighted Loss:2.324    Policy Loss: 4.157    Value Loss: 6.067    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 168957     Buffer Size: 28310      Transition Number: 1499.930k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:13:07,938][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 4.455    Value Loss: 6.147    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 169873     Buffer Size: 28416      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:16:24,094][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 4.377    Value Loss: 5.917    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 170794     Buffer Size: 28416      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:19:41,254][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.154    [weighted Loss:2.154    Policy Loss: 4.598    Value Loss: 5.726    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 171670     Buffer Size: 28394      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:22:59,674][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 4.548    Value Loss: 5.479    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 172621     Buffer Size: 28372      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:26:19,690][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 4.863    Value Loss: 5.808    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 173514     Buffer Size: 28299      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:29:40,060][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 4.795    Value Loss: 5.812    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 174406     Buffer Size: 28294      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:33:01,744][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 5.044    Value Loss: 6.067    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 175289     Buffer Size: 28288      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:36:23,067][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 5.416    Value Loss: 6.027    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 176163     Buffer Size: 28307      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:39:40,833][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.311    [weighted Loss:3.311    Policy Loss: 4.572    Value Loss: 5.629    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 176980     Buffer Size: 28352      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:42:59,647][train][INFO][train.py>_log] ==> #168000     Total Loss: 3.358    [weighted Loss:3.358    Policy Loss: 5.782    Value Loss: 5.972    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 177812     Buffer Size: 28386      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:46:19,082][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 4.584    Value Loss: 6.103    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 179759     Buffer Size: 29437      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:49:38,385][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 4.566    Value Loss: 6.195    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 181737     Buffer Size: 30535      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:52:57,464][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 4.729    Value Loss: 5.979    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 183432     Buffer Size: 31386      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:56:16,639][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 4.173    Value Loss: 6.471    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 185151     Buffer Size: 32197      Transition Number: 1499.931k Batch Size: 256        Lr: 0.10000 
[2022-01-14 10:59:35,515][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 4.326    Value Loss: 5.652    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 185974     Buffer Size: 32100      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:02:55,350][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 4.404    Value Loss: 6.245    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 186838     Buffer Size: 31987      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:06:14,827][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 4.072    Value Loss: 5.986    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 187712     Buffer Size: 31898      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:09:34,847][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 4.347    Value Loss: 6.109    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 188583     Buffer Size: 31833      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:12:54,604][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 3.898    Value Loss: 6.168    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 189378     Buffer Size: 31772      Transition Number: 1500.083k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:16:12,761][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 4.073    Value Loss: 6.650    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 190224     Buffer Size: 31274      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:19:32,429][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.478    [weighted Loss:1.478    Policy Loss: 4.640    Value Loss: 6.284    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 191076     Buffer Size: 30344      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:22:52,195][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.715    [weighted Loss:2.715    Policy Loss: 4.023    Value Loss: 5.983    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 191907     Buffer Size: 29808      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:26:11,277][train][INFO][train.py>_log] ==> #181000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 4.425    Value Loss: 5.752    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 192725     Buffer Size: 29480      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:29:28,422][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.644    [weighted Loss:2.644    Policy Loss: 4.721    Value Loss: 5.929    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 193544     Buffer Size: 29345      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:32:47,094][train][INFO][train.py>_log] ==> #183000     Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 4.362    Value Loss: 5.879    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 194375     Buffer Size: 29290      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:36:05,724][train][INFO][train.py>_log] ==> #184000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 4.502    Value Loss: 5.791    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 195230     Buffer Size: 29229      Transition Number: 1500.139k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:39:25,617][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 4.582    Value Loss: 6.256    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 196216     Buffer Size: 29340      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:42:45,734][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.626    [weighted Loss:2.626    Policy Loss: 4.273    Value Loss: 5.609    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 197203     Buffer Size: 29398      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:46:05,001][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 4.889    Value Loss: 6.119    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 198193     Buffer Size: 29433      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:49:23,737][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 4.014    Value Loss: 6.137    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 199181     Buffer Size: 29489      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:52:42,502][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 4.457    Value Loss: 5.658    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 200066     Buffer Size: 29425      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:56:03,954][train][INFO][train.py>_log] ==> #190000     Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 4.547    Value Loss: 5.765    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 200927     Buffer Size: 29343      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-14 11:59:24,247][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 4.254    Value Loss: 5.670    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 201789     Buffer Size: 29225      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:02:43,299][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.958    [weighted Loss:2.958    Policy Loss: 4.744    Value Loss: 5.946    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 202626     Buffer Size: 29159      Transition Number: 1500.170k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:06:05,482][train][INFO][train.py>_log] ==> #193000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 3.731    Value Loss: 5.831    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 203681     Buffer Size: 29324      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:09:29,498][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 4.521    Value Loss: 5.659    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 204766     Buffer Size: 29524      Transition Number: 1500.112k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:12:49,426][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 3.829    Value Loss: 5.963    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 205683     Buffer Size: 29562      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:16:07,524][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.435    [weighted Loss:1.435    Policy Loss: 4.724    Value Loss: 5.738    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 206585     Buffer Size: 29598      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:19:27,838][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.374    [weighted Loss:2.374    Policy Loss: 4.263    Value Loss: 6.021    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 207402     Buffer Size: 29527      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:22:49,303][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 5.039    Value Loss: 6.187    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 208256     Buffer Size: 28330      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:26:11,519][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 4.113    Value Loss: 5.948    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 209257     Buffer Size: 27240      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:29:32,750][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 4.336    Value Loss: 5.987    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 210183     Buffer Size: 26440      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:32:52,986][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 4.125    Value Loss: 5.462    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 210992     Buffer Size: 25683      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:36:12,889][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 4.640    Value Loss: 5.770    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 211852     Buffer Size: 25641      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:39:34,438][train][INFO][train.py>_log] ==> #203000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 4.354    Value Loss: 5.391    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 212757     Buffer Size: 25663      Transition Number: 1500.115k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:42:56,095][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 5.132    Value Loss: 6.064    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 213664     Buffer Size: 25677      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:46:15,414][train][INFO][train.py>_log] ==> #205000     Total Loss: 1.589    [weighted Loss:1.589    Policy Loss: 4.360    Value Loss: 5.789    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 214556     Buffer Size: 25743      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:49:36,038][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 4.365    Value Loss: 5.760    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 215462     Buffer Size: 25802      Transition Number: 1500.083k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:52:56,296][train][INFO][train.py>_log] ==> #207000     Total Loss: 1.832    [weighted Loss:1.832    Policy Loss: 5.067    Value Loss: 6.253    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 216332     Buffer Size: 25792      Transition Number: 1500.070k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:56:15,667][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 5.300    Value Loss: 6.037    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 217191     Buffer Size: 25805      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-14 12:59:35,662][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.494    [weighted Loss:2.494    Policy Loss: 4.961    Value Loss: 5.822    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 218060     Buffer Size: 25834      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:02:56,945][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.589    [weighted Loss:1.589    Policy Loss: 4.625    Value Loss: 5.770    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 218916     Buffer Size: 25873      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:06:16,396][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 5.197    Value Loss: 5.880    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 219785     Buffer Size: 25932      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:09:35,496][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 4.942    Value Loss: 5.196    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 220668     Buffer Size: 25996      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:12:55,618][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 4.917    Value Loss: 5.712    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 221542     Buffer Size: 26004      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:16:16,741][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 5.509    Value Loss: 5.652    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 222450     Buffer Size: 25870      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:19:38,488][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.894    [weighted Loss:2.894    Policy Loss: 6.599    Value Loss: 5.872    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 223412     Buffer Size: 25798      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:23:01,101][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 4.763    Value Loss: 6.341    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 224379     Buffer Size: 25748      Transition Number: 1500.172k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:26:22,268][train][INFO][train.py>_log] ==> #217000     Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 5.713    Value Loss: 5.862    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 225348     Buffer Size: 25770      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:29:43,191][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 4.809    Value Loss: 6.111    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 226316     Buffer Size: 25889      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:33:03,936][train][INFO][train.py>_log] ==> #219000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 5.056    Value Loss: 5.967    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 227245     Buffer Size: 26006      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:36:24,976][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 4.873    Value Loss: 6.425    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 228186     Buffer Size: 26117      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:39:48,599][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.443    [weighted Loss:2.443    Policy Loss: 4.783    Value Loss: 5.679    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 229056     Buffer Size: 26144      Transition Number: 1500.104k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:43:11,425][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 4.290    Value Loss: 5.937    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 229984     Buffer Size: 25922      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:46:35,495][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 6.185    Value Loss: 5.815    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 230890     Buffer Size: 25784      Transition Number: 1500.100k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:49:55,878][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.589    [weighted Loss:2.589    Policy Loss: 5.322    Value Loss: 5.964    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 231788     Buffer Size: 25746      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:53:20,099][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 6.010    Value Loss: 5.928    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 232690     Buffer Size: 25764      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-14 13:56:40,612][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 5.569    Value Loss: 5.599    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 233594     Buffer Size: 25870      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:00:01,504][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 5.158    Value Loss: 6.291    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 234537     Buffer Size: 25952      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:03:23,876][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 5.203    Value Loss: 6.006    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 235465     Buffer Size: 25924      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:06:44,372][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.898    [weighted Loss:2.898    Policy Loss: 5.197    Value Loss: 5.899    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 236507     Buffer Size: 26058      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:10:02,981][train][INFO][train.py>_log] ==> #230000     Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 4.962    Value Loss: 6.302    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 237576     Buffer Size: 26302      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:13:25,695][train][INFO][train.py>_log] ==> #231000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 5.096    Value Loss: 6.529    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 238508     Buffer Size: 26360      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:16:45,232][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 4.356    Value Loss: 5.916    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 239416     Buffer Size: 26378      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:20:05,778][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 4.610    Value Loss: 5.645    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 240249     Buffer Size: 26309      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:23:28,934][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 4.708    Value Loss: 6.089    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 241145     Buffer Size: 26213      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:26:52,753][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 4.536    Value Loss: 5.884    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 242058     Buffer Size: 26203      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:30:13,804][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 5.190    Value Loss: 6.045    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 242949     Buffer Size: 26234      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:33:36,755][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 5.472    Value Loss: 5.881    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 243921     Buffer Size: 26343      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:36:57,510][train][INFO][train.py>_log] ==> #238000     Total Loss: 1.226    [weighted Loss:1.226    Policy Loss: 4.974    Value Loss: 6.087    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 244901     Buffer Size: 26443      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:40:22,195][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 4.605    Value Loss: 5.863    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 245769     Buffer Size: 26398      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:43:46,359][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.000    [weighted Loss:3.000    Policy Loss: 5.027    Value Loss: 5.837    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 246634     Buffer Size: 26341      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:47:09,027][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 4.759    Value Loss: 5.862    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 247589     Buffer Size: 26384      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:50:29,852][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 4.433    Value Loss: 6.152    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 248516     Buffer Size: 26441      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:53:50,713][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 4.492    Value Loss: 6.121    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 249384     Buffer Size: 26335      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-14 14:57:11,949][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 4.430    Value Loss: 5.493    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 250250     Buffer Size: 26211      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:00:34,752][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 5.040    Value Loss: 5.732    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 251165     Buffer Size: 26137      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:03:57,092][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 4.534    Value Loss: 5.965    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 252073     Buffer Size: 26032      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:07:16,551][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 4.717    Value Loss: 6.046    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 253010     Buffer Size: 25973      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:10:40,271][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 4.791    Value Loss: 6.275    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 253934     Buffer Size: 25946      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:14:05,087][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 4.880    Value Loss: 6.067    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 254809     Buffer Size: 25873      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:17:30,065][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.478    [weighted Loss:2.478    Policy Loss: 3.957    Value Loss: 6.085    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 255662     Buffer Size: 25796      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:20:54,658][train][INFO][train.py>_log] ==> #251000     Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 4.818    Value Loss: 5.759    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 256508     Buffer Size: 25724      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:24:18,886][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 6.194    Value Loss: 5.465    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 257370     Buffer Size: 25650      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:27:43,434][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 5.537    Value Loss: 5.518    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 258332     Buffer Size: 25674      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:31:03,851][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 5.156    Value Loss: 5.933    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 259282     Buffer Size: 25684      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:34:26,024][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.611    [weighted Loss:2.611    Policy Loss: 5.402    Value Loss: 5.803    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 260261     Buffer Size: 25718      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:37:46,542][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.959    [weighted Loss:2.959    Policy Loss: 4.846    Value Loss: 5.321    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 261231     Buffer Size: 25728      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:41:07,638][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 4.547    Value Loss: 6.188    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 262136     Buffer Size: 25595      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:44:30,127][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 4.203    Value Loss: 5.524    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 263033     Buffer Size: 25419      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:47:51,020][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 4.293    Value Loss: 5.707    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 263909     Buffer Size: 25421      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:51:14,912][train][INFO][train.py>_log] ==> #260000     Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 4.399    Value Loss: 5.942    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 264864     Buffer Size: 25384      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:54:40,491][train][INFO][train.py>_log] ==> #261000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 4.520    Value Loss: 5.789    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 265752     Buffer Size: 25385      Transition Number: 1500.134k Batch Size: 256        Lr: 0.10000 
[2022-01-14 15:58:02,340][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.636    Value Loss: 6.108    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 266637     Buffer Size: 25383      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:01:23,824][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.618    [weighted Loss:2.618    Policy Loss: 4.806    Value Loss: 5.516    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 267496     Buffer Size: 25353      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:04:46,724][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.490    [weighted Loss:1.490    Policy Loss: 4.767    Value Loss: 5.512    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 268394     Buffer Size: 25328      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:08:08,968][train][INFO][train.py>_log] ==> #265000     Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 4.744    Value Loss: 5.757    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 269263     Buffer Size: 25211      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:11:32,471][train][INFO][train.py>_log] ==> #266000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 5.011    Value Loss: 5.314    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 270184     Buffer Size: 25125      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:14:55,555][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.412    [weighted Loss:2.412    Policy Loss: 5.012    Value Loss: 6.294    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 271039     Buffer Size: 25154      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:18:17,482][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.922    [weighted Loss:2.922    Policy Loss: 4.887    Value Loss: 5.619    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 271940     Buffer Size: 25187      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:21:40,273][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.548    [weighted Loss:2.548    Policy Loss: 4.818    Value Loss: 5.461    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 272860     Buffer Size: 25149      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:25:04,897][train][INFO][train.py>_log] ==> #270000     Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 5.221    Value Loss: 5.888    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 273794     Buffer Size: 25143      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:28:25,064][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 5.121    Value Loss: 5.496    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 274735     Buffer Size: 25259      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:31:45,518][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.960    [weighted Loss:2.960    Policy Loss: 4.905    Value Loss: 5.963    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 275715     Buffer Size: 25352      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:35:07,926][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 5.577    Value Loss: 5.805    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 276709     Buffer Size: 25447      Transition Number: 1500.101k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:38:31,363][train][INFO][train.py>_log] ==> #274000     Total Loss: 4.204    [weighted Loss:4.204    Policy Loss: 5.497    Value Loss: 6.086    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 277714     Buffer Size: 25549      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:41:52,601][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 5.054    Value Loss: 5.979    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 278649     Buffer Size: 25551      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:45:15,839][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 5.265    Value Loss: 5.802    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 279584     Buffer Size: 25561      Transition Number: 1500.061k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:48:39,942][train][INFO][train.py>_log] ==> #277000     Total Loss: 3.304    [weighted Loss:3.304    Policy Loss: 5.007    Value Loss: 5.916    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 280481     Buffer Size: 25620      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:52:04,888][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 5.353    Value Loss: 5.752    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 281408     Buffer Size: 25710      Transition Number: 1500.088k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:55:27,678][train][INFO][train.py>_log] ==> #279000     Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 5.116    Value Loss: 5.953    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 282316     Buffer Size: 25800      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-14 16:58:52,282][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 5.211    Value Loss: 5.777    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 283252     Buffer Size: 25889      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:02:13,176][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 5.169    Value Loss: 6.108    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 284187     Buffer Size: 25893      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:05:32,835][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 5.486    Value Loss: 6.021    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 285128     Buffer Size: 25899      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:08:52,870][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 4.990    Value Loss: 5.816    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 286044     Buffer Size: 25834      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:12:14,300][train][INFO][train.py>_log] ==> #284000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 6.248    Value Loss: 5.592    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 286959     Buffer Size: 25789      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:15:38,243][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 5.268    Value Loss: 6.031    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 287930     Buffer Size: 25812      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:19:00,536][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 5.334    Value Loss: 5.987    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 288867     Buffer Size: 25848      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:22:22,992][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 4.979    Value Loss: 5.843    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 289748     Buffer Size: 25823      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:25:47,540][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 5.472    Value Loss: 5.504    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 290639     Buffer Size: 25814      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:29:08,123][train][INFO][train.py>_log] ==> #289000     Total Loss: 3.464    [weighted Loss:3.464    Policy Loss: 6.104    Value Loss: 5.688    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 291487     Buffer Size: 25822      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:32:31,076][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 5.390    Value Loss: 5.442    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 292373     Buffer Size: 25855      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:35:50,347][train][INFO][train.py>_log] ==> #291000     Total Loss: 3.079    [weighted Loss:3.079    Policy Loss: 4.813    Value Loss: 6.006    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 293279     Buffer Size: 25916      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:39:11,589][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 5.066    Value Loss: 6.023    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 294196     Buffer Size: 25981      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:42:33,994][train][INFO][train.py>_log] ==> #293000     Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 5.528    Value Loss: 6.008    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 295082     Buffer Size: 25998      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:45:58,549][train][INFO][train.py>_log] ==> #294000     Total Loss: 3.176    [weighted Loss:3.176    Policy Loss: 5.527    Value Loss: 5.645    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 295976     Buffer Size: 25997      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:49:21,333][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 5.172    Value Loss: 6.046    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 296889     Buffer Size: 26031      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:52:42,750][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 5.254    Value Loss: 5.856    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 297790     Buffer Size: 26031      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:56:04,987][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.069    [weighted Loss:3.069    Policy Loss: 6.797    Value Loss: 5.876    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 298659     Buffer Size: 25997      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-14 17:59:26,763][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 5.707    Value Loss: 5.976    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 299559     Buffer Size: 25940      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:02:51,564][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 6.215    Value Loss: 6.097    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 300549     Buffer Size: 25969      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:06:16,190][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 6.283    Value Loss: 5.458    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 301582     Buffer Size: 26011      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:09:35,418][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 5.756    Value Loss: 5.680    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 302605     Buffer Size: 26078      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:12:59,719][train][INFO][train.py>_log] ==> #302000     Total Loss: 3.092    [weighted Loss:3.092    Policy Loss: 5.544    Value Loss: 6.151    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 303657     Buffer Size: 26154      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:16:23,494][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 5.922    Value Loss: 5.996    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 304671     Buffer Size: 26193      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:19:43,964][train][INFO][train.py>_log] ==> #304000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 4.890    Value Loss: 5.804    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 305618     Buffer Size: 26251      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:23:06,814][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.200    [weighted Loss:2.200    Policy Loss: 5.750    Value Loss: 5.919    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 306484     Buffer Size: 26201      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:26:29,573][train][INFO][train.py>_log] ==> #306000     Total Loss: 2.756    [weighted Loss:2.756    Policy Loss: 5.102    Value Loss: 5.879    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 307355     Buffer Size: 26143      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:29:53,797][train][INFO][train.py>_log] ==> #307000     Total Loss: 3.208    [weighted Loss:3.208    Policy Loss: 6.171    Value Loss: 6.044    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 308356     Buffer Size: 26197      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:33:15,999][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.938    [weighted Loss:1.938    Policy Loss: 5.115    Value Loss: 6.092    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 309353     Buffer Size: 26282      Transition Number: 1500.176k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:36:40,327][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.511    [weighted Loss:2.511    Policy Loss: 5.384    Value Loss: 6.384    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 310260     Buffer Size: 26301      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:40:01,031][train][INFO][train.py>_log] ==> #310000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 5.798    Value Loss: 6.015    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 311195     Buffer Size: 26319      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:43:23,781][train][INFO][train.py>_log] ==> #311000     Total Loss: 3.303    [weighted Loss:3.303    Policy Loss: 5.621    Value Loss: 6.001    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 312364     Buffer Size: 26580      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:46:47,642][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 5.035    Value Loss: 6.160    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 313549     Buffer Size: 26853      Transition Number: 1500.059k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:50:08,960][train][INFO][train.py>_log] ==> #313000     Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 6.537    Value Loss: 6.565    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 314632     Buffer Size: 27021      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:53:30,526][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 6.110    Value Loss: 6.485    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 315770     Buffer Size: 27231      Transition Number: 1500.077k Batch Size: 256        Lr: 0.10000 
[2022-01-14 18:56:52,216][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 5.867    Value Loss: 6.328    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 316728     Buffer Size: 27299      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:00:13,482][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 5.160    Value Loss: 5.990    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 317681     Buffer Size: 27396      Transition Number: 1500.103k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:03:37,754][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 5.716    Value Loss: 6.668    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 318760     Buffer Size: 27611      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:06:59,662][train][INFO][train.py>_log] ==> #318000     Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 5.547    Value Loss: 6.084    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 319911     Buffer Size: 27893      Transition Number: 1500.135k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:10:21,737][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.648    [weighted Loss:2.648    Policy Loss: 6.202    Value Loss: 6.347    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 321078     Buffer Size: 28166      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:13:44,318][train][INFO][train.py>_log] ==> #320000     Total Loss: 2.958    [weighted Loss:2.958    Policy Loss: 6.747    Value Loss: 6.274    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 322269     Buffer Size: 28420      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:17:05,235][train][INFO][train.py>_log] ==> #321000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 6.216    Value Loss: 6.191    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 323225     Buffer Size: 28534      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:20:27,934][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.720    [weighted Loss:1.720    Policy Loss: 6.866    Value Loss: 6.584    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 324234     Buffer Size: 28650      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:23:48,270][train][INFO][train.py>_log] ==> #323000     Total Loss: 3.782    [weighted Loss:3.782    Policy Loss: 6.239    Value Loss: 6.481    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 325261     Buffer Size: 28838      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:27:10,962][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 5.654    Value Loss: 6.497    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 326326     Buffer Size: 29020      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:30:30,185][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.374    [weighted Loss:2.374    Policy Loss: 5.895    Value Loss: 6.101    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 327308     Buffer Size: 29149      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:33:52,832][train][INFO][train.py>_log] ==> #326000     Total Loss: 3.192    [weighted Loss:3.192    Policy Loss: 6.173    Value Loss: 6.321    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 328280     Buffer Size: 29269      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:37:14,130][train][INFO][train.py>_log] ==> #327000     Total Loss: 3.176    [weighted Loss:3.176    Policy Loss: 5.525    Value Loss: 6.635    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 329247     Buffer Size: 29341      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:40:37,391][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 6.511    Value Loss: 6.428    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 330202     Buffer Size: 29306      Transition Number: 1500.116k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:44:00,299][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 5.871    Value Loss: 6.253    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 331266     Buffer Size: 29368      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:47:21,014][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 6.181    Value Loss: 6.996    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 332353     Buffer Size: 29414      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:50:43,102][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 6.253    Value Loss: 6.846    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 333424     Buffer Size: 29437      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:54:04,951][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 5.153    Value Loss: 6.141    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 334483     Buffer Size: 29511      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-14 19:57:26,042][train][INFO][train.py>_log] ==> #333000     Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 6.490    Value Loss: 6.498    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 335433     Buffer Size: 29569      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:00:45,218][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 5.692    Value Loss: 6.464    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 336368     Buffer Size: 29679      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:04:03,232][train][INFO][train.py>_log] ==> #335000     Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 6.217    Value Loss: 6.217    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 337239     Buffer Size: 29720      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:07:24,045][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 5.668    Value Loss: 6.612    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 338098     Buffer Size: 29642      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:10:46,077][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.346    [weighted Loss:3.346    Policy Loss: 6.137    Value Loss: 6.441    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 339071     Buffer Size: 29635      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:14:07,699][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.767    [weighted Loss:2.767    Policy Loss: 5.837    Value Loss: 6.408    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 340044     Buffer Size: 29692      Transition Number: 1500.112k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:17:28,861][train][INFO][train.py>_log] ==> #339000     Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 6.280    Value Loss: 6.189    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 341172     Buffer Size: 29850      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:20:47,817][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 5.231    Value Loss: 6.645    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 342311     Buffer Size: 29820      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:24:09,969][train][INFO][train.py>_log] ==> #341000     Total Loss: 3.000    [weighted Loss:3.000    Policy Loss: 5.975    Value Loss: 6.823    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 343386     Buffer Size: 29742      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:27:31,459][train][INFO][train.py>_log] ==> #342000     Total Loss: 3.626    [weighted Loss:3.626    Policy Loss: 5.793    Value Loss: 6.515    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 344484     Buffer Size: 29726      Transition Number: 1500.080k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:30:55,580][train][INFO][train.py>_log] ==> #343000     Total Loss: 3.217    [weighted Loss:3.217    Policy Loss: 5.567    Value Loss: 6.660    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 345499     Buffer Size: 29608      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:34:18,233][train][INFO][train.py>_log] ==> #344000     Total Loss: 3.079    [weighted Loss:3.079    Policy Loss: 5.776    Value Loss: 6.391    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 346491     Buffer Size: 29635      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:37:40,546][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 6.995    Value Loss: 6.583    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 347618     Buffer Size: 29793      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:41:03,755][train][INFO][train.py>_log] ==> #346000     Total Loss: 3.131    [weighted Loss:3.131    Policy Loss: 5.805    Value Loss: 6.587    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 348776     Buffer Size: 29874      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:44:25,691][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 6.209    Value Loss: 6.658    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 349961     Buffer Size: 29938      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:47:47,657][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 5.647    Value Loss: 6.799    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 351093     Buffer Size: 29887      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:51:06,647][train][INFO][train.py>_log] ==> #349000     Total Loss: 2.802    [weighted Loss:2.802    Policy Loss: 5.469    Value Loss: 6.873    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 352116     Buffer Size: 29801      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:54:26,283][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 6.298    Value Loss: 6.564    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 353177     Buffer Size: 29876      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-14 20:57:47,238][train][INFO][train.py>_log] ==> #351000     Total Loss: 0.950    [weighted Loss:0.950    Policy Loss: 6.175    Value Loss: 7.001    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 354402     Buffer Size: 30078      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:01:08,840][train][INFO][train.py>_log] ==> #352000     Total Loss: 3.372    [weighted Loss:3.372    Policy Loss: 6.087    Value Loss: 7.326    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 355592     Buffer Size: 30195      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:04:29,699][train][INFO][train.py>_log] ==> #353000     Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 5.664    Value Loss: 6.676    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 356714     Buffer Size: 30282      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:07:51,310][train][INFO][train.py>_log] ==> #354000     Total Loss: 3.219    [weighted Loss:3.219    Policy Loss: 5.721    Value Loss: 6.752    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 357854     Buffer Size: 30443      Transition Number: 1500.168k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:11:11,641][train][INFO][train.py>_log] ==> #355000     Total Loss: 4.277    [weighted Loss:4.277    Policy Loss: 6.685    Value Loss: 6.861    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 358965     Buffer Size: 30595      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:14:31,970][train][INFO][train.py>_log] ==> #356000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 6.081    Value Loss: 6.877    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 360093     Buffer Size: 30760      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:17:51,590][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 5.800    Value Loss: 6.665    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 361421     Buffer Size: 31142      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:21:10,736][train][INFO][train.py>_log] ==> #358000     Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 5.602    Value Loss: 7.029    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 362765     Buffer Size: 31425      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:24:30,630][train][INFO][train.py>_log] ==> #359000     Total Loss: 3.136    [weighted Loss:3.136    Policy Loss: 4.882    Value Loss: 6.417    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 363740     Buffer Size: 31365      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:27:52,203][train][INFO][train.py>_log] ==> #360000     Total Loss: 3.076    [weighted Loss:3.076    Policy Loss: 4.991    Value Loss: 6.624    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 364740     Buffer Size: 31301      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:31:12,974][train][INFO][train.py>_log] ==> #361000     Total Loss: 1.396    [weighted Loss:1.396    Policy Loss: 5.016    Value Loss: 6.270    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 365692     Buffer Size: 31206      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:34:34,441][train][INFO][train.py>_log] ==> #362000     Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 4.965    Value Loss: 6.725    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 366657     Buffer Size: 31193      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:37:54,096][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.019    [weighted Loss:3.019    Policy Loss: 5.467    Value Loss: 6.939    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 367567     Buffer Size: 31168      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:41:14,687][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 4.793    Value Loss: 6.553    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 368455     Buffer Size: 31194      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:44:35,204][train][INFO][train.py>_log] ==> #365000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 4.965    Value Loss: 6.693    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 369306     Buffer Size: 31203      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:47:55,800][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 5.786    Value Loss: 6.433    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 370168     Buffer Size: 31099      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:51:17,587][train][INFO][train.py>_log] ==> #367000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 5.116    Value Loss: 6.634    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 371334     Buffer Size: 31215      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:54:41,705][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 5.195    Value Loss: 6.356    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 372498     Buffer Size: 31264      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-14 21:58:02,961][train][INFO][train.py>_log] ==> #369000     Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 6.297    Value Loss: 6.933    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 373640     Buffer Size: 31306      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:01:24,231][train][INFO][train.py>_log] ==> #370000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 5.568    Value Loss: 6.344    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 374799     Buffer Size: 31386      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:04:42,756][train][INFO][train.py>_log] ==> #371000     Total Loss: 3.239    [weighted Loss:3.239    Policy Loss: 6.071    Value Loss: 6.733    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 376075     Buffer Size: 31622      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:08:03,079][train][INFO][train.py>_log] ==> #372000     Total Loss: 3.133    [weighted Loss:3.133    Policy Loss: 5.862    Value Loss: 6.681    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 377451     Buffer Size: 32000      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:11:23,012][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.076    [weighted Loss:2.076    Policy Loss: 6.214    Value Loss: 6.664    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 378666     Buffer Size: 32281      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:14:42,567][train][INFO][train.py>_log] ==> #374000     Total Loss: 3.767    [weighted Loss:3.767    Policy Loss: 5.728    Value Loss: 6.071    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 379910     Buffer Size: 32401      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:18:04,199][train][INFO][train.py>_log] ==> #375000     Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 5.284    Value Loss: 6.562    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 380934     Buffer Size: 32273      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:21:26,208][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.006    [weighted Loss:2.006    Policy Loss: 5.438    Value Loss: 6.816    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 381913     Buffer Size: 32100      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:24:47,861][train][INFO][train.py>_log] ==> #377000     Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 4.783    Value Loss: 6.368    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 382844     Buffer Size: 31917      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:28:09,154][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 5.755    Value Loss: 6.616    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 383788     Buffer Size: 31769      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:31:30,918][train][INFO][train.py>_log] ==> #379000     Total Loss: 1.400    [weighted Loss:1.400    Policy Loss: 4.839    Value Loss: 6.988    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 384766     Buffer Size: 31713      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:34:51,556][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 4.633    Value Loss: 6.398    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 385742     Buffer Size: 31505      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:38:11,774][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 5.372    Value Loss: 6.453    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 386575     Buffer Size: 31214      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:41:35,779][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 5.135    Value Loss: 6.373    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 387435     Buffer Size: 30939      Transition Number: 1500.154k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:44:57,649][train][INFO][train.py>_log] ==> #383000     Total Loss: 3.177    [weighted Loss:3.177    Policy Loss: 5.149    Value Loss: 6.873    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 388301     Buffer Size: 30644      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:48:21,235][train][INFO][train.py>_log] ==> #384000     Total Loss: 1.990    [weighted Loss:1.990    Policy Loss: 5.020    Value Loss: 6.140    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 389184     Buffer Size: 30344      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:51:44,962][train][INFO][train.py>_log] ==> #385000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 4.889    Value Loss: 6.230    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 390055     Buffer Size: 30097      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:55:13,576][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 5.453    Value Loss: 6.164    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 390927     Buffer Size: 29665      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-14 22:58:37,356][train][INFO][train.py>_log] ==> #387000     Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 5.613    Value Loss: 6.406    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 391904     Buffer Size: 29262      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:01:59,961][train][INFO][train.py>_log] ==> #388000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 5.556    Value Loss: 5.843    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 392838     Buffer Size: 29147      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:05:26,185][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 5.732    Value Loss: 6.279    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 393956     Buffer Size: 29235      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:08:48,673][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.912    [weighted Loss:2.912    Policy Loss: 5.857    Value Loss: 6.515    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 395099     Buffer Size: 29367      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:12:13,917][train][INFO][train.py>_log] ==> #391000     Total Loss: 3.311    [weighted Loss:3.311    Policy Loss: 4.905    Value Loss: 5.998    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 396317     Buffer Size: 29571      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:15:36,919][train][INFO][train.py>_log] ==> #392000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 6.268    Value Loss: 6.476    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 397563     Buffer Size: 29836      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:18:57,793][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 5.787    Value Loss: 6.803    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 398790     Buffer Size: 30146      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:22:19,667][train][INFO][train.py>_log] ==> #394000     Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 5.860    Value Loss: 6.671    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 400016     Buffer Size: 30484      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:25:40,504][train][INFO][train.py>_log] ==> #395000     Total Loss: 1.444    [weighted Loss:1.444    Policy Loss: 5.258    Value Loss: 6.684    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 401073     Buffer Size: 30636      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:29:02,538][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 5.522    Value Loss: 7.018    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 402096     Buffer Size: 30545      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:32:26,344][train][INFO][train.py>_log] ==> #397000     Total Loss: 2.861    [weighted Loss:2.861    Policy Loss: 4.913    Value Loss: 6.376    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 403089     Buffer Size: 30351      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:35:50,972][train][INFO][train.py>_log] ==> #398000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 4.718    Value Loss: 6.015    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 404057     Buffer Size: 30157      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:39:13,530][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 5.611    Value Loss: 6.475    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 405272     Buffer Size: 30131      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:42:36,245][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 5.474    Value Loss: 6.523    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 406525     Buffer Size: 29996      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:45:59,551][train][INFO][train.py>_log] ==> #401000     Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 6.304    Value Loss: 6.513    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 407605     Buffer Size: 29752      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:49:21,700][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 4.879    Value Loss: 6.541    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 408732     Buffer Size: 29639      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:52:41,482][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 5.635    Value Loss: 6.344    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 409645     Buffer Size: 29375      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:56:05,607][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.356    [weighted Loss:2.356    Policy Loss: 4.862    Value Loss: 5.930    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 410558     Buffer Size: 29277      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-14 23:59:27,122][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 5.072    Value Loss: 6.847    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 411461     Buffer Size: 29188      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:02:52,395][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 4.893    Value Loss: 6.437    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 412353     Buffer Size: 29160      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:06:14,250][train][INFO][train.py>_log] ==> #407000     Total Loss: 3.226    [weighted Loss:3.226    Policy Loss: 5.782    Value Loss: 6.189    Reward Loss: 1.152    Consistency Loss: 0.000    ] Replay Episodes Collected: 413323     Buffer Size: 29144      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:09:38,901][train][INFO][train.py>_log] ==> #408000     Total Loss: 2.305    [weighted Loss:2.305    Policy Loss: 4.954    Value Loss: 6.028    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 414301     Buffer Size: 29109      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:13:02,621][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 4.353    Value Loss: 6.654    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 415284     Buffer Size: 29180      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:16:26,194][train][INFO][train.py>_log] ==> #410000     Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 4.527    Value Loss: 6.330    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 416316     Buffer Size: 29329      Transition Number: 1500.081k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:19:45,971][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 4.877    Value Loss: 6.258    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 417299     Buffer Size: 29461      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:23:09,143][train][INFO][train.py>_log] ==> #412000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 5.305    Value Loss: 6.601    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 418327     Buffer Size: 29608      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:26:30,387][train][INFO][train.py>_log] ==> #413000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 4.977    Value Loss: 6.290    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 419260     Buffer Size: 29713      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:29:53,333][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.382    [weighted Loss:2.382    Policy Loss: 5.280    Value Loss: 6.542    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 420208     Buffer Size: 29790      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:33:17,170][train][INFO][train.py>_log] ==> #415000     Total Loss: 1.197    [weighted Loss:1.197    Policy Loss: 5.464    Value Loss: 6.059    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 421240     Buffer Size: 29892      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:36:38,822][train][INFO][train.py>_log] ==> #416000     Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 6.663    Value Loss: 6.294    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 422237     Buffer Size: 29946      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:40:04,044][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 4.769    Value Loss: 6.346    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 423780     Buffer Size: 30432      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:43:27,195][train][INFO][train.py>_log] ==> #418000     Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 6.469    Value Loss: 6.527    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 425279     Buffer Size: 30819      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:46:48,785][train][INFO][train.py>_log] ==> #419000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 5.293    Value Loss: 6.933    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 426834     Buffer Size: 31243      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:50:08,851][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 5.590    Value Loss: 7.006    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 428431     Buffer Size: 31632      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:53:29,854][train][INFO][train.py>_log] ==> #421000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 4.611    Value Loss: 6.701    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 429808     Buffer Size: 31749      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-15 00:56:53,286][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 5.060    Value Loss: 6.801    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 431184     Buffer Size: 31916      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:00:15,052][train][INFO][train.py>_log] ==> #423000     Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 4.785    Value Loss: 6.847    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 432027     Buffer Size: 31636      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:03:38,593][train][INFO][train.py>_log] ==> #424000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 4.639    Value Loss: 6.390    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 432924     Buffer Size: 31443      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:06:59,329][train][INFO][train.py>_log] ==> #425000     Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 4.926    Value Loss: 6.656    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 433775     Buffer Size: 31268      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:10:23,345][train][INFO][train.py>_log] ==> #426000     Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 4.642    Value Loss: 6.365    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 434660     Buffer Size: 31114      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:13:46,559][train][INFO][train.py>_log] ==> #427000     Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 4.715    Value Loss: 6.424    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 435524     Buffer Size: 30896      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:17:08,275][train][INFO][train.py>_log] ==> #428000     Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 5.126    Value Loss: 6.192    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 436381     Buffer Size: 30533      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:20:30,500][train][INFO][train.py>_log] ==> #429000     Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 5.204    Value Loss: 6.713    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 437303     Buffer Size: 30273      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:23:56,489][train][INFO][train.py>_log] ==> #430000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 4.603    Value Loss: 6.726    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 438260     Buffer Size: 30093      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:27:20,627][train][INFO][train.py>_log] ==> #431000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 5.055    Value Loss: 6.202    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 439186     Buffer Size: 29991      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:30:43,206][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 4.852    Value Loss: 5.942    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 440092     Buffer Size: 29972      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:34:08,452][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.385    [weighted Loss:2.385    Policy Loss: 5.852    Value Loss: 6.320    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 441076     Buffer Size: 30035      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:37:28,301][train][INFO][train.py>_log] ==> #434000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 5.551    Value Loss: 6.254    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 442007     Buffer Size: 30086      Transition Number: 1500.140k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:40:51,289][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 5.047    Value Loss: 6.490    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 443031     Buffer Size: 30189      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:44:13,627][train][INFO][train.py>_log] ==> #436000     Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 5.101    Value Loss: 6.336    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 444055     Buffer Size: 30263      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:47:36,303][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 5.059    Value Loss: 6.612    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 445028     Buffer Size: 30270      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:50:55,362][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.695    [weighted Loss:2.695    Policy Loss: 5.085    Value Loss: 6.380    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 446004     Buffer Size: 30274      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:54:19,066][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 4.887    Value Loss: 6.242    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 447062     Buffer Size: 30298      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-15 01:57:40,087][train][INFO][train.py>_log] ==> #440000     Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 5.824    Value Loss: 6.557    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 448078     Buffer Size: 30282      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:01:02,350][train][INFO][train.py>_log] ==> #441000     Total Loss: 3.107    [weighted Loss:3.107    Policy Loss: 5.360    Value Loss: 6.578    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 449190     Buffer Size: 30376      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:04:25,759][train][INFO][train.py>_log] ==> #442000     Total Loss: 1.950    [weighted Loss:1.950    Policy Loss: 5.802    Value Loss: 6.049    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 450275     Buffer Size: 30522      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:07:47,446][train][INFO][train.py>_log] ==> #443000     Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 4.887    Value Loss: 6.354    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 451239     Buffer Size: 30507      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:11:11,222][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 4.964    Value Loss: 6.795    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 452214     Buffer Size: 30447      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:14:34,769][train][INFO][train.py>_log] ==> #445000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 4.561    Value Loss: 6.532    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 453104     Buffer Size: 30128      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:17:58,347][train][INFO][train.py>_log] ==> #446000     Total Loss: 1.845    [weighted Loss:1.845    Policy Loss: 5.294    Value Loss: 6.496    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 454007     Buffer Size: 29529      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:21:23,135][train][INFO][train.py>_log] ==> #447000     Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 4.757    Value Loss: 6.306    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 454886     Buffer Size: 28904      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:24:47,972][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 5.032    Value Loss: 6.271    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 455755     Buffer Size: 28216      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:28:09,915][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 5.042    Value Loss: 5.986    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 456640     Buffer Size: 27639      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:31:36,059][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 5.619    Value Loss: 6.294    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 457532     Buffer Size: 27139      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:34:59,269][train][INFO][train.py>_log] ==> #451000     Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 6.523    Value Loss: 6.136    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 458470     Buffer Size: 26889      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:38:23,586][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.734    [weighted Loss:1.734    Policy Loss: 5.881    Value Loss: 6.333    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 459396     Buffer Size: 26939      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:41:49,551][train][INFO][train.py>_log] ==> #453000     Total Loss: 1.768    [weighted Loss:1.768    Policy Loss: 6.664    Value Loss: 5.950    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 460557     Buffer Size: 27195      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:45:13,262][train][INFO][train.py>_log] ==> #454000     Total Loss: 3.543    [weighted Loss:3.543    Policy Loss: 8.226    Value Loss: 6.518    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 461740     Buffer Size: 27495      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:48:36,579][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 6.782    Value Loss: 6.608    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 463026     Buffer Size: 27901      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:51:59,161][train][INFO][train.py>_log] ==> #456000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 6.060    Value Loss: 6.582    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 464279     Buffer Size: 28294      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:55:21,000][train][INFO][train.py>_log] ==> #457000     Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 5.845    Value Loss: 6.732    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 465672     Buffer Size: 28772      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-15 02:58:43,317][train][INFO][train.py>_log] ==> #458000     Total Loss: 3.091    [weighted Loss:3.091    Policy Loss: 5.496    Value Loss: 6.162    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 467077     Buffer Size: 29227      Transition Number: 1500.124k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:02:04,592][train][INFO][train.py>_log] ==> #459000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 5.046    Value Loss: 6.104    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 468135     Buffer Size: 29377      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:05:29,448][train][INFO][train.py>_log] ==> #460000     Total Loss: 1.728    [weighted Loss:1.728    Policy Loss: 5.053    Value Loss: 6.391    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 469221     Buffer Size: 29525      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:08:54,055][train][INFO][train.py>_log] ==> #461000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 5.379    Value Loss: 6.462    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 470276     Buffer Size: 29630      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:12:18,482][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 5.115    Value Loss: 6.412    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 471330     Buffer Size: 29706      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:15:44,917][train][INFO][train.py>_log] ==> #463000     Total Loss: 1.379    [weighted Loss:1.379    Policy Loss: 4.579    Value Loss: 6.461    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 472343     Buffer Size: 29682      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:19:08,389][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 6.144    Value Loss: 6.705    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 473315     Buffer Size: 29624      Transition Number: 1500.097k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:22:31,148][train][INFO][train.py>_log] ==> #465000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 5.264    Value Loss: 6.538    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 474323     Buffer Size: 29600      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:25:57,307][train][INFO][train.py>_log] ==> #466000     Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 5.766    Value Loss: 6.901    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 475331     Buffer Size: 29600      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:29:20,476][train][INFO][train.py>_log] ==> #467000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 6.022    Value Loss: 6.356    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 476399     Buffer Size: 29619      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:32:45,094][train][INFO][train.py>_log] ==> #468000     Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 5.780    Value Loss: 6.325    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 477524     Buffer Size: 29700      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:36:11,835][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.247    [weighted Loss:2.247    Policy Loss: 6.339    Value Loss: 6.514    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 478719     Buffer Size: 29792      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:39:35,260][train][INFO][train.py>_log] ==> #470000     Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 5.504    Value Loss: 6.764    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 479940     Buffer Size: 29879      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:43:01,615][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 5.629    Value Loss: 6.249    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 480904     Buffer Size: 29871      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:46:23,732][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.191    [weighted Loss:2.191    Policy Loss: 5.226    Value Loss: 6.696    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 481872     Buffer Size: 29892      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:49:45,232][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 5.814    Value Loss: 6.489    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 482757     Buffer Size: 29870      Transition Number: 1500.085k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:53:10,873][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 5.043    Value Loss: 6.543    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 483694     Buffer Size: 29910      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:56:31,282][train][INFO][train.py>_log] ==> #475000     Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 5.457    Value Loss: 6.655    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 484554     Buffer Size: 29890      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-15 03:59:56,078][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.830    [weighted Loss:1.830    Policy Loss: 4.925    Value Loss: 6.231    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 485427     Buffer Size: 29890      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:03:19,560][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 5.018    Value Loss: 6.646    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 486326     Buffer Size: 29873      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:06:46,230][train][INFO][train.py>_log] ==> #478000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 4.653    Value Loss: 6.236    Reward Loss: 1.152    Consistency Loss: 0.000    ] Replay Episodes Collected: 487200     Buffer Size: 29851      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:10:09,283][train][INFO][train.py>_log] ==> #479000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 5.516    Value Loss: 6.249    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 488069     Buffer Size: 29781      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:13:33,896][train][INFO][train.py>_log] ==> #480000     Total Loss: 1.597    [weighted Loss:1.597    Policy Loss: 4.475    Value Loss: 6.395    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 488960     Buffer Size: 29727      Transition Number: 1500.247k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:16:56,808][train][INFO][train.py>_log] ==> #481000     Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 6.183    Value Loss: 6.343    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 489826     Buffer Size: 29536      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:20:21,210][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 5.958    Value Loss: 6.501    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 490731     Buffer Size: 29243      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:23:46,075][train][INFO][train.py>_log] ==> #483000     Total Loss: 1.977    [weighted Loss:1.977    Policy Loss: 5.894    Value Loss: 5.940    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 491678     Buffer Size: 28942      Transition Number: 1500.108k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:27:12,236][train][INFO][train.py>_log] ==> #484000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 5.763    Value Loss: 6.544    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 492617     Buffer Size: 28602      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:30:36,419][train][INFO][train.py>_log] ==> #485000     Total Loss: 1.385    [weighted Loss:1.385    Policy Loss: 5.468    Value Loss: 6.560    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 493578     Buffer Size: 28264      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:34:02,907][train][INFO][train.py>_log] ==> #486000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 5.564    Value Loss: 6.148    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 494572     Buffer Size: 27834      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:37:25,997][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.878    [weighted Loss:2.878    Policy Loss: 6.330    Value Loss: 6.319    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 495443     Buffer Size: 27540      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:40:49,064][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 5.706    Value Loss: 6.370    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 496318     Buffer Size: 27360      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:44:13,193][train][INFO][train.py>_log] ==> #489000     Total Loss: 2.626    [weighted Loss:2.626    Policy Loss: 6.501    Value Loss: 6.420    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 497171     Buffer Size: 27167      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:47:36,392][train][INFO][train.py>_log] ==> #490000     Total Loss: 2.715    [weighted Loss:2.715    Policy Loss: 5.687    Value Loss: 6.194    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 498048     Buffer Size: 27006      Transition Number: 1500.054k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:51:02,989][train][INFO][train.py>_log] ==> #491000     Total Loss: 3.350    [weighted Loss:3.350    Policy Loss: 6.984    Value Loss: 5.827    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 499084     Buffer Size: 27022      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:54:31,552][train][INFO][train.py>_log] ==> #492000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 5.676    Value Loss: 6.196    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 500172     Buffer Size: 27098      Transition Number: 1500.066k Batch Size: 256        Lr: 0.10000 
[2022-01-15 04:57:57,051][train][INFO][train.py>_log] ==> #493000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 6.646    Value Loss: 6.594    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 501342     Buffer Size: 27274      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-15 05:01:22,338][train][INFO][train.py>_log] ==> #494000     Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 7.013    Value Loss: 6.558    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 502548     Buffer Size: 27436      Transition Number: 1500.187k Batch Size: 256        Lr: 0.10000 
[2022-01-15 05:04:46,764][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 6.784    Value Loss: 6.467    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 503766     Buffer Size: 27569      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-15 05:08:11,918][train][INFO][train.py>_log] ==> #496000     Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 6.273    Value Loss: 6.614    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 504963     Buffer Size: 27639      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-15 05:11:34,276][train][INFO][train.py>_log] ==> #497000     Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 6.575    Value Loss: 6.348    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 506137     Buffer Size: 27679      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-15 05:15:01,098][train][INFO][train.py>_log] ==> #498000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 5.862    Value Loss: 6.420    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 507367     Buffer Size: 27665      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-15 05:18:25,088][train][INFO][train.py>_log] ==> #499000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 7.232    Value Loss: 6.242    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 508352     Buffer Size: 27634      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-15 05:21:48,995][train][INFO][train.py>_log] ==> #500000     Total Loss: 2.912    [weighted Loss:2.912    Policy Loss: 5.777    Value Loss: 6.477    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 509359     Buffer Size: 27652      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-15 05:25:13,026][train][INFO][train.py>_log] ==> #501000     Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 6.491    Value Loss: 6.022    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 510316     Buffer Size: 27695      Transition Number: 1500.004k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:28:37,024][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 5.755    Value Loss: 6.255    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 511308     Buffer Size: 27754      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:32:00,181][train][INFO][train.py>_log] ==> #503000     Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 5.839    Value Loss: 6.644    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 512265     Buffer Size: 27822      Transition Number: 1500.019k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:35:24,179][train][INFO][train.py>_log] ==> #504000     Total Loss: 1.335    [weighted Loss:1.335    Policy Loss: 5.114    Value Loss: 6.705    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 513204     Buffer Size: 27913      Transition Number: 1500.021k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:38:46,582][train][INFO][train.py>_log] ==> #505000     Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 5.519    Value Loss: 6.490    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 514096     Buffer Size: 27963      Transition Number: 1499.963k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:42:11,021][train][INFO][train.py>_log] ==> #506000     Total Loss: 2.412    [weighted Loss:2.412    Policy Loss: 5.389    Value Loss: 6.434    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 514981     Buffer Size: 28012      Transition Number: 1499.962k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:45:36,472][train][INFO][train.py>_log] ==> #507000     Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 5.531    Value Loss: 6.135    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 515861     Buffer Size: 28020      Transition Number: 1500.236k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:49:02,734][train][INFO][train.py>_log] ==> #508000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 4.927    Value Loss: 6.462    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 516747     Buffer Size: 28027      Transition Number: 1499.949k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:52:26,883][train][INFO][train.py>_log] ==> #509000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 5.605    Value Loss: 6.301    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 517660     Buffer Size: 28063      Transition Number: 1500.108k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:55:51,485][train][INFO][train.py>_log] ==> #510000     Total Loss: 2.701    [weighted Loss:2.701    Policy Loss: 4.957    Value Loss: 5.968    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 518603     Buffer Size: 28107      Transition Number: 1499.967k Batch Size: 256        Lr: 0.09000 
[2022-01-15 05:59:13,528][train][INFO][train.py>_log] ==> #511000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 5.646    Value Loss: 6.706    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 519500     Buffer Size: 28113      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:02:38,703][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 4.739    Value Loss: 6.200    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 520432     Buffer Size: 28110      Transition Number: 1499.968k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:06:04,456][train][INFO][train.py>_log] ==> #513000     Total Loss: 2.747    [weighted Loss:2.747    Policy Loss: 5.834    Value Loss: 6.376    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 521335     Buffer Size: 28056      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:09:27,981][train][INFO][train.py>_log] ==> #514000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 5.274    Value Loss: 6.548    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 522263     Buffer Size: 27979      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:12:53,472][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 5.925    Value Loss: 6.211    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 523191     Buffer Size: 27989      Transition Number: 1499.961k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:16:17,667][train][INFO][train.py>_log] ==> #516000     Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 4.877    Value Loss: 6.407    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 524124     Buffer Size: 28032      Transition Number: 1499.954k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:19:42,149][train][INFO][train.py>_log] ==> #517000     Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 5.143    Value Loss: 6.200    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 525093     Buffer Size: 28125      Transition Number: 1499.984k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:23:07,726][train][INFO][train.py>_log] ==> #518000     Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 5.002    Value Loss: 6.496    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 526081     Buffer Size: 28215      Transition Number: 1499.981k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:26:31,940][train][INFO][train.py>_log] ==> #519000     Total Loss: 3.234    [weighted Loss:3.234    Policy Loss: 5.568    Value Loss: 6.085    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 527034     Buffer Size: 28152      Transition Number: 1500.062k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:29:56,833][train][INFO][train.py>_log] ==> #520000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 5.217    Value Loss: 6.760    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 527986     Buffer Size: 28070      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:33:23,426][train][INFO][train.py>_log] ==> #521000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 6.451    Value Loss: 6.493    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 528949     Buffer Size: 27881      Transition Number: 1500.005k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:36:47,995][train][INFO][train.py>_log] ==> #522000     Total Loss: 1.140    [weighted Loss:1.140    Policy Loss: 5.573    Value Loss: 6.199    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 529947     Buffer Size: 27662      Transition Number: 1499.964k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:40:11,978][train][INFO][train.py>_log] ==> #523000     Total Loss: 3.387    [weighted Loss:3.387    Policy Loss: 6.796    Value Loss: 6.458    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 530986     Buffer Size: 27508      Transition Number: 1499.970k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:43:37,698][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 5.416    Value Loss: 6.170    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 532037     Buffer Size: 27374      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:47:01,167][train][INFO][train.py>_log] ==> #525000     Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 5.787    Value Loss: 6.622    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 533120     Buffer Size: 27272      Transition Number: 1500.169k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:50:25,173][train][INFO][train.py>_log] ==> #526000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 6.343    Value Loss: 6.035    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 534174     Buffer Size: 27143      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:53:54,047][train][INFO][train.py>_log] ==> #527000     Total Loss: 1.318    [weighted Loss:1.318    Policy Loss: 5.844    Value Loss: 6.391    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 535502     Buffer Size: 27355      Transition Number: 1499.973k Batch Size: 256        Lr: 0.09000 
[2022-01-15 06:57:20,776][train][INFO][train.py>_log] ==> #528000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 5.338    Value Loss: 6.346    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 536799     Buffer Size: 27638      Transition Number: 1500.034k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:00:47,978][train][INFO][train.py>_log] ==> #529000     Total Loss: 3.720    [weighted Loss:3.720    Policy Loss: 5.841    Value Loss: 6.056    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 537842     Buffer Size: 27687      Transition Number: 1499.985k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:04:13,486][train][INFO][train.py>_log] ==> #530000     Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 5.044    Value Loss: 6.340    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 538888     Buffer Size: 27722      Transition Number: 1499.983k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:07:38,974][train][INFO][train.py>_log] ==> #531000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 5.337    Value Loss: 6.027    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 539787     Buffer Size: 27666      Transition Number: 1500.058k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:11:02,185][train][INFO][train.py>_log] ==> #532000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 4.659    Value Loss: 6.007    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 540704     Buffer Size: 27604      Transition Number: 1499.952k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:14:25,942][train][INFO][train.py>_log] ==> #533000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 5.250    Value Loss: 6.016    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 541579     Buffer Size: 27576      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:17:52,142][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 5.452    Value Loss: 6.269    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 542489     Buffer Size: 27549      Transition Number: 1500.095k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:21:16,097][train][INFO][train.py>_log] ==> #535000     Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 5.290    Value Loss: 6.145    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 543444     Buffer Size: 27618      Transition Number: 1500.043k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:24:39,462][train][INFO][train.py>_log] ==> #536000     Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 5.315    Value Loss: 6.395    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 544414     Buffer Size: 27696      Transition Number: 1499.993k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:28:03,668][train][INFO][train.py>_log] ==> #537000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 5.455    Value Loss: 5.936    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 545414     Buffer Size: 27809      Transition Number: 1500.000k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:31:28,746][train][INFO][train.py>_log] ==> #538000     Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 6.137    Value Loss: 6.356    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 546463     Buffer Size: 27923      Transition Number: 1500.092k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:34:51,999][train][INFO][train.py>_log] ==> #539000     Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 5.593    Value Loss: 6.125    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 547553     Buffer Size: 28101      Transition Number: 1499.971k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:38:16,408][train][INFO][train.py>_log] ==> #540000     Total Loss: 2.429    [weighted Loss:2.429    Policy Loss: 5.912    Value Loss: 6.181    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 548637     Buffer Size: 28265      Transition Number: 1500.003k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:41:38,646][train][INFO][train.py>_log] ==> #541000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 5.414    Value Loss: 6.396    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 550389     Buffer Size: 29052      Transition Number: 1499.966k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:44:59,304][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 6.898    Value Loss: 6.894    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 552199     Buffer Size: 29911      Transition Number: 1500.043k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:48:21,080][train][INFO][train.py>_log] ==> #543000     Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 5.131    Value Loss: 6.945    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 553685     Buffer Size: 30468      Transition Number: 1499.993k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:51:41,424][train][INFO][train.py>_log] ==> #544000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 5.956    Value Loss: 7.189    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 555203     Buffer Size: 31039      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:55:04,355][train][INFO][train.py>_log] ==> #545000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 5.296    Value Loss: 6.617    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 556222     Buffer Size: 31120      Transition Number: 1500.002k Batch Size: 256        Lr: 0.09000 
[2022-01-15 07:58:28,467][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.617    [weighted Loss:1.617    Policy Loss: 4.784    Value Loss: 6.806    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 557262     Buffer Size: 31187      Transition Number: 1499.941k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:01:52,101][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.312    [weighted Loss:2.312    Policy Loss: 4.581    Value Loss: 6.453    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 558129     Buffer Size: 31131      Transition Number: 1499.996k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:05:14,046][train][INFO][train.py>_log] ==> #548000     Total Loss: 2.324    [weighted Loss:2.324    Policy Loss: 4.752    Value Loss: 6.915    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 559010     Buffer Size: 31058      Transition Number: 1499.975k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:08:36,498][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 4.438    Value Loss: 6.290    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 560064     Buffer Size: 31148      Transition Number: 1499.960k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:11:59,753][train][INFO][train.py>_log] ==> #550000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 5.037    Value Loss: 6.376    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 561131     Buffer Size: 31235      Transition Number: 1499.988k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:15:21,096][train][INFO][train.py>_log] ==> #551000     Total Loss: 1.406    [weighted Loss:1.406    Policy Loss: 5.474    Value Loss: 6.220    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 562201     Buffer Size: 31266      Transition Number: 1499.968k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:18:42,580][train][INFO][train.py>_log] ==> #552000     Total Loss: 1.014    [weighted Loss:1.014    Policy Loss: 4.961    Value Loss: 6.412    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 563257     Buffer Size: 31314      Transition Number: 1499.977k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:22:04,956][train][INFO][train.py>_log] ==> #553000     Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 4.555    Value Loss: 6.390    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 564246     Buffer Size: 31258      Transition Number: 1499.940k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:25:27,761][train][INFO][train.py>_log] ==> #554000     Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 4.857    Value Loss: 6.319    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 565261     Buffer Size: 31225      Transition Number: 1499.969k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:28:50,232][train][INFO][train.py>_log] ==> #555000     Total Loss: 1.443    [weighted Loss:1.443    Policy Loss: 4.610    Value Loss: 6.711    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 566299     Buffer Size: 31038      Transition Number: 1500.015k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:32:15,644][train][INFO][train.py>_log] ==> #556000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 5.135    Value Loss: 6.919    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 567350     Buffer Size: 30814      Transition Number: 1499.970k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:35:39,654][train][INFO][train.py>_log] ==> #557000     Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 5.171    Value Loss: 6.132    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 568250     Buffer Size: 30627      Transition Number: 1499.959k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:39:03,642][train][INFO][train.py>_log] ==> #558000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 4.339    Value Loss: 6.500    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 569148     Buffer Size: 30504      Transition Number: 1499.955k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:42:25,009][train][INFO][train.py>_log] ==> #559000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 4.789    Value Loss: 6.149    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 570022     Buffer Size: 30422      Transition Number: 1499.987k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:45:51,955][train][INFO][train.py>_log] ==> #560000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 4.755    Value Loss: 6.230    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 570903     Buffer Size: 30388      Transition Number: 1499.951k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:49:15,102][train][INFO][train.py>_log] ==> #561000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 5.065    Value Loss: 6.190    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 571755     Buffer Size: 30360      Transition Number: 1499.958k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:52:36,771][train][INFO][train.py>_log] ==> #562000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 5.250    Value Loss: 6.279    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 572628     Buffer Size: 30340      Transition Number: 1500.095k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:56:03,009][train][INFO][train.py>_log] ==> #563000     Total Loss: 1.895    [weighted Loss:1.895    Policy Loss: 4.723    Value Loss: 5.931    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 573605     Buffer Size: 30359      Transition Number: 1499.972k Batch Size: 256        Lr: 0.09000 
[2022-01-15 08:59:27,410][train][INFO][train.py>_log] ==> #564000     Total Loss: 1.027    [weighted Loss:1.027    Policy Loss: 5.347    Value Loss: 6.481    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 574582     Buffer Size: 30376      Transition Number: 1500.046k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:02:53,160][train][INFO][train.py>_log] ==> #565000     Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 5.323    Value Loss: 6.833    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 575585     Buffer Size: 30387      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:06:18,163][train][INFO][train.py>_log] ==> #566000     Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 4.961    Value Loss: 6.591    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 576593     Buffer Size: 30375      Transition Number: 1499.944k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:09:43,407][train][INFO][train.py>_log] ==> #567000     Total Loss: 1.714    [weighted Loss:1.714    Policy Loss: 5.403    Value Loss: 6.139    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 577556     Buffer Size: 30251      Transition Number: 1499.938k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:13:08,151][train][INFO][train.py>_log] ==> #568000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 5.446    Value Loss: 6.634    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 578538     Buffer Size: 30121      Transition Number: 1499.954k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:16:33,836][train][INFO][train.py>_log] ==> #569000     Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 5.206    Value Loss: 7.127    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 579618     Buffer Size: 29644      Transition Number: 1499.949k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:20:00,628][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 5.245    Value Loss: 6.472    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 580755     Buffer Size: 29027      Transition Number: 1499.946k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:23:27,037][train][INFO][train.py>_log] ==> #571000     Total Loss: 2.758    [weighted Loss:2.758    Policy Loss: 5.547    Value Loss: 6.458    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 581734     Buffer Size: 28427      Transition Number: 1499.998k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:26:54,251][train][INFO][train.py>_log] ==> #572000     Total Loss: 1.881    [weighted Loss:1.881    Policy Loss: 5.488    Value Loss: 6.465    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 582746     Buffer Size: 27933      Transition Number: 1499.998k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:30:18,563][train][INFO][train.py>_log] ==> #573000     Total Loss: 3.048    [weighted Loss:3.048    Policy Loss: 6.945    Value Loss: 5.785    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 583666     Buffer Size: 27718      Transition Number: 1499.951k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:33:43,506][train][INFO][train.py>_log] ==> #574000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 5.099    Value Loss: 6.269    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 584641     Buffer Size: 27626      Transition Number: 1499.962k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:37:08,091][train][INFO][train.py>_log] ==> #575000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 7.075    Value Loss: 6.199    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 585545     Buffer Size: 27615      Transition Number: 1500.042k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:40:32,928][train][INFO][train.py>_log] ==> #576000     Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 5.242    Value Loss: 6.128    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 586451     Buffer Size: 27642      Transition Number: 1500.055k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:43:57,809][train][INFO][train.py>_log] ==> #577000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 7.477    Value Loss: 6.520    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 587614     Buffer Size: 27759      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:47:25,126][train][INFO][train.py>_log] ==> #578000     Total Loss: 3.573    [weighted Loss:3.573    Policy Loss: 6.401    Value Loss: 6.358    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 588774     Buffer Size: 27839      Transition Number: 1499.983k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:50:50,285][train][INFO][train.py>_log] ==> #579000     Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 7.442    Value Loss: 6.502    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 589898     Buffer Size: 27882      Transition Number: 1500.051k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:54:20,222][train][INFO][train.py>_log] ==> #580000     Total Loss: 1.522    [weighted Loss:1.522    Policy Loss: 6.786    Value Loss: 6.634    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 591022     Buffer Size: 27864      Transition Number: 1499.937k Batch Size: 256        Lr: 0.09000 
[2022-01-15 09:57:45,123][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.437    [weighted Loss:3.437    Policy Loss: 6.656    Value Loss: 6.023    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 592088     Buffer Size: 27900      Transition Number: 1500.024k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:01:08,754][train][INFO][train.py>_log] ==> #582000     Total Loss: 2.561    [weighted Loss:2.561    Policy Loss: 6.183    Value Loss: 6.429    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 593157     Buffer Size: 27936      Transition Number: 1499.954k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:04:38,021][train][INFO][train.py>_log] ==> #583000     Total Loss: 1.424    [weighted Loss:1.424    Policy Loss: 5.929    Value Loss: 6.119    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 594154     Buffer Size: 27868      Transition Number: 1499.982k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:08:04,463][train][INFO][train.py>_log] ==> #584000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 5.479    Value Loss: 6.460    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 595153     Buffer Size: 27806      Transition Number: 1499.947k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:11:31,194][train][INFO][train.py>_log] ==> #585000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 5.691    Value Loss: 6.411    Reward Loss: 1.270    Consistency Loss: 0.000    ] Replay Episodes Collected: 596085     Buffer Size: 27848      Transition Number: 1499.955k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:14:56,483][train][INFO][train.py>_log] ==> #586000     Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 5.953    Value Loss: 5.958    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 597020     Buffer Size: 27893      Transition Number: 1499.962k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:18:21,973][train][INFO][train.py>_log] ==> #587000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 5.254    Value Loss: 6.476    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 597970     Buffer Size: 27931      Transition Number: 1500.005k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:21:45,412][train][INFO][train.py>_log] ==> #588000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 5.330    Value Loss: 6.265    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 598877     Buffer Size: 27975      Transition Number: 1499.966k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:25:08,881][train][INFO][train.py>_log] ==> #589000     Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 5.773    Value Loss: 6.525    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 599942     Buffer Size: 28148      Transition Number: 1499.965k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:28:30,880][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 5.933    Value Loss: 6.653    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 600976     Buffer Size: 28324      Transition Number: 1499.938k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:31:54,602][train][INFO][train.py>_log] ==> #591000     Total Loss: 1.637    [weighted Loss:1.637    Policy Loss: 5.601    Value Loss: 6.446    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 602030     Buffer Size: 28397      Transition Number: 1499.975k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:35:22,758][train][INFO][train.py>_log] ==> #592000     Total Loss: 1.632    [weighted Loss:1.632    Policy Loss: 5.229    Value Loss: 6.350    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 603052     Buffer Size: 28451      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:38:46,168][train][INFO][train.py>_log] ==> #593000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 6.226    Value Loss: 6.378    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 604127     Buffer Size: 28494      Transition Number: 1499.994k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:42:12,012][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 5.986    Value Loss: 6.395    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 605218     Buffer Size: 28557      Transition Number: 1499.961k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:45:39,290][train][INFO][train.py>_log] ==> #595000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 5.714    Value Loss: 6.022    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 606461     Buffer Size: 28789      Transition Number: 1499.984k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:49:04,609][train][INFO][train.py>_log] ==> #596000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 5.541    Value Loss: 6.909    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 607680     Buffer Size: 29006      Transition Number: 1499.996k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:52:30,371][train][INFO][train.py>_log] ==> #597000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 5.697    Value Loss: 6.246    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 608711     Buffer Size: 28956      Transition Number: 1499.953k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:55:58,244][train][INFO][train.py>_log] ==> #598000     Total Loss: 2.849    [weighted Loss:2.849    Policy Loss: 5.091    Value Loss: 6.264    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 609737     Buffer Size: 28871      Transition Number: 1500.012k Batch Size: 256        Lr: 0.09000 
[2022-01-15 10:59:23,884][train][INFO][train.py>_log] ==> #599000     Total Loss: 2.508    [weighted Loss:2.508    Policy Loss: 6.517    Value Loss: 6.438    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 610693     Buffer Size: 28844      Transition Number: 1500.159k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:02:47,792][train][INFO][train.py>_log] ==> #600000     Total Loss: 1.734    [weighted Loss:1.734    Policy Loss: 5.477    Value Loss: 6.792    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 611596     Buffer Size: 28784      Transition Number: 1500.011k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:06:16,694][train][INFO][train.py>_log] ==> #601000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 5.789    Value Loss: 6.790    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 612513     Buffer Size: 28748      Transition Number: 1500.036k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:09:43,498][train][INFO][train.py>_log] ==> #602000     Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 6.011    Value Loss: 6.476    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 613422     Buffer Size: 28713      Transition Number: 1499.982k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:13:11,830][train][INFO][train.py>_log] ==> #603000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 5.169    Value Loss: 6.291    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 614621     Buffer Size: 28960      Transition Number: 1500.042k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:16:35,185][train][INFO][train.py>_log] ==> #604000     Total Loss: 2.469    [weighted Loss:2.469    Policy Loss: 6.116    Value Loss: 6.457    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 615776     Buffer Size: 29174      Transition Number: 1499.986k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:20:00,451][train][INFO][train.py>_log] ==> #605000     Total Loss: 3.317    [weighted Loss:3.317    Policy Loss: 6.272    Value Loss: 6.608    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 616969     Buffer Size: 29241      Transition Number: 1500.000k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:23:23,756][train][INFO][train.py>_log] ==> #606000     Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 6.051    Value Loss: 6.821    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 618188     Buffer Size: 29296      Transition Number: 1500.008k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:26:48,706][train][INFO][train.py>_log] ==> #607000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 5.639    Value Loss: 6.797    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 619370     Buffer Size: 29378      Transition Number: 1499.971k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:30:13,543][train][INFO][train.py>_log] ==> #608000     Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 5.503    Value Loss: 6.736    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 620564     Buffer Size: 29469      Transition Number: 1499.953k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:33:42,330][train][INFO][train.py>_log] ==> #609000     Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 6.001    Value Loss: 6.944    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 622189     Buffer Size: 29974      Transition Number: 1500.002k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:37:04,456][train][INFO][train.py>_log] ==> #610000     Total Loss: 2.676    [weighted Loss:2.676    Policy Loss: 5.539    Value Loss: 6.832    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 623782     Buffer Size: 30481      Transition Number: 1499.946k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:40:24,202][train][INFO][train.py>_log] ==> #611000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 5.711    Value Loss: 6.763    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 625113     Buffer Size: 30833      Transition Number: 1499.943k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:43:49,126][train][INFO][train.py>_log] ==> #612000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 5.446    Value Loss: 6.922    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 626396     Buffer Size: 31129      Transition Number: 1499.951k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:47:10,887][train][INFO][train.py>_log] ==> #613000     Total Loss: 2.102    [weighted Loss:2.102    Policy Loss: 5.410    Value Loss: 6.757    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 627334     Buffer Size: 31158      Transition Number: 1499.976k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:50:35,969][train][INFO][train.py>_log] ==> #614000     Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 5.472    Value Loss: 6.363    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 628290     Buffer Size: 31188      Transition Number: 1500.040k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:54:01,620][train][INFO][train.py>_log] ==> #615000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 5.925    Value Loss: 6.741    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 629268     Buffer Size: 31241      Transition Number: 1499.964k Batch Size: 256        Lr: 0.09000 
[2022-01-15 11:57:25,324][train][INFO][train.py>_log] ==> #616000     Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 5.449    Value Loss: 6.606    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 630211     Buffer Size: 31277      Transition Number: 1500.049k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:00:48,947][train][INFO][train.py>_log] ==> #617000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 6.520    Value Loss: 6.670    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 631098     Buffer Size: 31139      Transition Number: 1500.002k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:04:13,067][train][INFO][train.py>_log] ==> #618000     Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 5.575    Value Loss: 6.367    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 632024     Buffer Size: 31018      Transition Number: 1499.983k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:07:32,999][train][INFO][train.py>_log] ==> #619000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 5.955    Value Loss: 6.727    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 632930     Buffer Size: 30961      Transition Number: 1499.944k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:10:56,328][train][INFO][train.py>_log] ==> #620000     Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 5.407    Value Loss: 6.368    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 633878     Buffer Size: 30909      Transition Number: 1500.113k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:14:23,067][train][INFO][train.py>_log] ==> #621000     Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 6.042    Value Loss: 6.468    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 634852     Buffer Size: 30835      Transition Number: 1499.955k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:17:47,307][train][INFO][train.py>_log] ==> #622000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 5.706    Value Loss: 6.621    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 635881     Buffer Size: 30792      Transition Number: 1500.054k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:21:11,089][train][INFO][train.py>_log] ==> #623000     Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 5.428    Value Loss: 6.484    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 636910     Buffer Size: 30690      Transition Number: 1499.959k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:24:35,843][train][INFO][train.py>_log] ==> #624000     Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 5.030    Value Loss: 6.323    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 637925     Buffer Size: 30545      Transition Number: 1500.051k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:28:02,322][train][INFO][train.py>_log] ==> #625000     Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 5.821    Value Loss: 5.728    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 638928     Buffer Size: 30471      Transition Number: 1499.961k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:31:27,044][train][INFO][train.py>_log] ==> #626000     Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 6.039    Value Loss: 6.632    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 639941     Buffer Size: 30462      Transition Number: 1500.030k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:34:53,916][train][INFO][train.py>_log] ==> #627000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 5.742    Value Loss: 6.162    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 640926     Buffer Size: 30477      Transition Number: 1499.996k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:38:16,169][train][INFO][train.py>_log] ==> #628000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 5.290    Value Loss: 6.734    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 641908     Buffer Size: 30519      Transition Number: 1499.992k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:41:39,081][train][INFO][train.py>_log] ==> #629000     Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 5.574    Value Loss: 6.389    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 643017     Buffer Size: 30725      Transition Number: 1500.048k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:45:03,238][train][INFO][train.py>_log] ==> #630000     Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 4.943    Value Loss: 6.681    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 644116     Buffer Size: 30923      Transition Number: 1499.980k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:48:25,803][train][INFO][train.py>_log] ==> #631000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 5.610    Value Loss: 6.650    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 645134     Buffer Size: 30881      Transition Number: 1500.241k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:51:53,854][train][INFO][train.py>_log] ==> #632000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 5.412    Value Loss: 6.668    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 646191     Buffer Size: 30791      Transition Number: 1499.955k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:55:19,546][train][INFO][train.py>_log] ==> #633000     Total Loss: 1.292    [weighted Loss:1.292    Policy Loss: 5.289    Value Loss: 6.678    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 647382     Buffer Size: 30746      Transition Number: 1499.966k Batch Size: 256        Lr: 0.09000 
[2022-01-15 12:58:42,496][train][INFO][train.py>_log] ==> #634000     Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 6.614    Value Loss: 7.103    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 648537     Buffer Size: 30727      Transition Number: 1500.002k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:02:07,754][train][INFO][train.py>_log] ==> #635000     Total Loss: 3.087    [weighted Loss:3.087    Policy Loss: 5.678    Value Loss: 6.744    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 649889     Buffer Size: 30829      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:05:32,985][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 6.158    Value Loss: 6.721    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 651233     Buffer Size: 30958      Transition Number: 1499.938k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:08:56,456][train][INFO][train.py>_log] ==> #637000     Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 5.594    Value Loss: 6.844    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 652329     Buffer Size: 30673      Transition Number: 1499.998k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:12:21,458][train][INFO][train.py>_log] ==> #638000     Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 5.819    Value Loss: 6.944    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 653422     Buffer Size: 30190      Transition Number: 1500.091k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:15:48,067][train][INFO][train.py>_log] ==> #639000     Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 6.501    Value Loss: 6.547    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 654458     Buffer Size: 29790      Transition Number: 1499.951k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:19:12,491][train][INFO][train.py>_log] ==> #640000     Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 5.929    Value Loss: 6.620    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 655454     Buffer Size: 29526      Transition Number: 1499.976k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:22:36,787][train][INFO][train.py>_log] ==> #641000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 6.257    Value Loss: 6.620    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 656433     Buffer Size: 29446      Transition Number: 1499.973k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:26:04,619][train][INFO][train.py>_log] ==> #642000     Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 6.270    Value Loss: 6.378    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 657458     Buffer Size: 29489      Transition Number: 1499.965k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:29:30,033][train][INFO][train.py>_log] ==> #643000     Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 6.833    Value Loss: 6.924    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 658375     Buffer Size: 29448      Transition Number: 1500.007k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:32:51,756][train][INFO][train.py>_log] ==> #644000     Total Loss: 1.527    [weighted Loss:1.527    Policy Loss: 6.342    Value Loss: 6.170    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 659273     Buffer Size: 29410      Transition Number: 1500.244k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:36:18,735][train][INFO][train.py>_log] ==> #645000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 6.792    Value Loss: 6.232    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 660186     Buffer Size: 29423      Transition Number: 1499.943k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:39:43,700][train][INFO][train.py>_log] ==> #646000     Total Loss: 0.999    [weighted Loss:0.999    Policy Loss: 6.474    Value Loss: 6.773    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 661117     Buffer Size: 29444      Transition Number: 1500.021k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:43:09,915][train][INFO][train.py>_log] ==> #647000     Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 6.573    Value Loss: 6.378    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 662158     Buffer Size: 29515      Transition Number: 1499.973k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:46:34,540][train][INFO][train.py>_log] ==> #648000     Total Loss: 2.958    [weighted Loss:2.958    Policy Loss: 6.334    Value Loss: 6.427    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 663174     Buffer Size: 29564      Transition Number: 1500.028k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:49:58,483][train][INFO][train.py>_log] ==> #649000     Total Loss: 3.360    [weighted Loss:3.360    Policy Loss: 6.622    Value Loss: 6.329    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 664328     Buffer Size: 29727      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:53:21,820][train][INFO][train.py>_log] ==> #650000     Total Loss: 3.393    [weighted Loss:3.393    Policy Loss: 6.034    Value Loss: 6.605    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 665489     Buffer Size: 29874      Transition Number: 1499.992k Batch Size: 256        Lr: 0.09000 
[2022-01-15 13:56:48,012][train][INFO][train.py>_log] ==> #651000     Total Loss: 3.228    [weighted Loss:3.228    Policy Loss: 6.659    Value Loss: 6.415    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 666507     Buffer Size: 29860      Transition Number: 1500.043k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:00:13,305][train][INFO][train.py>_log] ==> #652000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 6.541    Value Loss: 6.389    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 667518     Buffer Size: 29825      Transition Number: 1500.047k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:03:41,091][train][INFO][train.py>_log] ==> #653000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 6.630    Value Loss: 6.410    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 668444     Buffer Size: 29722      Transition Number: 1499.944k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:07:04,118][train][INFO][train.py>_log] ==> #654000     Total Loss: 2.931    [weighted Loss:2.931    Policy Loss: 5.475    Value Loss: 6.559    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 669357     Buffer Size: 29626      Transition Number: 1499.993k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:10:28,931][train][INFO][train.py>_log] ==> #655000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 5.728    Value Loss: 6.195    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 670282     Buffer Size: 29576      Transition Number: 1499.988k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:13:52,302][train][INFO][train.py>_log] ==> #656000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 6.190    Value Loss: 6.274    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 671238     Buffer Size: 29536      Transition Number: 1500.003k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:17:18,374][train][INFO][train.py>_log] ==> #657000     Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 6.116    Value Loss: 6.516    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 672157     Buffer Size: 29360      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:20:43,664][train][INFO][train.py>_log] ==> #658000     Total Loss: 1.111    [weighted Loss:1.111    Policy Loss: 5.464    Value Loss: 6.610    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 673066     Buffer Size: 29157      Transition Number: 1499.985k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:24:09,589][train][INFO][train.py>_log] ==> #659000     Total Loss: 2.210    [weighted Loss:2.210    Policy Loss: 6.030    Value Loss: 6.658    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 673952     Buffer Size: 28963      Transition Number: 1500.178k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:27:35,565][train][INFO][train.py>_log] ==> #660000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 5.878    Value Loss: 6.285    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 674848     Buffer Size: 28784      Transition Number: 1500.005k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:31:01,612][train][INFO][train.py>_log] ==> #661000     Total Loss: 4.009    [weighted Loss:4.009    Policy Loss: 6.219    Value Loss: 6.291    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 675752     Buffer Size: 28551      Transition Number: 1499.977k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:34:29,172][train][INFO][train.py>_log] ==> #662000     Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 5.699    Value Loss: 5.924    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 676656     Buffer Size: 28283      Transition Number: 1499.943k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:37:54,675][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 6.235    Value Loss: 5.859    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 677598     Buffer Size: 27898      Transition Number: 1500.128k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:41:20,490][train][INFO][train.py>_log] ==> #664000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 6.003    Value Loss: 5.838    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 678524     Buffer Size: 27469      Transition Number: 1499.942k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:44:47,949][train][INFO][train.py>_log] ==> #665000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 5.737    Value Loss: 6.134    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 679444     Buffer Size: 27208      Transition Number: 1499.969k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:48:13,755][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 5.637    Value Loss: 6.098    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 680373     Buffer Size: 27054      Transition Number: 1500.002k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:51:41,018][train][INFO][train.py>_log] ==> #667000     Total Loss: 1.246    [weighted Loss:1.246    Policy Loss: 6.852    Value Loss: 5.950    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 681297     Buffer Size: 26933      Transition Number: 1500.114k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:55:09,066][train][INFO][train.py>_log] ==> #668000     Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 6.157    Value Loss: 5.955    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 682227     Buffer Size: 26831      Transition Number: 1500.000k Batch Size: 256        Lr: 0.09000 
[2022-01-15 14:58:33,017][train][INFO][train.py>_log] ==> #669000     Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 6.212    Value Loss: 5.923    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 683125     Buffer Size: 26732      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:01:57,530][train][INFO][train.py>_log] ==> #670000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 6.646    Value Loss: 5.878    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 684068     Buffer Size: 26644      Transition Number: 1499.984k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:05:24,517][train][INFO][train.py>_log] ==> #671000     Total Loss: 0.969    [weighted Loss:0.969    Policy Loss: 6.232    Value Loss: 6.148    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 685020     Buffer Size: 26644      Transition Number: 1500.043k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:08:49,938][train][INFO][train.py>_log] ==> #672000     Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 6.551    Value Loss: 5.836    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 685947     Buffer Size: 26660      Transition Number: 1499.950k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:12:17,163][train][INFO][train.py>_log] ==> #673000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 6.685    Value Loss: 6.430    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 687755     Buffer Size: 27430      Transition Number: 1500.060k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:15:42,649][train][INFO][train.py>_log] ==> #674000     Total Loss: 3.557    [weighted Loss:3.557    Policy Loss: 8.372    Value Loss: 6.655    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 689555     Buffer Size: 28199      Transition Number: 1500.097k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:19:07,444][train][INFO][train.py>_log] ==> #675000     Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 8.200    Value Loss: 6.880    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 690890     Buffer Size: 28476      Transition Number: 1500.183k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:22:33,647][train][INFO][train.py>_log] ==> #676000     Total Loss: 3.450    [weighted Loss:3.450    Policy Loss: 8.669    Value Loss: 6.374    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 692213     Buffer Size: 28706      Transition Number: 1500.004k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:25:57,993][train][INFO][train.py>_log] ==> #677000     Total Loss: 2.614    [weighted Loss:2.614    Policy Loss: 7.553    Value Loss: 6.627    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 693398     Buffer Size: 28712      Transition Number: 1500.028k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:29:22,626][train][INFO][train.py>_log] ==> #678000     Total Loss: 2.856    [weighted Loss:2.856    Policy Loss: 8.322    Value Loss: 6.664    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 694587     Buffer Size: 28742      Transition Number: 1499.979k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:32:47,700][train][INFO][train.py>_log] ==> #679000     Total Loss: 3.278    [weighted Loss:3.278    Policy Loss: 8.827    Value Loss: 6.571    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 695997     Buffer Size: 29053      Transition Number: 1500.195k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:36:10,740][train][INFO][train.py>_log] ==> #680000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 8.130    Value Loss: 7.019    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 697411     Buffer Size: 29450      Transition Number: 1500.073k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:39:32,425][train][INFO][train.py>_log] ==> #681000     Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 8.580    Value Loss: 7.388    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 698833     Buffer Size: 29929      Transition Number: 1499.980k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:42:57,833][train][INFO][train.py>_log] ==> #682000     Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 8.503    Value Loss: 7.229    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 700319     Buffer Size: 30443      Transition Number: 1499.988k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:46:21,458][train][INFO][train.py>_log] ==> #683000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 7.565    Value Loss: 6.982    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 701586     Buffer Size: 30765      Transition Number: 1499.968k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:49:42,834][train][INFO][train.py>_log] ==> #684000     Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 5.955    Value Loss: 6.923    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 702818     Buffer Size: 31066      Transition Number: 1500.129k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:53:05,734][train][INFO][train.py>_log] ==> #685000     Total Loss: 1.461    [weighted Loss:1.461    Policy Loss: 6.221    Value Loss: 7.056    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 703945     Buffer Size: 31310      Transition Number: 1499.979k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:56:29,488][train][INFO][train.py>_log] ==> #686000     Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 6.577    Value Loss: 7.349    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 705076     Buffer Size: 31560      Transition Number: 1499.992k Batch Size: 256        Lr: 0.09000 
[2022-01-15 15:59:50,935][train][INFO][train.py>_log] ==> #687000     Total Loss: 2.046    [weighted Loss:2.046    Policy Loss: 6.215    Value Loss: 6.827    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 705984     Buffer Size: 31633      Transition Number: 1500.072k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:03:15,762][train][INFO][train.py>_log] ==> #688000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 6.588    Value Loss: 6.956    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 706912     Buffer Size: 31714      Transition Number: 1500.089k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:06:39,365][train][INFO][train.py>_log] ==> #689000     Total Loss: 3.243    [weighted Loss:3.243    Policy Loss: 5.790    Value Loss: 6.925    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 707827     Buffer Size: 31757      Transition Number: 1500.025k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:10:00,639][train][INFO][train.py>_log] ==> #690000     Total Loss: 2.644    [weighted Loss:2.644    Policy Loss: 5.154    Value Loss: 7.050    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 708710     Buffer Size: 31783      Transition Number: 1500.008k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:13:22,310][train][INFO][train.py>_log] ==> #691000     Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 5.257    Value Loss: 7.094    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 709620     Buffer Size: 31813      Transition Number: 1499.981k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:16:44,908][train][INFO][train.py>_log] ==> #692000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 4.825    Value Loss: 6.924    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 710521     Buffer Size: 31841      Transition Number: 1499.982k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:20:10,596][train][INFO][train.py>_log] ==> #693000     Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 6.341    Value Loss: 6.987    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 711435     Buffer Size: 31868      Transition Number: 1500.005k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:23:33,134][train][INFO][train.py>_log] ==> #694000     Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 5.388    Value Loss: 6.977    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 712366     Buffer Size: 31887      Transition Number: 1499.962k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:26:57,567][train][INFO][train.py>_log] ==> #695000     Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 4.763    Value Loss: 6.618    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 713303     Buffer Size: 31920      Transition Number: 1499.986k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:30:20,236][train][INFO][train.py>_log] ==> #696000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 5.366    Value Loss: 6.777    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 714241     Buffer Size: 31945      Transition Number: 1500.055k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:33:43,552][train][INFO][train.py>_log] ==> #697000     Total Loss: 3.545    [weighted Loss:3.545    Policy Loss: 7.162    Value Loss: 6.866    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 715140     Buffer Size: 31972      Transition Number: 1500.054k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:37:06,481][train][INFO][train.py>_log] ==> #698000     Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 5.264    Value Loss: 6.654    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 716071     Buffer Size: 31996      Transition Number: 1499.994k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:40:29,035][train][INFO][train.py>_log] ==> #699000     Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 6.212    Value Loss: 6.663    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 716976     Buffer Size: 32017      Transition Number: 1499.998k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:43:53,175][train][INFO][train.py>_log] ==> #700000     Total Loss: 0.757    [weighted Loss:0.757    Policy Loss: 4.747    Value Loss: 6.663    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 717923     Buffer Size: 32045      Transition Number: 1500.043k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:47:19,308][train][INFO][train.py>_log] ==> #701000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 5.868    Value Loss: 6.744    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 718902     Buffer Size: 31485      Transition Number: 1499.947k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:50:43,486][train][INFO][train.py>_log] ==> #702000     Total Loss: 3.101    [weighted Loss:3.101    Policy Loss: 5.458    Value Loss: 6.547    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 719858     Buffer Size: 30803      Transition Number: 1499.990k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:54:07,820][train][INFO][train.py>_log] ==> #703000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 5.811    Value Loss: 6.394    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 720739     Buffer Size: 30257      Transition Number: 1500.172k Batch Size: 256        Lr: 0.09000 
[2022-01-15 16:57:29,987][train][INFO][train.py>_log] ==> #704000     Total Loss: 3.245    [weighted Loss:3.245    Policy Loss: 5.831    Value Loss: 6.709    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 721595     Buffer Size: 29878      Transition Number: 1500.033k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:00:53,590][train][INFO][train.py>_log] ==> #705000     Total Loss: 4.101    [weighted Loss:4.101    Policy Loss: 6.890    Value Loss: 6.892    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 722789     Buffer Size: 29842      Transition Number: 1499.992k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:04:19,126][train][INFO][train.py>_log] ==> #706000     Total Loss: 3.424    [weighted Loss:3.424    Policy Loss: 6.362    Value Loss: 6.105    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 723989     Buffer Size: 29874      Transition Number: 1500.100k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:07:44,529][train][INFO][train.py>_log] ==> #707000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 6.230    Value Loss: 6.536    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 725369     Buffer Size: 29959      Transition Number: 1499.983k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:11:06,146][train][INFO][train.py>_log] ==> #708000     Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 5.644    Value Loss: 6.601    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 726694     Buffer Size: 29933      Transition Number: 1499.995k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:14:30,215][train][INFO][train.py>_log] ==> #709000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 6.256    Value Loss: 6.450    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 727648     Buffer Size: 29557      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:17:54,464][train][INFO][train.py>_log] ==> #710000     Total Loss: 3.477    [weighted Loss:3.477    Policy Loss: 6.071    Value Loss: 6.882    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 728593     Buffer Size: 29097      Transition Number: 1499.972k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:21:21,000][train][INFO][train.py>_log] ==> #711000     Total Loss: 1.100    [weighted Loss:1.100    Policy Loss: 5.997    Value Loss: 6.735    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 729560     Buffer Size: 28686      Transition Number: 1499.964k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:24:44,841][train][INFO][train.py>_log] ==> #712000     Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 6.095    Value Loss: 6.535    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 730522     Buffer Size: 28383      Transition Number: 1499.965k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:28:09,079][train][INFO][train.py>_log] ==> #713000     Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 7.388    Value Loss: 6.530    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 731527     Buffer Size: 28194      Transition Number: 1499.955k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:31:36,534][train][INFO][train.py>_log] ==> #714000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 6.104    Value Loss: 6.451    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 732570     Buffer Size: 28071      Transition Number: 1499.968k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:35:01,507][train][INFO][train.py>_log] ==> #715000     Total Loss: 3.599    [weighted Loss:3.599    Policy Loss: 7.333    Value Loss: 6.506    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 733620     Buffer Size: 28078      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:38:24,055][train][INFO][train.py>_log] ==> #716000     Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 7.065    Value Loss: 6.509    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 734638     Buffer Size: 28193      Transition Number: 1499.987k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:41:51,013][train][INFO][train.py>_log] ==> #717000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 7.275    Value Loss: 6.334    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 735730     Buffer Size: 28345      Transition Number: 1499.980k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:45:13,220][train][INFO][train.py>_log] ==> #718000     Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 6.611    Value Loss: 6.564    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 736784     Buffer Size: 28490      Transition Number: 1500.107k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:48:35,733][train][INFO][train.py>_log] ==> #719000     Total Loss: 1.381    [weighted Loss:1.381    Policy Loss: 7.657    Value Loss: 6.743    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 737773     Buffer Size: 28561      Transition Number: 1499.970k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:51:58,719][train][INFO][train.py>_log] ==> #720000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 7.717    Value Loss: 6.801    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 738771     Buffer Size: 28630      Transition Number: 1499.996k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:55:23,633][train][INFO][train.py>_log] ==> #721000     Total Loss: 2.714    [weighted Loss:2.714    Policy Loss: 7.010    Value Loss: 6.556    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 740216     Buffer Size: 29074      Transition Number: 1500.034k Batch Size: 256        Lr: 0.09000 
[2022-01-15 17:58:48,878][train][INFO][train.py>_log] ==> #722000     Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 7.613    Value Loss: 7.030    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 741740     Buffer Size: 29621      Transition Number: 1500.031k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:02:13,902][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 6.778    Value Loss: 7.055    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 742948     Buffer Size: 29889      Transition Number: 1499.961k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:05:36,456][train][INFO][train.py>_log] ==> #724000     Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 6.075    Value Loss: 6.364    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 744123     Buffer Size: 30112      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:08:59,183][train][INFO][train.py>_log] ==> #725000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 7.940    Value Loss: 6.772    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 745181     Buffer Size: 30227      Transition Number: 1500.002k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:12:24,170][train][INFO][train.py>_log] ==> #726000     Total Loss: 3.373    [weighted Loss:3.373    Policy Loss: 7.578    Value Loss: 6.535    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 746267     Buffer Size: 30347      Transition Number: 1499.982k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:15:44,621][train][INFO][train.py>_log] ==> #727000     Total Loss: 3.649    [weighted Loss:3.649    Policy Loss: 8.401    Value Loss: 6.998    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 747677     Buffer Size: 30786      Transition Number: 1499.941k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:19:06,425][train][INFO][train.py>_log] ==> #728000     Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 7.228    Value Loss: 6.643    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 749096     Buffer Size: 31265      Transition Number: 1499.984k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:22:28,287][train][INFO][train.py>_log] ==> #729000     Total Loss: 3.267    [weighted Loss:3.267    Policy Loss: 7.953    Value Loss: 6.627    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 750061     Buffer Size: 31283      Transition Number: 1499.964k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:25:51,093][train][INFO][train.py>_log] ==> #730000     Total Loss: 3.696    [weighted Loss:3.696    Policy Loss: 6.941    Value Loss: 6.908    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 751074     Buffer Size: 31303      Transition Number: 1500.046k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:29:14,315][train][INFO][train.py>_log] ==> #731000     Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 7.612    Value Loss: 6.708    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 752058     Buffer Size: 31421      Transition Number: 1500.019k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:32:36,277][train][INFO][train.py>_log] ==> #732000     Total Loss: 2.082    [weighted Loss:2.082    Policy Loss: 6.570    Value Loss: 6.707    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 753064     Buffer Size: 31558      Transition Number: 1499.995k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:35:58,893][train][INFO][train.py>_log] ==> #733000     Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 8.553    Value Loss: 6.620    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 754037     Buffer Size: 31424      Transition Number: 1499.965k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:39:21,767][train][INFO][train.py>_log] ==> #734000     Total Loss: 1.527    [weighted Loss:1.527    Policy Loss: 7.863    Value Loss: 6.819    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 755014     Buffer Size: 31246      Transition Number: 1499.966k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:42:43,706][train][INFO][train.py>_log] ==> #735000     Total Loss: 3.561    [weighted Loss:3.561    Policy Loss: 8.828    Value Loss: 6.309    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 755982     Buffer Size: 30924      Transition Number: 1500.005k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:46:09,603][train][INFO][train.py>_log] ==> #736000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 6.947    Value Loss: 6.643    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 756975     Buffer Size: 30568      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:49:33,519][train][INFO][train.py>_log] ==> #737000     Total Loss: 2.871    [weighted Loss:2.871    Policy Loss: 8.847    Value Loss: 6.662    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 757872     Buffer Size: 30460      Transition Number: 1499.936k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:53:00,290][train][INFO][train.py>_log] ==> #738000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 6.803    Value Loss: 6.516    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 758791     Buffer Size: 30443      Transition Number: 1500.033k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:56:21,813][train][INFO][train.py>_log] ==> #739000     Total Loss: 0.917    [weighted Loss:0.917    Policy Loss: 7.915    Value Loss: 6.350    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 759707     Buffer Size: 30439      Transition Number: 1499.985k Batch Size: 256        Lr: 0.09000 
[2022-01-15 18:59:43,743][train][INFO][train.py>_log] ==> #740000     Total Loss: 3.723    [weighted Loss:3.723    Policy Loss: 7.612    Value Loss: 6.155    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 760615     Buffer Size: 30408      Transition Number: 1499.938k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:03:07,907][train][INFO][train.py>_log] ==> #741000     Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 7.322    Value Loss: 7.037    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 761749     Buffer Size: 30550      Transition Number: 1499.968k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:06:32,796][train][INFO][train.py>_log] ==> #742000     Total Loss: 3.893    [weighted Loss:3.893    Policy Loss: 7.021    Value Loss: 6.547    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 762883     Buffer Size: 30668      Transition Number: 1499.949k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:09:55,150][train][INFO][train.py>_log] ==> #743000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 8.792    Value Loss: 6.708    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 763938     Buffer Size: 30714      Transition Number: 1500.024k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:13:18,831][train][INFO][train.py>_log] ==> #744000     Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 6.892    Value Loss: 6.299    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 765016     Buffer Size: 30743      Transition Number: 1500.020k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:16:43,333][train][INFO][train.py>_log] ==> #745000     Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 8.211    Value Loss: 6.634    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 766038     Buffer Size: 30740      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:20:06,762][train][INFO][train.py>_log] ==> #746000     Total Loss: 1.881    [weighted Loss:1.881    Policy Loss: 7.125    Value Loss: 6.611    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 767116     Buffer Size: 30750      Transition Number: 1499.979k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:23:32,266][train][INFO][train.py>_log] ==> #747000     Total Loss: 3.253    [weighted Loss:3.253    Policy Loss: 8.405    Value Loss: 7.266    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 768109     Buffer Size: 30738      Transition Number: 1500.052k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:26:53,575][train][INFO][train.py>_log] ==> #748000     Total Loss: 3.866    [weighted Loss:3.866    Policy Loss: 7.911    Value Loss: 7.278    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 769090     Buffer Size: 30737      Transition Number: 1499.942k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:30:15,743][train][INFO][train.py>_log] ==> #749000     Total Loss: 4.069    [weighted Loss:4.069    Policy Loss: 9.078    Value Loss: 6.877    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 770168     Buffer Size: 30687      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:33:41,567][train][INFO][train.py>_log] ==> #750000     Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 7.049    Value Loss: 6.739    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 771301     Buffer Size: 30376      Transition Number: 1500.038k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:37:05,505][train][INFO][train.py>_log] ==> #751000     Total Loss: 2.995    [weighted Loss:2.995    Policy Loss: 8.944    Value Loss: 6.416    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 772387     Buffer Size: 30113      Transition Number: 1500.006k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:40:31,432][train][INFO][train.py>_log] ==> #752000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 7.699    Value Loss: 6.589    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 773462     Buffer Size: 29995      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:43:58,990][train][INFO][train.py>_log] ==> #753000     Total Loss: 1.964    [weighted Loss:1.964    Policy Loss: 8.520    Value Loss: 6.283    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 774575     Buffer Size: 29952      Transition Number: 1500.019k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:47:22,199][train][INFO][train.py>_log] ==> #754000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 8.401    Value Loss: 6.474    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 775619     Buffer Size: 29971      Transition Number: 1500.002k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:50:43,201][train][INFO][train.py>_log] ==> #755000     Total Loss: 2.478    [weighted Loss:2.478    Policy Loss: 8.714    Value Loss: 6.819    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 776753     Buffer Size: 29942      Transition Number: 1500.049k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:54:08,877][train][INFO][train.py>_log] ==> #756000     Total Loss: 3.402    [weighted Loss:3.402    Policy Loss: 8.649    Value Loss: 6.582    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 777904     Buffer Size: 29656      Transition Number: 1499.994k Batch Size: 256        Lr: 0.09000 
[2022-01-15 19:57:37,658][train][INFO][train.py>_log] ==> #757000     Total Loss: 3.750    [weighted Loss:3.750    Policy Loss: 9.108    Value Loss: 6.653    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 780174     Buffer Size: 30544      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:00:59,374][train][INFO][train.py>_log] ==> #758000     Total Loss: 4.952    [weighted Loss:4.952    Policy Loss: 10.089   Value Loss: 7.442    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 782356     Buffer Size: 31681      Transition Number: 1499.974k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:04:21,661][train][INFO][train.py>_log] ==> #759000     Total Loss: 1.577    [weighted Loss:1.577    Policy Loss: 8.016    Value Loss: 7.485    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 783922     Buffer Size: 32244      Transition Number: 1499.993k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:07:42,756][train][INFO][train.py>_log] ==> #760000     Total Loss: 4.855    [weighted Loss:4.855    Policy Loss: 9.029    Value Loss: 6.840    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 785468     Buffer Size: 32771      Transition Number: 1499.974k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:11:02,493][train][INFO][train.py>_log] ==> #761000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 7.798    Value Loss: 6.742    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 786394     Buffer Size: 32748      Transition Number: 1500.052k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:14:24,020][train][INFO][train.py>_log] ==> #762000     Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 8.115    Value Loss: 6.665    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 787328     Buffer Size: 32697      Transition Number: 1499.990k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:17:46,754][train][INFO][train.py>_log] ==> #763000     Total Loss: 4.196    [weighted Loss:4.196    Policy Loss: 8.976    Value Loss: 6.684    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 788491     Buffer Size: 32875      Transition Number: 1499.948k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:21:10,439][train][INFO][train.py>_log] ==> #764000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 9.315    Value Loss: 6.884    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 789678     Buffer Size: 33058      Transition Number: 1500.061k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:24:31,336][train][INFO][train.py>_log] ==> #765000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 8.467    Value Loss: 6.824    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 790673     Buffer Size: 33151      Transition Number: 1500.028k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:27:54,388][train][INFO][train.py>_log] ==> #766000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 9.027    Value Loss: 6.944    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 791699     Buffer Size: 33254      Transition Number: 1499.987k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:31:14,908][train][INFO][train.py>_log] ==> #767000     Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 9.064    Value Loss: 6.728    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 792680     Buffer Size: 33307      Transition Number: 1499.974k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:34:36,173][train][INFO][train.py>_log] ==> #768000     Total Loss: 3.985    [weighted Loss:3.985    Policy Loss: 9.096    Value Loss: 6.630    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 793628     Buffer Size: 33360      Transition Number: 1500.112k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:37:58,361][train][INFO][train.py>_log] ==> #769000     Total Loss: 3.527    [weighted Loss:3.527    Policy Loss: 9.574    Value Loss: 6.898    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 794610     Buffer Size: 33305      Transition Number: 1499.949k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:41:21,907][train][INFO][train.py>_log] ==> #770000     Total Loss: 4.374    [weighted Loss:4.374    Policy Loss: 9.392    Value Loss: 6.814    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 795593     Buffer Size: 33156      Transition Number: 1500.107k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:44:45,367][train][INFO][train.py>_log] ==> #771000     Total Loss: 2.596    [weighted Loss:2.596    Policy Loss: 8.770    Value Loss: 6.546    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 796574     Buffer Size: 33050      Transition Number: 1499.954k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:48:10,390][train][INFO][train.py>_log] ==> #772000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 9.665    Value Loss: 7.090    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 797544     Buffer Size: 32966      Transition Number: 1500.121k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:51:32,929][train][INFO][train.py>_log] ==> #773000     Total Loss: 3.161    [weighted Loss:3.161    Policy Loss: 8.897    Value Loss: 6.475    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 798508     Buffer Size: 32884      Transition Number: 1500.107k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:54:57,575][train][INFO][train.py>_log] ==> #774000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 8.741    Value Loss: 6.740    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 799485     Buffer Size: 32791      Transition Number: 1499.963k Batch Size: 256        Lr: 0.09000 
[2022-01-15 20:58:19,390][train][INFO][train.py>_log] ==> #775000     Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 7.946    Value Loss: 6.542    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 800434     Buffer Size: 32699      Transition Number: 1500.021k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:01:42,001][train][INFO][train.py>_log] ==> #776000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 8.852    Value Loss: 6.819    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 801367     Buffer Size: 32653      Transition Number: 1499.953k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:05:04,870][train][INFO][train.py>_log] ==> #777000     Total Loss: 0.604    [weighted Loss:0.604    Policy Loss: 8.943    Value Loss: 6.914    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 802440     Buffer Size: 32644      Transition Number: 1499.943k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:08:29,535][train][INFO][train.py>_log] ==> #778000     Total Loss: 3.426    [weighted Loss:3.426    Policy Loss: 9.220    Value Loss: 6.719    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 803526     Buffer Size: 32615      Transition Number: 1499.987k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:11:53,704][train][INFO][train.py>_log] ==> #779000     Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 9.867    Value Loss: 7.101    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 804653     Buffer Size: 32621      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:15:15,871][train][INFO][train.py>_log] ==> #780000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 8.982    Value Loss: 6.863    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 805760     Buffer Size: 32665      Transition Number: 1500.197k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:18:39,541][train][INFO][train.py>_log] ==> #781000     Total Loss: 3.808    [weighted Loss:3.808    Policy Loss: 9.204    Value Loss: 6.727    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 806839     Buffer Size: 32676      Transition Number: 1499.946k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:22:02,864][train][INFO][train.py>_log] ==> #782000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 9.149    Value Loss: 7.029    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 807922     Buffer Size: 32705      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:25:27,063][train][INFO][train.py>_log] ==> #783000     Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 8.361    Value Loss: 6.991    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 809010     Buffer Size: 32660      Transition Number: 1500.035k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:28:50,717][train][INFO][train.py>_log] ==> #784000     Total Loss: 3.821    [weighted Loss:3.821    Policy Loss: 9.350    Value Loss: 6.677    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 810104     Buffer Size: 32611      Transition Number: 1499.954k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:32:14,587][train][INFO][train.py>_log] ==> #785000     Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 9.356    Value Loss: 7.130    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 811395     Buffer Size: 32133      Transition Number: 1500.000k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:35:38,894][train][INFO][train.py>_log] ==> #786000     Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 9.768    Value Loss: 7.355    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 812710     Buffer Size: 31299      Transition Number: 1500.038k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:39:03,275][train][INFO][train.py>_log] ==> #787000     Total Loss: 3.904    [weighted Loss:3.904    Policy Loss: 10.039   Value Loss: 7.067    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 814141     Buffer Size: 30848      Transition Number: 1500.007k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:42:28,064][train][INFO][train.py>_log] ==> #788000     Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 10.367   Value Loss: 7.093    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 815551     Buffer Size: 30683      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:45:53,353][train][INFO][train.py>_log] ==> #789000     Total Loss: 3.360    [weighted Loss:3.360    Policy Loss: 9.418    Value Loss: 7.213    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 816693     Buffer Size: 30623      Transition Number: 1499.965k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:49:15,846][train][INFO][train.py>_log] ==> #790000     Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 9.936    Value Loss: 6.947    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 817851     Buffer Size: 30828      Transition Number: 1500.013k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:52:38,026][train][INFO][train.py>_log] ==> #791000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 8.487    Value Loss: 7.542    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 819253     Buffer Size: 31110      Transition Number: 1499.969k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:56:03,751][train][INFO][train.py>_log] ==> #792000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 10.317   Value Loss: 7.090    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 820657     Buffer Size: 31330      Transition Number: 1500.004k Batch Size: 256        Lr: 0.09000 
[2022-01-15 21:59:26,094][train][INFO][train.py>_log] ==> #793000     Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 7.970    Value Loss: 6.740    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 822010     Buffer Size: 31617      Transition Number: 1499.983k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:02:46,819][train][INFO][train.py>_log] ==> #794000     Total Loss: 2.600    [weighted Loss:2.600    Policy Loss: 9.206    Value Loss: 6.778    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 823392     Buffer Size: 31944      Transition Number: 1500.024k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:06:11,012][train][INFO][train.py>_log] ==> #795000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 8.659    Value Loss: 7.306    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 824739     Buffer Size: 32266      Transition Number: 1499.983k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:09:31,348][train][INFO][train.py>_log] ==> #796000     Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 8.117    Value Loss: 6.936    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 826016     Buffer Size: 32564      Transition Number: 1499.971k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:12:51,522][train][INFO][train.py>_log] ==> #797000     Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 8.996    Value Loss: 6.790    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 827224     Buffer Size: 32786      Transition Number: 1499.947k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:16:14,455][train][INFO][train.py>_log] ==> #798000     Total Loss: 4.560    [weighted Loss:4.560    Policy Loss: 8.788    Value Loss: 7.035    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 828426     Buffer Size: 32989      Transition Number: 1499.954k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:19:35,581][train][INFO][train.py>_log] ==> #799000     Total Loss: 4.183    [weighted Loss:4.183    Policy Loss: 8.659    Value Loss: 7.536    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 829628     Buffer Size: 33226      Transition Number: 1500.099k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:22:58,945][train][INFO][train.py>_log] ==> #800000     Total Loss: 2.708    [weighted Loss:2.708    Policy Loss: 9.630    Value Loss: 7.138    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 830853     Buffer Size: 33453      Transition Number: 1500.046k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:26:19,757][train][INFO][train.py>_log] ==> #801000     Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 9.026    Value Loss: 7.122    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 832049     Buffer Size: 33684      Transition Number: 1500.055k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:29:40,544][train][INFO][train.py>_log] ==> #802000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 8.942    Value Loss: 7.328    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 833280     Buffer Size: 33921      Transition Number: 1500.001k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:33:04,114][train][INFO][train.py>_log] ==> #803000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 8.309    Value Loss: 7.339    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 834567     Buffer Size: 34216      Transition Number: 1500.027k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:36:24,904][train][INFO][train.py>_log] ==> #804000     Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 8.183    Value Loss: 7.026    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 835844     Buffer Size: 34545      Transition Number: 1499.982k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:39:46,258][train][INFO][train.py>_log] ==> #805000     Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 8.268    Value Loss: 6.741    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 837134     Buffer Size: 34815      Transition Number: 1499.972k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:43:08,289][train][INFO][train.py>_log] ==> #806000     Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 7.883    Value Loss: 7.149    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 838433     Buffer Size: 35031      Transition Number: 1499.970k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:46:27,352][train][INFO][train.py>_log] ==> #807000     Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 8.382    Value Loss: 7.093    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 839548     Buffer Size: 35085      Transition Number: 1499.975k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:49:49,217][train][INFO][train.py>_log] ==> #808000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 8.295    Value Loss: 7.336    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 840693     Buffer Size: 35129      Transition Number: 1500.012k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:53:12,788][train][INFO][train.py>_log] ==> #809000     Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 7.804    Value Loss: 7.045    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 841823     Buffer Size: 35172      Transition Number: 1500.001k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:56:33,185][train][INFO][train.py>_log] ==> #810000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 8.260    Value Loss: 7.297    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 842951     Buffer Size: 35239      Transition Number: 1500.011k Batch Size: 256        Lr: 0.09000 
[2022-01-15 22:59:55,358][train][INFO][train.py>_log] ==> #811000     Total Loss: 1.785    [weighted Loss:1.785    Policy Loss: 8.722    Value Loss: 7.096    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 844451     Buffer Size: 35607      Transition Number: 1500.004k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:03:16,277][train][INFO][train.py>_log] ==> #812000     Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 8.103    Value Loss: 7.444    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 845949     Buffer Size: 36014      Transition Number: 1500.036k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:06:34,680][train][INFO][train.py>_log] ==> #813000     Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 8.052    Value Loss: 6.932    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 847286     Buffer Size: 36167      Transition Number: 1499.994k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:09:57,088][train][INFO][train.py>_log] ==> #814000     Total Loss: 1.203    [weighted Loss:1.203    Policy Loss: 7.899    Value Loss: 7.571    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 848694     Buffer Size: 36279      Transition Number: 1499.942k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:13:20,291][train][INFO][train.py>_log] ==> #815000     Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 8.851    Value Loss: 7.638    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 849623     Buffer Size: 35913      Transition Number: 1500.127k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:16:43,869][train][INFO][train.py>_log] ==> #816000     Total Loss: 1.292    [weighted Loss:1.292    Policy Loss: 7.493    Value Loss: 6.838    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 850558     Buffer Size: 35530      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:20:04,289][train][INFO][train.py>_log] ==> #817000     Total Loss: 4.109    [weighted Loss:4.109    Policy Loss: 7.183    Value Loss: 7.057    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 851594     Buffer Size: 35373      Transition Number: 1499.990k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:23:26,364][train][INFO][train.py>_log] ==> #818000     Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 7.321    Value Loss: 7.293    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 852692     Buffer Size: 35335      Transition Number: 1500.192k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:26:49,803][train][INFO][train.py>_log] ==> #819000     Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 6.443    Value Loss: 7.328    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 853644     Buffer Size: 35081      Transition Number: 1499.977k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:30:10,479][train][INFO][train.py>_log] ==> #820000     Total Loss: 3.628    [weighted Loss:3.628    Policy Loss: 7.814    Value Loss: 7.309    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 854582     Buffer Size: 34694      Transition Number: 1499.963k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:33:32,630][train][INFO][train.py>_log] ==> #821000     Total Loss: 3.800    [weighted Loss:3.800    Policy Loss: 8.197    Value Loss: 7.476    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 855649     Buffer Size: 34366      Transition Number: 1499.977k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:36:56,376][train][INFO][train.py>_log] ==> #822000     Total Loss: 1.354    [weighted Loss:1.354    Policy Loss: 7.430    Value Loss: 7.279    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 856719     Buffer Size: 34082      Transition Number: 1499.990k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:40:21,323][train][INFO][train.py>_log] ==> #823000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 7.173    Value Loss: 6.864    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 858160     Buffer Size: 34123      Transition Number: 1500.014k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:43:41,929][train][INFO][train.py>_log] ==> #824000     Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 7.216    Value Loss: 7.060    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 859612     Buffer Size: 34218      Transition Number: 1500.007k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:47:02,286][train][INFO][train.py>_log] ==> #825000     Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 7.243    Value Loss: 7.027    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 860629     Buffer Size: 34067      Transition Number: 1499.980k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:50:20,828][train][INFO][train.py>_log] ==> #826000     Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 6.985    Value Loss: 7.647    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 861661     Buffer Size: 33941      Transition Number: 1500.048k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:53:44,829][train][INFO][train.py>_log] ==> #827000     Total Loss: 2.621    [weighted Loss:2.621    Policy Loss: 7.225    Value Loss: 7.273    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 863487     Buffer Size: 34607      Transition Number: 1500.000k Batch Size: 256        Lr: 0.09000 
[2022-01-15 23:57:07,113][train][INFO][train.py>_log] ==> #828000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 8.416    Value Loss: 7.299    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 865455     Buffer Size: 35355      Transition Number: 1500.125k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:00:26,601][train][INFO][train.py>_log] ==> #829000     Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 7.064    Value Loss: 7.054    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 867223     Buffer Size: 35896      Transition Number: 1500.067k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:03:48,796][train][INFO][train.py>_log] ==> #830000     Total Loss: 1.423    [weighted Loss:1.423    Policy Loss: 7.462    Value Loss: 7.200    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 869072     Buffer Size: 36531      Transition Number: 1499.947k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:07:10,037][train][INFO][train.py>_log] ==> #831000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 6.826    Value Loss: 6.725    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 870085     Buffer Size: 36357      Transition Number: 1499.943k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:10:32,011][train][INFO][train.py>_log] ==> #832000     Total Loss: 2.738    [weighted Loss:2.738    Policy Loss: 6.835    Value Loss: 7.121    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 871112     Buffer Size: 36120      Transition Number: 1500.055k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:13:52,666][train][INFO][train.py>_log] ==> #833000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 7.711    Value Loss: 7.395    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 872050     Buffer Size: 35824      Transition Number: 1500.093k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:17:14,085][train][INFO][train.py>_log] ==> #834000     Total Loss: 2.942    [weighted Loss:2.942    Policy Loss: 7.009    Value Loss: 7.010    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 872998     Buffer Size: 35476      Transition Number: 1499.940k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:20:37,619][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 7.013    Value Loss: 6.571    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 873959     Buffer Size: 35180      Transition Number: 1499.953k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:24:00,721][train][INFO][train.py>_log] ==> #836000     Total Loss: 1.565    [weighted Loss:1.565    Policy Loss: 7.372    Value Loss: 6.953    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 874919     Buffer Size: 35001      Transition Number: 1500.100k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:27:22,435][train][INFO][train.py>_log] ==> #837000     Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 6.849    Value Loss: 6.799    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 875958     Buffer Size: 34924      Transition Number: 1500.020k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:30:46,874][train][INFO][train.py>_log] ==> #838000     Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 7.425    Value Loss: 7.638    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 877022     Buffer Size: 34844      Transition Number: 1500.010k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:34:09,282][train][INFO][train.py>_log] ==> #839000     Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 7.054    Value Loss: 6.725    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 877883     Buffer Size: 34570      Transition Number: 1500.067k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:37:32,009][train][INFO][train.py>_log] ==> #840000     Total Loss: 2.443    [weighted Loss:2.443    Policy Loss: 7.032    Value Loss: 7.275    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 878780     Buffer Size: 34001      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:40:57,685][train][INFO][train.py>_log] ==> #841000     Total Loss: 2.950    [weighted Loss:2.950    Policy Loss: 6.770    Value Loss: 6.247    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 879632     Buffer Size: 33397      Transition Number: 1499.981k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:44:22,030][train][INFO][train.py>_log] ==> #842000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 6.303    Value Loss: 6.589    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 880473     Buffer Size: 32933      Transition Number: 1499.981k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:47:44,584][train][INFO][train.py>_log] ==> #843000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 6.333    Value Loss: 6.004    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 881388     Buffer Size: 32536      Transition Number: 1500.194k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:51:07,786][train][INFO][train.py>_log] ==> #844000     Total Loss: 2.561    [weighted Loss:2.561    Policy Loss: 7.301    Value Loss: 6.730    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 882265     Buffer Size: 32502      Transition Number: 1500.011k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:54:33,725][train][INFO][train.py>_log] ==> #845000     Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 8.150    Value Loss: 6.894    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 883223     Buffer Size: 32503      Transition Number: 1499.961k Batch Size: 256        Lr: 0.09000 
[2022-01-16 00:57:55,207][train][INFO][train.py>_log] ==> #846000     Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 7.242    Value Loss: 6.319    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 884186     Buffer Size: 32383      Transition Number: 1499.988k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:01:18,329][train][INFO][train.py>_log] ==> #847000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 7.926    Value Loss: 6.686    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 885229     Buffer Size: 32323      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:04:43,835][train][INFO][train.py>_log] ==> #848000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 7.296    Value Loss: 6.334    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 886243     Buffer Size: 32369      Transition Number: 1499.950k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:08:06,859][train][INFO][train.py>_log] ==> #849000     Total Loss: 2.990    [weighted Loss:2.990    Policy Loss: 8.442    Value Loss: 6.724    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 887363     Buffer Size: 32512      Transition Number: 1499.962k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:11:28,511][train][INFO][train.py>_log] ==> #850000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 7.119    Value Loss: 6.614    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 888471     Buffer Size: 32524      Transition Number: 1499.939k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:14:54,122][train][INFO][train.py>_log] ==> #851000     Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 6.804    Value Loss: 6.458    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 889470     Buffer Size: 32371      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:18:19,875][train][INFO][train.py>_log] ==> #852000     Total Loss: 0.851    [weighted Loss:0.851    Policy Loss: 7.089    Value Loss: 6.520    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 890459     Buffer Size: 31993      Transition Number: 1500.095k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:21:45,644][train][INFO][train.py>_log] ==> #853000     Total Loss: 2.918    [weighted Loss:2.918    Policy Loss: 6.798    Value Loss: 6.570    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 891506     Buffer Size: 31683      Transition Number: 1500.033k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:25:09,540][train][INFO][train.py>_log] ==> #854000     Total Loss: 2.961    [weighted Loss:2.961    Policy Loss: 7.576    Value Loss: 7.025    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 892585     Buffer Size: 31675      Transition Number: 1499.973k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:28:35,006][train][INFO][train.py>_log] ==> #855000     Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 7.982    Value Loss: 6.309    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 893707     Buffer Size: 31463      Transition Number: 1499.996k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:32:00,533][train][INFO][train.py>_log] ==> #856000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 8.024    Value Loss: 6.861    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 894832     Buffer Size: 30618      Transition Number: 1499.980k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:35:23,874][train][INFO][train.py>_log] ==> #857000     Total Loss: 3.677    [weighted Loss:3.677    Policy Loss: 8.307    Value Loss: 6.736    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 896163     Buffer Size: 29970      Transition Number: 1499.979k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:38:48,592][train][INFO][train.py>_log] ==> #858000     Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 7.769    Value Loss: 6.990    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 897515     Buffer Size: 29411      Transition Number: 1500.025k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:42:11,722][train][INFO][train.py>_log] ==> #859000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 8.418    Value Loss: 7.111    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 898659     Buffer Size: 29099      Transition Number: 1499.972k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:45:38,244][train][INFO][train.py>_log] ==> #860000     Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 7.744    Value Loss: 6.743    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 899799     Buffer Size: 29173      Transition Number: 1499.979k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:49:00,324][train][INFO][train.py>_log] ==> #861000     Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 7.543    Value Loss: 6.637    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 900882     Buffer Size: 29250      Transition Number: 1499.994k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:52:25,152][train][INFO][train.py>_log] ==> #862000     Total Loss: 1.800    [weighted Loss:1.800    Policy Loss: 8.910    Value Loss: 6.374    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 901975     Buffer Size: 29365      Transition Number: 1500.032k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:55:49,466][train][INFO][train.py>_log] ==> #863000     Total Loss: 2.772    [weighted Loss:2.772    Policy Loss: 9.652    Value Loss: 6.719    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 903319     Buffer Size: 29691      Transition Number: 1500.007k Batch Size: 256        Lr: 0.09000 
[2022-01-16 01:59:13,405][train][INFO][train.py>_log] ==> #864000     Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 9.104    Value Loss: 6.672    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 904656     Buffer Size: 30034      Transition Number: 1499.938k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:02:35,100][train][INFO][train.py>_log] ==> #865000     Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 10.355   Value Loss: 7.058    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 905980     Buffer Size: 30323      Transition Number: 1499.981k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:05:58,998][train][INFO][train.py>_log] ==> #866000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 9.137    Value Loss: 6.959    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 907332     Buffer Size: 30586      Transition Number: 1499.975k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:09:22,519][train][INFO][train.py>_log] ==> #867000     Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 9.564    Value Loss: 6.972    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 908570     Buffer Size: 30856      Transition Number: 1500.044k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:12:45,578][train][INFO][train.py>_log] ==> #868000     Total Loss: 1.494    [weighted Loss:1.494    Policy Loss: 8.474    Value Loss: 7.675    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 909850     Buffer Size: 31199      Transition Number: 1499.981k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:16:08,477][train][INFO][train.py>_log] ==> #869000     Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 8.272    Value Loss: 6.806    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 910980     Buffer Size: 31480      Transition Number: 1499.944k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:19:30,161][train][INFO][train.py>_log] ==> #870000     Total Loss: 2.515    [weighted Loss:2.515    Policy Loss: 7.892    Value Loss: 7.032    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 912135     Buffer Size: 31750      Transition Number: 1499.979k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:22:52,638][train][INFO][train.py>_log] ==> #871000     Total Loss: 3.310    [weighted Loss:3.310    Policy Loss: 7.864    Value Loss: 6.771    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 913282     Buffer Size: 32009      Transition Number: 1500.217k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:26:15,664][train][INFO][train.py>_log] ==> #872000     Total Loss: 3.193    [weighted Loss:3.193    Policy Loss: 8.812    Value Loss: 7.236    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 914426     Buffer Size: 32247      Transition Number: 1499.938k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:29:37,808][train][INFO][train.py>_log] ==> #873000     Total Loss: 3.457    [weighted Loss:3.457    Policy Loss: 7.688    Value Loss: 7.217    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 915498     Buffer Size: 32381      Transition Number: 1500.079k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:33:01,681][train][INFO][train.py>_log] ==> #874000     Total Loss: 1.872    [weighted Loss:1.872    Policy Loss: 7.313    Value Loss: 7.013    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 916589     Buffer Size: 32509      Transition Number: 1499.971k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:36:22,706][train][INFO][train.py>_log] ==> #875000     Total Loss: 1.674    [weighted Loss:1.674    Policy Loss: 8.535    Value Loss: 7.231    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 917508     Buffer Size: 32474      Transition Number: 1499.996k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:39:47,479][train][INFO][train.py>_log] ==> #876000     Total Loss: 2.162    [weighted Loss:2.162    Policy Loss: 6.848    Value Loss: 6.829    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 918447     Buffer Size: 32428      Transition Number: 1499.959k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:43:10,870][train][INFO][train.py>_log] ==> #877000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 7.825    Value Loss: 7.107    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 919364     Buffer Size: 32291      Transition Number: 1499.974k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:46:30,517][train][INFO][train.py>_log] ==> #878000     Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 6.415    Value Loss: 7.340    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 920299     Buffer Size: 32150      Transition Number: 1499.998k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:49:51,368][train][INFO][train.py>_log] ==> #879000     Total Loss: 1.473    [weighted Loss:1.473    Policy Loss: 7.284    Value Loss: 7.070    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 921290     Buffer Size: 32128      Transition Number: 1500.128k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:53:12,660][train][INFO][train.py>_log] ==> #880000     Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 7.191    Value Loss: 7.249    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 922287     Buffer Size: 32163      Transition Number: 1500.000k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:56:36,314][train][INFO][train.py>_log] ==> #881000     Total Loss: 2.627    [weighted Loss:2.627    Policy Loss: 7.722    Value Loss: 7.342    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 923525     Buffer Size: 32366      Transition Number: 1499.990k Batch Size: 256        Lr: 0.09000 
[2022-01-16 02:59:59,275][train][INFO][train.py>_log] ==> #882000     Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 7.056    Value Loss: 6.864    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 924796     Buffer Size: 32563      Transition Number: 1500.013k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:03:22,978][train][INFO][train.py>_log] ==> #883000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 7.626    Value Loss: 7.078    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 925882     Buffer Size: 32543      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:06:46,721][train][INFO][train.py>_log] ==> #884000     Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 6.923    Value Loss: 7.546    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 926937     Buffer Size: 32500      Transition Number: 1499.979k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:10:09,793][train][INFO][train.py>_log] ==> #885000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 6.478    Value Loss: 7.185    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 927839     Buffer Size: 32219      Transition Number: 1500.083k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:13:33,708][train][INFO][train.py>_log] ==> #886000     Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 5.985    Value Loss: 7.153    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 928738     Buffer Size: 31843      Transition Number: 1499.947k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:16:56,741][train][INFO][train.py>_log] ==> #887000     Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 6.762    Value Loss: 6.954    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 929640     Buffer Size: 31528      Transition Number: 1499.995k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:20:21,829][train][INFO][train.py>_log] ==> #888000     Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 6.047    Value Loss: 7.191    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 930533     Buffer Size: 31313      Transition Number: 1499.982k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:23:45,788][train][INFO][train.py>_log] ==> #889000     Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 6.505    Value Loss: 6.702    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 931479     Buffer Size: 31182      Transition Number: 1499.976k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:27:08,373][train][INFO][train.py>_log] ==> #890000     Total Loss: 0.925    [weighted Loss:0.925    Policy Loss: 5.963    Value Loss: 6.864    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 932439     Buffer Size: 31058      Transition Number: 1500.015k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:30:35,042][train][INFO][train.py>_log] ==> #891000     Total Loss: 1.653    [weighted Loss:1.653    Policy Loss: 6.009    Value Loss: 6.609    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 933415     Buffer Size: 30832      Transition Number: 1499.967k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:33:58,976][train][INFO][train.py>_log] ==> #892000     Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 5.795    Value Loss: 6.774    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 934330     Buffer Size: 30520      Transition Number: 1499.998k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:37:22,995][train][INFO][train.py>_log] ==> #893000     Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 6.174    Value Loss: 6.874    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 935179     Buffer Size: 30171      Transition Number: 1499.992k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:40:48,541][train][INFO][train.py>_log] ==> #894000     Total Loss: 1.090    [weighted Loss:1.090    Policy Loss: 5.449    Value Loss: 6.691    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 936098     Buffer Size: 29776      Transition Number: 1499.946k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:44:15,205][train][INFO][train.py>_log] ==> #895000     Total Loss: 0.877    [weighted Loss:0.877    Policy Loss: 5.954    Value Loss: 6.605    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 937000     Buffer Size: 29308      Transition Number: 1499.963k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:47:38,165][train][INFO][train.py>_log] ==> #896000     Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 6.701    Value Loss: 6.155    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 937852     Buffer Size: 28973      Transition Number: 1499.990k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:51:01,934][train][INFO][train.py>_log] ==> #897000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 6.047    Value Loss: 6.403    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 938744     Buffer Size: 28673      Transition Number: 1499.988k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:54:26,254][train][INFO][train.py>_log] ==> #898000     Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 6.568    Value Loss: 6.613    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 939628     Buffer Size: 28404      Transition Number: 1500.027k Batch Size: 256        Lr: 0.09000 
[2022-01-16 03:57:49,239][train][INFO][train.py>_log] ==> #899000     Total Loss: 2.161    [weighted Loss:2.161    Policy Loss: 6.528    Value Loss: 6.681    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 940470     Buffer Size: 28107      Transition Number: 1499.998k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:01:14,238][train][INFO][train.py>_log] ==> #900000     Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 6.357    Value Loss: 6.392    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 941348     Buffer Size: 27808      Transition Number: 1500.019k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:04:38,663][train][INFO][train.py>_log] ==> #901000     Total Loss: 2.869    [weighted Loss:2.869    Policy Loss: 7.720    Value Loss: 6.676    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 942405     Buffer Size: 27675      Transition Number: 1499.967k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:08:03,578][train][INFO][train.py>_log] ==> #902000     Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 7.259    Value Loss: 6.559    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 943502     Buffer Size: 27640      Transition Number: 1500.007k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:11:26,188][train][INFO][train.py>_log] ==> #903000     Total Loss: 1.825    [weighted Loss:1.825    Policy Loss: 8.344    Value Loss: 6.589    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 944499     Buffer Size: 27567      Transition Number: 1499.978k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:14:52,069][train][INFO][train.py>_log] ==> #904000     Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 7.206    Value Loss: 6.487    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 945490     Buffer Size: 27587      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:18:16,450][train][INFO][train.py>_log] ==> #905000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 7.778    Value Loss: 6.656    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 946405     Buffer Size: 27531      Transition Number: 1500.008k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:21:40,582][train][INFO][train.py>_log] ==> #906000     Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 7.286    Value Loss: 6.132    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 947325     Buffer Size: 27488      Transition Number: 1499.956k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:25:07,645][train][INFO][train.py>_log] ==> #907000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 7.858    Value Loss: 7.094    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 949112     Buffer Size: 28180      Transition Number: 1499.950k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:28:32,895][train][INFO][train.py>_log] ==> #908000     Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 7.495    Value Loss: 6.371    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 950951     Buffer Size: 28937      Transition Number: 1499.967k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:31:57,835][train][INFO][train.py>_log] ==> #909000     Total Loss: 4.120    [weighted Loss:4.120    Policy Loss: 8.810    Value Loss: 7.108    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 952606     Buffer Size: 29384      Transition Number: 1500.023k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:35:24,301][train][INFO][train.py>_log] ==> #910000     Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 7.326    Value Loss: 6.775    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 954300     Buffer Size: 29745      Transition Number: 1500.000k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:38:48,441][train][INFO][train.py>_log] ==> #911000     Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 8.561    Value Loss: 6.840    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 955385     Buffer Size: 29722      Transition Number: 1499.981k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:42:13,018][train][INFO][train.py>_log] ==> #912000     Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 7.763    Value Loss: 6.656    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 956498     Buffer Size: 29727      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:45:40,125][train][INFO][train.py>_log] ==> #913000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 8.063    Value Loss: 6.708    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 957687     Buffer Size: 29913      Transition Number: 1500.041k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:49:03,678][train][INFO][train.py>_log] ==> #914000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 7.516    Value Loss: 6.493    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 958799     Buffer Size: 30113      Transition Number: 1500.025k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:52:27,438][train][INFO][train.py>_log] ==> #915000     Total Loss: 2.640    [weighted Loss:2.640    Policy Loss: 8.004    Value Loss: 6.579    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 959927     Buffer Size: 30334      Transition Number: 1499.934k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:55:52,611][train][INFO][train.py>_log] ==> #916000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 6.544    Value Loss: 7.124    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 961084     Buffer Size: 30591      Transition Number: 1499.973k Batch Size: 256        Lr: 0.09000 
[2022-01-16 04:59:14,031][train][INFO][train.py>_log] ==> #917000     Total Loss: 1.249    [weighted Loss:1.249    Policy Loss: 7.976    Value Loss: 6.722    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 962258     Buffer Size: 30796      Transition Number: 1499.992k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:02:36,081][train][INFO][train.py>_log] ==> #918000     Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 6.794    Value Loss: 6.905    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 963414     Buffer Size: 30994      Transition Number: 1499.974k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:05:57,966][train][INFO][train.py>_log] ==> #919000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 7.750    Value Loss: 7.046    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 964486     Buffer Size: 31117      Transition Number: 1500.114k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:09:22,119][train][INFO][train.py>_log] ==> #920000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 7.607    Value Loss: 6.726    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 965544     Buffer Size: 31221      Transition Number: 1499.940k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:12:47,507][train][INFO][train.py>_log] ==> #921000     Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 7.145    Value Loss: 6.351    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 966587     Buffer Size: 31342      Transition Number: 1500.015k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:16:10,676][train][INFO][train.py>_log] ==> #922000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 6.511    Value Loss: 6.954    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 967661     Buffer Size: 31489      Transition Number: 1499.981k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:19:35,635][train][INFO][train.py>_log] ==> #923000     Total Loss: 2.456    [weighted Loss:2.456    Policy Loss: 7.592    Value Loss: 6.512    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 968552     Buffer Size: 31542      Transition Number: 1499.956k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:22:59,651][train][INFO][train.py>_log] ==> #924000     Total Loss: 1.205    [weighted Loss:1.205    Policy Loss: 6.905    Value Loss: 6.819    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 969457     Buffer Size: 31591      Transition Number: 1499.982k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:26:20,558][train][INFO][train.py>_log] ==> #925000     Total Loss: 1.429    [weighted Loss:1.429    Policy Loss: 6.919    Value Loss: 6.556    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 970810     Buffer Size: 32004      Transition Number: 1499.970k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:29:42,452][train][INFO][train.py>_log] ==> #926000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 7.833    Value Loss: 6.768    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 972129     Buffer Size: 32462      Transition Number: 1500.029k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:33:03,427][train][INFO][train.py>_log] ==> #927000     Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 8.210    Value Loss: 7.144    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 973345     Buffer Size: 32817      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:36:23,704][train][INFO][train.py>_log] ==> #928000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 7.253    Value Loss: 7.078    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 974522     Buffer Size: 33142      Transition Number: 1500.003k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:39:47,964][train][INFO][train.py>_log] ==> #929000     Total Loss: 1.396    [weighted Loss:1.396    Policy Loss: 7.996    Value Loss: 6.626    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 975613     Buffer Size: 33223      Transition Number: 1499.989k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:43:10,346][train][INFO][train.py>_log] ==> #930000     Total Loss: 1.845    [weighted Loss:1.845    Policy Loss: 7.644    Value Loss: 6.966    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 976738     Buffer Size: 33286      Transition Number: 1499.996k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:46:32,579][train][INFO][train.py>_log] ==> #931000     Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 8.405    Value Loss: 7.179    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 977854     Buffer Size: 33381      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:49:55,669][train][INFO][train.py>_log] ==> #932000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 7.417    Value Loss: 7.013    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 978956     Buffer Size: 33495      Transition Number: 1499.995k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:53:18,766][train][INFO][train.py>_log] ==> #933000     Total Loss: 3.590    [weighted Loss:3.590    Policy Loss: 8.690    Value Loss: 6.781    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 980150     Buffer Size: 33779      Transition Number: 1499.947k Batch Size: 256        Lr: 0.09000 
[2022-01-16 05:56:38,083][train][INFO][train.py>_log] ==> #934000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 8.184    Value Loss: 7.203    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 981297     Buffer Size: 34035      Transition Number: 1499.947k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:00:01,046][train][INFO][train.py>_log] ==> #935000     Total Loss: 2.335    [weighted Loss:2.335    Policy Loss: 8.741    Value Loss: 7.227    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 983082     Buffer Size: 34174      Transition Number: 1500.024k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:03:23,442][train][INFO][train.py>_log] ==> #936000     Total Loss: 1.712    [weighted Loss:1.712    Policy Loss: 8.816    Value Loss: 6.932    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 984864     Buffer Size: 34116      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:06:44,986][train][INFO][train.py>_log] ==> #937000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 8.930    Value Loss: 7.151    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 986069     Buffer Size: 33762      Transition Number: 1500.095k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:10:07,010][train][INFO][train.py>_log] ==> #938000     Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 8.338    Value Loss: 7.047    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 987315     Buffer Size: 33421      Transition Number: 1500.012k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:13:31,119][train][INFO][train.py>_log] ==> #939000     Total Loss: 3.452    [weighted Loss:3.452    Policy Loss: 8.822    Value Loss: 7.199    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 988603     Buffer Size: 33469      Transition Number: 1500.109k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:16:55,934][train][INFO][train.py>_log] ==> #940000     Total Loss: 3.394    [weighted Loss:3.394    Policy Loss: 8.469    Value Loss: 7.090    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 989886     Buffer Size: 33669      Transition Number: 1499.966k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:20:19,774][train][INFO][train.py>_log] ==> #941000     Total Loss: 3.157    [weighted Loss:3.157    Policy Loss: 8.907    Value Loss: 7.427    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 991306     Buffer Size: 33958      Transition Number: 1499.987k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:23:41,489][train][INFO][train.py>_log] ==> #942000     Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 8.686    Value Loss: 7.391    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 992699     Buffer Size: 34207      Transition Number: 1500.054k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:27:04,179][train][INFO][train.py>_log] ==> #943000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 8.557    Value Loss: 7.376    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 994643     Buffer Size: 34987      Transition Number: 1500.042k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:30:25,541][train][INFO][train.py>_log] ==> #944000     Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 8.120    Value Loss: 7.464    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 996511     Buffer Size: 35697      Transition Number: 1500.047k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:33:49,591][train][INFO][train.py>_log] ==> #945000     Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 8.284    Value Loss: 6.814    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 997723     Buffer Size: 35781      Transition Number: 1499.980k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:37:09,025][train][INFO][train.py>_log] ==> #946000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 8.434    Value Loss: 7.280    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 998948     Buffer Size: 35849      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:40:31,408][train][INFO][train.py>_log] ==> #947000     Total Loss: 3.722    [weighted Loss:3.722    Policy Loss: 8.466    Value Loss: 7.114    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000803    Buffer Size: 36503      Transition Number: 1499.995k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:43:52,712][train][INFO][train.py>_log] ==> #948000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 8.408    Value Loss: 7.304    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002611    Buffer Size: 37187      Transition Number: 1500.163k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:47:12,573][train][INFO][train.py>_log] ==> #949000     Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 8.977    Value Loss: 7.512    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 1003851    Buffer Size: 37422      Transition Number: 1499.943k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:50:30,973][train][INFO][train.py>_log] ==> #950000     Total Loss: 1.895    [weighted Loss:1.895    Policy Loss: 8.089    Value Loss: 7.617    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 1005112    Buffer Size: 37626      Transition Number: 1500.033k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:53:52,289][train][INFO][train.py>_log] ==> #951000     Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 8.241    Value Loss: 7.458    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 1006245    Buffer Size: 37846      Transition Number: 1500.116k Batch Size: 256        Lr: 0.09000 
[2022-01-16 06:57:11,697][train][INFO][train.py>_log] ==> #952000     Total Loss: 2.674    [weighted Loss:2.674    Policy Loss: 7.819    Value Loss: 7.308    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1007380    Buffer Size: 38088      Transition Number: 1500.112k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:00:32,042][train][INFO][train.py>_log] ==> #953000     Total Loss: 3.325    [weighted Loss:3.325    Policy Loss: 7.602    Value Loss: 6.976    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 1008457    Buffer Size: 37982      Transition Number: 1499.954k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:03:49,444][train][INFO][train.py>_log] ==> #954000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 7.940    Value Loss: 7.411    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1009548    Buffer Size: 37775      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:07:10,885][train][INFO][train.py>_log] ==> #955000     Total Loss: 1.300    [weighted Loss:1.300    Policy Loss: 7.604    Value Loss: 7.270    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1010611    Buffer Size: 37588      Transition Number: 1499.984k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:10:31,868][train][INFO][train.py>_log] ==> #956000     Total Loss: 3.773    [weighted Loss:3.773    Policy Loss: 8.638    Value Loss: 7.375    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 1011630    Buffer Size: 37432      Transition Number: 1500.020k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:13:56,415][train][INFO][train.py>_log] ==> #957000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 7.708    Value Loss: 7.611    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013062    Buffer Size: 37693      Transition Number: 1499.970k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:17:17,522][train][INFO][train.py>_log] ==> #958000     Total Loss: 3.243    [weighted Loss:3.243    Policy Loss: 8.539    Value Loss: 7.481    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 1014477    Buffer Size: 37972      Transition Number: 1499.992k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:20:37,130][train][INFO][train.py>_log] ==> #959000     Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 7.737    Value Loss: 7.209    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 1015739    Buffer Size: 38125      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:23:58,105][train][INFO][train.py>_log] ==> #960000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 7.147    Value Loss: 7.428    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1017007    Buffer Size: 38285      Transition Number: 1499.987k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:27:17,387][train][INFO][train.py>_log] ==> #961000     Total Loss: 1.490    [weighted Loss:1.490    Policy Loss: 7.079    Value Loss: 6.592    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 1018223    Buffer Size: 38360      Transition Number: 1500.035k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:30:38,242][train][INFO][train.py>_log] ==> #962000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 7.571    Value Loss: 7.490    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 1019424    Buffer Size: 38385      Transition Number: 1499.974k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:33:59,133][train][INFO][train.py>_log] ==> #963000     Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 7.786    Value Loss: 7.369    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 1020488    Buffer Size: 37922      Transition Number: 1500.035k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:37:20,825][train][INFO][train.py>_log] ==> #964000     Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 7.899    Value Loss: 7.346    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1021558    Buffer Size: 37330      Transition Number: 1500.053k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:40:44,870][train][INFO][train.py>_log] ==> #965000     Total Loss: 1.984    [weighted Loss:1.984    Policy Loss: 8.522    Value Loss: 7.562    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 1022788    Buffer Size: 37110      Transition Number: 1499.995k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:44:08,510][train][INFO][train.py>_log] ==> #966000     Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 8.765    Value Loss: 7.394    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 1024041    Buffer Size: 37096      Transition Number: 1500.042k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:47:30,334][train][INFO][train.py>_log] ==> #967000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 8.417    Value Loss: 7.836    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025570    Buffer Size: 37291      Transition Number: 1500.180k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:50:52,024][train][INFO][train.py>_log] ==> #968000     Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 8.446    Value Loss: 7.331    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 1027100    Buffer Size: 37508      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:54:14,096][train][INFO][train.py>_log] ==> #969000     Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 7.701    Value Loss: 7.460    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 1028818    Buffer Size: 37807      Transition Number: 1500.099k Batch Size: 256        Lr: 0.09000 
[2022-01-16 07:57:34,808][train][INFO][train.py>_log] ==> #970000     Total Loss: 3.084    [weighted Loss:3.084    Policy Loss: 8.773    Value Loss: 7.154    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030480    Buffer Size: 38063      Transition Number: 1499.958k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:00:57,891][train][INFO][train.py>_log] ==> #971000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 8.904    Value Loss: 7.586    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032013    Buffer Size: 37821      Transition Number: 1499.991k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:04:16,939][train][INFO][train.py>_log] ==> #972000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 7.937    Value Loss: 7.406    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 1033577    Buffer Size: 37532      Transition Number: 1500.064k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:07:36,753][train][INFO][train.py>_log] ==> #973000     Total Loss: 2.619    [weighted Loss:2.619    Policy Loss: 8.149    Value Loss: 7.346    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 1034814    Buffer Size: 37404      Transition Number: 1499.990k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:10:56,377][train][INFO][train.py>_log] ==> #974000     Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 7.769    Value Loss: 7.575    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 1036094    Buffer Size: 37473      Transition Number: 1500.114k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:14:16,205][train][INFO][train.py>_log] ==> #975000     Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 8.309    Value Loss: 7.186    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 1037341    Buffer Size: 37202      Transition Number: 1499.972k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:17:38,347][train][INFO][train.py>_log] ==> #976000     Total Loss: 3.855    [weighted Loss:3.855    Policy Loss: 8.385    Value Loss: 7.465    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 1038562    Buffer Size: 36727      Transition Number: 1499.974k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:20:58,353][train][INFO][train.py>_log] ==> #977000     Total Loss: 3.143    [weighted Loss:3.143    Policy Loss: 7.750    Value Loss: 7.528    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 1040022    Buffer Size: 36704      Transition Number: 1500.045k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:24:20,065][train][INFO][train.py>_log] ==> #978000     Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 8.178    Value Loss: 7.529    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1041533    Buffer Size: 36903      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:27:42,627][train][INFO][train.py>_log] ==> #979000     Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 8.014    Value Loss: 7.287    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043191    Buffer Size: 37327      Transition Number: 1499.979k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:31:03,715][train][INFO][train.py>_log] ==> #980000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 8.208    Value Loss: 7.460    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 1044868    Buffer Size: 37810      Transition Number: 1500.056k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:34:22,778][train][INFO][train.py>_log] ==> #981000     Total Loss: 0.983    [weighted Loss:0.983    Policy Loss: 7.888    Value Loss: 7.249    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 1046191    Buffer Size: 38050      Transition Number: 1500.050k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:37:46,738][train][INFO][train.py>_log] ==> #982000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 8.465    Value Loss: 7.427    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 1047564    Buffer Size: 38296      Transition Number: 1499.957k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:41:06,271][train][INFO][train.py>_log] ==> #983000     Total Loss: 3.508    [weighted Loss:3.508    Policy Loss: 8.156    Value Loss: 7.364    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048827    Buffer Size: 38483      Transition Number: 1500.010k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:44:26,764][train][INFO][train.py>_log] ==> #984000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 8.369    Value Loss: 7.458    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 1050103    Buffer Size: 38711      Transition Number: 1500.016k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:47:48,464][train][INFO][train.py>_log] ==> #985000     Total Loss: 3.917    [weighted Loss:3.917    Policy Loss: 9.949    Value Loss: 7.343    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 1051468    Buffer Size: 38798      Transition Number: 1500.039k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:51:08,107][train][INFO][train.py>_log] ==> #986000     Total Loss: 3.527    [weighted Loss:3.527    Policy Loss: 8.722    Value Loss: 7.708    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 1052873    Buffer Size: 38771      Transition Number: 1499.997k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:54:28,019][train][INFO][train.py>_log] ==> #987000     Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 10.215   Value Loss: 7.533    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 1054327    Buffer Size: 38927      Transition Number: 1499.993k Batch Size: 256        Lr: 0.09000 
[2022-01-16 08:57:50,301][train][INFO][train.py>_log] ==> #988000     Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 8.263    Value Loss: 7.680    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 1055810    Buffer Size: 39106      Transition Number: 1499.982k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:01:11,062][train][INFO][train.py>_log] ==> #989000     Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 9.273    Value Loss: 7.292    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 1057451    Buffer Size: 39456      Transition Number: 1500.009k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:04:31,298][train][INFO][train.py>_log] ==> #990000     Total Loss: 2.733    [weighted Loss:2.733    Policy Loss: 10.077   Value Loss: 7.886    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 1059051    Buffer Size: 39852      Transition Number: 1500.069k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:07:50,047][train][INFO][train.py>_log] ==> #991000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 8.854    Value Loss: 7.536    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 1060726    Buffer Size: 40399      Transition Number: 1500.003k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:11:08,460][train][INFO][train.py>_log] ==> #992000     Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 8.143    Value Loss: 7.460    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 1062362    Buffer Size: 40946      Transition Number: 1500.000k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:14:27,874][train][INFO][train.py>_log] ==> #993000     Total Loss: 3.400    [weighted Loss:3.400    Policy Loss: 8.610    Value Loss: 7.372    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063898    Buffer Size: 41274      Transition Number: 1500.080k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:17:46,424][train][INFO][train.py>_log] ==> #994000     Total Loss: 4.064    [weighted Loss:4.064    Policy Loss: 9.268    Value Loss: 7.775    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 1065445    Buffer Size: 41594      Transition Number: 1500.134k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:21:05,800][train][INFO][train.py>_log] ==> #995000     Total Loss: 3.327    [weighted Loss:3.327    Policy Loss: 10.059   Value Loss: 7.274    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 1067116    Buffer Size: 41795      Transition Number: 1499.992k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:24:25,315][train][INFO][train.py>_log] ==> #996000     Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 10.298   Value Loss: 7.766    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 1068731    Buffer Size: 41891      Transition Number: 1500.082k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:27:44,830][train][INFO][train.py>_log] ==> #997000     Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 11.044   Value Loss: 8.040    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1070667    Buffer Size: 42129      Transition Number: 1499.999k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:31:03,062][train][INFO][train.py>_log] ==> #998000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 9.516    Value Loss: 7.614    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 1072552    Buffer Size: 42335      Transition Number: 1499.975k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:34:23,640][train][INFO][train.py>_log] ==> #999000     Total Loss: 4.534    [weighted Loss:4.534    Policy Loss: 9.808    Value Loss: 7.802    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 1074433    Buffer Size: 42582      Transition Number: 1500.018k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:37:42,655][train][INFO][train.py>_log] ==> #1000000    Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 8.220    Value Loss: 7.182    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076296    Buffer Size: 42858      Transition Number: 1500.001k Batch Size: 256        Lr: 0.09000 
[2022-01-16 09:41:02,550][train][INFO][train.py>_log] ==> #1001000    Total Loss: 4.438    [weighted Loss:4.438    Policy Loss: 8.868    Value Loss: 7.143    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 1077790    Buffer Size: 43044      Transition Number: 1499.980k Batch Size: 256        Lr: 0.08100 
[2022-01-16 09:44:23,697][train][INFO][train.py>_log] ==> #1002000    Total Loss: 1.601    [weighted Loss:1.601    Policy Loss: 7.851    Value Loss: 7.992    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 1079310    Buffer Size: 43227      Transition Number: 1499.955k Batch Size: 256        Lr: 0.08100 
[2022-01-16 09:47:42,044][train][INFO][train.py>_log] ==> #1003000    Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 7.931    Value Loss: 7.646    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 1080524    Buffer Size: 43230      Transition Number: 1499.947k Batch Size: 256        Lr: 0.08100 
[2022-01-16 09:50:59,440][train][INFO][train.py>_log] ==> #1004000    Total Loss: 1.740    [weighted Loss:1.740    Policy Loss: 8.591    Value Loss: 7.694    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 1081799    Buffer Size: 43268      Transition Number: 1500.025k Batch Size: 256        Lr: 0.08100 
[2022-01-16 09:54:21,298][train][INFO][train.py>_log] ==> #1005000    Total Loss: 0.897    [weighted Loss:0.897    Policy Loss: 8.872    Value Loss: 7.177    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 1084125    Buffer Size: 44063      Transition Number: 1500.068k Batch Size: 256        Lr: 0.08100 
[2022-01-16 09:57:41,910][train][INFO][train.py>_log] ==> #1006000    Total Loss: 3.713    [weighted Loss:3.713    Policy Loss: 8.919    Value Loss: 7.714    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 1086414    Buffer Size: 44857      Transition Number: 1499.977k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:00:59,929][train][INFO][train.py>_log] ==> #1007000    Total Loss: 3.645    [weighted Loss:3.645    Policy Loss: 7.892    Value Loss: 7.665    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 1088242    Buffer Size: 45067      Transition Number: 1499.942k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:04:18,071][train][INFO][train.py>_log] ==> #1008000    Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 8.534    Value Loss: 7.741    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 1090096    Buffer Size: 45259      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:07:34,562][train][INFO][train.py>_log] ==> #1009000    Total Loss: 3.175    [weighted Loss:3.175    Policy Loss: 7.849    Value Loss: 7.429    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 1091371    Buffer Size: 45239      Transition Number: 1499.963k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:10:53,487][train][INFO][train.py>_log] ==> #1010000    Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 7.781    Value Loss: 7.589    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092641    Buffer Size: 45177      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:14:11,724][train][INFO][train.py>_log] ==> #1011000    Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 8.366    Value Loss: 7.504    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 1093949    Buffer Size: 45243      Transition Number: 1500.005k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:17:31,318][train][INFO][train.py>_log] ==> #1012000    Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 8.024    Value Loss: 7.426    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 1095253    Buffer Size: 45271      Transition Number: 1500.003k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:20:47,857][train][INFO][train.py>_log] ==> #1013000    Total Loss: 3.909    [weighted Loss:3.909    Policy Loss: 8.805    Value Loss: 7.603    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 1096848    Buffer Size: 45544      Transition Number: 1499.946k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:24:08,884][train][INFO][train.py>_log] ==> #1014000    Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 8.235    Value Loss: 7.479    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098520    Buffer Size: 45827      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:27:24,116][train][INFO][train.py>_log] ==> #1015000    Total Loss: 2.330    [weighted Loss:2.330    Policy Loss: 7.690    Value Loss: 7.593    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 1099662    Buffer Size: 45658      Transition Number: 1500.045k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:30:41,917][train][INFO][train.py>_log] ==> #1016000    Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 6.596    Value Loss: 7.417    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100838    Buffer Size: 45457      Transition Number: 1499.971k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:33:57,796][train][INFO][train.py>_log] ==> #1017000    Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 6.631    Value Loss: 6.936    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1101666    Buffer Size: 44908      Transition Number: 1499.987k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:37:17,087][train][INFO][train.py>_log] ==> #1018000    Total Loss: 1.895    [weighted Loss:1.895    Policy Loss: 6.388    Value Loss: 7.288    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 1102541    Buffer Size: 44284      Transition Number: 1499.975k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:40:36,310][train][INFO][train.py>_log] ==> #1019000    Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 7.069    Value Loss: 7.432    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103623    Buffer Size: 43825      Transition Number: 1500.035k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:43:58,877][train][INFO][train.py>_log] ==> #1020000    Total Loss: 0.186    [weighted Loss:0.186    Policy Loss: 6.371    Value Loss: 7.389    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 1104726    Buffer Size: 43352      Transition Number: 1499.997k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:47:16,433][train][INFO][train.py>_log] ==> #1021000    Total Loss: 3.197    [weighted Loss:3.197    Policy Loss: 7.159    Value Loss: 7.413    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 1105904    Buffer Size: 42973      Transition Number: 1499.981k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:50:35,893][train][INFO][train.py>_log] ==> #1022000    Total Loss: 1.767    [weighted Loss:1.767    Policy Loss: 6.902    Value Loss: 6.966    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 1107134    Buffer Size: 42761      Transition Number: 1500.106k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:53:56,779][train][INFO][train.py>_log] ==> #1023000    Total Loss: 1.300    [weighted Loss:1.300    Policy Loss: 7.012    Value Loss: 6.765    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 1108329    Buffer Size: 42423      Transition Number: 1500.017k Batch Size: 256        Lr: 0.08100 
[2022-01-16 10:57:16,422][train][INFO][train.py>_log] ==> #1024000    Total Loss: 2.693    [weighted Loss:2.693    Policy Loss: 6.277    Value Loss: 7.242    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 1109524    Buffer Size: 42008      Transition Number: 1499.985k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:00:38,007][train][INFO][train.py>_log] ==> #1025000    Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 6.248    Value Loss: 7.086    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111575    Buffer Size: 42352      Transition Number: 1500.043k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:04:00,182][train][INFO][train.py>_log] ==> #1026000    Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 7.601    Value Loss: 7.612    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113634    Buffer Size: 42520      Transition Number: 1500.020k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:07:18,698][train][INFO][train.py>_log] ==> #1027000    Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 7.009    Value Loss: 7.184    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 1115070    Buffer Size: 42164      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:10:38,373][train][INFO][train.py>_log] ==> #1028000    Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 6.632    Value Loss: 7.448    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 1116488    Buffer Size: 41862      Transition Number: 1499.987k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:13:59,464][train][INFO][train.py>_log] ==> #1029000    Total Loss: 1.341    [weighted Loss:1.341    Policy Loss: 7.735    Value Loss: 7.292    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117704    Buffer Size: 41358      Transition Number: 1500.016k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:17:19,889][train][INFO][train.py>_log] ==> #1030000    Total Loss: 1.669    [weighted Loss:1.669    Policy Loss: 7.453    Value Loss: 7.381    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 1118956    Buffer Size: 41114      Transition Number: 1500.054k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:20:40,513][train][INFO][train.py>_log] ==> #1031000    Total Loss: 1.643    [weighted Loss:1.643    Policy Loss: 8.077    Value Loss: 7.078    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 1120244    Buffer Size: 40903      Transition Number: 1499.941k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:24:01,697][train][INFO][train.py>_log] ==> #1032000    Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 7.207    Value Loss: 7.013    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 1121531    Buffer Size: 40924      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:27:21,698][train][INFO][train.py>_log] ==> #1033000    Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 8.044    Value Loss: 7.048    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 1122719    Buffer Size: 40863      Transition Number: 1500.009k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:30:40,555][train][INFO][train.py>_log] ==> #1034000    Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 7.029    Value Loss: 7.408    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 1123931    Buffer Size: 39912      Transition Number: 1499.954k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:34:02,203][train][INFO][train.py>_log] ==> #1035000    Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 8.159    Value Loss: 7.071    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 1125027    Buffer Size: 38877      Transition Number: 1499.947k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:37:23,710][train][INFO][train.py>_log] ==> #1036000    Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 7.451    Value Loss: 6.889    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126181    Buffer Size: 38127      Transition Number: 1499.988k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:40:47,171][train][INFO][train.py>_log] ==> #1037000    Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 7.919    Value Loss: 7.215    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 1127970    Buffer Size: 37999      Transition Number: 1499.949k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:44:09,364][train][INFO][train.py>_log] ==> #1038000    Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 9.737    Value Loss: 6.997    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 1129717    Buffer Size: 38327      Transition Number: 1500.057k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:47:32,704][train][INFO][train.py>_log] ==> #1039000    Total Loss: 1.029    [weighted Loss:1.029    Policy Loss: 8.321    Value Loss: 7.211    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 1131704    Buffer Size: 38904      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:50:55,436][train][INFO][train.py>_log] ==> #1040000    Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 9.692    Value Loss: 7.262    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133621    Buffer Size: 39417      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:54:17,048][train][INFO][train.py>_log] ==> #1041000    Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 8.099    Value Loss: 7.610    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135154    Buffer Size: 39567      Transition Number: 1500.054k Batch Size: 256        Lr: 0.08100 
[2022-01-16 11:57:38,866][train][INFO][train.py>_log] ==> #1042000    Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 8.683    Value Loss: 7.584    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 1136729    Buffer Size: 39431      Transition Number: 1499.996k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:01:00,229][train][INFO][train.py>_log] ==> #1043000    Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 8.718    Value Loss: 7.245    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 1137979    Buffer Size: 39125      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:04:24,182][train][INFO][train.py>_log] ==> #1044000    Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 8.961    Value Loss: 7.056    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139258    Buffer Size: 39182      Transition Number: 1499.943k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:07:42,630][train][INFO][train.py>_log] ==> #1045000    Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 9.534    Value Loss: 7.614    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 1140356    Buffer Size: 39199      Transition Number: 1500.110k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:11:02,732][train][INFO][train.py>_log] ==> #1046000    Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 9.098    Value Loss: 7.165    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 1141534    Buffer Size: 39452      Transition Number: 1499.968k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:14:22,564][train][INFO][train.py>_log] ==> #1047000    Total Loss: 3.844    [weighted Loss:3.844    Policy Loss: 10.003   Value Loss: 7.359    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1142910    Buffer Size: 39773      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:17:41,242][train][INFO][train.py>_log] ==> #1048000    Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 8.500    Value Loss: 7.414    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144247    Buffer Size: 39945      Transition Number: 1500.025k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:21:00,191][train][INFO][train.py>_log] ==> #1049000    Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 9.205    Value Loss: 7.142    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 1145585    Buffer Size: 40080      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:24:23,551][train][INFO][train.py>_log] ==> #1050000    Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 8.648    Value Loss: 7.444    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147011    Buffer Size: 40216      Transition Number: 1499.962k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:27:46,669][train][INFO][train.py>_log] ==> #1051000    Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 8.354    Value Loss: 6.870    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 1148329    Buffer Size: 40310      Transition Number: 1499.964k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:31:06,377][train][INFO][train.py>_log] ==> #1052000    Total Loss: 3.483    [weighted Loss:3.483    Policy Loss: 8.426    Value Loss: 7.864    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 1149630    Buffer Size: 40424      Transition Number: 1500.020k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:34:29,242][train][INFO][train.py>_log] ==> #1053000    Total Loss: 2.960    [weighted Loss:2.960    Policy Loss: 8.390    Value Loss: 7.380    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1151168    Buffer Size: 40134      Transition Number: 1500.004k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:37:54,307][train][INFO][train.py>_log] ==> #1054000    Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 8.847    Value Loss: 7.828    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152754    Buffer Size: 39581      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:41:16,516][train][INFO][train.py>_log] ==> #1055000    Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 8.472    Value Loss: 7.478    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 1154553    Buffer Size: 39700      Transition Number: 1500.024k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:44:36,691][train][INFO][train.py>_log] ==> #1056000    Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 8.994    Value Loss: 7.727    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 1156321    Buffer Size: 39928      Transition Number: 1500.045k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:47:59,417][train][INFO][train.py>_log] ==> #1057000    Total Loss: 3.243    [weighted Loss:3.243    Policy Loss: 8.160    Value Loss: 7.178    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 1158089    Buffer Size: 40383      Transition Number: 1499.999k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:51:17,927][train][INFO][train.py>_log] ==> #1058000    Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 8.620    Value Loss: 7.064    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 1159876    Buffer Size: 40889      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:54:38,985][train][INFO][train.py>_log] ==> #1059000    Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 8.024    Value Loss: 7.176    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 1161738    Buffer Size: 41428      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 12:57:58,507][train][INFO][train.py>_log] ==> #1060000    Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 8.788    Value Loss: 7.539    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1163599    Buffer Size: 41970      Transition Number: 1499.990k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:01:18,152][train][INFO][train.py>_log] ==> #1061000    Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 8.444    Value Loss: 7.673    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1165233    Buffer Size: 42373      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:04:36,384][train][INFO][train.py>_log] ==> #1062000    Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 7.963    Value Loss: 7.943    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 1166909    Buffer Size: 42800      Transition Number: 1500.007k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:07:55,228][train][INFO][train.py>_log] ==> #1063000    Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 9.049    Value Loss: 7.523    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 1168157    Buffer Size: 42925      Transition Number: 1499.983k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:11:17,016][train][INFO][train.py>_log] ==> #1064000    Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 7.814    Value Loss: 8.075    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 1169344    Buffer Size: 42939      Transition Number: 1500.039k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:14:37,663][train][INFO][train.py>_log] ==> #1065000    Total Loss: 0.960    [weighted Loss:0.960    Policy Loss: 8.692    Value Loss: 7.602    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 1170533    Buffer Size: 42366      Transition Number: 1500.091k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:17:57,176][train][INFO][train.py>_log] ==> #1066000    Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 7.611    Value Loss: 7.392    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1171651    Buffer Size: 41824      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:21:16,482][train][INFO][train.py>_log] ==> #1067000    Total Loss: 2.830    [weighted Loss:2.830    Policy Loss: 9.155    Value Loss: 7.555    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 1172766    Buffer Size: 41119      Transition Number: 1499.986k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:24:38,962][train][INFO][train.py>_log] ==> #1068000    Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 7.580    Value Loss: 7.774    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 1173938    Buffer Size: 40427      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:27:58,600][train][INFO][train.py>_log] ==> #1069000    Total Loss: 2.614    [weighted Loss:2.614    Policy Loss: 9.898    Value Loss: 7.679    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 1175099    Buffer Size: 40087      Transition Number: 1500.047k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:31:18,170][train][INFO][train.py>_log] ==> #1070000    Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 8.169    Value Loss: 7.422    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 1176282    Buffer Size: 39767      Transition Number: 1499.986k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:34:43,696][train][INFO][train.py>_log] ==> #1071000    Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 9.033    Value Loss: 7.277    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 1178672    Buffer Size: 40726      Transition Number: 1499.960k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:38:05,996][train][INFO][train.py>_log] ==> #1072000    Total Loss: 3.500    [weighted Loss:3.500    Policy Loss: 8.339    Value Loss: 7.509    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 1180967    Buffer Size: 41696      Transition Number: 1500.073k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:41:25,763][train][INFO][train.py>_log] ==> #1073000    Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 9.129    Value Loss: 7.995    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 1182600    Buffer Size: 42196      Transition Number: 1500.017k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:44:42,737][train][INFO][train.py>_log] ==> #1074000    Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 8.562    Value Loss: 7.636    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 1184237    Buffer Size: 42663      Transition Number: 1500.067k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:48:03,370][train][INFO][train.py>_log] ==> #1075000    Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 7.859    Value Loss: 7.730    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1185568    Buffer Size: 42675      Transition Number: 1499.970k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:51:23,215][train][INFO][train.py>_log] ==> #1076000    Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 8.991    Value Loss: 7.639    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1186863    Buffer Size: 42678      Transition Number: 1500.008k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:54:45,967][train][INFO][train.py>_log] ==> #1077000    Total Loss: 3.794    [weighted Loss:3.794    Policy Loss: 8.862    Value Loss: 7.306    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 1188224    Buffer Size: 42678      Transition Number: 1499.935k Batch Size: 256        Lr: 0.08100 
[2022-01-16 13:58:02,513][train][INFO][train.py>_log] ==> #1078000    Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 8.046    Value Loss: 7.427    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1189557    Buffer Size: 42647      Transition Number: 1499.972k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:01:22,999][train][INFO][train.py>_log] ==> #1079000    Total Loss: 4.083    [weighted Loss:4.083    Policy Loss: 9.044    Value Loss: 7.337    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 1190946    Buffer Size: 42697      Transition Number: 1500.037k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:04:40,449][train][INFO][train.py>_log] ==> #1080000    Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 8.031    Value Loss: 7.699    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 1192318    Buffer Size: 42792      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:08:00,206][train][INFO][train.py>_log] ==> #1081000    Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 8.684    Value Loss: 7.266    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1193560    Buffer Size: 42598      Transition Number: 1500.166k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:11:22,322][train][INFO][train.py>_log] ==> #1082000    Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 8.098    Value Loss: 7.755    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1194841    Buffer Size: 42341      Transition Number: 1499.964k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:14:46,586][train][INFO][train.py>_log] ==> #1083000    Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 9.584    Value Loss: 7.592    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 1196135    Buffer Size: 41921      Transition Number: 1500.016k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:18:08,264][train][INFO][train.py>_log] ==> #1084000    Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 7.586    Value Loss: 7.312    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 1197360    Buffer Size: 41474      Transition Number: 1499.990k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:21:28,454][train][INFO][train.py>_log] ==> #1085000    Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 9.188    Value Loss: 7.252    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 1198574    Buffer Size: 41016      Transition Number: 1500.020k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:24:50,058][train][INFO][train.py>_log] ==> #1086000    Total Loss: 1.784    [weighted Loss:1.784    Policy Loss: 8.185    Value Loss: 7.306    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 1199843    Buffer Size: 40551      Transition Number: 1500.042k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:28:12,895][train][INFO][train.py>_log] ==> #1087000    Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 9.051    Value Loss: 7.798    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 1201523    Buffer Size: 40349      Transition Number: 1500.023k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:31:35,793][train][INFO][train.py>_log] ==> #1088000    Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 8.894    Value Loss: 7.324    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 1203193    Buffer Size: 40147      Transition Number: 1500.023k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:35:00,974][train][INFO][train.py>_log] ==> #1089000    Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 9.225    Value Loss: 7.398    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 1205614    Buffer Size: 40701      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:38:23,721][train][INFO][train.py>_log] ==> #1090000    Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 8.767    Value Loss: 7.811    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1208027    Buffer Size: 41392      Transition Number: 1500.033k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:41:43,958][train][INFO][train.py>_log] ==> #1091000    Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 9.027    Value Loss: 7.561    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 1209780    Buffer Size: 41801      Transition Number: 1500.041k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:45:04,242][train][INFO][train.py>_log] ==> #1092000    Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 9.342    Value Loss: 7.741    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 1211597    Buffer Size: 42357      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:48:23,438][train][INFO][train.py>_log] ==> #1093000    Total Loss: 1.443    [weighted Loss:1.443    Policy Loss: 9.036    Value Loss: 7.890    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 1213155    Buffer Size: 42747      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:51:41,750][train][INFO][train.py>_log] ==> #1094000    Total Loss: 2.222    [weighted Loss:2.222    Policy Loss: 8.019    Value Loss: 7.880    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 1214661    Buffer Size: 43111      Transition Number: 1500.029k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:55:01,559][train][INFO][train.py>_log] ==> #1095000    Total Loss: 3.790    [weighted Loss:3.790    Policy Loss: 8.599    Value Loss: 7.140    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 1215810    Buffer Size: 43177      Transition Number: 1500.087k Batch Size: 256        Lr: 0.08100 
[2022-01-16 14:58:22,026][train][INFO][train.py>_log] ==> #1096000    Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 8.383    Value Loss: 7.428    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216989    Buffer Size: 43205      Transition Number: 1500.054k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:01:41,620][train][INFO][train.py>_log] ==> #1097000    Total Loss: 4.430    [weighted Loss:4.430    Policy Loss: 9.912    Value Loss: 7.662    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218249    Buffer Size: 43255      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:05:03,024][train][INFO][train.py>_log] ==> #1098000    Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 9.175    Value Loss: 7.630    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 1219554    Buffer Size: 43333      Transition Number: 1499.986k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:08:22,851][train][INFO][train.py>_log] ==> #1099000    Total Loss: 2.985    [weighted Loss:2.985    Policy Loss: 8.987    Value Loss: 6.915    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 1220774    Buffer Size: 42499      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:11:45,469][train][INFO][train.py>_log] ==> #1100000    Total Loss: 3.250    [weighted Loss:3.250    Policy Loss: 7.467    Value Loss: 7.417    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 1222037    Buffer Size: 41514      Transition Number: 1500.050k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:15:08,611][train][INFO][train.py>_log] ==> #1101000    Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 8.977    Value Loss: 7.129    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223561    Buffer Size: 41206      Transition Number: 1499.972k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:18:28,332][train][INFO][train.py>_log] ==> #1102000    Total Loss: 2.613    [weighted Loss:2.613    Policy Loss: 9.101    Value Loss: 7.432    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225014    Buffer Size: 41058      Transition Number: 1499.942k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:21:49,387][train][INFO][train.py>_log] ==> #1103000    Total Loss: 3.104    [weighted Loss:3.104    Policy Loss: 8.712    Value Loss: 7.309    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 1226948    Buffer Size: 41521      Transition Number: 1499.992k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:25:10,977][train][INFO][train.py>_log] ==> #1104000    Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 8.967    Value Loss: 7.439    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 1228923    Buffer Size: 42119      Transition Number: 1499.962k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:28:29,981][train][INFO][train.py>_log] ==> #1105000    Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 8.211    Value Loss: 7.324    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 1230461    Buffer Size: 42324      Transition Number: 1499.999k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:31:50,356][train][INFO][train.py>_log] ==> #1106000    Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 8.450    Value Loss: 7.360    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 1232022    Buffer Size: 42530      Transition Number: 1500.021k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:35:11,717][train][INFO][train.py>_log] ==> #1107000    Total Loss: 3.663    [weighted Loss:3.663    Policy Loss: 9.876    Value Loss: 7.798    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 1233473    Buffer Size: 42578      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:38:31,350][train][INFO][train.py>_log] ==> #1108000    Total Loss: 3.928    [weighted Loss:3.928    Policy Loss: 8.453    Value Loss: 7.470    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 1234846    Buffer Size: 42603      Transition Number: 1499.953k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:41:52,476][train][INFO][train.py>_log] ==> #1109000    Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 8.238    Value Loss: 7.253    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236626    Buffer Size: 43046      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:45:13,220][train][INFO][train.py>_log] ==> #1110000    Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 9.108    Value Loss: 6.934    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 1238443    Buffer Size: 43555      Transition Number: 1499.978k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:48:32,706][train][INFO][train.py>_log] ==> #1111000    Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 8.399    Value Loss: 7.488    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 1239958    Buffer Size: 43819      Transition Number: 1499.987k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:51:53,365][train][INFO][train.py>_log] ==> #1112000    Total Loss: 3.495    [weighted Loss:3.495    Policy Loss: 8.628    Value Loss: 7.518    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241581    Buffer Size: 44164      Transition Number: 1500.040k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:55:14,300][train][INFO][train.py>_log] ==> #1113000    Total Loss: 2.830    [weighted Loss:2.830    Policy Loss: 8.893    Value Loss: 7.539    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 1242826    Buffer Size: 44200      Transition Number: 1499.998k Batch Size: 256        Lr: 0.08100 
[2022-01-16 15:58:32,656][train][INFO][train.py>_log] ==> #1114000    Total Loss: 3.465    [weighted Loss:3.465    Policy Loss: 9.110    Value Loss: 7.489    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 1244067    Buffer Size: 44218      Transition Number: 1500.197k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:01:54,728][train][INFO][train.py>_log] ==> #1115000    Total Loss: 3.166    [weighted Loss:3.166    Policy Loss: 9.013    Value Loss: 7.112    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 1245828    Buffer Size: 44328      Transition Number: 1500.109k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:05:14,720][train][INFO][train.py>_log] ==> #1116000    Total Loss: 2.707    [weighted Loss:2.707    Policy Loss: 7.923    Value Loss: 7.352    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1247626    Buffer Size: 44456      Transition Number: 1499.999k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:08:32,340][train][INFO][train.py>_log] ==> #1117000    Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 8.521    Value Loss: 7.309    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 1249324    Buffer Size: 43980      Transition Number: 1499.979k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:11:54,443][train][INFO][train.py>_log] ==> #1118000    Total Loss: 3.556    [weighted Loss:3.556    Policy Loss: 8.292    Value Loss: 7.378    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1251052    Buffer Size: 43393      Transition Number: 1499.974k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:15:15,367][train][INFO][train.py>_log] ==> #1119000    Total Loss: 3.285    [weighted Loss:3.285    Policy Loss: 8.661    Value Loss: 7.419    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252450    Buffer Size: 42931      Transition Number: 1499.958k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:18:36,237][train][INFO][train.py>_log] ==> #1120000    Total Loss: 1.452    [weighted Loss:1.452    Policy Loss: 9.049    Value Loss: 7.594    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 1253843    Buffer Size: 42576      Transition Number: 1499.944k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:21:57,865][train][INFO][train.py>_log] ==> #1121000    Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 8.658    Value Loss: 7.585    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 1255391    Buffer Size: 42500      Transition Number: 1499.999k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:25:17,794][train][INFO][train.py>_log] ==> #1122000    Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 8.859    Value Loss: 7.429    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 1257009    Buffer Size: 42571      Transition Number: 1499.978k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:28:38,416][train][INFO][train.py>_log] ==> #1123000    Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 7.817    Value Loss: 7.450    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 1258592    Buffer Size: 42892      Transition Number: 1499.939k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:31:58,556][train][INFO][train.py>_log] ==> #1124000    Total Loss: 3.888    [weighted Loss:3.888    Policy Loss: 9.797    Value Loss: 7.554    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 1260212    Buffer Size: 43325      Transition Number: 1499.977k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:35:18,648][train][INFO][train.py>_log] ==> #1125000    Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 8.009    Value Loss: 7.307    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 1262925    Buffer Size: 44691      Transition Number: 1500.023k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:38:38,392][train][INFO][train.py>_log] ==> #1126000    Total Loss: 1.403    [weighted Loss:1.403    Policy Loss: 8.054    Value Loss: 7.194    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1265764    Buffer Size: 46170      Transition Number: 1500.044k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:41:53,302][train][INFO][train.py>_log] ==> #1127000    Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 7.714    Value Loss: 7.356    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 1267247    Buffer Size: 46481      Transition Number: 1499.962k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:45:13,347][train][INFO][train.py>_log] ==> #1128000    Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 8.491    Value Loss: 7.492    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 1268747    Buffer Size: 46744      Transition Number: 1500.023k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:48:31,825][train][INFO][train.py>_log] ==> #1129000    Total Loss: 1.990    [weighted Loss:1.990    Policy Loss: 8.167    Value Loss: 7.449    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 1269786    Buffer Size: 46381      Transition Number: 1499.977k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:51:51,268][train][INFO][train.py>_log] ==> #1130000    Total Loss: 1.580    [weighted Loss:1.580    Policy Loss: 8.049    Value Loss: 7.926    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 1270802    Buffer Size: 45954      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:55:11,028][train][INFO][train.py>_log] ==> #1131000    Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 7.567    Value Loss: 7.178    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 1272273    Buffer Size: 45639      Transition Number: 1500.007k Batch Size: 256        Lr: 0.08100 
[2022-01-16 16:58:29,916][train][INFO][train.py>_log] ==> #1132000    Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 7.415    Value Loss: 7.406    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 1273742    Buffer Size: 45248      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:01:51,203][train][INFO][train.py>_log] ==> #1133000    Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 8.092    Value Loss: 7.228    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 1276640    Buffer Size: 46450      Transition Number: 1500.107k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:05:13,857][train][INFO][train.py>_log] ==> #1134000    Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 8.169    Value Loss: 7.318    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 1279677    Buffer Size: 47871      Transition Number: 1499.977k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:08:29,952][train][INFO][train.py>_log] ==> #1135000    Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 7.766    Value Loss: 7.309    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 1281504    Buffer Size: 48304      Transition Number: 1500.028k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:11:49,504][train][INFO][train.py>_log] ==> #1136000    Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 8.282    Value Loss: 7.298    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1283326    Buffer Size: 48673      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:15:09,307][train][INFO][train.py>_log] ==> #1137000    Total Loss: 3.811    [weighted Loss:3.811    Policy Loss: 8.546    Value Loss: 7.452    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1284612    Buffer Size: 48401      Transition Number: 1500.031k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:18:27,070][train][INFO][train.py>_log] ==> #1138000    Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 7.848    Value Loss: 7.415    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 1285925    Buffer Size: 47982      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:21:47,914][train][INFO][train.py>_log] ==> #1139000    Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 8.229    Value Loss: 7.430    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 1287177    Buffer Size: 47630      Transition Number: 1499.988k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:25:07,219][train][INFO][train.py>_log] ==> #1140000    Total Loss: 2.137    [weighted Loss:2.137    Policy Loss: 8.350    Value Loss: 7.393    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 1288389    Buffer Size: 47320      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:28:26,267][train][INFO][train.py>_log] ==> #1141000    Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 8.279    Value Loss: 7.408    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 1290153    Buffer Size: 47632      Transition Number: 1500.007k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:31:46,295][train][INFO][train.py>_log] ==> #1142000    Total Loss: 3.587    [weighted Loss:3.587    Policy Loss: 8.563    Value Loss: 7.452    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1291943    Buffer Size: 48099      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:35:05,044][train][INFO][train.py>_log] ==> #1143000    Total Loss: 2.320    [weighted Loss:2.320    Policy Loss: 7.834    Value Loss: 7.392    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 1293606    Buffer Size: 48145      Transition Number: 1499.964k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:38:23,916][train][INFO][train.py>_log] ==> #1144000    Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 8.504    Value Loss: 7.320    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 1295242    Buffer Size: 48050      Transition Number: 1500.022k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:41:42,526][train][INFO][train.py>_log] ==> #1145000    Total Loss: 2.728    [weighted Loss:2.728    Policy Loss: 8.402    Value Loss: 7.486    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 1296626    Buffer Size: 47715      Transition Number: 1499.985k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:45:05,625][train][INFO][train.py>_log] ==> #1146000    Total Loss: 3.969    [weighted Loss:3.969    Policy Loss: 8.234    Value Loss: 7.179    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 1298000    Buffer Size: 47407      Transition Number: 1499.958k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:48:23,796][train][INFO][train.py>_log] ==> #1147000    Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 8.184    Value Loss: 7.664    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299384    Buffer Size: 47280      Transition Number: 1500.022k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:51:44,223][train][INFO][train.py>_log] ==> #1148000    Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 7.797    Value Loss: 7.521    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1300778    Buffer Size: 47291      Transition Number: 1500.055k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:55:04,061][train][INFO][train.py>_log] ==> #1149000    Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 7.136    Value Loss: 7.214    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 1302141    Buffer Size: 47156      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-16 17:58:24,386][train][INFO][train.py>_log] ==> #1150000    Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 8.632    Value Loss: 7.838    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 1303531    Buffer Size: 46950      Transition Number: 1499.980k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:01:44,993][train][INFO][train.py>_log] ==> #1151000    Total Loss: 0.352    [weighted Loss:0.352    Policy Loss: 8.004    Value Loss: 7.422    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304900    Buffer Size: 46779      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:05:03,308][train][INFO][train.py>_log] ==> #1152000    Total Loss: 3.309    [weighted Loss:3.309    Policy Loss: 7.693    Value Loss: 7.408    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 1306238    Buffer Size: 46509      Transition Number: 1500.108k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:08:20,342][train][INFO][train.py>_log] ==> #1153000    Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 7.531    Value Loss: 7.126    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 1307391    Buffer Size: 45523      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:11:43,699][train][INFO][train.py>_log] ==> #1154000    Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 7.071    Value Loss: 7.586    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 1308634    Buffer Size: 44081      Transition Number: 1499.994k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:15:04,370][train][INFO][train.py>_log] ==> #1155000    Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 7.955    Value Loss: 7.336    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 1309639    Buffer Size: 43075      Transition Number: 1499.985k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:18:24,749][train][INFO][train.py>_log] ==> #1156000    Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 7.118    Value Loss: 7.570    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 1310654    Buffer Size: 42586      Transition Number: 1499.996k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:21:46,091][train][INFO][train.py>_log] ==> #1157000    Total Loss: 2.220    [weighted Loss:2.220    Policy Loss: 8.072    Value Loss: 7.275    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 1311767    Buffer Size: 42431      Transition Number: 1500.025k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:25:06,989][train][INFO][train.py>_log] ==> #1158000    Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 8.129    Value Loss: 7.211    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1312852    Buffer Size: 42483      Transition Number: 1499.942k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:28:30,809][train][INFO][train.py>_log] ==> #1159000    Total Loss: 3.338    [weighted Loss:3.338    Policy Loss: 8.567    Value Loss: 7.117    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 1314045    Buffer Size: 42377      Transition Number: 1499.957k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:31:51,847][train][INFO][train.py>_log] ==> #1160000    Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 7.970    Value Loss: 7.396    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 1315206    Buffer Size: 42047      Transition Number: 1500.058k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:35:11,677][train][INFO][train.py>_log] ==> #1161000    Total Loss: 1.987    [weighted Loss:1.987    Policy Loss: 8.388    Value Loss: 7.278    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 1316445    Buffer Size: 41177      Transition Number: 1500.006k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:38:32,519][train][INFO][train.py>_log] ==> #1162000    Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 8.977    Value Loss: 7.000    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 1317687    Buffer Size: 39570      Transition Number: 1499.969k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:41:57,828][train][INFO][train.py>_log] ==> #1163000    Total Loss: 3.845    [weighted Loss:3.845    Policy Loss: 8.444    Value Loss: 7.238    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 1320833    Buffer Size: 39920      Transition Number: 1499.992k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:45:26,333][train][INFO][train.py>_log] ==> #1164000    Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 10.846   Value Loss: 7.369    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1323960    Buffer Size: 41093      Transition Number: 1499.999k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:48:48,145][train][INFO][train.py>_log] ==> #1165000    Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 10.352   Value Loss: 7.967    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 1327044    Buffer Size: 42611      Transition Number: 1500.011k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:52:08,570][train][INFO][train.py>_log] ==> #1166000    Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 8.560    Value Loss: 7.344    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 1330135    Buffer Size: 44262      Transition Number: 1500.019k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:55:28,863][train][INFO][train.py>_log] ==> #1167000    Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 8.816    Value Loss: 7.623    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1331730    Buffer Size: 44624      Transition Number: 1500.105k Batch Size: 256        Lr: 0.08100 
[2022-01-16 18:58:48,515][train][INFO][train.py>_log] ==> #1168000    Total Loss: 2.826    [weighted Loss:2.826    Policy Loss: 8.424    Value Loss: 7.401    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 1333350    Buffer Size: 44974      Transition Number: 1499.962k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:02:07,023][train][INFO][train.py>_log] ==> #1169000    Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 7.245    Value Loss: 7.421    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 1334906    Buffer Size: 44825      Transition Number: 1499.970k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:05:29,294][train][INFO][train.py>_log] ==> #1170000    Total Loss: 3.377    [weighted Loss:3.377    Policy Loss: 9.251    Value Loss: 7.366    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1336532    Buffer Size: 44653      Transition Number: 1500.021k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:08:51,994][train][INFO][train.py>_log] ==> #1171000    Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 7.683    Value Loss: 7.260    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 1338640    Buffer Size: 44976      Transition Number: 1499.970k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:12:14,420][train][INFO][train.py>_log] ==> #1172000    Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 8.095    Value Loss: 7.662    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1340738    Buffer Size: 45349      Transition Number: 1499.980k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:15:37,384][train][INFO][train.py>_log] ==> #1173000    Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 7.103    Value Loss: 7.411    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 1342196    Buffer Size: 45428      Transition Number: 1500.090k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:18:54,614][train][INFO][train.py>_log] ==> #1174000    Total Loss: 1.443    [weighted Loss:1.443    Policy Loss: 7.971    Value Loss: 7.560    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 1343643    Buffer Size: 45500      Transition Number: 1500.200k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:22:14,542][train][INFO][train.py>_log] ==> #1175000    Total Loss: 3.593    [weighted Loss:3.593    Policy Loss: 8.030    Value Loss: 7.861    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 1344971    Buffer Size: 45468      Transition Number: 1500.027k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:25:34,410][train][INFO][train.py>_log] ==> #1176000    Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 8.572    Value Loss: 7.353    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 1346291    Buffer Size: 45426      Transition Number: 1499.944k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:28:54,715][train][INFO][train.py>_log] ==> #1177000    Total Loss: 0.970    [weighted Loss:0.970    Policy Loss: 7.635    Value Loss: 7.195    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 1347613    Buffer Size: 45393      Transition Number: 1499.985k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:32:15,974][train][INFO][train.py>_log] ==> #1178000    Total Loss: 1.615    [weighted Loss:1.615    Policy Loss: 8.505    Value Loss: 7.576    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 1349009    Buffer Size: 45398      Transition Number: 1499.983k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:35:37,887][train][INFO][train.py>_log] ==> #1179000    Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 8.398    Value Loss: 7.362    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350649    Buffer Size: 45606      Transition Number: 1500.111k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:38:57,478][train][INFO][train.py>_log] ==> #1180000    Total Loss: 2.632    [weighted Loss:2.632    Policy Loss: 8.560    Value Loss: 7.324    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 1352255    Buffer Size: 45848      Transition Number: 1499.965k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:42:16,835][train][INFO][train.py>_log] ==> #1181000    Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 8.094    Value Loss: 7.367    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1353641    Buffer Size: 46064      Transition Number: 1500.050k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:45:35,801][train][INFO][train.py>_log] ==> #1182000    Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 7.924    Value Loss: 7.274    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 1355043    Buffer Size: 46269      Transition Number: 1500.008k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:48:51,524][train][INFO][train.py>_log] ==> #1183000    Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 6.789    Value Loss: 7.391    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1356278    Buffer Size: 46504      Transition Number: 1499.965k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:52:08,118][train][INFO][train.py>_log] ==> #1184000    Total Loss: 3.467    [weighted Loss:3.467    Policy Loss: 8.065    Value Loss: 7.376    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 1357472    Buffer Size: 46692      Transition Number: 1499.977k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:55:28,213][train][INFO][train.py>_log] ==> #1185000    Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 7.138    Value Loss: 7.463    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 1358651    Buffer Size: 46777      Transition Number: 1499.987k Batch Size: 256        Lr: 0.08100 
[2022-01-16 19:58:49,219][train][INFO][train.py>_log] ==> #1186000    Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 7.546    Value Loss: 7.342    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 1359834    Buffer Size: 46840      Transition Number: 1499.986k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:02:07,023][train][INFO][train.py>_log] ==> #1187000    Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 6.905    Value Loss: 6.939    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 1360922    Buffer Size: 46761      Transition Number: 1499.997k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:05:29,111][train][INFO][train.py>_log] ==> #1188000    Total Loss: 3.002    [weighted Loss:3.002    Policy Loss: 6.374    Value Loss: 7.272    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 1362045    Buffer Size: 46694      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:08:48,094][train][INFO][train.py>_log] ==> #1189000    Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 7.255    Value Loss: 7.211    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 1363083    Buffer Size: 46499      Transition Number: 1499.999k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:12:08,607][train][INFO][train.py>_log] ==> #1190000    Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 8.328    Value Loss: 7.200    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1364144    Buffer Size: 46280      Transition Number: 1500.216k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:15:32,376][train][INFO][train.py>_log] ==> #1191000    Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 7.647    Value Loss: 7.566    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1365322    Buffer Size: 44670      Transition Number: 1499.983k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:18:52,671][train][INFO][train.py>_log] ==> #1192000    Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 8.173    Value Loss: 7.269    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 1366447    Buffer Size: 42998      Transition Number: 1500.012k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:22:18,200][train][INFO][train.py>_log] ==> #1193000    Total Loss: 1.433    [weighted Loss:1.433    Policy Loss: 8.536    Value Loss: 7.271    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 1367755    Buffer Size: 41371      Transition Number: 1499.985k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:25:43,749][train][INFO][train.py>_log] ==> #1194000    Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 7.783    Value Loss: 7.427    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 1369023    Buffer Size: 39782      Transition Number: 1499.986k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:29:07,270][train][INFO][train.py>_log] ==> #1195000    Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 9.310    Value Loss: 7.183    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370716    Buffer Size: 39373      Transition Number: 1500.075k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:32:27,162][train][INFO][train.py>_log] ==> #1196000    Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 8.244    Value Loss: 7.332    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1372367    Buffer Size: 39426      Transition Number: 1500.098k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:35:51,404][train][INFO][train.py>_log] ==> #1197000    Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 8.235    Value Loss: 7.352    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373869    Buffer Size: 39309      Transition Number: 1499.972k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:39:13,100][train][INFO][train.py>_log] ==> #1198000    Total Loss: 1.623    [weighted Loss:1.623    Policy Loss: 7.584    Value Loss: 7.293    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375339    Buffer Size: 39203      Transition Number: 1500.048k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:42:35,172][train][INFO][train.py>_log] ==> #1199000    Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 9.292    Value Loss: 7.595    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 1376782    Buffer Size: 38746      Transition Number: 1499.992k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:45:56,244][train][INFO][train.py>_log] ==> #1200000    Total Loss: 3.270    [weighted Loss:3.270    Policy Loss: 9.769    Value Loss: 7.249    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 1378178    Buffer Size: 38111      Transition Number: 1500.110k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:49:17,006][train][INFO][train.py>_log] ==> #1201000    Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 7.983    Value Loss: 7.219    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1379802    Buffer Size: 38094      Transition Number: 1500.015k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:52:39,641][train][INFO][train.py>_log] ==> #1202000    Total Loss: 1.677    [weighted Loss:1.677    Policy Loss: 9.693    Value Loss: 7.290    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 1381538    Buffer Size: 38355      Transition Number: 1500.053k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:56:00,738][train][INFO][train.py>_log] ==> #1203000    Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 9.234    Value Loss: 7.290    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 1383672    Buffer Size: 39010      Transition Number: 1499.992k Batch Size: 256        Lr: 0.08100 
[2022-01-16 20:59:23,881][train][INFO][train.py>_log] ==> #1204000    Total Loss: 1.636    [weighted Loss:1.636    Policy Loss: 9.234    Value Loss: 7.520    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 1385820    Buffer Size: 39740      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:02:43,385][train][INFO][train.py>_log] ==> #1205000    Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 8.853    Value Loss: 7.692    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 1387346    Buffer Size: 39929      Transition Number: 1499.957k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:06:02,707][train][INFO][train.py>_log] ==> #1206000    Total Loss: 1.257    [weighted Loss:1.257    Policy Loss: 9.061    Value Loss: 7.302    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 1388880    Buffer Size: 40047      Transition Number: 1500.018k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:09:29,303][train][INFO][train.py>_log] ==> #1207000    Total Loss: 2.796    [weighted Loss:2.796    Policy Loss: 7.730    Value Loss: 7.168    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 1391380    Buffer Size: 40817      Transition Number: 1500.063k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:12:52,593][train][INFO][train.py>_log] ==> #1208000    Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 8.655    Value Loss: 7.378    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 1393793    Buffer Size: 41521      Transition Number: 1499.974k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:16:14,124][train][INFO][train.py>_log] ==> #1209000    Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 8.231    Value Loss: 7.731    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 1395536    Buffer Size: 41847      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:19:33,547][train][INFO][train.py>_log] ==> #1210000    Total Loss: 1.179    [weighted Loss:1.179    Policy Loss: 7.657    Value Loss: 7.038    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 1397224    Buffer Size: 42126      Transition Number: 1499.968k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:22:52,206][train][INFO][train.py>_log] ==> #1211000    Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 7.137    Value Loss: 7.404    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 1398400    Buffer Size: 42063      Transition Number: 1500.034k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:26:13,551][train][INFO][train.py>_log] ==> #1212000    Total Loss: 1.184    [weighted Loss:1.184    Policy Loss: 7.988    Value Loss: 7.358    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 1399605    Buffer Size: 42027      Transition Number: 1499.939k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:29:32,858][train][INFO][train.py>_log] ==> #1213000    Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 9.006    Value Loss: 7.226    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 1400692    Buffer Size: 41968      Transition Number: 1499.978k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:32:53,445][train][INFO][train.py>_log] ==> #1214000    Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 8.334    Value Loss: 7.471    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 1401836    Buffer Size: 41939      Transition Number: 1500.070k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:36:13,617][train][INFO][train.py>_log] ==> #1215000    Total Loss: 1.990    [weighted Loss:1.990    Policy Loss: 8.015    Value Loss: 7.368    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 1403022    Buffer Size: 42007      Transition Number: 1499.966k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:39:35,048][train][INFO][train.py>_log] ==> #1216000    Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 9.027    Value Loss: 7.819    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 1404178    Buffer Size: 42066      Transition Number: 1500.031k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:42:57,841][train][INFO][train.py>_log] ==> #1217000    Total Loss: 1.990    [weighted Loss:1.990    Policy Loss: 7.877    Value Loss: 7.210    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 1405585    Buffer Size: 42337      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:46:18,295][train][INFO][train.py>_log] ==> #1218000    Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 8.340    Value Loss: 7.016    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406985    Buffer Size: 42618      Transition Number: 1500.096k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:49:40,263][train][INFO][train.py>_log] ==> #1219000    Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 8.793    Value Loss: 7.468    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 1408449    Buffer Size: 42946      Transition Number: 1500.018k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:53:02,368][train][INFO][train.py>_log] ==> #1220000    Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 8.348    Value Loss: 7.733    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1409997    Buffer Size: 43336      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:56:24,701][train][INFO][train.py>_log] ==> #1221000    Total Loss: 1.360    [weighted Loss:1.360    Policy Loss: 8.171    Value Loss: 7.526    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 1413285    Buffer Size: 45231      Transition Number: 1500.107k Batch Size: 256        Lr: 0.08100 
[2022-01-16 21:59:48,678][train][INFO][train.py>_log] ==> #1222000    Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 7.554    Value Loss: 7.619    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 1416831    Buffer Size: 47306      Transition Number: 1500.036k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:03:10,096][train][INFO][train.py>_log] ==> #1223000    Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 6.940    Value Loss: 7.334    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 1418871    Buffer Size: 47793      Transition Number: 1499.996k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:06:28,883][train][INFO][train.py>_log] ==> #1224000    Total Loss: 2.336    [weighted Loss:2.336    Policy Loss: 7.142    Value Loss: 7.828    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1420995    Buffer Size: 48279      Transition Number: 1499.980k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:09:47,419][train][INFO][train.py>_log] ==> #1225000    Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 6.944    Value Loss: 7.280    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 1422102    Buffer Size: 47989      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:13:08,536][train][INFO][train.py>_log] ==> #1226000    Total Loss: 1.131    [weighted Loss:1.131    Policy Loss: 6.856    Value Loss: 6.978    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 1423221    Buffer Size: 47684      Transition Number: 1500.013k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:16:26,530][train][INFO][train.py>_log] ==> #1227000    Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 7.467    Value Loss: 6.955    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424277    Buffer Size: 47398      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:19:46,690][train][INFO][train.py>_log] ==> #1228000    Total Loss: 1.819    [weighted Loss:1.819    Policy Loss: 7.231    Value Loss: 7.121    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 1425335    Buffer Size: 47101      Transition Number: 1500.146k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:23:08,962][train][INFO][train.py>_log] ==> #1229000    Total Loss: 2.492    [weighted Loss:2.492    Policy Loss: 7.970    Value Loss: 7.296    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1426387    Buffer Size: 46603      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:26:29,109][train][INFO][train.py>_log] ==> #1230000    Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 8.120    Value Loss: 7.189    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 1427433    Buffer Size: 46002      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:29:51,022][train][INFO][train.py>_log] ==> #1231000    Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 7.306    Value Loss: 7.413    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 1428702    Buffer Size: 45276      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:33:16,595][train][INFO][train.py>_log] ==> #1232000    Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 6.433    Value Loss: 7.255    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 1429953    Buffer Size: 44496      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:36:41,950][train][INFO][train.py>_log] ==> #1233000    Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 8.191    Value Loss: 7.139    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 1431306    Buffer Size: 44144      Transition Number: 1500.059k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:40:03,439][train][INFO][train.py>_log] ==> #1234000    Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 7.497    Value Loss: 7.396    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 1432609    Buffer Size: 43971      Transition Number: 1499.979k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:43:24,859][train][INFO][train.py>_log] ==> #1235000    Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 9.025    Value Loss: 7.332    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 1434260    Buffer Size: 43476      Transition Number: 1499.998k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:46:45,652][train][INFO][train.py>_log] ==> #1236000    Total Loss: 3.115    [weighted Loss:3.115    Policy Loss: 7.464    Value Loss: 7.266    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435875    Buffer Size: 42825      Transition Number: 1500.004k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:50:06,187][train][INFO][train.py>_log] ==> #1237000    Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 10.071   Value Loss: 7.308    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 1437254    Buffer Size: 42329      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:53:29,949][train][INFO][train.py>_log] ==> #1238000    Total Loss: 2.872    [weighted Loss:2.872    Policy Loss: 7.999    Value Loss: 7.319    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 1438653    Buffer Size: 42023      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 22:56:50,742][train][INFO][train.py>_log] ==> #1239000    Total Loss: 0.586    [weighted Loss:0.586    Policy Loss: 9.839    Value Loss: 7.806    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440011    Buffer Size: 41961      Transition Number: 1499.986k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:00:09,881][train][INFO][train.py>_log] ==> #1240000    Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 8.972    Value Loss: 7.339    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1441332    Buffer Size: 42105      Transition Number: 1500.045k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:03:32,588][train][INFO][train.py>_log] ==> #1241000    Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 8.338    Value Loss: 7.110    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 1443015    Buffer Size: 42561      Transition Number: 1499.973k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:06:54,145][train][INFO][train.py>_log] ==> #1242000    Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 9.132    Value Loss: 7.121    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 1444644    Buffer Size: 43026      Transition Number: 1500.086k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:10:13,013][train][INFO][train.py>_log] ==> #1243000    Total Loss: 1.428    [weighted Loss:1.428    Policy Loss: 8.588    Value Loss: 7.510    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 1446132    Buffer Size: 43319      Transition Number: 1500.053k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:13:34,297][train][INFO][train.py>_log] ==> #1244000    Total Loss: 1.356    [weighted Loss:1.356    Policy Loss: 8.215    Value Loss: 7.356    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 1447630    Buffer Size: 43604      Transition Number: 1500.008k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:16:54,792][train][INFO][train.py>_log] ==> #1245000    Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 8.337    Value Loss: 7.333    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 1448896    Buffer Size: 43582      Transition Number: 1499.981k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:20:15,698][train][INFO][train.py>_log] ==> #1246000    Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 7.879    Value Loss: 7.679    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 1450173    Buffer Size: 43487      Transition Number: 1499.998k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:23:37,282][train][INFO][train.py>_log] ==> #1247000    Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 9.135    Value Loss: 7.490    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451376    Buffer Size: 43228      Transition Number: 1500.041k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:26:59,328][train][INFO][train.py>_log] ==> #1248000    Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 6.934    Value Loss: 6.742    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 1452569    Buffer Size: 42887      Transition Number: 1500.022k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:30:21,491][train][INFO][train.py>_log] ==> #1249000    Total Loss: 1.809    [weighted Loss:1.809    Policy Loss: 8.079    Value Loss: 6.772    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 1453727    Buffer Size: 41507      Transition Number: 1500.104k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:33:45,542][train][INFO][train.py>_log] ==> #1250000    Total Loss: 1.628    [weighted Loss:1.628    Policy Loss: 7.743    Value Loss: 7.237    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1454922    Buffer Size: 39424      Transition Number: 1500.051k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:37:09,533][train][INFO][train.py>_log] ==> #1251000    Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 8.002    Value Loss: 6.883    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 1455924    Buffer Size: 37846      Transition Number: 1499.995k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:40:33,334][train][INFO][train.py>_log] ==> #1252000    Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 6.952    Value Loss: 7.131    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 1456931    Buffer Size: 36872      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:44:01,520][train][INFO][train.py>_log] ==> #1253000    Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 8.959    Value Loss: 7.227    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 1458009    Buffer Size: 36337      Transition Number: 1500.029k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:47:23,986][train][INFO][train.py>_log] ==> #1254000    Total Loss: 1.484    [weighted Loss:1.484    Policy Loss: 8.917    Value Loss: 6.896    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 1459094    Buffer Size: 36258      Transition Number: 1500.022k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:50:46,549][train][INFO][train.py>_log] ==> #1255000    Total Loss: 1.317    [weighted Loss:1.317    Policy Loss: 8.082    Value Loss: 7.608    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 1460617    Buffer Size: 36596      Transition Number: 1499.978k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:54:09,315][train][INFO][train.py>_log] ==> #1256000    Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 8.542    Value Loss: 6.924    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 1462091    Buffer Size: 36983      Transition Number: 1499.997k Batch Size: 256        Lr: 0.08100 
[2022-01-16 23:57:31,510][train][INFO][train.py>_log] ==> #1257000    Total Loss: 0.815    [weighted Loss:0.815    Policy Loss: 9.260    Value Loss: 7.374    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 1463937    Buffer Size: 37684      Transition Number: 1500.005k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:00:53,325][train][INFO][train.py>_log] ==> #1258000    Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 9.025    Value Loss: 7.566    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 1465752    Buffer Size: 38356      Transition Number: 1499.944k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:04:15,155][train][INFO][train.py>_log] ==> #1259000    Total Loss: 1.285    [weighted Loss:1.285    Policy Loss: 9.378    Value Loss: 7.451    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1467779    Buffer Size: 39056      Transition Number: 1500.032k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:07:36,600][train][INFO][train.py>_log] ==> #1260000    Total Loss: 2.660    [weighted Loss:2.660    Policy Loss: 8.800    Value Loss: 7.553    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 1469798    Buffer Size: 39798      Transition Number: 1499.963k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:11:00,155][train][INFO][train.py>_log] ==> #1261000    Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 8.760    Value Loss: 7.625    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 1471786    Buffer Size: 40462      Transition Number: 1499.987k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:14:22,061][train][INFO][train.py>_log] ==> #1262000    Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 8.700    Value Loss: 7.355    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 1473767    Buffer Size: 41019      Transition Number: 1500.021k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:17:42,863][train][INFO][train.py>_log] ==> #1263000    Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 8.131    Value Loss: 7.842    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 1475523    Buffer Size: 41157      Transition Number: 1500.032k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:21:05,200][train][INFO][train.py>_log] ==> #1264000    Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 7.821    Value Loss: 7.314    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 1477290    Buffer Size: 41278      Transition Number: 1500.011k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:24:28,355][train][INFO][train.py>_log] ==> #1265000    Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 7.841    Value Loss: 7.550    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 1478786    Buffer Size: 41395      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:27:52,125][train][INFO][train.py>_log] ==> #1266000    Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 8.111    Value Loss: 7.679    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 1480317    Buffer Size: 41517      Transition Number: 1499.955k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:31:12,880][train][INFO][train.py>_log] ==> #1267000    Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 8.933    Value Loss: 7.392    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1481729    Buffer Size: 41584      Transition Number: 1499.992k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:34:37,091][train][INFO][train.py>_log] ==> #1268000    Total Loss: 1.200    [weighted Loss:1.200    Policy Loss: 7.201    Value Loss: 6.820    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 1483199    Buffer Size: 41623      Transition Number: 1499.956k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:38:00,080][train][INFO][train.py>_log] ==> #1269000    Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 7.715    Value Loss: 7.046    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 1484285    Buffer Size: 41123      Transition Number: 1499.962k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:41:21,555][train][INFO][train.py>_log] ==> #1270000    Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 8.161    Value Loss: 7.360    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485389    Buffer Size: 40618      Transition Number: 1499.990k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:44:44,273][train][INFO][train.py>_log] ==> #1271000    Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 8.107    Value Loss: 7.407    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 1486528    Buffer Size: 40298      Transition Number: 1499.987k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:48:07,901][train][INFO][train.py>_log] ==> #1272000    Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 7.744    Value Loss: 7.298    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1487649    Buffer Size: 39968      Transition Number: 1500.000k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:51:31,894][train][INFO][train.py>_log] ==> #1273000    Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 8.443    Value Loss: 6.955    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 1488723    Buffer Size: 39774      Transition Number: 1499.988k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:54:55,466][train][INFO][train.py>_log] ==> #1274000    Total Loss: 1.016    [weighted Loss:1.016    Policy Loss: 9.055    Value Loss: 6.986    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 1489821    Buffer Size: 39580      Transition Number: 1500.006k Batch Size: 256        Lr: 0.08100 
[2022-01-17 00:58:17,839][train][INFO][train.py>_log] ==> #1275000    Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 8.617    Value Loss: 7.179    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 1491126    Buffer Size: 39681      Transition Number: 1499.991k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:01:39,555][train][INFO][train.py>_log] ==> #1276000    Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 7.882    Value Loss: 7.053    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 1492468    Buffer Size: 39795      Transition Number: 1499.948k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:05:03,915][train][INFO][train.py>_log] ==> #1277000    Total Loss: 1.104    [weighted Loss:1.104    Policy Loss: 8.068    Value Loss: 7.159    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 1493805    Buffer Size: 39948      Transition Number: 1500.009k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:08:25,091][train][INFO][train.py>_log] ==> #1278000    Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 10.655   Value Loss: 7.643    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1495161    Buffer Size: 40118      Transition Number: 1500.042k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:11:48,040][train][INFO][train.py>_log] ==> #1279000    Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 8.310    Value Loss: 7.403    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 1496397    Buffer Size: 40309      Transition Number: 1500.087k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:15:15,333][train][INFO][train.py>_log] ==> #1280000    Total Loss: 2.918    [weighted Loss:2.918    Policy Loss: 8.691    Value Loss: 7.124    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 1497671    Buffer Size: 40510      Transition Number: 1500.038k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:18:38,043][train][INFO][train.py>_log] ==> #1281000    Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 9.347    Value Loss: 7.510    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 1499387    Buffer Size: 41100      Transition Number: 1499.996k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:21:58,182][train][INFO][train.py>_log] ==> #1282000    Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 9.050    Value Loss: 7.375    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 1501049    Buffer Size: 41600      Transition Number: 1499.978k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:25:17,951][train][INFO][train.py>_log] ==> #1283000    Total Loss: 2.092    [weighted Loss:2.092    Policy Loss: 8.567    Value Loss: 7.112    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 1502403    Buffer Size: 41491      Transition Number: 1500.003k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:28:41,319][train][INFO][train.py>_log] ==> #1284000    Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 8.993    Value Loss: 7.482    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 1503717    Buffer Size: 41335      Transition Number: 1500.099k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:32:05,026][train][INFO][train.py>_log] ==> #1285000    Total Loss: 1.569    [weighted Loss:1.569    Policy Loss: 8.663    Value Loss: 7.415    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 1505694    Buffer Size: 41426      Transition Number: 1500.055k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:35:29,381][train][INFO][train.py>_log] ==> #1286000    Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 8.219    Value Loss: 7.243    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 1507791    Buffer Size: 41621      Transition Number: 1499.969k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:38:50,923][train][INFO][train.py>_log] ==> #1287000    Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 8.884    Value Loss: 7.672    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 1509368    Buffer Size: 41336      Transition Number: 1500.095k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:42:12,937][train][INFO][train.py>_log] ==> #1288000    Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 9.186    Value Loss: 7.528    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 1510998    Buffer Size: 40999      Transition Number: 1499.971k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:45:35,211][train][INFO][train.py>_log] ==> #1289000    Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 8.166    Value Loss: 7.382    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 1512881    Buffer Size: 40857      Transition Number: 1500.041k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:49:01,387][train][INFO][train.py>_log] ==> #1290000    Total Loss: 3.439    [weighted Loss:3.439    Policy Loss: 8.969    Value Loss: 7.155    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 1514816    Buffer Size: 40763      Transition Number: 1500.012k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:52:21,368][train][INFO][train.py>_log] ==> #1291000    Total Loss: 0.570    [weighted Loss:0.570    Policy Loss: 9.149    Value Loss: 7.749    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 1516816    Buffer Size: 40975      Transition Number: 1499.943k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:55:44,241][train][INFO][train.py>_log] ==> #1292000    Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 7.687    Value Loss: 7.754    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 1518772    Buffer Size: 41164      Transition Number: 1500.008k Batch Size: 256        Lr: 0.08100 
[2022-01-17 01:59:08,762][train][INFO][train.py>_log] ==> #1293000    Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 9.372    Value Loss: 7.693    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 1520722    Buffer Size: 41625      Transition Number: 1499.972k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:02:27,948][train][INFO][train.py>_log] ==> #1294000    Total Loss: 2.596    [weighted Loss:2.596    Policy Loss: 7.593    Value Loss: 7.566    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1522617    Buffer Size: 41997      Transition Number: 1499.958k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:05:50,440][train][INFO][train.py>_log] ==> #1295000    Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 10.082   Value Loss: 7.827    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524036    Buffer Size: 42014      Transition Number: 1499.975k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:09:08,716][train][INFO][train.py>_log] ==> #1296000    Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 8.511    Value Loss: 7.813    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 1525459    Buffer Size: 42080      Transition Number: 1500.122k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:12:29,830][train][INFO][train.py>_log] ==> #1297000    Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 9.188    Value Loss: 7.507    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 1527490    Buffer Size: 42996      Transition Number: 1500.006k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:15:51,932][train][INFO][train.py>_log] ==> #1298000    Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 8.724    Value Loss: 7.641    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 1529524    Buffer Size: 43907      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:19:08,114][train][INFO][train.py>_log] ==> #1299000    Total Loss: 2.785    [weighted Loss:2.785    Policy Loss: 9.516    Value Loss: 7.280    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 1531344    Buffer Size: 44622      Transition Number: 1499.994k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:22:28,213][train][INFO][train.py>_log] ==> #1300000    Total Loss: 1.438    [weighted Loss:1.438    Policy Loss: 8.006    Value Loss: 7.006    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 1533083    Buffer Size: 45261      Transition Number: 1499.976k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:25:47,425][train][INFO][train.py>_log] ==> #1301000    Total Loss: 1.081    [weighted Loss:1.081    Policy Loss: 10.022   Value Loss: 7.212    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 1534614    Buffer Size: 45710      Transition Number: 1500.145k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:29:04,369][train][INFO][train.py>_log] ==> #1302000    Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 9.526    Value Loss: 7.300    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 1536103    Buffer Size: 46111      Transition Number: 1500.188k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:32:23,435][train][INFO][train.py>_log] ==> #1303000    Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 9.217    Value Loss: 7.017    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 1537570    Buffer Size: 46263      Transition Number: 1500.024k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:35:42,634][train][INFO][train.py>_log] ==> #1304000    Total Loss: 3.292    [weighted Loss:3.292    Policy Loss: 7.539    Value Loss: 7.386    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 1539018    Buffer Size: 46380      Transition Number: 1500.005k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:39:03,507][train][INFO][train.py>_log] ==> #1305000    Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 9.075    Value Loss: 7.284    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 1540541    Buffer Size: 46543      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:42:24,402][train][INFO][train.py>_log] ==> #1306000    Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 8.334    Value Loss: 7.347    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 1542125    Buffer Size: 46746      Transition Number: 1500.094k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:45:42,853][train][INFO][train.py>_log] ==> #1307000    Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 8.365    Value Loss: 7.788    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1543742    Buffer Size: 47140      Transition Number: 1499.977k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:49:02,389][train][INFO][train.py>_log] ==> #1308000    Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 8.412    Value Loss: 7.549    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 1545332    Buffer Size: 47440      Transition Number: 1499.997k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:52:20,120][train][INFO][train.py>_log] ==> #1309000    Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 8.590    Value Loss: 7.386    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 1547254    Buffer Size: 47657      Transition Number: 1500.015k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:55:40,218][train][INFO][train.py>_log] ==> #1310000    Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 8.756    Value Loss: 7.532    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1549186    Buffer Size: 47921      Transition Number: 1500.135k Batch Size: 256        Lr: 0.08100 
[2022-01-17 02:58:57,733][train][INFO][train.py>_log] ==> #1311000    Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 9.498    Value Loss: 7.422    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1550648    Buffer Size: 48051      Transition Number: 1499.956k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:02:16,030][train][INFO][train.py>_log] ==> #1312000    Total Loss: 2.596    [weighted Loss:2.596    Policy Loss: 8.554    Value Loss: 7.250    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 1552072    Buffer Size: 48103      Transition Number: 1500.073k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:05:38,520][train][INFO][train.py>_log] ==> #1313000    Total Loss: 0.976    [weighted Loss:0.976    Policy Loss: 9.283    Value Loss: 7.563    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 1553698    Buffer Size: 47739      Transition Number: 1500.077k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:08:56,745][train][INFO][train.py>_log] ==> #1314000    Total Loss: 1.736    [weighted Loss:1.736    Policy Loss: 10.007   Value Loss: 7.428    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 1555325    Buffer Size: 47346      Transition Number: 1499.979k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:12:18,479][train][INFO][train.py>_log] ==> #1315000    Total Loss: 2.448    [weighted Loss:2.448    Policy Loss: 10.815   Value Loss: 7.564    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 1557604    Buffer Size: 47956      Transition Number: 1500.001k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:15:39,070][train][INFO][train.py>_log] ==> #1316000    Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 9.258    Value Loss: 7.498    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 1559932    Buffer Size: 48610      Transition Number: 1500.040k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:19:00,466][train][INFO][train.py>_log] ==> #1317000    Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 9.095    Value Loss: 7.310    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 1561822    Buffer Size: 48707      Transition Number: 1500.010k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:22:19,170][train][INFO][train.py>_log] ==> #1318000    Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 8.414    Value Loss: 7.524    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 1563683    Buffer Size: 48694      Transition Number: 1499.990k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:25:37,704][train][INFO][train.py>_log] ==> #1319000    Total Loss: 1.399    [weighted Loss:1.399    Policy Loss: 9.628    Value Loss: 7.506    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1564996    Buffer Size: 48138      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:28:57,417][train][INFO][train.py>_log] ==> #1320000    Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 7.859    Value Loss: 7.007    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 1566287    Buffer Size: 47587      Transition Number: 1499.985k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:32:19,278][train][INFO][train.py>_log] ==> #1321000    Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 11.473   Value Loss: 6.977    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 1567498    Buffer Size: 46858      Transition Number: 1499.939k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:35:42,578][train][INFO][train.py>_log] ==> #1322000    Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 8.821    Value Loss: 7.144    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 1568717    Buffer Size: 46198      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:39:02,926][train][INFO][train.py>_log] ==> #1323000    Total Loss: 3.534    [weighted Loss:3.534    Policy Loss: 10.419   Value Loss: 7.758    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 1570069    Buffer Size: 46108      Transition Number: 1499.998k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:42:22,420][train][INFO][train.py>_log] ==> #1324000    Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 9.271    Value Loss: 7.813    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 1571491    Buffer Size: 46074      Transition Number: 1499.990k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:45:47,950][train][INFO][train.py>_log] ==> #1325000    Total Loss: 2.849    [weighted Loss:2.849    Policy Loss: 10.476   Value Loss: 7.635    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 1574552    Buffer Size: 46988      Transition Number: 1500.042k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:49:09,553][train][INFO][train.py>_log] ==> #1326000    Total Loss: 1.203    [weighted Loss:1.203    Policy Loss: 9.767    Value Loss: 7.407    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 1577697    Buffer Size: 47971      Transition Number: 1499.975k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:52:29,303][train][INFO][train.py>_log] ==> #1327000    Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 8.613    Value Loss: 7.528    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 1579554    Buffer Size: 48004      Transition Number: 1499.999k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:55:47,427][train][INFO][train.py>_log] ==> #1328000    Total Loss: 1.534    [weighted Loss:1.534    Policy Loss: 9.533    Value Loss: 7.495    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 1581425    Buffer Size: 48139      Transition Number: 1499.946k Batch Size: 256        Lr: 0.08100 
[2022-01-17 03:59:07,985][train][INFO][train.py>_log] ==> #1329000    Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 9.658    Value Loss: 7.346    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 1582931    Buffer Size: 48062      Transition Number: 1499.979k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:02:28,909][train][INFO][train.py>_log] ==> #1330000    Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 9.257    Value Loss: 7.528    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 1584382    Buffer Size: 48031      Transition Number: 1499.988k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:05:46,289][train][INFO][train.py>_log] ==> #1331000    Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 8.970    Value Loss: 7.215    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 1585834    Buffer Size: 48016      Transition Number: 1500.002k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:09:07,907][train][INFO][train.py>_log] ==> #1332000    Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 9.609    Value Loss: 7.416    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1587286    Buffer Size: 47981      Transition Number: 1500.035k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:12:24,485][train][INFO][train.py>_log] ==> #1333000    Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 10.991   Value Loss: 7.561    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 1588703    Buffer Size: 47913      Transition Number: 1500.234k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:15:43,906][train][INFO][train.py>_log] ==> #1334000    Total Loss: 1.518    [weighted Loss:1.518    Policy Loss: 9.072    Value Loss: 7.827    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 1590085    Buffer Size: 47768      Transition Number: 1500.001k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:19:05,064][train][INFO][train.py>_log] ==> #1335000    Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 9.656    Value Loss: 7.519    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 1591469    Buffer Size: 47520      Transition Number: 1500.017k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:22:22,726][train][INFO][train.py>_log] ==> #1336000    Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 9.028    Value Loss: 7.664    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 1592793    Buffer Size: 47324      Transition Number: 1500.051k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:25:41,177][train][INFO][train.py>_log] ==> #1337000    Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 10.294   Value Loss: 7.596    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 1594081    Buffer Size: 46829      Transition Number: 1499.973k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:29:02,340][train][INFO][train.py>_log] ==> #1338000    Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 9.334    Value Loss: 7.385    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 1595468    Buffer Size: 46338      Transition Number: 1499.971k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:32:22,640][train][INFO][train.py>_log] ==> #1339000    Total Loss: 3.243    [weighted Loss:3.243    Policy Loss: 9.707    Value Loss: 7.674    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1596704    Buffer Size: 46052      Transition Number: 1500.032k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:35:43,765][train][INFO][train.py>_log] ==> #1340000    Total Loss: 2.651    [weighted Loss:2.651    Policy Loss: 8.605    Value Loss: 7.307    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 1597899    Buffer Size: 45849      Transition Number: 1499.988k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:39:04,255][train][INFO][train.py>_log] ==> #1341000    Total Loss: 1.220    [weighted Loss:1.220    Policy Loss: 9.499    Value Loss: 7.093    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 1598967    Buffer Size: 45426      Transition Number: 1499.976k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:42:28,692][train][INFO][train.py>_log] ==> #1342000    Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 8.793    Value Loss: 7.177    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 1600112    Buffer Size: 45004      Transition Number: 1500.057k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:45:53,260][train][INFO][train.py>_log] ==> #1343000    Total Loss: 1.525    [weighted Loss:1.525    Policy Loss: 8.452    Value Loss: 6.998    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 1601455    Buffer Size: 44111      Transition Number: 1499.967k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:49:16,256][train][INFO][train.py>_log] ==> #1344000    Total Loss: 1.286    [weighted Loss:1.286    Policy Loss: 8.414    Value Loss: 7.093    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 1602751    Buffer Size: 43168      Transition Number: 1500.134k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:52:40,604][train][INFO][train.py>_log] ==> #1345000    Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 8.197    Value Loss: 7.021    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 1604073    Buffer Size: 42471      Transition Number: 1500.029k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:56:07,289][train][INFO][train.py>_log] ==> #1346000    Total Loss: 3.132    [weighted Loss:3.132    Policy Loss: 8.548    Value Loss: 7.215    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 1605458    Buffer Size: 41963      Transition Number: 1500.056k Batch Size: 256        Lr: 0.08100 
[2022-01-17 04:59:30,220][train][INFO][train.py>_log] ==> #1347000    Total Loss: 1.756    [weighted Loss:1.756    Policy Loss: 9.128    Value Loss: 7.753    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 1606575    Buffer Size: 41690      Transition Number: 1499.976k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:02:57,491][train][INFO][train.py>_log] ==> #1348000    Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 8.349    Value Loss: 7.359    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 1607745    Buffer Size: 41501      Transition Number: 1500.211k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:06:18,467][train][INFO][train.py>_log] ==> #1349000    Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 9.473    Value Loss: 7.196    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 1608767    Buffer Size: 41348      Transition Number: 1499.975k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:09:46,515][train][INFO][train.py>_log] ==> #1350000    Total Loss: 2.318    [weighted Loss:2.318    Policy Loss: 8.273    Value Loss: 6.942    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 1609828    Buffer Size: 41189      Transition Number: 1499.972k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:13:11,348][train][INFO][train.py>_log] ==> #1351000    Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 8.523    Value Loss: 7.488    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 1611785    Buffer Size: 41692      Transition Number: 1500.022k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:16:35,646][train][INFO][train.py>_log] ==> #1352000    Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 8.338    Value Loss: 7.384    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 1613733    Buffer Size: 42134      Transition Number: 1499.990k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:19:56,641][train][INFO][train.py>_log] ==> #1353000    Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 8.692    Value Loss: 7.597    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 1615429    Buffer Size: 40898      Transition Number: 1500.017k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:23:21,348][train][INFO][train.py>_log] ==> #1354000    Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 7.670    Value Loss: 7.022    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 1617193    Buffer Size: 39486      Transition Number: 1500.068k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:26:44,309][train][INFO][train.py>_log] ==> #1355000    Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 9.514    Value Loss: 7.453    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 1618973    Buffer Size: 39326      Transition Number: 1500.078k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:30:03,696][train][INFO][train.py>_log] ==> #1356000    Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 9.674    Value Loss: 7.335    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 1620754    Buffer Size: 39235      Transition Number: 1499.976k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:33:29,099][train][INFO][train.py>_log] ==> #1357000    Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 8.302    Value Loss: 6.911    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 1623281    Buffer Size: 40192      Transition Number: 1499.981k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:36:51,034][train][INFO][train.py>_log] ==> #1358000    Total Loss: 2.912    [weighted Loss:2.912    Policy Loss: 8.795    Value Loss: 7.660    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 1625936    Buffer Size: 41276      Transition Number: 1500.018k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:40:10,863][train][INFO][train.py>_log] ==> #1359000    Total Loss: 1.332    [weighted Loss:1.332    Policy Loss: 7.776    Value Loss: 7.166    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 1627819    Buffer Size: 41636      Transition Number: 1499.977k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:43:32,750][train][INFO][train.py>_log] ==> #1360000    Total Loss: 1.126    [weighted Loss:1.126    Policy Loss: 8.851    Value Loss: 7.368    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1629648    Buffer Size: 42008      Transition Number: 1500.067k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:46:52,196][train][INFO][train.py>_log] ==> #1361000    Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 7.633    Value Loss: 6.930    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 1631284    Buffer Size: 42204      Transition Number: 1500.028k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:50:15,428][train][INFO][train.py>_log] ==> #1362000    Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 8.590    Value Loss: 7.446    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 1632989    Buffer Size: 42448      Transition Number: 1499.989k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:53:37,690][train][INFO][train.py>_log] ==> #1363000    Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 7.985    Value Loss: 7.052    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 1634298    Buffer Size: 42389      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-17 05:56:59,361][train][INFO][train.py>_log] ==> #1364000    Total Loss: 1.023    [weighted Loss:1.023    Policy Loss: 7.437    Value Loss: 7.529    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1635632    Buffer Size: 42356      Transition Number: 1499.985k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:00:19,870][train][INFO][train.py>_log] ==> #1365000    Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 8.487    Value Loss: 7.100    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 1636921    Buffer Size: 42302      Transition Number: 1499.966k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:03:43,311][train][INFO][train.py>_log] ==> #1366000    Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 8.191    Value Loss: 7.627    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 1638223    Buffer Size: 42261      Transition Number: 1500.008k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:07:05,315][train][INFO][train.py>_log] ==> #1367000    Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 7.845    Value Loss: 7.475    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 1639474    Buffer Size: 42292      Transition Number: 1500.068k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:10:27,063][train][INFO][train.py>_log] ==> #1368000    Total Loss: 1.852    [weighted Loss:1.852    Policy Loss: 7.975    Value Loss: 7.396    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 1640743    Buffer Size: 42357      Transition Number: 1499.981k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:13:49,739][train][INFO][train.py>_log] ==> #1369000    Total Loss: 1.345    [weighted Loss:1.345    Policy Loss: 7.420    Value Loss: 7.252    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 1641869    Buffer Size: 42389      Transition Number: 1500.122k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:17:12,725][train][INFO][train.py>_log] ==> #1370000    Total Loss: 1.528    [weighted Loss:1.528    Policy Loss: 8.837    Value Loss: 7.141    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 1643011    Buffer Size: 42348      Transition Number: 1499.979k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:20:35,126][train][INFO][train.py>_log] ==> #1371000    Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 7.818    Value Loss: 6.968    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 1644447    Buffer Size: 42467      Transition Number: 1500.038k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:24:00,820][train][INFO][train.py>_log] ==> #1372000    Total Loss: 2.897    [weighted Loss:2.897    Policy Loss: 7.672    Value Loss: 7.281    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 1645892    Buffer Size: 42614      Transition Number: 1500.072k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:27:21,799][train][INFO][train.py>_log] ==> #1373000    Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 7.543    Value Loss: 7.375    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 1647504    Buffer Size: 42876      Transition Number: 1499.987k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:30:42,181][train][INFO][train.py>_log] ==> #1374000    Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 9.373    Value Loss: 7.415    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1649172    Buffer Size: 43239      Transition Number: 1499.984k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:34:04,644][train][INFO][train.py>_log] ==> #1375000    Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 7.604    Value Loss: 7.490    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 1650557    Buffer Size: 43532      Transition Number: 1499.998k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:37:22,773][train][INFO][train.py>_log] ==> #1376000    Total Loss: 3.724    [weighted Loss:3.724    Policy Loss: 8.808    Value Loss: 7.434    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 1651927    Buffer Size: 43810      Transition Number: 1500.030k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:40:45,622][train][INFO][train.py>_log] ==> #1377000    Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 7.642    Value Loss: 7.225    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 1653347    Buffer Size: 44128      Transition Number: 1499.985k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:44:08,107][train][INFO][train.py>_log] ==> #1378000    Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 8.236    Value Loss: 6.783    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 1654743    Buffer Size: 44219      Transition Number: 1500.023k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:47:28,377][train][INFO][train.py>_log] ==> #1379000    Total Loss: 1.567    [weighted Loss:1.567    Policy Loss: 7.482    Value Loss: 6.879    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1656099    Buffer Size: 43673      Transition Number: 1500.056k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:50:50,183][train][INFO][train.py>_log] ==> #1380000    Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 8.765    Value Loss: 6.980    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1657462    Buffer Size: 43182      Transition Number: 1499.967k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:54:11,988][train][INFO][train.py>_log] ==> #1381000    Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 7.836    Value Loss: 7.254    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 1659173    Buffer Size: 43231      Transition Number: 1500.039k Batch Size: 256        Lr: 0.08100 
[2022-01-17 06:57:34,138][train][INFO][train.py>_log] ==> #1382000    Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 8.014    Value Loss: 7.291    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 1660931    Buffer Size: 43277      Transition Number: 1500.008k Batch Size: 256        Lr: 0.08100 
[2022-01-17 07:00:56,085][train][INFO][train.py>_log] ==> #1383000    Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 8.391    Value Loss: 7.064    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1662670    Buffer Size: 43198      Transition Number: 1499.982k Batch Size: 256        Lr: 0.08100 
[2022-01-17 07:04:19,638][train][INFO][train.py>_log] ==> #1384000    Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 9.232    Value Loss: 7.536    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 1664456    Buffer Size: 43034      Transition Number: 1499.993k Batch Size: 256        Lr: 0.08100 
