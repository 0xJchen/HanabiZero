[2022-01-05 12:52:54,426][train][INFO][train.py>_log] ==> #0          Total Loss: 56.010   [weighted Loss:56.010   Policy Loss: 14.909   Value Loss: 37.125   Reward Loss: 31.820   Consistency Loss: 0.000    ] Replay Episodes Collected: 447        Buffer Size: 447        Transition Number: 5.230   k Batch Size: 256        Lr: 0.00000 
[2022-01-05 12:55:00,156][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.308    [weighted Loss:7.308    Policy Loss: 15.554   Value Loss: 3.935    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 1990       Buffer Size: 1990       Transition Number: 25.082  k Batch Size: 256        Lr: 0.10000 
[2022-01-05 12:57:05,630][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.614    [weighted Loss:5.614    Policy Loss: 14.174   Value Loss: 3.443    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 3586       Buffer Size: 3586       Transition Number: 44.876  k Batch Size: 256        Lr: 0.10000 
[2022-01-05 12:59:11,931][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.008    [weighted Loss:5.008    Policy Loss: 12.779   Value Loss: 3.293    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 6013       Buffer Size: 6013       Transition Number: 65.354  k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:01:14,383][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.806    [weighted Loss:5.806    Policy Loss: 13.862   Value Loss: 3.369    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 8356       Buffer Size: 8356       Transition Number: 84.641  k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:03:18,001][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.648    [weighted Loss:4.648    Policy Loss: 12.912   Value Loss: 3.020    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 9707       Buffer Size: 9707       Transition Number: 102.230 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:05:22,095][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 13.133   Value Loss: 3.411    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 11119      Buffer Size: 11119      Transition Number: 121.539 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:07:24,294][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.530    [weighted Loss:5.530    Policy Loss: 13.600   Value Loss: 3.506    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 11829      Buffer Size: 11829      Transition Number: 138.142 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:09:27,185][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.754    [weighted Loss:4.754    Policy Loss: 11.561   Value Loss: 3.419    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 12568      Buffer Size: 12568      Transition Number: 155.403 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:11:34,180][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.236    [weighted Loss:3.236    Policy Loss: 11.480   Value Loss: 3.486    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 13061      Buffer Size: 13061      Transition Number: 169.788 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:13:41,410][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.133    [weighted Loss:5.133    Policy Loss: 11.452   Value Loss: 3.534    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 13633      Buffer Size: 13633      Transition Number: 189.493 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:15:51,098][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.945    [weighted Loss:4.945    Policy Loss: 11.584   Value Loss: 3.489    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 13992      Buffer Size: 13992      Transition Number: 205.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:17:58,606][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 10.557   Value Loss: 3.506    Reward Loss: 0.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 14339      Buffer Size: 14339      Transition Number: 222.781 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:20:03,622][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.473    [weighted Loss:5.473    Policy Loss: 10.916   Value Loss: 3.456    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 14633      Buffer Size: 14633      Transition Number: 236.441 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:22:16,075][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 10.197   Value Loss: 3.719    Reward Loss: 0.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 14928      Buffer Size: 14928      Transition Number: 251.516 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:24:26,143][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.898    [weighted Loss:3.898    Policy Loss: 9.017    Value Loss: 3.711    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 15233      Buffer Size: 15233      Transition Number: 269.110 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:26:37,067][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 8.794    Value Loss: 3.765    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 15529      Buffer Size: 15529      Transition Number: 286.260 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:28:51,866][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.198    [weighted Loss:3.198    Policy Loss: 7.256    Value Loss: 4.126    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 15879      Buffer Size: 15879      Transition Number: 303.619 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:31:07,271][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 7.142    Value Loss: 4.121    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 16193      Buffer Size: 16193      Transition Number: 319.752 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:33:23,966][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.216    [weighted Loss:4.216    Policy Loss: 8.369    Value Loss: 4.181    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 16488      Buffer Size: 16488      Transition Number: 334.567 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:35:45,045][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.594    [weighted Loss:3.594    Policy Loss: 7.506    Value Loss: 4.273    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 16837      Buffer Size: 16837      Transition Number: 352.882 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:37:57,382][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 7.342    Value Loss: 4.219    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 17177      Buffer Size: 17177      Transition Number: 371.239 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:40:08,360][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 7.570    Value Loss: 4.202    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 17490      Buffer Size: 17490      Transition Number: 388.411 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:42:15,130][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 7.896    Value Loss: 4.194    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 17782      Buffer Size: 17782      Transition Number: 405.228 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:44:20,604][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.819    [weighted Loss:2.819    Policy Loss: 7.818    Value Loss: 4.247    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 18081      Buffer Size: 18081      Transition Number: 422.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:46:28,063][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.582    [weighted Loss:2.582    Policy Loss: 7.843    Value Loss: 4.222    Reward Loss: 0.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 18319      Buffer Size: 18319      Transition Number: 436.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:48:35,356][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 7.604    Value Loss: 4.311    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 18623      Buffer Size: 18623      Transition Number: 454.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:50:40,558][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 8.086    Value Loss: 4.314    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 18919      Buffer Size: 18919      Transition Number: 471.872 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:52:49,992][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.368    [weighted Loss:3.368    Policy Loss: 7.466    Value Loss: 4.437    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 19218      Buffer Size: 19218      Transition Number: 488.666 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:55:02,484][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.048    [weighted Loss:3.048    Policy Loss: 7.344    Value Loss: 4.252    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 19487      Buffer Size: 19487      Transition Number: 505.229 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:57:09,656][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 7.441    Value Loss: 4.442    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 19742      Buffer Size: 19742      Transition Number: 520.662 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 13:59:24,416][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.736    [weighted Loss:1.736    Policy Loss: 6.851    Value Loss: 4.381    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 20037      Buffer Size: 20037      Transition Number: 538.126 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:01:39,565][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.128    [weighted Loss:4.128    Policy Loss: 8.015    Value Loss: 4.444    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 20345      Buffer Size: 20345      Transition Number: 556.248 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:03:54,508][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 7.688    Value Loss: 4.326    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 20606      Buffer Size: 20606      Transition Number: 571.792 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:06:05,926][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.513    [weighted Loss:2.513    Policy Loss: 7.875    Value Loss: 4.480    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 20879      Buffer Size: 20879      Transition Number: 588.042 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:08:29,743][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.604    [weighted Loss:2.604    Policy Loss: 7.225    Value Loss: 4.583    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 21233      Buffer Size: 21233      Transition Number: 606.864 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:10:51,539][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 6.892    Value Loss: 4.576    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 21568      Buffer Size: 21568      Transition Number: 625.132 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:13:15,070][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.458    [weighted Loss:3.458    Policy Loss: 6.997    Value Loss: 4.671    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 21873      Buffer Size: 21873      Transition Number: 643.113 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:15:39,029][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.467    [weighted Loss:3.467    Policy Loss: 7.020    Value Loss: 4.531    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 22175      Buffer Size: 22175      Transition Number: 660.364 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:18:04,602][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.324    [weighted Loss:3.324    Policy Loss: 7.022    Value Loss: 4.494    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 22526      Buffer Size: 22526      Transition Number: 680.214 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:20:28,679][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 7.574    Value Loss: 4.600    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 22879      Buffer Size: 22879      Transition Number: 699.785 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:22:54,944][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.279    [weighted Loss:3.279    Policy Loss: 7.343    Value Loss: 4.767    Reward Loss: 0.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 23254      Buffer Size: 23254      Transition Number: 719.546 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:25:17,796][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 6.200    Value Loss: 4.636    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 23639      Buffer Size: 23639      Transition Number: 738.316 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:27:41,710][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 6.102    Value Loss: 4.658    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 23991      Buffer Size: 23991      Transition Number: 757.054 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:30:02,518][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.196    [weighted Loss:3.196    Policy Loss: 6.061    Value Loss: 4.736    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 24354      Buffer Size: 24354      Transition Number: 776.371 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:32:25,195][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 5.097    Value Loss: 4.920    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 24741      Buffer Size: 24741      Transition Number: 795.241 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:34:48,470][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 5.824    Value Loss: 4.558    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 25110      Buffer Size: 25110      Transition Number: 814.137 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:37:11,524][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 5.724    Value Loss: 4.698    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 25668      Buffer Size: 25668      Transition Number: 831.723 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:39:35,269][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 6.061    Value Loss: 4.607    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 26236      Buffer Size: 26236      Transition Number: 850.771 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:42:01,939][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.992    [weighted Loss:2.992    Policy Loss: 6.479    Value Loss: 4.697    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 26570      Buffer Size: 26570      Transition Number: 868.690 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:44:24,942][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.122    [weighted Loss:2.122    Policy Loss: 5.528    Value Loss: 4.640    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 26942      Buffer Size: 26942      Transition Number: 888.647 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:46:51,864][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 5.515    Value Loss: 4.562    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 27316      Buffer Size: 27316      Transition Number: 908.624 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:49:21,013][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.567    [weighted Loss:3.567    Policy Loss: 6.768    Value Loss: 4.961    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 27691      Buffer Size: 27691      Transition Number: 927.616 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:51:48,040][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.929    [weighted Loss:2.929    Policy Loss: 5.206    Value Loss: 4.791    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 28035      Buffer Size: 28035      Transition Number: 946.164 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:54:15,123][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 5.509    Value Loss: 4.867    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 28422      Buffer Size: 28422      Transition Number: 965.913 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:56:42,329][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 5.041    Value Loss: 5.040    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 28802      Buffer Size: 28802      Transition Number: 985.537 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 14:59:08,611][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.916    [weighted Loss:2.916    Policy Loss: 5.603    Value Loss: 5.014    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 29179      Buffer Size: 28760      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:01:41,217][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 5.099    Value Loss: 5.102    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 29550      Buffer Size: 27628      Transition Number: 1000.079k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:04:14,648][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.937    [weighted Loss:1.937    Policy Loss: 5.542    Value Loss: 4.842    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 29961      Buffer Size: 26310      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:06:45,389][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.930    [weighted Loss:1.930    Policy Loss: 5.780    Value Loss: 5.304    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 30379      Buffer Size: 24322      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:09:21,358][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 5.631    Value Loss: 5.143    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 30817      Buffer Size: 22267      Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:11:56,756][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.018    [weighted Loss:3.018    Policy Loss: 6.449    Value Loss: 5.656    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 31240      Buffer Size: 21130      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:14:29,429][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 5.608    Value Loss: 5.428    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 31640      Buffer Size: 20203      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:17:02,950][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 5.539    Value Loss: 5.291    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 32011      Buffer Size: 19780      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:19:38,122][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 5.434    Value Loss: 5.024    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 32378      Buffer Size: 19358      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:22:13,947][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 5.980    Value Loss: 5.425    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 32763      Buffer Size: 19100      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:24:47,294][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.859    [weighted Loss:1.859    Policy Loss: 5.525    Value Loss: 5.276    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 33164      Buffer Size: 19034      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:27:22,974][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 5.409    Value Loss: 5.228    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 33565      Buffer Size: 19005      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:29:57,732][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 5.483    Value Loss: 5.322    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 33954      Buffer Size: 18990      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:32:34,679][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.041    [weighted Loss:2.041    Policy Loss: 5.521    Value Loss: 5.502    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 34372      Buffer Size: 19040      Transition Number: 1000.002k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:35:11,670][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.165    [weighted Loss:2.165    Policy Loss: 5.214    Value Loss: 5.275    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 34816      Buffer Size: 19065      Transition Number: 1000.033k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:37:47,435][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 6.437    Value Loss: 5.240    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 35263      Buffer Size: 19099      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:40:21,949][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.024    [weighted Loss:3.024    Policy Loss: 6.754    Value Loss: 5.397    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 35696      Buffer Size: 19138      Transition Number: 999.922 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:42:58,300][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.316    [weighted Loss:2.316    Policy Loss: 6.274    Value Loss: 4.907    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 36150      Buffer Size: 19198      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:45:33,751][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.570    [weighted Loss:3.570    Policy Loss: 6.666    Value Loss: 5.352    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 36630      Buffer Size: 19280      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:48:10,171][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 6.804    Value Loss: 5.528    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 37081      Buffer Size: 19377      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:50:43,845][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.649    [weighted Loss:3.649    Policy Loss: 7.074    Value Loss: 5.697    Reward Loss: 0.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 37528      Buffer Size: 19450      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:53:19,450][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.312    [weighted Loss:3.312    Policy Loss: 7.993    Value Loss: 5.352    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 37996      Buffer Size: 19566      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:55:54,426][train][INFO][train.py>_log] ==> #78000      Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 7.245    Value Loss: 5.635    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 38475      Buffer Size: 19683      Transition Number: 999.925 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 15:58:28,224][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 7.686    Value Loss: 5.539    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 38907      Buffer Size: 19736      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:01:05,403][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 7.128    Value Loss: 5.729    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 39322      Buffer Size: 19800      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:03:37,463][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.736    [weighted Loss:2.736    Policy Loss: 7.257    Value Loss: 5.496    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 39760      Buffer Size: 19904      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:06:10,759][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 6.403    Value Loss: 5.741    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 40223      Buffer Size: 20024      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:08:44,154][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.362    [weighted Loss:3.362    Policy Loss: 6.898    Value Loss: 5.762    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 40622      Buffer Size: 20062      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:11:20,767][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 6.253    Value Loss: 5.324    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 41014      Buffer Size: 20094      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:13:57,234][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 5.138    Value Loss: 5.925    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 41398      Buffer Size: 20060      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:16:30,765][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 4.247    Value Loss: 5.827    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 41767      Buffer Size: 20057      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:19:08,994][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.191    [weighted Loss:2.191    Policy Loss: 4.536    Value Loss: 6.057    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 42139      Buffer Size: 20047      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:21:44,743][train][INFO][train.py>_log] ==> #88000      Total Loss: 3.158    [weighted Loss:3.158    Policy Loss: 4.764    Value Loss: 5.723    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 42529      Buffer Size: 20042      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:24:22,939][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.709    [weighted Loss:2.709    Policy Loss: 4.721    Value Loss: 5.796    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 42958      Buffer Size: 20068      Transition Number: 1000.162k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:27:01,052][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.364    [weighted Loss:1.364    Policy Loss: 4.618    Value Loss: 5.896    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 43356      Buffer Size: 20023      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:29:35,388][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 4.717    Value Loss: 5.800    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 43762      Buffer Size: 20008      Transition Number: 999.924 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:32:13,016][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 4.188    Value Loss: 5.566    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 44203      Buffer Size: 20033      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:34:51,742][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.456    [weighted Loss:2.456    Policy Loss: 4.708    Value Loss: 5.818    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 44592      Buffer Size: 20017      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:37:28,273][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 4.526    Value Loss: 5.958    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 44994      Buffer Size: 19981      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:40:03,698][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 4.138    Value Loss: 6.029    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 45422      Buffer Size: 19779      Transition Number: 999.924 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:42:39,783][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 4.849    Value Loss: 5.990    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 45831      Buffer Size: 19566      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:45:16,811][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.916    [weighted Loss:2.916    Policy Loss: 5.062    Value Loss: 5.838    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 46366      Buffer Size: 19713      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:47:51,548][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 4.620    Value Loss: 6.068    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 46914      Buffer Size: 19859      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:50:29,772][train][INFO][train.py>_log] ==> #99000      Total Loss: 0.640    [weighted Loss:0.640    Policy Loss: 4.335    Value Loss: 6.088    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 47310      Buffer Size: 19844      Transition Number: 1000.005k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:53:06,173][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.149    [weighted Loss:2.149    Policy Loss: 5.210    Value Loss: 5.758    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 47696      Buffer Size: 19801      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:55:44,282][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 4.591    Value Loss: 5.800    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 48035      Buffer Size: 19711      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 16:58:22,324][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 4.205    Value Loss: 5.593    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 48387      Buffer Size: 19638      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:00:59,918][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 4.577    Value Loss: 5.917    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 48784      Buffer Size: 19584      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:03:36,737][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.437    [weighted Loss:2.437    Policy Loss: 4.581    Value Loss: 5.488    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 49177      Buffer Size: 19562      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:06:14,329][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 4.416    Value Loss: 5.805    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 49616      Buffer Size: 19558      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:08:51,897][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 4.619    Value Loss: 6.076    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 50036      Buffer Size: 19524      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:11:30,360][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.882    [weighted Loss:2.882    Policy Loss: 4.231    Value Loss: 5.878    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 50458      Buffer Size: 19483      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:14:10,102][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.781    [weighted Loss:1.781    Policy Loss: 3.994    Value Loss: 5.895    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 50919      Buffer Size: 19466      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:16:48,031][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 4.171    Value Loss: 5.710    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 51252      Buffer Size: 19396      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:19:26,589][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 3.671    Value Loss: 5.651    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 51593      Buffer Size: 19341      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:22:06,143][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 4.338    Value Loss: 5.635    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 51947      Buffer Size: 19266      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:24:44,204][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.135    Value Loss: 5.727    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 52315      Buffer Size: 19160      Transition Number: 1000.012k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:27:21,928][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 4.396    Value Loss: 5.881    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 52665      Buffer Size: 19053      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:29:59,728][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 4.510    Value Loss: 5.636    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 52992      Buffer Size: 18973      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:32:39,731][train][INFO][train.py>_log] ==> #115000     Total Loss: 1.987    [weighted Loss:1.987    Policy Loss: 4.258    Value Loss: 5.515    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 53385      Buffer Size: 18848      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:35:18,302][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.461    [weighted Loss:1.461    Policy Loss: 3.875    Value Loss: 5.574    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 53740      Buffer Size: 18733      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:37:57,621][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 3.954    Value Loss: 5.358    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 54089      Buffer Size: 18588      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:40:36,751][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 4.348    Value Loss: 5.891    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 54440      Buffer Size: 18458      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:43:17,823][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 3.788    Value Loss: 5.440    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 54804      Buffer Size: 18269      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:45:56,173][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 4.331    Value Loss: 5.388    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 55162      Buffer Size: 18105      Transition Number: 999.939 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:48:35,797][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.501    [weighted Loss:2.501    Policy Loss: 4.058    Value Loss: 5.468    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 55526      Buffer Size: 17984      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:51:14,364][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 4.447    Value Loss: 5.531    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 55879      Buffer Size: 17828      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:53:55,861][train][INFO][train.py>_log] ==> #123000     Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 3.992    Value Loss: 5.304    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 56238      Buffer Size: 17672      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:56:38,638][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.611    [weighted Loss:2.611    Policy Loss: 4.240    Value Loss: 6.016    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 56619      Buffer Size: 17549      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 17:59:19,511][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 4.562    Value Loss: 5.542    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 56975      Buffer Size: 17390      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:01:58,290][train][INFO][train.py>_log] ==> #126000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 4.649    Value Loss: 5.214    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 57305      Buffer Size: 17200      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:04:36,547][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.579    [weighted Loss:1.579    Policy Loss: 4.858    Value Loss: 5.676    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 57670      Buffer Size: 17096      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:07:13,645][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 4.925    Value Loss: 5.573    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 58030      Buffer Size: 17031      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:09:54,406][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 4.910    Value Loss: 5.428    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 58411      Buffer Size: 17002      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:12:34,912][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 4.328    Value Loss: 5.504    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 58792      Buffer Size: 16989      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:15:15,950][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 5.228    Value Loss: 5.376    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 59151      Buffer Size: 16933      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:17:56,836][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 5.296    Value Loss: 5.327    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 59512      Buffer Size: 16859      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:20:35,083][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.524    [weighted Loss:2.524    Policy Loss: 5.511    Value Loss: 5.459    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 59845      Buffer Size: 16779      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:23:15,490][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 4.387    Value Loss: 5.319    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 60209      Buffer Size: 16714      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:25:54,893][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 4.689    Value Loss: 5.144    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 60589      Buffer Size: 16606      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:28:37,231][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.841    [weighted Loss:2.841    Policy Loss: 4.870    Value Loss: 5.050    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 60950      Buffer Size: 16519      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:31:17,582][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 4.299    Value Loss: 4.924    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 61300      Buffer Size: 16449      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:33:57,388][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 5.023    Value Loss: 5.675    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 61656      Buffer Size: 16375      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:36:37,685][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 4.292    Value Loss: 5.297    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 62015      Buffer Size: 16282      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:39:17,463][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.826    [weighted Loss:1.826    Policy Loss: 4.170    Value Loss: 5.287    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 62414      Buffer Size: 16081      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:41:59,564][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 4.158    Value Loss: 5.742    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 62774      Buffer Size: 15837      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:44:36,327][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 4.594    Value Loss: 5.048    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 63141      Buffer Size: 15794      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:47:16,936][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.756    [weighted Loss:1.756    Policy Loss: 4.743    Value Loss: 4.907    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 63485      Buffer Size: 15766      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:49:59,010][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 4.177    Value Loss: 5.129    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 63847      Buffer Size: 15765      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:52:38,413][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 4.995    Value Loss: 5.324    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 64229      Buffer Size: 15782      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:55:19,952][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 4.568    Value Loss: 5.216    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 64663      Buffer Size: 15746      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 18:57:59,336][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.443    [weighted Loss:2.443    Policy Loss: 5.017    Value Loss: 5.405    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 65052      Buffer Size: 15705      Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:00:42,840][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 4.432    Value Loss: 5.311    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 65437      Buffer Size: 15639      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:03:26,861][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.076    [weighted Loss:2.076    Policy Loss: 4.457    Value Loss: 5.613    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 65793      Buffer Size: 15584      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:06:11,066][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.119    [weighted Loss:2.119    Policy Loss: 4.686    Value Loss: 5.687    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 66182      Buffer Size: 15515      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:08:50,958][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 4.465    Value Loss: 5.039    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 66530      Buffer Size: 15442      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:11:33,789][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 4.600    Value Loss: 5.312    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 66917      Buffer Size: 15443      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:14:14,174][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 4.747    Value Loss: 5.187    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 67269      Buffer Size: 15455      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:16:56,846][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.692    [weighted Loss:1.692    Policy Loss: 4.136    Value Loss: 5.303    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 67627      Buffer Size: 15465      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:19:40,309][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 5.028    Value Loss: 5.218    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 67998      Buffer Size: 15507      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:22:25,128][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 4.645    Value Loss: 5.032    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 68400      Buffer Size: 15551      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:25:08,729][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.437    [weighted Loss:2.437    Policy Loss: 4.955    Value Loss: 5.219    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 68799      Buffer Size: 15604      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:27:50,678][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.618    [weighted Loss:2.618    Policy Loss: 5.002    Value Loss: 5.590    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 69223      Buffer Size: 15638      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:30:32,880][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 4.059    Value Loss: 5.409    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 69585      Buffer Size: 15664      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:33:15,815][train][INFO][train.py>_log] ==> #160000     Total Loss: 0.855    [weighted Loss:0.855    Policy Loss: 4.404    Value Loss: 5.891    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 69943      Buffer Size: 15672      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:36:01,133][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 4.647    Value Loss: 5.343    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 70324      Buffer Size: 15682      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:38:43,175][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 4.271    Value Loss: 5.347    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 70701      Buffer Size: 15706      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:41:25,776][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 4.701    Value Loss: 5.615    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 71082      Buffer Size: 15729      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:44:07,505][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 5.857    Value Loss: 5.606    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 71479      Buffer Size: 15748      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:46:51,095][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.776    [weighted Loss:2.776    Policy Loss: 4.669    Value Loss: 5.591    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 71843      Buffer Size: 15776      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:49:33,784][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 5.080    Value Loss: 5.978    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 72233      Buffer Size: 15808      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:52:16,152][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 5.022    Value Loss: 5.697    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 72604      Buffer Size: 15840      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:54:57,862][train][INFO][train.py>_log] ==> #168000     Total Loss: 3.245    [weighted Loss:3.245    Policy Loss: 5.365    Value Loss: 5.465    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 72968      Buffer Size: 15878      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 19:57:39,796][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 4.988    Value Loss: 5.834    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 73312      Buffer Size: 15902      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:00:23,584][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.898    [weighted Loss:2.898    Policy Loss: 5.552    Value Loss: 5.757    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 73701      Buffer Size: 15895      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:03:07,151][train][INFO][train.py>_log] ==> #171000     Total Loss: 2.492    [weighted Loss:2.492    Policy Loss: 4.407    Value Loss: 6.257    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 74177      Buffer Size: 15967      Transition Number: 1000.092k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:05:51,613][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 4.768    Value Loss: 5.406    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 74626      Buffer Size: 16033      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:08:31,970][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.751    [weighted Loss:1.751    Policy Loss: 4.213    Value Loss: 5.331    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 74992      Buffer Size: 16060      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:11:16,478][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 4.802    Value Loss: 5.483    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 75412      Buffer Size: 16106      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:13:56,950][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 4.701    Value Loss: 5.825    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 75798      Buffer Size: 16148      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:16:39,044][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 4.789    Value Loss: 5.855    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 76193      Buffer Size: 16184      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:19:21,493][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 4.549    Value Loss: 5.622    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 76555      Buffer Size: 16209      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:22:05,124][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 4.663    Value Loss: 5.640    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 76952      Buffer Size: 16223      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:24:47,579][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 5.213    Value Loss: 5.457    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 77322      Buffer Size: 16219      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:27:31,066][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 4.248    Value Loss: 5.875    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 77663      Buffer Size: 16207      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:30:11,732][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 4.854    Value Loss: 5.701    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 78015      Buffer Size: 16195      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:32:53,666][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 4.298    Value Loss: 5.423    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 78375      Buffer Size: 16198      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:35:37,263][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 4.305    Value Loss: 5.617    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 78786      Buffer Size: 16197      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:38:19,964][train][INFO][train.py>_log] ==> #184000     Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 4.891    Value Loss: 6.218    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 79159      Buffer Size: 16212      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:41:04,655][train][INFO][train.py>_log] ==> #185000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 4.721    Value Loss: 5.764    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 79548      Buffer Size: 16242      Transition Number: 1000.017k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:43:46,547][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.228    [weighted Loss:2.228    Policy Loss: 4.509    Value Loss: 5.697    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 79953      Buffer Size: 16275      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:46:30,452][train][INFO][train.py>_log] ==> #187000     Total Loss: 1.332    [weighted Loss:1.332    Policy Loss: 4.010    Value Loss: 5.617    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 80386      Buffer Size: 16340      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:49:12,424][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 4.320    Value Loss: 5.828    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 80804      Buffer Size: 16364      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:51:54,654][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 4.541    Value Loss: 5.894    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 81354      Buffer Size: 16544      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:54:37,820][train][INFO][train.py>_log] ==> #190000     Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 4.238    Value Loss: 5.909    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 81960      Buffer Size: 16770      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 20:57:19,973][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 4.398    Value Loss: 5.822    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 82486      Buffer Size: 16895      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:00:03,146][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 4.357    Value Loss: 5.493    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 82959      Buffer Size: 16996      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:02:44,344][train][INFO][train.py>_log] ==> #193000     Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 4.674    Value Loss: 6.065    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 83445      Buffer Size: 17120      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:05:28,025][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 4.453    Value Loss: 6.263    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 83959      Buffer Size: 17282      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:08:10,001][train][INFO][train.py>_log] ==> #195000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 4.134    Value Loss: 5.620    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 84368      Buffer Size: 17348      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:10:50,055][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 4.740    Value Loss: 5.640    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 84808      Buffer Size: 17416      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:13:32,139][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 4.859    Value Loss: 5.863    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 85166      Buffer Size: 17434      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:16:12,873][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 4.754    Value Loss: 5.926    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 85572      Buffer Size: 17424      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:18:55,706][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 4.348    Value Loss: 5.443    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 85959      Buffer Size: 17415      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:21:38,752][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 4.158    Value Loss: 5.580    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 86329      Buffer Size: 17378      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:24:22,394][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 4.340    Value Loss: 6.071    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 86696      Buffer Size: 17351      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:27:05,751][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 4.509    Value Loss: 5.942    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 87064      Buffer Size: 17337      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:29:48,751][train][INFO][train.py>_log] ==> #203000     Total Loss: 1.494    [weighted Loss:1.494    Policy Loss: 4.279    Value Loss: 5.736    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 87458      Buffer Size: 17342      Transition Number: 1000.184k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:32:32,300][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 4.503    Value Loss: 5.525    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 87835      Buffer Size: 17335      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:35:17,562][train][INFO][train.py>_log] ==> #205000     Total Loss: 1.313    [weighted Loss:1.313    Policy Loss: 4.143    Value Loss: 5.473    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 88459      Buffer Size: 17591      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:37:58,867][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 4.277    Value Loss: 5.709    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 89077      Buffer Size: 17814      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:40:39,512][train][INFO][train.py>_log] ==> #207000     Total Loss: 0.935    [weighted Loss:0.935    Policy Loss: 4.836    Value Loss: 5.953    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 89456      Buffer Size: 17835      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:43:22,371][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 4.562    Value Loss: 5.820    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 89886      Buffer Size: 17851      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:46:05,582][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 4.748    Value Loss: 5.684    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 90238      Buffer Size: 17840      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:48:46,581][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 5.116    Value Loss: 5.730    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 90604      Buffer Size: 17837      Transition Number: 1000.092k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:51:27,507][train][INFO][train.py>_log] ==> #211000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 4.433    Value Loss: 5.667    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 90975      Buffer Size: 17834      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:54:08,867][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.386    [weighted Loss:1.386    Policy Loss: 4.672    Value Loss: 5.793    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 91361      Buffer Size: 17842      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:56:52,937][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 4.401    Value Loss: 6.070    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 91735      Buffer Size: 17849      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 21:59:35,435][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 5.264    Value Loss: 5.764    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 92129      Buffer Size: 17779      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:02:15,610][train][INFO][train.py>_log] ==> #215000     Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 4.879    Value Loss: 5.995    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 92494      Buffer Size: 17730      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:05:00,482][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 4.711    Value Loss: 5.463    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 92899      Buffer Size: 17733      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:07:42,975][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 4.595    Value Loss: 5.855    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 93292      Buffer Size: 17733      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:10:25,423][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 5.013    Value Loss: 6.221    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 93668      Buffer Size: 17745      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:13:06,245][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 5.058    Value Loss: 5.797    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 94316      Buffer Size: 17967      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:15:47,742][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.228    [weighted Loss:2.228    Policy Loss: 4.535    Value Loss: 5.898    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 94939      Buffer Size: 18218      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:18:29,673][train][INFO][train.py>_log] ==> #221000     Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 4.907    Value Loss: 5.997    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 95346      Buffer Size: 18298      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:21:11,665][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.989    [weighted Loss:1.989    Policy Loss: 4.512    Value Loss: 6.103    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 95792      Buffer Size: 18384      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:23:53,886][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.200    [weighted Loss:2.200    Policy Loss: 4.950    Value Loss: 5.903    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 96156      Buffer Size: 18403      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:26:35,534][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 5.065    Value Loss: 5.940    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 96543      Buffer Size: 18429      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:29:18,432][train][INFO][train.py>_log] ==> #225000     Total Loss: 3.006    [weighted Loss:3.006    Policy Loss: 5.223    Value Loss: 5.929    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 96915      Buffer Size: 18453      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:32:01,102][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 5.108    Value Loss: 5.681    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 97301      Buffer Size: 18469      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:34:41,537][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.690    [weighted Loss:2.690    Policy Loss: 5.993    Value Loss: 5.921    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 97694      Buffer Size: 18509      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:37:26,769][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 5.511    Value Loss: 6.373    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 98137      Buffer Size: 18517      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:40:09,750][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.232    [weighted Loss:2.232    Policy Loss: 5.610    Value Loss: 6.098    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 98547      Buffer Size: 18546      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:42:50,122][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 4.883    Value Loss: 5.930    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 98967      Buffer Size: 18543      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:45:31,389][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 5.674    Value Loss: 6.282    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 99398      Buffer Size: 18569      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:48:15,405][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.600    [weighted Loss:2.600    Policy Loss: 5.331    Value Loss: 6.243    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 99862      Buffer Size: 18419      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:50:56,702][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 5.898    Value Loss: 6.065    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 100243     Buffer Size: 18222      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:53:36,830][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.785    [weighted Loss:2.785    Policy Loss: 5.098    Value Loss: 5.775    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 100610     Buffer Size: 18116      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:56:18,298][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 5.569    Value Loss: 6.340    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 100990     Buffer Size: 18036      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 22:58:59,224][train][INFO][train.py>_log] ==> #236000     Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 5.758    Value Loss: 6.480    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 101371     Buffer Size: 17952      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:01:41,145][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.524    [weighted Loss:2.524    Policy Loss: 6.210    Value Loss: 6.278    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 101772     Buffer Size: 17863      Transition Number: 1000.128k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:04:23,810][train][INFO][train.py>_log] ==> #238000     Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 5.954    Value Loss: 6.101    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 102180     Buffer Size: 17833      Transition Number: 1000.065k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:07:07,788][train][INFO][train.py>_log] ==> #239000     Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 5.784    Value Loss: 6.475    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 102598     Buffer Size: 17825      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:09:51,328][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.320    [weighted Loss:3.320    Policy Loss: 5.673    Value Loss: 6.259    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 103020     Buffer Size: 17876      Transition Number: 1000.158k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:12:33,758][train][INFO][train.py>_log] ==> #241000     Total Loss: 3.176    [weighted Loss:3.176    Policy Loss: 7.158    Value Loss: 6.449    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 103407     Buffer Size: 17900      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:15:17,073][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 5.662    Value Loss: 6.609    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 103835     Buffer Size: 17948      Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:17:57,193][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 5.860    Value Loss: 6.369    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 104244     Buffer Size: 18013      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:20:40,592][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 5.389    Value Loss: 6.045    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 104652     Buffer Size: 18085      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:23:25,003][train][INFO][train.py>_log] ==> #245000     Total Loss: 3.146    [weighted Loss:3.146    Policy Loss: 5.760    Value Loss: 6.044    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 105040     Buffer Size: 18127      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:26:07,334][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.340    [weighted Loss:2.340    Policy Loss: 6.226    Value Loss: 6.325    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 105476     Buffer Size: 18168      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:28:50,415][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 5.971    Value Loss: 6.251    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 106093     Buffer Size: 18435      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:31:33,096][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 5.736    Value Loss: 6.471    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 106747     Buffer Size: 18629      Transition Number: 1000.047k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:34:17,374][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 6.525    Value Loss: 6.581    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 107328     Buffer Size: 18603      Transition Number: 1000.002k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:36:58,350][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.302    [weighted Loss:3.302    Policy Loss: 5.854    Value Loss: 6.362    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 107884     Buffer Size: 18647      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:39:39,077][train][INFO][train.py>_log] ==> #251000     Total Loss: 3.765    [weighted Loss:3.765    Policy Loss: 6.297    Value Loss: 6.237    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 108347     Buffer Size: 18713      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:42:22,626][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 5.824    Value Loss: 6.017    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 108819     Buffer Size: 18788      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:45:05,432][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 6.602    Value Loss: 6.026    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 109267     Buffer Size: 18876      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:47:47,219][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 5.965    Value Loss: 6.853    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 109729     Buffer Size: 18979      Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:50:27,515][train][INFO][train.py>_log] ==> #255000     Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 6.092    Value Loss: 6.223    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 110245     Buffer Size: 19122      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:53:08,975][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 6.208    Value Loss: 6.455    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 110771     Buffer Size: 19279      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:55:52,364][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.105    [weighted Loss:2.105    Policy Loss: 6.544    Value Loss: 6.577    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 111394     Buffer Size: 19520      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-05 23:58:33,919][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 6.634    Value Loss: 6.550    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 112026     Buffer Size: 19785      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:01:13,059][train][INFO][train.py>_log] ==> #259000     Total Loss: 3.483    [weighted Loss:3.483    Policy Loss: 6.735    Value Loss: 6.506    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 112640     Buffer Size: 20030      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:03:54,011][train][INFO][train.py>_log] ==> #260000     Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 6.536    Value Loss: 6.310    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 113219     Buffer Size: 20228      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:06:36,978][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 5.849    Value Loss: 6.629    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 113631     Buffer Size: 20284      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:09:20,035][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 6.016    Value Loss: 6.781    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 114060     Buffer Size: 20317      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:12:01,998][train][INFO][train.py>_log] ==> #263000     Total Loss: 3.018    [weighted Loss:3.018    Policy Loss: 6.678    Value Loss: 7.051    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 114462     Buffer Size: 20102      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:14:42,973][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 6.445    Value Loss: 6.066    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 114886     Buffer Size: 19905      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:17:24,398][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.916    [weighted Loss:2.916    Policy Loss: 6.032    Value Loss: 6.632    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 115286     Buffer Size: 19885      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:20:07,712][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.328    [weighted Loss:1.328    Policy Loss: 6.035    Value Loss: 6.377    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 115705     Buffer Size: 19883      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:22:49,190][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 6.149    Value Loss: 5.884    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 116170     Buffer Size: 19980      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:25:28,805][train][INFO][train.py>_log] ==> #268000     Total Loss: 3.219    [weighted Loss:3.219    Policy Loss: 5.817    Value Loss: 6.746    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 116608     Buffer Size: 20061      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:28:08,161][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 6.453    Value Loss: 6.264    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 117002     Buffer Size: 20099      Transition Number: 1000.173k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:30:48,994][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 6.376    Value Loss: 6.713    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 117408     Buffer Size: 20130      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:33:29,039][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.926    [weighted Loss:2.926    Policy Loss: 6.344    Value Loss: 6.558    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 117926     Buffer Size: 20247      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:36:08,473][train][INFO][train.py>_log] ==> #272000     Total Loss: 1.826    [weighted Loss:1.826    Policy Loss: 6.167    Value Loss: 6.595    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 118402     Buffer Size: 20327      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:38:49,293][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 6.245    Value Loss: 6.829    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 118807     Buffer Size: 20343      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:41:32,305][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 6.052    Value Loss: 6.352    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 119287     Buffer Size: 20361      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:44:13,687][train][INFO][train.py>_log] ==> #275000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 6.530    Value Loss: 6.711    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 119726     Buffer Size: 20366      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:46:55,184][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 6.218    Value Loss: 6.602    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 120159     Buffer Size: 20368      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:49:35,959][train][INFO][train.py>_log] ==> #277000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 6.360    Value Loss: 6.255    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 120533     Buffer Size: 20368      Transition Number: 1000.267k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:52:20,374][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.771    [weighted Loss:2.771    Policy Loss: 6.012    Value Loss: 6.550    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 120898     Buffer Size: 20357      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:55:01,849][train][INFO][train.py>_log] ==> #279000     Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 6.218    Value Loss: 6.042    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 121291     Buffer Size: 20345      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 00:57:42,649][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.485    [weighted Loss:1.485    Policy Loss: 5.717    Value Loss: 6.414    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 121676     Buffer Size: 20328      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:00:25,587][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 5.551    Value Loss: 6.599    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 122066     Buffer Size: 20329      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:03:09,787][train][INFO][train.py>_log] ==> #282000     Total Loss: 3.231    [weighted Loss:3.231    Policy Loss: 6.633    Value Loss: 6.582    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 122497     Buffer Size: 20328      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:05:52,575][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 5.924    Value Loss: 6.578    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 122946     Buffer Size: 20338      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:08:37,303][train][INFO][train.py>_log] ==> #284000     Total Loss: 3.504    [weighted Loss:3.504    Policy Loss: 6.371    Value Loss: 6.508    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 123356     Buffer Size: 20337      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:11:19,428][train][INFO][train.py>_log] ==> #285000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 6.171    Value Loss: 6.277    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 123737     Buffer Size: 20326      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:14:00,807][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.155    Value Loss: 6.603    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 124117     Buffer Size: 20303      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:16:43,615][train][INFO][train.py>_log] ==> #287000     Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 6.439    Value Loss: 7.059    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 124540     Buffer Size: 20297      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:19:25,128][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.933    [weighted Loss:1.933    Policy Loss: 6.890    Value Loss: 6.249    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 124964     Buffer Size: 20283      Transition Number: 1000.117k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:22:09,683][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.647    [weighted Loss:2.647    Policy Loss: 6.254    Value Loss: 6.607    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 125741     Buffer Size: 20663      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:24:48,218][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 6.251    Value Loss: 6.600    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 126510     Buffer Size: 21042      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:27:29,453][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.429    [weighted Loss:2.429    Policy Loss: 6.204    Value Loss: 6.533    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 126975     Buffer Size: 20890      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:30:11,113][train][INFO][train.py>_log] ==> #292000     Total Loss: 3.259    [weighted Loss:3.259    Policy Loss: 6.964    Value Loss: 6.340    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 127456     Buffer Size: 20745      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:32:52,668][train][INFO][train.py>_log] ==> #293000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 6.730    Value Loss: 6.281    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 127901     Buffer Size: 20627      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:35:35,918][train][INFO][train.py>_log] ==> #294000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 7.563    Value Loss: 6.142    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 128347     Buffer Size: 20497      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:38:18,555][train][INFO][train.py>_log] ==> #295000     Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 5.957    Value Loss: 6.409    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 128909     Buffer Size: 20544      Transition Number: 1000.039k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:40:59,524][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.936    [weighted Loss:2.936    Policy Loss: 6.873    Value Loss: 6.532    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 129451     Buffer Size: 20618      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:43:39,990][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.483    [weighted Loss:3.483    Policy Loss: 6.763    Value Loss: 6.891    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 130063     Buffer Size: 20779      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:46:19,482][train][INFO][train.py>_log] ==> #298000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 6.370    Value Loss: 6.629    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 130685     Buffer Size: 20939      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:49:01,221][train][INFO][train.py>_log] ==> #299000     Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 7.026    Value Loss: 6.233    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 131180     Buffer Size: 20934      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:51:40,346][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 6.842    Value Loss: 6.962    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 131673     Buffer Size: 20901      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:54:21,569][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 6.812    Value Loss: 6.737    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 132137     Buffer Size: 20750      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:57:01,835][train][INFO][train.py>_log] ==> #302000     Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 7.001    Value Loss: 6.604    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 132600     Buffer Size: 20583      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 01:59:43,593][train][INFO][train.py>_log] ==> #303000     Total Loss: 3.830    [weighted Loss:3.830    Policy Loss: 7.732    Value Loss: 6.405    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 133175     Buffer Size: 20536      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:02:22,052][train][INFO][train.py>_log] ==> #304000     Total Loss: 5.354    [weighted Loss:5.354    Policy Loss: 8.874    Value Loss: 6.841    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 133764     Buffer Size: 20551      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:05:03,263][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.460    [weighted Loss:2.460    Policy Loss: 7.097    Value Loss: 6.584    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 134383     Buffer Size: 20756      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:07:42,878][train][INFO][train.py>_log] ==> #306000     Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 7.321    Value Loss: 6.999    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 135041     Buffer Size: 20976      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:10:21,913][train][INFO][train.py>_log] ==> #307000     Total Loss: 4.357    [weighted Loss:4.357    Policy Loss: 7.069    Value Loss: 6.754    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 135532     Buffer Size: 21070      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:13:02,596][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.660    [weighted Loss:2.660    Policy Loss: 6.228    Value Loss: 6.723    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 136004     Buffer Size: 21131      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:15:43,867][train][INFO][train.py>_log] ==> #309000     Total Loss: 3.936    [weighted Loss:3.936    Policy Loss: 7.460    Value Loss: 7.268    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 136427     Buffer Size: 21135      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:18:23,528][train][INFO][train.py>_log] ==> #310000     Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 7.072    Value Loss: 6.745    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 136832     Buffer Size: 21127      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:21:06,552][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.137    [weighted Loss:2.137    Policy Loss: 6.314    Value Loss: 6.167    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 137260     Buffer Size: 21076      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:23:45,641][train][INFO][train.py>_log] ==> #312000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 6.318    Value Loss: 6.750    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 137675     Buffer Size: 21032      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:26:26,674][train][INFO][train.py>_log] ==> #313000     Total Loss: 1.666    [weighted Loss:1.666    Policy Loss: 7.269    Value Loss: 6.696    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 138160     Buffer Size: 21126      Transition Number: 1000.107k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:29:09,403][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 6.168    Value Loss: 7.179    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 138697     Buffer Size: 21230      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:31:49,296][train][INFO][train.py>_log] ==> #315000     Total Loss: 3.001    [weighted Loss:3.001    Policy Loss: 7.021    Value Loss: 6.462    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 139128     Buffer Size: 21162      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:34:31,021][train][INFO][train.py>_log] ==> #316000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 6.491    Value Loss: 6.576    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 139589     Buffer Size: 21143      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:37:12,898][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 6.351    Value Loss: 6.713    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 140327     Buffer Size: 21442      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:39:49,987][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 6.687    Value Loss: 6.742    Reward Loss: 1.261    Consistency Loss: 0.000    ] Replay Episodes Collected: 141012     Buffer Size: 21694      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:42:29,243][train][INFO][train.py>_log] ==> #319000     Total Loss: 3.867    [weighted Loss:3.867    Policy Loss: 6.919    Value Loss: 6.873    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 141452     Buffer Size: 21716      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:45:07,396][train][INFO][train.py>_log] ==> #320000     Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 6.560    Value Loss: 6.796    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 141885     Buffer Size: 21717      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:47:50,094][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.949    [weighted Loss:2.949    Policy Loss: 6.406    Value Loss: 6.806    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 142293     Buffer Size: 21746      Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:50:27,686][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 7.013    Value Loss: 6.746    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 142712     Buffer Size: 21818      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:53:08,209][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 7.489    Value Loss: 6.336    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 143120     Buffer Size: 21862      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:55:48,274][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 7.553    Value Loss: 6.815    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 143544     Buffer Size: 21907      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 02:58:27,468][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.776    [weighted Loss:2.776    Policy Loss: 6.335    Value Loss: 6.109    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 143955     Buffer Size: 21947      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:01:08,115][train][INFO][train.py>_log] ==> #326000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 7.373    Value Loss: 6.555    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 144408     Buffer Size: 21985      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:03:48,427][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 7.818    Value Loss: 6.589    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 144827     Buffer Size: 22001      Transition Number: 1000.020k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:06:30,643][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 7.895    Value Loss: 6.622    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 145260     Buffer Size: 22014      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:09:12,864][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 6.903    Value Loss: 6.931    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 145705     Buffer Size: 22069      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:11:53,569][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 7.960    Value Loss: 6.592    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 146140     Buffer Size: 22127      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:14:34,184][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 7.852    Value Loss: 6.690    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 146563     Buffer Size: 22137      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:17:14,714][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 6.566    Value Loss: 6.192    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 146992     Buffer Size: 22132      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:19:58,662][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.438    [weighted Loss:3.438    Policy Loss: 7.219    Value Loss: 6.856    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 147504     Buffer Size: 21999      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:22:40,380][train][INFO][train.py>_log] ==> #334000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 7.365    Value Loss: 6.955    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 148048     Buffer Size: 21722      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:25:22,649][train][INFO][train.py>_log] ==> #335000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 7.477    Value Loss: 6.849    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 148503     Buffer Size: 21652      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:28:02,632][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 8.299    Value Loss: 7.321    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 148971     Buffer Size: 21647      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:30:42,904][train][INFO][train.py>_log] ==> #337000     Total Loss: 4.298    [weighted Loss:4.298    Policy Loss: 7.508    Value Loss: 6.792    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 149492     Buffer Size: 21707      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:33:22,572][train][INFO][train.py>_log] ==> #338000     Total Loss: 4.204    [weighted Loss:4.204    Policy Loss: 8.451    Value Loss: 6.998    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 150037     Buffer Size: 21801      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:36:04,568][train][INFO][train.py>_log] ==> #339000     Total Loss: 4.281    [weighted Loss:4.281    Policy Loss: 9.251    Value Loss: 6.792    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 150498     Buffer Size: 21768      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:38:46,334][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 8.446    Value Loss: 6.885    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 150942     Buffer Size: 21709      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:41:27,524][train][INFO][train.py>_log] ==> #341000     Total Loss: 5.165    [weighted Loss:5.165    Policy Loss: 9.797    Value Loss: 6.930    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 151389     Buffer Size: 21601      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:44:11,918][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 8.518    Value Loss: 6.593    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 151851     Buffer Size: 21448      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:46:53,360][train][INFO][train.py>_log] ==> #343000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 8.960    Value Loss: 7.134    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 152358     Buffer Size: 21353      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:49:34,141][train][INFO][train.py>_log] ==> #344000     Total Loss: 4.942    [weighted Loss:4.942    Policy Loss: 10.061   Value Loss: 7.028    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 152838     Buffer Size: 21342      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:52:15,650][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.745    [weighted Loss:3.745    Policy Loss: 8.247    Value Loss: 6.624    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 153677     Buffer Size: 21678      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:54:54,919][train][INFO][train.py>_log] ==> #346000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 8.345    Value Loss: 7.224    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 154585     Buffer Size: 22102      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-01-06 03:57:35,571][train][INFO][train.py>_log] ==> #347000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 8.594    Value Loss: 7.304    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 155261     Buffer Size: 22223      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:00:14,693][train][INFO][train.py>_log] ==> #348000     Total Loss: 3.848    [weighted Loss:3.848    Policy Loss: 8.135    Value Loss: 6.749    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 155948     Buffer Size: 22314      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:02:53,338][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.419    [weighted Loss:3.419    Policy Loss: 7.446    Value Loss: 7.347    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 156561     Buffer Size: 22285      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:05:33,787][train][INFO][train.py>_log] ==> #350000     Total Loss: 3.223    [weighted Loss:3.223    Policy Loss: 7.991    Value Loss: 7.113    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 157173     Buffer Size: 22241      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:08:14,545][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.976    [weighted Loss:3.976    Policy Loss: 7.445    Value Loss: 7.040    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 157775     Buffer Size: 22276      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:10:59,127][train][INFO][train.py>_log] ==> #352000     Total Loss: 4.172    [weighted Loss:4.172    Policy Loss: 7.781    Value Loss: 6.547    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 158389     Buffer Size: 22391      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:13:37,217][train][INFO][train.py>_log] ==> #353000     Total Loss: 3.195    [weighted Loss:3.195    Policy Loss: 7.399    Value Loss: 7.075    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 159030     Buffer Size: 22617      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:16:15,146][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.707    [weighted Loss:2.707    Policy Loss: 7.453    Value Loss: 6.852    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 159674     Buffer Size: 22845      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:18:54,531][train][INFO][train.py>_log] ==> #355000     Total Loss: 3.346    [weighted Loss:3.346    Policy Loss: 7.986    Value Loss: 6.799    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 160365     Buffer Size: 23119      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:21:31,316][train][INFO][train.py>_log] ==> #356000     Total Loss: 3.702    [weighted Loss:3.702    Policy Loss: 8.271    Value Loss: 7.370    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 161049     Buffer Size: 23401      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:24:10,637][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 7.562    Value Loss: 7.155    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 161731     Buffer Size: 23593      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:26:50,074][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 8.349    Value Loss: 7.467    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 162459     Buffer Size: 23779      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:29:27,467][train][INFO][train.py>_log] ==> #359000     Total Loss: 4.621    [weighted Loss:4.621    Policy Loss: 8.804    Value Loss: 6.869    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 163188     Buffer Size: 24042      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:32:06,607][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 8.224    Value Loss: 7.159    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 163938     Buffer Size: 24293      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:34:46,586][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 8.603    Value Loss: 7.122    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 164594     Buffer Size: 24230      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:37:26,683][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 8.286    Value Loss: 7.198    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 165289     Buffer Size: 24214      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:40:06,185][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.497    [weighted Loss:3.497    Policy Loss: 8.933    Value Loss: 7.432    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 165948     Buffer Size: 24415      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:42:44,063][train][INFO][train.py>_log] ==> #364000     Total Loss: 3.752    [weighted Loss:3.752    Policy Loss: 8.749    Value Loss: 7.064    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 166599     Buffer Size: 24617      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:45:23,210][train][INFO][train.py>_log] ==> #365000     Total Loss: 4.965    [weighted Loss:4.965    Policy Loss: 9.234    Value Loss: 7.289    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 167381     Buffer Size: 24967      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:47:59,485][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 9.255    Value Loss: 7.705    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 168190     Buffer Size: 25335      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:50:36,196][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.676    [weighted Loss:2.676    Policy Loss: 9.275    Value Loss: 7.386    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 168984     Buffer Size: 25706      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:53:09,865][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 9.268    Value Loss: 7.584    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 169780     Buffer Size: 26064      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:55:44,536][train][INFO][train.py>_log] ==> #369000     Total Loss: 3.789    [weighted Loss:3.789    Policy Loss: 9.031    Value Loss: 7.149    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 170244     Buffer Size: 26148      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 04:58:19,620][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 8.433    Value Loss: 7.301    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 170727     Buffer Size: 26198      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:00:59,127][train][INFO][train.py>_log] ==> #371000     Total Loss: 3.226    [weighted Loss:3.226    Policy Loss: 9.434    Value Loss: 7.019    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 171205     Buffer Size: 26247      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:03:38,052][train][INFO][train.py>_log] ==> #372000     Total Loss: 3.722    [weighted Loss:3.722    Policy Loss: 8.527    Value Loss: 7.114    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 171682     Buffer Size: 26305      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:06:14,498][train][INFO][train.py>_log] ==> #373000     Total Loss: 4.234    [weighted Loss:4.234    Policy Loss: 9.477    Value Loss: 7.367    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 172179     Buffer Size: 26382      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:08:51,459][train][INFO][train.py>_log] ==> #374000     Total Loss: 4.632    [weighted Loss:4.632    Policy Loss: 8.886    Value Loss: 7.689    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 172689     Buffer Size: 26459      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:11:29,070][train][INFO][train.py>_log] ==> #375000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 9.316    Value Loss: 7.345    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 173269     Buffer Size: 26611      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:14:07,040][train][INFO][train.py>_log] ==> #376000     Total Loss: 3.917    [weighted Loss:3.917    Policy Loss: 9.784    Value Loss: 7.407    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 173839     Buffer Size: 26758      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:16:43,751][train][INFO][train.py>_log] ==> #377000     Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 9.619    Value Loss: 7.381    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 174828     Buffer Size: 27209      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:19:20,085][train][INFO][train.py>_log] ==> #378000     Total Loss: 3.346    [weighted Loss:3.346    Policy Loss: 9.129    Value Loss: 6.993    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 175890     Buffer Size: 27730      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:21:55,851][train][INFO][train.py>_log] ==> #379000     Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 9.187    Value Loss: 7.213    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 176487     Buffer Size: 27887      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:24:29,461][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 8.837    Value Loss: 7.126    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 177075     Buffer Size: 28011      Transition Number: 1000.036k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:27:10,104][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 10.023   Value Loss: 7.593    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 177675     Buffer Size: 28086      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:29:47,970][train][INFO][train.py>_log] ==> #382000     Total Loss: 4.421    [weighted Loss:4.421    Policy Loss: 9.655    Value Loss: 7.423    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 178286     Buffer Size: 28148      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:32:23,207][train][INFO][train.py>_log] ==> #383000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 9.528    Value Loss: 7.518    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 178741     Buffer Size: 28177      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:34:58,858][train][INFO][train.py>_log] ==> #384000     Total Loss: 3.084    [weighted Loss:3.084    Policy Loss: 9.131    Value Loss: 7.152    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 179208     Buffer Size: 28200      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:37:38,640][train][INFO][train.py>_log] ==> #385000     Total Loss: 4.950    [weighted Loss:4.950    Policy Loss: 9.871    Value Loss: 7.231    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 179715     Buffer Size: 28267      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:40:16,363][train][INFO][train.py>_log] ==> #386000     Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 9.153    Value Loss: 7.600    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 180239     Buffer Size: 28333      Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:42:53,229][train][INFO][train.py>_log] ==> #387000     Total Loss: 4.508    [weighted Loss:4.508    Policy Loss: 8.859    Value Loss: 7.320    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 180883     Buffer Size: 28495      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:45:30,874][train][INFO][train.py>_log] ==> #388000     Total Loss: 3.860    [weighted Loss:3.860    Policy Loss: 9.349    Value Loss: 7.167    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 181542     Buffer Size: 28678      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:48:08,055][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 8.863    Value Loss: 7.256    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 182141     Buffer Size: 28497      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:50:48,615][train][INFO][train.py>_log] ==> #390000     Total Loss: 3.192    [weighted Loss:3.192    Policy Loss: 10.281   Value Loss: 7.119    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 182756     Buffer Size: 28247      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:53:26,591][train][INFO][train.py>_log] ==> #391000     Total Loss: 5.571    [weighted Loss:5.571    Policy Loss: 10.683   Value Loss: 7.233    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 183302     Buffer Size: 28124      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:56:06,642][train][INFO][train.py>_log] ==> #392000     Total Loss: 4.949    [weighted Loss:4.949    Policy Loss: 10.592   Value Loss: 7.291    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 183878     Buffer Size: 28025      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-01-06 05:58:45,900][train][INFO][train.py>_log] ==> #393000     Total Loss: 4.232    [weighted Loss:4.232    Policy Loss: 9.760    Value Loss: 7.436    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 184421     Buffer Size: 27969      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:01:22,491][train][INFO][train.py>_log] ==> #394000     Total Loss: 5.106    [weighted Loss:5.106    Policy Loss: 10.745   Value Loss: 7.098    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 184967     Buffer Size: 27916      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:04:01,924][train][INFO][train.py>_log] ==> #395000     Total Loss: 4.949    [weighted Loss:4.949    Policy Loss: 9.621    Value Loss: 7.178    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 185632     Buffer Size: 28020      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:06:41,503][train][INFO][train.py>_log] ==> #396000     Total Loss: 3.034    [weighted Loss:3.034    Policy Loss: 10.598   Value Loss: 7.486    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 186313     Buffer Size: 28080      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:09:16,138][train][INFO][train.py>_log] ==> #397000     Total Loss: 4.372    [weighted Loss:4.372    Policy Loss: 9.146    Value Loss: 7.687    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 186853     Buffer Size: 28032      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:11:55,739][train][INFO][train.py>_log] ==> #398000     Total Loss: 3.104    [weighted Loss:3.104    Policy Loss: 10.099   Value Loss: 7.222    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 187444     Buffer Size: 27991      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:14:33,857][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.904    [weighted Loss:3.904    Policy Loss: 9.919    Value Loss: 7.305    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 188013     Buffer Size: 27881      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:17:08,962][train][INFO][train.py>_log] ==> #400000     Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 9.996    Value Loss: 7.383    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 188534     Buffer Size: 27780      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:19:43,910][train][INFO][train.py>_log] ==> #401000     Total Loss: 4.885    [weighted Loss:4.885    Policy Loss: 9.702    Value Loss: 7.368    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 189112     Buffer Size: 27691      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:22:22,073][train][INFO][train.py>_log] ==> #402000     Total Loss: 3.498    [weighted Loss:3.498    Policy Loss: 9.299    Value Loss: 7.230    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 189696     Buffer Size: 27596      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:25:00,470][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 9.533    Value Loss: 7.651    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 190261     Buffer Size: 27475      Transition Number: 1000.023k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:27:41,769][train][INFO][train.py>_log] ==> #404000     Total Loss: 3.920    [weighted Loss:3.920    Policy Loss: 9.077    Value Loss: 7.140    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 190814     Buffer Size: 27290      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:30:21,324][train][INFO][train.py>_log] ==> #405000     Total Loss: 3.811    [weighted Loss:3.811    Policy Loss: 9.247    Value Loss: 7.458    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 191261     Buffer Size: 27096      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:32:59,771][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 8.545    Value Loss: 7.629    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 191709     Buffer Size: 26917      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:35:40,293][train][INFO][train.py>_log] ==> #407000     Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 8.829    Value Loss: 7.656    Reward Loss: 1.274    Consistency Loss: 0.000    ] Replay Episodes Collected: 192498     Buffer Size: 26969      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:38:19,393][train][INFO][train.py>_log] ==> #408000     Total Loss: 4.420    [weighted Loss:4.420    Policy Loss: 8.912    Value Loss: 7.444    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 193271     Buffer Size: 27099      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:40:57,780][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.034    [weighted Loss:2.034    Policy Loss: 7.754    Value Loss: 6.928    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 193907     Buffer Size: 27090      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:43:34,639][train][INFO][train.py>_log] ==> #410000     Total Loss: 3.258    [weighted Loss:3.258    Policy Loss: 8.564    Value Loss: 7.590    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 194569     Buffer Size: 26971      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:46:14,181][train][INFO][train.py>_log] ==> #411000     Total Loss: 3.301    [weighted Loss:3.301    Policy Loss: 7.975    Value Loss: 7.082    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 195115     Buffer Size: 26770      Transition Number: 1000.024k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:48:54,953][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 9.396    Value Loss: 7.576    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 195664     Buffer Size: 26526      Transition Number: 1000.005k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:51:35,002][train][INFO][train.py>_log] ==> #413000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 8.496    Value Loss: 7.062    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 196151     Buffer Size: 26262      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:54:14,433][train][INFO][train.py>_log] ==> #414000     Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 8.118    Value Loss: 7.242    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 196641     Buffer Size: 26263      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:56:51,127][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.890    [weighted Loss:2.890    Policy Loss: 8.588    Value Loss: 7.492    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 197331     Buffer Size: 26447      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-01-06 06:59:28,644][train][INFO][train.py>_log] ==> #416000     Total Loss: 3.710    [weighted Loss:3.710    Policy Loss: 8.599    Value Loss: 7.692    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 198019     Buffer Size: 26637      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:02:07,154][train][INFO][train.py>_log] ==> #417000     Total Loss: 4.835    [weighted Loss:4.835    Policy Loss: 8.732    Value Loss: 6.989    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 198770     Buffer Size: 26917      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:04:46,062][train][INFO][train.py>_log] ==> #418000     Total Loss: 4.165    [weighted Loss:4.165    Policy Loss: 9.769    Value Loss: 7.193    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 199539     Buffer Size: 27143      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:07:25,166][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 8.091    Value Loss: 7.342    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 200320     Buffer Size: 27373      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:10:05,269][train][INFO][train.py>_log] ==> #420000     Total Loss: 3.583    [weighted Loss:3.583    Policy Loss: 10.125   Value Loss: 7.758    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 201106     Buffer Size: 27565      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:12:43,305][train][INFO][train.py>_log] ==> #421000     Total Loss: 3.863    [weighted Loss:3.863    Policy Loss: 8.735    Value Loss: 7.078    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 201754     Buffer Size: 27509      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:15:20,869][train][INFO][train.py>_log] ==> #422000     Total Loss: 3.228    [weighted Loss:3.228    Policy Loss: 9.449    Value Loss: 7.547    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 202452     Buffer Size: 27198      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:17:58,127][train][INFO][train.py>_log] ==> #423000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 7.952    Value Loss: 7.036    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 202954     Buffer Size: 26860      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:20:37,981][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 8.801    Value Loss: 7.214    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 203463     Buffer Size: 26770      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:23:16,701][train][INFO][train.py>_log] ==> #425000     Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 8.085    Value Loss: 6.989    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 203816     Buffer Size: 26577      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:25:56,328][train][INFO][train.py>_log] ==> #426000     Total Loss: 4.494    [weighted Loss:4.494    Policy Loss: 7.840    Value Loss: 7.270    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 204174     Buffer Size: 26356      Transition Number: 1000.102k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:28:37,824][train][INFO][train.py>_log] ==> #427000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 8.376    Value Loss: 7.206    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 204662     Buffer Size: 26268      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:31:19,933][train][INFO][train.py>_log] ==> #428000     Total Loss: 3.894    [weighted Loss:3.894    Policy Loss: 7.580    Value Loss: 7.076    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 205206     Buffer Size: 26312      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:33:57,571][train][INFO][train.py>_log] ==> #429000     Total Loss: 4.515    [weighted Loss:4.515    Policy Loss: 7.441    Value Loss: 7.122    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 205588     Buffer Size: 26246      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:36:37,948][train][INFO][train.py>_log] ==> #430000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 7.101    Value Loss: 7.343    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 206010     Buffer Size: 26123      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:39:17,884][train][INFO][train.py>_log] ==> #431000     Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 7.704    Value Loss: 7.167    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 206500     Buffer Size: 26041      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:42:01,845][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.251    [weighted Loss:1.251    Policy Loss: 7.332    Value Loss: 7.313    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 206964     Buffer Size: 25833      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:44:42,130][train][INFO][train.py>_log] ==> #433000     Total Loss: 3.693    [weighted Loss:3.693    Policy Loss: 8.229    Value Loss: 7.498    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 207408     Buffer Size: 25666      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:47:23,032][train][INFO][train.py>_log] ==> #434000     Total Loss: 2.885    [weighted Loss:2.885    Policy Loss: 6.919    Value Loss: 7.485    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 207881     Buffer Size: 25527      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:50:03,763][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.714    [weighted Loss:2.714    Policy Loss: 7.515    Value Loss: 7.018    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 208274     Buffer Size: 25350      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:52:46,803][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 7.402    Value Loss: 7.075    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 208698     Buffer Size: 25229      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:55:28,088][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 7.487    Value Loss: 6.686    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 209184     Buffer Size: 25147      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-01-06 07:58:07,565][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.721    [weighted Loss:2.721    Policy Loss: 7.118    Value Loss: 7.064    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 209673     Buffer Size: 25108      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:00:47,751][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 7.882    Value Loss: 7.526    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 210209     Buffer Size: 25051      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:03:28,609][train][INFO][train.py>_log] ==> #440000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 7.263    Value Loss: 7.093    Reward Loss: 1.270    Consistency Loss: 0.000    ] Replay Episodes Collected: 210758     Buffer Size: 24929      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:06:07,269][train][INFO][train.py>_log] ==> #441000     Total Loss: 4.224    [weighted Loss:4.224    Policy Loss: 7.555    Value Loss: 7.494    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 211296     Buffer Size: 24882      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:08:49,431][train][INFO][train.py>_log] ==> #442000     Total Loss: 3.964    [weighted Loss:3.964    Policy Loss: 7.628    Value Loss: 7.129    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 211886     Buffer Size: 24856      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:11:28,902][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.410    [weighted Loss:3.410    Policy Loss: 7.488    Value Loss: 7.484    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 212454     Buffer Size: 24830      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:14:10,203][train][INFO][train.py>_log] ==> #444000     Total Loss: 3.612    [weighted Loss:3.612    Policy Loss: 7.681    Value Loss: 7.388    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 213008     Buffer Size: 24812      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:16:51,733][train][INFO][train.py>_log] ==> #445000     Total Loss: 1.881    [weighted Loss:1.881    Policy Loss: 7.377    Value Loss: 7.001    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 213498     Buffer Size: 24744      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:19:31,000][train][INFO][train.py>_log] ==> #446000     Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 7.643    Value Loss: 7.023    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 214002     Buffer Size: 24674      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:22:12,606][train][INFO][train.py>_log] ==> #447000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 8.074    Value Loss: 7.057    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 214543     Buffer Size: 24611      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:24:52,772][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 7.479    Value Loss: 7.591    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 215049     Buffer Size: 24557      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:27:34,513][train][INFO][train.py>_log] ==> #449000     Total Loss: 3.264    [weighted Loss:3.264    Policy Loss: 7.709    Value Loss: 7.164    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 215602     Buffer Size: 24563      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:30:15,200][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 8.292    Value Loss: 6.965    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 216170     Buffer Size: 24678      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:32:56,285][train][INFO][train.py>_log] ==> #451000     Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 7.708    Value Loss: 7.525    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 216692     Buffer Size: 24639      Transition Number: 1000.001k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:35:37,210][train][INFO][train.py>_log] ==> #452000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 7.415    Value Loss: 7.333    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 217232     Buffer Size: 24395      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:38:16,102][train][INFO][train.py>_log] ==> #453000     Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 6.554    Value Loss: 7.010    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 217968     Buffer Size: 24402      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:40:55,171][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 7.764    Value Loss: 6.947    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 218738     Buffer Size: 24516      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:43:38,449][train][INFO][train.py>_log] ==> #455000     Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 7.721    Value Loss: 7.363    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 220868     Buffer Size: 25916      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:46:17,692][train][INFO][train.py>_log] ==> #456000     Total Loss: 4.119    [weighted Loss:4.119    Policy Loss: 8.848    Value Loss: 7.050    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 223000     Buffer Size: 27446      Transition Number: 1000.012k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:48:54,610][train][INFO][train.py>_log] ==> #457000     Total Loss: 3.878    [weighted Loss:3.878    Policy Loss: 8.052    Value Loss: 7.170    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 224567     Buffer Size: 28503      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:51:32,498][train][INFO][train.py>_log] ==> #458000     Total Loss: 4.567    [weighted Loss:4.567    Policy Loss: 8.130    Value Loss: 7.253    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 226233     Buffer Size: 29636      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:54:08,263][train][INFO][train.py>_log] ==> #459000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 7.980    Value Loss: 7.296    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 226983     Buffer Size: 29725      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:56:46,950][train][INFO][train.py>_log] ==> #460000     Total Loss: 4.041    [weighted Loss:4.041    Policy Loss: 8.287    Value Loss: 7.096    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 227754     Buffer Size: 29812      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 08:59:23,175][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.672    [weighted Loss:3.672    Policy Loss: 8.438    Value Loss: 7.306    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 228379     Buffer Size: 29684      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:01:59,970][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.940    [weighted Loss:2.940    Policy Loss: 7.741    Value Loss: 6.757    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 229051     Buffer Size: 29609      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:04:40,050][train][INFO][train.py>_log] ==> #463000     Total Loss: 3.470    [weighted Loss:3.470    Policy Loss: 7.362    Value Loss: 7.037    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 229538     Buffer Size: 29374      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:07:19,519][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.767    [weighted Loss:2.767    Policy Loss: 7.691    Value Loss: 6.667    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 230029     Buffer Size: 29108      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:09:59,307][train][INFO][train.py>_log] ==> #465000     Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 7.624    Value Loss: 7.191    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 230641     Buffer Size: 29037      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:12:37,008][train][INFO][train.py>_log] ==> #466000     Total Loss: 4.079    [weighted Loss:4.079    Policy Loss: 7.644    Value Loss: 6.929    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 231331     Buffer Size: 29037      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:15:13,114][train][INFO][train.py>_log] ==> #467000     Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 8.193    Value Loss: 6.982    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 231838     Buffer Size: 28949      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:17:53,066][train][INFO][train.py>_log] ==> #468000     Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 7.627    Value Loss: 7.132    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 232331     Buffer Size: 28957      Transition Number: 1000.116k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:20:32,097][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 8.330    Value Loss: 7.186    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 232830     Buffer Size: 29045      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:23:12,154][train][INFO][train.py>_log] ==> #470000     Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 8.035    Value Loss: 7.248    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 233337     Buffer Size: 29197      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:25:48,621][train][INFO][train.py>_log] ==> #471000     Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 8.648    Value Loss: 7.242    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 233871     Buffer Size: 29254      Transition Number: 1000.025k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:28:28,763][train][INFO][train.py>_log] ==> #472000     Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 8.199    Value Loss: 7.157    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 234405     Buffer Size: 29266      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:31:06,273][train][INFO][train.py>_log] ==> #473000     Total Loss: 3.142    [weighted Loss:3.142    Policy Loss: 8.523    Value Loss: 7.363    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 234995     Buffer Size: 29431      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:33:47,061][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.801    [weighted Loss:2.801    Policy Loss: 7.909    Value Loss: 6.947    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 235606     Buffer Size: 29610      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:36:25,006][train][INFO][train.py>_log] ==> #475000     Total Loss: 3.814    [weighted Loss:3.814    Policy Loss: 8.550    Value Loss: 7.321    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 236185     Buffer Size: 29721      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:39:01,361][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 8.528    Value Loss: 7.431    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 236751     Buffer Size: 29824      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:41:39,679][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 7.947    Value Loss: 7.131    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 237250     Buffer Size: 29890      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:44:16,990][train][INFO][train.py>_log] ==> #478000     Total Loss: 3.418    [weighted Loss:3.418    Policy Loss: 7.764    Value Loss: 7.592    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 237778     Buffer Size: 29945      Transition Number: 1000.035k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:46:57,521][train][INFO][train.py>_log] ==> #479000     Total Loss: 5.199    [weighted Loss:5.199    Policy Loss: 8.203    Value Loss: 7.132    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 238161     Buffer Size: 29932      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:49:35,744][train][INFO][train.py>_log] ==> #480000     Total Loss: 4.839    [weighted Loss:4.839    Policy Loss: 8.146    Value Loss: 7.342    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 238553     Buffer Size: 29907      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:52:16,980][train][INFO][train.py>_log] ==> #481000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 7.564    Value Loss: 7.145    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 238937     Buffer Size: 29835      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:54:57,982][train][INFO][train.py>_log] ==> #482000     Total Loss: 3.469    [weighted Loss:3.469    Policy Loss: 8.173    Value Loss: 7.471    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 239341     Buffer Size: 29731      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 09:57:38,795][train][INFO][train.py>_log] ==> #483000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 8.055    Value Loss: 7.418    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 239916     Buffer Size: 29751      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:00:16,984][train][INFO][train.py>_log] ==> #484000     Total Loss: 1.984    [weighted Loss:1.984    Policy Loss: 8.469    Value Loss: 7.292    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 240485     Buffer Size: 29782      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:02:56,828][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 8.040    Value Loss: 7.656    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 241143     Buffer Size: 29854      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:05:35,834][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 8.996    Value Loss: 7.359    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 241771     Buffer Size: 29943      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:08:11,635][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 7.715    Value Loss: 7.118    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 242519     Buffer Size: 30097      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:10:49,991][train][INFO][train.py>_log] ==> #488000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 8.689    Value Loss: 7.018    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 243287     Buffer Size: 30308      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:13:28,022][train][INFO][train.py>_log] ==> #489000     Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 8.161    Value Loss: 7.300    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 243833     Buffer Size: 30387      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:16:06,776][train][INFO][train.py>_log] ==> #490000     Total Loss: 4.270    [weighted Loss:4.270    Policy Loss: 8.676    Value Loss: 7.238    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 244417     Buffer Size: 30446      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:18:44,790][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.864    [weighted Loss:2.864    Policy Loss: 7.502    Value Loss: 6.767    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 244899     Buffer Size: 30424      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:21:22,982][train][INFO][train.py>_log] ==> #492000     Total Loss: 4.101    [weighted Loss:4.101    Policy Loss: 7.575    Value Loss: 6.558    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 245398     Buffer Size: 30394      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:24:04,366][train][INFO][train.py>_log] ==> #493000     Total Loss: 4.175    [weighted Loss:4.175    Policy Loss: 7.150    Value Loss: 7.368    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 245866     Buffer Size: 30344      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:26:44,013][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.028    [weighted Loss:3.028    Policy Loss: 7.239    Value Loss: 7.645    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 246326     Buffer Size: 30259      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:29:24,036][train][INFO][train.py>_log] ==> #495000     Total Loss: 3.662    [weighted Loss:3.662    Policy Loss: 7.888    Value Loss: 7.258    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 246967     Buffer Size: 30353      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:32:04,926][train][INFO][train.py>_log] ==> #496000     Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 8.108    Value Loss: 7.145    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 247584     Buffer Size: 30462      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:34:41,502][train][INFO][train.py>_log] ==> #497000     Total Loss: 3.361    [weighted Loss:3.361    Policy Loss: 7.505    Value Loss: 6.645    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 248063     Buffer Size: 30276      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:37:21,452][train][INFO][train.py>_log] ==> #498000     Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 6.842    Value Loss: 7.247    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 248543     Buffer Size: 30020      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:40:01,745][train][INFO][train.py>_log] ==> #499000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 7.360    Value Loss: 7.101    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 249139     Buffer Size: 29168      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:42:46,184][train][INFO][train.py>_log] ==> #500000     Total Loss: 1.832    [weighted Loss:1.832    Policy Loss: 7.812    Value Loss: 7.205    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 249701     Buffer Size: 27831      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:45:27,233][train][INFO][train.py>_log] ==> #501000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 7.767    Value Loss: 7.258    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 250480     Buffer Size: 26707      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:48:04,153][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 7.892    Value Loss: 7.136    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 251264     Buffer Size: 25994      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:50:45,791][train][INFO][train.py>_log] ==> #503000     Total Loss: 4.198    [weighted Loss:4.198    Policy Loss: 8.014    Value Loss: 7.503    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 251954     Buffer Size: 25353      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:53:24,002][train][INFO][train.py>_log] ==> #504000     Total Loss: 4.215    [weighted Loss:4.215    Policy Loss: 8.063    Value Loss: 7.205    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 252588     Buffer Size: 25245      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:56:02,948][train][INFO][train.py>_log] ==> #505000     Total Loss: 3.557    [weighted Loss:3.557    Policy Loss: 8.609    Value Loss: 7.527    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 253156     Buffer Size: 25134      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 10:58:43,863][train][INFO][train.py>_log] ==> #506000     Total Loss: 2.806    [weighted Loss:2.806    Policy Loss: 8.720    Value Loss: 7.556    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 253752     Buffer Size: 25039      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:01:23,303][train][INFO][train.py>_log] ==> #507000     Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 8.513    Value Loss: 7.100    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 254602     Buffer Size: 25289      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:04:01,877][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 8.284    Value Loss: 7.602    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 255545     Buffer Size: 25694      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:06:42,583][train][INFO][train.py>_log] ==> #509000     Total Loss: 3.446    [weighted Loss:3.446    Policy Loss: 9.296    Value Loss: 7.676    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 257170     Buffer Size: 26687      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:09:21,273][train][INFO][train.py>_log] ==> #510000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 8.349    Value Loss: 7.630    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 259064     Buffer Size: 27859      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:11:57,846][train][INFO][train.py>_log] ==> #511000     Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 7.925    Value Loss: 7.422    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 260328     Buffer Size: 28575      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:14:36,154][train][INFO][train.py>_log] ==> #512000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 8.318    Value Loss: 7.154    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 261516     Buffer Size: 29237      Transition Number: 1000.013k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:17:11,055][train][INFO][train.py>_log] ==> #513000     Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 7.560    Value Loss: 7.339    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 262083     Buffer Size: 29336      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:19:49,628][train][INFO][train.py>_log] ==> #514000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 7.128    Value Loss: 6.901    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 262698     Buffer Size: 29429      Transition Number: 1000.002k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:22:28,415][train][INFO][train.py>_log] ==> #515000     Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 8.059    Value Loss: 6.975    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 263283     Buffer Size: 29482      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:25:07,562][train][INFO][train.py>_log] ==> #516000     Total Loss: 3.688    [weighted Loss:3.688    Policy Loss: 8.906    Value Loss: 7.611    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 263838     Buffer Size: 29502      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:27:48,893][train][INFO][train.py>_log] ==> #517000     Total Loss: 3.052    [weighted Loss:3.052    Policy Loss: 8.245    Value Loss: 7.436    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 264355     Buffer Size: 29449      Transition Number: 1000.012k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:30:27,314][train][INFO][train.py>_log] ==> #518000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 7.761    Value Loss: 7.256    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 264871     Buffer Size: 29378      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:33:09,048][train][INFO][train.py>_log] ==> #519000     Total Loss: 3.646    [weighted Loss:3.646    Policy Loss: 7.703    Value Loss: 6.978    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 265368     Buffer Size: 29278      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:35:47,167][train][INFO][train.py>_log] ==> #520000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 7.992    Value Loss: 7.369    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 265841     Buffer Size: 29177      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:38:29,516][train][INFO][train.py>_log] ==> #521000     Total Loss: 2.496    [weighted Loss:2.496    Policy Loss: 7.790    Value Loss: 7.497    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 266299     Buffer Size: 29108      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:41:09,681][train][INFO][train.py>_log] ==> #522000     Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 7.902    Value Loss: 7.097    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 266774     Buffer Size: 29052      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:43:55,025][train][INFO][train.py>_log] ==> #523000     Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 8.665    Value Loss: 7.221    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 267269     Buffer Size: 29127      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:46:36,068][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 7.956    Value Loss: 7.376    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 267765     Buffer Size: 29219      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:49:17,185][train][INFO][train.py>_log] ==> #525000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 8.044    Value Loss: 7.408    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 268256     Buffer Size: 29330      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:51:57,442][train][INFO][train.py>_log] ==> #526000     Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 8.348    Value Loss: 7.401    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 268759     Buffer Size: 29441      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:54:39,110][train][INFO][train.py>_log] ==> #527000     Total Loss: 2.896    [weighted Loss:2.896    Policy Loss: 7.853    Value Loss: 7.240    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 269215     Buffer Size: 29345      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:57:19,150][train][INFO][train.py>_log] ==> #528000     Total Loss: 3.067    [weighted Loss:3.067    Policy Loss: 7.603    Value Loss: 7.201    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 269651     Buffer Size: 29219      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 11:59:58,630][train][INFO][train.py>_log] ==> #529000     Total Loss: 3.315    [weighted Loss:3.315    Policy Loss: 8.655    Value Loss: 7.180    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 270105     Buffer Size: 29067      Transition Number: 1000.056k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:02:41,478][train][INFO][train.py>_log] ==> #530000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 8.051    Value Loss: 6.889    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 270579     Buffer Size: 28879      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:05:25,240][train][INFO][train.py>_log] ==> #531000     Total Loss: 3.801    [weighted Loss:3.801    Policy Loss: 8.395    Value Loss: 7.148    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 271095     Buffer Size: 28667      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:08:08,187][train][INFO][train.py>_log] ==> #532000     Total Loss: 3.561    [weighted Loss:3.561    Policy Loss: 8.373    Value Loss: 7.134    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 271587     Buffer Size: 28404      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:10:48,682][train][INFO][train.py>_log] ==> #533000     Total Loss: 3.764    [weighted Loss:3.764    Policy Loss: 8.355    Value Loss: 7.299    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 272050     Buffer Size: 28263      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:13:32,248][train][INFO][train.py>_log] ==> #534000     Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 8.145    Value Loss: 7.339    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 272514     Buffer Size: 28161      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:16:14,567][train][INFO][train.py>_log] ==> #535000     Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 8.514    Value Loss: 7.357    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 273207     Buffer Size: 28310      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:18:55,549][train][INFO][train.py>_log] ==> #536000     Total Loss: 4.402    [weighted Loss:4.402    Policy Loss: 8.682    Value Loss: 7.379    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 273887     Buffer Size: 28490      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:21:37,818][train][INFO][train.py>_log] ==> #537000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 7.376    Value Loss: 7.115    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 274489     Buffer Size: 28619      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:24:18,261][train][INFO][train.py>_log] ==> #538000     Total Loss: 3.325    [weighted Loss:3.325    Policy Loss: 8.077    Value Loss: 7.256    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 275077     Buffer Size: 28708      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:27:02,170][train][INFO][train.py>_log] ==> #539000     Total Loss: 3.444    [weighted Loss:3.444    Policy Loss: 8.697    Value Loss: 7.173    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 275637     Buffer Size: 28584      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:29:42,983][train][INFO][train.py>_log] ==> #540000     Total Loss: 3.284    [weighted Loss:3.284    Policy Loss: 8.786    Value Loss: 7.402    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 276174     Buffer Size: 28488      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:32:24,520][train][INFO][train.py>_log] ==> #541000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 8.277    Value Loss: 6.823    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 276667     Buffer Size: 28517      Transition Number: 1000.135k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:35:09,584][train][INFO][train.py>_log] ==> #542000     Total Loss: 3.337    [weighted Loss:3.337    Policy Loss: 8.879    Value Loss: 7.551    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 277177     Buffer Size: 28498      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:37:52,776][train][INFO][train.py>_log] ==> #543000     Total Loss: 4.760    [weighted Loss:4.760    Policy Loss: 8.680    Value Loss: 7.096    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 277665     Buffer Size: 28407      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:40:34,451][train][INFO][train.py>_log] ==> #544000     Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 8.460    Value Loss: 7.210    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 278155     Buffer Size: 28320      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:43:12,794][train][INFO][train.py>_log] ==> #545000     Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 8.694    Value Loss: 7.155    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 278643     Buffer Size: 28070      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:45:53,978][train][INFO][train.py>_log] ==> #546000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 8.219    Value Loss: 6.956    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 279169     Buffer Size: 27829      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:48:32,428][train][INFO][train.py>_log] ==> #547000     Total Loss: 4.083    [weighted Loss:4.083    Policy Loss: 8.919    Value Loss: 7.064    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 279662     Buffer Size: 27680      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:51:12,104][train][INFO][train.py>_log] ==> #548000     Total Loss: 2.625    [weighted Loss:2.625    Policy Loss: 8.281    Value Loss: 7.386    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 280156     Buffer Size: 27528      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:53:53,102][train][INFO][train.py>_log] ==> #549000     Total Loss: 3.244    [weighted Loss:3.244    Policy Loss: 8.663    Value Loss: 7.466    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 280854     Buffer Size: 27621      Transition Number: 1000.012k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:56:33,192][train][INFO][train.py>_log] ==> #550000     Total Loss: 3.103    [weighted Loss:3.103    Policy Loss: 8.581    Value Loss: 7.425    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 281581     Buffer Size: 27779      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-01-06 12:59:14,861][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.181    [weighted Loss:3.181    Policy Loss: 8.587    Value Loss: 7.215    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 282317     Buffer Size: 27634      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:01:53,927][train][INFO][train.py>_log] ==> #552000     Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 8.265    Value Loss: 7.076    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 283094     Buffer Size: 27457      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:04:37,951][train][INFO][train.py>_log] ==> #553000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 9.015    Value Loss: 7.032    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 283758     Buffer Size: 26604      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:07:21,255][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 8.367    Value Loss: 7.026    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 284418     Buffer Size: 25416      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:10:05,412][train][INFO][train.py>_log] ==> #555000     Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 9.179    Value Loss: 7.282    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 285030     Buffer Size: 24734      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:12:46,054][train][INFO][train.py>_log] ==> #556000     Total Loss: 3.954    [weighted Loss:3.954    Policy Loss: 8.294    Value Loss: 7.476    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 285616     Buffer Size: 24130      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:15:29,744][train][INFO][train.py>_log] ==> #557000     Total Loss: 3.641    [weighted Loss:3.641    Policy Loss: 10.078   Value Loss: 7.340    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 286237     Buffer Size: 24118      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
