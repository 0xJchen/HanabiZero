[2022-01-10 01:38:09,440][train][INFO][train.py>_log] ==> #0          Total Loss: 56.361   [weighted Loss:56.361   Policy Loss: 15.260   Value Loss: 37.125   Reward Loss: 31.820   Consistency Loss: 0.000    ] Replay Episodes Collected: 555        Buffer Size: 555        Transition Number: 5.896   k Batch Size: 256        Lr: 0.00000 
[2022-01-10 01:40:51,362][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.766    [weighted Loss:6.766    Policy Loss: 15.183   Value Loss: 4.069    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 3596       Buffer Size: 3596       Transition Number: 44.110  k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:43:43,205][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.657    [weighted Loss:5.657    Policy Loss: 14.714   Value Loss: 3.650    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 6693       Buffer Size: 6693       Transition Number: 83.126  k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:46:24,846][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.883    [weighted Loss:5.883    Policy Loss: 13.801   Value Loss: 3.404    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 9823       Buffer Size: 9823       Transition Number: 120.508 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:49:03,122][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.924    [weighted Loss:4.924    Policy Loss: 13.932   Value Loss: 3.368    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 12909      Buffer Size: 12909      Transition Number: 156.503 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:51:41,091][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.365    [weighted Loss:5.365    Policy Loss: 14.174   Value Loss: 3.385    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 14932      Buffer Size: 14932      Transition Number: 187.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:54:19,381][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.823    [weighted Loss:3.823    Policy Loss: 14.444   Value Loss: 3.038    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 16985      Buffer Size: 16985      Transition Number: 224.604 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:57:04,230][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.986    [weighted Loss:4.986    Policy Loss: 13.285   Value Loss: 3.188    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 18875      Buffer Size: 18875      Transition Number: 257.701 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:59:48,194][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.798    [weighted Loss:5.798    Policy Loss: 13.678   Value Loss: 3.299    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 20726      Buffer Size: 20726      Transition Number: 292.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:02:30,290][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.586    [weighted Loss:5.586    Policy Loss: 13.471   Value Loss: 2.937    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 22494      Buffer Size: 22494      Transition Number: 328.209 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:05:14,320][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.445    [weighted Loss:3.445    Policy Loss: 13.966   Value Loss: 2.975    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 24263      Buffer Size: 24263      Transition Number: 361.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:08:01,507][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.285    [weighted Loss:5.285    Policy Loss: 14.004   Value Loss: 3.189    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 26592      Buffer Size: 26592      Transition Number: 401.204 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:10:43,793][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.074    [weighted Loss:5.074    Policy Loss: 13.911   Value Loss: 3.241    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 28817      Buffer Size: 28817      Transition Number: 436.554 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:13:26,438][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.448    [weighted Loss:5.448    Policy Loss: 13.603   Value Loss: 3.045    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 30741      Buffer Size: 30741      Transition Number: 468.297 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:16:06,809][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 14.053   Value Loss: 3.356    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 32670      Buffer Size: 32670      Transition Number: 504.681 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:18:51,112][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.668    [weighted Loss:5.668    Policy Loss: 14.024   Value Loss: 3.556    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 34379      Buffer Size: 34379      Transition Number: 534.634 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:21:34,657][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.861    [weighted Loss:3.861    Policy Loss: 11.269   Value Loss: 3.447    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 35991      Buffer Size: 35991      Transition Number: 569.291 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:24:24,048][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.923    [weighted Loss:4.923    Policy Loss: 10.545   Value Loss: 3.670    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 36970      Buffer Size: 36970      Transition Number: 602.499 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:27:05,628][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.579    [weighted Loss:4.579    Policy Loss: 9.502    Value Loss: 3.831    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 37776      Buffer Size: 37776      Transition Number: 625.124 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:29:52,219][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 8.986    Value Loss: 3.849    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 38565      Buffer Size: 38565      Transition Number: 659.063 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:32:35,575][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 7.487    Value Loss: 3.882    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 39285      Buffer Size: 39285      Transition Number: 691.897 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:35:24,582][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 7.191    Value Loss: 4.140    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 39795      Buffer Size: 39795      Transition Number: 716.772 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:38:09,481][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 6.973    Value Loss: 4.442    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 40409      Buffer Size: 40409      Transition Number: 753.330 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:40:56,707][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 6.311    Value Loss: 4.010    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 40959      Buffer Size: 40959      Transition Number: 785.910 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:43:45,122][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 6.032    Value Loss: 4.128    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 41494      Buffer Size: 41494      Transition Number: 818.888 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:46:31,919][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 5.883    Value Loss: 3.927    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 42265      Buffer Size: 42265      Transition Number: 853.829 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:49:15,921][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 6.344    Value Loss: 4.011    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 43003      Buffer Size: 43003      Transition Number: 880.089 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:52:00,483][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 5.209    Value Loss: 4.158    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 43664      Buffer Size: 43664      Transition Number: 913.219 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:54:47,003][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.832    [weighted Loss:2.832    Policy Loss: 6.068    Value Loss: 4.224    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 44311      Buffer Size: 44311      Transition Number: 947.078 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:57:38,871][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 4.674    Value Loss: 4.068    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 44808      Buffer Size: 44808      Transition Number: 978.774 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:00:27,193][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 4.626    Value Loss: 4.333    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 45358      Buffer Size: 45358      Transition Number: 1014.309k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:03:14,457][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 4.635    Value Loss: 4.321    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 45852      Buffer Size: 45852      Transition Number: 1047.282k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:06:01,970][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.395    [weighted Loss:1.395    Policy Loss: 4.513    Value Loss: 4.354    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 46317      Buffer Size: 46317      Transition Number: 1078.011k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:08:52,793][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.066    [weighted Loss:1.066    Policy Loss: 4.160    Value Loss: 4.391    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 46818      Buffer Size: 46818      Transition Number: 1112.835k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:11:42,912][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 4.453    Value Loss: 4.110    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 47248      Buffer Size: 47248      Transition Number: 1143.333k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:14:33,695][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 4.703    Value Loss: 4.402    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 47656      Buffer Size: 47656      Transition Number: 1170.504k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:17:22,715][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 4.374    Value Loss: 4.229    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 48097      Buffer Size: 48097      Transition Number: 1202.003k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:20:12,605][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 4.340    Value Loss: 4.005    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 48572      Buffer Size: 48572      Transition Number: 1231.464k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:23:07,452][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 4.081    Value Loss: 4.259    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 49024      Buffer Size: 49024      Transition Number: 1258.405k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:26:02,965][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 4.882    Value Loss: 4.212    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 49517      Buffer Size: 49517      Transition Number: 1292.041k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:28:54,170][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 4.357    Value Loss: 4.317    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 49974      Buffer Size: 49974      Transition Number: 1322.780k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:31:48,934][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 4.703    Value Loss: 4.391    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 50367      Buffer Size: 50367      Transition Number: 1347.848k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:34:44,904][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 4.296    Value Loss: 4.321    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 50890      Buffer Size: 50890      Transition Number: 1382.900k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:37:43,539][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.651    [weighted Loss:1.651    Policy Loss: 3.909    Value Loss: 4.283    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 51372      Buffer Size: 51372      Transition Number: 1415.653k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:40:42,945][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 3.365    Value Loss: 4.693    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 51801      Buffer Size: 51801      Transition Number: 1444.270k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:43:42,412][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 3.782    Value Loss: 4.340    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 52210      Buffer Size: 52210      Transition Number: 1474.330k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:46:43,233][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 3.762    Value Loss: 4.468    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 52643      Buffer Size: 52025      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:49:48,747][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 4.415    Value Loss: 4.264    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 53141      Buffer Size: 50135      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:52:57,679][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.089    [weighted Loss:1.089    Policy Loss: 3.946    Value Loss: 4.354    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 53631      Buffer Size: 48215      Transition Number: 1500.083k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:56:08,241][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 3.315    Value Loss: 4.532    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 54142      Buffer Size: 46025      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:59:16,205][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 3.817    Value Loss: 4.375    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 54645      Buffer Size: 43568      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:02:26,322][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.540    [weighted Loss:1.540    Policy Loss: 3.546    Value Loss: 4.786    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 55121      Buffer Size: 41272      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:05:32,942][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 3.359    Value Loss: 4.720    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 55526      Buffer Size: 39851      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:08:42,090][train][INFO][train.py>_log] ==> #53000      Total Loss: 0.835    [weighted Loss:0.835    Policy Loss: 3.502    Value Loss: 4.319    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 55987      Buffer Size: 38304      Transition Number: 1500.250k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:11:50,594][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 3.389    Value Loss: 4.528    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 56453      Buffer Size: 36914      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:15:01,061][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 3.614    Value Loss: 4.843    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 56911      Buffer Size: 35460      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:18:08,878][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 3.581    Value Loss: 4.662    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 57345      Buffer Size: 34349      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:21:18,835][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 3.494    Value Loss: 4.593    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 57841      Buffer Size: 32806      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:24:29,230][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 3.716    Value Loss: 4.463    Reward Loss: 0.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 58312      Buffer Size: 31054      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:27:39,343][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 3.946    Value Loss: 4.491    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 58839      Buffer Size: 29164      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:30:52,001][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 3.252    Value Loss: 4.511    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 59311      Buffer Size: 27653      Transition Number: 1500.076k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:34:08,098][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 3.949    Value Loss: 4.571    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 59881      Buffer Size: 25777      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:37:21,983][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.362    [weighted Loss:1.362    Policy Loss: 3.164    Value Loss: 4.281    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 60436      Buffer Size: 24448      Transition Number: 1500.250k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:40:38,252][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.079    [weighted Loss:1.079    Policy Loss: 3.880    Value Loss: 4.547    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 60978      Buffer Size: 23762      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:43:53,765][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 3.470    Value Loss: 4.538    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 61599      Buffer Size: 23141      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:47:07,980][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 3.647    Value Loss: 4.575    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 62114      Buffer Size: 22804      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:50:24,289][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 3.705    Value Loss: 4.929    Reward Loss: 0.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 62716      Buffer Size: 22589      Transition Number: 1499.926k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:53:38,248][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 3.102    Value Loss: 4.637    Reward Loss: 0.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 63271      Buffer Size: 22473      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:56:54,359][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 3.546    Value Loss: 4.659    Reward Loss: 0.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 63889      Buffer Size: 22385      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:00:12,027][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 4.085    Value Loss: 4.654    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 64514      Buffer Size: 21893      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:03:26,939][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 4.154    Value Loss: 4.349    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 65067      Buffer Size: 21626      Transition Number: 1500.108k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:06:46,698][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 3.677    Value Loss: 4.546    Reward Loss: 0.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 65700      Buffer Size: 21325      Transition Number: 1500.105k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:10:04,790][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.393    [weighted Loss:1.393    Policy Loss: 3.949    Value Loss: 4.598    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 66330      Buffer Size: 21239      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:13:22,873][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 4.583    Value Loss: 4.331    Reward Loss: 0.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 66908      Buffer Size: 21174      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:16:38,362][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 4.095    Value Loss: 4.610    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 67528      Buffer Size: 21103      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:19:55,266][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 4.151    Value Loss: 4.522    Reward Loss: 0.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 68261      Buffer Size: 21208      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:23:09,231][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 4.503    Value Loss: 4.587    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 68997      Buffer Size: 21329      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:26:25,115][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 4.572    Value Loss: 4.268    Reward Loss: 0.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 69664      Buffer Size: 21368      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:29:42,639][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 4.493    Value Loss: 4.638    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 70353      Buffer Size: 21351      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:32:59,098][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 4.821    Value Loss: 4.386    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 71005      Buffer Size: 21329      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:36:15,105][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 4.787    Value Loss: 4.606    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 71611      Buffer Size: 21307      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:39:32,790][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 4.271    Value Loss: 4.287    Reward Loss: 0.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 72247      Buffer Size: 21280      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:42:51,942][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 4.635    Value Loss: 4.430    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 72945      Buffer Size: 21246      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:46:09,359][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 4.565    Value Loss: 4.375    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 73582      Buffer Size: 21286      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:49:28,098][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 5.006    Value Loss: 4.745    Reward Loss: 0.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 74258      Buffer Size: 21267      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:52:48,930][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 4.909    Value Loss: 4.505    Reward Loss: 0.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 74925      Buffer Size: 21215      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:56:07,771][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 4.586    Value Loss: 4.527    Reward Loss: 0.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 75606      Buffer Size: 21239      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:59:26,940][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 5.385    Value Loss: 4.794    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 76320      Buffer Size: 21340      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:02:47,022][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.435    [weighted Loss:2.435    Policy Loss: 4.998    Value Loss: 4.313    Reward Loss: 0.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 76995      Buffer Size: 21444      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:06:06,176][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 4.727    Value Loss: 4.723    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 77740      Buffer Size: 21600      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:09:23,874][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.305    [weighted Loss:2.305    Policy Loss: 4.454    Value Loss: 4.585    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 78438      Buffer Size: 21744      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:12:43,299][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 5.026    Value Loss: 4.810    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 79176      Buffer Size: 21904      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:16:00,644][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 5.140    Value Loss: 4.840    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 79874      Buffer Size: 22048      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:19:16,665][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 4.578    Value Loss: 4.860    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 80595      Buffer Size: 22194      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:22:33,680][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 5.368    Value Loss: 4.880    Reward Loss: 0.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 81335      Buffer Size: 22353      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:25:51,127][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 4.369    Value Loss: 4.677    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 82018      Buffer Size: 22498      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:29:08,808][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 4.567    Value Loss: 4.822    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 82746      Buffer Size: 22657      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:32:27,358][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 4.875    Value Loss: 5.034    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 83569      Buffer Size: 22890      Transition Number: 1500.106k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:35:45,671][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 4.796    Value Loss: 4.818    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 84416      Buffer Size: 23158      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:39:05,059][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.339    [weighted Loss:2.339    Policy Loss: 4.669    Value Loss: 4.941    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 85187      Buffer Size: 23383      Transition Number: 1500.082k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:42:21,659][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 4.794    Value Loss: 4.992    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 85995      Buffer Size: 23623      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:45:37,665][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 4.370    Value Loss: 4.911    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 86674      Buffer Size: 23735      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:48:55,501][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 5.004    Value Loss: 5.466    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 87400      Buffer Size: 23838      Transition Number: 1499.928k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:52:13,257][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 4.083    Value Loss: 5.210    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 88198      Buffer Size: 24013      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:55:29,007][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 4.380    Value Loss: 5.237    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 88998      Buffer Size: 24237      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:58:46,920][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 4.479    Value Loss: 5.160    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 89789      Buffer Size: 24443      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:02:04,585][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.959    [weighted Loss:1.959    Policy Loss: 3.916    Value Loss: 4.937    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 90574      Buffer Size: 24655      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:05:20,484][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 4.594    Value Loss: 5.558    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 91284      Buffer Size: 24783      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:08:38,336][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 4.073    Value Loss: 5.174    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 92009      Buffer Size: 24920      Transition Number: 1500.098k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:11:54,692][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 5.280    Value Loss: 4.957    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 92655      Buffer Size: 25003      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:15:13,610][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 3.896    Value Loss: 5.178    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 93399      Buffer Size: 24940      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:18:31,254][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 5.200    Value Loss: 4.972    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 94006      Buffer Size: 24858      Transition Number: 1500.096k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:21:53,806][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.017    [weighted Loss:2.017    Policy Loss: 4.168    Value Loss: 4.915    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 94736      Buffer Size: 24814      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:25:08,557][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 5.237    Value Loss: 5.427    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 95374      Buffer Size: 24804      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:28:25,212][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 4.418    Value Loss: 4.739    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 96002      Buffer Size: 24810      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:31:44,282][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 4.664    Value Loss: 5.172    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 96718      Buffer Size: 24849      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:34:59,444][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 4.675    Value Loss: 5.066    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 97331      Buffer Size: 24881      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:38:17,530][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 5.004    Value Loss: 5.305    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 98016      Buffer Size: 24887      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:41:35,302][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.433    [weighted Loss:1.433    Policy Loss: 3.710    Value Loss: 5.142    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 98633      Buffer Size: 24888      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:44:51,421][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 4.738    Value Loss: 5.262    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 99312      Buffer Size: 24931      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:48:09,299][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 4.553    Value Loss: 5.499    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 100005     Buffer Size: 24949      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:51:26,523][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 4.282    Value Loss: 5.319    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 100614     Buffer Size: 24941      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:54:46,082][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.030    [weighted Loss:2.030    Policy Loss: 4.193    Value Loss: 5.298    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 101311     Buffer Size: 24882      Transition Number: 1500.108k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:58:03,849][train][INFO][train.py>_log] ==> #123000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 4.604    Value Loss: 5.395    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 101892     Buffer Size: 24842      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:01:20,932][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 4.736    Value Loss: 5.376    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 102567     Buffer Size: 24737      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:04:38,617][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 4.505    Value Loss: 5.273    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 103216     Buffer Size: 24640      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:08:01,900][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 4.857    Value Loss: 5.339    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 103871     Buffer Size: 24558      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:11:20,545][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.666    [weighted Loss:1.666    Policy Loss: 4.618    Value Loss: 5.352    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 104567     Buffer Size: 24527      Transition Number: 1500.237k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:14:39,197][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.177    [weighted Loss:1.177    Policy Loss: 4.266    Value Loss: 5.216    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 105223     Buffer Size: 24476      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:17:58,779][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 4.798    Value Loss: 5.291    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 105879     Buffer Size: 24403      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:21:18,481][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.405    [weighted Loss:2.405    Policy Loss: 4.579    Value Loss: 5.310    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 106507     Buffer Size: 24332      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:24:38,065][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 4.504    Value Loss: 5.461    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 107198     Buffer Size: 24220      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:27:57,915][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 4.231    Value Loss: 5.574    Reward Loss: 0.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 107852     Buffer Size: 24088      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:31:19,749][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.848    [weighted Loss:2.848    Policy Loss: 4.693    Value Loss: 5.571    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 108457     Buffer Size: 23904      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:34:38,781][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 4.334    Value Loss: 5.424    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 109137     Buffer Size: 23718      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:37:59,190][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 5.302    Value Loss: 5.407    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 110299     Buffer Size: 24069      Transition Number: 1499.927k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:41:16,326][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 4.698    Value Loss: 5.736    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 111383     Buffer Size: 24454      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:44:35,761][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 4.885    Value Loss: 5.625    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 112056     Buffer Size: 24441      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:47:53,544][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 4.814    Value Loss: 5.865    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 112756     Buffer Size: 24354      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:51:10,747][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 4.746    Value Loss: 5.579    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 113406     Buffer Size: 24213      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:54:27,103][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 4.973    Value Loss: 5.319    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 114031     Buffer Size: 24079      Transition Number: 1500.110k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:57:46,767][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 4.919    Value Loss: 5.259    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 114708     Buffer Size: 23936      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:01:05,844][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.767    [weighted Loss:1.767    Policy Loss: 4.825    Value Loss: 5.503    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 115345     Buffer Size: 23862      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:04:26,811][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 4.900    Value Loss: 5.692    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 116012     Buffer Size: 23776      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:07:46,737][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 4.490    Value Loss: 5.558    Reward Loss: 0.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 116684     Buffer Size: 23757      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:11:07,470][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.802    [weighted Loss:2.802    Policy Loss: 4.490    Value Loss: 5.520    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 117344     Buffer Size: 23707      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:14:30,086][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 3.905    Value Loss: 5.445    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 118003     Buffer Size: 23692      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:17:49,248][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 4.235    Value Loss: 5.325    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 118700     Buffer Size: 23681      Transition Number: 1499.932k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:21:07,258][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.859    [weighted Loss:1.859    Policy Loss: 3.945    Value Loss: 5.548    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 119347     Buffer Size: 23677      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:24:30,171][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 4.245    Value Loss: 5.460    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 120049     Buffer Size: 23660      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:27:51,087][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.330    [weighted Loss:2.330    Policy Loss: 4.345    Value Loss: 5.789    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 120735     Buffer Size: 23631      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:31:11,856][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.857    [weighted Loss:1.857    Policy Loss: 3.934    Value Loss: 5.141    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 121335     Buffer Size: 23600      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:34:31,634][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 4.357    Value Loss: 5.715    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 122069     Buffer Size: 23574      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:37:51,852][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.974    [weighted Loss:2.974    Policy Loss: 4.453    Value Loss: 5.350    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 122708     Buffer Size: 23532      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:41:11,606][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 4.251    Value Loss: 5.494    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 123338     Buffer Size: 23465      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:44:32,640][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 4.556    Value Loss: 5.407    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 124060     Buffer Size: 23404      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:47:54,270][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 4.814    Value Loss: 5.269    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 124737     Buffer Size: 23376      Transition Number: 1499.929k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:51:16,083][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 4.485    Value Loss: 5.858    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 125371     Buffer Size: 23369      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:54:38,143][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 4.739    Value Loss: 5.360    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 126098     Buffer Size: 23360      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:58:01,584][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 4.853    Value Loss: 5.747    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 126840     Buffer Size: 23339      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:01:24,225][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 5.036    Value Loss: 5.491    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 127471     Buffer Size: 23340      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:04:44,796][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 4.705    Value Loss: 5.453    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 128152     Buffer Size: 23304      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:08:06,488][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 4.896    Value Loss: 5.500    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 128866     Buffer Size: 23308      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:11:29,360][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 4.834    Value Loss: 5.839    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 129518     Buffer Size: 23292      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:14:51,606][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.721    [weighted Loss:2.721    Policy Loss: 4.994    Value Loss: 5.453    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 130225     Buffer Size: 23261      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:18:12,046][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 5.009    Value Loss: 5.748    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 130930     Buffer Size: 23206      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:21:33,055][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 5.235    Value Loss: 5.786    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 131582     Buffer Size: 23181      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:24:54,520][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 5.973    Value Loss: 5.750    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 132235     Buffer Size: 23130      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:28:17,990][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 4.929    Value Loss: 5.083    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 132938     Buffer Size: 22512      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:31:39,523][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 5.370    Value Loss: 5.377    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 133632     Buffer Size: 22057      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:35:01,756][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 4.915    Value Loss: 5.404    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 134319     Buffer Size: 21979      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:38:25,079][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 5.246    Value Loss: 5.576    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 135049     Buffer Size: 21915      Transition Number: 1499.936k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:41:49,086][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 5.538    Value Loss: 5.189    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 135745     Buffer Size: 21884      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:45:09,724][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.715    [weighted Loss:2.715    Policy Loss: 5.513    Value Loss: 5.543    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 136420     Buffer Size: 21876      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:48:32,456][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 4.927    Value Loss: 5.407    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 137126     Buffer Size: 21858      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:51:55,474][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 5.082    Value Loss: 5.616    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 137826     Buffer Size: 21860      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:55:15,330][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 5.101    Value Loss: 5.155    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 138554     Buffer Size: 21840      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:58:38,139][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.666    [weighted Loss:2.666    Policy Loss: 4.844    Value Loss: 5.756    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 139285     Buffer Size: 21885      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:02:04,857][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 4.908    Value Loss: 5.685    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 140003     Buffer Size: 21919      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:05:32,250][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.813    [weighted Loss:2.813    Policy Loss: 4.384    Value Loss: 5.801    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 140771     Buffer Size: 21970      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:08:55,901][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 5.241    Value Loss: 5.300    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 141506     Buffer Size: 22019      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:12:18,677][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.051    [weighted Loss:2.051    Policy Loss: 4.656    Value Loss: 5.638    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 142230     Buffer Size: 22088      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:15:39,113][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.569    [weighted Loss:2.569    Policy Loss: 4.688    Value Loss: 5.646    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 142962     Buffer Size: 22170      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:19:01,785][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 5.330    Value Loss: 5.422    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 143680     Buffer Size: 22263      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:22:22,894][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 5.741    Value Loss: 5.312    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 144428     Buffer Size: 22351      Transition Number: 1500.080k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:25:46,983][train][INFO][train.py>_log] ==> #185000     Total Loss: 3.189    [weighted Loss:3.189    Policy Loss: 5.536    Value Loss: 5.577    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 145130     Buffer Size: 22447      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:29:09,098][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 5.276    Value Loss: 6.104    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 145868     Buffer Size: 22535      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:32:30,106][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 5.115    Value Loss: 5.676    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 146567     Buffer Size: 22645      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:35:51,252][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.677    [weighted Loss:2.677    Policy Loss: 5.559    Value Loss: 5.538    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 147297     Buffer Size: 22744      Transition Number: 1500.052k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:39:13,430][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 5.021    Value Loss: 6.073    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 148007     Buffer Size: 22844      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:42:35,132][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.425    [weighted Loss:1.425    Policy Loss: 5.511    Value Loss: 6.084    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 148740     Buffer Size: 22937      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:45:56,168][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 5.081    Value Loss: 5.951    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 149405     Buffer Size: 23006      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:49:16,864][train][INFO][train.py>_log] ==> #192000     Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 5.462    Value Loss: 5.463    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 150135     Buffer Size: 23084      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:52:37,115][train][INFO][train.py>_log] ==> #193000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 4.724    Value Loss: 5.404    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 150789     Buffer Size: 23132      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:55:59,611][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 5.238    Value Loss: 5.900    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 151517     Buffer Size: 23155      Transition Number: 1500.148k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:59:21,986][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 5.278    Value Loss: 5.645    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 152250     Buffer Size: 23217      Transition Number: 1499.927k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:02:42,431][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 4.894    Value Loss: 5.635    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 152982     Buffer Size: 23333      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:06:04,122][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.469    [weighted Loss:2.469    Policy Loss: 5.211    Value Loss: 5.549    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 153643     Buffer Size: 23364      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:09:22,506][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 5.465    Value Loss: 5.510    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 154287     Buffer Size: 23407      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:12:42,613][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 5.337    Value Loss: 5.541    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 155021     Buffer Size: 23470      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:16:01,244][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.428    [weighted Loss:1.428    Policy Loss: 5.127    Value Loss: 5.469    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 155682     Buffer Size: 23545      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:19:23,117][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 5.243    Value Loss: 5.567    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 156330     Buffer Size: 23606      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:22:43,688][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 4.938    Value Loss: 5.933    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 157043     Buffer Size: 23669      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:26:06,998][train][INFO][train.py>_log] ==> #203000     Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 5.211    Value Loss: 5.928    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 157980     Buffer Size: 24026      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:29:28,556][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 5.018    Value Loss: 5.673    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 159005     Buffer Size: 24370      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:32:50,666][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 5.392    Value Loss: 5.797    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 159654     Buffer Size: 24432      Transition Number: 1499.931k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:36:10,417][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 4.783    Value Loss: 5.987    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 160373     Buffer Size: 24511      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:39:31,255][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 4.989    Value Loss: 5.846    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 161122     Buffer Size: 24576      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:42:50,888][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 4.912    Value Loss: 5.818    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 161767     Buffer Size: 24649      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:46:12,145][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.257    [weighted Loss:2.257    Policy Loss: 4.565    Value Loss: 5.782    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 162494     Buffer Size: 24718      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:49:34,992][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.581    [weighted Loss:2.581    Policy Loss: 5.417    Value Loss: 5.617    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 163215     Buffer Size: 24795      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:52:56,536][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.092    [weighted Loss:2.092    Policy Loss: 4.748    Value Loss: 5.602    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 163886     Buffer Size: 24832      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:56:19,237][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.950    [weighted Loss:1.950    Policy Loss: 4.972    Value Loss: 5.798    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 164585     Buffer Size: 24852      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:59:40,140][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 4.671    Value Loss: 5.758    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 165261     Buffer Size: 24886      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:03:03,861][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.292    [weighted Loss:1.292    Policy Loss: 4.537    Value Loss: 5.764    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 165950     Buffer Size: 24900      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:06:23,364][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.082    [weighted Loss:2.082    Policy Loss: 4.476    Value Loss: 5.949    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 166678     Buffer Size: 24894      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:09:44,094][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 4.082    Value Loss: 6.137    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 167323     Buffer Size: 24880      Transition Number: 1500.071k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:13:05,711][train][INFO][train.py>_log] ==> #217000     Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 4.074    Value Loss: 6.169    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 168003     Buffer Size: 24865      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:16:25,959][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 3.833    Value Loss: 5.764    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 168661     Buffer Size: 24847      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:19:45,301][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 3.975    Value Loss: 6.056    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 169370     Buffer Size: 24854      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:23:10,366][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 3.804    Value Loss: 6.161    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 170086     Buffer Size: 24852      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:26:30,818][train][INFO][train.py>_log] ==> #221000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 3.927    Value Loss: 5.733    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 170803     Buffer Size: 24845      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:29:53,341][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 3.557    Value Loss: 5.706    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 171508     Buffer Size: 24829      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:33:14,170][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 3.863    Value Loss: 5.693    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 172199     Buffer Size: 24793      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:36:35,950][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 3.816    Value Loss: 5.538    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 172876     Buffer Size: 24761      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:39:58,149][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 4.171    Value Loss: 5.736    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 173563     Buffer Size: 24728      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:43:22,451][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 4.152    Value Loss: 5.732    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 174275     Buffer Size: 24716      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:46:43,082][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 4.092    Value Loss: 5.434    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 174983     Buffer Size: 24678      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:50:06,651][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 3.572    Value Loss: 5.791    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 175706     Buffer Size: 24685      Transition Number: 1500.162k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:53:28,984][train][INFO][train.py>_log] ==> #229000     Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 3.691    Value Loss: 5.769    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 176448     Buffer Size: 24734      Transition Number: 1500.142k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:56:51,628][train][INFO][train.py>_log] ==> #230000     Total Loss: 0.830    [weighted Loss:0.830    Policy Loss: 3.999    Value Loss: 5.658    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 177188     Buffer Size: 24740      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:00:13,455][train][INFO][train.py>_log] ==> #231000     Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 4.083    Value Loss: 5.939    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 177915     Buffer Size: 24708      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:03:33,969][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 4.148    Value Loss: 5.826    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 178603     Buffer Size: 24729      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:06:59,096][train][INFO][train.py>_log] ==> #233000     Total Loss: 0.971    [weighted Loss:0.971    Policy Loss: 4.774    Value Loss: 5.311    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 179337     Buffer Size: 24725      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:10:23,483][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 3.884    Value Loss: 6.179    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 180027     Buffer Size: 24719      Transition Number: 1500.092k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:13:45,918][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 4.684    Value Loss: 5.769    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 180722     Buffer Size: 24724      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:17:09,750][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.407    [weighted Loss:2.407    Policy Loss: 4.526    Value Loss: 5.694    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 181399     Buffer Size: 24733      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:20:33,127][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 5.210    Value Loss: 5.414    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 182224     Buffer Size: 24705      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:23:54,395][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 4.403    Value Loss: 5.583    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 183049     Buffer Size: 24561      Transition Number: 1500.101k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:27:16,771][train][INFO][train.py>_log] ==> #239000     Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 4.259    Value Loss: 5.711    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 183910     Buffer Size: 24571      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:30:40,561][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 3.911    Value Loss: 6.026    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 184749     Buffer Size: 24712      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:34:04,846][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 4.450    Value Loss: 5.865    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 185486     Buffer Size: 24756      Transition Number: 1500.263k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:37:27,110][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 3.659    Value Loss: 5.654    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 186216     Buffer Size: 24768      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:40:47,043][train][INFO][train.py>_log] ==> #243000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 4.113    Value Loss: 5.702    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 186855     Buffer Size: 24728      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:44:07,824][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 3.752    Value Loss: 5.721    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 187570     Buffer Size: 24695      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:47:31,422][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 4.069    Value Loss: 5.772    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 188283     Buffer Size: 24658      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:50:56,625][train][INFO][train.py>_log] ==> #246000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 3.768    Value Loss: 5.738    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 188971     Buffer Size: 24630      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:54:19,934][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 4.489    Value Loss: 5.367    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 189635     Buffer Size: 24601      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:57:42,601][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 3.826    Value Loss: 5.542    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 190323     Buffer Size: 24561      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:01:06,857][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 4.228    Value Loss: 5.655    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 191033     Buffer Size: 24578      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:04:33,133][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 4.506    Value Loss: 5.695    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 191768     Buffer Size: 24621      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:07:55,161][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 4.406    Value Loss: 5.983    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 192478     Buffer Size: 24654      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:11:21,525][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 4.685    Value Loss: 6.212    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 193205     Buffer Size: 24675      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:14:41,577][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 4.559    Value Loss: 5.747    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 193889     Buffer Size: 24678      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:18:04,399][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 4.139    Value Loss: 5.531    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 194570     Buffer Size: 24678      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:21:27,234][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 5.062    Value Loss: 5.530    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 195327     Buffer Size: 24688      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:24:48,158][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 4.164    Value Loss: 5.896    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 196017     Buffer Size: 24707      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:28:12,876][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 4.262    Value Loss: 5.629    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 196720     Buffer Size: 24692      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:31:36,165][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 4.328    Value Loss: 5.456    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 197432     Buffer Size: 24685      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:35:00,843][train][INFO][train.py>_log] ==> #259000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 4.537    Value Loss: 5.725    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 198125     Buffer Size: 24682      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:38:24,674][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.308    [weighted Loss:1.308    Policy Loss: 3.935    Value Loss: 5.849    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 198801     Buffer Size: 24687      Transition Number: 1500.128k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:41:47,325][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 4.316    Value Loss: 6.070    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 199512     Buffer Size: 24679      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:45:09,858][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 3.630    Value Loss: 5.772    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 200176     Buffer Size: 24676      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:48:33,098][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 4.535    Value Loss: 5.848    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 200876     Buffer Size: 24637      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:51:54,588][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 4.073    Value Loss: 5.596    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 201573     Buffer Size: 24554      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:55:21,292][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 4.423    Value Loss: 5.402    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 202382     Buffer Size: 24629      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:58:44,807][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 5.891    Value Loss: 5.718    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 203204     Buffer Size: 24762      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:02:07,574][train][INFO][train.py>_log] ==> #267000     Total Loss: 1.948    [weighted Loss:1.948    Policy Loss: 4.830    Value Loss: 6.552    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 204421     Buffer Size: 25298      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:05:28,516][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 4.374    Value Loss: 5.990    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 205586     Buffer Size: 25796      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:08:51,738][train][INFO][train.py>_log] ==> #269000     Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 4.078    Value Loss: 5.708    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 206406     Buffer Size: 25959      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:12:15,051][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 4.279    Value Loss: 6.228    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 207244     Buffer Size: 26136      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:15:36,360][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.071    Value Loss: 5.870    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 207995     Buffer Size: 26174      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:18:58,651][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 3.968    Value Loss: 6.064    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 208742     Buffer Size: 26110      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:22:21,779][train][INFO][train.py>_log] ==> #273000     Total Loss: 1.555    [weighted Loss:1.555    Policy Loss: 3.997    Value Loss: 5.909    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 209471     Buffer Size: 25997      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:25:44,901][train][INFO][train.py>_log] ==> #274000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 3.989    Value Loss: 5.936    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 210187     Buffer Size: 25839      Transition Number: 1500.130k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:29:07,531][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 4.071    Value Loss: 5.658    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 210891     Buffer Size: 25738      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:32:29,643][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 3.793    Value Loss: 5.953    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 211573     Buffer Size: 25705      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:35:50,441][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.267    [weighted Loss:1.267    Policy Loss: 3.940    Value Loss: 5.669    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 212288     Buffer Size: 25703      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:39:12,766][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 3.855    Value Loss: 5.836    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 212965     Buffer Size: 25743      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:42:34,916][train][INFO][train.py>_log] ==> #279000     Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 3.940    Value Loss: 5.480    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 213696     Buffer Size: 25781      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:45:59,012][train][INFO][train.py>_log] ==> #280000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 3.650    Value Loss: 5.751    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 214373     Buffer Size: 25815      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:49:23,037][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 5.304    Value Loss: 5.478    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 215066     Buffer Size: 25860      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:52:47,631][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 3.788    Value Loss: 5.788    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 215790     Buffer Size: 25894      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:56:10,188][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 4.289    Value Loss: 6.243    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 216575     Buffer Size: 26007      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:59:33,027][train][INFO][train.py>_log] ==> #284000     Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 4.064    Value Loss: 5.859    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 217389     Buffer Size: 26081      Transition Number: 1500.090k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:02:54,499][train][INFO][train.py>_log] ==> #285000     Total Loss: 1.243    [weighted Loss:1.243    Policy Loss: 4.755    Value Loss: 6.154    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 218084     Buffer Size: 26088      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:06:16,755][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 4.175    Value Loss: 5.775    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 218764     Buffer Size: 26089      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:09:38,552][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 4.097    Value Loss: 5.935    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 219483     Buffer Size: 26076      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:13:01,643][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.444    [weighted Loss:1.444    Policy Loss: 3.997    Value Loss: 6.229    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 220172     Buffer Size: 26077      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:16:21,023][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 3.891    Value Loss: 6.055    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 220921     Buffer Size: 26135      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:19:43,619][train][INFO][train.py>_log] ==> #290000     Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 3.737    Value Loss: 5.830    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 221708     Buffer Size: 26183      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:23:06,221][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.484    [weighted Loss:1.484    Policy Loss: 4.241    Value Loss: 5.879    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 222380     Buffer Size: 26194      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:26:29,957][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 4.128    Value Loss: 5.892    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 223130     Buffer Size: 26229      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:29:53,297][train][INFO][train.py>_log] ==> #293000     Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 4.222    Value Loss: 5.644    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 223790     Buffer Size: 26245      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:33:17,669][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 3.942    Value Loss: 5.911    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 224479     Buffer Size: 26249      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:36:40,280][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 4.238    Value Loss: 5.855    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 225212     Buffer Size: 26266      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:40:01,811][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 3.965    Value Loss: 5.808    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 225853     Buffer Size: 26283      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:43:25,571][train][INFO][train.py>_log] ==> #297000     Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 4.340    Value Loss: 5.994    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 226592     Buffer Size: 26319      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:46:47,017][train][INFO][train.py>_log] ==> #298000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 4.105    Value Loss: 6.068    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 227266     Buffer Size: 26351      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:50:09,964][train][INFO][train.py>_log] ==> #299000     Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 4.314    Value Loss: 5.802    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 228030     Buffer Size: 26410      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:53:34,120][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 4.841    Value Loss: 6.122    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 228787     Buffer Size: 26353      Transition Number: 1500.140k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:56:56,011][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 4.532    Value Loss: 6.081    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 229528     Buffer Size: 26273      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:00:24,681][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 4.533    Value Loss: 6.025    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 230308     Buffer Size: 25801      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:03:51,123][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 4.491    Value Loss: 5.684    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 231033     Buffer Size: 25366      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:07:14,559][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 4.137    Value Loss: 5.439    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 231737     Buffer Size: 25269      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:10:41,182][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 4.297    Value Loss: 6.153    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 232496     Buffer Size: 25136      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:14:05,383][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 4.725    Value Loss: 5.696    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 233257     Buffer Size: 25084      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:17:28,639][train][INFO][train.py>_log] ==> #307000     Total Loss: 1.865    [weighted Loss:1.865    Policy Loss: 4.309    Value Loss: 6.349    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 233997     Buffer Size: 25118      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:20:53,167][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 3.851    Value Loss: 5.958    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 234808     Buffer Size: 25171      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:24:14,566][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 4.473    Value Loss: 5.979    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 235510     Buffer Size: 25172      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:27:39,445][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 3.957    Value Loss: 6.109    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 236176     Buffer Size: 25161      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:31:02,459][train][INFO][train.py>_log] ==> #311000     Total Loss: 1.045    [weighted Loss:1.045    Policy Loss: 4.389    Value Loss: 5.918    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 236898     Buffer Size: 25148      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:34:24,871][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 4.747    Value Loss: 5.562    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 237596     Buffer Size: 25114      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:37:47,632][train][INFO][train.py>_log] ==> #313000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 4.372    Value Loss: 5.700    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 238358     Buffer Size: 25197      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:41:08,823][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 4.152    Value Loss: 6.337    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 239148     Buffer Size: 25276      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:44:33,309][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.577    [weighted Loss:1.577    Policy Loss: 4.492    Value Loss: 5.716    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 239871     Buffer Size: 25319      Transition Number: 1500.102k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:47:56,534][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 3.938    Value Loss: 5.868    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 240612     Buffer Size: 25366      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:51:19,624][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.544    [weighted Loss:1.544    Policy Loss: 4.515    Value Loss: 6.314    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 241341     Buffer Size: 25347      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:54:44,648][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 4.079    Value Loss: 5.861    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 242024     Buffer Size: 25258      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:58:09,188][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 4.723    Value Loss: 5.771    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 242732     Buffer Size: 25183      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:01:34,541][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 4.160    Value Loss: 5.798    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 243477     Buffer Size: 25173      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:04:56,220][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.747    Value Loss: 6.587    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 244119     Buffer Size: 25176      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:08:20,407][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 4.419    Value Loss: 5.872    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 244814     Buffer Size: 25175      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:11:45,165][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.682    Value Loss: 6.162    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 245551     Buffer Size: 25172      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:15:10,362][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 4.086    Value Loss: 6.004    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 246247     Buffer Size: 25124      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:18:34,338][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 5.154    Value Loss: 6.116    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 247031     Buffer Size: 25122      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:21:58,147][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 4.636    Value Loss: 6.285    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 247823     Buffer Size: 25196      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:25:24,275][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 5.233    Value Loss: 5.802    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 248511     Buffer Size: 25216      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:28:47,746][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.694    [weighted Loss:2.694    Policy Loss: 4.445    Value Loss: 6.233    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 249264     Buffer Size: 25268      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:32:09,740][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 4.844    Value Loss: 5.780    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 249940     Buffer Size: 25294      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:35:33,536][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 4.869    Value Loss: 6.039    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 250635     Buffer Size: 25305      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:38:57,130][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 4.954    Value Loss: 6.188    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 251381     Buffer Size: 25304      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:42:21,762][train][INFO][train.py>_log] ==> #332000     Total Loss: 3.171    [weighted Loss:3.171    Policy Loss: 4.796    Value Loss: 6.388    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 252064     Buffer Size: 25289      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:45:43,907][train][INFO][train.py>_log] ==> #333000     Total Loss: 2.490    [weighted Loss:2.490    Policy Loss: 5.762    Value Loss: 6.248    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 252758     Buffer Size: 25301      Transition Number: 1500.149k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:49:09,905][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 5.612    Value Loss: 6.051    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 253463     Buffer Size: 25266      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:52:32,960][train][INFO][train.py>_log] ==> #335000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 5.597    Value Loss: 6.066    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 254231     Buffer Size: 25277      Transition Number: 1500.097k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:55:52,822][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 5.363    Value Loss: 6.093    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 254927     Buffer Size: 25249      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:59:16,304][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.079    [weighted Loss:3.079    Policy Loss: 5.192    Value Loss: 6.242    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 255755     Buffer Size: 25321      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:02:40,501][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 5.063    Value Loss: 5.834    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 256595     Buffer Size: 25470      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:06:03,281][train][INFO][train.py>_log] ==> #339000     Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 5.109    Value Loss: 6.437    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 257348     Buffer Size: 25513      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:09:28,899][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 5.343    Value Loss: 6.163    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 258145     Buffer Size: 25558      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:12:53,734][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 5.073    Value Loss: 6.098    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 258905     Buffer Size: 25592      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:16:17,461][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 5.027    Value Loss: 5.943    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 259628     Buffer Size: 25583      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:19:43,393][train][INFO][train.py>_log] ==> #343000     Total Loss: 1.174    [weighted Loss:1.174    Policy Loss: 5.724    Value Loss: 6.288    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 260385     Buffer Size: 25539      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:23:05,852][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.802    [weighted Loss:2.802    Policy Loss: 4.598    Value Loss: 5.944    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 261098     Buffer Size: 25593      Transition Number: 1500.130k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:26:29,299][train][INFO][train.py>_log] ==> #345000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 4.827    Value Loss: 6.062    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 261804     Buffer Size: 25657      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:29:52,118][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 5.490    Value Loss: 6.269    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 262553     Buffer Size: 25722      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:33:14,664][train][INFO][train.py>_log] ==> #347000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 4.995    Value Loss: 6.383    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 263437     Buffer Size: 25914      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:36:34,479][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 5.765    Value Loss: 6.431    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 264278     Buffer Size: 26017      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:39:59,101][train][INFO][train.py>_log] ==> #349000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 5.334    Value Loss: 6.496    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 265129     Buffer Size: 26069      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:43:25,793][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 4.930    Value Loss: 6.241    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 265937     Buffer Size: 26152      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:46:50,470][train][INFO][train.py>_log] ==> #351000     Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 4.772    Value Loss: 6.710    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 266825     Buffer Size: 26272      Transition Number: 1500.085k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:50:14,089][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 4.441    Value Loss: 6.388    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 267742     Buffer Size: 26488      Transition Number: 1500.217k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:53:36,593][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.071    [weighted Loss:2.071    Policy Loss: 4.411    Value Loss: 6.274    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 268524     Buffer Size: 26636      Transition Number: 1500.204k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:56:58,845][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 4.984    Value Loss: 6.593    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 269387     Buffer Size: 26775      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:00:21,029][train][INFO][train.py>_log] ==> #355000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 5.836    Value Loss: 6.335    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 270200     Buffer Size: 26924      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:03:44,139][train][INFO][train.py>_log] ==> #356000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 4.528    Value Loss: 6.187    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 271069     Buffer Size: 27075      Transition Number: 1500.269k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:07:05,269][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 5.204    Value Loss: 6.354    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 271824     Buffer Size: 27156      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:10:27,655][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 4.590    Value Loss: 6.273    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 272545     Buffer Size: 27210      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:13:49,635][train][INFO][train.py>_log] ==> #359000     Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 4.825    Value Loss: 6.763    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 273321     Buffer Size: 27265      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:17:11,152][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.600    [weighted Loss:2.600    Policy Loss: 5.101    Value Loss: 6.726    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 274010     Buffer Size: 27284      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:20:34,054][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 5.404    Value Loss: 6.762    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 274931     Buffer Size: 27416      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:23:56,756][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 5.112    Value Loss: 6.720    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 275826     Buffer Size: 27588      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:27:18,205][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 5.329    Value Loss: 6.910    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 276924     Buffer Size: 27964      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:30:41,875][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 5.348    Value Loss: 6.722    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 278082     Buffer Size: 28392      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:34:01,796][train][INFO][train.py>_log] ==> #365000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 5.862    Value Loss: 6.758    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 278952     Buffer Size: 28631      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:37:24,316][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.745    [weighted Loss:1.745    Policy Loss: 5.101    Value Loss: 6.768    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 279909     Buffer Size: 28876      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:40:45,479][train][INFO][train.py>_log] ==> #367000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 5.127    Value Loss: 6.849    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 280765     Buffer Size: 29045      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:44:08,031][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.709    [weighted Loss:2.709    Policy Loss: 5.398    Value Loss: 6.340    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 281572     Buffer Size: 29189      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:47:33,288][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 4.946    Value Loss: 7.068    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 282674     Buffer Size: 29557      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:50:56,384][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 4.993    Value Loss: 6.899    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 283818     Buffer Size: 29982      Transition Number: 1500.102k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:54:14,919][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 4.971    Value Loss: 6.834    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 284651     Buffer Size: 30133      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:57:38,058][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 4.799    Value Loss: 7.138    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 285537     Buffer Size: 30247      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:01:02,414][train][INFO][train.py>_log] ==> #373000     Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 5.473    Value Loss: 6.635    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 286443     Buffer Size: 30326      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:04:25,758][train][INFO][train.py>_log] ==> #374000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 4.952    Value Loss: 7.221    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 287337     Buffer Size: 30393      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:07:52,080][train][INFO][train.py>_log] ==> #375000     Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 4.940    Value Loss: 6.595    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 288212     Buffer Size: 30507      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:11:14,033][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 4.796    Value Loss: 7.081    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 289068     Buffer Size: 30612      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:14:37,044][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 4.854    Value Loss: 6.855    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 289868     Buffer Size: 30662      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:17:58,777][train][INFO][train.py>_log] ==> #378000     Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 4.668    Value Loss: 6.637    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 290664     Buffer Size: 30747      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:21:19,928][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 4.980    Value Loss: 6.901    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 291544     Buffer Size: 30874      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:24:43,239][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 6.395    Value Loss: 7.071    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 292392     Buffer Size: 30987      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:28:05,487][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 5.039    Value Loss: 6.473    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 293311     Buffer Size: 31197      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:31:25,855][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 5.506    Value Loss: 7.083    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 294270     Buffer Size: 31379      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:34:47,167][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 4.789    Value Loss: 7.282    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 295426     Buffer Size: 31621      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:38:06,360][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 5.549    Value Loss: 7.364    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 296568     Buffer Size: 31902      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:41:26,188][train][INFO][train.py>_log] ==> #385000     Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 6.127    Value Loss: 6.828    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 297393     Buffer Size: 31996      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:44:47,372][train][INFO][train.py>_log] ==> #386000     Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 5.306    Value Loss: 6.537    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 298333     Buffer Size: 32052      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:48:07,073][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.963    [weighted Loss:1.963    Policy Loss: 4.995    Value Loss: 6.772    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 299090     Buffer Size: 31975      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:51:30,022][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.222    [weighted Loss:2.222    Policy Loss: 4.994    Value Loss: 6.972    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 299853     Buffer Size: 31859      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:54:50,203][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.915    [weighted Loss:2.915    Policy Loss: 5.453    Value Loss: 7.057    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 300689     Buffer Size: 31860      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:58:12,384][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 6.427    Value Loss: 7.285    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 301484     Buffer Size: 31903      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:01:34,410][train][INFO][train.py>_log] ==> #391000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 5.152    Value Loss: 7.231    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 302638     Buffer Size: 32129      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:04:56,338][train][INFO][train.py>_log] ==> #392000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 6.070    Value Loss: 7.350    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 303760     Buffer Size: 32408      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:08:15,165][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 5.952    Value Loss: 7.220    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 304991     Buffer Size: 32882      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:11:35,725][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 6.630    Value Loss: 7.036    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 306241     Buffer Size: 33381      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:14:54,383][train][INFO][train.py>_log] ==> #395000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 5.909    Value Loss: 6.990    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 307392     Buffer Size: 33785      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:18:14,910][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 6.517    Value Loss: 7.225    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 308566     Buffer Size: 34136      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:21:32,992][train][INFO][train.py>_log] ==> #397000     Total Loss: 2.996    [weighted Loss:2.996    Policy Loss: 5.943    Value Loss: 7.083    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 309901     Buffer Size: 34565      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:24:52,924][train][INFO][train.py>_log] ==> #398000     Total Loss: 3.550    [weighted Loss:3.550    Policy Loss: 6.750    Value Loss: 6.845    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 311263     Buffer Size: 34918      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:28:13,334][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 7.428    Value Loss: 7.477    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 312270     Buffer Size: 34890      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:31:30,096][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 6.561    Value Loss: 7.002    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 313283     Buffer Size: 34814      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:34:49,808][train][INFO][train.py>_log] ==> #401000     Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 6.450    Value Loss: 7.163    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 314287     Buffer Size: 34877      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:38:09,872][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.830    [weighted Loss:2.830    Policy Loss: 6.353    Value Loss: 7.499    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 315320     Buffer Size: 34989      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:41:31,946][train][INFO][train.py>_log] ==> #403000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 6.433    Value Loss: 7.075    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 316663     Buffer Size: 35454      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:44:49,381][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 6.666    Value Loss: 7.484    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 317954     Buffer Size: 35833      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:48:09,609][train][INFO][train.py>_log] ==> #405000     Total Loss: 3.423    [weighted Loss:3.423    Policy Loss: 8.147    Value Loss: 7.051    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 319102     Buffer Size: 35883      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:51:27,395][train][INFO][train.py>_log] ==> #406000     Total Loss: 3.871    [weighted Loss:3.871    Policy Loss: 7.151    Value Loss: 6.955    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 320208     Buffer Size: 35946      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:54:47,833][train][INFO][train.py>_log] ==> #407000     Total Loss: 3.153    [weighted Loss:3.153    Policy Loss: 7.428    Value Loss: 6.931    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 321387     Buffer Size: 36280      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:58:09,101][train][INFO][train.py>_log] ==> #408000     Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 6.588    Value Loss: 6.959    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 322566     Buffer Size: 36549      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:01:26,928][train][INFO][train.py>_log] ==> #409000     Total Loss: 3.834    [weighted Loss:3.834    Policy Loss: 6.464    Value Loss: 7.677    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 323513     Buffer Size: 36638      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:04:46,324][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 6.066    Value Loss: 7.212    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 324447     Buffer Size: 36722      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:08:08,363][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 7.042    Value Loss: 7.302    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 325540     Buffer Size: 36921      Transition Number: 1500.061k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:11:28,813][train][INFO][train.py>_log] ==> #412000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 5.827    Value Loss: 7.019    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 326575     Buffer Size: 37136      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:14:45,551][train][INFO][train.py>_log] ==> #413000     Total Loss: 4.187    [weighted Loss:4.187    Policy Loss: 7.601    Value Loss: 7.217    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 327749     Buffer Size: 37504      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:18:04,218][train][INFO][train.py>_log] ==> #414000     Total Loss: 3.508    [weighted Loss:3.508    Policy Loss: 7.383    Value Loss: 7.283    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 328926     Buffer Size: 37823      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:21:22,668][train][INFO][train.py>_log] ==> #415000     Total Loss: 3.413    [weighted Loss:3.413    Policy Loss: 7.843    Value Loss: 7.150    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 330045     Buffer Size: 38080      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:24:40,780][train][INFO][train.py>_log] ==> #416000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 7.059    Value Loss: 7.073    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 331144     Buffer Size: 38286      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:28:01,874][train][INFO][train.py>_log] ==> #417000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 9.307    Value Loss: 7.509    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 332254     Buffer Size: 38459      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:31:22,584][train][INFO][train.py>_log] ==> #418000     Total Loss: 3.860    [weighted Loss:3.860    Policy Loss: 8.119    Value Loss: 7.193    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 333373     Buffer Size: 38519      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:34:41,728][train][INFO][train.py>_log] ==> #419000     Total Loss: 4.264    [weighted Loss:4.264    Policy Loss: 9.137    Value Loss: 7.507    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 334650     Buffer Size: 38645      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:38:00,598][train][INFO][train.py>_log] ==> #420000     Total Loss: 3.383    [weighted Loss:3.383    Policy Loss: 8.250    Value Loss: 7.129    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 335874     Buffer Size: 38832      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:41:17,432][train][INFO][train.py>_log] ==> #421000     Total Loss: 3.188    [weighted Loss:3.188    Policy Loss: 8.572    Value Loss: 7.329    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 337217     Buffer Size: 39275      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:44:35,434][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 8.658    Value Loss: 7.279    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 338576     Buffer Size: 39799      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:47:55,596][train][INFO][train.py>_log] ==> #423000     Total Loss: 1.294    [weighted Loss:1.294    Policy Loss: 8.059    Value Loss: 7.091    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 340013     Buffer Size: 40405      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:51:14,788][train][INFO][train.py>_log] ==> #424000     Total Loss: 3.436    [weighted Loss:3.436    Policy Loss: 7.748    Value Loss: 7.164    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 341386     Buffer Size: 40966      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:54:32,413][train][INFO][train.py>_log] ==> #425000     Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 8.784    Value Loss: 7.341    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 342626     Buffer Size: 41375      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:57:49,791][train][INFO][train.py>_log] ==> #426000     Total Loss: 4.914    [weighted Loss:4.914    Policy Loss: 8.182    Value Loss: 7.120    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 343923     Buffer Size: 41688      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:01:03,737][train][INFO][train.py>_log] ==> #427000     Total Loss: 4.362    [weighted Loss:4.362    Policy Loss: 7.803    Value Loss: 7.185    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 344959     Buffer Size: 41683      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:04:18,644][train][INFO][train.py>_log] ==> #428000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 7.362    Value Loss: 7.196    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 346002     Buffer Size: 41574      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:07:38,763][train][INFO][train.py>_log] ==> #429000     Total Loss: 3.319    [weighted Loss:3.319    Policy Loss: 7.975    Value Loss: 7.177    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 347137     Buffer Size: 41514      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:10:54,832][train][INFO][train.py>_log] ==> #430000     Total Loss: 2.320    [weighted Loss:2.320    Policy Loss: 6.905    Value Loss: 6.933    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 348267     Buffer Size: 41457      Transition Number: 1500.130k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:14:09,861][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 7.732    Value Loss: 7.333    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 349173     Buffer Size: 41300      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:17:28,264][train][INFO][train.py>_log] ==> #432000     Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 8.466    Value Loss: 7.552    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 350110     Buffer Size: 41035      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:20:48,786][train][INFO][train.py>_log] ==> #433000     Total Loss: 5.307    [weighted Loss:5.307    Policy Loss: 7.207    Value Loss: 7.014    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 351114     Buffer Size: 40713      Transition Number: 1500.115k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:24:04,670][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.788    [weighted Loss:3.788    Policy Loss: 7.953    Value Loss: 7.342    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 352032     Buffer Size: 40429      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:27:25,392][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 7.468    Value Loss: 6.991    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 353399     Buffer Size: 40746      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:30:42,331][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 7.204    Value Loss: 7.080    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 354803     Buffer Size: 41121      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:34:00,226][train][INFO][train.py>_log] ==> #437000     Total Loss: 3.334    [weighted Loss:3.334    Policy Loss: 7.438    Value Loss: 7.524    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 356292     Buffer Size: 41570      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:37:14,209][train][INFO][train.py>_log] ==> #438000     Total Loss: 3.912    [weighted Loss:3.912    Policy Loss: 8.454    Value Loss: 7.255    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 357766     Buffer Size: 41974      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:40:30,806][train][INFO][train.py>_log] ==> #439000     Total Loss: 3.870    [weighted Loss:3.870    Policy Loss: 6.625    Value Loss: 7.236    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 359017     Buffer Size: 41951      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:43:47,993][train][INFO][train.py>_log] ==> #440000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 7.374    Value Loss: 7.460    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 360284     Buffer Size: 41909      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:47:06,564][train][INFO][train.py>_log] ==> #441000     Total Loss: 4.905    [weighted Loss:4.905    Policy Loss: 8.509    Value Loss: 7.207    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 361207     Buffer Size: 41745      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:50:23,281][train][INFO][train.py>_log] ==> #442000     Total Loss: 4.594    [weighted Loss:4.594    Policy Loss: 7.317    Value Loss: 7.119    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 362136     Buffer Size: 41601      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:53:41,928][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.295    [weighted Loss:3.295    Policy Loss: 7.173    Value Loss: 7.277    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 363338     Buffer Size: 41556      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:56:59,346][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.239    [weighted Loss:2.239    Policy Loss: 9.083    Value Loss: 6.993    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 364503     Buffer Size: 41607      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:00:20,218][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 8.119    Value Loss: 7.179    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 367307     Buffer Size: 43331      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:03:37,625][train][INFO][train.py>_log] ==> #446000     Total Loss: 5.234    [weighted Loss:5.234    Policy Loss: 9.634    Value Loss: 7.690    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 370032     Buffer Size: 44966      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:06:55,178][train][INFO][train.py>_log] ==> #447000     Total Loss: 4.452    [weighted Loss:4.452    Policy Loss: 8.705    Value Loss: 7.193    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 372088     Buffer Size: 45948      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:10:14,257][train][INFO][train.py>_log] ==> #448000     Total Loss: 3.525    [weighted Loss:3.525    Policy Loss: 8.838    Value Loss: 7.155    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 374106     Buffer Size: 46848      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:13:28,892][train][INFO][train.py>_log] ==> #449000     Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 8.806    Value Loss: 7.155    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 375236     Buffer Size: 46870      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:16:42,882][train][INFO][train.py>_log] ==> #450000     Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 9.094    Value Loss: 7.175    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 376414     Buffer Size: 46911      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:19:57,219][train][INFO][train.py>_log] ==> #451000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 7.893    Value Loss: 7.826    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 377637     Buffer Size: 47014      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:23:14,436][train][INFO][train.py>_log] ==> #452000     Total Loss: 4.355    [weighted Loss:4.355    Policy Loss: 9.464    Value Loss: 7.311    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 378871     Buffer Size: 47204      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:26:31,576][train][INFO][train.py>_log] ==> #453000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 7.223    Value Loss: 7.097    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 380017     Buffer Size: 47266      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:29:48,678][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 8.091    Value Loss: 7.077    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 381230     Buffer Size: 47272      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:33:03,562][train][INFO][train.py>_log] ==> #455000     Total Loss: 4.715    [weighted Loss:4.715    Policy Loss: 9.165    Value Loss: 7.395    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 382264     Buffer Size: 47159      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:36:19,787][train][INFO][train.py>_log] ==> #456000     Total Loss: 4.466    [weighted Loss:4.466    Policy Loss: 8.276    Value Loss: 7.396    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 383304     Buffer Size: 46966      Transition Number: 1500.159k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:39:37,315][train][INFO][train.py>_log] ==> #457000     Total Loss: 4.991    [weighted Loss:4.991    Policy Loss: 8.392    Value Loss: 7.595    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 384268     Buffer Size: 46654      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:42:52,288][train][INFO][train.py>_log] ==> #458000     Total Loss: 4.348    [weighted Loss:4.348    Policy Loss: 7.749    Value Loss: 7.184    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 385275     Buffer Size: 46316      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:46:11,072][train][INFO][train.py>_log] ==> #459000     Total Loss: 5.478    [weighted Loss:5.478    Policy Loss: 10.045   Value Loss: 7.284    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 386183     Buffer Size: 45859      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:49:29,377][train][INFO][train.py>_log] ==> #460000     Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 7.871    Value Loss: 7.299    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 387073     Buffer Size: 45445      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:52:45,198][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 8.884    Value Loss: 7.218    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 388376     Buffer Size: 45517      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:56:02,331][train][INFO][train.py>_log] ==> #462000     Total Loss: 3.726    [weighted Loss:3.726    Policy Loss: 7.066    Value Loss: 7.067    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 389790     Buffer Size: 45656      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:59:20,910][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 6.441    Value Loss: 7.268    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 391349     Buffer Size: 46097      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:02:37,833][train][INFO][train.py>_log] ==> #464000     Total Loss: 3.267    [weighted Loss:3.267    Policy Loss: 8.222    Value Loss: 7.525    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 392919     Buffer Size: 46548      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:05:53,334][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.354    [weighted Loss:3.354    Policy Loss: 7.058    Value Loss: 7.721    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 394243     Buffer Size: 46770      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:09:12,515][train][INFO][train.py>_log] ==> #466000     Total Loss: 4.069    [weighted Loss:4.069    Policy Loss: 8.481    Value Loss: 7.680    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 395642     Buffer Size: 47023      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:12:30,672][train][INFO][train.py>_log] ==> #467000     Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 7.273    Value Loss: 7.036    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 396709     Buffer Size: 47136      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:15:44,747][train][INFO][train.py>_log] ==> #468000     Total Loss: 1.989    [weighted Loss:1.989    Policy Loss: 6.930    Value Loss: 7.038    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 397689     Buffer Size: 47170      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:19:03,041][train][INFO][train.py>_log] ==> #469000     Total Loss: 4.882    [weighted Loss:4.882    Policy Loss: 7.157    Value Loss: 6.963    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 398872     Buffer Size: 47392      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:22:20,773][train][INFO][train.py>_log] ==> #470000     Total Loss: 3.687    [weighted Loss:3.687    Policy Loss: 8.060    Value Loss: 7.189    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 400125     Buffer Size: 47547      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:25:39,036][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 6.966    Value Loss: 7.234    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 401465     Buffer Size: 47466      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:28:55,503][train][INFO][train.py>_log] ==> #472000     Total Loss: 3.181    [weighted Loss:3.181    Policy Loss: 7.438    Value Loss: 7.346    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 402848     Buffer Size: 47420      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:32:16,047][train][INFO][train.py>_log] ==> #473000     Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 6.880    Value Loss: 7.292    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 403720     Buffer Size: 46941      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:35:31,568][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 6.301    Value Loss: 7.132    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 404604     Buffer Size: 46489      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:38:49,574][train][INFO][train.py>_log] ==> #475000     Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 8.183    Value Loss: 7.226    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 405617     Buffer Size: 46194      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:42:03,432][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 7.832    Value Loss: 7.528    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 406536     Buffer Size: 45989      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:45:21,324][train][INFO][train.py>_log] ==> #477000     Total Loss: 3.333    [weighted Loss:3.333    Policy Loss: 7.439    Value Loss: 7.408    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 407718     Buffer Size: 46211      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:48:39,924][train][INFO][train.py>_log] ==> #478000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 6.796    Value Loss: 7.316    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 408972     Buffer Size: 46489      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:51:57,731][train][INFO][train.py>_log] ==> #479000     Total Loss: 3.047    [weighted Loss:3.047    Policy Loss: 7.747    Value Loss: 6.999    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 410016     Buffer Size: 46356      Transition Number: 1500.137k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:55:14,765][train][INFO][train.py>_log] ==> #480000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 6.360    Value Loss: 7.306    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 411035     Buffer Size: 46018      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:58:34,289][train][INFO][train.py>_log] ==> #481000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 7.042    Value Loss: 7.358    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 412153     Buffer Size: 44510      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:01:53,765][train][INFO][train.py>_log] ==> #482000     Total Loss: 1.642    [weighted Loss:1.642    Policy Loss: 6.086    Value Loss: 7.188    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 413266     Buffer Size: 43105      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:05:15,645][train][INFO][train.py>_log] ==> #483000     Total Loss: 4.237    [weighted Loss:4.237    Policy Loss: 6.380    Value Loss: 7.281    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 414162     Buffer Size: 42053      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:08:35,630][train][INFO][train.py>_log] ==> #484000     Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 5.397    Value Loss: 7.478    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 415082     Buffer Size: 40953      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:11:52,626][train][INFO][train.py>_log] ==> #485000     Total Loss: 3.028    [weighted Loss:3.028    Policy Loss: 6.610    Value Loss: 7.164    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 416055     Buffer Size: 40800      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:15:13,214][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 6.154    Value Loss: 7.318    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 417046     Buffer Size: 40658      Transition Number: 1500.165k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:18:34,583][train][INFO][train.py>_log] ==> #487000     Total Loss: 3.675    [weighted Loss:3.675    Policy Loss: 7.298    Value Loss: 7.296    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 418444     Buffer Size: 40758      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:21:54,076][train][INFO][train.py>_log] ==> #488000     Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 6.597    Value Loss: 7.455    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 419798     Buffer Size: 40825      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:25:11,460][train][INFO][train.py>_log] ==> #489000     Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 6.316    Value Loss: 7.307    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 420816     Buffer Size: 40730      Transition Number: 1500.122k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:28:29,741][train][INFO][train.py>_log] ==> #490000     Total Loss: 1.224    [weighted Loss:1.224    Policy Loss: 6.547    Value Loss: 6.957    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 421812     Buffer Size: 40539      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:31:44,517][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 7.458    Value Loss: 7.193    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 422888     Buffer Size: 40566      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:35:04,374][train][INFO][train.py>_log] ==> #492000     Total Loss: 4.116    [weighted Loss:4.116    Policy Loss: 6.811    Value Loss: 7.594    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 423972     Buffer Size: 40609      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:38:20,583][train][INFO][train.py>_log] ==> #493000     Total Loss: 3.850    [weighted Loss:3.850    Policy Loss: 7.727    Value Loss: 7.349    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 424959     Buffer Size: 40589      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:41:38,839][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 7.572    Value Loss: 7.173    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 425956     Buffer Size: 40604      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:44:57,030][train][INFO][train.py>_log] ==> #495000     Total Loss: 1.247    [weighted Loss:1.247    Policy Loss: 6.021    Value Loss: 7.196    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 427071     Buffer Size: 40808      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:48:18,794][train][INFO][train.py>_log] ==> #496000     Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 8.011    Value Loss: 7.359    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 428262     Buffer Size: 41020      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:51:35,924][train][INFO][train.py>_log] ==> #497000     Total Loss: 4.899    [weighted Loss:4.899    Policy Loss: 7.615    Value Loss: 7.592    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 429395     Buffer Size: 40808      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:54:55,782][train][INFO][train.py>_log] ==> #498000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 7.529    Value Loss: 7.418    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 430556     Buffer Size: 40523      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:58:14,510][train][INFO][train.py>_log] ==> #499000     Total Loss: 4.164    [weighted Loss:4.164    Policy Loss: 7.330    Value Loss: 7.385    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 431803     Buffer Size: 40215      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:01:34,412][train][INFO][train.py>_log] ==> #500000     Total Loss: 4.589    [weighted Loss:4.589    Policy Loss: 8.053    Value Loss: 7.649    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 433118     Buffer Size: 39935      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:04:54,925][train][INFO][train.py>_log] ==> #501000     Total Loss: 3.733    [weighted Loss:3.733    Policy Loss: 8.567    Value Loss: 7.315    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 434414     Buffer Size: 39877      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:08:12,299][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 8.327    Value Loss: 7.388    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 435723     Buffer Size: 39840      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:11:31,758][train][INFO][train.py>_log] ==> #503000     Total Loss: 4.478    [weighted Loss:4.478    Policy Loss: 8.367    Value Loss: 7.183    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 436944     Buffer Size: 40014      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:14:50,285][train][INFO][train.py>_log] ==> #504000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 9.206    Value Loss: 7.534    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 438154     Buffer Size: 40151      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:18:12,275][train][INFO][train.py>_log] ==> #505000     Total Loss: 3.194    [weighted Loss:3.194    Policy Loss: 6.894    Value Loss: 7.271    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 439287     Buffer Size: 40079      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:21:29,867][train][INFO][train.py>_log] ==> #506000     Total Loss: 4.034    [weighted Loss:4.034    Policy Loss: 6.854    Value Loss: 7.504    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 440431     Buffer Size: 39926      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:24:49,838][train][INFO][train.py>_log] ==> #507000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 8.099    Value Loss: 7.454    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 441535     Buffer Size: 39746      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:28:12,139][train][INFO][train.py>_log] ==> #508000     Total Loss: 1.898    [weighted Loss:1.898    Policy Loss: 7.264    Value Loss: 7.258    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 442689     Buffer Size: 39601      Transition Number: 1500.166k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:31:30,122][train][INFO][train.py>_log] ==> #509000     Total Loss: 2.475    [weighted Loss:2.475    Policy Loss: 7.701    Value Loss: 7.419    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 443854     Buffer Size: 39812      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:34:48,410][train][INFO][train.py>_log] ==> #510000     Total Loss: 3.952    [weighted Loss:3.952    Policy Loss: 6.434    Value Loss: 7.383    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 445056     Buffer Size: 40072      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:38:05,628][train][INFO][train.py>_log] ==> #511000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 7.423    Value Loss: 7.145    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 445859     Buffer Size: 39940      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:41:22,652][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 6.923    Value Loss: 7.052    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 446698     Buffer Size: 39786      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:44:42,048][train][INFO][train.py>_log] ==> #513000     Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 6.846    Value Loss: 7.345    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 447721     Buffer Size: 39624      Transition Number: 1500.119k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:47:59,923][train][INFO][train.py>_log] ==> #514000     Total Loss: 2.683    [weighted Loss:2.683    Policy Loss: 6.297    Value Loss: 7.359    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 448751     Buffer Size: 39440      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:51:17,963][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 6.556    Value Loss: 7.241    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 449953     Buffer Size: 39587      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:54:38,602][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 6.984    Value Loss: 6.957    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 451179     Buffer Size: 39713      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:57:58,656][train][INFO][train.py>_log] ==> #517000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 6.656    Value Loss: 6.880    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 452149     Buffer Size: 39588      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:01:18,609][train][INFO][train.py>_log] ==> #518000     Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 6.245    Value Loss: 7.163    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 453123     Buffer Size: 39513      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:04:39,484][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 6.847    Value Loss: 7.242    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 454675     Buffer Size: 40131      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:08:00,296][train][INFO][train.py>_log] ==> #520000     Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 6.849    Value Loss: 7.245    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 456258     Buffer Size: 40750      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:11:19,633][train][INFO][train.py>_log] ==> #521000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 7.195    Value Loss: 7.183    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 457470     Buffer Size: 40970      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:14:37,710][train][INFO][train.py>_log] ==> #522000     Total Loss: 4.347    [weighted Loss:4.347    Policy Loss: 6.214    Value Loss: 7.287    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 458752     Buffer Size: 41143      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:17:59,602][train][INFO][train.py>_log] ==> #523000     Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 6.799    Value Loss: 6.893    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 459629     Buffer Size: 40703      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:21:21,531][train][INFO][train.py>_log] ==> #524000     Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 6.618    Value Loss: 7.391    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 460465     Buffer Size: 40308      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:24:38,621][train][INFO][train.py>_log] ==> #525000     Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 8.472    Value Loss: 7.389    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 461461     Buffer Size: 40276      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:28:02,215][train][INFO][train.py>_log] ==> #526000     Total Loss: 4.239    [weighted Loss:4.239    Policy Loss: 7.127    Value Loss: 6.918    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 462440     Buffer Size: 40235      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:31:22,281][train][INFO][train.py>_log] ==> #527000     Total Loss: 3.131    [weighted Loss:3.131    Policy Loss: 7.319    Value Loss: 7.018    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 463381     Buffer Size: 40041      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:34:39,372][train][INFO][train.py>_log] ==> #528000     Total Loss: 3.984    [weighted Loss:3.984    Policy Loss: 7.474    Value Loss: 7.225    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 464272     Buffer Size: 39901      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:37:58,618][train][INFO][train.py>_log] ==> #529000     Total Loss: 3.923    [weighted Loss:3.923    Policy Loss: 7.034    Value Loss: 7.097    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 465288     Buffer Size: 39915      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:41:15,092][train][INFO][train.py>_log] ==> #530000     Total Loss: 3.356    [weighted Loss:3.356    Policy Loss: 6.956    Value Loss: 7.184    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 466260     Buffer Size: 39879      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:44:38,893][train][INFO][train.py>_log] ==> #531000     Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 7.683    Value Loss: 7.044    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 468110     Buffer Size: 40509      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:47:56,669][train][INFO][train.py>_log] ==> #532000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 8.308    Value Loss: 7.364    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 470111     Buffer Size: 41288      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:51:15,813][train][INFO][train.py>_log] ==> #533000     Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 7.730    Value Loss: 7.026    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 471916     Buffer Size: 41909      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:54:34,982][train][INFO][train.py>_log] ==> #534000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 7.495    Value Loss: 6.867    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 473724     Buffer Size: 42476      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:57:53,129][train][INFO][train.py>_log] ==> #535000     Total Loss: 3.362    [weighted Loss:3.362    Policy Loss: 7.662    Value Loss: 6.685    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 474692     Buffer Size: 42282      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:01:12,342][train][INFO][train.py>_log] ==> #536000     Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 7.195    Value Loss: 6.943    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 475711     Buffer Size: 41973      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:04:34,116][train][INFO][train.py>_log] ==> #537000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 8.357    Value Loss: 7.329    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 476548     Buffer Size: 41538      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:07:54,342][train][INFO][train.py>_log] ==> #538000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 5.744    Value Loss: 6.865    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 477396     Buffer Size: 41144      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:11:12,480][train][INFO][train.py>_log] ==> #539000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 7.698    Value Loss: 6.879    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 478228     Buffer Size: 40830      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:14:30,820][train][INFO][train.py>_log] ==> #540000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 6.614    Value Loss: 6.725    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 479110     Buffer Size: 40539      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:17:51,866][train][INFO][train.py>_log] ==> #541000     Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 7.726    Value Loss: 6.996    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 480123     Buffer Size: 40442      Transition Number: 1500.066k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:21:10,366][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 7.131    Value Loss: 7.020    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 481182     Buffer Size: 40399      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:24:31,330][train][INFO][train.py>_log] ==> #543000     Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 6.481    Value Loss: 6.537    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 482628     Buffer Size: 40668      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:27:52,590][train][INFO][train.py>_log] ==> #544000     Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 7.876    Value Loss: 6.878    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 484075     Buffer Size: 40921      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:31:10,906][train][INFO][train.py>_log] ==> #545000     Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 8.071    Value Loss: 6.706    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 485204     Buffer Size: 40878      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:34:27,155][train][INFO][train.py>_log] ==> #546000     Total Loss: 3.341    [weighted Loss:3.341    Policy Loss: 7.066    Value Loss: 7.082    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 486327     Buffer Size: 40952      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:37:48,086][train][INFO][train.py>_log] ==> #547000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 7.977    Value Loss: 7.312    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 487258     Buffer Size: 41053      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:41:07,118][train][INFO][train.py>_log] ==> #548000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 8.340    Value Loss: 7.113    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 488192     Buffer Size: 41077      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:44:25,765][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 9.019    Value Loss: 7.294    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 489329     Buffer Size: 41134      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:47:46,835][train][INFO][train.py>_log] ==> #550000     Total Loss: 5.169    [weighted Loss:5.169    Policy Loss: 9.624    Value Loss: 7.099    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 490531     Buffer Size: 41174      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:51:04,197][train][INFO][train.py>_log] ==> #551000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 8.506    Value Loss: 7.537    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 491797     Buffer Size: 41233      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:54:22,636][train][INFO][train.py>_log] ==> #552000     Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 9.250    Value Loss: 7.435    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 493055     Buffer Size: 41388      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:57:42,779][train][INFO][train.py>_log] ==> #553000     Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 8.935    Value Loss: 6.999    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 494532     Buffer Size: 41830      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:01:01,375][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 8.914    Value Loss: 7.373    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 496030     Buffer Size: 41991      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:04:22,526][train][INFO][train.py>_log] ==> #555000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 7.667    Value Loss: 7.120    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 497240     Buffer Size: 41608      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:07:40,708][train][INFO][train.py>_log] ==> #556000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 8.499    Value Loss: 7.550    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 498428     Buffer Size: 41405      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:11:01,742][train][INFO][train.py>_log] ==> #557000     Total Loss: 3.737    [weighted Loss:3.737    Policy Loss: 7.657    Value Loss: 7.142    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 499786     Buffer Size: 41431      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:14:22,113][train][INFO][train.py>_log] ==> #558000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 8.049    Value Loss: 7.536    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 501139     Buffer Size: 41748      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:17:40,146][train][INFO][train.py>_log] ==> #559000     Total Loss: 4.162    [weighted Loss:4.162    Policy Loss: 9.295    Value Loss: 7.483    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 502352     Buffer Size: 42090      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:20:57,952][train][INFO][train.py>_log] ==> #560000     Total Loss: 2.956    [weighted Loss:2.956    Policy Loss: 8.412    Value Loss: 7.606    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 503542     Buffer Size: 42329      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:24:14,917][train][INFO][train.py>_log] ==> #561000     Total Loss: 3.654    [weighted Loss:3.654    Policy Loss: 8.784    Value Loss: 7.409    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 504983     Buffer Size: 42741      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:27:32,318][train][INFO][train.py>_log] ==> #562000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 8.683    Value Loss: 7.348    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 506434     Buffer Size: 43218      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:30:49,836][train][INFO][train.py>_log] ==> #563000     Total Loss: 2.216    [weighted Loss:2.216    Policy Loss: 8.177    Value Loss: 7.485    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 507621     Buffer Size: 43481      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:34:06,573][train][INFO][train.py>_log] ==> #564000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 9.609    Value Loss: 7.452    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 508787     Buffer Size: 43661      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:37:24,938][train][INFO][train.py>_log] ==> #565000     Total Loss: 3.851    [weighted Loss:3.851    Policy Loss: 7.588    Value Loss: 7.004    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 510081     Buffer Size: 43903      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:40:40,915][train][INFO][train.py>_log] ==> #566000     Total Loss: 4.029    [weighted Loss:4.029    Policy Loss: 9.526    Value Loss: 7.630    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 511408     Buffer Size: 43574      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:44:00,751][train][INFO][train.py>_log] ==> #567000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 9.018    Value Loss: 7.217    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 512897     Buffer Size: 43093      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:47:19,164][train][INFO][train.py>_log] ==> #568000     Total Loss: 4.228    [weighted Loss:4.228    Policy Loss: 9.148    Value Loss: 7.777    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 514388     Buffer Size: 42751      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:50:41,300][train][INFO][train.py>_log] ==> #569000     Total Loss: 3.442    [weighted Loss:3.442    Policy Loss: 7.970    Value Loss: 7.327    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 515711     Buffer Size: 42319      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:53:58,086][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 8.031    Value Loss: 7.482    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 517001     Buffer Size: 42456      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:57:15,444][train][INFO][train.py>_log] ==> #571000     Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 9.514    Value Loss: 7.604    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 518345     Buffer Size: 42821      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:00:36,444][train][INFO][train.py>_log] ==> #572000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.532    Value Loss: 7.553    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 519784     Buffer Size: 43359      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:03:49,809][train][INFO][train.py>_log] ==> #573000     Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 9.115    Value Loss: 7.558    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 520872     Buffer Size: 43647      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:07:05,943][train][INFO][train.py>_log] ==> #574000     Total Loss: 3.970    [weighted Loss:3.970    Policy Loss: 8.598    Value Loss: 7.090    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 521974     Buffer Size: 43900      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:10:22,714][train][INFO][train.py>_log] ==> #575000     Total Loss: 4.883    [weighted Loss:4.883    Policy Loss: 8.323    Value Loss: 7.660    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 523527     Buffer Size: 44542      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:13:40,361][train][INFO][train.py>_log] ==> #576000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 8.341    Value Loss: 7.507    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 525062     Buffer Size: 45039      Transition Number: 1500.142k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:16:54,621][train][INFO][train.py>_log] ==> #577000     Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 7.697    Value Loss: 7.884    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 526228     Buffer Size: 45209      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:20:12,391][train][INFO][train.py>_log] ==> #578000     Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 7.758    Value Loss: 7.638    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 527486     Buffer Size: 45090      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:23:31,130][train][INFO][train.py>_log] ==> #579000     Total Loss: 3.898    [weighted Loss:3.898    Policy Loss: 7.532    Value Loss: 7.588    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 528328     Buffer Size: 44650      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:26:49,381][train][INFO][train.py>_log] ==> #580000     Total Loss: 3.968    [weighted Loss:3.968    Policy Loss: 7.823    Value Loss: 7.804    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 529197     Buffer Size: 44242      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:30:08,167][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 7.335    Value Loss: 7.324    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 530080     Buffer Size: 44067      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:33:26,673][train][INFO][train.py>_log] ==> #582000     Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 7.635    Value Loss: 7.364    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 531009     Buffer Size: 43970      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:36:43,706][train][INFO][train.py>_log] ==> #583000     Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 7.417    Value Loss: 7.147    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 531998     Buffer Size: 44073      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:40:00,604][train][INFO][train.py>_log] ==> #584000     Total Loss: 3.026    [weighted Loss:3.026    Policy Loss: 8.257    Value Loss: 7.105    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 533059     Buffer Size: 44014      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:43:20,920][train][INFO][train.py>_log] ==> #585000     Total Loss: 3.107    [weighted Loss:3.107    Policy Loss: 7.301    Value Loss: 7.127    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 534145     Buffer Size: 43965      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:46:40,621][train][INFO][train.py>_log] ==> #586000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 7.201    Value Loss: 7.458    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 535259     Buffer Size: 43859      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:49:57,025][train][INFO][train.py>_log] ==> #587000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 6.593    Value Loss: 7.671    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 536367     Buffer Size: 43748      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:53:17,089][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 7.242    Value Loss: 7.310    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 537476     Buffer Size: 43488      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:56:33,055][train][INFO][train.py>_log] ==> #589000     Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 7.140    Value Loss: 7.291    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 538359     Buffer Size: 43038      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:59:52,365][train][INFO][train.py>_log] ==> #590000     Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 8.151    Value Loss: 7.427    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 539281     Buffer Size: 42663      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:03:15,068][train][INFO][train.py>_log] ==> #591000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 5.973    Value Loss: 7.389    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 540347     Buffer Size: 42510      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:06:35,998][train][INFO][train.py>_log] ==> #592000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 8.411    Value Loss: 7.411    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 541396     Buffer Size: 42307      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:09:54,786][train][INFO][train.py>_log] ==> #593000     Total Loss: 3.822    [weighted Loss:3.822    Policy Loss: 7.164    Value Loss: 7.051    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 542782     Buffer Size: 42334      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:13:12,906][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 7.963    Value Loss: 7.623    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 544221     Buffer Size: 42482      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:16:29,804][train][INFO][train.py>_log] ==> #595000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 7.443    Value Loss: 7.520    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 545921     Buffer Size: 42981      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:19:51,448][train][INFO][train.py>_log] ==> #596000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 7.124    Value Loss: 7.445    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 547690     Buffer Size: 43377      Transition Number: 1500.067k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:23:08,614][train][INFO][train.py>_log] ==> #597000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 6.705    Value Loss: 7.545    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 548594     Buffer Size: 43012      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:26:27,622][train][INFO][train.py>_log] ==> #598000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 7.316    Value Loss: 7.379    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 549568     Buffer Size: 42644      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:29:49,874][train][INFO][train.py>_log] ==> #599000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 6.726    Value Loss: 7.050    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 551067     Buffer Size: 42857      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:33:09,518][train][INFO][train.py>_log] ==> #600000     Total Loss: 3.838    [weighted Loss:3.838    Policy Loss: 8.336    Value Loss: 7.220    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 552519     Buffer Size: 43044      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:36:27,502][train][INFO][train.py>_log] ==> #601000     Total Loss: 4.059    [weighted Loss:4.059    Policy Loss: 6.183    Value Loss: 7.433    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 553968     Buffer Size: 43204      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:39:45,223][train][INFO][train.py>_log] ==> #602000     Total Loss: 3.567    [weighted Loss:3.567    Policy Loss: 7.094    Value Loss: 7.545    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 555447     Buffer Size: 43251      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:43:06,752][train][INFO][train.py>_log] ==> #603000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 7.845    Value Loss: 7.542    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 556634     Buffer Size: 42960      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:46:28,675][train][INFO][train.py>_log] ==> #604000     Total Loss: 3.955    [weighted Loss:3.955    Policy Loss: 7.887    Value Loss: 7.723    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 557794     Buffer Size: 42732      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:49:46,806][train][INFO][train.py>_log] ==> #605000     Total Loss: 3.441    [weighted Loss:3.441    Policy Loss: 7.973    Value Loss: 7.431    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 558884     Buffer Size: 42576      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:53:05,996][train][INFO][train.py>_log] ==> #606000     Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 6.882    Value Loss: 7.265    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 559947     Buffer Size: 42317      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:56:23,275][train][INFO][train.py>_log] ==> #607000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 8.252    Value Loss: 7.246    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 560889     Buffer Size: 41940      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:59:43,106][train][INFO][train.py>_log] ==> #608000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 7.046    Value Loss: 7.606    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 561862     Buffer Size: 41597      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:03:01,811][train][INFO][train.py>_log] ==> #609000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 7.572    Value Loss: 7.543    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 562783     Buffer Size: 41433      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:06:22,856][train][INFO][train.py>_log] ==> #610000     Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 6.071    Value Loss: 7.189    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 563726     Buffer Size: 41132      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:09:41,152][train][INFO][train.py>_log] ==> #611000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 7.637    Value Loss: 7.174    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 564613     Buffer Size: 40558      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:13:03,888][train][INFO][train.py>_log] ==> #612000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 7.041    Value Loss: 7.163    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 565566     Buffer Size: 40089      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:16:29,178][train][INFO][train.py>_log] ==> #613000     Total Loss: 3.244    [weighted Loss:3.244    Policy Loss: 7.200    Value Loss: 7.175    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 566371     Buffer Size: 39709      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:19:46,436][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 5.669    Value Loss: 6.993    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 567164     Buffer Size: 39380      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:23:07,505][train][INFO][train.py>_log] ==> #615000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 6.792    Value Loss: 6.852    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 567944     Buffer Size: 39338      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:26:28,859][train][INFO][train.py>_log] ==> #616000     Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 6.072    Value Loss: 6.934    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 568749     Buffer Size: 39257      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:29:45,325][train][INFO][train.py>_log] ==> #617000     Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 7.772    Value Loss: 7.587    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 569555     Buffer Size: 39170      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:33:04,488][train][INFO][train.py>_log] ==> #618000     Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 6.954    Value Loss: 6.922    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 570340     Buffer Size: 39044      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:36:25,751][train][INFO][train.py>_log] ==> #619000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 6.846    Value Loss: 7.348    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 571430     Buffer Size: 39033      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:39:48,904][train][INFO][train.py>_log] ==> #620000     Total Loss: 3.336    [weighted Loss:3.336    Policy Loss: 6.000    Value Loss: 6.943    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 572488     Buffer Size: 38996      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:43:09,541][train][INFO][train.py>_log] ==> #621000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 6.511    Value Loss: 7.033    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 573462     Buffer Size: 38906      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:46:28,852][train][INFO][train.py>_log] ==> #622000     Total Loss: 3.211    [weighted Loss:3.211    Policy Loss: 7.543    Value Loss: 7.328    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 574477     Buffer Size: 38819      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:49:51,066][train][INFO][train.py>_log] ==> #623000     Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 7.946    Value Loss: 7.029    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 575842     Buffer Size: 38989      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:53:11,794][train][INFO][train.py>_log] ==> #624000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 7.455    Value Loss: 7.204    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 577172     Buffer Size: 39295      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:56:32,359][train][INFO][train.py>_log] ==> #625000     Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.797    Value Loss: 7.084    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 578106     Buffer Size: 39279      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:59:52,733][train][INFO][train.py>_log] ==> #626000     Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 7.291    Value Loss: 7.437    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 579026     Buffer Size: 39259      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:03:15,082][train][INFO][train.py>_log] ==> #627000     Total Loss: 3.006    [weighted Loss:3.006    Policy Loss: 8.027    Value Loss: 7.386    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 579949     Buffer Size: 39138      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:06:34,704][train][INFO][train.py>_log] ==> #628000     Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 7.694    Value Loss: 7.409    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 580856     Buffer Size: 38932      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:09:59,161][train][INFO][train.py>_log] ==> #629000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 8.017    Value Loss: 7.245    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 581793     Buffer Size: 38420      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:13:19,097][train][INFO][train.py>_log] ==> #630000     Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 8.326    Value Loss: 7.347    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 582701     Buffer Size: 37801      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:16:40,991][train][INFO][train.py>_log] ==> #631000     Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 7.635    Value Loss: 7.132    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 584343     Buffer Size: 37630      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:20:03,349][train][INFO][train.py>_log] ==> #632000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 7.749    Value Loss: 7.081    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 585989     Buffer Size: 37816      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:23:20,356][train][INFO][train.py>_log] ==> #633000     Total Loss: 3.185    [weighted Loss:3.185    Policy Loss: 8.128    Value Loss: 7.119    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 586826     Buffer Size: 37773      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:26:41,815][train][INFO][train.py>_log] ==> #634000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 8.504    Value Loss: 7.003    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 587720     Buffer Size: 37508      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:30:03,933][train][INFO][train.py>_log] ==> #635000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 9.410    Value Loss: 7.120    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 588703     Buffer Size: 37060      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:33:24,011][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 8.864    Value Loss: 7.270    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 589666     Buffer Size: 36608      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:36:45,567][train][INFO][train.py>_log] ==> #637000     Total Loss: 3.316    [weighted Loss:3.316    Policy Loss: 10.027   Value Loss: 7.241    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 590817     Buffer Size: 36286      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:40:08,469][train][INFO][train.py>_log] ==> #638000     Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 9.432    Value Loss: 7.248    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 591950     Buffer Size: 36042      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:43:29,371][train][INFO][train.py>_log] ==> #639000     Total Loss: 3.875    [weighted Loss:3.875    Policy Loss: 8.833    Value Loss: 7.146    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 593147     Buffer Size: 36025      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:46:51,471][train][INFO][train.py>_log] ==> #640000     Total Loss: 4.368    [weighted Loss:4.368    Policy Loss: 9.535    Value Loss: 6.995    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 594348     Buffer Size: 36050      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:50:16,831][train][INFO][train.py>_log] ==> #641000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 8.821    Value Loss: 7.520    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 595756     Buffer Size: 36290      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:53:41,958][train][INFO][train.py>_log] ==> #642000     Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 9.636    Value Loss: 7.396    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 597089     Buffer Size: 36587      Transition Number: 1500.112k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:57:02,574][train][INFO][train.py>_log] ==> #643000     Total Loss: 3.830    [weighted Loss:3.830    Policy Loss: 9.126    Value Loss: 7.340    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 598504     Buffer Size: 36997      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:00:27,348][train][INFO][train.py>_log] ==> #644000     Total Loss: 3.834    [weighted Loss:3.834    Policy Loss: 9.643    Value Loss: 7.265    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 600034     Buffer Size: 37502      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:03:46,657][train][INFO][train.py>_log] ==> #645000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 7.863    Value Loss: 7.518    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 601311     Buffer Size: 37777      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:07:05,506][train][INFO][train.py>_log] ==> #646000     Total Loss: 3.734    [weighted Loss:3.734    Policy Loss: 8.971    Value Loss: 7.314    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 602583     Buffer Size: 38084      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:10:26,617][train][INFO][train.py>_log] ==> #647000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 7.940    Value Loss: 7.088    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 604251     Buffer Size: 38749      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:13:45,093][train][INFO][train.py>_log] ==> #648000     Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 8.324    Value Loss: 7.204    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 605846     Buffer Size: 39492      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:17:02,853][train][INFO][train.py>_log] ==> #649000     Total Loss: 3.494    [weighted Loss:3.494    Policy Loss: 10.218   Value Loss: 7.199    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 606662     Buffer Size: 39562      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:20:23,234][train][INFO][train.py>_log] ==> #650000     Total Loss: 0.958    [weighted Loss:0.958    Policy Loss: 7.732    Value Loss: 7.281    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 607539     Buffer Size: 39623      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:23:44,675][train][INFO][train.py>_log] ==> #651000     Total Loss: 3.621    [weighted Loss:3.621    Policy Loss: 8.138    Value Loss: 6.958    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 608519     Buffer Size: 39783      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:27:00,897][train][INFO][train.py>_log] ==> #652000     Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 7.848    Value Loss: 7.147    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 609428     Buffer Size: 39904      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:30:22,576][train][INFO][train.py>_log] ==> #653000     Total Loss: 1.101    [weighted Loss:1.101    Policy Loss: 7.489    Value Loss: 6.881    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 610371     Buffer Size: 40023      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:33:41,798][train][INFO][train.py>_log] ==> #654000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 7.240    Value Loss: 7.224    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 611315     Buffer Size: 39946      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:37:02,736][train][INFO][train.py>_log] ==> #655000     Total Loss: 3.228    [weighted Loss:3.228    Policy Loss: 8.903    Value Loss: 7.165    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 612444     Buffer Size: 40004      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:40:22,243][train][INFO][train.py>_log] ==> #656000     Total Loss: 3.114    [weighted Loss:3.114    Policy Loss: 7.339    Value Loss: 7.179    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 613531     Buffer Size: 40077      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:43:43,722][train][INFO][train.py>_log] ==> #657000     Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 8.757    Value Loss: 7.538    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 614981     Buffer Size: 40511      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:47:08,467][train][INFO][train.py>_log] ==> #658000     Total Loss: 4.298    [weighted Loss:4.298    Policy Loss: 9.595    Value Loss: 7.710    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 616416     Buffer Size: 40596      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:50:27,064][train][INFO][train.py>_log] ==> #659000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 8.464    Value Loss: 7.767    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 617864     Buffer Size: 40646      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:53:49,496][train][INFO][train.py>_log] ==> #660000     Total Loss: 1.774    [weighted Loss:1.774    Policy Loss: 8.172    Value Loss: 7.312    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 619316     Buffer Size: 41107      Transition Number: 1500.082k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:57:09,808][train][INFO][train.py>_log] ==> #661000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 8.932    Value Loss: 7.242    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 620386     Buffer Size: 41270      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:00:30,631][train][INFO][train.py>_log] ==> #662000     Total Loss: 1.333    [weighted Loss:1.333    Policy Loss: 8.146    Value Loss: 7.587    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 621483     Buffer Size: 41454      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:03:48,570][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 8.525    Value Loss: 7.093    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 622541     Buffer Size: 41558      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:07:07,086][train][INFO][train.py>_log] ==> #664000     Total Loss: 3.721    [weighted Loss:3.721    Policy Loss: 8.611    Value Loss: 7.541    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 623598     Buffer Size: 41660      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:10:27,348][train][INFO][train.py>_log] ==> #665000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 9.228    Value Loss: 7.114    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 624551     Buffer Size: 41703      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:13:46,218][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 8.218    Value Loss: 7.405    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 625504     Buffer Size: 41090      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:17:05,409][train][INFO][train.py>_log] ==> #667000     Total Loss: 3.856    [weighted Loss:3.856    Policy Loss: 9.114    Value Loss: 7.297    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 626708     Buffer Size: 40652      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:20:28,818][train][INFO][train.py>_log] ==> #668000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 10.044   Value Loss: 7.494    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 627930     Buffer Size: 40917      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:23:48,545][train][INFO][train.py>_log] ==> #669000     Total Loss: 4.232    [weighted Loss:4.232    Policy Loss: 9.849    Value Loss: 7.409    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 629064     Buffer Size: 41161      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:27:05,882][train][INFO][train.py>_log] ==> #670000     Total Loss: 4.077    [weighted Loss:4.077    Policy Loss: 9.041    Value Loss: 7.510    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 630165     Buffer Size: 41305      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:30:25,647][train][INFO][train.py>_log] ==> #671000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 9.240    Value Loss: 7.642    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 631167     Buffer Size: 41338      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:33:43,719][train][INFO][train.py>_log] ==> #672000     Total Loss: 4.310    [weighted Loss:4.310    Policy Loss: 8.934    Value Loss: 7.328    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 632176     Buffer Size: 41205      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:37:01,485][train][INFO][train.py>_log] ==> #673000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 7.852    Value Loss: 7.377    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 633583     Buffer Size: 41475      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:40:22,197][train][INFO][train.py>_log] ==> #674000     Total Loss: 4.338    [weighted Loss:4.338    Policy Loss: 8.682    Value Loss: 7.534    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 635018     Buffer Size: 41768      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:43:41,193][train][INFO][train.py>_log] ==> #675000     Total Loss: 3.264    [weighted Loss:3.264    Policy Loss: 9.234    Value Loss: 7.755    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 636270     Buffer Size: 41877      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:46:59,701][train][INFO][train.py>_log] ==> #676000     Total Loss: 2.165    [weighted Loss:2.165    Policy Loss: 8.133    Value Loss: 7.490    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 637513     Buffer Size: 41801      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:50:18,495][train][INFO][train.py>_log] ==> #677000     Total Loss: 4.093    [weighted Loss:4.093    Policy Loss: 8.127    Value Loss: 7.128    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 638779     Buffer Size: 41722      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:53:37,244][train][INFO][train.py>_log] ==> #678000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 8.194    Value Loss: 7.585    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 640042     Buffer Size: 41570      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:56:56,251][train][INFO][train.py>_log] ==> #679000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 8.054    Value Loss: 7.275    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 641326     Buffer Size: 41420      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:00:16,438][train][INFO][train.py>_log] ==> #680000     Total Loss: 4.040    [weighted Loss:4.040    Policy Loss: 9.350    Value Loss: 8.014    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 642609     Buffer Size: 41425      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:03:31,916][train][INFO][train.py>_log] ==> #681000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 8.784    Value Loss: 7.470    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 643793     Buffer Size: 41388      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:06:50,612][train][INFO][train.py>_log] ==> #682000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 8.932    Value Loss: 7.222    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 645090     Buffer Size: 41124      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:10:12,549][train][INFO][train.py>_log] ==> #683000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 8.463    Value Loss: 7.054    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 646275     Buffer Size: 40667      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:13:30,921][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.844    [weighted Loss:2.844    Policy Loss: 7.798    Value Loss: 7.407    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 647381     Buffer Size: 40770      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:16:48,157][train][INFO][train.py>_log] ==> #685000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 8.864    Value Loss: 7.612    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 648441     Buffer Size: 40994      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:20:07,606][train][INFO][train.py>_log] ==> #686000     Total Loss: 3.622    [weighted Loss:3.622    Policy Loss: 6.617    Value Loss: 7.079    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 649536     Buffer Size: 41111      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:23:26,485][train][INFO][train.py>_log] ==> #687000     Total Loss: 4.194    [weighted Loss:4.194    Policy Loss: 9.310    Value Loss: 7.963    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 650580     Buffer Size: 41216      Transition Number: 1500.093k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:26:46,569][train][INFO][train.py>_log] ==> #688000     Total Loss: 1.366    [weighted Loss:1.366    Policy Loss: 7.560    Value Loss: 7.408    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 651630     Buffer Size: 41313      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:30:08,639][train][INFO][train.py>_log] ==> #689000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 8.747    Value Loss: 7.513    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 652624     Buffer Size: 41355      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:33:30,211][train][INFO][train.py>_log] ==> #690000     Total Loss: 4.311    [weighted Loss:4.311    Policy Loss: 7.920    Value Loss: 7.362    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 653643     Buffer Size: 41276      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:36:48,936][train][INFO][train.py>_log] ==> #691000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 7.573    Value Loss: 7.186    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 654909     Buffer Size: 41432      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:40:08,098][train][INFO][train.py>_log] ==> #692000     Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 9.251    Value Loss: 7.620    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 656155     Buffer Size: 41255      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:43:28,743][train][INFO][train.py>_log] ==> #693000     Total Loss: 4.763    [weighted Loss:4.763    Policy Loss: 8.272    Value Loss: 7.235    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 657198     Buffer Size: 40972      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:46:49,369][train][INFO][train.py>_log] ==> #694000     Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 8.715    Value Loss: 7.738    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 658252     Buffer Size: 40654      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:50:12,800][train][INFO][train.py>_log] ==> #695000     Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 8.508    Value Loss: 7.408    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 659699     Buffer Size: 40579      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:53:34,962][train][INFO][train.py>_log] ==> #696000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 9.678    Value Loss: 7.561    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 661079     Buffer Size: 40757      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:56:56,783][train][INFO][train.py>_log] ==> #697000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 8.495    Value Loss: 7.664    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 662178     Buffer Size: 40805      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:00:16,286][train][INFO][train.py>_log] ==> #698000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 8.245    Value Loss: 7.283    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 663294     Buffer Size: 40874      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:03:34,922][train][INFO][train.py>_log] ==> #699000     Total Loss: 4.301    [weighted Loss:4.301    Policy Loss: 8.352    Value Loss: 7.267    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 664507     Buffer Size: 41023      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:06:52,197][train][INFO][train.py>_log] ==> #700000     Total Loss: 4.247    [weighted Loss:4.247    Policy Loss: 9.749    Value Loss: 7.550    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 665693     Buffer Size: 41244      Transition Number: 1500.140k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:10:11,755][train][INFO][train.py>_log] ==> #701000     Total Loss: 3.194    [weighted Loss:3.194    Policy Loss: 8.482    Value Loss: 7.504    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 667188     Buffer Size: 41730      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:13:28,067][train][INFO][train.py>_log] ==> #702000     Total Loss: 3.632    [weighted Loss:3.632    Policy Loss: 9.851    Value Loss: 7.248    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 668644     Buffer Size: 42025      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:16:45,966][train][INFO][train.py>_log] ==> #703000     Total Loss: 5.367    [weighted Loss:5.367    Policy Loss: 10.225   Value Loss: 7.543    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 669981     Buffer Size: 42229      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:20:06,484][train][INFO][train.py>_log] ==> #704000     Total Loss: 4.546    [weighted Loss:4.546    Policy Loss: 9.256    Value Loss: 7.541    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 671325     Buffer Size: 42405      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:23:27,274][train][INFO][train.py>_log] ==> #705000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 8.875    Value Loss: 7.322    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 672513     Buffer Size: 42464      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:26:47,423][train][INFO][train.py>_log] ==> #706000     Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 8.663    Value Loss: 7.173    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 673665     Buffer Size: 42551      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:30:08,578][train][INFO][train.py>_log] ==> #707000     Total Loss: 4.825    [weighted Loss:4.825    Policy Loss: 8.705    Value Loss: 7.479    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 675562     Buffer Size: 43354      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:33:25,606][train][INFO][train.py>_log] ==> #708000     Total Loss: 4.651    [weighted Loss:4.651    Policy Loss: 8.864    Value Loss: 7.557    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 677529     Buffer Size: 43860      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:36:39,385][train][INFO][train.py>_log] ==> #709000     Total Loss: 3.481    [weighted Loss:3.481    Policy Loss: 8.953    Value Loss: 7.459    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 678774     Buffer Size: 43764      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:39:56,544][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 8.940    Value Loss: 7.617    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 680080     Buffer Size: 43798      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:43:15,002][train][INFO][train.py>_log] ==> #711000     Total Loss: 5.453    [weighted Loss:5.453    Policy Loss: 9.165    Value Loss: 7.905    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 681657     Buffer Size: 44095      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:46:30,621][train][INFO][train.py>_log] ==> #712000     Total Loss: 4.058    [weighted Loss:4.058    Policy Loss: 8.801    Value Loss: 7.254    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 683203     Buffer Size: 44437      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:49:49,064][train][INFO][train.py>_log] ==> #713000     Total Loss: 2.747    [weighted Loss:2.747    Policy Loss: 7.883    Value Loss: 7.385    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 684529     Buffer Size: 44528      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:53:08,597][train][INFO][train.py>_log] ==> #714000     Total Loss: 4.807    [weighted Loss:4.807    Policy Loss: 8.424    Value Loss: 7.326    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 685878     Buffer Size: 44581      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:56:24,702][train][INFO][train.py>_log] ==> #715000     Total Loss: 4.434    [weighted Loss:4.434    Policy Loss: 8.310    Value Loss: 7.306    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 687160     Buffer Size: 44570      Transition Number: 1500.084k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:59:45,880][train][INFO][train.py>_log] ==> #716000     Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 8.045    Value Loss: 7.357    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 688423     Buffer Size: 44656      Transition Number: 1500.136k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:03:03,381][train][INFO][train.py>_log] ==> #717000     Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 8.360    Value Loss: 7.554    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 689541     Buffer Size: 44539      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:06:22,789][train][INFO][train.py>_log] ==> #718000     Total Loss: 3.504    [weighted Loss:3.504    Policy Loss: 8.696    Value Loss: 7.430    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 690731     Buffer Size: 44502      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:09:40,742][train][INFO][train.py>_log] ==> #719000     Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 8.257    Value Loss: 7.221    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 691691     Buffer Size: 44370      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:13:00,557][train][INFO][train.py>_log] ==> #720000     Total Loss: 4.364    [weighted Loss:4.364    Policy Loss: 7.586    Value Loss: 7.303    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 692684     Buffer Size: 44263      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:16:18,035][train][INFO][train.py>_log] ==> #721000     Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 9.794    Value Loss: 7.271    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 693711     Buffer Size: 44246      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:19:38,014][train][INFO][train.py>_log] ==> #722000     Total Loss: 3.635    [weighted Loss:3.635    Policy Loss: 8.804    Value Loss: 7.384    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 694783     Buffer Size: 44248      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:22:55,546][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.812    [weighted Loss:2.812    Policy Loss: 10.275   Value Loss: 7.793    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 695952     Buffer Size: 44344      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:26:13,375][train][INFO][train.py>_log] ==> #724000     Total Loss: 1.146    [weighted Loss:1.146    Policy Loss: 9.088    Value Loss: 7.748    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 697171     Buffer Size: 44527      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:29:33,128][train][INFO][train.py>_log] ==> #725000     Total Loss: 3.599    [weighted Loss:3.599    Policy Loss: 9.587    Value Loss: 7.213    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 698060     Buffer Size: 44496      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:32:51,383][train][INFO][train.py>_log] ==> #726000     Total Loss: 3.508    [weighted Loss:3.508    Policy Loss: 9.886    Value Loss: 7.632    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 698997     Buffer Size: 44188      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:36:13,256][train][INFO][train.py>_log] ==> #727000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 9.411    Value Loss: 7.340    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 700448     Buffer Size: 44300      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:39:35,464][train][INFO][train.py>_log] ==> #728000     Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 8.242    Value Loss: 7.453    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 701828     Buffer Size: 44591      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:42:53,023][train][INFO][train.py>_log] ==> #729000     Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 8.594    Value Loss: 7.312    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 703226     Buffer Size: 44916      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:46:11,788][train][INFO][train.py>_log] ==> #730000     Total Loss: 3.259    [weighted Loss:3.259    Policy Loss: 10.187   Value Loss: 8.057    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 704694     Buffer Size: 45034      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:49:29,232][train][INFO][train.py>_log] ==> #731000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 8.807    Value Loss: 7.102    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 706124     Buffer Size: 45112      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:52:46,512][train][INFO][train.py>_log] ==> #732000     Total Loss: 3.747    [weighted Loss:3.747    Policy Loss: 9.150    Value Loss: 7.833    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 707570     Buffer Size: 45411      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:56:04,658][train][INFO][train.py>_log] ==> #733000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 8.917    Value Loss: 7.622    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 708785     Buffer Size: 45542      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:59:21,549][train][INFO][train.py>_log] ==> #734000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 9.094    Value Loss: 7.659    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 709984     Buffer Size: 45549      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:02:36,586][train][INFO][train.py>_log] ==> #735000     Total Loss: 3.234    [weighted Loss:3.234    Policy Loss: 8.171    Value Loss: 7.189    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 711166     Buffer Size: 45546      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:05:52,546][train][INFO][train.py>_log] ==> #736000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 9.689    Value Loss: 7.815    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 712349     Buffer Size: 45316      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:09:13,575][train][INFO][train.py>_log] ==> #737000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 9.539    Value Loss: 7.669    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 714165     Buffer Size: 45568      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:12:32,376][train][INFO][train.py>_log] ==> #738000     Total Loss: 3.792    [weighted Loss:3.792    Policy Loss: 9.163    Value Loss: 7.216    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 715987     Buffer Size: 45987      Transition Number: 1500.143k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:15:51,414][train][INFO][train.py>_log] ==> #739000     Total Loss: 4.394    [weighted Loss:4.394    Policy Loss: 9.053    Value Loss: 7.875    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 717959     Buffer Size: 46563      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:19:09,686][train][INFO][train.py>_log] ==> #740000     Total Loss: 5.534    [weighted Loss:5.534    Policy Loss: 9.874    Value Loss: 7.698    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 719935     Buffer Size: 47296      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:22:28,422][train][INFO][train.py>_log] ==> #741000     Total Loss: 3.448    [weighted Loss:3.448    Policy Loss: 9.958    Value Loss: 7.479    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 721549     Buffer Size: 47766      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:25:45,842][train][INFO][train.py>_log] ==> #742000     Total Loss: 3.454    [weighted Loss:3.454    Policy Loss: 9.480    Value Loss: 7.513    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 723158     Buffer Size: 47588      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:29:03,218][train][INFO][train.py>_log] ==> #743000     Total Loss: 3.990    [weighted Loss:3.990    Policy Loss: 10.016   Value Loss: 7.360    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 724537     Buffer Size: 47106      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:32:20,969][train][INFO][train.py>_log] ==> #744000     Total Loss: 3.927    [weighted Loss:3.927    Policy Loss: 9.836    Value Loss: 7.911    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 725946     Buffer Size: 47106      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:35:37,868][train][INFO][train.py>_log] ==> #745000     Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 9.067    Value Loss: 7.720    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 727082     Buffer Size: 46950      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:38:59,840][train][INFO][train.py>_log] ==> #746000     Total Loss: 3.982    [weighted Loss:3.982    Policy Loss: 10.927   Value Loss: 7.551    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 728229     Buffer Size: 46511      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:42:16,716][train][INFO][train.py>_log] ==> #747000     Total Loss: 2.639    [weighted Loss:2.639    Policy Loss: 9.584    Value Loss: 7.657    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 729448     Buffer Size: 46134      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:45:35,695][train][INFO][train.py>_log] ==> #748000     Total Loss: 3.994    [weighted Loss:3.994    Policy Loss: 9.351    Value Loss: 7.594    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 730701     Buffer Size: 46049      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:48:54,592][train][INFO][train.py>_log] ==> #749000     Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 9.491    Value Loss: 7.421    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 731864     Buffer Size: 45892      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:52:11,783][train][INFO][train.py>_log] ==> #750000     Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 9.251    Value Loss: 7.531    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 733017     Buffer Size: 45831      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:55:29,650][train][INFO][train.py>_log] ==> #751000     Total Loss: 2.881    [weighted Loss:2.881    Policy Loss: 9.036    Value Loss: 7.637    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 734118     Buffer Size: 45616      Transition Number: 1500.094k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:58:48,575][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 8.748    Value Loss: 7.719    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 735245     Buffer Size: 45583      Transition Number: 1500.076k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:02:07,774][train][INFO][train.py>_log] ==> #753000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 8.237    Value Loss: 7.761    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 736181     Buffer Size: 45450      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:05:22,705][train][INFO][train.py>_log] ==> #754000     Total Loss: 3.907    [weighted Loss:3.907    Policy Loss: 10.010   Value Loss: 7.499    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 737155     Buffer Size: 45454      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:08:44,892][train][INFO][train.py>_log] ==> #755000     Total Loss: 1.948    [weighted Loss:1.948    Policy Loss: 8.987    Value Loss: 7.451    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 738685     Buffer Size: 45943      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:12:04,621][train][INFO][train.py>_log] ==> #756000     Total Loss: 4.562    [weighted Loss:4.562    Policy Loss: 9.535    Value Loss: 7.386    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 740173     Buffer Size: 46299      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:15:21,737][train][INFO][train.py>_log] ==> #757000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 8.886    Value Loss: 7.621    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 741463     Buffer Size: 46533      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:18:40,583][train][INFO][train.py>_log] ==> #758000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 9.958    Value Loss: 7.413    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 742850     Buffer Size: 46729      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:22:01,188][train][INFO][train.py>_log] ==> #759000     Total Loss: 4.039    [weighted Loss:4.039    Policy Loss: 7.722    Value Loss: 7.598    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 744410     Buffer Size: 47089      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:25:16,898][train][INFO][train.py>_log] ==> #760000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 9.376    Value Loss: 7.602    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 745991     Buffer Size: 47688      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:28:34,681][train][INFO][train.py>_log] ==> #761000     Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 8.078    Value Loss: 7.391    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 747152     Buffer Size: 47891      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:31:50,958][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 8.338    Value Loss: 7.377    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 748345     Buffer Size: 47770      Transition Number: 1500.086k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:35:04,614][train][INFO][train.py>_log] ==> #763000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 7.695    Value Loss: 7.445    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 749177     Buffer Size: 47317      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:38:25,356][train][INFO][train.py>_log] ==> #764000     Total Loss: 3.492    [weighted Loss:3.492    Policy Loss: 9.769    Value Loss: 7.318    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 750036     Buffer Size: 46812      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:41:44,262][train][INFO][train.py>_log] ==> #765000     Total Loss: 3.456    [weighted Loss:3.456    Policy Loss: 8.089    Value Loss: 7.363    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 751119     Buffer Size: 46444      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:45:01,986][train][INFO][train.py>_log] ==> #766000     Total Loss: 3.086    [weighted Loss:3.086    Policy Loss: 8.082    Value Loss: 7.485    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 752218     Buffer Size: 46155      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:48:19,171][train][INFO][train.py>_log] ==> #767000     Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 8.671    Value Loss: 7.363    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 753121     Buffer Size: 45668      Transition Number: 1500.079k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:51:38,949][train][INFO][train.py>_log] ==> #768000     Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 8.738    Value Loss: 7.907    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 754029     Buffer Size: 45322      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:54:57,512][train][INFO][train.py>_log] ==> #769000     Total Loss: 3.176    [weighted Loss:3.176    Policy Loss: 10.493   Value Loss: 7.775    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 755075     Buffer Size: 45136      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:58:18,593][train][INFO][train.py>_log] ==> #770000     Total Loss: 3.135    [weighted Loss:3.135    Policy Loss: 9.075    Value Loss: 7.530    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 756057     Buffer Size: 44966      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:01:40,159][train][INFO][train.py>_log] ==> #771000     Total Loss: 3.624    [weighted Loss:3.624    Policy Loss: 9.208    Value Loss: 7.338    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 757141     Buffer Size: 44826      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:05:00,981][train][INFO][train.py>_log] ==> #772000     Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 8.356    Value Loss: 7.037    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 758188     Buffer Size: 44185      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:08:22,177][train][INFO][train.py>_log] ==> #773000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 8.090    Value Loss: 7.172    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 759237     Buffer Size: 43528      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:11:41,363][train][INFO][train.py>_log] ==> #774000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 9.100    Value Loss: 7.387    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 760290     Buffer Size: 42790      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:15:01,120][train][INFO][train.py>_log] ==> #775000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 8.569    Value Loss: 7.290    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 761477     Buffer Size: 42030      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:18:23,154][train][INFO][train.py>_log] ==> #776000     Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 9.078    Value Loss: 7.807    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 762610     Buffer Size: 41439      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:21:40,122][train][INFO][train.py>_log] ==> #777000     Total Loss: 1.309    [weighted Loss:1.309    Policy Loss: 9.745    Value Loss: 7.664    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 763574     Buffer Size: 40834      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:24:58,378][train][INFO][train.py>_log] ==> #778000     Total Loss: 4.590    [weighted Loss:4.590    Policy Loss: 10.111   Value Loss: 7.666    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 764507     Buffer Size: 40395      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:28:20,766][train][INFO][train.py>_log] ==> #779000     Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 9.683    Value Loss: 7.370    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 765925     Buffer Size: 40366      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:31:43,222][train][INFO][train.py>_log] ==> #780000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 9.532    Value Loss: 7.473    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 767399     Buffer Size: 40565      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:35:05,228][train][INFO][train.py>_log] ==> #781000     Total Loss: 4.256    [weighted Loss:4.256    Policy Loss: 9.214    Value Loss: 7.352    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 768714     Buffer Size: 40724      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:38:28,524][train][INFO][train.py>_log] ==> #782000     Total Loss: 1.253    [weighted Loss:1.253    Policy Loss: 10.102   Value Loss: 7.384    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 770038     Buffer Size: 40805      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:41:48,342][train][INFO][train.py>_log] ==> #783000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 9.574    Value Loss: 7.604    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 771557     Buffer Size: 41062      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:45:09,060][train][INFO][train.py>_log] ==> #784000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 9.918    Value Loss: 7.513    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 773056     Buffer Size: 41346      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:48:30,297][train][INFO][train.py>_log] ==> #785000     Total Loss: 4.137    [weighted Loss:4.137    Policy Loss: 10.029   Value Loss: 8.078    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 774392     Buffer Size: 41459      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:51:51,595][train][INFO][train.py>_log] ==> #786000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 8.521    Value Loss: 7.286    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 775756     Buffer Size: 41711      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:55:11,750][train][INFO][train.py>_log] ==> #787000     Total Loss: 3.878    [weighted Loss:3.878    Policy Loss: 9.036    Value Loss: 7.478    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 776795     Buffer Size: 41680      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:58:32,959][train][INFO][train.py>_log] ==> #788000     Total Loss: 3.403    [weighted Loss:3.403    Policy Loss: 8.267    Value Loss: 7.831    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 777821     Buffer Size: 41750      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:01:52,456][train][INFO][train.py>_log] ==> #789000     Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 9.479    Value Loss: 7.252    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 778859     Buffer Size: 41802      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:05:11,003][train][INFO][train.py>_log] ==> #790000     Total Loss: 4.513    [weighted Loss:4.513    Policy Loss: 10.143   Value Loss: 7.526    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 779997     Buffer Size: 41490      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:08:34,609][train][INFO][train.py>_log] ==> #791000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 8.735    Value Loss: 7.485    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 781234     Buffer Size: 41152      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:11:54,743][train][INFO][train.py>_log] ==> #792000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 9.264    Value Loss: 7.312    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 782441     Buffer Size: 41078      Transition Number: 1500.201k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:15:14,343][train][INFO][train.py>_log] ==> #793000     Total Loss: 3.320    [weighted Loss:3.320    Policy Loss: 9.178    Value Loss: 7.889    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 783445     Buffer Size: 40829      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:18:37,218][train][INFO][train.py>_log] ==> #794000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 9.253    Value Loss: 7.621    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 784547     Buffer Size: 40352      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:21:57,093][train][INFO][train.py>_log] ==> #795000     Total Loss: 3.700    [weighted Loss:3.700    Policy Loss: 8.901    Value Loss: 7.472    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 785553     Buffer Size: 39804      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:25:20,387][train][INFO][train.py>_log] ==> #796000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 8.401    Value Loss: 7.502    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 786586     Buffer Size: 39568      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:28:41,544][train][INFO][train.py>_log] ==> #797000     Total Loss: 4.261    [weighted Loss:4.261    Policy Loss: 8.723    Value Loss: 7.440    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 787607     Buffer Size: 39395      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:32:00,053][train][INFO][train.py>_log] ==> #798000     Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 8.980    Value Loss: 7.144    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 788654     Buffer Size: 39541      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:35:24,133][train][INFO][train.py>_log] ==> #799000     Total Loss: 4.826    [weighted Loss:4.826    Policy Loss: 8.452    Value Loss: 7.540    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 789672     Buffer Size: 39657      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:38:46,438][train][INFO][train.py>_log] ==> #800000     Total Loss: 3.063    [weighted Loss:3.063    Policy Loss: 8.985    Value Loss: 7.396    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 790702     Buffer Size: 39587      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:42:06,358][train][INFO][train.py>_log] ==> #801000     Total Loss: 5.444    [weighted Loss:5.444    Policy Loss: 9.652    Value Loss: 7.417    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 791697     Buffer Size: 39503      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:45:28,287][train][INFO][train.py>_log] ==> #802000     Total Loss: 4.147    [weighted Loss:4.147    Policy Loss: 8.925    Value Loss: 7.559    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 792661     Buffer Size: 39551      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:48:50,042][train][INFO][train.py>_log] ==> #803000     Total Loss: 4.993    [weighted Loss:4.993    Policy Loss: 9.645    Value Loss: 7.148    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 793835     Buffer Size: 39758      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:52:11,651][train][INFO][train.py>_log] ==> #804000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 9.645    Value Loss: 7.253    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 794977     Buffer Size: 39838      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:55:32,353][train][INFO][train.py>_log] ==> #805000     Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 10.508   Value Loss: 7.588    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 796295     Buffer Size: 40114      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:58:55,916][train][INFO][train.py>_log] ==> #806000     Total Loss: 4.459    [weighted Loss:4.459    Policy Loss: 9.336    Value Loss: 7.494    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 797650     Buffer Size: 40364      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:02:14,646][train][INFO][train.py>_log] ==> #807000     Total Loss: 4.649    [weighted Loss:4.649    Policy Loss: 8.918    Value Loss: 7.408    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 798993     Buffer Size: 40640      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:05:34,225][train][INFO][train.py>_log] ==> #808000     Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 10.406   Value Loss: 7.583    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 800371     Buffer Size: 40911      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:08:56,663][train][INFO][train.py>_log] ==> #809000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 10.128   Value Loss: 7.043    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 801946     Buffer Size: 41352      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:12:18,047][train][INFO][train.py>_log] ==> #810000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 9.201    Value Loss: 7.658    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 803499     Buffer Size: 41720      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:15:35,730][train][INFO][train.py>_log] ==> #811000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 8.522    Value Loss: 7.180    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 804897     Buffer Size: 42012      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:18:56,709][train][INFO][train.py>_log] ==> #812000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 9.469    Value Loss: 7.346    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 806286     Buffer Size: 42421      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:22:16,780][train][INFO][train.py>_log] ==> #813000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 10.321   Value Loss: 7.180    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 807331     Buffer Size: 42443      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:25:36,463][train][INFO][train.py>_log] ==> #814000     Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 8.919    Value Loss: 7.525    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 808394     Buffer Size: 42095      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:28:59,758][train][INFO][train.py>_log] ==> #815000     Total Loss: 4.610    [weighted Loss:4.610    Policy Loss: 11.474   Value Loss: 7.909    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 809839     Buffer Size: 42047      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:32:18,911][train][INFO][train.py>_log] ==> #816000     Total Loss: 3.496    [weighted Loss:3.496    Policy Loss: 9.792    Value Loss: 7.412    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 811297     Buffer Size: 42167      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:35:37,674][train][INFO][train.py>_log] ==> #817000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 9.648    Value Loss: 7.485    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 812805     Buffer Size: 42362      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:39:00,370][train][INFO][train.py>_log] ==> #818000     Total Loss: 3.458    [weighted Loss:3.458    Policy Loss: 9.332    Value Loss: 7.449    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 814379     Buffer Size: 42387      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:42:19,659][train][INFO][train.py>_log] ==> #819000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 8.452    Value Loss: 7.609    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 815556     Buffer Size: 42131      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:45:41,053][train][INFO][train.py>_log] ==> #820000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 10.315   Value Loss: 7.412    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 816743     Buffer Size: 41973      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:49:03,965][train][INFO][train.py>_log] ==> #821000     Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 9.032    Value Loss: 7.766    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 818323     Buffer Size: 42233      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:52:25,408][train][INFO][train.py>_log] ==> #822000     Total Loss: 3.957    [weighted Loss:3.957    Policy Loss: 9.223    Value Loss: 7.312    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 819978     Buffer Size: 42738      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:55:46,717][train][INFO][train.py>_log] ==> #823000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 7.398    Value Loss: 7.140    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 820973     Buffer Size: 42712      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:59:05,319][train][INFO][train.py>_log] ==> #824000     Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 9.108    Value Loss: 7.733    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 821980     Buffer Size: 42668      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:02:25,143][train][INFO][train.py>_log] ==> #825000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 8.142    Value Loss: 7.290    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 822953     Buffer Size: 42555      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:05:45,257][train][INFO][train.py>_log] ==> #826000     Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 8.905    Value Loss: 7.271    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 823996     Buffer Size: 42414      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:09:06,169][train][INFO][train.py>_log] ==> #827000     Total Loss: 3.368    [weighted Loss:3.368    Policy Loss: 8.990    Value Loss: 7.493    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 825096     Buffer Size: 42310      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:12:26,851][train][INFO][train.py>_log] ==> #828000     Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 9.303    Value Loss: 7.538    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 826149     Buffer Size: 42314      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:15:47,754][train][INFO][train.py>_log] ==> #829000     Total Loss: 1.527    [weighted Loss:1.527    Policy Loss: 9.632    Value Loss: 7.000    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 827640     Buffer Size: 42701      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:19:08,622][train][INFO][train.py>_log] ==> #830000     Total Loss: 4.352    [weighted Loss:4.352    Policy Loss: 9.120    Value Loss: 7.412    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 829130     Buffer Size: 43137      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:22:25,750][train][INFO][train.py>_log] ==> #831000     Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 8.618    Value Loss: 7.498    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 830371     Buffer Size: 43363      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:25:42,366][train][INFO][train.py>_log] ==> #832000     Total Loss: 2.769    [weighted Loss:2.769    Policy Loss: 9.620    Value Loss: 7.586    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 831586     Buffer Size: 43518      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:29:02,734][train][INFO][train.py>_log] ==> #833000     Total Loss: 2.967    [weighted Loss:2.967    Policy Loss: 7.303    Value Loss: 7.200    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 833284     Buffer Size: 44110      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:32:22,632][train][INFO][train.py>_log] ==> #834000     Total Loss: 5.090    [weighted Loss:5.090    Policy Loss: 9.739    Value Loss: 7.275    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 835029     Buffer Size: 44826      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:35:40,060][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 7.831    Value Loss: 7.795    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 836492     Buffer Size: 45274      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:38:56,940][train][INFO][train.py>_log] ==> #836000     Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 8.384    Value Loss: 7.448    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 837933     Buffer Size: 45698      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:42:14,423][train][INFO][train.py>_log] ==> #837000     Total Loss: 3.650    [weighted Loss:3.650    Policy Loss: 8.294    Value Loss: 7.420    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 839259     Buffer Size: 46006      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:45:29,290][train][INFO][train.py>_log] ==> #838000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 8.897    Value Loss: 7.074    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 840577     Buffer Size: 46275      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:48:48,676][train][INFO][train.py>_log] ==> #839000     Total Loss: 3.815    [weighted Loss:3.815    Policy Loss: 9.098    Value Loss: 7.339    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 841703     Buffer Size: 46217      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:52:08,307][train][INFO][train.py>_log] ==> #840000     Total Loss: 3.733    [weighted Loss:3.733    Policy Loss: 9.374    Value Loss: 7.314    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 842819     Buffer Size: 46026      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:55:26,747][train][INFO][train.py>_log] ==> #841000     Total Loss: 3.025    [weighted Loss:3.025    Policy Loss: 8.656    Value Loss: 7.561    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 844044     Buffer Size: 45949      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:58:47,243][train][INFO][train.py>_log] ==> #842000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 9.775    Value Loss: 7.455    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 845300     Buffer Size: 45852      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:02:04,098][train][INFO][train.py>_log] ==> #843000     Total Loss: 3.979    [weighted Loss:3.979    Policy Loss: 9.106    Value Loss: 7.569    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 846334     Buffer Size: 45537      Transition Number: 1500.182k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:05:23,890][train][INFO][train.py>_log] ==> #844000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 8.885    Value Loss: 7.784    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 847348     Buffer Size: 45093      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:08:44,703][train][INFO][train.py>_log] ==> #845000     Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 9.353    Value Loss: 7.283    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 848402     Buffer Size: 44620      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:12:06,013][train][INFO][train.py>_log] ==> #846000     Total Loss: 4.281    [weighted Loss:4.281    Policy Loss: 8.937    Value Loss: 7.245    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 849483     Buffer Size: 44267      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:15:27,099][train][INFO][train.py>_log] ==> #847000     Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 10.899   Value Loss: 7.580    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 850492     Buffer Size: 43959      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:18:46,765][train][INFO][train.py>_log] ==> #848000     Total Loss: 3.023    [weighted Loss:3.023    Policy Loss: 8.604    Value Loss: 7.247    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 851487     Buffer Size: 43936      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:22:05,586][train][INFO][train.py>_log] ==> #849000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 10.169   Value Loss: 7.680    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 853203     Buffer Size: 44500      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:25:24,337][train][INFO][train.py>_log] ==> #850000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 10.508   Value Loss: 7.427    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 854980     Buffer Size: 44821      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:28:42,688][train][INFO][train.py>_log] ==> #851000     Total Loss: 3.781    [weighted Loss:3.781    Policy Loss: 10.199   Value Loss: 7.792    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 856560     Buffer Size: 44938      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:32:03,294][train][INFO][train.py>_log] ==> #852000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 9.910    Value Loss: 7.322    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 858124     Buffer Size: 44956      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:35:23,103][train][INFO][train.py>_log] ==> #853000     Total Loss: 3.548    [weighted Loss:3.548    Policy Loss: 10.536   Value Loss: 7.363    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 859683     Buffer Size: 45046      Transition Number: 1500.098k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:38:44,873][train][INFO][train.py>_log] ==> #854000     Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 9.614    Value Loss: 7.529    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 861258     Buffer Size: 45375      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:42:04,176][train][INFO][train.py>_log] ==> #855000     Total Loss: 4.216    [weighted Loss:4.216    Policy Loss: 11.903   Value Loss: 7.336    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 862822     Buffer Size: 45677      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:45:21,126][train][INFO][train.py>_log] ==> #856000     Total Loss: 3.145    [weighted Loss:3.145    Policy Loss: 10.488   Value Loss: 7.572    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 864434     Buffer Size: 45704      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:48:42,584][train][INFO][train.py>_log] ==> #857000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 10.942   Value Loss: 7.700    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 865956     Buffer Size: 45712      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:52:02,080][train][INFO][train.py>_log] ==> #858000     Total Loss: 3.656    [weighted Loss:3.656    Policy Loss: 9.536    Value Loss: 7.287    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 867494     Buffer Size: 46231      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:55:20,476][train][INFO][train.py>_log] ==> #859000     Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 9.240    Value Loss: 7.525    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 868895     Buffer Size: 46611      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:58:38,369][train][INFO][train.py>_log] ==> #860000     Total Loss: 3.581    [weighted Loss:3.581    Policy Loss: 9.640    Value Loss: 7.182    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 870266     Buffer Size: 46951      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:01:53,654][train][INFO][train.py>_log] ==> #861000     Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 9.233    Value Loss: 7.574    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 871489     Buffer Size: 47174      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:05:09,682][train][INFO][train.py>_log] ==> #862000     Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 9.968    Value Loss: 7.863    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 872739     Buffer Size: 47341      Transition Number: 1500.127k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:08:26,474][train][INFO][train.py>_log] ==> #863000     Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 8.955    Value Loss: 7.639    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 874274     Buffer Size: 47702      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:11:46,805][train][INFO][train.py>_log] ==> #864000     Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 9.736    Value Loss: 7.352    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 875826     Buffer Size: 47734      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:15:05,759][train][INFO][train.py>_log] ==> #865000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 10.320   Value Loss: 7.719    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 877195     Buffer Size: 47706      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:18:23,641][train][INFO][train.py>_log] ==> #866000     Total Loss: 4.411    [weighted Loss:4.411    Policy Loss: 9.485    Value Loss: 7.366    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 878582     Buffer Size: 47804      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:21:42,818][train][INFO][train.py>_log] ==> #867000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 9.673    Value Loss: 7.533    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 879925     Buffer Size: 47895      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:25:00,816][train][INFO][train.py>_log] ==> #868000     Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 9.251    Value Loss: 7.259    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 881193     Buffer Size: 47492      Transition Number: 1500.147k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:28:20,191][train][INFO][train.py>_log] ==> #869000     Total Loss: 3.783    [weighted Loss:3.783    Policy Loss: 10.164   Value Loss: 7.345    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 882464     Buffer Size: 47079      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:31:37,534][train][INFO][train.py>_log] ==> #870000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 9.804    Value Loss: 7.408    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 883651     Buffer Size: 46859      Transition Number: 1500.142k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:34:56,887][train][INFO][train.py>_log] ==> #871000     Total Loss: 1.185    [weighted Loss:1.185    Policy Loss: 8.845    Value Loss: 7.552    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 885523     Buffer Size: 47250      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:38:16,640][train][INFO][train.py>_log] ==> #872000     Total Loss: 3.568    [weighted Loss:3.568    Policy Loss: 9.814    Value Loss: 7.212    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 887377     Buffer Size: 47673      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:41:35,686][train][INFO][train.py>_log] ==> #873000     Total Loss: 3.404    [weighted Loss:3.404    Policy Loss: 9.854    Value Loss: 7.038    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 888747     Buffer Size: 47726      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:44:50,404][train][INFO][train.py>_log] ==> #874000     Total Loss: 5.508    [weighted Loss:5.508    Policy Loss: 9.587    Value Loss: 7.730    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 890016     Buffer Size: 47913      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:48:10,203][train][INFO][train.py>_log] ==> #875000     Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 10.184   Value Loss: 7.484    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 891312     Buffer Size: 48045      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:51:28,582][train][INFO][train.py>_log] ==> #876000     Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 9.376    Value Loss: 7.621    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 892616     Buffer Size: 48157      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:54:47,534][train][INFO][train.py>_log] ==> #877000     Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 10.812   Value Loss: 7.683    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 894165     Buffer Size: 48454      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:58:04,010][train][INFO][train.py>_log] ==> #878000     Total Loss: 3.865    [weighted Loss:3.865    Policy Loss: 9.418    Value Loss: 7.660    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 895704     Buffer Size: 48937      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:01:18,287][train][INFO][train.py>_log] ==> #879000     Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 10.116   Value Loss: 7.158    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 896917     Buffer Size: 49139      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:04:34,006][train][INFO][train.py>_log] ==> #880000     Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 10.417   Value Loss: 7.563    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 898082     Buffer Size: 49277      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:07:51,284][train][INFO][train.py>_log] ==> #881000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 9.910    Value Loss: 7.613    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 900164     Buffer Size: 50260      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:11:05,834][train][INFO][train.py>_log] ==> #882000     Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 9.679    Value Loss: 7.224    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 902254     Buffer Size: 51299      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:14:21,831][train][INFO][train.py>_log] ==> #883000     Total Loss: 3.756    [weighted Loss:3.756    Policy Loss: 9.934    Value Loss: 7.378    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 904403     Buffer Size: 52139      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:17:40,138][train][INFO][train.py>_log] ==> #884000     Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 9.794    Value Loss: 7.505    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 906593     Buffer Size: 52612      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:20:54,890][train][INFO][train.py>_log] ==> #885000     Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 9.928    Value Loss: 7.470    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 907930     Buffer Size: 52398      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:24:10,296][train][INFO][train.py>_log] ==> #886000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 9.185    Value Loss: 7.363    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 909302     Buffer Size: 52247      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:27:27,640][train][INFO][train.py>_log] ==> #887000     Total Loss: 3.912    [weighted Loss:3.912    Policy Loss: 9.878    Value Loss: 7.441    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 911258     Buffer Size: 52582      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:30:47,603][train][INFO][train.py>_log] ==> #888000     Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 10.435   Value Loss: 7.220    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 913084     Buffer Size: 52855      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:34:02,782][train][INFO][train.py>_log] ==> #889000     Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 9.620    Value Loss: 7.076    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 915159     Buffer Size: 53390      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:37:16,806][train][INFO][train.py>_log] ==> #890000     Total Loss: 4.983    [weighted Loss:4.983    Policy Loss: 10.496   Value Loss: 7.405    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 917184     Buffer Size: 53813      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:40:34,376][train][INFO][train.py>_log] ==> #891000     Total Loss: 1.640    [weighted Loss:1.640    Policy Loss: 8.950    Value Loss: 7.124    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 918873     Buffer Size: 53937      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:43:52,730][train][INFO][train.py>_log] ==> #892000     Total Loss: 2.140    [weighted Loss:2.140    Policy Loss: 10.412   Value Loss: 7.297    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 920560     Buffer Size: 54102      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:47:08,773][train][INFO][train.py>_log] ==> #893000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 9.943    Value Loss: 7.747    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 921997     Buffer Size: 54131      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:50:25,349][train][INFO][train.py>_log] ==> #894000     Total Loss: 2.985    [weighted Loss:2.985    Policy Loss: 10.914   Value Loss: 7.588    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 923459     Buffer Size: 54224      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:53:39,101][train][INFO][train.py>_log] ==> #895000     Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 10.289   Value Loss: 7.675    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 924801     Buffer Size: 54209      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:56:58,417][train][INFO][train.py>_log] ==> #896000     Total Loss: 4.273    [weighted Loss:4.273    Policy Loss: 9.513    Value Loss: 7.533    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 926132     Buffer Size: 54274      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:00:18,919][train][INFO][train.py>_log] ==> #897000     Total Loss: 5.342    [weighted Loss:5.342    Policy Loss: 10.007   Value Loss: 6.944    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 928280     Buffer Size: 55001      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:03:33,783][train][INFO][train.py>_log] ==> #898000     Total Loss: 3.537    [weighted Loss:3.537    Policy Loss: 9.514    Value Loss: 7.438    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 930428     Buffer Size: 55609      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:06:48,765][train][INFO][train.py>_log] ==> #899000     Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 9.028    Value Loss: 7.323    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 932099     Buffer Size: 55785      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:10:04,997][train][INFO][train.py>_log] ==> #900000     Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 9.351    Value Loss: 7.491    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 933708     Buffer Size: 56082      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:13:19,678][train][INFO][train.py>_log] ==> #901000     Total Loss: 4.223    [weighted Loss:4.223    Policy Loss: 10.078   Value Loss: 7.359    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 935298     Buffer Size: 56318      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:16:35,440][train][INFO][train.py>_log] ==> #902000     Total Loss: 3.958    [weighted Loss:3.958    Policy Loss: 9.610    Value Loss: 7.518    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 936935     Buffer Size: 56620      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:19:52,085][train][INFO][train.py>_log] ==> #903000     Total Loss: 1.128    [weighted Loss:1.128    Policy Loss: 9.041    Value Loss: 7.565    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 938296     Buffer Size: 56713      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:23:06,185][train][INFO][train.py>_log] ==> #904000     Total Loss: 2.374    [weighted Loss:2.374    Policy Loss: 9.433    Value Loss: 7.390    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 939583     Buffer Size: 56758      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:26:20,962][train][INFO][train.py>_log] ==> #905000     Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 8.913    Value Loss: 7.312    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 941232     Buffer Size: 57063      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:29:40,903][train][INFO][train.py>_log] ==> #906000     Total Loss: 3.607    [weighted Loss:3.607    Policy Loss: 10.391   Value Loss: 7.379    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 942884     Buffer Size: 56869      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:32:57,460][train][INFO][train.py>_log] ==> #907000     Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 9.844    Value Loss: 7.411    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 945393     Buffer Size: 57546      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:36:11,724][train][INFO][train.py>_log] ==> #908000     Total Loss: 4.343    [weighted Loss:4.343    Policy Loss: 11.433   Value Loss: 7.905    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 947862     Buffer Size: 58624      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:39:23,550][train][INFO][train.py>_log] ==> #909000     Total Loss: 3.907    [weighted Loss:3.907    Policy Loss: 9.283    Value Loss: 7.338    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 949986     Buffer Size: 59484      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:42:36,138][train][INFO][train.py>_log] ==> #910000     Total Loss: 5.062    [weighted Loss:5.062    Policy Loss: 10.434   Value Loss: 7.600    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 952098     Buffer Size: 60297      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:45:47,457][train][INFO][train.py>_log] ==> #911000     Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 10.483   Value Loss: 7.112    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 953709     Buffer Size: 60616      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:49:02,694][train][INFO][train.py>_log] ==> #912000     Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 10.193   Value Loss: 7.481    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 955473     Buffer Size: 60792      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:52:14,142][train][INFO][train.py>_log] ==> #913000     Total Loss: 4.120    [weighted Loss:4.120    Policy Loss: 10.288   Value Loss: 7.441    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 956666     Buffer Size: 60652      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:55:29,826][train][INFO][train.py>_log] ==> #914000     Total Loss: 3.143    [weighted Loss:3.143    Policy Loss: 9.897    Value Loss: 7.168    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 957974     Buffer Size: 60742      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-12 03:58:45,832][train][INFO][train.py>_log] ==> #915000     Total Loss: 3.673    [weighted Loss:3.673    Policy Loss: 9.590    Value Loss: 7.427    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 959458     Buffer Size: 60851      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:01:55,970][train][INFO][train.py>_log] ==> #916000     Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 9.340    Value Loss: 7.313    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 960877     Buffer Size: 60300      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:05:11,230][train][INFO][train.py>_log] ==> #917000     Total Loss: 1.392    [weighted Loss:1.392    Policy Loss: 8.588    Value Loss: 7.457    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 962440     Buffer Size: 59827      Transition Number: 1500.124k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:08:26,694][train][INFO][train.py>_log] ==> #918000     Total Loss: 4.173    [weighted Loss:4.173    Policy Loss: 10.324   Value Loss: 7.682    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 964024     Buffer Size: 59240      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:11:42,083][train][INFO][train.py>_log] ==> #919000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 8.956    Value Loss: 7.397    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 965732     Buffer Size: 58884      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:14:57,080][train][INFO][train.py>_log] ==> #920000     Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 9.370    Value Loss: 7.230    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 967438     Buffer Size: 59203      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:18:11,922][train][INFO][train.py>_log] ==> #921000     Total Loss: 0.830    [weighted Loss:0.830    Policy Loss: 8.982    Value Loss: 7.611    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 968394     Buffer Size: 58943      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:21:22,871][train][INFO][train.py>_log] ==> #922000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 8.937    Value Loss: 7.208    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 969395     Buffer Size: 58163      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:24:41,153][train][INFO][train.py>_log] ==> #923000     Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 9.993    Value Loss: 7.319    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 970983     Buffer Size: 57892      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:28:05,700][train][INFO][train.py>_log] ==> #924000     Total Loss: 4.120    [weighted Loss:4.120    Policy Loss: 10.148   Value Loss: 7.377    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 972643     Buffer Size: 57502      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:31:23,446][train][INFO][train.py>_log] ==> #925000     Total Loss: 3.418    [weighted Loss:3.418    Policy Loss: 9.824    Value Loss: 7.507    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 974875     Buffer Size: 57623      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:34:42,726][train][INFO][train.py>_log] ==> #926000     Total Loss: 4.757    [weighted Loss:4.757    Policy Loss: 10.277   Value Loss: 7.810    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 977175     Buffer Size: 58171      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:38:00,672][train][INFO][train.py>_log] ==> #927000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 9.504    Value Loss: 7.458    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 979125     Buffer Size: 58427      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:41:16,308][train][INFO][train.py>_log] ==> #928000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 9.756    Value Loss: 7.216    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 981044     Buffer Size: 58870      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:44:31,622][train][INFO][train.py>_log] ==> #929000     Total Loss: 4.905    [weighted Loss:4.905    Policy Loss: 10.685   Value Loss: 7.494    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 982495     Buffer Size: 58884      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:47:47,929][train][INFO][train.py>_log] ==> #930000     Total Loss: 1.060    [weighted Loss:1.060    Policy Loss: 9.190    Value Loss: 7.272    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 984032     Buffer Size: 59077      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:51:00,718][train][INFO][train.py>_log] ==> #931000     Total Loss: 2.437    [weighted Loss:2.437    Policy Loss: 8.744    Value Loss: 7.334    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 985149     Buffer Size: 58939      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:54:15,861][train][INFO][train.py>_log] ==> #932000     Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 8.765    Value Loss: 7.777    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 986319     Buffer Size: 58195      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-12 04:57:28,735][train][INFO][train.py>_log] ==> #933000     Total Loss: 3.497    [weighted Loss:3.497    Policy Loss: 9.054    Value Loss: 7.222    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 987465     Buffer Size: 57270      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:00:46,989][train][INFO][train.py>_log] ==> #934000     Total Loss: 2.981    [weighted Loss:2.981    Policy Loss: 8.680    Value Loss: 7.664    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 988657     Buffer Size: 56709      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:04:05,833][train][INFO][train.py>_log] ==> #935000     Total Loss: 3.274    [weighted Loss:3.274    Policy Loss: 10.082   Value Loss: 7.720    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 990555     Buffer Size: 56864      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:07:20,375][train][INFO][train.py>_log] ==> #936000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 10.098   Value Loss: 7.589    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 992418     Buffer Size: 57120      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:10:37,853][train][INFO][train.py>_log] ==> #937000     Total Loss: 5.013    [weighted Loss:5.013    Policy Loss: 10.577   Value Loss: 7.556    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 994191     Buffer Size: 57265      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:13:52,611][train][INFO][train.py>_log] ==> #938000     Total Loss: 4.315    [weighted Loss:4.315    Policy Loss: 9.024    Value Loss: 7.335    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 996005     Buffer Size: 57683      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:17:06,449][train][INFO][train.py>_log] ==> #939000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 9.876    Value Loss: 7.629    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 997960     Buffer Size: 58326      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:20:23,262][train][INFO][train.py>_log] ==> #940000     Total Loss: 2.358    [weighted Loss:2.358    Policy Loss: 8.925    Value Loss: 7.481    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 999935     Buffer Size: 58621      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:23:38,612][train][INFO][train.py>_log] ==> #941000     Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 9.088    Value Loss: 7.251    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 1001741    Buffer Size: 58790      Transition Number: 1500.070k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:26:56,393][train][INFO][train.py>_log] ==> #942000     Total Loss: 3.608    [weighted Loss:3.608    Policy Loss: 11.012   Value Loss: 7.533    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 1003605    Buffer Size: 58240      Transition Number: 1500.150k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:30:13,162][train][INFO][train.py>_log] ==> #943000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 8.609    Value Loss: 7.620    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 1005077    Buffer Size: 57376      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:33:30,211][train][INFO][train.py>_log] ==> #944000     Total Loss: 4.377    [weighted Loss:4.377    Policy Loss: 9.456    Value Loss: 8.194    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1006565    Buffer Size: 56655      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:36:47,858][train][INFO][train.py>_log] ==> #945000     Total Loss: 2.903    [weighted Loss:2.903    Policy Loss: 8.711    Value Loss: 7.488    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1008091    Buffer Size: 56121      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:40:08,212][train][INFO][train.py>_log] ==> #946000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 9.235    Value Loss: 7.454    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 1009643    Buffer Size: 55888      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:43:25,982][train][INFO][train.py>_log] ==> #947000     Total Loss: 2.092    [weighted Loss:2.092    Policy Loss: 9.159    Value Loss: 7.554    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 1011148    Buffer Size: 55634      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:46:42,603][train][INFO][train.py>_log] ==> #948000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 9.459    Value Loss: 7.796    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1012552    Buffer Size: 55748      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:49:56,398][train][INFO][train.py>_log] ==> #949000     Total Loss: 3.826    [weighted Loss:3.826    Policy Loss: 9.929    Value Loss: 7.717    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 1014057    Buffer Size: 55994      Transition Number: 1499.936k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:53:14,612][train][INFO][train.py>_log] ==> #950000     Total Loss: 1.178    [weighted Loss:1.178    Policy Loss: 9.191    Value Loss: 7.966    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1015645    Buffer Size: 56054      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:56:30,872][train][INFO][train.py>_log] ==> #951000     Total Loss: 2.549    [weighted Loss:2.549    Policy Loss: 11.270   Value Loss: 7.600    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1017514    Buffer Size: 56415      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 05:59:49,333][train][INFO][train.py>_log] ==> #952000     Total Loss: 4.820    [weighted Loss:4.820    Policy Loss: 11.057   Value Loss: 7.651    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 1019353    Buffer Size: 56670      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:03:06,123][train][INFO][train.py>_log] ==> #953000     Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 10.233   Value Loss: 7.688    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1021060    Buffer Size: 56814      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:06:23,259][train][INFO][train.py>_log] ==> #954000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 9.396    Value Loss: 7.408    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 1022830    Buffer Size: 56780      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:09:44,655][train][INFO][train.py>_log] ==> #955000     Total Loss: 2.324    [weighted Loss:2.324    Policy Loss: 9.740    Value Loss: 7.616    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025841    Buffer Size: 58092      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:13:01,705][train][INFO][train.py>_log] ==> #956000     Total Loss: 2.940    [weighted Loss:2.940    Policy Loss: 10.982   Value Loss: 7.505    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 1028895    Buffer Size: 60029      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:16:14,378][train][INFO][train.py>_log] ==> #957000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 8.898    Value Loss: 7.349    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030977    Buffer Size: 60916      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:19:30,043][train][INFO][train.py>_log] ==> #958000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 10.155   Value Loss: 7.361    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1033132    Buffer Size: 61399      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:22:44,207][train][INFO][train.py>_log] ==> #959000     Total Loss: 3.130    [weighted Loss:3.130    Policy Loss: 8.670    Value Loss: 7.640    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 1034475    Buffer Size: 61079      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:25:57,556][train][INFO][train.py>_log] ==> #960000     Total Loss: 4.023    [weighted Loss:4.023    Policy Loss: 9.843    Value Loss: 7.594    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035794    Buffer Size: 60336      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:29:17,213][train][INFO][train.py>_log] ==> #961000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 10.110   Value Loss: 7.420    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 1037354    Buffer Size: 59662      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:32:38,020][train][INFO][train.py>_log] ==> #962000     Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 10.074   Value Loss: 7.499    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1038863    Buffer Size: 59246      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:35:56,674][train][INFO][train.py>_log] ==> #963000     Total Loss: 4.532    [weighted Loss:4.532    Policy Loss: 10.069   Value Loss: 7.680    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 1041027    Buffer Size: 59448      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:39:14,878][train][INFO][train.py>_log] ==> #964000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 10.452   Value Loss: 7.343    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043153    Buffer Size: 60037      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:42:31,609][train][INFO][train.py>_log] ==> #965000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 9.789    Value Loss: 7.130    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 1045111    Buffer Size: 60586      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:45:45,149][train][INFO][train.py>_log] ==> #966000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 10.867   Value Loss: 7.343    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1046987    Buffer Size: 61280      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:48:57,121][train][INFO][train.py>_log] ==> #967000     Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 9.067    Value Loss: 7.396    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048602    Buffer Size: 61761      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:52:13,552][train][INFO][train.py>_log] ==> #968000     Total Loss: 4.509    [weighted Loss:4.509    Policy Loss: 10.057   Value Loss: 7.438    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1050246    Buffer Size: 62222      Transition Number: 1500.088k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:55:24,292][train][INFO][train.py>_log] ==> #969000     Total Loss: 4.957    [weighted Loss:4.957    Policy Loss: 10.211   Value Loss: 7.225    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 1051760    Buffer Size: 62342      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-12 06:58:39,621][train][INFO][train.py>_log] ==> #970000     Total Loss: 3.576    [weighted Loss:3.576    Policy Loss: 10.519   Value Loss: 7.461    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 1053250    Buffer Size: 62008      Transition Number: 1500.052k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:01:56,780][train][INFO][train.py>_log] ==> #971000     Total Loss: 4.419    [weighted Loss:4.419    Policy Loss: 10.140   Value Loss: 7.368    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 1054599    Buffer Size: 61564      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:05:12,999][train][INFO][train.py>_log] ==> #972000     Total Loss: 4.437    [weighted Loss:4.437    Policy Loss: 9.810    Value Loss: 7.384    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 1055954    Buffer Size: 61157      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:08:30,152][train][INFO][train.py>_log] ==> #973000     Total Loss: 3.017    [weighted Loss:3.017    Policy Loss: 10.354   Value Loss: 7.503    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 1057416    Buffer Size: 60765      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:11:45,360][train][INFO][train.py>_log] ==> #974000     Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 10.366   Value Loss: 7.576    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 1058886    Buffer Size: 60337      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:15:02,131][train][INFO][train.py>_log] ==> #975000     Total Loss: 3.427    [weighted Loss:3.427    Policy Loss: 10.747   Value Loss: 7.422    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 1060423    Buffer Size: 59962      Transition Number: 1500.066k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:18:19,423][train][INFO][train.py>_log] ==> #976000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 9.736    Value Loss: 7.309    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 1061960    Buffer Size: 59726      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:21:33,842][train][INFO][train.py>_log] ==> #977000     Total Loss: 3.462    [weighted Loss:3.462    Policy Loss: 10.489   Value Loss: 7.398    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063456    Buffer Size: 59509      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:24:49,710][train][INFO][train.py>_log] ==> #978000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 10.826   Value Loss: 7.106    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 1064891    Buffer Size: 59450      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:28:09,979][train][INFO][train.py>_log] ==> #979000     Total Loss: 3.228    [weighted Loss:3.228    Policy Loss: 10.155   Value Loss: 7.456    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1066354    Buffer Size: 59407      Transition Number: 1500.086k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:31:28,905][train][INFO][train.py>_log] ==> #980000     Total Loss: 4.791    [weighted Loss:4.791    Policy Loss: 9.726    Value Loss: 7.376    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 1067832    Buffer Size: 59339      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:34:46,388][train][INFO][train.py>_log] ==> #981000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 9.623    Value Loss: 7.227    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069325    Buffer Size: 59388      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:38:03,107][train][INFO][train.py>_log] ==> #982000     Total Loss: 4.384    [weighted Loss:4.384    Policy Loss: 9.906    Value Loss: 7.724    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1070815    Buffer Size: 59415      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:41:19,822][train][INFO][train.py>_log] ==> #983000     Total Loss: 3.026    [weighted Loss:3.026    Policy Loss: 10.680   Value Loss: 7.709    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 1072963    Buffer Size: 60063      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:44:34,958][train][INFO][train.py>_log] ==> #984000     Total Loss: 5.634    [weighted Loss:5.634    Policy Loss: 10.579   Value Loss: 7.649    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1075164    Buffer Size: 60681      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:47:56,864][train][INFO][train.py>_log] ==> #985000     Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 10.296   Value Loss: 7.402    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 1077432    Buffer Size: 61228      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:51:11,018][train][INFO][train.py>_log] ==> #986000     Total Loss: 3.481    [weighted Loss:3.481    Policy Loss: 10.211   Value Loss: 7.093    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 1079598    Buffer Size: 61486      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:54:24,942][train][INFO][train.py>_log] ==> #987000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 9.367    Value Loss: 7.254    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 1081448    Buffer Size: 61534      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 07:57:42,254][train][INFO][train.py>_log] ==> #988000     Total Loss: 3.803    [weighted Loss:3.803    Policy Loss: 10.688   Value Loss: 7.322    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1083305    Buffer Size: 61683      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:00:55,334][train][INFO][train.py>_log] ==> #989000     Total Loss: 3.111    [weighted Loss:3.111    Policy Loss: 9.041    Value Loss: 7.322    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 1084869    Buffer Size: 61392      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:04:14,292][train][INFO][train.py>_log] ==> #990000     Total Loss: 3.410    [weighted Loss:3.410    Policy Loss: 9.363    Value Loss: 7.696    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 1086455    Buffer Size: 60071      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:07:35,963][train][INFO][train.py>_log] ==> #991000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 9.045    Value Loss: 7.757    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1088594    Buffer Size: 59302      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:10:50,534][train][INFO][train.py>_log] ==> #992000     Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 9.952    Value Loss: 7.379    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 1090712    Buffer Size: 59278      Transition Number: 1500.073k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:14:07,171][train][INFO][train.py>_log] ==> #993000     Total Loss: 3.589    [weighted Loss:3.589    Policy Loss: 10.063   Value Loss: 7.655    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092345    Buffer Size: 58939      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:17:22,777][train][INFO][train.py>_log] ==> #994000     Total Loss: 4.507    [weighted Loss:4.507    Policy Loss: 9.868    Value Loss: 7.444    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 1094011    Buffer Size: 59246      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:20:38,645][train][INFO][train.py>_log] ==> #995000     Total Loss: 2.440    [weighted Loss:2.440    Policy Loss: 9.639    Value Loss: 7.686    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 1096293    Buffer Size: 60093      Transition Number: 1500.067k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:23:54,792][train][INFO][train.py>_log] ==> #996000     Total Loss: 4.816    [weighted Loss:4.816    Policy Loss: 10.519   Value Loss: 7.754    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098604    Buffer Size: 60806      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:27:11,134][train][INFO][train.py>_log] ==> #997000     Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 10.414   Value Loss: 7.572    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100906    Buffer Size: 61521      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:30:25,536][train][INFO][train.py>_log] ==> #998000     Total Loss: 3.284    [weighted Loss:3.284    Policy Loss: 9.863    Value Loss: 7.745    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103330    Buffer Size: 61811      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:33:45,498][train][INFO][train.py>_log] ==> #999000     Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 9.952    Value Loss: 7.657    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 1106251    Buffer Size: 62571      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:37:01,655][train][INFO][train.py>_log] ==> #1000000    Total Loss: 2.927    [weighted Loss:2.927    Policy Loss: 9.363    Value Loss: 7.644    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1109091    Buffer Size: 63394      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:40:15,502][train][INFO][train.py>_log] ==> #1001000    Total Loss: 2.709    [weighted Loss:2.709    Policy Loss: 10.470   Value Loss: 7.594    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111071    Buffer Size: 63631      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:43:27,406][train][INFO][train.py>_log] ==> #1002000    Total Loss: 4.183    [weighted Loss:4.183    Policy Loss: 9.505    Value Loss: 7.438    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113117    Buffer Size: 64013      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:46:42,641][train][INFO][train.py>_log] ==> #1003000    Total Loss: 3.865    [weighted Loss:3.865    Policy Loss: 10.656   Value Loss: 7.547    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1114580    Buffer Size: 63851      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:49:57,067][train][INFO][train.py>_log] ==> #1004000    Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 9.769    Value Loss: 7.761    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1115992    Buffer Size: 63757      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:53:14,409][train][INFO][train.py>_log] ==> #1005000    Total Loss: 4.276    [weighted Loss:4.276    Policy Loss: 10.136   Value Loss: 7.312    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117744    Buffer Size: 64025      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:56:30,481][train][INFO][train.py>_log] ==> #1006000    Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 8.656    Value Loss: 7.333    Reward Loss: 1.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 1119580    Buffer Size: 64468      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-12 08:59:45,551][train][INFO][train.py>_log] ==> #1007000    Total Loss: 5.641    [weighted Loss:5.641    Policy Loss: 9.404    Value Loss: 7.430    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1120888    Buffer Size: 64468      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:03:01,047][train][INFO][train.py>_log] ==> #1008000    Total Loss: 2.844    [weighted Loss:2.844    Policy Loss: 8.474    Value Loss: 7.188    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 1122203    Buffer Size: 64295      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:06:18,320][train][INFO][train.py>_log] ==> #1009000    Total Loss: 4.264    [weighted Loss:4.264    Policy Loss: 8.060    Value Loss: 7.336    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1124053    Buffer Size: 64636      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:09:34,859][train][INFO][train.py>_log] ==> #1010000    Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 8.346    Value Loss: 7.481    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1125831    Buffer Size: 64838      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:12:51,418][train][INFO][train.py>_log] ==> #1011000    Total Loss: 4.090    [weighted Loss:4.090    Policy Loss: 7.698    Value Loss: 7.236    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1127290    Buffer Size: 64791      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:16:03,957][train][INFO][train.py>_log] ==> #1012000    Total Loss: 1.577    [weighted Loss:1.577    Policy Loss: 8.269    Value Loss: 7.517    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128727    Buffer Size: 64720      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:19:20,544][train][INFO][train.py>_log] ==> #1013000    Total Loss: 3.464    [weighted Loss:3.464    Policy Loss: 7.867    Value Loss: 7.286    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 1129944    Buffer Size: 64617      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:22:34,520][train][INFO][train.py>_log] ==> #1014000    Total Loss: 2.164    [weighted Loss:2.164    Policy Loss: 6.387    Value Loss: 7.597    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1131156    Buffer Size: 64440      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:25:48,925][train][INFO][train.py>_log] ==> #1015000    Total Loss: 0.970    [weighted Loss:0.970    Policy Loss: 7.817    Value Loss: 7.510    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1132051    Buffer Size: 63945      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:29:06,953][train][INFO][train.py>_log] ==> #1016000    Total Loss: 2.286    [weighted Loss:2.286    Policy Loss: 6.441    Value Loss: 7.777    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 1132942    Buffer Size: 63393      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:32:24,605][train][INFO][train.py>_log] ==> #1017000    Total Loss: 3.325    [weighted Loss:3.325    Policy Loss: 9.276    Value Loss: 7.613    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1134044    Buffer Size: 63026      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:35:40,038][train][INFO][train.py>_log] ==> #1018000    Total Loss: 3.544    [weighted Loss:3.544    Policy Loss: 8.565    Value Loss: 7.729    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135144    Buffer Size: 62066      Transition Number: 1500.106k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:39:00,048][train][INFO][train.py>_log] ==> #1019000    Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 10.461   Value Loss: 7.465    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1136706    Buffer Size: 61329      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:42:18,738][train][INFO][train.py>_log] ==> #1020000    Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 9.376    Value Loss: 7.519    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1138263    Buffer Size: 60608      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:45:33,376][train][INFO][train.py>_log] ==> #1021000    Total Loss: 3.372    [weighted Loss:3.372    Policy Loss: 11.231   Value Loss: 7.718    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139654    Buffer Size: 60028      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:48:51,787][train][INFO][train.py>_log] ==> #1022000    Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 9.324    Value Loss: 7.295    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 1141062    Buffer Size: 59564      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:52:08,140][train][INFO][train.py>_log] ==> #1023000    Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 11.559   Value Loss: 7.462    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1143057    Buffer Size: 59570      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:55:26,651][train][INFO][train.py>_log] ==> #1024000    Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 10.028   Value Loss: 7.263    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1145030    Buffer Size: 59900      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-12 09:58:44,686][train][INFO][train.py>_log] ==> #1025000    Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 10.243   Value Loss: 7.448    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147005    Buffer Size: 60166      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:02:04,681][train][INFO][train.py>_log] ==> #1026000    Total Loss: 2.006    [weighted Loss:2.006    Policy Loss: 8.984    Value Loss: 7.642    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1148990    Buffer Size: 60017      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:05:21,301][train][INFO][train.py>_log] ==> #1027000    Total Loss: 3.296    [weighted Loss:3.296    Policy Loss: 10.567   Value Loss: 7.300    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1150499    Buffer Size: 59500      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:08:36,931][train][INFO][train.py>_log] ==> #1028000    Total Loss: 4.270    [weighted Loss:4.270    Policy Loss: 9.194    Value Loss: 7.580    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152022    Buffer Size: 59340      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:11:54,254][train][INFO][train.py>_log] ==> #1029000    Total Loss: 2.425    [weighted Loss:2.425    Policy Loss: 10.508   Value Loss: 7.574    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1153399    Buffer Size: 58972      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:15:12,854][train][INFO][train.py>_log] ==> #1030000    Total Loss: 2.773    [weighted Loss:2.773    Policy Loss: 10.164   Value Loss: 7.929    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1154776    Buffer Size: 58147      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:18:31,300][train][INFO][train.py>_log] ==> #1031000    Total Loss: 3.655    [weighted Loss:3.655    Policy Loss: 10.559   Value Loss: 7.600    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1156341    Buffer Size: 57377      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:21:49,625][train][INFO][train.py>_log] ==> #1032000    Total Loss: 3.786    [weighted Loss:3.786    Policy Loss: 9.821    Value Loss: 7.564    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1157903    Buffer Size: 56604      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:25:07,421][train][INFO][train.py>_log] ==> #1033000    Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 8.862    Value Loss: 7.508    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 1159477    Buffer Size: 55719      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:28:31,239][train][INFO][train.py>_log] ==> #1034000    Total Loss: 1.767    [weighted Loss:1.767    Policy Loss: 8.532    Value Loss: 7.451    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 1161080    Buffer Size: 54494      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:31:51,566][train][INFO][train.py>_log] ==> #1035000    Total Loss: 2.640    [weighted Loss:2.640    Policy Loss: 9.749    Value Loss: 7.669    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1162401    Buffer Size: 53085      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:35:10,372][train][INFO][train.py>_log] ==> #1036000    Total Loss: 5.096    [weighted Loss:5.096    Policy Loss: 9.679    Value Loss: 8.029    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 1163737    Buffer Size: 52362      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:38:27,788][train][INFO][train.py>_log] ==> #1037000    Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 9.300    Value Loss: 7.529    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 1165209    Buffer Size: 51824      Transition Number: 1500.090k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:41:45,805][train][INFO][train.py>_log] ==> #1038000    Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 10.194   Value Loss: 7.298    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 1166730    Buffer Size: 51869      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:45:02,962][train][INFO][train.py>_log] ==> #1039000    Total Loss: 2.247    [weighted Loss:2.247    Policy Loss: 10.055   Value Loss: 7.226    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 1168703    Buffer Size: 52310      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:48:21,421][train][INFO][train.py>_log] ==> #1040000    Total Loss: 3.644    [weighted Loss:3.644    Policy Loss: 10.366   Value Loss: 7.374    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1170701    Buffer Size: 52500      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:51:40,898][train][INFO][train.py>_log] ==> #1041000    Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 9.978    Value Loss: 7.415    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 1172617    Buffer Size: 52715      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:54:58,577][train][INFO][train.py>_log] ==> #1042000    Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 9.484    Value Loss: 7.713    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1174626    Buffer Size: 53290      Transition Number: 1500.106k Batch Size: 256        Lr: 0.10000 
[2022-01-12 10:58:17,341][train][INFO][train.py>_log] ==> #1043000    Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 8.348    Value Loss: 7.285    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 1176805    Buffer Size: 53939      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:01:36,755][train][INFO][train.py>_log] ==> #1044000    Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 9.196    Value Loss: 7.837    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1178927    Buffer Size: 54163      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:04:58,213][train][INFO][train.py>_log] ==> #1045000    Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 8.767    Value Loss: 7.181    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1181684    Buffer Size: 55077      Transition Number: 1500.088k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:08:18,048][train][INFO][train.py>_log] ==> #1046000    Total Loss: 4.099    [weighted Loss:4.099    Policy Loss: 9.742    Value Loss: 7.437    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1184482    Buffer Size: 56377      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:11:34,550][train][INFO][train.py>_log] ==> #1047000    Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 9.088    Value Loss: 7.350    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 1187022    Buffer Size: 57463      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:14:51,345][train][INFO][train.py>_log] ==> #1048000    Total Loss: 3.169    [weighted Loss:3.169    Policy Loss: 9.647    Value Loss: 7.275    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 1189561    Buffer Size: 58660      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:18:08,760][train][INFO][train.py>_log] ==> #1049000    Total Loss: 3.327    [weighted Loss:3.327    Policy Loss: 9.751    Value Loss: 7.439    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 1191219    Buffer Size: 59323      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:21:24,459][train][INFO][train.py>_log] ==> #1050000    Total Loss: 1.622    [weighted Loss:1.622    Policy Loss: 9.851    Value Loss: 7.747    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1192818    Buffer Size: 60003      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:24:40,095][train][INFO][train.py>_log] ==> #1051000    Total Loss: 1.540    [weighted Loss:1.540    Policy Loss: 10.027   Value Loss: 7.430    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 1195067    Buffer Size: 61065      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:27:55,516][train][INFO][train.py>_log] ==> #1052000    Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 9.940    Value Loss: 7.755    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 1197297    Buffer Size: 62163      Transition Number: 1500.114k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:31:10,875][train][INFO][train.py>_log] ==> #1053000    Total Loss: 2.955    [weighted Loss:2.955    Policy Loss: 10.107   Value Loss: 7.324    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1199944    Buffer Size: 63306      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:34:25,743][train][INFO][train.py>_log] ==> #1054000    Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 10.362   Value Loss: 7.110    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1202716    Buffer Size: 64511      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:37:45,443][train][INFO][train.py>_log] ==> #1055000    Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 9.329    Value Loss: 7.226    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1204995    Buffer Size: 65285      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:40:55,877][train][INFO][train.py>_log] ==> #1056000    Total Loss: 2.581    [weighted Loss:2.581    Policy Loss: 11.204   Value Loss: 7.242    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 1207233    Buffer Size: 66081      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:44:11,528][train][INFO][train.py>_log] ==> #1057000    Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 9.315    Value Loss: 7.132    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1208872    Buffer Size: 65893      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:47:26,586][train][INFO][train.py>_log] ==> #1058000    Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 10.023   Value Loss: 7.131    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1210608    Buffer Size: 65708      Transition Number: 1500.110k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:50:48,761][train][INFO][train.py>_log] ==> #1059000    Total Loss: 3.428    [weighted Loss:3.428    Policy Loss: 9.782    Value Loss: 7.439    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1212124    Buffer Size: 65228      Transition Number: 1500.081k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:54:05,202][train][INFO][train.py>_log] ==> #1060000    Total Loss: 3.857    [weighted Loss:3.857    Policy Loss: 9.520    Value Loss: 7.333    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1213576    Buffer Size: 64809      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 11:57:19,914][train][INFO][train.py>_log] ==> #1061000    Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 9.245    Value Loss: 7.510    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1214696    Buffer Size: 64479      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:00:37,292][train][INFO][train.py>_log] ==> #1062000    Total Loss: 4.541    [weighted Loss:4.541    Policy Loss: 8.396    Value Loss: 7.558    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 1215838    Buffer Size: 64164      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:03:52,670][train][INFO][train.py>_log] ==> #1063000    Total Loss: 4.565    [weighted Loss:4.565    Policy Loss: 9.048    Value Loss: 8.077    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216934    Buffer Size: 63865      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:07:09,252][train][INFO][train.py>_log] ==> #1064000    Total Loss: 3.525    [weighted Loss:3.525    Policy Loss: 9.348    Value Loss: 7.328    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218019    Buffer Size: 63598      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:10:25,253][train][INFO][train.py>_log] ==> #1065000    Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 7.959    Value Loss: 7.322    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 1219488    Buffer Size: 63646      Transition Number: 1500.095k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:13:39,834][train][INFO][train.py>_log] ==> #1066000    Total Loss: 2.728    [weighted Loss:2.728    Policy Loss: 8.271    Value Loss: 7.219    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 1221005    Buffer Size: 63632      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:16:56,197][train][INFO][train.py>_log] ==> #1067000    Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 6.244    Value Loss: 7.522    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1221981    Buffer Size: 63172      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:20:15,900][train][INFO][train.py>_log] ==> #1068000    Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 6.238    Value Loss: 7.357    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223009    Buffer Size: 62683      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:23:37,149][train][INFO][train.py>_log] ==> #1069000    Total Loss: 2.993    [weighted Loss:2.993    Policy Loss: 5.807    Value Loss: 7.253    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 1224031    Buffer Size: 62344      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:26:55,507][train][INFO][train.py>_log] ==> #1070000    Total Loss: 1.257    [weighted Loss:1.257    Policy Loss: 4.732    Value Loss: 6.864    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225061    Buffer Size: 62125      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:30:13,641][train][INFO][train.py>_log] ==> #1071000    Total Loss: 0.827    [weighted Loss:0.827    Policy Loss: 5.004    Value Loss: 7.497    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225826    Buffer Size: 61682      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:33:30,573][train][INFO][train.py>_log] ==> #1072000    Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 4.672    Value Loss: 7.207    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 1226658    Buffer Size: 61036      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:36:46,688][train][INFO][train.py>_log] ==> #1073000    Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 5.179    Value Loss: 7.309    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1227519    Buffer Size: 60455      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:40:05,609][train][INFO][train.py>_log] ==> #1074000    Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 4.884    Value Loss: 7.265    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 1228406    Buffer Size: 59499      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:43:24,448][train][INFO][train.py>_log] ==> #1075000    Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 5.117    Value Loss: 7.092    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 1229343    Buffer Size: 58591      Transition Number: 1500.136k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:46:38,441][train][INFO][train.py>_log] ==> #1076000    Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 5.255    Value Loss: 7.102    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1230287    Buffer Size: 57591      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:49:58,404][train][INFO][train.py>_log] ==> #1077000    Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 5.905    Value Loss: 7.344    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 1231849    Buffer Size: 57135      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:53:16,779][train][INFO][train.py>_log] ==> #1078000    Total Loss: 0.932    [weighted Loss:0.932    Policy Loss: 6.605    Value Loss: 7.240    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 1233401    Buffer Size: 56554      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:56:33,063][train][INFO][train.py>_log] ==> #1079000    Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 6.692    Value Loss: 7.673    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 1234662    Buffer Size: 55839      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 12:59:50,290][train][INFO][train.py>_log] ==> #1080000    Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 6.389    Value Loss: 7.590    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 1235936    Buffer Size: 54633      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:03:09,642][train][INFO][train.py>_log] ==> #1081000    Total Loss: 2.956    [weighted Loss:2.956    Policy Loss: 7.402    Value Loss: 7.360    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1237445    Buffer Size: 53451      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:06:26,168][train][INFO][train.py>_log] ==> #1082000    Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 6.984    Value Loss: 7.230    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 1238910    Buffer Size: 52472      Transition Number: 1500.090k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:09:44,032][train][INFO][train.py>_log] ==> #1083000    Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 6.854    Value Loss: 7.139    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1240304    Buffer Size: 51377      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:13:00,958][train][INFO][train.py>_log] ==> #1084000    Total Loss: 1.959    [weighted Loss:1.959    Policy Loss: 7.034    Value Loss: 7.490    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241681    Buffer Size: 50815      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:16:22,164][train][INFO][train.py>_log] ==> #1085000    Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 8.127    Value Loss: 7.437    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1243919    Buffer Size: 51232      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:19:44,533][train][INFO][train.py>_log] ==> #1086000    Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 7.715    Value Loss: 7.348    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 1246202    Buffer Size: 51310      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:22:59,981][train][INFO][train.py>_log] ==> #1087000    Total Loss: 3.753    [weighted Loss:3.753    Policy Loss: 7.778    Value Loss: 7.141    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 1247704    Buffer Size: 50709      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:26:16,699][train][INFO][train.py>_log] ==> #1088000    Total Loss: 2.604    [weighted Loss:2.604    Policy Loss: 7.969    Value Loss: 7.594    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1249231    Buffer Size: 49698      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:29:32,689][train][INFO][train.py>_log] ==> #1089000    Total Loss: 1.092    [weighted Loss:1.092    Policy Loss: 7.188    Value Loss: 7.358    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1250687    Buffer Size: 48539      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:32:52,153][train][INFO][train.py>_log] ==> #1090000    Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 8.756    Value Loss: 7.801    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252229    Buffer Size: 47743      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:36:10,543][train][INFO][train.py>_log] ==> #1091000    Total Loss: 2.409    [weighted Loss:2.409    Policy Loss: 8.787    Value Loss: 8.137    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 1253765    Buffer Size: 47031      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:39:30,201][train][INFO][train.py>_log] ==> #1092000    Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 8.175    Value Loss: 7.383    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1255415    Buffer Size: 46837      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:42:53,609][train][INFO][train.py>_log] ==> #1093000    Total Loss: 3.552    [weighted Loss:3.552    Policy Loss: 8.526    Value Loss: 7.479    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 1258550    Buffer Size: 48059      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:46:16,009][train][INFO][train.py>_log] ==> #1094000    Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 8.060    Value Loss: 7.054    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1261787    Buffer Size: 49656      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:49:35,547][train][INFO][train.py>_log] ==> #1095000    Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 7.518    Value Loss: 7.290    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 1264007    Buffer Size: 50348      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:52:55,828][train][INFO][train.py>_log] ==> #1096000    Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 7.176    Value Loss: 7.242    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266111    Buffer Size: 51215      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:56:11,198][train][INFO][train.py>_log] ==> #1097000    Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 7.727    Value Loss: 7.239    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 1267814    Buffer Size: 51767      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 13:59:27,500][train][INFO][train.py>_log] ==> #1098000    Total Loss: 0.914    [weighted Loss:0.914    Policy Loss: 7.855    Value Loss: 7.517    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 1269575    Buffer Size: 52388      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:02:43,510][train][INFO][train.py>_log] ==> #1099000    Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 8.011    Value Loss: 7.512    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1271024    Buffer Size: 52650      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:06:02,832][train][INFO][train.py>_log] ==> #1100000    Total Loss: 2.705    [weighted Loss:2.705    Policy Loss: 8.545    Value Loss: 6.777    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 1272454    Buffer Size: 52512      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:09:18,384][train][INFO][train.py>_log] ==> #1101000    Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 8.885    Value Loss: 7.157    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 1273631    Buffer Size: 52349      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:12:38,283][train][INFO][train.py>_log] ==> #1102000    Total Loss: 3.697    [weighted Loss:3.697    Policy Loss: 8.264    Value Loss: 7.415    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 1274899    Buffer Size: 52537      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:15:56,643][train][INFO][train.py>_log] ==> #1103000    Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 8.118    Value Loss: 7.407    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1276794    Buffer Size: 53371      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:19:16,291][train][INFO][train.py>_log] ==> #1104000    Total Loss: 3.770    [weighted Loss:3.770    Policy Loss: 7.490    Value Loss: 7.444    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1278725    Buffer Size: 54213      Transition Number: 1500.090k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:22:30,944][train][INFO][train.py>_log] ==> #1105000    Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 6.878    Value Loss: 7.362    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 1280742    Buffer Size: 55242      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:25:45,843][train][INFO][train.py>_log] ==> #1106000    Total Loss: 3.847    [weighted Loss:3.847    Policy Loss: 8.512    Value Loss: 7.432    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1282829    Buffer Size: 56456      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:29:04,255][train][INFO][train.py>_log] ==> #1107000    Total Loss: 4.758    [weighted Loss:4.758    Policy Loss: 7.547    Value Loss: 7.158    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1284720    Buffer Size: 57416      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:32:17,028][train][INFO][train.py>_log] ==> #1108000    Total Loss: 1.963    [weighted Loss:1.963    Policy Loss: 8.262    Value Loss: 7.246    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1286523    Buffer Size: 58305      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:35:32,888][train][INFO][train.py>_log] ==> #1109000    Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 9.226    Value Loss: 7.325    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1288174    Buffer Size: 59026      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:38:49,021][train][INFO][train.py>_log] ==> #1110000    Total Loss: 2.115    [weighted Loss:2.115    Policy Loss: 9.524    Value Loss: 7.029    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1289798    Buffer Size: 59704      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:41:58,886][train][INFO][train.py>_log] ==> #1111000    Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 8.366    Value Loss: 7.256    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 1291294    Buffer Size: 59915      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:45:15,853][train][INFO][train.py>_log] ==> #1112000    Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 8.967    Value Loss: 7.781    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1292918    Buffer Size: 59997      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:48:35,065][train][INFO][train.py>_log] ==> #1113000    Total Loss: 0.702    [weighted Loss:0.702    Policy Loss: 10.175   Value Loss: 7.677    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1294281    Buffer Size: 59966      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:51:56,750][train][INFO][train.py>_log] ==> #1114000    Total Loss: 2.513    [weighted Loss:2.513    Policy Loss: 8.890    Value Loss: 7.261    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1295699    Buffer Size: 60093      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:55:17,064][train][INFO][train.py>_log] ==> #1115000    Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 10.761   Value Loss: 7.380    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1297434    Buffer Size: 60336      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-12 14:58:34,646][train][INFO][train.py>_log] ==> #1116000    Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 8.247    Value Loss: 7.057    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299173    Buffer Size: 60574      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:01:52,422][train][INFO][train.py>_log] ==> #1117000    Total Loss: 3.823    [weighted Loss:3.823    Policy Loss: 8.970    Value Loss: 7.155    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 1300683    Buffer Size: 60717      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:05:09,452][train][INFO][train.py>_log] ==> #1118000    Total Loss: 2.487    [weighted Loss:2.487    Policy Loss: 8.493    Value Loss: 7.181    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 1302226    Buffer Size: 60857      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:08:25,899][train][INFO][train.py>_log] ==> #1119000    Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 8.616    Value Loss: 6.980    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 1303263    Buffer Size: 60250      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:11:44,876][train][INFO][train.py>_log] ==> #1120000    Total Loss: 2.700    [weighted Loss:2.700    Policy Loss: 8.514    Value Loss: 7.424    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304303    Buffer Size: 59285      Transition Number: 1500.143k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:15:00,933][train][INFO][train.py>_log] ==> #1121000    Total Loss: 1.320    [weighted Loss:1.320    Policy Loss: 7.598    Value Loss: 7.269    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1305335    Buffer Size: 58460      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:18:17,825][train][INFO][train.py>_log] ==> #1122000    Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 8.593    Value Loss: 7.302    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 1306418    Buffer Size: 58060      Transition Number: 1500.162k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:21:34,042][train][INFO][train.py>_log] ==> #1123000    Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 8.465    Value Loss: 7.242    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 1307506    Buffer Size: 57724      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:24:55,565][train][INFO][train.py>_log] ==> #1124000    Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 7.190    Value Loss: 7.127    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 1308661    Buffer Size: 57386      Transition Number: 1500.076k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:28:14,288][train][INFO][train.py>_log] ==> #1125000    Total Loss: 2.356    [weighted Loss:2.356    Policy Loss: 8.476    Value Loss: 7.156    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 1309731    Buffer Size: 57028      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:31:31,979][train][INFO][train.py>_log] ==> #1126000    Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 8.060    Value Loss: 7.273    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 1310824    Buffer Size: 56596      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:34:51,329][train][INFO][train.py>_log] ==> #1127000    Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 6.252    Value Loss: 7.587    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1312844    Buffer Size: 56586      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:38:15,732][train][INFO][train.py>_log] ==> #1128000    Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 8.536    Value Loss: 7.412    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 1314932    Buffer Size: 55553      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:41:40,671][train][INFO][train.py>_log] ==> #1129000    Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 6.302    Value Loss: 7.529    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 1316935    Buffer Size: 54581      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:44:59,394][train][INFO][train.py>_log] ==> #1130000    Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 8.822    Value Loss: 7.821    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1318897    Buffer Size: 54436      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:48:20,619][train][INFO][train.py>_log] ==> #1131000    Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 7.662    Value Loss: 7.422    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 1320242    Buffer Size: 53757      Transition Number: 1500.043k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:51:39,027][train][INFO][train.py>_log] ==> #1132000    Total Loss: 2.801    [weighted Loss:2.801    Policy Loss: 9.542    Value Loss: 7.678    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 1321565    Buffer Size: 53358      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:54:58,309][train][INFO][train.py>_log] ==> #1133000    Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 8.618    Value Loss: 7.719    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 1323187    Buffer Size: 53222      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-12 15:58:18,318][train][INFO][train.py>_log] ==> #1134000    Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 9.703    Value Loss: 7.409    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1324883    Buffer Size: 53442      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:01:37,748][train][INFO][train.py>_log] ==> #1135000    Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 10.370   Value Loss: 7.392    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 1326586    Buffer Size: 53704      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:04:55,404][train][INFO][train.py>_log] ==> #1136000    Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 10.329   Value Loss: 7.169    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 1328323    Buffer Size: 54150      Transition Number: 1500.073k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:08:13,352][train][INFO][train.py>_log] ==> #1137000    Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 8.418    Value Loss: 7.702    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 1329632    Buffer Size: 54110      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:11:32,558][train][INFO][train.py>_log] ==> #1138000    Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 9.191    Value Loss: 7.304    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1331026    Buffer Size: 53534      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:14:51,989][train][INFO][train.py>_log] ==> #1139000    Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 10.174   Value Loss: 7.649    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332178    Buffer Size: 52827      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:18:12,580][train][INFO][train.py>_log] ==> #1140000    Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 10.615   Value Loss: 7.071    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 1333361    Buffer Size: 51930      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:21:31,411][train][INFO][train.py>_log] ==> #1141000    Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 9.938    Value Loss: 7.647    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1334609    Buffer Size: 51263      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:24:52,866][train][INFO][train.py>_log] ==> #1142000    Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 10.139   Value Loss: 7.439    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1335879    Buffer Size: 50677      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:28:16,941][train][INFO][train.py>_log] ==> #1143000    Total Loss: 3.478    [weighted Loss:3.478    Policy Loss: 9.361    Value Loss: 7.624    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 1338799    Buffer Size: 51611      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:31:39,408][train][INFO][train.py>_log] ==> #1144000    Total Loss: 3.772    [weighted Loss:3.772    Policy Loss: 8.834    Value Loss: 6.994    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1341745    Buffer Size: 52798      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:34:56,750][train][INFO][train.py>_log] ==> #1145000    Total Loss: 1.825    [weighted Loss:1.825    Policy Loss: 9.760    Value Loss: 7.126    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 1343597    Buffer Size: 53034      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:38:16,578][train][INFO][train.py>_log] ==> #1146000    Total Loss: 3.442    [weighted Loss:3.442    Policy Loss: 9.872    Value Loss: 7.314    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 1345512    Buffer Size: 53343      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:41:35,984][train][INFO][train.py>_log] ==> #1147000    Total Loss: 2.882    [weighted Loss:2.882    Policy Loss: 10.008   Value Loss: 7.641    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1346882    Buffer Size: 53266      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:44:54,997][train][INFO][train.py>_log] ==> #1148000    Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 9.452    Value Loss: 7.537    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 1348232    Buffer Size: 53216      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:48:16,424][train][INFO][train.py>_log] ==> #1149000    Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 8.845    Value Loss: 7.525    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1349270    Buffer Size: 52807      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:51:37,604][train][INFO][train.py>_log] ==> #1150000    Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 8.691    Value Loss: 7.395    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350324    Buffer Size: 52221      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:54:58,220][train][INFO][train.py>_log] ==> #1151000    Total Loss: 0.733    [weighted Loss:0.733    Policy Loss: 9.060    Value Loss: 7.406    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1351273    Buffer Size: 51573      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-12 16:58:22,708][train][INFO][train.py>_log] ==> #1152000    Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 8.178    Value Loss: 7.631    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 1352230    Buffer Size: 50974      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:01:42,058][train][INFO][train.py>_log] ==> #1153000    Total Loss: 1.539    [weighted Loss:1.539    Policy Loss: 9.537    Value Loss: 7.127    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1353288    Buffer Size: 50649      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:05:01,169][train][INFO][train.py>_log] ==> #1154000    Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 8.848    Value Loss: 7.469    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 1354344    Buffer Size: 50660      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:08:27,317][train][INFO][train.py>_log] ==> #1155000    Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 9.059    Value Loss: 7.298    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1356254    Buffer Size: 51331      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:11:50,370][train][INFO][train.py>_log] ==> #1156000    Total Loss: 1.836    [weighted Loss:1.836    Policy Loss: 8.799    Value Loss: 7.338    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 1358184    Buffer Size: 52093      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:15:10,921][train][INFO][train.py>_log] ==> #1157000    Total Loss: 1.829    [weighted Loss:1.829    Policy Loss: 8.415    Value Loss: 7.548    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 1360045    Buffer Size: 52795      Transition Number: 1500.081k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:18:29,502][train][INFO][train.py>_log] ==> #1158000    Total Loss: 3.407    [weighted Loss:3.407    Policy Loss: 9.101    Value Loss: 7.340    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1361942    Buffer Size: 53502      Transition Number: 1500.084k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:21:47,265][train][INFO][train.py>_log] ==> #1159000    Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 8.851    Value Loss: 7.208    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 1363780    Buffer Size: 54187      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:25:05,904][train][INFO][train.py>_log] ==> #1160000    Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 9.023    Value Loss: 7.327    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 1365565    Buffer Size: 54839      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:28:24,551][train][INFO][train.py>_log] ==> #1161000    Total Loss: 2.785    [weighted Loss:2.785    Policy Loss: 9.327    Value Loss: 7.746    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 1366591    Buffer Size: 54178      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:31:42,314][train][INFO][train.py>_log] ==> #1162000    Total Loss: 1.401    [weighted Loss:1.401    Policy Loss: 8.866    Value Loss: 7.782    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 1367645    Buffer Size: 53362      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:34:59,919][train][INFO][train.py>_log] ==> #1163000    Total Loss: 1.659    [weighted Loss:1.659    Policy Loss: 8.317    Value Loss: 7.107    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1368909    Buffer Size: 52708      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:38:20,075][train][INFO][train.py>_log] ==> #1164000    Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 8.562    Value Loss: 7.651    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370153    Buffer Size: 52003      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:41:40,846][train][INFO][train.py>_log] ==> #1165000    Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 9.049    Value Loss: 7.728    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1371076    Buffer Size: 51443      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:44:59,026][train][INFO][train.py>_log] ==> #1166000    Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 8.189    Value Loss: 7.397    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 1372003    Buffer Size: 51096      Transition Number: 1500.052k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:48:16,728][train][INFO][train.py>_log] ==> #1167000    Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 7.300    Value Loss: 7.533    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1372978    Buffer Size: 50653      Transition Number: 1500.043k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:51:34,729][train][INFO][train.py>_log] ==> #1168000    Total Loss: 3.305    [weighted Loss:3.305    Policy Loss: 8.794    Value Loss: 7.463    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373915    Buffer Size: 50033      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:54:55,109][train][INFO][train.py>_log] ==> #1169000    Total Loss: 1.479    [weighted Loss:1.479    Policy Loss: 8.130    Value Loss: 7.797    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 1374805    Buffer Size: 49358      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-12 17:58:14,755][train][INFO][train.py>_log] ==> #1170000    Total Loss: 2.846    [weighted Loss:2.846    Policy Loss: 7.349    Value Loss: 7.503    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375730    Buffer Size: 48658      Transition Number: 1500.077k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:01:36,467][train][INFO][train.py>_log] ==> #1171000    Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 8.281    Value Loss: 7.578    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1376893    Buffer Size: 48213      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:05:01,234][train][INFO][train.py>_log] ==> #1172000    Total Loss: 1.832    [weighted Loss:1.832    Policy Loss: 7.334    Value Loss: 7.338    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 1378082    Buffer Size: 48042      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:08:21,556][train][INFO][train.py>_log] ==> #1173000    Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 7.858    Value Loss: 7.390    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 1379395    Buffer Size: 48002      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:11:42,868][train][INFO][train.py>_log] ==> #1174000    Total Loss: 1.089    [weighted Loss:1.089    Policy Loss: 7.022    Value Loss: 7.771    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 1380715    Buffer Size: 48160      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:15:05,954][train][INFO][train.py>_log] ==> #1175000    Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 8.979    Value Loss: 7.448    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 1381914    Buffer Size: 48151      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:18:25,096][train][INFO][train.py>_log] ==> #1176000    Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 6.533    Value Loss: 7.617    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1383076    Buffer Size: 48083      Transition Number: 1500.071k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:21:45,361][train][INFO][train.py>_log] ==> #1177000    Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 9.152    Value Loss: 7.712    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 1384200    Buffer Size: 47695      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:25:03,389][train][INFO][train.py>_log] ==> #1178000    Total Loss: 1.391    [weighted Loss:1.391    Policy Loss: 6.683    Value Loss: 7.486    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 1385288    Buffer Size: 46138      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:28:23,272][train][INFO][train.py>_log] ==> #1179000    Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 9.360    Value Loss: 7.410    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 1386850    Buffer Size: 44825      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:31:41,838][train][INFO][train.py>_log] ==> #1180000    Total Loss: 1.157    [weighted Loss:1.157    Policy Loss: 7.879    Value Loss: 7.200    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 1388372    Buffer Size: 44534      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:34:59,075][train][INFO][train.py>_log] ==> #1181000    Total Loss: 3.792    [weighted Loss:3.792    Policy Loss: 9.684    Value Loss: 7.512    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 1390018    Buffer Size: 44344      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:38:23,501][train][INFO][train.py>_log] ==> #1182000    Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 9.925    Value Loss: 7.534    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1391706    Buffer Size: 44550      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:41:48,884][train][INFO][train.py>_log] ==> #1183000    Total Loss: 3.206    [weighted Loss:3.206    Policy Loss: 10.245   Value Loss: 7.615    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1394172    Buffer Size: 45574      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:45:10,892][train][INFO][train.py>_log] ==> #1184000    Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 9.840    Value Loss: 7.417    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 1396653    Buffer Size: 46902      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:48:35,964][train][INFO][train.py>_log] ==> #1185000    Total Loss: 4.016    [weighted Loss:4.016    Policy Loss: 9.485    Value Loss: 7.874    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1399719    Buffer Size: 48795      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:51:54,997][train][INFO][train.py>_log] ==> #1186000    Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 9.578    Value Loss: 7.349    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1402663    Buffer Size: 50718      Transition Number: 1500.093k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:55:17,732][train][INFO][train.py>_log] ==> #1187000    Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 10.472   Value Loss: 7.465    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406341    Buffer Size: 53242      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-12 18:58:35,236][train][INFO][train.py>_log] ==> #1188000    Total Loss: 3.520    [weighted Loss:3.520    Policy Loss: 9.673    Value Loss: 7.494    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1409949    Buffer Size: 55661      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:01:53,672][train][INFO][train.py>_log] ==> #1189000    Total Loss: 1.931    [weighted Loss:1.931    Policy Loss: 9.841    Value Loss: 7.461    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 1412600    Buffer Size: 56636      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:05:10,816][train][INFO][train.py>_log] ==> #1190000    Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 8.840    Value Loss: 7.240    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 1415232    Buffer Size: 57380      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:08:30,464][train][INFO][train.py>_log] ==> #1191000    Total Loss: 3.764    [weighted Loss:3.764    Policy Loss: 9.411    Value Loss: 7.187    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1417667    Buffer Size: 57859      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:11:47,505][train][INFO][train.py>_log] ==> #1192000    Total Loss: 3.092    [weighted Loss:3.092    Policy Loss: 9.503    Value Loss: 6.921    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1420043    Buffer Size: 58316      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:15:04,185][train][INFO][train.py>_log] ==> #1193000    Total Loss: 3.581    [weighted Loss:3.581    Policy Loss: 9.295    Value Loss: 7.415    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1422161    Buffer Size: 58628      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:18:21,835][train][INFO][train.py>_log] ==> #1194000    Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 9.329    Value Loss: 7.543    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424290    Buffer Size: 58976      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:21:37,197][train][INFO][train.py>_log] ==> #1195000    Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 9.561    Value Loss: 7.356    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1425908    Buffer Size: 59397      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:24:52,542][train][INFO][train.py>_log] ==> #1196000    Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 9.195    Value Loss: 7.451    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 1427546    Buffer Size: 59937      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:28:10,031][train][INFO][train.py>_log] ==> #1197000    Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 9.546    Value Loss: 7.490    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 1428783    Buffer Size: 59982      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:31:26,543][train][INFO][train.py>_log] ==> #1198000    Total Loss: 1.450    [weighted Loss:1.450    Policy Loss: 9.090    Value Loss: 7.512    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1430044    Buffer Size: 60026      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:34:43,810][train][INFO][train.py>_log] ==> #1199000    Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 8.875    Value Loss: 7.287    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 1431068    Buffer Size: 60073      Transition Number: 1500.192k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:38:01,854][train][INFO][train.py>_log] ==> #1200000    Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 9.374    Value Loss: 7.711    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1432093    Buffer Size: 60181      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:41:19,878][train][INFO][train.py>_log] ==> #1201000    Total Loss: 3.997    [weighted Loss:3.997    Policy Loss: 8.399    Value Loss: 7.012    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 1433508    Buffer Size: 60605      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:44:35,410][train][INFO][train.py>_log] ==> #1202000    Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 8.989    Value Loss: 7.406    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 1434969    Buffer Size: 61085      Transition Number: 1500.104k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:47:57,252][train][INFO][train.py>_log] ==> #1203000    Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 8.951    Value Loss: 7.139    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1436191    Buffer Size: 61363      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:51:10,011][train][INFO][train.py>_log] ==> #1204000    Total Loss: 3.235    [weighted Loss:3.235    Policy Loss: 8.789    Value Loss: 7.488    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1437297    Buffer Size: 61601      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:54:27,122][train][INFO][train.py>_log] ==> #1205000    Total Loss: 3.391    [weighted Loss:3.391    Policy Loss: 8.772    Value Loss: 6.968    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1438504    Buffer Size: 61682      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-12 19:57:48,049][train][INFO][train.py>_log] ==> #1206000    Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 8.368    Value Loss: 7.381    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1439719    Buffer Size: 61722      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:01:01,212][train][INFO][train.py>_log] ==> #1207000    Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 9.655    Value Loss: 7.285    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440812    Buffer Size: 61588      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:04:18,705][train][INFO][train.py>_log] ==> #1208000    Total Loss: 1.462    [weighted Loss:1.462    Policy Loss: 8.655    Value Loss: 7.147    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1441908    Buffer Size: 61437      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:07:36,379][train][INFO][train.py>_log] ==> #1209000    Total Loss: 3.858    [weighted Loss:3.858    Policy Loss: 9.427    Value Loss: 7.423    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1443132    Buffer Size: 61424      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:10:53,592][train][INFO][train.py>_log] ==> #1210000    Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 9.086    Value Loss: 7.236    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 1444355    Buffer Size: 61463      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:14:11,299][train][INFO][train.py>_log] ==> #1211000    Total Loss: 4.162    [weighted Loss:4.162    Policy Loss: 10.974   Value Loss: 7.393    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1445624    Buffer Size: 61569      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:17:29,006][train][INFO][train.py>_log] ==> #1212000    Total Loss: 3.633    [weighted Loss:3.633    Policy Loss: 9.467    Value Loss: 7.517    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 1446881    Buffer Size: 61687      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:20:46,786][train][INFO][train.py>_log] ==> #1213000    Total Loss: 3.579    [weighted Loss:3.579    Policy Loss: 10.419   Value Loss: 7.438    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 1448152    Buffer Size: 61550      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:24:04,236][train][INFO][train.py>_log] ==> #1214000    Total Loss: 3.693    [weighted Loss:3.693    Policy Loss: 10.351   Value Loss: 7.577    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1449431    Buffer Size: 61298      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:27:21,461][train][INFO][train.py>_log] ==> #1215000    Total Loss: 3.142    [weighted Loss:3.142    Policy Loss: 10.016   Value Loss: 7.476    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451520    Buffer Size: 61669      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:30:39,703][train][INFO][train.py>_log] ==> #1216000    Total Loss: 1.826    [weighted Loss:1.826    Policy Loss: 10.381   Value Loss: 7.536    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1453753    Buffer Size: 62188      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:33:57,913][train][INFO][train.py>_log] ==> #1217000    Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 9.628    Value Loss: 7.629    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1455841    Buffer Size: 62057      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:37:17,322][train][INFO][train.py>_log] ==> #1218000    Total Loss: 2.566    [weighted Loss:2.566    Policy Loss: 9.905    Value Loss: 7.745    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1458072    Buffer Size: 61865      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:40:33,897][train][INFO][train.py>_log] ==> #1219000    Total Loss: 2.335    [weighted Loss:2.335    Policy Loss: 10.340   Value Loss: 7.820    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1459915    Buffer Size: 61049      Transition Number: 1500.088k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:43:49,657][train][INFO][train.py>_log] ==> #1220000    Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 9.807    Value Loss: 7.316    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1461749    Buffer Size: 60062      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:47:04,568][train][INFO][train.py>_log] ==> #1221000    Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 9.915    Value Loss: 7.852    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1463104    Buffer Size: 58493      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:50:22,219][train][INFO][train.py>_log] ==> #1222000    Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 8.480    Value Loss: 7.176    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 1464501    Buffer Size: 56494      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:53:38,157][train][INFO][train.py>_log] ==> #1223000    Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 9.365    Value Loss: 7.445    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 1465842    Buffer Size: 54793      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 20:56:54,805][train][INFO][train.py>_log] ==> #1224000    Total Loss: 3.266    [weighted Loss:3.266    Policy Loss: 9.953    Value Loss: 7.451    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1467189    Buffer Size: 53632      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:00:16,027][train][INFO][train.py>_log] ==> #1225000    Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 9.715    Value Loss: 7.589    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 1468481    Buffer Size: 52511      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:03:33,101][train][INFO][train.py>_log] ==> #1226000    Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 10.212   Value Loss: 7.468    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 1469780    Buffer Size: 51523      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:06:48,932][train][INFO][train.py>_log] ==> #1227000    Total Loss: 2.330    [weighted Loss:2.330    Policy Loss: 10.461   Value Loss: 7.549    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1471161    Buffer Size: 50651      Transition Number: 1500.124k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:10:08,406][train][INFO][train.py>_log] ==> #1228000    Total Loss: 1.443    [weighted Loss:1.443    Policy Loss: 10.529   Value Loss: 7.621    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 1472630    Buffer Size: 49879      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:13:27,559][train][INFO][train.py>_log] ==> #1229000    Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 9.816    Value Loss: 7.248    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 1474833    Buffer Size: 50086      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:16:46,997][train][INFO][train.py>_log] ==> #1230000    Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 11.725   Value Loss: 7.529    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 1477068    Buffer Size: 50618      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:20:07,286][train][INFO][train.py>_log] ==> #1231000    Total Loss: 2.164    [weighted Loss:2.164    Policy Loss: 10.372   Value Loss: 7.199    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 1479957    Buffer Size: 51836      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:23:24,231][train][INFO][train.py>_log] ==> #1232000    Total Loss: 1.151    [weighted Loss:1.151    Policy Loss: 11.067   Value Loss: 7.293    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 1482792    Buffer Size: 53311      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:26:40,989][train][INFO][train.py>_log] ==> #1233000    Total Loss: 3.179    [weighted Loss:3.179    Policy Loss: 10.516   Value Loss: 7.419    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485106    Buffer Size: 54445      Transition Number: 1500.100k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:29:58,137][train][INFO][train.py>_log] ==> #1234000    Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 11.866   Value Loss: 7.638    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1487461    Buffer Size: 55724      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:33:11,056][train][INFO][train.py>_log] ==> #1235000    Total Loss: 0.858    [weighted Loss:0.858    Policy Loss: 11.313   Value Loss: 7.501    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 1489176    Buffer Size: 56205      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:36:26,768][train][INFO][train.py>_log] ==> #1236000    Total Loss: 3.420    [weighted Loss:3.420    Policy Loss: 11.612   Value Loss: 7.435    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1490888    Buffer Size: 56479      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:39:44,649][train][INFO][train.py>_log] ==> #1237000    Total Loss: 5.027    [weighted Loss:5.027    Policy Loss: 10.746   Value Loss: 7.289    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 1492329    Buffer Size: 56623      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:42:56,080][train][INFO][train.py>_log] ==> #1238000    Total Loss: 1.069    [weighted Loss:1.069    Policy Loss: 9.653    Value Loss: 7.296    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1493772    Buffer Size: 56910      Transition Number: 1500.059k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:46:14,782][train][INFO][train.py>_log] ==> #1239000    Total Loss: 3.025    [weighted Loss:3.025    Policy Loss: 10.994   Value Loss: 7.754    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1495050    Buffer Size: 56981      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:49:31,514][train][INFO][train.py>_log] ==> #1240000    Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 9.816    Value Loss: 7.667    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 1496337    Buffer Size: 57053      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:52:48,376][train][INFO][train.py>_log] ==> #1241000    Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 9.363    Value Loss: 7.634    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 1497932    Buffer Size: 57447      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:56:05,221][train][INFO][train.py>_log] ==> #1242000    Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 9.736    Value Loss: 7.185    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 1499597    Buffer Size: 57985      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-12 21:59:24,099][train][INFO][train.py>_log] ==> #1243000    Total Loss: 1.525    [weighted Loss:1.525    Policy Loss: 8.954    Value Loss: 7.529    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 1501183    Buffer Size: 58333      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:02:40,206][train][INFO][train.py>_log] ==> #1244000    Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 10.359   Value Loss: 7.504    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 1502675    Buffer Size: 58623      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:05:57,403][train][INFO][train.py>_log] ==> #1245000    Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 10.325   Value Loss: 7.284    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 1505105    Buffer Size: 59705      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:09:13,531][train][INFO][train.py>_log] ==> #1246000    Total Loss: 3.408    [weighted Loss:3.408    Policy Loss: 9.595    Value Loss: 7.303    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1507554    Buffer Size: 60878      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:12:29,301][train][INFO][train.py>_log] ==> #1247000    Total Loss: 3.652    [weighted Loss:3.652    Policy Loss: 10.538   Value Loss: 7.216    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 1509608    Buffer Size: 61679      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:15:43,135][train][INFO][train.py>_log] ==> #1248000    Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 10.576   Value Loss: 7.346    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1511684    Buffer Size: 62452      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:18:57,878][train][INFO][train.py>_log] ==> #1249000    Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 10.065   Value Loss: 7.331    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 1513200    Buffer Size: 62191      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:22:14,917][train][INFO][train.py>_log] ==> #1250000    Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 10.666   Value Loss: 7.626    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1514742    Buffer Size: 61667      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:25:32,166][train][INFO][train.py>_log] ==> #1251000    Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 10.044   Value Loss: 7.331    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 1516377    Buffer Size: 61187      Transition Number: 1500.144k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:28:53,307][train][INFO][train.py>_log] ==> #1252000    Total Loss: 4.155    [weighted Loss:4.155    Policy Loss: 10.217   Value Loss: 7.548    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 1518017    Buffer Size: 60738      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:32:07,731][train][INFO][train.py>_log] ==> #1253000    Total Loss: 3.338    [weighted Loss:3.338    Policy Loss: 9.603    Value Loss: 7.540    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 1519394    Buffer Size: 60253      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:35:26,768][train][INFO][train.py>_log] ==> #1254000    Total Loss: 3.929    [weighted Loss:3.929    Policy Loss: 9.932    Value Loss: 8.118    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1520841    Buffer Size: 59851      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:38:47,839][train][INFO][train.py>_log] ==> #1255000    Total Loss: 3.834    [weighted Loss:3.834    Policy Loss: 10.460   Value Loss: 7.444    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 1522652    Buffer Size: 60004      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:42:03,240][train][INFO][train.py>_log] ==> #1256000    Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 10.171   Value Loss: 7.448    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524430    Buffer Size: 60354      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:45:18,892][train][INFO][train.py>_log] ==> #1257000    Total Loss: 2.808    [weighted Loss:2.808    Policy Loss: 10.205   Value Loss: 7.439    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1525965    Buffer Size: 60559      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:48:38,069][train][INFO][train.py>_log] ==> #1258000    Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 9.471    Value Loss: 7.639    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1527625    Buffer Size: 60806      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:51:56,806][train][INFO][train.py>_log] ==> #1259000    Total Loss: 3.277    [weighted Loss:3.277    Policy Loss: 9.502    Value Loss: 7.714    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1529264    Buffer Size: 61113      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:55:15,195][train][INFO][train.py>_log] ==> #1260000    Total Loss: 2.885    [weighted Loss:2.885    Policy Loss: 9.489    Value Loss: 7.609    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1530880    Buffer Size: 61418      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-12 22:58:31,452][train][INFO][train.py>_log] ==> #1261000    Total Loss: 2.613    [weighted Loss:2.613    Policy Loss: 9.328    Value Loss: 7.264    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 1532163    Buffer Size: 61412      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:01:48,506][train][INFO][train.py>_log] ==> #1262000    Total Loss: 3.698    [weighted Loss:3.698    Policy Loss: 10.372   Value Loss: 7.316    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 1533453    Buffer Size: 61313      Transition Number: 1500.079k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:05:08,857][train][INFO][train.py>_log] ==> #1263000    Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 9.452    Value Loss: 7.395    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 1535047    Buffer Size: 60922      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:08:28,119][train][INFO][train.py>_log] ==> #1264000    Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 9.677    Value Loss: 7.464    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1536628    Buffer Size: 60296      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:11:49,871][train][INFO][train.py>_log] ==> #1265000    Total Loss: 4.116    [weighted Loss:4.116    Policy Loss: 9.695    Value Loss: 7.295    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 1539242    Buffer Size: 60358      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:15:09,034][train][INFO][train.py>_log] ==> #1266000    Total Loss: 2.789    [weighted Loss:2.789    Policy Loss: 8.896    Value Loss: 7.704    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1541746    Buffer Size: 60064      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:18:26,001][train][INFO][train.py>_log] ==> #1267000    Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 9.279    Value Loss: 7.575    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1543610    Buffer Size: 59528      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:21:42,048][train][INFO][train.py>_log] ==> #1268000    Total Loss: 3.447    [weighted Loss:3.447    Policy Loss: 8.732    Value Loss: 7.416    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1545419    Buffer Size: 59089      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:25:01,049][train][INFO][train.py>_log] ==> #1269000    Total Loss: 3.244    [weighted Loss:3.244    Policy Loss: 9.804    Value Loss: 7.459    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 1546959    Buffer Size: 58589      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:28:19,052][train][INFO][train.py>_log] ==> #1270000    Total Loss: 0.967    [weighted Loss:0.967    Policy Loss: 9.140    Value Loss: 7.747    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1548491    Buffer Size: 58448      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:31:37,340][train][INFO][train.py>_log] ==> #1271000    Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 9.743    Value Loss: 7.554    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1550384    Buffer Size: 58697      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:34:52,841][train][INFO][train.py>_log] ==> #1272000    Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 8.791    Value Loss: 7.353    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 1552303    Buffer Size: 59118      Transition Number: 1500.067k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:38:14,043][train][INFO][train.py>_log] ==> #1273000    Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 8.625    Value Loss: 7.267    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1554938    Buffer Size: 60287      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:41:32,550][train][INFO][train.py>_log] ==> #1274000    Total Loss: 1.254    [weighted Loss:1.254    Policy Loss: 8.894    Value Loss: 7.510    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1557468    Buffer Size: 61473      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:44:50,254][train][INFO][train.py>_log] ==> #1275000    Total Loss: 2.672    [weighted Loss:2.672    Policy Loss: 9.180    Value Loss: 7.737    Reward Loss: 1.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 1560021    Buffer Size: 62448      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:48:10,155][train][INFO][train.py>_log] ==> #1276000    Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 10.357   Value Loss: 7.919    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1562686    Buffer Size: 63336      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:51:25,207][train][INFO][train.py>_log] ==> #1277000    Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 9.167    Value Loss: 7.457    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1564706    Buffer Size: 63824      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:54:38,792][train][INFO][train.py>_log] ==> #1278000    Total Loss: 0.413    [weighted Loss:0.413    Policy Loss: 8.593    Value Loss: 7.419    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 1566793    Buffer Size: 64348      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-12 23:57:58,355][train][INFO][train.py>_log] ==> #1279000    Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 7.906    Value Loss: 7.345    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1568483    Buffer Size: 63964      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:01:15,951][train][INFO][train.py>_log] ==> #1280000    Total Loss: 0.928    [weighted Loss:0.928    Policy Loss: 8.473    Value Loss: 7.223    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1570172    Buffer Size: 63205      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:04:33,964][train][INFO][train.py>_log] ==> #1281000    Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 9.466    Value Loss: 7.399    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 1572107    Buffer Size: 62923      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:07:54,806][train][INFO][train.py>_log] ==> #1282000    Total Loss: 3.665    [weighted Loss:3.665    Policy Loss: 9.149    Value Loss: 7.192    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1574096    Buffer Size: 62840      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:11:11,895][train][INFO][train.py>_log] ==> #1283000    Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 9.737    Value Loss: 7.509    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1575813    Buffer Size: 62885      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:14:26,929][train][INFO][train.py>_log] ==> #1284000    Total Loss: 1.809    [weighted Loss:1.809    Policy Loss: 8.486    Value Loss: 7.447    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 1577526    Buffer Size: 63076      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:17:48,632][train][INFO][train.py>_log] ==> #1285000    Total Loss: 2.333    [weighted Loss:2.333    Policy Loss: 9.509    Value Loss: 7.485    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1579237    Buffer Size: 63201      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:21:03,125][train][INFO][train.py>_log] ==> #1286000    Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 9.297    Value Loss: 7.787    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 1580882    Buffer Size: 63202      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:24:19,979][train][INFO][train.py>_log] ==> #1287000    Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 9.305    Value Loss: 7.471    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1582304    Buffer Size: 63197      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:27:35,111][train][INFO][train.py>_log] ==> #1288000    Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 8.283    Value Loss: 7.218    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1583708    Buffer Size: 63208      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:30:56,317][train][INFO][train.py>_log] ==> #1289000    Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 9.506    Value Loss: 7.753    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1585068    Buffer Size: 62929      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:34:15,280][train][INFO][train.py>_log] ==> #1290000    Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 8.838    Value Loss: 7.611    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1586421    Buffer Size: 62508      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:37:32,718][train][INFO][train.py>_log] ==> #1291000    Total Loss: 2.713    [weighted Loss:2.713    Policy Loss: 9.372    Value Loss: 7.220    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 1587949    Buffer Size: 62403      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:40:51,250][train][INFO][train.py>_log] ==> #1292000    Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 9.750    Value Loss: 7.374    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1589503    Buffer Size: 62351      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:44:06,536][train][INFO][train.py>_log] ==> #1293000    Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 9.743    Value Loss: 7.690    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1591434    Buffer Size: 62657      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:47:25,755][train][INFO][train.py>_log] ==> #1294000    Total Loss: 3.800    [weighted Loss:3.800    Policy Loss: 8.887    Value Loss: 7.296    Reward Loss: 1.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 1593438    Buffer Size: 63027      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:50:45,706][train][INFO][train.py>_log] ==> #1295000    Total Loss: 3.305    [weighted Loss:3.305    Policy Loss: 9.304    Value Loss: 7.239    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1595705    Buffer Size: 63795      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:54:01,633][train][INFO][train.py>_log] ==> #1296000    Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 9.384    Value Loss: 7.506    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1597960    Buffer Size: 64735      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-13 00:57:13,758][train][INFO][train.py>_log] ==> #1297000    Total Loss: 5.001    [weighted Loss:5.001    Policy Loss: 8.647    Value Loss: 7.667    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1599841    Buffer Size: 65201      Transition Number: 1500.100k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:00:33,667][train][INFO][train.py>_log] ==> #1298000    Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 9.186    Value Loss: 7.251    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1601879    Buffer Size: 65609      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:03:50,318][train][INFO][train.py>_log] ==> #1299000    Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 9.425    Value Loss: 7.529    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1603303    Buffer Size: 64875      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:07:08,277][train][INFO][train.py>_log] ==> #1300000    Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 9.281    Value Loss: 7.172    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1604774    Buffer Size: 63871      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:10:26,706][train][INFO][train.py>_log] ==> #1301000    Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 9.855    Value Loss: 7.436    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1606327    Buffer Size: 63266      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:13:40,290][train][INFO][train.py>_log] ==> #1302000    Total Loss: 2.753    [weighted Loss:2.753    Policy Loss: 9.322    Value Loss: 7.534    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 1607816    Buffer Size: 62928      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:16:58,712][train][INFO][train.py>_log] ==> #1303000    Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 9.488    Value Loss: 7.521    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1609615    Buffer Size: 63006      Transition Number: 1500.116k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:20:16,921][train][INFO][train.py>_log] ==> #1304000    Total Loss: 2.247    [weighted Loss:2.247    Policy Loss: 9.604    Value Loss: 7.596    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1611417    Buffer Size: 63196      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:23:32,498][train][INFO][train.py>_log] ==> #1305000    Total Loss: 2.885    [weighted Loss:2.885    Policy Loss: 8.330    Value Loss: 7.249    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1613222    Buffer Size: 63263      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:26:48,997][train][INFO][train.py>_log] ==> #1306000    Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 9.500    Value Loss: 7.252    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1615025    Buffer Size: 63166      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:30:05,562][train][INFO][train.py>_log] ==> #1307000    Total Loss: 4.590    [weighted Loss:4.590    Policy Loss: 9.794    Value Loss: 7.702    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1616545    Buffer Size: 62383      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:33:23,750][train][INFO][train.py>_log] ==> #1308000    Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 9.183    Value Loss: 7.565    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1618096    Buffer Size: 61396      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:36:39,829][train][INFO][train.py>_log] ==> #1309000    Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 9.195    Value Loss: 7.657    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1619624    Buffer Size: 60609      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:39:58,864][train][INFO][train.py>_log] ==> #1310000    Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 8.408    Value Loss: 7.359    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1621151    Buffer Size: 59683      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:43:12,713][train][INFO][train.py>_log] ==> #1311000    Total Loss: 2.051    [weighted Loss:2.051    Policy Loss: 8.231    Value Loss: 7.556    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1622482    Buffer Size: 58779      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:46:32,155][train][INFO][train.py>_log] ==> #1312000    Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 8.946    Value Loss: 7.502    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 1623826    Buffer Size: 58112      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:49:55,384][train][INFO][train.py>_log] ==> #1313000    Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 8.018    Value Loss: 7.534    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1626084    Buffer Size: 58305      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:53:11,456][train][INFO][train.py>_log] ==> #1314000    Total Loss: 0.877    [weighted Loss:0.877    Policy Loss: 8.671    Value Loss: 7.292    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 1628327    Buffer Size: 58783      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:56:28,480][train][INFO][train.py>_log] ==> #1315000    Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 9.392    Value Loss: 7.722    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1630436    Buffer Size: 59092      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-13 01:59:47,326][train][INFO][train.py>_log] ==> #1316000    Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 9.501    Value Loss: 7.338    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1632548    Buffer Size: 59135      Transition Number: 1500.090k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:03:05,199][train][INFO][train.py>_log] ==> #1317000    Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 8.243    Value Loss: 7.502    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1634338    Buffer Size: 59096      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:06:23,266][train][INFO][train.py>_log] ==> #1318000    Total Loss: 3.504    [weighted Loss:3.504    Policy Loss: 9.520    Value Loss: 7.531    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 1636061    Buffer Size: 59127      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:09:41,172][train][INFO][train.py>_log] ==> #1319000    Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 9.015    Value Loss: 7.460    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 1637858    Buffer Size: 59132      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:12:58,876][train][INFO][train.py>_log] ==> #1320000    Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 9.344    Value Loss: 7.660    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1639598    Buffer Size: 59204      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:16:16,747][train][INFO][train.py>_log] ==> #1321000    Total Loss: 1.764    [weighted Loss:1.764    Policy Loss: 9.894    Value Loss: 7.527    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1641245    Buffer Size: 59308      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:19:36,134][train][INFO][train.py>_log] ==> #1322000    Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 9.255    Value Loss: 7.625    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1642883    Buffer Size: 59502      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:22:52,832][train][INFO][train.py>_log] ==> #1323000    Total Loss: 3.196    [weighted Loss:3.196    Policy Loss: 10.819   Value Loss: 7.806    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1644580    Buffer Size: 59795      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:26:14,702][train][INFO][train.py>_log] ==> #1324000    Total Loss: 4.329    [weighted Loss:4.329    Policy Loss: 9.945    Value Loss: 7.901    Reward Loss: 1.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 1646297    Buffer Size: 60127      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:29:32,535][train][INFO][train.py>_log] ==> #1325000    Total Loss: 3.158    [weighted Loss:3.158    Policy Loss: 10.173   Value Loss: 7.605    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1647802    Buffer Size: 60139      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:32:48,816][train][INFO][train.py>_log] ==> #1326000    Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 8.985    Value Loss: 7.640    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 1649364    Buffer Size: 60191      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:36:04,608][train][INFO][train.py>_log] ==> #1327000    Total Loss: 4.454    [weighted Loss:4.454    Policy Loss: 10.041   Value Loss: 7.722    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1650553    Buffer Size: 59663      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:39:22,526][train][INFO][train.py>_log] ==> #1328000    Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 10.254   Value Loss: 7.881    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1651758    Buffer Size: 58900      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:42:40,975][train][INFO][train.py>_log] ==> #1329000    Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 9.870    Value Loss: 7.500    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1653101    Buffer Size: 58155      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:45:57,964][train][INFO][train.py>_log] ==> #1330000    Total Loss: 3.483    [weighted Loss:3.483    Policy Loss: 9.868    Value Loss: 7.518    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1654448    Buffer Size: 57259      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:49:17,028][train][INFO][train.py>_log] ==> #1331000    Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 10.261   Value Loss: 7.612    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 1656062    Buffer Size: 56800      Transition Number: 1500.067k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:52:35,140][train][INFO][train.py>_log] ==> #1332000    Total Loss: 4.070    [weighted Loss:4.070    Policy Loss: 9.411    Value Loss: 7.423    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1657628    Buffer Size: 56396      Transition Number: 1500.077k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:55:56,710][train][INFO][train.py>_log] ==> #1333000    Total Loss: 3.166    [weighted Loss:3.166    Policy Loss: 10.414   Value Loss: 7.491    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1659577    Buffer Size: 56605      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-13 02:59:19,192][train][INFO][train.py>_log] ==> #1334000    Total Loss: 1.327    [weighted Loss:1.327    Policy Loss: 10.454   Value Loss: 7.529    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1661539    Buffer Size: 57029      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:02:37,790][train][INFO][train.py>_log] ==> #1335000    Total Loss: 3.600    [weighted Loss:3.600    Policy Loss: 9.955    Value Loss: 7.335    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1663428    Buffer Size: 57384      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:05:54,888][train][INFO][train.py>_log] ==> #1336000    Total Loss: 3.499    [weighted Loss:3.499    Policy Loss: 10.258   Value Loss: 7.759    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 1665254    Buffer Size: 57637      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:09:16,244][train][INFO][train.py>_log] ==> #1337000    Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 9.701    Value Loss: 7.682    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 1667105    Buffer Size: 57823      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:12:35,377][train][INFO][train.py>_log] ==> #1338000    Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 8.926    Value Loss: 7.510    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 1668924    Buffer Size: 57849      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:15:51,153][train][INFO][train.py>_log] ==> #1339000    Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 10.314   Value Loss: 7.437    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 1669999    Buffer Size: 57241      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:19:11,850][train][INFO][train.py>_log] ==> #1340000    Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 9.746    Value Loss: 7.211    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 1671056    Buffer Size: 56569      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:22:33,932][train][INFO][train.py>_log] ==> #1341000    Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 9.600    Value Loss: 7.304    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1672446    Buffer Size: 56262      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:25:54,091][train][INFO][train.py>_log] ==> #1342000    Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 9.271    Value Loss: 7.168    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1673824    Buffer Size: 56131      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:29:15,349][train][INFO][train.py>_log] ==> #1343000    Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 10.560   Value Loss: 7.472    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1675191    Buffer Size: 55880      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:32:37,873][train][INFO][train.py>_log] ==> #1344000    Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 10.159   Value Loss: 7.404    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 1676560    Buffer Size: 55699      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:35:54,644][train][INFO][train.py>_log] ==> #1345000    Total Loss: 2.407    [weighted Loss:2.407    Policy Loss: 10.890   Value Loss: 7.625    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1677792    Buffer Size: 55578      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:39:14,208][train][INFO][train.py>_log] ==> #1346000    Total Loss: 4.921    [weighted Loss:4.921    Policy Loss: 10.330   Value Loss: 7.518    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 1679023    Buffer Size: 55455      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:42:33,789][train][INFO][train.py>_log] ==> #1347000    Total Loss: 3.316    [weighted Loss:3.316    Policy Loss: 9.271    Value Loss: 7.796    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 1681285    Buffer Size: 55590      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:45:54,163][train][INFO][train.py>_log] ==> #1348000    Total Loss: 1.223    [weighted Loss:1.223    Policy Loss: 10.678   Value Loss: 7.407    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1683506    Buffer Size: 55575      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:49:15,967][train][INFO][train.py>_log] ==> #1349000    Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 8.429    Value Loss: 7.802    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1684939    Buffer Size: 54954      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:52:36,319][train][INFO][train.py>_log] ==> #1350000    Total Loss: 3.015    [weighted Loss:3.015    Policy Loss: 9.036    Value Loss: 7.496    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 1686457    Buffer Size: 54431      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:55:55,548][train][INFO][train.py>_log] ==> #1351000    Total Loss: 1.579    [weighted Loss:1.579    Policy Loss: 8.226    Value Loss: 7.374    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 1687360    Buffer Size: 53605      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-13 03:59:18,361][train][INFO][train.py>_log] ==> #1352000    Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 8.173    Value Loss: 7.351    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 1688332    Buffer Size: 52827      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:02:38,926][train][INFO][train.py>_log] ==> #1353000    Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 6.851    Value Loss: 7.160    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 1689284    Buffer Size: 52101      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:05:56,785][train][INFO][train.py>_log] ==> #1354000    Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 7.398    Value Loss: 7.378    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 1690243    Buffer Size: 51358      Transition Number: 1500.073k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:09:18,122][train][INFO][train.py>_log] ==> #1355000    Total Loss: 1.637    [weighted Loss:1.637    Policy Loss: 7.189    Value Loss: 7.341    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 1691087    Buffer Size: 50642      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:12:34,675][train][INFO][train.py>_log] ==> #1356000    Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 7.641    Value Loss: 7.279    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 1691940    Buffer Size: 49991      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:15:54,933][train][INFO][train.py>_log] ==> #1357000    Total Loss: 0.824    [weighted Loss:0.824    Policy Loss: 7.516    Value Loss: 7.424    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 1693051    Buffer Size: 49463      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:19:17,989][train][INFO][train.py>_log] ==> #1358000    Total Loss: 1.635    [weighted Loss:1.635    Policy Loss: 7.150    Value Loss: 7.487    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 1694224    Buffer Size: 48969      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:22:36,823][train][INFO][train.py>_log] ==> #1359000    Total Loss: 1.807    [weighted Loss:1.807    Policy Loss: 7.502    Value Loss: 7.386    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 1695240    Buffer Size: 48375      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:25:56,574][train][INFO][train.py>_log] ==> #1360000    Total Loss: 2.759    [weighted Loss:2.759    Policy Loss: 8.088    Value Loss: 7.601    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 1696222    Buffer Size: 47886      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:29:16,863][train][INFO][train.py>_log] ==> #1361000    Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 7.241    Value Loss: 7.558    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 1697306    Buffer Size: 47532      Transition Number: 1500.100k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:32:36,121][train][INFO][train.py>_log] ==> #1362000    Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 7.828    Value Loss: 7.784    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1698353    Buffer Size: 47398      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:35:58,615][train][INFO][train.py>_log] ==> #1363000    Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 7.965    Value Loss: 7.322    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 1699950    Buffer Size: 47629      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:39:20,836][train][INFO][train.py>_log] ==> #1364000    Total Loss: 1.571    [weighted Loss:1.571    Policy Loss: 8.465    Value Loss: 7.674    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 1701483    Buffer Size: 47792      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:42:42,693][train][INFO][train.py>_log] ==> #1365000    Total Loss: 1.070    [weighted Loss:1.070    Policy Loss: 7.726    Value Loss: 7.212    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 1703186    Buffer Size: 48009      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:46:01,551][train][INFO][train.py>_log] ==> #1366000    Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 8.734    Value Loss: 7.322    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 1704824    Buffer Size: 48031      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:49:22,561][train][INFO][train.py>_log] ==> #1367000    Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 8.498    Value Loss: 7.514    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 1706317    Buffer Size: 47793      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:52:44,281][train][INFO][train.py>_log] ==> #1368000    Total Loss: 1.903    [weighted Loss:1.903    Policy Loss: 7.924    Value Loss: 7.655    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 1707788    Buffer Size: 47365      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:56:04,018][train][INFO][train.py>_log] ==> #1369000    Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 9.048    Value Loss: 7.599    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1709381    Buffer Size: 47003      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 04:59:26,254][train][INFO][train.py>_log] ==> #1370000    Total Loss: 0.564    [weighted Loss:0.564    Policy Loss: 7.644    Value Loss: 7.496    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 1711004    Buffer Size: 46753      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:02:47,666][train][INFO][train.py>_log] ==> #1371000    Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 9.252    Value Loss: 7.659    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 1712287    Buffer Size: 46232      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:06:05,747][train][INFO][train.py>_log] ==> #1372000    Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 8.445    Value Loss: 7.658    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1713570    Buffer Size: 45644      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:09:26,279][train][INFO][train.py>_log] ==> #1373000    Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 9.982    Value Loss: 7.642    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 1714964    Buffer Size: 45495      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:12:46,749][train][INFO][train.py>_log] ==> #1374000    Total Loss: 2.352    [weighted Loss:2.352    Policy Loss: 7.846    Value Loss: 7.190    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 1716356    Buffer Size: 45766      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:16:09,470][train][INFO][train.py>_log] ==> #1375000    Total Loss: 1.041    [weighted Loss:1.041    Policy Loss: 8.841    Value Loss: 7.477    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 1718419    Buffer Size: 46526      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:19:35,412][train][INFO][train.py>_log] ==> #1376000    Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 8.755    Value Loss: 7.795    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1720573    Buffer Size: 47186      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:22:55,761][train][INFO][train.py>_log] ==> #1377000    Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 8.701    Value Loss: 7.595    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 1722683    Buffer Size: 47870      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:26:16,040][train][INFO][train.py>_log] ==> #1378000    Total Loss: 2.076    [weighted Loss:2.076    Policy Loss: 8.648    Value Loss: 7.885    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1724854    Buffer Size: 48629      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:29:36,622][train][INFO][train.py>_log] ==> #1379000    Total Loss: 3.008    [weighted Loss:3.008    Policy Loss: 8.341    Value Loss: 7.757    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1726229    Buffer Size: 48751      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:32:56,048][train][INFO][train.py>_log] ==> #1380000    Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 8.064    Value Loss: 7.606    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1727544    Buffer Size: 48832      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:36:15,799][train][INFO][train.py>_log] ==> #1381000    Total Loss: 2.431    [weighted Loss:2.431    Policy Loss: 8.686    Value Loss: 7.731    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 1728570    Buffer Size: 48113      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:39:38,424][train][INFO][train.py>_log] ==> #1382000    Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 8.018    Value Loss: 7.599    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 1729599    Buffer Size: 47017      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:42:54,679][train][INFO][train.py>_log] ==> #1383000    Total Loss: 0.550    [weighted Loss:0.550    Policy Loss: 8.927    Value Loss: 7.532    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 1730594    Buffer Size: 46284      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:46:20,133][train][INFO][train.py>_log] ==> #1384000    Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 8.525    Value Loss: 7.727    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1731663    Buffer Size: 45804      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:49:46,778][train][INFO][train.py>_log] ==> #1385000    Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 8.528    Value Loss: 7.348    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 1733105    Buffer Size: 46027      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:53:04,824][train][INFO][train.py>_log] ==> #1386000    Total Loss: 1.538    [weighted Loss:1.538    Policy Loss: 8.943    Value Loss: 7.430    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 1734523    Buffer Size: 46496      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:56:27,777][train][INFO][train.py>_log] ==> #1387000    Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 8.584    Value Loss: 7.384    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 1736214    Buffer Size: 47137      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-13 05:59:52,030][train][INFO][train.py>_log] ==> #1388000    Total Loss: 2.658    [weighted Loss:2.658    Policy Loss: 9.286    Value Loss: 7.463    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 1737888    Buffer Size: 47778      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:03:15,067][train][INFO][train.py>_log] ==> #1389000    Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 9.163    Value Loss: 7.226    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 1739791    Buffer Size: 48692      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:06:34,321][train][INFO][train.py>_log] ==> #1390000    Total Loss: 0.604    [weighted Loss:0.604    Policy Loss: 10.218   Value Loss: 7.508    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1741568    Buffer Size: 49541      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:09:54,925][train][INFO][train.py>_log] ==> #1391000    Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 10.320   Value Loss: 7.402    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 1743254    Buffer Size: 50063      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:13:12,821][train][INFO][train.py>_log] ==> #1392000    Total Loss: 0.817    [weighted Loss:0.817    Policy Loss: 8.924    Value Loss: 7.345    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1744858    Buffer Size: 50494      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:16:29,099][train][INFO][train.py>_log] ==> #1393000    Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 10.663   Value Loss: 7.603    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1745935    Buffer Size: 50621      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:19:51,051][train][INFO][train.py>_log] ==> #1394000    Total Loss: 0.754    [weighted Loss:0.754    Policy Loss: 9.956    Value Loss: 7.621    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 1747091    Buffer Size: 50751      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:23:10,146][train][INFO][train.py>_log] ==> #1395000    Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 11.453   Value Loss: 7.231    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1748304    Buffer Size: 50882      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:26:29,635][train][INFO][train.py>_log] ==> #1396000    Total Loss: 1.126    [weighted Loss:1.126    Policy Loss: 10.017   Value Loss: 7.362    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 1749550    Buffer Size: 50963      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:29:52,727][train][INFO][train.py>_log] ==> #1397000    Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 10.124   Value Loss: 7.645    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1750694    Buffer Size: 50681      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:33:13,131][train][INFO][train.py>_log] ==> #1398000    Total Loss: 1.643    [weighted Loss:1.643    Policy Loss: 11.193   Value Loss: 7.713    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 1751893    Buffer Size: 50327      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:36:33,949][train][INFO][train.py>_log] ==> #1399000    Total Loss: 2.240    [weighted Loss:2.240    Policy Loss: 9.993    Value Loss: 7.289    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1753145    Buffer Size: 50065      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:39:56,360][train][INFO][train.py>_log] ==> #1400000    Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 10.180   Value Loss: 7.214    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 1754474    Buffer Size: 49688      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:43:19,851][train][INFO][train.py>_log] ==> #1401000    Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 10.924   Value Loss: 7.649    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 1756424    Buffer Size: 50081      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:46:42,370][train][INFO][train.py>_log] ==> #1402000    Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 10.402   Value Loss: 7.645    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 1758285    Buffer Size: 50445      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:50:05,719][train][INFO][train.py>_log] ==> #1403000    Total Loss: 1.659    [weighted Loss:1.659    Policy Loss: 10.208   Value Loss: 7.559    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 1759788    Buffer Size: 50399      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:53:29,322][train][INFO][train.py>_log] ==> #1404000    Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 10.756   Value Loss: 7.937    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 1761319    Buffer Size: 50355      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-13 06:56:47,956][train][INFO][train.py>_log] ==> #1405000    Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 10.265   Value Loss: 7.596    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1762431    Buffer Size: 50199      Transition Number: 1500.165k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:00:08,719][train][INFO][train.py>_log] ==> #1406000    Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 9.001    Value Loss: 7.301    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 1763540    Buffer Size: 50080      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:03:31,333][train][INFO][train.py>_log] ==> #1407000    Total Loss: 2.714    [weighted Loss:2.714    Policy Loss: 9.824    Value Loss: 7.411    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 1764876    Buffer Size: 49994      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:06:51,604][train][INFO][train.py>_log] ==> #1408000    Total Loss: 3.130    [weighted Loss:3.130    Policy Loss: 9.835    Value Loss: 7.684    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1766258    Buffer Size: 49965      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:10:17,748][train][INFO][train.py>_log] ==> #1409000    Total Loss: 1.180    [weighted Loss:1.180    Policy Loss: 8.646    Value Loss: 7.637    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1767952    Buffer Size: 49629      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:13:41,367][train][INFO][train.py>_log] ==> #1410000    Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 10.640   Value Loss: 7.703    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1769578    Buffer Size: 49295      Transition Number: 1500.113k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:17:02,889][train][INFO][train.py>_log] ==> #1411000    Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 9.335    Value Loss: 8.039    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1771122    Buffer Size: 48760      Transition Number: 1500.070k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:20:26,591][train][INFO][train.py>_log] ==> #1412000    Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 9.300    Value Loss: 7.471    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 1772680    Buffer Size: 48209      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:23:46,087][train][INFO][train.py>_log] ==> #1413000    Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 10.666   Value Loss: 7.702    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 1774044    Buffer Size: 48076      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:27:08,309][train][INFO][train.py>_log] ==> #1414000    Total Loss: 4.493    [weighted Loss:4.493    Policy Loss: 9.395    Value Loss: 7.651    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 1775464    Buffer Size: 48119      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:30:33,253][train][INFO][train.py>_log] ==> #1415000    Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 9.592    Value Loss: 7.801    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1776899    Buffer Size: 48365      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:33:55,243][train][INFO][train.py>_log] ==> #1416000    Total Loss: 1.669    [weighted Loss:1.669    Policy Loss: 9.072    Value Loss: 7.420    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 1778228    Buffer Size: 48664      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:37:16,275][train][INFO][train.py>_log] ==> #1417000    Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 9.330    Value Loss: 8.123    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 1779544    Buffer Size: 48942      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:40:40,160][train][INFO][train.py>_log] ==> #1418000    Total Loss: 1.843    [weighted Loss:1.843    Policy Loss: 8.638    Value Loss: 7.335    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 1780883    Buffer Size: 49229      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:44:01,522][train][INFO][train.py>_log] ==> #1419000    Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 9.172    Value Loss: 7.535    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 1782191    Buffer Size: 49116      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:47:23,410][train][INFO][train.py>_log] ==> #1420000    Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 9.945    Value Loss: 7.507    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 1783527    Buffer Size: 48958      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:50:47,918][train][INFO][train.py>_log] ==> #1421000    Total Loss: 4.026    [weighted Loss:4.026    Policy Loss: 8.976    Value Loss: 7.174    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 1785012    Buffer Size: 48876      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:54:09,353][train][INFO][train.py>_log] ==> #1422000    Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 9.219    Value Loss: 7.598    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 1786570    Buffer Size: 48782      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-13 07:57:33,299][train][INFO][train.py>_log] ==> #1423000    Total Loss: 2.632    [weighted Loss:2.632    Policy Loss: 9.831    Value Loss: 7.730    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 1788275    Buffer Size: 48669      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:00:53,109][train][INFO][train.py>_log] ==> #1424000    Total Loss: 1.395    [weighted Loss:1.395    Policy Loss: 10.150   Value Loss: 7.630    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1789939    Buffer Size: 48499      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:04:11,810][train][INFO][train.py>_log] ==> #1425000    Total Loss: 2.924    [weighted Loss:2.924    Policy Loss: 9.646    Value Loss: 7.124    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 1791802    Buffer Size: 48665      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:07:33,835][train][INFO][train.py>_log] ==> #1426000    Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 10.408   Value Loss: 7.760    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 1793706    Buffer Size: 48940      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:10:54,968][train][INFO][train.py>_log] ==> #1427000    Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 9.747    Value Loss: 7.462    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1795495    Buffer Size: 49490      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:14:13,249][train][INFO][train.py>_log] ==> #1428000    Total Loss: 1.919    [weighted Loss:1.919    Policy Loss: 9.276    Value Loss: 7.510    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 1797301    Buffer Size: 50123      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:17:31,220][train][INFO][train.py>_log] ==> #1429000    Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 8.798    Value Loss: 7.617    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1798758    Buffer Size: 50364      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:20:52,718][train][INFO][train.py>_log] ==> #1430000    Total Loss: 2.318    [weighted Loss:2.318    Policy Loss: 9.180    Value Loss: 7.658    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 1800318    Buffer Size: 50672      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:24:11,949][train][INFO][train.py>_log] ==> #1431000    Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 9.366    Value Loss: 7.480    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 1801764    Buffer Size: 50920      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:27:31,781][train][INFO][train.py>_log] ==> #1432000    Total Loss: 2.090    [weighted Loss:2.090    Policy Loss: 9.636    Value Loss: 7.510    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 1803273    Buffer Size: 51225      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:30:53,282][train][INFO][train.py>_log] ==> #1433000    Total Loss: 1.767    [weighted Loss:1.767    Policy Loss: 8.750    Value Loss: 7.485    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 1804949    Buffer Size: 51586      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:34:12,373][train][INFO][train.py>_log] ==> #1434000    Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 8.944    Value Loss: 7.416    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1806655    Buffer Size: 51852      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:37:32,530][train][INFO][train.py>_log] ==> #1435000    Total Loss: 3.794    [weighted Loss:3.794    Policy Loss: 9.522    Value Loss: 7.534    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 1808078    Buffer Size: 51588      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:40:57,100][train][INFO][train.py>_log] ==> #1436000    Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 8.723    Value Loss: 7.401    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 1809584    Buffer Size: 51207      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:44:17,155][train][INFO][train.py>_log] ==> #1437000    Total Loss: 1.040    [weighted Loss:1.040    Policy Loss: 10.357   Value Loss: 7.460    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 1810548    Buffer Size: 50780      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:47:38,975][train][INFO][train.py>_log] ==> #1438000    Total Loss: 1.937    [weighted Loss:1.937    Policy Loss: 8.144    Value Loss: 7.534    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 1811519    Buffer Size: 50221      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:51:03,339][train][INFO][train.py>_log] ==> #1439000    Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 9.046    Value Loss: 7.439    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1812731    Buffer Size: 50255      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:54:23,315][train][INFO][train.py>_log] ==> #1440000    Total Loss: 1.652    [weighted Loss:1.652    Policy Loss: 8.555    Value Loss: 7.227    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 1813887    Buffer Size: 50324      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-13 08:57:47,098][train][INFO][train.py>_log] ==> #1441000    Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 8.992    Value Loss: 7.488    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1815189    Buffer Size: 50269      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:01:08,263][train][INFO][train.py>_log] ==> #1442000    Total Loss: 3.317    [weighted Loss:3.317    Policy Loss: 8.732    Value Loss: 7.763    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1816564    Buffer Size: 50193      Transition Number: 1500.121k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:04:28,626][train][INFO][train.py>_log] ==> #1443000    Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 9.282    Value Loss: 7.639    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1817890    Buffer Size: 49945      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:07:58,345][train][INFO][train.py>_log] ==> #1444000    Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 7.969    Value Loss: 7.462    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1819343    Buffer Size: 49695      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:11:21,010][train][INFO][train.py>_log] ==> #1445000    Total Loss: 3.174    [weighted Loss:3.174    Policy Loss: 7.751    Value Loss: 7.876    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1820586    Buffer Size: 49467      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:14:42,367][train][INFO][train.py>_log] ==> #1446000    Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 7.866    Value Loss: 7.315    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 1821854    Buffer Size: 49171      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:18:05,566][train][INFO][train.py>_log] ==> #1447000    Total Loss: 1.171    [weighted Loss:1.171    Policy Loss: 9.278    Value Loss: 7.743    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 1822917    Buffer Size: 48848      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:21:26,908][train][INFO][train.py>_log] ==> #1448000    Total Loss: 3.007    [weighted Loss:3.007    Policy Loss: 8.303    Value Loss: 7.532    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1823994    Buffer Size: 48532      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:24:52,721][train][INFO][train.py>_log] ==> #1449000    Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 9.546    Value Loss: 7.679    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 1825412    Buffer Size: 48552      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:28:18,127][train][INFO][train.py>_log] ==> #1450000    Total Loss: 1.515    [weighted Loss:1.515    Policy Loss: 8.565    Value Loss: 7.652    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1826823    Buffer Size: 48588      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:31:42,378][train][INFO][train.py>_log] ==> #1451000    Total Loss: 2.240    [weighted Loss:2.240    Policy Loss: 10.158   Value Loss: 7.591    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 1829098    Buffer Size: 49384      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:35:02,963][train][INFO][train.py>_log] ==> #1452000    Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 9.279    Value Loss: 7.631    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 1831335    Buffer Size: 50260      Transition Number: 1500.084k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:38:24,613][train][INFO][train.py>_log] ==> #1453000    Total Loss: 3.610    [weighted Loss:3.610    Policy Loss: 9.566    Value Loss: 7.439    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 1833213    Buffer Size: 50858      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:41:46,671][train][INFO][train.py>_log] ==> #1454000    Total Loss: 1.331    [weighted Loss:1.331    Policy Loss: 8.604    Value Loss: 7.406    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1835200    Buffer Size: 51462      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:45:05,275][train][INFO][train.py>_log] ==> #1455000    Total Loss: 1.844    [weighted Loss:1.844    Policy Loss: 9.498    Value Loss: 7.816    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 1836680    Buffer Size: 51466      Transition Number: 1500.119k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:48:26,580][train][INFO][train.py>_log] ==> #1456000    Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 9.186    Value Loss: 7.311    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 1838151    Buffer Size: 51323      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:51:46,621][train][INFO][train.py>_log] ==> #1457000    Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 9.935    Value Loss: 7.142    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 1839497    Buffer Size: 51039      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:55:04,317][train][INFO][train.py>_log] ==> #1458000    Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 10.089   Value Loss: 7.397    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 1840847    Buffer Size: 50797      Transition Number: 1500.086k Batch Size: 256        Lr: 0.10000 
[2022-01-13 09:58:27,353][train][INFO][train.py>_log] ==> #1459000    Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 10.212   Value Loss: 7.212    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1842664    Buffer Size: 50659      Transition Number: 1500.071k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:01:52,722][train][INFO][train.py>_log] ==> #1460000    Total Loss: 1.376    [weighted Loss:1.376    Policy Loss: 10.884   Value Loss: 7.543    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 1844554    Buffer Size: 50529      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:05:12,771][train][INFO][train.py>_log] ==> #1461000    Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 10.115   Value Loss: 7.438    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1846113    Buffer Size: 50358      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:08:34,108][train][INFO][train.py>_log] ==> #1462000    Total Loss: 1.131    [weighted Loss:1.131    Policy Loss: 11.031   Value Loss: 7.341    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 1847686    Buffer Size: 50135      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:11:55,932][train][INFO][train.py>_log] ==> #1463000    Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 10.685   Value Loss: 7.547    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1849105    Buffer Size: 50052      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:15:17,390][train][INFO][train.py>_log] ==> #1464000    Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 8.850    Value Loss: 7.440    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 1850502    Buffer Size: 49940      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:18:38,763][train][INFO][train.py>_log] ==> #1465000    Total Loss: 3.484    [weighted Loss:3.484    Policy Loss: 9.954    Value Loss: 7.522    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1851729    Buffer Size: 49670      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:22:02,220][train][INFO][train.py>_log] ==> #1466000    Total Loss: 1.252    [weighted Loss:1.252    Policy Loss: 9.724    Value Loss: 7.727    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 1852979    Buffer Size: 49403      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:25:21,902][train][INFO][train.py>_log] ==> #1467000    Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 9.817    Value Loss: 7.421    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1854145    Buffer Size: 48925      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:28:47,216][train][INFO][train.py>_log] ==> #1468000    Total Loss: 2.619    [weighted Loss:2.619    Policy Loss: 9.651    Value Loss: 7.379    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 1855337    Buffer Size: 48387      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:32:10,393][train][INFO][train.py>_log] ==> #1469000    Total Loss: 2.243    [weighted Loss:2.243    Policy Loss: 10.459   Value Loss: 7.393    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 1856801    Buffer Size: 48377      Transition Number: 1500.072k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:35:34,927][train][INFO][train.py>_log] ==> #1470000    Total Loss: 2.815    [weighted Loss:2.815    Policy Loss: 9.641    Value Loss: 7.439    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 1858313    Buffer Size: 48451      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:38:55,800][train][INFO][train.py>_log] ==> #1471000    Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 10.442   Value Loss: 7.450    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1860081    Buffer Size: 49174      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:42:13,416][train][INFO][train.py>_log] ==> #1472000    Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 10.494   Value Loss: 7.530    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 1861789    Buffer Size: 49851      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:45:33,610][train][INFO][train.py>_log] ==> #1473000    Total Loss: 1.333    [weighted Loss:1.333    Policy Loss: 9.628    Value Loss: 7.656    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 1863557    Buffer Size: 50377      Transition Number: 1500.086k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:48:56,595][train][INFO][train.py>_log] ==> #1474000    Total Loss: 3.467    [weighted Loss:3.467    Policy Loss: 10.307   Value Loss: 7.532    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1865330    Buffer Size: 50889      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:52:15,412][train][INFO][train.py>_log] ==> #1475000    Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 10.793   Value Loss: 7.653    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1866725    Buffer Size: 51009      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:55:34,174][train][INFO][train.py>_log] ==> #1476000    Total Loss: 0.771    [weighted Loss:0.771    Policy Loss: 11.925   Value Loss: 7.550    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 1868135    Buffer Size: 51096      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-13 10:58:56,644][train][INFO][train.py>_log] ==> #1477000    Total Loss: 2.110    [weighted Loss:2.110    Policy Loss: 10.459   Value Loss: 7.534    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1870124    Buffer Size: 51659      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:02:15,307][train][INFO][train.py>_log] ==> #1478000    Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 11.332   Value Loss: 7.385    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 1872135    Buffer Size: 52259      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:05:35,467][train][INFO][train.py>_log] ==> #1479000    Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 10.364   Value Loss: 7.298    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 1873769    Buffer Size: 52636      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:08:55,614][train][INFO][train.py>_log] ==> #1480000    Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 10.171   Value Loss: 7.105    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 1875318    Buffer Size: 52994      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:12:11,597][train][INFO][train.py>_log] ==> #1481000    Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 10.979   Value Loss: 7.660    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1876465    Buffer Size: 53134      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:15:27,806][train][INFO][train.py>_log] ==> #1482000    Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 11.208   Value Loss: 7.209    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 1877628    Buffer Size: 53179      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:18:50,788][train][INFO][train.py>_log] ==> #1483000    Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 10.743   Value Loss: 7.485    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1879911    Buffer Size: 53919      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:22:09,263][train][INFO][train.py>_log] ==> #1484000    Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 10.723   Value Loss: 7.475    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 1882200    Buffer Size: 54464      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:25:29,989][train][INFO][train.py>_log] ==> #1485000    Total Loss: 2.789    [weighted Loss:2.789    Policy Loss: 11.352   Value Loss: 7.677    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1885477    Buffer Size: 55388      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:28:52,079][train][INFO][train.py>_log] ==> #1486000    Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 10.794   Value Loss: 7.469    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 1888834    Buffer Size: 56566      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:32:06,993][train][INFO][train.py>_log] ==> #1487000    Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 9.901    Value Loss: 7.429    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1890414    Buffer Size: 56425      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:35:25,908][train][INFO][train.py>_log] ==> #1488000    Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 10.362   Value Loss: 7.899    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 1892014    Buffer Size: 56260      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:38:48,264][train][INFO][train.py>_log] ==> #1489000    Total Loss: 4.037    [weighted Loss:4.037    Policy Loss: 10.880   Value Loss: 7.583    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 1893867    Buffer Size: 56641      Transition Number: 1500.148k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:42:04,497][train][INFO][train.py>_log] ==> #1490000    Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 10.388   Value Loss: 7.374    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 1895798    Buffer Size: 57043      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:45:24,234][train][INFO][train.py>_log] ==> #1491000    Total Loss: 1.097    [weighted Loss:1.097    Policy Loss: 10.543   Value Loss: 7.288    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 1897230    Buffer Size: 57144      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:48:46,710][train][INFO][train.py>_log] ==> #1492000    Total Loss: 2.137    [weighted Loss:2.137    Policy Loss: 9.418    Value Loss: 7.410    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1898669    Buffer Size: 57108      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:52:06,030][train][INFO][train.py>_log] ==> #1493000    Total Loss: 2.494    [weighted Loss:2.494    Policy Loss: 9.864    Value Loss: 7.412    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 1899789    Buffer Size: 56571      Transition Number: 1500.097k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:55:27,262][train][INFO][train.py>_log] ==> #1494000    Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 9.245    Value Loss: 7.246    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1900943    Buffer Size: 55976      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-13 11:58:45,616][train][INFO][train.py>_log] ==> #1495000    Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 11.236   Value Loss: 7.592    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1902266    Buffer Size: 55755      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:02:02,619][train][INFO][train.py>_log] ==> #1496000    Total Loss: 3.728    [weighted Loss:3.728    Policy Loss: 9.627    Value Loss: 7.431    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1903561    Buffer Size: 55536      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:05:20,978][train][INFO][train.py>_log] ==> #1497000    Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 9.471    Value Loss: 7.382    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1905700    Buffer Size: 56236      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:08:39,275][train][INFO][train.py>_log] ==> #1498000    Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 9.182    Value Loss: 7.337    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 1907784    Buffer Size: 56977      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:12:00,036][train][INFO][train.py>_log] ==> #1499000    Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 9.570    Value Loss: 7.514    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1910798    Buffer Size: 58671      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:15:19,547][train][INFO][train.py>_log] ==> #1500000    Total Loss: 3.015    [weighted Loss:3.015    Policy Loss: 9.680    Value Loss: 7.690    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1913802    Buffer Size: 60394      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:18:36,861][train][INFO][train.py>_log] ==> #1501000    Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 10.755   Value Loss: 7.654    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 1915098    Buffer Size: 60608      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:21:58,103][train][INFO][train.py>_log] ==> #1502000    Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 10.282   Value Loss: 7.341    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1916441    Buffer Size: 60712      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:25:15,100][train][INFO][train.py>_log] ==> #1503000    Total Loss: 1.278    [weighted Loss:1.278    Policy Loss: 9.643    Value Loss: 7.499    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1918823    Buffer Size: 61520      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:28:32,618][train][INFO][train.py>_log] ==> #1504000    Total Loss: 1.376    [weighted Loss:1.376    Policy Loss: 10.267   Value Loss: 7.433    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 1921148    Buffer Size: 62237      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:31:48,242][train][INFO][train.py>_log] ==> #1505000    Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 9.831    Value Loss: 7.340    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1922625    Buffer Size: 62145      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:35:02,247][train][INFO][train.py>_log] ==> #1506000    Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 9.502    Value Loss: 7.219    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 1924089    Buffer Size: 61913      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:38:23,054][train][INFO][train.py>_log] ==> #1507000    Total Loss: 3.908    [weighted Loss:3.908    Policy Loss: 10.645   Value Loss: 7.866    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1925733    Buffer Size: 61814      Transition Number: 1500.100k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:41:41,383][train][INFO][train.py>_log] ==> #1508000    Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 10.198   Value Loss: 7.592    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1927375    Buffer Size: 61739      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:44:55,381][train][INFO][train.py>_log] ==> #1509000    Total Loss: 2.709    [weighted Loss:2.709    Policy Loss: 11.017   Value Loss: 7.508    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 1928945    Buffer Size: 61967      Transition Number: 1500.094k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:48:15,854][train][INFO][train.py>_log] ==> #1510000    Total Loss: 0.784    [weighted Loss:0.784    Policy Loss: 9.992    Value Loss: 7.600    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 1930637    Buffer Size: 62139      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:51:34,195][train][INFO][train.py>_log] ==> #1511000    Total Loss: 4.059    [weighted Loss:4.059    Policy Loss: 10.644   Value Loss: 7.134    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1931812    Buffer Size: 61501      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:54:52,953][train][INFO][train.py>_log] ==> #1512000    Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 9.646    Value Loss: 7.485    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1932994    Buffer Size: 60771      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-13 12:58:13,584][train][INFO][train.py>_log] ==> #1513000    Total Loss: 1.089    [weighted Loss:1.089    Policy Loss: 9.090    Value Loss: 7.364    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 1934257    Buffer Size: 60441      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:01:31,406][train][INFO][train.py>_log] ==> #1514000    Total Loss: 2.912    [weighted Loss:2.912    Policy Loss: 10.379   Value Loss: 7.846    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1935489    Buffer Size: 60189      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:04:51,436][train][INFO][train.py>_log] ==> #1515000    Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 10.248   Value Loss: 7.668    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 1936707    Buffer Size: 60175      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:08:12,239][train][INFO][train.py>_log] ==> #1516000    Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 9.991    Value Loss: 7.541    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 1937972    Buffer Size: 60204      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:11:31,342][train][INFO][train.py>_log] ==> #1517000    Total Loss: 2.582    [weighted Loss:2.582    Policy Loss: 11.182   Value Loss: 7.893    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 1939507    Buffer Size: 59606      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:14:52,663][train][INFO][train.py>_log] ==> #1518000    Total Loss: 1.670    [weighted Loss:1.670    Policy Loss: 10.414   Value Loss: 7.351    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 1941085    Buffer Size: 58972      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:18:13,353][train][INFO][train.py>_log] ==> #1519000    Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 11.225   Value Loss: 7.583    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 1942388    Buffer Size: 57325      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:21:31,997][train][INFO][train.py>_log] ==> #1520000    Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 8.776    Value Loss: 7.112    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 1943642    Buffer Size: 55536      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:24:50,070][train][INFO][train.py>_log] ==> #1521000    Total Loss: 3.872    [weighted Loss:3.872    Policy Loss: 11.285   Value Loss: 7.484    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 1944747    Buffer Size: 54633      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:28:07,799][train][INFO][train.py>_log] ==> #1522000    Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 10.087   Value Loss: 7.490    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1945792    Buffer Size: 54151      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:31:24,827][train][INFO][train.py>_log] ==> #1523000    Total Loss: 1.105    [weighted Loss:1.105    Policy Loss: 11.169   Value Loss: 7.529    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1946968    Buffer Size: 53695      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:34:44,621][train][INFO][train.py>_log] ==> #1524000    Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 9.780    Value Loss: 7.501    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1948181    Buffer Size: 53077      Transition Number: 1500.139k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:38:04,405][train][INFO][train.py>_log] ==> #1525000    Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 10.853   Value Loss: 7.743    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1949473    Buffer Size: 52730      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:41:23,799][train][INFO][train.py>_log] ==> #1526000    Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 10.612   Value Loss: 7.906    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1950777    Buffer Size: 52614      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:44:43,416][train][INFO][train.py>_log] ==> #1527000    Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 11.264   Value Loss: 7.587    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1952099    Buffer Size: 52698      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:48:05,467][train][INFO][train.py>_log] ==> #1528000    Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 10.383   Value Loss: 7.557    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 1953476    Buffer Size: 52909      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:51:33,385][train][INFO][train.py>_log] ==> #1529000    Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 10.928   Value Loss: 7.388    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 1957605    Buffer Size: 55547      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:54:54,823][train][INFO][train.py>_log] ==> #1530000    Total Loss: 3.142    [weighted Loss:3.142    Policy Loss: 9.904    Value Loss: 7.856    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 1961701    Buffer Size: 58249      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-13 13:58:18,246][train][INFO][train.py>_log] ==> #1531000    Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 11.274   Value Loss: 7.138    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 1964264    Buffer Size: 58819      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:01:36,662][train][INFO][train.py>_log] ==> #1532000    Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 10.819   Value Loss: 7.458    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 1966717    Buffer Size: 59141      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:04:57,055][train][INFO][train.py>_log] ==> #1533000    Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 10.853   Value Loss: 7.170    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1968446    Buffer Size: 58062      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:08:18,205][train][INFO][train.py>_log] ==> #1534000    Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 10.752   Value Loss: 7.689    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 1970167    Buffer Size: 56850      Transition Number: 1500.052k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:11:38,487][train][INFO][train.py>_log] ==> #1535000    Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 10.670   Value Loss: 7.599    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1972182    Buffer Size: 57167      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:14:56,517][train][INFO][train.py>_log] ==> #1536000    Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 10.479   Value Loss: 7.662    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1974127    Buffer Size: 57786      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:18:17,049][train][INFO][train.py>_log] ==> #1537000    Total Loss: 4.011    [weighted Loss:4.011    Policy Loss: 10.451   Value Loss: 7.252    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 1976140    Buffer Size: 57633      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:21:37,362][train][INFO][train.py>_log] ==> #1538000    Total Loss: 1.838    [weighted Loss:1.838    Policy Loss: 10.483   Value Loss: 7.410    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1978151    Buffer Size: 57308      Transition Number: 1500.043k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:24:56,005][train][INFO][train.py>_log] ==> #1539000    Total Loss: 1.006    [weighted Loss:1.006    Policy Loss: 9.971    Value Loss: 7.326    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1979997    Buffer Size: 57492      Transition Number: 1500.043k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:28:15,436][train][INFO][train.py>_log] ==> #1540000    Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 10.695   Value Loss: 7.682    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1981851    Buffer Size: 57828      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:31:36,869][train][INFO][train.py>_log] ==> #1541000    Total Loss: 2.733    [weighted Loss:2.733    Policy Loss: 9.870    Value Loss: 7.642    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1984261    Buffer Size: 58589      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:34:55,505][train][INFO][train.py>_log] ==> #1542000    Total Loss: 3.856    [weighted Loss:3.856    Policy Loss: 10.803   Value Loss: 7.351    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1986813    Buffer Size: 59471      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:38:16,179][train][INFO][train.py>_log] ==> #1543000    Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 10.268   Value Loss: 7.545    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1988667    Buffer Size: 59688      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:41:34,263][train][INFO][train.py>_log] ==> #1544000    Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 11.243   Value Loss: 7.660    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 1990595    Buffer Size: 59946      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:44:53,327][train][INFO][train.py>_log] ==> #1545000    Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 10.682   Value Loss: 7.678    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1991943    Buffer Size: 60101      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:48:12,350][train][INFO][train.py>_log] ==> #1546000    Total Loss: 2.507    [weighted Loss:2.507    Policy Loss: 10.065   Value Loss: 7.323    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 1993309    Buffer Size: 60256      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:51:30,245][train][INFO][train.py>_log] ==> #1547000    Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 10.879   Value Loss: 7.729    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1994962    Buffer Size: 60612      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:54:47,606][train][INFO][train.py>_log] ==> #1548000    Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 10.919   Value Loss: 7.399    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 1996550    Buffer Size: 60938      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-13 14:58:02,913][train][INFO][train.py>_log] ==> #1549000    Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 10.303   Value Loss: 7.555    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1998453    Buffer Size: 61632      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:01:18,745][train][INFO][train.py>_log] ==> #1550000    Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 10.177   Value Loss: 7.622    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2000313    Buffer Size: 62252      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:04:32,369][train][INFO][train.py>_log] ==> #1551000    Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 10.079   Value Loss: 7.616    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 2002333    Buffer Size: 62690      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:07:54,587][train][INFO][train.py>_log] ==> #1552000    Total Loss: 3.725    [weighted Loss:3.725    Policy Loss: 9.771    Value Loss: 7.801    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 2004391    Buffer Size: 63175      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:11:07,296][train][INFO][train.py>_log] ==> #1553000    Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 9.494    Value Loss: 7.892    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 2005840    Buffer Size: 63383      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:14:22,375][train][INFO][train.py>_log] ==> #1554000    Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 9.635    Value Loss: 7.561    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 2007303    Buffer Size: 63621      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:17:38,739][train][INFO][train.py>_log] ==> #1555000    Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 9.686    Value Loss: 7.435    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 2008655    Buffer Size: 63828      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:20:56,711][train][INFO][train.py>_log] ==> #1556000    Total Loss: 1.938    [weighted Loss:1.938    Policy Loss: 9.989    Value Loss: 7.393    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 2009974    Buffer Size: 64054      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:24:13,523][train][INFO][train.py>_log] ==> #1557000    Total Loss: 3.501    [weighted Loss:3.501    Policy Loss: 10.504   Value Loss: 7.226    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 2011740    Buffer Size: 64578      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:27:32,350][train][INFO][train.py>_log] ==> #1558000    Total Loss: 4.581    [weighted Loss:4.581    Policy Loss: 9.867    Value Loss: 7.511    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 2013533    Buffer Size: 65122      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:30:50,499][train][INFO][train.py>_log] ==> #1559000    Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 9.433    Value Loss: 7.476    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 2015429    Buffer Size: 65675      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:34:03,933][train][INFO][train.py>_log] ==> #1560000    Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 11.030   Value Loss: 7.489    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 2017195    Buffer Size: 66135      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:37:20,970][train][INFO][train.py>_log] ==> #1561000    Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 10.552   Value Loss: 7.611    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2018967    Buffer Size: 66580      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:40:39,112][train][INFO][train.py>_log] ==> #1562000    Total Loss: 2.359    [weighted Loss:2.359    Policy Loss: 10.326   Value Loss: 7.316    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 2020726    Buffer Size: 66693      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:44:00,013][train][INFO][train.py>_log] ==> #1563000    Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 10.264   Value Loss: 7.087    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 2022916    Buffer Size: 64805      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:47:18,895][train][INFO][train.py>_log] ==> #1564000    Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 10.958   Value Loss: 7.646    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 2024989    Buffer Size: 63092      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:50:40,664][train][INFO][train.py>_log] ==> #1565000    Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 11.257   Value Loss: 7.537    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 2027178    Buffer Size: 62689      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:53:56,336][train][INFO][train.py>_log] ==> #1566000    Total Loss: 3.503    [weighted Loss:3.503    Policy Loss: 11.502   Value Loss: 7.428    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 2029275    Buffer Size: 62436      Transition Number: 1500.043k Batch Size: 256        Lr: 0.10000 
[2022-01-13 15:57:14,490][train][INFO][train.py>_log] ==> #1567000    Total Loss: 3.534    [weighted Loss:3.534    Policy Loss: 11.397   Value Loss: 7.452    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 2031090    Buffer Size: 62557      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:00:35,476][train][INFO][train.py>_log] ==> #1568000    Total Loss: 3.199    [weighted Loss:3.199    Policy Loss: 11.519   Value Loss: 7.505    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 2032929    Buffer Size: 62663      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:03:48,903][train][INFO][train.py>_log] ==> #1569000    Total Loss: 4.650    [weighted Loss:4.650    Policy Loss: 11.609   Value Loss: 7.490    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 2034502    Buffer Size: 62329      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:07:08,926][train][INFO][train.py>_log] ==> #1570000    Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 12.063   Value Loss: 7.561    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 2036110    Buffer Size: 61995      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:10:25,537][train][INFO][train.py>_log] ==> #1571000    Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 12.535   Value Loss: 7.229    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 2037756    Buffer Size: 61695      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:13:44,798][train][INFO][train.py>_log] ==> #1572000    Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 11.863   Value Loss: 7.636    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 2039518    Buffer Size: 61479      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:17:08,578][train][INFO][train.py>_log] ==> #1573000    Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 11.907   Value Loss: 7.200    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 2041322    Buffer Size: 61403      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:20:26,212][train][INFO][train.py>_log] ==> #1574000    Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 11.836   Value Loss: 7.538    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 2043179    Buffer Size: 61419      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:23:44,430][train][INFO][train.py>_log] ==> #1575000    Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 11.973   Value Loss: 7.744    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 2044871    Buffer Size: 60821      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:27:00,030][train][INFO][train.py>_log] ==> #1576000    Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 11.358   Value Loss: 7.309    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 2046545    Buffer Size: 60076      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:30:18,050][train][INFO][train.py>_log] ==> #1577000    Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 11.761   Value Loss: 7.452    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 2047770    Buffer Size: 59465      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:33:36,119][train][INFO][train.py>_log] ==> #1578000    Total Loss: 4.168    [weighted Loss:4.168    Policy Loss: 10.464   Value Loss: 7.206    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 2049027    Buffer Size: 58817      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:36:53,808][train][INFO][train.py>_log] ==> #1579000    Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 11.110   Value Loss: 7.486    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 2050229    Buffer Size: 58565      Transition Number: 1500.169k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:40:13,025][train][INFO][train.py>_log] ==> #1580000    Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 10.970   Value Loss: 7.078    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 2051431    Buffer Size: 58413      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:43:31,155][train][INFO][train.py>_log] ==> #1581000    Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 10.796   Value Loss: 7.264    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 2052540    Buffer Size: 58006      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:46:49,902][train][INFO][train.py>_log] ==> #1582000    Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 10.767   Value Loss: 7.589    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2053662    Buffer Size: 57551      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:50:12,132][train][INFO][train.py>_log] ==> #1583000    Total Loss: 3.192    [weighted Loss:3.192    Policy Loss: 12.306   Value Loss: 7.433    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2054484    Buffer Size: 56711      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:53:26,621][train][INFO][train.py>_log] ==> #1584000    Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 10.774   Value Loss: 7.460    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 2055314    Buffer Size: 55673      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-13 16:56:49,308][train][INFO][train.py>_log] ==> #1585000    Total Loss: 3.615    [weighted Loss:3.615    Policy Loss: 11.426   Value Loss: 7.724    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 2056560    Buffer Size: 54994      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:00:05,227][train][INFO][train.py>_log] ==> #1586000    Total Loss: 3.747    [weighted Loss:3.747    Policy Loss: 10.392   Value Loss: 7.600    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 2057835    Buffer Size: 54365      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:03:24,331][train][INFO][train.py>_log] ==> #1587000    Total Loss: 1.196    [weighted Loss:1.196    Policy Loss: 10.888   Value Loss: 7.385    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 2059550    Buffer Size: 54226      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:06:43,489][train][INFO][train.py>_log] ==> #1588000    Total Loss: 2.958    [weighted Loss:2.958    Policy Loss: 12.577   Value Loss: 7.753    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 2061250    Buffer Size: 54409      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:10:04,281][train][INFO][train.py>_log] ==> #1589000    Total Loss: 1.596    [weighted Loss:1.596    Policy Loss: 10.791   Value Loss: 7.808    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 2062899    Buffer Size: 54600      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:13:24,297][train][INFO][train.py>_log] ==> #1590000    Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 12.312   Value Loss: 7.558    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 2064553    Buffer Size: 54903      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:16:43,250][train][INFO][train.py>_log] ==> #1591000    Total Loss: 1.479    [weighted Loss:1.479    Policy Loss: 11.043   Value Loss: 7.471    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 2066845    Buffer Size: 55445      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:20:04,356][train][INFO][train.py>_log] ==> #1592000    Total Loss: 1.182    [weighted Loss:1.182    Policy Loss: 12.603   Value Loss: 7.791    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2069159    Buffer Size: 55865      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:23:22,018][train][INFO][train.py>_log] ==> #1593000    Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 11.317   Value Loss: 8.006    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 2071248    Buffer Size: 56159      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:26:42,774][train][INFO][train.py>_log] ==> #1594000    Total Loss: 2.869    [weighted Loss:2.869    Policy Loss: 11.698   Value Loss: 7.702    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2073432    Buffer Size: 56423      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:29:59,083][train][INFO][train.py>_log] ==> #1595000    Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 11.467   Value Loss: 7.808    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 2075602    Buffer Size: 56734      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:33:19,089][train][INFO][train.py>_log] ==> #1596000    Total Loss: 3.809    [weighted Loss:3.809    Policy Loss: 11.885   Value Loss: 7.623    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 2077729    Buffer Size: 57076      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:36:33,342][train][INFO][train.py>_log] ==> #1597000    Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 10.617   Value Loss: 7.430    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 2079443    Buffer Size: 56825      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:39:55,234][train][INFO][train.py>_log] ==> #1598000    Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 10.237   Value Loss: 7.527    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 2081165    Buffer Size: 56404      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:43:14,556][train][INFO][train.py>_log] ==> #1599000    Total Loss: 4.083    [weighted Loss:4.083    Policy Loss: 10.262   Value Loss: 7.287    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 2082452    Buffer Size: 55593      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:46:33,864][train][INFO][train.py>_log] ==> #1600000    Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 10.476   Value Loss: 7.662    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 2083712    Buffer Size: 54707      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:49:59,129][train][INFO][train.py>_log] ==> #1601000    Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 10.141   Value Loss: 7.802    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 2085045    Buffer Size: 54262      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:53:18,850][train][INFO][train.py>_log] ==> #1602000    Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 10.795   Value Loss: 7.815    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 2086405    Buffer Size: 53757      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-13 17:56:38,696][train][INFO][train.py>_log] ==> #1603000    Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 9.883    Value Loss: 7.677    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 2088207    Buffer Size: 53841      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:00:00,747][train][INFO][train.py>_log] ==> #1604000    Total Loss: 0.419    [weighted Loss:0.419    Policy Loss: 12.093   Value Loss: 7.636    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2090100    Buffer Size: 54119      Transition Number: 1500.080k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:03:19,586][train][INFO][train.py>_log] ==> #1605000    Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 10.850   Value Loss: 7.544    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 2091774    Buffer Size: 54181      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:06:40,740][train][INFO][train.py>_log] ==> #1606000    Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 10.503   Value Loss: 7.459    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 2093591    Buffer Size: 54187      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:10:02,664][train][INFO][train.py>_log] ==> #1607000    Total Loss: 0.918    [weighted Loss:0.918    Policy Loss: 11.088   Value Loss: 7.180    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 2095143    Buffer Size: 53911      Transition Number: 1500.137k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:13:22,011][train][INFO][train.py>_log] ==> #1608000    Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 10.469   Value Loss: 7.625    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 2096648    Buffer Size: 53581      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:16:43,641][train][INFO][train.py>_log] ==> #1609000    Total Loss: 0.761    [weighted Loss:0.761    Policy Loss: 10.886   Value Loss: 7.554    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 2098304    Buffer Size: 53519      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:20:06,645][train][INFO][train.py>_log] ==> #1610000    Total Loss: 1.355    [weighted Loss:1.355    Policy Loss: 10.527   Value Loss: 7.620    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 2099907    Buffer Size: 53424      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:23:27,924][train][INFO][train.py>_log] ==> #1611000    Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 11.570   Value Loss: 7.537    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 2101785    Buffer Size: 53899      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:26:48,424][train][INFO][train.py>_log] ==> #1612000    Total Loss: 3.866    [weighted Loss:3.866    Policy Loss: 10.700   Value Loss: 7.473    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 2103663    Buffer Size: 54472      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:30:11,298][train][INFO][train.py>_log] ==> #1613000    Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 11.404   Value Loss: 7.614    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 2105762    Buffer Size: 55271      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:33:31,240][train][INFO][train.py>_log] ==> #1614000    Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 10.729   Value Loss: 7.515    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 2107849    Buffer Size: 56105      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:36:50,270][train][INFO][train.py>_log] ==> #1615000    Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 11.131   Value Loss: 7.364    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 2110250    Buffer Size: 57314      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:40:07,302][train][INFO][train.py>_log] ==> #1616000    Total Loss: 4.300    [weighted Loss:4.300    Policy Loss: 11.247   Value Loss: 6.901    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 2112617    Buffer Size: 58588      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:43:22,855][train][INFO][train.py>_log] ==> #1617000    Total Loss: 3.383    [weighted Loss:3.383    Policy Loss: 11.296   Value Loss: 7.312    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 2114908    Buffer Size: 60023      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:46:36,248][train][INFO][train.py>_log] ==> #1618000    Total Loss: 3.219    [weighted Loss:3.219    Policy Loss: 12.093   Value Loss: 7.427    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 2117155    Buffer Size: 61248      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:49:53,494][train][INFO][train.py>_log] ==> #1619000    Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 11.381   Value Loss: 7.409    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 2118750    Buffer Size: 61531      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:53:10,597][train][INFO][train.py>_log] ==> #1620000    Total Loss: 2.530    [weighted Loss:2.530    Policy Loss: 11.942   Value Loss: 7.107    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 2120360    Buffer Size: 61677      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:56:30,463][train][INFO][train.py>_log] ==> #1621000    Total Loss: 3.122    [weighted Loss:3.122    Policy Loss: 11.042   Value Loss: 7.428    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 2121770    Buffer Size: 61465      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-13 18:59:48,386][train][INFO][train.py>_log] ==> #1622000    Total Loss: 2.995    [weighted Loss:2.995    Policy Loss: 11.055   Value Loss: 7.352    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 2123163    Buffer Size: 61207      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:03:02,130][train][INFO][train.py>_log] ==> #1623000    Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 11.072   Value Loss: 7.104    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 2124619    Buffer Size: 61145      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:06:20,211][train][INFO][train.py>_log] ==> #1624000    Total Loss: 1.542    [weighted Loss:1.542    Policy Loss: 11.184   Value Loss: 7.258    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 2126142    Buffer Size: 60800      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:09:42,176][train][INFO][train.py>_log] ==> #1625000    Total Loss: 1.221    [weighted Loss:1.221    Policy Loss: 11.225   Value Loss: 7.123    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 2127581    Buffer Size: 60061      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:13:02,160][train][INFO][train.py>_log] ==> #1626000    Total Loss: 2.660    [weighted Loss:2.660    Policy Loss: 10.917   Value Loss: 6.980    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 2129045    Buffer Size: 59372      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:16:20,678][train][INFO][train.py>_log] ==> #1627000    Total Loss: 1.434    [weighted Loss:1.434    Policy Loss: 10.991   Value Loss: 7.555    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2130108    Buffer Size: 58485      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:19:39,611][train][INFO][train.py>_log] ==> #1628000    Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 10.846   Value Loss: 7.440    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 2131199    Buffer Size: 57553      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:22:56,814][train][INFO][train.py>_log] ==> #1629000    Total Loss: 1.734    [weighted Loss:1.734    Policy Loss: 11.610   Value Loss: 7.278    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 2132574    Buffer Size: 56821      Transition Number: 1500.096k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:26:14,304][train][INFO][train.py>_log] ==> #1630000    Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 10.819   Value Loss: 7.365    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 2133912    Buffer Size: 56141      Transition Number: 1500.122k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:29:38,657][train][INFO][train.py>_log] ==> #1631000    Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 11.903   Value Loss: 7.554    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2135346    Buffer Size: 55808      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:33:01,233][train][INFO][train.py>_log] ==> #1632000    Total Loss: 2.721    [weighted Loss:2.721    Policy Loss: 9.178    Value Loss: 7.717    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2136694    Buffer Size: 55483      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:36:23,610][train][INFO][train.py>_log] ==> #1633000    Total Loss: 3.162    [weighted Loss:3.162    Policy Loss: 11.813   Value Loss: 7.499    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 2138267    Buffer Size: 55717      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:39:47,183][train][INFO][train.py>_log] ==> #1634000    Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 11.485   Value Loss: 7.433    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 2139924    Buffer Size: 56026      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:43:05,498][train][INFO][train.py>_log] ==> #1635000    Total Loss: 1.105    [weighted Loss:1.105    Policy Loss: 10.758   Value Loss: 7.419    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 2141523    Buffer Size: 56279      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:46:29,058][train][INFO][train.py>_log] ==> #1636000    Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 10.490   Value Loss: 7.336    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 2143197    Buffer Size: 56565      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:49:50,722][train][INFO][train.py>_log] ==> #1637000    Total Loss: 0.728    [weighted Loss:0.728    Policy Loss: 10.658   Value Loss: 7.456    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2145189    Buffer Size: 56687      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:53:09,226][train][INFO][train.py>_log] ==> #1638000    Total Loss: 1.736    [weighted Loss:1.736    Policy Loss: 11.030   Value Loss: 7.091    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 2147171    Buffer Size: 56765      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:56:28,077][train][INFO][train.py>_log] ==> #1639000    Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 11.230   Value Loss: 7.279    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 2148599    Buffer Size: 56509      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-13 19:59:49,231][train][INFO][train.py>_log] ==> #1640000    Total Loss: 2.744    [weighted Loss:2.744    Policy Loss: 11.132   Value Loss: 7.448    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 2150064    Buffer Size: 56208      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:03:09,010][train][INFO][train.py>_log] ==> #1641000    Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 9.761    Value Loss: 7.282    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 2151254    Buffer Size: 55995      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:06:31,771][train][INFO][train.py>_log] ==> #1642000    Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 9.328    Value Loss: 7.293    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2152456    Buffer Size: 55687      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:09:53,889][train][INFO][train.py>_log] ==> #1643000    Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 10.672   Value Loss: 7.011    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 2153911    Buffer Size: 55446      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:13:15,249][train][INFO][train.py>_log] ==> #1644000    Total Loss: 1.533    [weighted Loss:1.533    Policy Loss: 9.757    Value Loss: 7.575    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 2155363    Buffer Size: 55305      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:16:37,216][train][INFO][train.py>_log] ==> #1645000    Total Loss: 0.903    [weighted Loss:0.903    Policy Loss: 10.172   Value Loss: 7.439    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 2156981    Buffer Size: 55065      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:19:57,785][train][INFO][train.py>_log] ==> #1646000    Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 11.136   Value Loss: 7.480    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 2158605    Buffer Size: 54793      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:23:20,675][train][INFO][train.py>_log] ==> #1647000    Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 11.961   Value Loss: 7.269    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 2160367    Buffer Size: 54500      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:26:39,457][train][INFO][train.py>_log] ==> #1648000    Total Loss: 3.679    [weighted Loss:3.679    Policy Loss: 10.013   Value Loss: 7.118    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 2162078    Buffer Size: 54208      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:30:03,236][train][INFO][train.py>_log] ==> #1649000    Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 10.488   Value Loss: 7.354    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 2163744    Buffer Size: 53557      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:33:23,115][train][INFO][train.py>_log] ==> #1650000    Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 10.077   Value Loss: 7.551    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 2165360    Buffer Size: 52851      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:36:40,668][train][INFO][train.py>_log] ==> #1651000    Total Loss: 2.429    [weighted Loss:2.429    Policy Loss: 10.101   Value Loss: 7.555    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 2166478    Buffer Size: 51815      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:40:03,830][train][INFO][train.py>_log] ==> #1652000    Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 9.243    Value Loss: 7.302    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 2167625    Buffer Size: 50709      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:43:23,309][train][INFO][train.py>_log] ==> #1653000    Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 9.191    Value Loss: 7.487    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 2168624    Buffer Size: 50159      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:46:45,691][train][INFO][train.py>_log] ==> #1654000    Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 9.929    Value Loss: 7.441    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 2169698    Buffer Size: 49574      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:50:08,870][train][INFO][train.py>_log] ==> #1655000    Total Loss: 1.360    [weighted Loss:1.360    Policy Loss: 10.928   Value Loss: 7.690    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 2171401    Buffer Size: 49728      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:53:29,867][train][INFO][train.py>_log] ==> #1656000    Total Loss: 1.407    [weighted Loss:1.407    Policy Loss: 9.610    Value Loss: 7.470    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 2173142    Buffer Size: 50037      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-13 20:56:53,455][train][INFO][train.py>_log] ==> #1657000    Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 9.867    Value Loss: 7.786    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 2175346    Buffer Size: 50698      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:00:14,737][train][INFO][train.py>_log] ==> #1658000    Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 10.539   Value Loss: 7.885    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 2177634    Buffer Size: 51461      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:03:37,168][train][INFO][train.py>_log] ==> #1659000    Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 10.135   Value Loss: 7.803    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2179637    Buffer Size: 51958      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:06:57,718][train][INFO][train.py>_log] ==> #1660000    Total Loss: 1.422    [weighted Loss:1.422    Policy Loss: 8.574    Value Loss: 7.374    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 2181578    Buffer Size: 52415      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:10:18,912][train][INFO][train.py>_log] ==> #1661000    Total Loss: 1.393    [weighted Loss:1.393    Policy Loss: 9.649    Value Loss: 7.800    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2183439    Buffer Size: 53129      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:13:40,952][train][INFO][train.py>_log] ==> #1662000    Total Loss: 3.454    [weighted Loss:3.454    Policy Loss: 9.653    Value Loss: 7.800    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2185311    Buffer Size: 53879      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:16:56,917][train][INFO][train.py>_log] ==> #1663000    Total Loss: 1.243    [weighted Loss:1.243    Policy Loss: 10.027   Value Loss: 7.643    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 2186846    Buffer Size: 54020      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:20:16,993][train][INFO][train.py>_log] ==> #1664000    Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 9.826    Value Loss: 7.797    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 2188445    Buffer Size: 54214      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:23:36,720][train][INFO][train.py>_log] ==> #1665000    Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 8.325    Value Loss: 7.316    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 2190001    Buffer Size: 54399      Transition Number: 1500.043k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:26:59,345][train][INFO][train.py>_log] ==> #1666000    Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 8.311    Value Loss: 7.516    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 2191637    Buffer Size: 54646      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:30:23,707][train][INFO][train.py>_log] ==> #1667000    Total Loss: 1.251    [weighted Loss:1.251    Policy Loss: 9.443    Value Loss: 7.695    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 2193270    Buffer Size: 54693      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:33:45,502][train][INFO][train.py>_log] ==> #1668000    Total Loss: 4.274    [weighted Loss:4.274    Policy Loss: 9.222    Value Loss: 7.253    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 2194883    Buffer Size: 54677      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:37:07,033][train][INFO][train.py>_log] ==> #1669000    Total Loss: 0.974    [weighted Loss:0.974    Policy Loss: 9.388    Value Loss: 7.562    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 2196775    Buffer Size: 54889      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:40:32,348][train][INFO][train.py>_log] ==> #1670000    Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 11.229   Value Loss: 7.616    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2198733    Buffer Size: 55088      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:43:52,241][train][INFO][train.py>_log] ==> #1671000    Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 9.286    Value Loss: 7.470    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2200868    Buffer Size: 55239      Transition Number: 1500.071k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:47:15,937][train][INFO][train.py>_log] ==> #1672000    Total Loss: 1.487    [weighted Loss:1.487    Policy Loss: 9.578    Value Loss: 7.817    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2203029    Buffer Size: 55491      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:50:38,323][train][INFO][train.py>_log] ==> #1673000    Total Loss: 3.498    [weighted Loss:3.498    Policy Loss: 9.018    Value Loss: 7.371    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 2205205    Buffer Size: 56169      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:53:58,746][train][INFO][train.py>_log] ==> #1674000    Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 9.964    Value Loss: 7.542    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 2207347    Buffer Size: 56870      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-13 21:57:16,185][train][INFO][train.py>_log] ==> #1675000    Total Loss: 3.565    [weighted Loss:3.565    Policy Loss: 10.065   Value Loss: 7.617    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 2209368    Buffer Size: 57631      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:00:34,308][train][INFO][train.py>_log] ==> #1676000    Total Loss: 2.581    [weighted Loss:2.581    Policy Loss: 9.023    Value Loss: 7.860    Reward Loss: 1.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 2211385    Buffer Size: 58371      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:03:51,949][train][INFO][train.py>_log] ==> #1677000    Total Loss: 4.381    [weighted Loss:4.381    Policy Loss: 10.813   Value Loss: 7.494    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 2213269    Buffer Size: 58803      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:07:12,535][train][INFO][train.py>_log] ==> #1678000    Total Loss: 2.871    [weighted Loss:2.871    Policy Loss: 10.892   Value Loss: 7.624    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2215172    Buffer Size: 59196      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:10:33,968][train][INFO][train.py>_log] ==> #1679000    Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 10.579   Value Loss: 7.384    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2217006    Buffer Size: 59452      Transition Number: 1500.084k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:13:54,255][train][INFO][train.py>_log] ==> #1680000    Total Loss: 2.084    [weighted Loss:2.084    Policy Loss: 10.276   Value Loss: 7.690    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 2218765    Buffer Size: 59573      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:17:10,761][train][INFO][train.py>_log] ==> #1681000    Total Loss: 3.777    [weighted Loss:3.777    Policy Loss: 11.491   Value Loss: 7.387    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 2220078    Buffer Size: 59251      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:20:33,537][train][INFO][train.py>_log] ==> #1682000    Total Loss: 2.359    [weighted Loss:2.359    Policy Loss: 10.180   Value Loss: 7.997    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2221458    Buffer Size: 58885      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:23:54,064][train][INFO][train.py>_log] ==> #1683000    Total Loss: 0.915    [weighted Loss:0.915    Policy Loss: 10.718   Value Loss: 7.914    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 2222877    Buffer Size: 58636      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:27:15,177][train][INFO][train.py>_log] ==> #1684000    Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 9.620    Value Loss: 7.456    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 2224256    Buffer Size: 58531      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:30:35,717][train][INFO][train.py>_log] ==> #1685000    Total Loss: 0.763    [weighted Loss:0.763    Policy Loss: 11.263   Value Loss: 7.586    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2226231    Buffer Size: 59290      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:33:53,636][train][INFO][train.py>_log] ==> #1686000    Total Loss: 0.746    [weighted Loss:0.746    Policy Loss: 11.014   Value Loss: 7.554    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2228117    Buffer Size: 60028      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:37:10,133][train][INFO][train.py>_log] ==> #1687000    Total Loss: 0.370    [weighted Loss:0.370    Policy Loss: 11.118   Value Loss: 7.880    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 2229995    Buffer Size: 60832      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:40:27,545][train][INFO][train.py>_log] ==> #1688000    Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 11.001   Value Loss: 7.331    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2231899    Buffer Size: 61441      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:43:43,349][train][INFO][train.py>_log] ==> #1689000    Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 10.060   Value Loss: 7.027    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2234070    Buffer Size: 61900      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:47:02,701][train][INFO][train.py>_log] ==> #1690000    Total Loss: 1.539    [weighted Loss:1.539    Policy Loss: 11.761   Value Loss: 7.606    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 2236277    Buffer Size: 62224      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:50:21,009][train][INFO][train.py>_log] ==> #1691000    Total Loss: 1.519    [weighted Loss:1.519    Policy Loss: 11.201   Value Loss: 7.230    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 2237911    Buffer Size: 61658      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:53:36,782][train][INFO][train.py>_log] ==> #1692000    Total Loss: 4.538    [weighted Loss:4.538    Policy Loss: 11.805   Value Loss: 7.639    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2239545    Buffer Size: 61159      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-13 22:56:54,076][train][INFO][train.py>_log] ==> #1693000    Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 12.131   Value Loss: 7.287    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 2240952    Buffer Size: 60653      Transition Number: 1500.122k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:00:13,740][train][INFO][train.py>_log] ==> #1694000    Total Loss: 3.447    [weighted Loss:3.447    Policy Loss: 11.379   Value Loss: 7.560    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2242408    Buffer Size: 60269      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:03:33,334][train][INFO][train.py>_log] ==> #1695000    Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 11.593   Value Loss: 7.804    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2243896    Buffer Size: 59895      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:06:51,879][train][INFO][train.py>_log] ==> #1696000    Total Loss: 0.703    [weighted Loss:0.703    Policy Loss: 11.249   Value Loss: 7.243    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 2245361    Buffer Size: 59550      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:10:12,967][train][INFO][train.py>_log] ==> #1697000    Total Loss: 1.281    [weighted Loss:1.281    Policy Loss: 12.285   Value Loss: 7.580    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 2247167    Buffer Size: 59776      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:13:33,192][train][INFO][train.py>_log] ==> #1698000    Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 11.406   Value Loss: 7.354    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 2248917    Buffer Size: 59964      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:16:51,089][train][INFO][train.py>_log] ==> #1699000    Total Loss: 3.497    [weighted Loss:3.497    Policy Loss: 12.125   Value Loss: 7.670    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 2250951    Buffer Size: 60352      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:20:12,372][train][INFO][train.py>_log] ==> #1700000    Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 11.393   Value Loss: 7.502    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 2253022    Buffer Size: 60778      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:23:29,491][train][INFO][train.py>_log] ==> #1701000    Total Loss: 0.623    [weighted Loss:0.623    Policy Loss: 11.735   Value Loss: 7.539    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2255728    Buffer Size: 61815      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:26:47,104][train][INFO][train.py>_log] ==> #1702000    Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 12.103   Value Loss: 7.289    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 2258417    Buffer Size: 62757      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:30:04,989][train][INFO][train.py>_log] ==> #1703000    Total Loss: 3.167    [weighted Loss:3.167    Policy Loss: 11.080   Value Loss: 7.320    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2260068    Buffer Size: 62689      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:33:26,849][train][INFO][train.py>_log] ==> #1704000    Total Loss: 0.700    [weighted Loss:0.700    Policy Loss: 11.061   Value Loss: 7.627    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2261774    Buffer Size: 62424      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:36:46,809][train][INFO][train.py>_log] ==> #1705000    Total Loss: 3.006    [weighted Loss:3.006    Policy Loss: 11.406   Value Loss: 7.248    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 2263600    Buffer Size: 62104      Transition Number: 1500.052k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:40:05,965][train][INFO][train.py>_log] ==> #1706000    Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 11.392   Value Loss: 7.606    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 2265423    Buffer Size: 61788      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:43:25,034][train][INFO][train.py>_log] ==> #1707000    Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 10.520   Value Loss: 7.572    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 2266598    Buffer Size: 60964      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:46:40,980][train][INFO][train.py>_log] ==> #1708000    Total Loss: 2.621    [weighted Loss:2.621    Policy Loss: 9.989    Value Loss: 7.268    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 2267714    Buffer Size: 60149      Transition Number: 1500.098k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:50:00,068][train][INFO][train.py>_log] ==> #1709000    Total Loss: 1.475    [weighted Loss:1.475    Policy Loss: 11.707   Value Loss: 7.390    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 2269233    Buffer Size: 59653      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:53:20,313][train][INFO][train.py>_log] ==> #1710000    Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 11.055   Value Loss: 7.732    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 2270805    Buffer Size: 59177      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:56:40,705][train][INFO][train.py>_log] ==> #1711000    Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 10.721   Value Loss: 7.434    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 2272998    Buffer Size: 59382      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-13 23:59:59,862][train][INFO][train.py>_log] ==> #1712000    Total Loss: 3.424    [weighted Loss:3.424    Policy Loss: 11.685   Value Loss: 7.627    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2275166    Buffer Size: 59620      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:03:20,163][train][INFO][train.py>_log] ==> #1713000    Total Loss: 2.030    [weighted Loss:2.030    Policy Loss: 11.088   Value Loss: 7.624    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 2277569    Buffer Size: 60160      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:06:44,192][train][INFO][train.py>_log] ==> #1714000    Total Loss: 3.818    [weighted Loss:3.818    Policy Loss: 10.155   Value Loss: 7.414    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 2279955    Buffer Size: 60787      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:10:05,718][train][INFO][train.py>_log] ==> #1715000    Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 11.477   Value Loss: 7.792    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 2283482    Buffer Size: 62867      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:13:24,676][train][INFO][train.py>_log] ==> #1716000    Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 10.416   Value Loss: 7.172    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 2286957    Buffer Size: 64937      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:16:42,368][train][INFO][train.py>_log] ==> #1717000    Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 10.322   Value Loss: 7.619    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2288809    Buffer Size: 65450      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:19:59,604][train][INFO][train.py>_log] ==> #1718000    Total Loss: 0.855    [weighted Loss:0.855    Policy Loss: 9.477    Value Loss: 7.273    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2290598    Buffer Size: 65701      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:23:15,798][train][INFO][train.py>_log] ==> #1719000    Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 10.859   Value Loss: 7.379    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 2291822    Buffer Size: 65165      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:26:32,132][train][INFO][train.py>_log] ==> #1720000    Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 10.993   Value Loss: 7.568    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 2293028    Buffer Size: 64528      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:29:52,188][train][INFO][train.py>_log] ==> #1721000    Total Loss: 2.929    [weighted Loss:2.929    Policy Loss: 10.597   Value Loss: 7.384    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 2294474    Buffer Size: 64080      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:33:09,325][train][INFO][train.py>_log] ==> #1722000    Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 10.191   Value Loss: 7.489    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2295952    Buffer Size: 63675      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:36:28,827][train][INFO][train.py>_log] ==> #1723000    Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 9.300    Value Loss: 7.686    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 2297330    Buffer Size: 62933      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:39:48,196][train][INFO][train.py>_log] ==> #1724000    Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 9.313    Value Loss: 7.637    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2298765    Buffer Size: 62190      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:43:06,231][train][INFO][train.py>_log] ==> #1725000    Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 10.145   Value Loss: 7.691    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2299803    Buffer Size: 61762      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:46:24,546][train][INFO][train.py>_log] ==> #1726000    Total Loss: 1.233    [weighted Loss:1.233    Policy Loss: 9.835    Value Loss: 7.519    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 2300968    Buffer Size: 61342      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:49:44,404][train][INFO][train.py>_log] ==> #1727000    Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 9.536    Value Loss: 7.830    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 2302234    Buffer Size: 61183      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:53:05,224][train][INFO][train.py>_log] ==> #1728000    Total Loss: 1.326    [weighted Loss:1.326    Policy Loss: 8.890    Value Loss: 7.263    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 2303481    Buffer Size: 60953      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:56:24,312][train][INFO][train.py>_log] ==> #1729000    Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 9.852    Value Loss: 7.607    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 2304680    Buffer Size: 60714      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-14 00:59:46,886][train][INFO][train.py>_log] ==> #1730000    Total Loss: 1.332    [weighted Loss:1.332    Policy Loss: 9.422    Value Loss: 7.466    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 2305949    Buffer Size: 60454      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:03:07,816][train][INFO][train.py>_log] ==> #1731000    Total Loss: 1.430    [weighted Loss:1.430    Policy Loss: 9.319    Value Loss: 7.356    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 2307801    Buffer Size: 60386      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:06:28,331][train][INFO][train.py>_log] ==> #1732000    Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 9.286    Value Loss: 7.573    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2309679    Buffer Size: 60535      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:09:50,743][train][INFO][train.py>_log] ==> #1733000    Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 10.358   Value Loss: 7.624    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 2312124    Buffer Size: 60858      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:13:14,472][train][INFO][train.py>_log] ==> #1734000    Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 11.235   Value Loss: 7.994    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 2314736    Buffer Size: 61242      Transition Number: 1500.061k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:16:34,433][train][INFO][train.py>_log] ==> #1735000    Total Loss: 1.478    [weighted Loss:1.478    Policy Loss: 9.775    Value Loss: 7.401    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 2316833    Buffer Size: 60721      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:19:56,288][train][INFO][train.py>_log] ==> #1736000    Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 10.145   Value Loss: 7.809    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 2318962    Buffer Size: 60280      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:23:17,695][train][INFO][train.py>_log] ==> #1737000    Total Loss: 2.773    [weighted Loss:2.773    Policy Loss: 10.682   Value Loss: 7.834    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 2320619    Buffer Size: 60234      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:26:36,965][train][INFO][train.py>_log] ==> #1738000    Total Loss: 1.071    [weighted Loss:1.071    Policy Loss: 9.177    Value Loss: 7.546    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2322305    Buffer Size: 60196      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:29:57,267][train][INFO][train.py>_log] ==> #1739000    Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 11.265   Value Loss: 7.789    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 2323965    Buffer Size: 60009      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:33:16,954][train][INFO][train.py>_log] ==> #1740000    Total Loss: 3.484    [weighted Loss:3.484    Policy Loss: 10.963   Value Loss: 7.865    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 2325679    Buffer Size: 59978      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:36:35,939][train][INFO][train.py>_log] ==> #1741000    Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 9.657    Value Loss: 7.717    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 2327882    Buffer Size: 60978      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:39:56,030][train][INFO][train.py>_log] ==> #1742000    Total Loss: 1.320    [weighted Loss:1.320    Policy Loss: 11.612   Value Loss: 7.702    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2330117    Buffer Size: 61956      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:43:12,863][train][INFO][train.py>_log] ==> #1743000    Total Loss: 3.504    [weighted Loss:3.504    Policy Loss: 10.837   Value Loss: 7.612    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 2331820    Buffer Size: 62094      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:46:31,868][train][INFO][train.py>_log] ==> #1744000    Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 11.122   Value Loss: 7.614    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 2333477    Buffer Size: 62056      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:50:05,926][train][INFO][train.py>_log] ==> #1745000    Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 9.799    Value Loss: 7.623    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2340733    Buffer Size: 66803      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:53:35,863][train][INFO][train.py>_log] ==> #1746000    Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 9.775    Value Loss: 7.298    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 2348242    Buffer Size: 71795      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-14 01:56:55,295][train][INFO][train.py>_log] ==> #1747000    Total Loss: 0.821    [weighted Loss:0.821    Policy Loss: 9.958    Value Loss: 7.158    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 2352486    Buffer Size: 73649      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
