[2022-01-10 01:38:09,440][train][INFO][train.py>_log] ==> #0          Total Loss: 56.361   [weighted Loss:56.361   Policy Loss: 15.260   Value Loss: 37.125   Reward Loss: 31.820   Consistency Loss: 0.000    ] Replay Episodes Collected: 555        Buffer Size: 555        Transition Number: 5.896   k Batch Size: 256        Lr: 0.00000 
[2022-01-10 01:40:51,362][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.766    [weighted Loss:6.766    Policy Loss: 15.183   Value Loss: 4.069    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 3596       Buffer Size: 3596       Transition Number: 44.110  k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:43:43,205][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.657    [weighted Loss:5.657    Policy Loss: 14.714   Value Loss: 3.650    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 6693       Buffer Size: 6693       Transition Number: 83.126  k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:46:24,846][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.883    [weighted Loss:5.883    Policy Loss: 13.801   Value Loss: 3.404    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 9823       Buffer Size: 9823       Transition Number: 120.508 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:49:03,122][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.924    [weighted Loss:4.924    Policy Loss: 13.932   Value Loss: 3.368    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 12909      Buffer Size: 12909      Transition Number: 156.503 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:51:41,091][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.365    [weighted Loss:5.365    Policy Loss: 14.174   Value Loss: 3.385    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 14932      Buffer Size: 14932      Transition Number: 187.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:54:19,381][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.823    [weighted Loss:3.823    Policy Loss: 14.444   Value Loss: 3.038    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 16985      Buffer Size: 16985      Transition Number: 224.604 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:57:04,230][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.986    [weighted Loss:4.986    Policy Loss: 13.285   Value Loss: 3.188    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 18875      Buffer Size: 18875      Transition Number: 257.701 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 01:59:48,194][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.798    [weighted Loss:5.798    Policy Loss: 13.678   Value Loss: 3.299    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 20726      Buffer Size: 20726      Transition Number: 292.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:02:30,290][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.586    [weighted Loss:5.586    Policy Loss: 13.471   Value Loss: 2.937    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 22494      Buffer Size: 22494      Transition Number: 328.209 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:05:14,320][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.445    [weighted Loss:3.445    Policy Loss: 13.966   Value Loss: 2.975    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 24263      Buffer Size: 24263      Transition Number: 361.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:08:01,507][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.285    [weighted Loss:5.285    Policy Loss: 14.004   Value Loss: 3.189    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 26592      Buffer Size: 26592      Transition Number: 401.204 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:10:43,793][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.074    [weighted Loss:5.074    Policy Loss: 13.911   Value Loss: 3.241    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 28817      Buffer Size: 28817      Transition Number: 436.554 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:13:26,438][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.448    [weighted Loss:5.448    Policy Loss: 13.603   Value Loss: 3.045    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 30741      Buffer Size: 30741      Transition Number: 468.297 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:16:06,809][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 14.053   Value Loss: 3.356    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 32670      Buffer Size: 32670      Transition Number: 504.681 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:18:51,112][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.668    [weighted Loss:5.668    Policy Loss: 14.024   Value Loss: 3.556    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 34379      Buffer Size: 34379      Transition Number: 534.634 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:21:34,657][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.861    [weighted Loss:3.861    Policy Loss: 11.269   Value Loss: 3.447    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 35991      Buffer Size: 35991      Transition Number: 569.291 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:24:24,048][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.923    [weighted Loss:4.923    Policy Loss: 10.545   Value Loss: 3.670    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 36970      Buffer Size: 36970      Transition Number: 602.499 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:27:05,628][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.579    [weighted Loss:4.579    Policy Loss: 9.502    Value Loss: 3.831    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 37776      Buffer Size: 37776      Transition Number: 625.124 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:29:52,219][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 8.986    Value Loss: 3.849    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 38565      Buffer Size: 38565      Transition Number: 659.063 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:32:35,575][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 7.487    Value Loss: 3.882    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 39285      Buffer Size: 39285      Transition Number: 691.897 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:35:24,582][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 7.191    Value Loss: 4.140    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 39795      Buffer Size: 39795      Transition Number: 716.772 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:38:09,481][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 6.973    Value Loss: 4.442    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 40409      Buffer Size: 40409      Transition Number: 753.330 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:40:56,707][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 6.311    Value Loss: 4.010    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 40959      Buffer Size: 40959      Transition Number: 785.910 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:43:45,122][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 6.032    Value Loss: 4.128    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 41494      Buffer Size: 41494      Transition Number: 818.888 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:46:31,919][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 5.883    Value Loss: 3.927    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 42265      Buffer Size: 42265      Transition Number: 853.829 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:49:15,921][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 6.344    Value Loss: 4.011    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 43003      Buffer Size: 43003      Transition Number: 880.089 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:52:00,483][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 5.209    Value Loss: 4.158    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 43664      Buffer Size: 43664      Transition Number: 913.219 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:54:47,003][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.832    [weighted Loss:2.832    Policy Loss: 6.068    Value Loss: 4.224    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 44311      Buffer Size: 44311      Transition Number: 947.078 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 02:57:38,871][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 4.674    Value Loss: 4.068    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 44808      Buffer Size: 44808      Transition Number: 978.774 k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:00:27,193][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 4.626    Value Loss: 4.333    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 45358      Buffer Size: 45358      Transition Number: 1014.309k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:03:14,457][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 4.635    Value Loss: 4.321    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 45852      Buffer Size: 45852      Transition Number: 1047.282k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:06:01,970][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.395    [weighted Loss:1.395    Policy Loss: 4.513    Value Loss: 4.354    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 46317      Buffer Size: 46317      Transition Number: 1078.011k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:08:52,793][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.066    [weighted Loss:1.066    Policy Loss: 4.160    Value Loss: 4.391    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 46818      Buffer Size: 46818      Transition Number: 1112.835k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:11:42,912][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 4.453    Value Loss: 4.110    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 47248      Buffer Size: 47248      Transition Number: 1143.333k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:14:33,695][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 4.703    Value Loss: 4.402    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 47656      Buffer Size: 47656      Transition Number: 1170.504k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:17:22,715][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 4.374    Value Loss: 4.229    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 48097      Buffer Size: 48097      Transition Number: 1202.003k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:20:12,605][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 4.340    Value Loss: 4.005    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 48572      Buffer Size: 48572      Transition Number: 1231.464k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:23:07,452][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 4.081    Value Loss: 4.259    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 49024      Buffer Size: 49024      Transition Number: 1258.405k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:26:02,965][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 4.882    Value Loss: 4.212    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 49517      Buffer Size: 49517      Transition Number: 1292.041k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:28:54,170][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 4.357    Value Loss: 4.317    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 49974      Buffer Size: 49974      Transition Number: 1322.780k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:31:48,934][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 4.703    Value Loss: 4.391    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 50367      Buffer Size: 50367      Transition Number: 1347.848k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:34:44,904][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 4.296    Value Loss: 4.321    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 50890      Buffer Size: 50890      Transition Number: 1382.900k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:37:43,539][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.651    [weighted Loss:1.651    Policy Loss: 3.909    Value Loss: 4.283    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 51372      Buffer Size: 51372      Transition Number: 1415.653k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:40:42,945][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 3.365    Value Loss: 4.693    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 51801      Buffer Size: 51801      Transition Number: 1444.270k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:43:42,412][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 3.782    Value Loss: 4.340    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 52210      Buffer Size: 52210      Transition Number: 1474.330k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:46:43,233][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 3.762    Value Loss: 4.468    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 52643      Buffer Size: 52025      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:49:48,747][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 4.415    Value Loss: 4.264    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 53141      Buffer Size: 50135      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:52:57,679][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.089    [weighted Loss:1.089    Policy Loss: 3.946    Value Loss: 4.354    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 53631      Buffer Size: 48215      Transition Number: 1500.083k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:56:08,241][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 3.315    Value Loss: 4.532    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 54142      Buffer Size: 46025      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-10 03:59:16,205][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 3.817    Value Loss: 4.375    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 54645      Buffer Size: 43568      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:02:26,322][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.540    [weighted Loss:1.540    Policy Loss: 3.546    Value Loss: 4.786    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 55121      Buffer Size: 41272      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:05:32,942][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 3.359    Value Loss: 4.720    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 55526      Buffer Size: 39851      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:08:42,090][train][INFO][train.py>_log] ==> #53000      Total Loss: 0.835    [weighted Loss:0.835    Policy Loss: 3.502    Value Loss: 4.319    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 55987      Buffer Size: 38304      Transition Number: 1500.250k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:11:50,594][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 3.389    Value Loss: 4.528    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 56453      Buffer Size: 36914      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:15:01,061][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 3.614    Value Loss: 4.843    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 56911      Buffer Size: 35460      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:18:08,878][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 3.581    Value Loss: 4.662    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 57345      Buffer Size: 34349      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:21:18,835][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 3.494    Value Loss: 4.593    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 57841      Buffer Size: 32806      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:24:29,230][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 3.716    Value Loss: 4.463    Reward Loss: 0.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 58312      Buffer Size: 31054      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:27:39,343][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 3.946    Value Loss: 4.491    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 58839      Buffer Size: 29164      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:30:52,001][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 3.252    Value Loss: 4.511    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 59311      Buffer Size: 27653      Transition Number: 1500.076k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:34:08,098][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 3.949    Value Loss: 4.571    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 59881      Buffer Size: 25777      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:37:21,983][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.362    [weighted Loss:1.362    Policy Loss: 3.164    Value Loss: 4.281    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 60436      Buffer Size: 24448      Transition Number: 1500.250k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:40:38,252][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.079    [weighted Loss:1.079    Policy Loss: 3.880    Value Loss: 4.547    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 60978      Buffer Size: 23762      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:43:53,765][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 3.470    Value Loss: 4.538    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 61599      Buffer Size: 23141      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:47:07,980][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 3.647    Value Loss: 4.575    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 62114      Buffer Size: 22804      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:50:24,289][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 3.705    Value Loss: 4.929    Reward Loss: 0.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 62716      Buffer Size: 22589      Transition Number: 1499.926k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:53:38,248][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 3.102    Value Loss: 4.637    Reward Loss: 0.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 63271      Buffer Size: 22473      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-10 04:56:54,359][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 3.546    Value Loss: 4.659    Reward Loss: 0.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 63889      Buffer Size: 22385      Transition Number: 1500.078k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:00:12,027][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 4.085    Value Loss: 4.654    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 64514      Buffer Size: 21893      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:03:26,939][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 4.154    Value Loss: 4.349    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 65067      Buffer Size: 21626      Transition Number: 1500.108k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:06:46,698][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 3.677    Value Loss: 4.546    Reward Loss: 0.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 65700      Buffer Size: 21325      Transition Number: 1500.105k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:10:04,790][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.393    [weighted Loss:1.393    Policy Loss: 3.949    Value Loss: 4.598    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 66330      Buffer Size: 21239      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:13:22,873][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 4.583    Value Loss: 4.331    Reward Loss: 0.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 66908      Buffer Size: 21174      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:16:38,362][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 4.095    Value Loss: 4.610    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 67528      Buffer Size: 21103      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:19:55,266][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 4.151    Value Loss: 4.522    Reward Loss: 0.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 68261      Buffer Size: 21208      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:23:09,231][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 4.503    Value Loss: 4.587    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 68997      Buffer Size: 21329      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:26:25,115][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 4.572    Value Loss: 4.268    Reward Loss: 0.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 69664      Buffer Size: 21368      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:29:42,639][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 4.493    Value Loss: 4.638    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 70353      Buffer Size: 21351      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:32:59,098][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 4.821    Value Loss: 4.386    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 71005      Buffer Size: 21329      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:36:15,105][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 4.787    Value Loss: 4.606    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 71611      Buffer Size: 21307      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:39:32,790][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 4.271    Value Loss: 4.287    Reward Loss: 0.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 72247      Buffer Size: 21280      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:42:51,942][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 4.635    Value Loss: 4.430    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 72945      Buffer Size: 21246      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:46:09,359][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 4.565    Value Loss: 4.375    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 73582      Buffer Size: 21286      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:49:28,098][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 5.006    Value Loss: 4.745    Reward Loss: 0.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 74258      Buffer Size: 21267      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:52:48,930][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 4.909    Value Loss: 4.505    Reward Loss: 0.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 74925      Buffer Size: 21215      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:56:07,771][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 4.586    Value Loss: 4.527    Reward Loss: 0.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 75606      Buffer Size: 21239      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 05:59:26,940][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 5.385    Value Loss: 4.794    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 76320      Buffer Size: 21340      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:02:47,022][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.435    [weighted Loss:2.435    Policy Loss: 4.998    Value Loss: 4.313    Reward Loss: 0.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 76995      Buffer Size: 21444      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:06:06,176][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 4.727    Value Loss: 4.723    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 77740      Buffer Size: 21600      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:09:23,874][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.305    [weighted Loss:2.305    Policy Loss: 4.454    Value Loss: 4.585    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 78438      Buffer Size: 21744      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:12:43,299][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 5.026    Value Loss: 4.810    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 79176      Buffer Size: 21904      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:16:00,644][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 5.140    Value Loss: 4.840    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 79874      Buffer Size: 22048      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:19:16,665][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 4.578    Value Loss: 4.860    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 80595      Buffer Size: 22194      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:22:33,680][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 5.368    Value Loss: 4.880    Reward Loss: 0.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 81335      Buffer Size: 22353      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:25:51,127][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 4.369    Value Loss: 4.677    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 82018      Buffer Size: 22498      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:29:08,808][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 4.567    Value Loss: 4.822    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 82746      Buffer Size: 22657      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:32:27,358][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 4.875    Value Loss: 5.034    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 83569      Buffer Size: 22890      Transition Number: 1500.106k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:35:45,671][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 4.796    Value Loss: 4.818    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 84416      Buffer Size: 23158      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:39:05,059][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.339    [weighted Loss:2.339    Policy Loss: 4.669    Value Loss: 4.941    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 85187      Buffer Size: 23383      Transition Number: 1500.082k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:42:21,659][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 4.794    Value Loss: 4.992    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 85995      Buffer Size: 23623      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:45:37,665][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 4.370    Value Loss: 4.911    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 86674      Buffer Size: 23735      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:48:55,501][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 5.004    Value Loss: 5.466    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 87400      Buffer Size: 23838      Transition Number: 1499.928k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:52:13,257][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 4.083    Value Loss: 5.210    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 88198      Buffer Size: 24013      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:55:29,007][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 4.380    Value Loss: 5.237    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 88998      Buffer Size: 24237      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 06:58:46,920][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 4.479    Value Loss: 5.160    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 89789      Buffer Size: 24443      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:02:04,585][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.959    [weighted Loss:1.959    Policy Loss: 3.916    Value Loss: 4.937    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 90574      Buffer Size: 24655      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:05:20,484][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 4.594    Value Loss: 5.558    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 91284      Buffer Size: 24783      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:08:38,336][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 4.073    Value Loss: 5.174    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 92009      Buffer Size: 24920      Transition Number: 1500.098k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:11:54,692][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 5.280    Value Loss: 4.957    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 92655      Buffer Size: 25003      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:15:13,610][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 3.896    Value Loss: 5.178    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 93399      Buffer Size: 24940      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:18:31,254][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 5.200    Value Loss: 4.972    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 94006      Buffer Size: 24858      Transition Number: 1500.096k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:21:53,806][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.017    [weighted Loss:2.017    Policy Loss: 4.168    Value Loss: 4.915    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 94736      Buffer Size: 24814      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:25:08,557][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 5.237    Value Loss: 5.427    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 95374      Buffer Size: 24804      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:28:25,212][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 4.418    Value Loss: 4.739    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 96002      Buffer Size: 24810      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:31:44,282][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 4.664    Value Loss: 5.172    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 96718      Buffer Size: 24849      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:34:59,444][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 4.675    Value Loss: 5.066    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 97331      Buffer Size: 24881      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:38:17,530][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 5.004    Value Loss: 5.305    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 98016      Buffer Size: 24887      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:41:35,302][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.433    [weighted Loss:1.433    Policy Loss: 3.710    Value Loss: 5.142    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 98633      Buffer Size: 24888      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:44:51,421][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 4.738    Value Loss: 5.262    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 99312      Buffer Size: 24931      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:48:09,299][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 4.553    Value Loss: 5.499    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 100005     Buffer Size: 24949      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:51:26,523][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 4.282    Value Loss: 5.319    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 100614     Buffer Size: 24941      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:54:46,082][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.030    [weighted Loss:2.030    Policy Loss: 4.193    Value Loss: 5.298    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 101311     Buffer Size: 24882      Transition Number: 1500.108k Batch Size: 256        Lr: 0.10000 
[2022-01-10 07:58:03,849][train][INFO][train.py>_log] ==> #123000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 4.604    Value Loss: 5.395    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 101892     Buffer Size: 24842      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:01:20,932][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 4.736    Value Loss: 5.376    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 102567     Buffer Size: 24737      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:04:38,617][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 4.505    Value Loss: 5.273    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 103216     Buffer Size: 24640      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:08:01,900][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 4.857    Value Loss: 5.339    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 103871     Buffer Size: 24558      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:11:20,545][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.666    [weighted Loss:1.666    Policy Loss: 4.618    Value Loss: 5.352    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 104567     Buffer Size: 24527      Transition Number: 1500.237k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:14:39,197][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.177    [weighted Loss:1.177    Policy Loss: 4.266    Value Loss: 5.216    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 105223     Buffer Size: 24476      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:17:58,779][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 4.798    Value Loss: 5.291    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 105879     Buffer Size: 24403      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:21:18,481][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.405    [weighted Loss:2.405    Policy Loss: 4.579    Value Loss: 5.310    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 106507     Buffer Size: 24332      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:24:38,065][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 4.504    Value Loss: 5.461    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 107198     Buffer Size: 24220      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:27:57,915][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 4.231    Value Loss: 5.574    Reward Loss: 0.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 107852     Buffer Size: 24088      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:31:19,749][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.848    [weighted Loss:2.848    Policy Loss: 4.693    Value Loss: 5.571    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 108457     Buffer Size: 23904      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:34:38,781][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 4.334    Value Loss: 5.424    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 109137     Buffer Size: 23718      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:37:59,190][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 5.302    Value Loss: 5.407    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 110299     Buffer Size: 24069      Transition Number: 1499.927k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:41:16,326][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 4.698    Value Loss: 5.736    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 111383     Buffer Size: 24454      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:44:35,761][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 4.885    Value Loss: 5.625    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 112056     Buffer Size: 24441      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:47:53,544][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 4.814    Value Loss: 5.865    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 112756     Buffer Size: 24354      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:51:10,747][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 4.746    Value Loss: 5.579    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 113406     Buffer Size: 24213      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:54:27,103][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 4.973    Value Loss: 5.319    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 114031     Buffer Size: 24079      Transition Number: 1500.110k Batch Size: 256        Lr: 0.10000 
[2022-01-10 08:57:46,767][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 4.919    Value Loss: 5.259    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 114708     Buffer Size: 23936      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:01:05,844][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.767    [weighted Loss:1.767    Policy Loss: 4.825    Value Loss: 5.503    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 115345     Buffer Size: 23862      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:04:26,811][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 4.900    Value Loss: 5.692    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 116012     Buffer Size: 23776      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:07:46,737][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 4.490    Value Loss: 5.558    Reward Loss: 0.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 116684     Buffer Size: 23757      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:11:07,470][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.802    [weighted Loss:2.802    Policy Loss: 4.490    Value Loss: 5.520    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 117344     Buffer Size: 23707      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:14:30,086][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 3.905    Value Loss: 5.445    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 118003     Buffer Size: 23692      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:17:49,248][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 4.235    Value Loss: 5.325    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 118700     Buffer Size: 23681      Transition Number: 1499.932k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:21:07,258][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.859    [weighted Loss:1.859    Policy Loss: 3.945    Value Loss: 5.548    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 119347     Buffer Size: 23677      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:24:30,171][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 4.245    Value Loss: 5.460    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 120049     Buffer Size: 23660      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:27:51,087][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.330    [weighted Loss:2.330    Policy Loss: 4.345    Value Loss: 5.789    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 120735     Buffer Size: 23631      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:31:11,856][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.857    [weighted Loss:1.857    Policy Loss: 3.934    Value Loss: 5.141    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 121335     Buffer Size: 23600      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:34:31,634][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 4.357    Value Loss: 5.715    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 122069     Buffer Size: 23574      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:37:51,852][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.974    [weighted Loss:2.974    Policy Loss: 4.453    Value Loss: 5.350    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 122708     Buffer Size: 23532      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:41:11,606][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 4.251    Value Loss: 5.494    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 123338     Buffer Size: 23465      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:44:32,640][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 4.556    Value Loss: 5.407    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 124060     Buffer Size: 23404      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:47:54,270][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 4.814    Value Loss: 5.269    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 124737     Buffer Size: 23376      Transition Number: 1499.929k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:51:16,083][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 4.485    Value Loss: 5.858    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 125371     Buffer Size: 23369      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:54:38,143][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 4.739    Value Loss: 5.360    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 126098     Buffer Size: 23360      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-10 09:58:01,584][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 4.853    Value Loss: 5.747    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 126840     Buffer Size: 23339      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:01:24,225][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 5.036    Value Loss: 5.491    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 127471     Buffer Size: 23340      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:04:44,796][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 4.705    Value Loss: 5.453    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 128152     Buffer Size: 23304      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:08:06,488][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 4.896    Value Loss: 5.500    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 128866     Buffer Size: 23308      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:11:29,360][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 4.834    Value Loss: 5.839    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 129518     Buffer Size: 23292      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:14:51,606][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.721    [weighted Loss:2.721    Policy Loss: 4.994    Value Loss: 5.453    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 130225     Buffer Size: 23261      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:18:12,046][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 5.009    Value Loss: 5.748    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 130930     Buffer Size: 23206      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:21:33,055][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 5.235    Value Loss: 5.786    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 131582     Buffer Size: 23181      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:24:54,520][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 5.973    Value Loss: 5.750    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 132235     Buffer Size: 23130      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:28:17,990][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 4.929    Value Loss: 5.083    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 132938     Buffer Size: 22512      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:31:39,523][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 5.370    Value Loss: 5.377    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 133632     Buffer Size: 22057      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:35:01,756][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 4.915    Value Loss: 5.404    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 134319     Buffer Size: 21979      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:38:25,079][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 5.246    Value Loss: 5.576    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 135049     Buffer Size: 21915      Transition Number: 1499.936k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:41:49,086][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 5.538    Value Loss: 5.189    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 135745     Buffer Size: 21884      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:45:09,724][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.715    [weighted Loss:2.715    Policy Loss: 5.513    Value Loss: 5.543    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 136420     Buffer Size: 21876      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:48:32,456][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 4.927    Value Loss: 5.407    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 137126     Buffer Size: 21858      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:51:55,474][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 5.082    Value Loss: 5.616    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 137826     Buffer Size: 21860      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:55:15,330][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 5.101    Value Loss: 5.155    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 138554     Buffer Size: 21840      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-10 10:58:38,139][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.666    [weighted Loss:2.666    Policy Loss: 4.844    Value Loss: 5.756    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 139285     Buffer Size: 21885      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:02:04,857][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 4.908    Value Loss: 5.685    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 140003     Buffer Size: 21919      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:05:32,250][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.813    [weighted Loss:2.813    Policy Loss: 4.384    Value Loss: 5.801    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 140771     Buffer Size: 21970      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:08:55,901][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 5.241    Value Loss: 5.300    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 141506     Buffer Size: 22019      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:12:18,677][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.051    [weighted Loss:2.051    Policy Loss: 4.656    Value Loss: 5.638    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 142230     Buffer Size: 22088      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:15:39,113][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.569    [weighted Loss:2.569    Policy Loss: 4.688    Value Loss: 5.646    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 142962     Buffer Size: 22170      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:19:01,785][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 5.330    Value Loss: 5.422    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 143680     Buffer Size: 22263      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:22:22,894][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 5.741    Value Loss: 5.312    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 144428     Buffer Size: 22351      Transition Number: 1500.080k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:25:46,983][train][INFO][train.py>_log] ==> #185000     Total Loss: 3.189    [weighted Loss:3.189    Policy Loss: 5.536    Value Loss: 5.577    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 145130     Buffer Size: 22447      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:29:09,098][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 5.276    Value Loss: 6.104    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 145868     Buffer Size: 22535      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:32:30,106][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 5.115    Value Loss: 5.676    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 146567     Buffer Size: 22645      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:35:51,252][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.677    [weighted Loss:2.677    Policy Loss: 5.559    Value Loss: 5.538    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 147297     Buffer Size: 22744      Transition Number: 1500.052k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:39:13,430][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 5.021    Value Loss: 6.073    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 148007     Buffer Size: 22844      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:42:35,132][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.425    [weighted Loss:1.425    Policy Loss: 5.511    Value Loss: 6.084    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 148740     Buffer Size: 22937      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:45:56,168][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 5.081    Value Loss: 5.951    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 149405     Buffer Size: 23006      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:49:16,864][train][INFO][train.py>_log] ==> #192000     Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 5.462    Value Loss: 5.463    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 150135     Buffer Size: 23084      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:52:37,115][train][INFO][train.py>_log] ==> #193000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 4.724    Value Loss: 5.404    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 150789     Buffer Size: 23132      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:55:59,611][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 5.238    Value Loss: 5.900    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 151517     Buffer Size: 23155      Transition Number: 1500.148k Batch Size: 256        Lr: 0.10000 
[2022-01-10 11:59:21,986][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 5.278    Value Loss: 5.645    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 152250     Buffer Size: 23217      Transition Number: 1499.927k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:02:42,431][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 4.894    Value Loss: 5.635    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 152982     Buffer Size: 23333      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:06:04,122][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.469    [weighted Loss:2.469    Policy Loss: 5.211    Value Loss: 5.549    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 153643     Buffer Size: 23364      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:09:22,506][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 5.465    Value Loss: 5.510    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 154287     Buffer Size: 23407      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:12:42,613][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 5.337    Value Loss: 5.541    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 155021     Buffer Size: 23470      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:16:01,244][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.428    [weighted Loss:1.428    Policy Loss: 5.127    Value Loss: 5.469    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 155682     Buffer Size: 23545      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:19:23,117][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 5.243    Value Loss: 5.567    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 156330     Buffer Size: 23606      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:22:43,688][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 4.938    Value Loss: 5.933    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 157043     Buffer Size: 23669      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:26:06,998][train][INFO][train.py>_log] ==> #203000     Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 5.211    Value Loss: 5.928    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 157980     Buffer Size: 24026      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:29:28,556][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 5.018    Value Loss: 5.673    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 159005     Buffer Size: 24370      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:32:50,666][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 5.392    Value Loss: 5.797    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 159654     Buffer Size: 24432      Transition Number: 1499.931k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:36:10,417][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 4.783    Value Loss: 5.987    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 160373     Buffer Size: 24511      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:39:31,255][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 4.989    Value Loss: 5.846    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 161122     Buffer Size: 24576      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:42:50,888][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 4.912    Value Loss: 5.818    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 161767     Buffer Size: 24649      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:46:12,145][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.257    [weighted Loss:2.257    Policy Loss: 4.565    Value Loss: 5.782    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 162494     Buffer Size: 24718      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:49:34,992][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.581    [weighted Loss:2.581    Policy Loss: 5.417    Value Loss: 5.617    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 163215     Buffer Size: 24795      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:52:56,536][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.092    [weighted Loss:2.092    Policy Loss: 4.748    Value Loss: 5.602    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 163886     Buffer Size: 24832      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:56:19,237][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.950    [weighted Loss:1.950    Policy Loss: 4.972    Value Loss: 5.798    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 164585     Buffer Size: 24852      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 12:59:40,140][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 4.671    Value Loss: 5.758    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 165261     Buffer Size: 24886      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:03:03,861][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.292    [weighted Loss:1.292    Policy Loss: 4.537    Value Loss: 5.764    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 165950     Buffer Size: 24900      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:06:23,364][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.082    [weighted Loss:2.082    Policy Loss: 4.476    Value Loss: 5.949    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 166678     Buffer Size: 24894      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:09:44,094][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 4.082    Value Loss: 6.137    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 167323     Buffer Size: 24880      Transition Number: 1500.071k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:13:05,711][train][INFO][train.py>_log] ==> #217000     Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 4.074    Value Loss: 6.169    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 168003     Buffer Size: 24865      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:16:25,959][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 3.833    Value Loss: 5.764    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 168661     Buffer Size: 24847      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:19:45,301][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 3.975    Value Loss: 6.056    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 169370     Buffer Size: 24854      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:23:10,366][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 3.804    Value Loss: 6.161    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 170086     Buffer Size: 24852      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:26:30,818][train][INFO][train.py>_log] ==> #221000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 3.927    Value Loss: 5.733    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 170803     Buffer Size: 24845      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:29:53,341][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 3.557    Value Loss: 5.706    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 171508     Buffer Size: 24829      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:33:14,170][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 3.863    Value Loss: 5.693    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 172199     Buffer Size: 24793      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:36:35,950][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 3.816    Value Loss: 5.538    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 172876     Buffer Size: 24761      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:39:58,149][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 4.171    Value Loss: 5.736    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 173563     Buffer Size: 24728      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:43:22,451][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 4.152    Value Loss: 5.732    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 174275     Buffer Size: 24716      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:46:43,082][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 4.092    Value Loss: 5.434    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 174983     Buffer Size: 24678      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:50:06,651][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 3.572    Value Loss: 5.791    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 175706     Buffer Size: 24685      Transition Number: 1500.162k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:53:28,984][train][INFO][train.py>_log] ==> #229000     Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 3.691    Value Loss: 5.769    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 176448     Buffer Size: 24734      Transition Number: 1500.142k Batch Size: 256        Lr: 0.10000 
[2022-01-10 13:56:51,628][train][INFO][train.py>_log] ==> #230000     Total Loss: 0.830    [weighted Loss:0.830    Policy Loss: 3.999    Value Loss: 5.658    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 177188     Buffer Size: 24740      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:00:13,455][train][INFO][train.py>_log] ==> #231000     Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 4.083    Value Loss: 5.939    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 177915     Buffer Size: 24708      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:03:33,969][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 4.148    Value Loss: 5.826    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 178603     Buffer Size: 24729      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:06:59,096][train][INFO][train.py>_log] ==> #233000     Total Loss: 0.971    [weighted Loss:0.971    Policy Loss: 4.774    Value Loss: 5.311    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 179337     Buffer Size: 24725      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:10:23,483][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 3.884    Value Loss: 6.179    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 180027     Buffer Size: 24719      Transition Number: 1500.092k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:13:45,918][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 4.684    Value Loss: 5.769    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 180722     Buffer Size: 24724      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:17:09,750][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.407    [weighted Loss:2.407    Policy Loss: 4.526    Value Loss: 5.694    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 181399     Buffer Size: 24733      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:20:33,127][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 5.210    Value Loss: 5.414    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 182224     Buffer Size: 24705      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:23:54,395][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 4.403    Value Loss: 5.583    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 183049     Buffer Size: 24561      Transition Number: 1500.101k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:27:16,771][train][INFO][train.py>_log] ==> #239000     Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 4.259    Value Loss: 5.711    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 183910     Buffer Size: 24571      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:30:40,561][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 3.911    Value Loss: 6.026    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 184749     Buffer Size: 24712      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:34:04,846][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 4.450    Value Loss: 5.865    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 185486     Buffer Size: 24756      Transition Number: 1500.263k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:37:27,110][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 3.659    Value Loss: 5.654    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 186216     Buffer Size: 24768      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:40:47,043][train][INFO][train.py>_log] ==> #243000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 4.113    Value Loss: 5.702    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 186855     Buffer Size: 24728      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:44:07,824][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 3.752    Value Loss: 5.721    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 187570     Buffer Size: 24695      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:47:31,422][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 4.069    Value Loss: 5.772    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 188283     Buffer Size: 24658      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:50:56,625][train][INFO][train.py>_log] ==> #246000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 3.768    Value Loss: 5.738    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 188971     Buffer Size: 24630      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:54:19,934][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 4.489    Value Loss: 5.367    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 189635     Buffer Size: 24601      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 14:57:42,601][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 3.826    Value Loss: 5.542    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 190323     Buffer Size: 24561      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:01:06,857][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 4.228    Value Loss: 5.655    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 191033     Buffer Size: 24578      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:04:33,133][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 4.506    Value Loss: 5.695    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 191768     Buffer Size: 24621      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:07:55,161][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 4.406    Value Loss: 5.983    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 192478     Buffer Size: 24654      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:11:21,525][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 4.685    Value Loss: 6.212    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 193205     Buffer Size: 24675      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:14:41,577][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 4.559    Value Loss: 5.747    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 193889     Buffer Size: 24678      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:18:04,399][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 4.139    Value Loss: 5.531    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 194570     Buffer Size: 24678      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:21:27,234][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 5.062    Value Loss: 5.530    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 195327     Buffer Size: 24688      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:24:48,158][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 4.164    Value Loss: 5.896    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 196017     Buffer Size: 24707      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:28:12,876][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 4.262    Value Loss: 5.629    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 196720     Buffer Size: 24692      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:31:36,165][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 4.328    Value Loss: 5.456    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 197432     Buffer Size: 24685      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:35:00,843][train][INFO][train.py>_log] ==> #259000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 4.537    Value Loss: 5.725    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 198125     Buffer Size: 24682      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:38:24,674][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.308    [weighted Loss:1.308    Policy Loss: 3.935    Value Loss: 5.849    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 198801     Buffer Size: 24687      Transition Number: 1500.128k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:41:47,325][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 4.316    Value Loss: 6.070    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 199512     Buffer Size: 24679      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:45:09,858][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 3.630    Value Loss: 5.772    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 200176     Buffer Size: 24676      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:48:33,098][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 4.535    Value Loss: 5.848    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 200876     Buffer Size: 24637      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:51:54,588][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 4.073    Value Loss: 5.596    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 201573     Buffer Size: 24554      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:55:21,292][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 4.423    Value Loss: 5.402    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 202382     Buffer Size: 24629      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 15:58:44,807][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 5.891    Value Loss: 5.718    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 203204     Buffer Size: 24762      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:02:07,574][train][INFO][train.py>_log] ==> #267000     Total Loss: 1.948    [weighted Loss:1.948    Policy Loss: 4.830    Value Loss: 6.552    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 204421     Buffer Size: 25298      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:05:28,516][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 4.374    Value Loss: 5.990    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 205586     Buffer Size: 25796      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:08:51,738][train][INFO][train.py>_log] ==> #269000     Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 4.078    Value Loss: 5.708    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 206406     Buffer Size: 25959      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:12:15,051][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 4.279    Value Loss: 6.228    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 207244     Buffer Size: 26136      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:15:36,360][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.071    Value Loss: 5.870    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 207995     Buffer Size: 26174      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:18:58,651][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 3.968    Value Loss: 6.064    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 208742     Buffer Size: 26110      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:22:21,779][train][INFO][train.py>_log] ==> #273000     Total Loss: 1.555    [weighted Loss:1.555    Policy Loss: 3.997    Value Loss: 5.909    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 209471     Buffer Size: 25997      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:25:44,901][train][INFO][train.py>_log] ==> #274000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 3.989    Value Loss: 5.936    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 210187     Buffer Size: 25839      Transition Number: 1500.130k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:29:07,531][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 4.071    Value Loss: 5.658    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 210891     Buffer Size: 25738      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:32:29,643][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 3.793    Value Loss: 5.953    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 211573     Buffer Size: 25705      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:35:50,441][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.267    [weighted Loss:1.267    Policy Loss: 3.940    Value Loss: 5.669    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 212288     Buffer Size: 25703      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:39:12,766][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 3.855    Value Loss: 5.836    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 212965     Buffer Size: 25743      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:42:34,916][train][INFO][train.py>_log] ==> #279000     Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 3.940    Value Loss: 5.480    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 213696     Buffer Size: 25781      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:45:59,012][train][INFO][train.py>_log] ==> #280000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 3.650    Value Loss: 5.751    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 214373     Buffer Size: 25815      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:49:23,037][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 5.304    Value Loss: 5.478    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 215066     Buffer Size: 25860      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:52:47,631][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 3.788    Value Loss: 5.788    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 215790     Buffer Size: 25894      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:56:10,188][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 4.289    Value Loss: 6.243    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 216575     Buffer Size: 26007      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 16:59:33,027][train][INFO][train.py>_log] ==> #284000     Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 4.064    Value Loss: 5.859    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 217389     Buffer Size: 26081      Transition Number: 1500.090k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:02:54,499][train][INFO][train.py>_log] ==> #285000     Total Loss: 1.243    [weighted Loss:1.243    Policy Loss: 4.755    Value Loss: 6.154    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 218084     Buffer Size: 26088      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:06:16,755][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 4.175    Value Loss: 5.775    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 218764     Buffer Size: 26089      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:09:38,552][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 4.097    Value Loss: 5.935    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 219483     Buffer Size: 26076      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:13:01,643][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.444    [weighted Loss:1.444    Policy Loss: 3.997    Value Loss: 6.229    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 220172     Buffer Size: 26077      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:16:21,023][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 3.891    Value Loss: 6.055    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 220921     Buffer Size: 26135      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:19:43,619][train][INFO][train.py>_log] ==> #290000     Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 3.737    Value Loss: 5.830    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 221708     Buffer Size: 26183      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:23:06,221][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.484    [weighted Loss:1.484    Policy Loss: 4.241    Value Loss: 5.879    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 222380     Buffer Size: 26194      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:26:29,957][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 4.128    Value Loss: 5.892    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 223130     Buffer Size: 26229      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:29:53,297][train][INFO][train.py>_log] ==> #293000     Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 4.222    Value Loss: 5.644    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 223790     Buffer Size: 26245      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:33:17,669][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 3.942    Value Loss: 5.911    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 224479     Buffer Size: 26249      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:36:40,280][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 4.238    Value Loss: 5.855    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 225212     Buffer Size: 26266      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:40:01,811][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 3.965    Value Loss: 5.808    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 225853     Buffer Size: 26283      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:43:25,571][train][INFO][train.py>_log] ==> #297000     Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 4.340    Value Loss: 5.994    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 226592     Buffer Size: 26319      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:46:47,017][train][INFO][train.py>_log] ==> #298000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 4.105    Value Loss: 6.068    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 227266     Buffer Size: 26351      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:50:09,964][train][INFO][train.py>_log] ==> #299000     Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 4.314    Value Loss: 5.802    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 228030     Buffer Size: 26410      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:53:34,120][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 4.841    Value Loss: 6.122    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 228787     Buffer Size: 26353      Transition Number: 1500.140k Batch Size: 256        Lr: 0.10000 
[2022-01-10 17:56:56,011][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 4.532    Value Loss: 6.081    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 229528     Buffer Size: 26273      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:00:24,681][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 4.533    Value Loss: 6.025    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 230308     Buffer Size: 25801      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:03:51,123][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 4.491    Value Loss: 5.684    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 231033     Buffer Size: 25366      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:07:14,559][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 4.137    Value Loss: 5.439    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 231737     Buffer Size: 25269      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:10:41,182][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 4.297    Value Loss: 6.153    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 232496     Buffer Size: 25136      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:14:05,383][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 4.725    Value Loss: 5.696    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 233257     Buffer Size: 25084      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:17:28,639][train][INFO][train.py>_log] ==> #307000     Total Loss: 1.865    [weighted Loss:1.865    Policy Loss: 4.309    Value Loss: 6.349    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 233997     Buffer Size: 25118      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:20:53,167][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 3.851    Value Loss: 5.958    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 234808     Buffer Size: 25171      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:24:14,566][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 4.473    Value Loss: 5.979    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 235510     Buffer Size: 25172      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:27:39,445][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 3.957    Value Loss: 6.109    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 236176     Buffer Size: 25161      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:31:02,459][train][INFO][train.py>_log] ==> #311000     Total Loss: 1.045    [weighted Loss:1.045    Policy Loss: 4.389    Value Loss: 5.918    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 236898     Buffer Size: 25148      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:34:24,871][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 4.747    Value Loss: 5.562    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 237596     Buffer Size: 25114      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:37:47,632][train][INFO][train.py>_log] ==> #313000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 4.372    Value Loss: 5.700    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 238358     Buffer Size: 25197      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:41:08,823][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 4.152    Value Loss: 6.337    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 239148     Buffer Size: 25276      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:44:33,309][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.577    [weighted Loss:1.577    Policy Loss: 4.492    Value Loss: 5.716    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 239871     Buffer Size: 25319      Transition Number: 1500.102k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:47:56,534][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 3.938    Value Loss: 5.868    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 240612     Buffer Size: 25366      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:51:19,624][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.544    [weighted Loss:1.544    Policy Loss: 4.515    Value Loss: 6.314    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 241341     Buffer Size: 25347      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:54:44,648][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 4.079    Value Loss: 5.861    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 242024     Buffer Size: 25258      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-10 18:58:09,188][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 4.723    Value Loss: 5.771    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 242732     Buffer Size: 25183      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:01:34,541][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 4.160    Value Loss: 5.798    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 243477     Buffer Size: 25173      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:04:56,220][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.747    Value Loss: 6.587    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 244119     Buffer Size: 25176      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:08:20,407][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 4.419    Value Loss: 5.872    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 244814     Buffer Size: 25175      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:11:45,165][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.682    Value Loss: 6.162    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 245551     Buffer Size: 25172      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:15:10,362][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 4.086    Value Loss: 6.004    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 246247     Buffer Size: 25124      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:18:34,338][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 5.154    Value Loss: 6.116    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 247031     Buffer Size: 25122      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:21:58,147][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 4.636    Value Loss: 6.285    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 247823     Buffer Size: 25196      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:25:24,275][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 5.233    Value Loss: 5.802    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 248511     Buffer Size: 25216      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:28:47,746][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.694    [weighted Loss:2.694    Policy Loss: 4.445    Value Loss: 6.233    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 249264     Buffer Size: 25268      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:32:09,740][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 4.844    Value Loss: 5.780    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 249940     Buffer Size: 25294      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:35:33,536][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 4.869    Value Loss: 6.039    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 250635     Buffer Size: 25305      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:38:57,130][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 4.954    Value Loss: 6.188    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 251381     Buffer Size: 25304      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:42:21,762][train][INFO][train.py>_log] ==> #332000     Total Loss: 3.171    [weighted Loss:3.171    Policy Loss: 4.796    Value Loss: 6.388    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 252064     Buffer Size: 25289      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:45:43,907][train][INFO][train.py>_log] ==> #333000     Total Loss: 2.490    [weighted Loss:2.490    Policy Loss: 5.762    Value Loss: 6.248    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 252758     Buffer Size: 25301      Transition Number: 1500.149k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:49:09,905][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 5.612    Value Loss: 6.051    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 253463     Buffer Size: 25266      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:52:32,960][train][INFO][train.py>_log] ==> #335000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 5.597    Value Loss: 6.066    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 254231     Buffer Size: 25277      Transition Number: 1500.097k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:55:52,822][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 5.363    Value Loss: 6.093    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 254927     Buffer Size: 25249      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-10 19:59:16,304][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.079    [weighted Loss:3.079    Policy Loss: 5.192    Value Loss: 6.242    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 255755     Buffer Size: 25321      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:02:40,501][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 5.063    Value Loss: 5.834    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 256595     Buffer Size: 25470      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:06:03,281][train][INFO][train.py>_log] ==> #339000     Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 5.109    Value Loss: 6.437    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 257348     Buffer Size: 25513      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:09:28,899][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 5.343    Value Loss: 6.163    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 258145     Buffer Size: 25558      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:12:53,734][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 5.073    Value Loss: 6.098    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 258905     Buffer Size: 25592      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:16:17,461][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 5.027    Value Loss: 5.943    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 259628     Buffer Size: 25583      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:19:43,393][train][INFO][train.py>_log] ==> #343000     Total Loss: 1.174    [weighted Loss:1.174    Policy Loss: 5.724    Value Loss: 6.288    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 260385     Buffer Size: 25539      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:23:05,852][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.802    [weighted Loss:2.802    Policy Loss: 4.598    Value Loss: 5.944    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 261098     Buffer Size: 25593      Transition Number: 1500.130k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:26:29,299][train][INFO][train.py>_log] ==> #345000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 4.827    Value Loss: 6.062    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 261804     Buffer Size: 25657      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:29:52,118][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 5.490    Value Loss: 6.269    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 262553     Buffer Size: 25722      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:33:14,664][train][INFO][train.py>_log] ==> #347000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 4.995    Value Loss: 6.383    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 263437     Buffer Size: 25914      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:36:34,479][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 5.765    Value Loss: 6.431    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 264278     Buffer Size: 26017      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:39:59,101][train][INFO][train.py>_log] ==> #349000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 5.334    Value Loss: 6.496    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 265129     Buffer Size: 26069      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:43:25,793][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 4.930    Value Loss: 6.241    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 265937     Buffer Size: 26152      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:46:50,470][train][INFO][train.py>_log] ==> #351000     Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 4.772    Value Loss: 6.710    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 266825     Buffer Size: 26272      Transition Number: 1500.085k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:50:14,089][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 4.441    Value Loss: 6.388    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 267742     Buffer Size: 26488      Transition Number: 1500.217k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:53:36,593][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.071    [weighted Loss:2.071    Policy Loss: 4.411    Value Loss: 6.274    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 268524     Buffer Size: 26636      Transition Number: 1500.204k Batch Size: 256        Lr: 0.10000 
[2022-01-10 20:56:58,845][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 4.984    Value Loss: 6.593    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 269387     Buffer Size: 26775      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:00:21,029][train][INFO][train.py>_log] ==> #355000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 5.836    Value Loss: 6.335    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 270200     Buffer Size: 26924      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:03:44,139][train][INFO][train.py>_log] ==> #356000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 4.528    Value Loss: 6.187    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 271069     Buffer Size: 27075      Transition Number: 1500.269k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:07:05,269][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 5.204    Value Loss: 6.354    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 271824     Buffer Size: 27156      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:10:27,655][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 4.590    Value Loss: 6.273    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 272545     Buffer Size: 27210      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:13:49,635][train][INFO][train.py>_log] ==> #359000     Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 4.825    Value Loss: 6.763    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 273321     Buffer Size: 27265      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:17:11,152][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.600    [weighted Loss:2.600    Policy Loss: 5.101    Value Loss: 6.726    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 274010     Buffer Size: 27284      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:20:34,054][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 5.404    Value Loss: 6.762    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 274931     Buffer Size: 27416      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:23:56,756][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 5.112    Value Loss: 6.720    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 275826     Buffer Size: 27588      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:27:18,205][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 5.329    Value Loss: 6.910    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 276924     Buffer Size: 27964      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:30:41,875][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 5.348    Value Loss: 6.722    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 278082     Buffer Size: 28392      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:34:01,796][train][INFO][train.py>_log] ==> #365000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 5.862    Value Loss: 6.758    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 278952     Buffer Size: 28631      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:37:24,316][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.745    [weighted Loss:1.745    Policy Loss: 5.101    Value Loss: 6.768    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 279909     Buffer Size: 28876      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:40:45,479][train][INFO][train.py>_log] ==> #367000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 5.127    Value Loss: 6.849    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 280765     Buffer Size: 29045      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:44:08,031][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.709    [weighted Loss:2.709    Policy Loss: 5.398    Value Loss: 6.340    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 281572     Buffer Size: 29189      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:47:33,288][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 4.946    Value Loss: 7.068    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 282674     Buffer Size: 29557      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:50:56,384][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 4.993    Value Loss: 6.899    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 283818     Buffer Size: 29982      Transition Number: 1500.102k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:54:14,919][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 4.971    Value Loss: 6.834    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 284651     Buffer Size: 30133      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-10 21:57:38,058][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 4.799    Value Loss: 7.138    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 285537     Buffer Size: 30247      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:01:02,414][train][INFO][train.py>_log] ==> #373000     Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 5.473    Value Loss: 6.635    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 286443     Buffer Size: 30326      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:04:25,758][train][INFO][train.py>_log] ==> #374000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 4.952    Value Loss: 7.221    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 287337     Buffer Size: 30393      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:07:52,080][train][INFO][train.py>_log] ==> #375000     Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 4.940    Value Loss: 6.595    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 288212     Buffer Size: 30507      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:11:14,033][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 4.796    Value Loss: 7.081    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 289068     Buffer Size: 30612      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:14:37,044][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 4.854    Value Loss: 6.855    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 289868     Buffer Size: 30662      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:17:58,777][train][INFO][train.py>_log] ==> #378000     Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 4.668    Value Loss: 6.637    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 290664     Buffer Size: 30747      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:21:19,928][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 4.980    Value Loss: 6.901    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 291544     Buffer Size: 30874      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:24:43,239][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 6.395    Value Loss: 7.071    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 292392     Buffer Size: 30987      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:28:05,487][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 5.039    Value Loss: 6.473    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 293311     Buffer Size: 31197      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:31:25,855][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 5.506    Value Loss: 7.083    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 294270     Buffer Size: 31379      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:34:47,167][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 4.789    Value Loss: 7.282    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 295426     Buffer Size: 31621      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:38:06,360][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 5.549    Value Loss: 7.364    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 296568     Buffer Size: 31902      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:41:26,188][train][INFO][train.py>_log] ==> #385000     Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 6.127    Value Loss: 6.828    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 297393     Buffer Size: 31996      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:44:47,372][train][INFO][train.py>_log] ==> #386000     Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 5.306    Value Loss: 6.537    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 298333     Buffer Size: 32052      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:48:07,073][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.963    [weighted Loss:1.963    Policy Loss: 4.995    Value Loss: 6.772    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 299090     Buffer Size: 31975      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:51:30,022][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.222    [weighted Loss:2.222    Policy Loss: 4.994    Value Loss: 6.972    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 299853     Buffer Size: 31859      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:54:50,203][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.915    [weighted Loss:2.915    Policy Loss: 5.453    Value Loss: 7.057    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 300689     Buffer Size: 31860      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-10 22:58:12,384][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 6.427    Value Loss: 7.285    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 301484     Buffer Size: 31903      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:01:34,410][train][INFO][train.py>_log] ==> #391000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 5.152    Value Loss: 7.231    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 302638     Buffer Size: 32129      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:04:56,338][train][INFO][train.py>_log] ==> #392000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 6.070    Value Loss: 7.350    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 303760     Buffer Size: 32408      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:08:15,165][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 5.952    Value Loss: 7.220    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 304991     Buffer Size: 32882      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:11:35,725][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 6.630    Value Loss: 7.036    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 306241     Buffer Size: 33381      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:14:54,383][train][INFO][train.py>_log] ==> #395000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 5.909    Value Loss: 6.990    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 307392     Buffer Size: 33785      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:18:14,910][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 6.517    Value Loss: 7.225    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 308566     Buffer Size: 34136      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:21:32,992][train][INFO][train.py>_log] ==> #397000     Total Loss: 2.996    [weighted Loss:2.996    Policy Loss: 5.943    Value Loss: 7.083    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 309901     Buffer Size: 34565      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:24:52,924][train][INFO][train.py>_log] ==> #398000     Total Loss: 3.550    [weighted Loss:3.550    Policy Loss: 6.750    Value Loss: 6.845    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 311263     Buffer Size: 34918      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:28:13,334][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 7.428    Value Loss: 7.477    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 312270     Buffer Size: 34890      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:31:30,096][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 6.561    Value Loss: 7.002    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 313283     Buffer Size: 34814      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:34:49,808][train][INFO][train.py>_log] ==> #401000     Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 6.450    Value Loss: 7.163    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 314287     Buffer Size: 34877      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:38:09,872][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.830    [weighted Loss:2.830    Policy Loss: 6.353    Value Loss: 7.499    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 315320     Buffer Size: 34989      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:41:31,946][train][INFO][train.py>_log] ==> #403000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 6.433    Value Loss: 7.075    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 316663     Buffer Size: 35454      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:44:49,381][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 6.666    Value Loss: 7.484    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 317954     Buffer Size: 35833      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:48:09,609][train][INFO][train.py>_log] ==> #405000     Total Loss: 3.423    [weighted Loss:3.423    Policy Loss: 8.147    Value Loss: 7.051    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 319102     Buffer Size: 35883      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:51:27,395][train][INFO][train.py>_log] ==> #406000     Total Loss: 3.871    [weighted Loss:3.871    Policy Loss: 7.151    Value Loss: 6.955    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 320208     Buffer Size: 35946      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:54:47,833][train][INFO][train.py>_log] ==> #407000     Total Loss: 3.153    [weighted Loss:3.153    Policy Loss: 7.428    Value Loss: 6.931    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 321387     Buffer Size: 36280      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-10 23:58:09,101][train][INFO][train.py>_log] ==> #408000     Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 6.588    Value Loss: 6.959    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 322566     Buffer Size: 36549      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:01:26,928][train][INFO][train.py>_log] ==> #409000     Total Loss: 3.834    [weighted Loss:3.834    Policy Loss: 6.464    Value Loss: 7.677    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 323513     Buffer Size: 36638      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:04:46,324][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 6.066    Value Loss: 7.212    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 324447     Buffer Size: 36722      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:08:08,363][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 7.042    Value Loss: 7.302    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 325540     Buffer Size: 36921      Transition Number: 1500.061k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:11:28,813][train][INFO][train.py>_log] ==> #412000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 5.827    Value Loss: 7.019    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 326575     Buffer Size: 37136      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:14:45,551][train][INFO][train.py>_log] ==> #413000     Total Loss: 4.187    [weighted Loss:4.187    Policy Loss: 7.601    Value Loss: 7.217    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 327749     Buffer Size: 37504      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:18:04,218][train][INFO][train.py>_log] ==> #414000     Total Loss: 3.508    [weighted Loss:3.508    Policy Loss: 7.383    Value Loss: 7.283    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 328926     Buffer Size: 37823      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:21:22,668][train][INFO][train.py>_log] ==> #415000     Total Loss: 3.413    [weighted Loss:3.413    Policy Loss: 7.843    Value Loss: 7.150    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 330045     Buffer Size: 38080      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:24:40,780][train][INFO][train.py>_log] ==> #416000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 7.059    Value Loss: 7.073    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 331144     Buffer Size: 38286      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:28:01,874][train][INFO][train.py>_log] ==> #417000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 9.307    Value Loss: 7.509    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 332254     Buffer Size: 38459      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:31:22,584][train][INFO][train.py>_log] ==> #418000     Total Loss: 3.860    [weighted Loss:3.860    Policy Loss: 8.119    Value Loss: 7.193    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 333373     Buffer Size: 38519      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:34:41,728][train][INFO][train.py>_log] ==> #419000     Total Loss: 4.264    [weighted Loss:4.264    Policy Loss: 9.137    Value Loss: 7.507    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 334650     Buffer Size: 38645      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:38:00,598][train][INFO][train.py>_log] ==> #420000     Total Loss: 3.383    [weighted Loss:3.383    Policy Loss: 8.250    Value Loss: 7.129    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 335874     Buffer Size: 38832      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:41:17,432][train][INFO][train.py>_log] ==> #421000     Total Loss: 3.188    [weighted Loss:3.188    Policy Loss: 8.572    Value Loss: 7.329    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 337217     Buffer Size: 39275      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:44:35,434][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 8.658    Value Loss: 7.279    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 338576     Buffer Size: 39799      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:47:55,596][train][INFO][train.py>_log] ==> #423000     Total Loss: 1.294    [weighted Loss:1.294    Policy Loss: 8.059    Value Loss: 7.091    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 340013     Buffer Size: 40405      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:51:14,788][train][INFO][train.py>_log] ==> #424000     Total Loss: 3.436    [weighted Loss:3.436    Policy Loss: 7.748    Value Loss: 7.164    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 341386     Buffer Size: 40966      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:54:32,413][train][INFO][train.py>_log] ==> #425000     Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 8.784    Value Loss: 7.341    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 342626     Buffer Size: 41375      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-11 00:57:49,791][train][INFO][train.py>_log] ==> #426000     Total Loss: 4.914    [weighted Loss:4.914    Policy Loss: 8.182    Value Loss: 7.120    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 343923     Buffer Size: 41688      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:01:03,737][train][INFO][train.py>_log] ==> #427000     Total Loss: 4.362    [weighted Loss:4.362    Policy Loss: 7.803    Value Loss: 7.185    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 344959     Buffer Size: 41683      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:04:18,644][train][INFO][train.py>_log] ==> #428000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 7.362    Value Loss: 7.196    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 346002     Buffer Size: 41574      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:07:38,763][train][INFO][train.py>_log] ==> #429000     Total Loss: 3.319    [weighted Loss:3.319    Policy Loss: 7.975    Value Loss: 7.177    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 347137     Buffer Size: 41514      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:10:54,832][train][INFO][train.py>_log] ==> #430000     Total Loss: 2.320    [weighted Loss:2.320    Policy Loss: 6.905    Value Loss: 6.933    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 348267     Buffer Size: 41457      Transition Number: 1500.130k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:14:09,861][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 7.732    Value Loss: 7.333    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 349173     Buffer Size: 41300      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:17:28,264][train][INFO][train.py>_log] ==> #432000     Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 8.466    Value Loss: 7.552    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 350110     Buffer Size: 41035      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:20:48,786][train][INFO][train.py>_log] ==> #433000     Total Loss: 5.307    [weighted Loss:5.307    Policy Loss: 7.207    Value Loss: 7.014    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 351114     Buffer Size: 40713      Transition Number: 1500.115k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:24:04,670][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.788    [weighted Loss:3.788    Policy Loss: 7.953    Value Loss: 7.342    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 352032     Buffer Size: 40429      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:27:25,392][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 7.468    Value Loss: 6.991    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 353399     Buffer Size: 40746      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:30:42,331][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 7.204    Value Loss: 7.080    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 354803     Buffer Size: 41121      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:34:00,226][train][INFO][train.py>_log] ==> #437000     Total Loss: 3.334    [weighted Loss:3.334    Policy Loss: 7.438    Value Loss: 7.524    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 356292     Buffer Size: 41570      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:37:14,209][train][INFO][train.py>_log] ==> #438000     Total Loss: 3.912    [weighted Loss:3.912    Policy Loss: 8.454    Value Loss: 7.255    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 357766     Buffer Size: 41974      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:40:30,806][train][INFO][train.py>_log] ==> #439000     Total Loss: 3.870    [weighted Loss:3.870    Policy Loss: 6.625    Value Loss: 7.236    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 359017     Buffer Size: 41951      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:43:47,993][train][INFO][train.py>_log] ==> #440000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 7.374    Value Loss: 7.460    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 360284     Buffer Size: 41909      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:47:06,564][train][INFO][train.py>_log] ==> #441000     Total Loss: 4.905    [weighted Loss:4.905    Policy Loss: 8.509    Value Loss: 7.207    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 361207     Buffer Size: 41745      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:50:23,281][train][INFO][train.py>_log] ==> #442000     Total Loss: 4.594    [weighted Loss:4.594    Policy Loss: 7.317    Value Loss: 7.119    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 362136     Buffer Size: 41601      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:53:41,928][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.295    [weighted Loss:3.295    Policy Loss: 7.173    Value Loss: 7.277    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 363338     Buffer Size: 41556      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-11 01:56:59,346][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.239    [weighted Loss:2.239    Policy Loss: 9.083    Value Loss: 6.993    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 364503     Buffer Size: 41607      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:00:20,218][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 8.119    Value Loss: 7.179    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 367307     Buffer Size: 43331      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:03:37,625][train][INFO][train.py>_log] ==> #446000     Total Loss: 5.234    [weighted Loss:5.234    Policy Loss: 9.634    Value Loss: 7.690    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 370032     Buffer Size: 44966      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:06:55,178][train][INFO][train.py>_log] ==> #447000     Total Loss: 4.452    [weighted Loss:4.452    Policy Loss: 8.705    Value Loss: 7.193    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 372088     Buffer Size: 45948      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:10:14,257][train][INFO][train.py>_log] ==> #448000     Total Loss: 3.525    [weighted Loss:3.525    Policy Loss: 8.838    Value Loss: 7.155    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 374106     Buffer Size: 46848      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:13:28,892][train][INFO][train.py>_log] ==> #449000     Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 8.806    Value Loss: 7.155    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 375236     Buffer Size: 46870      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:16:42,882][train][INFO][train.py>_log] ==> #450000     Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 9.094    Value Loss: 7.175    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 376414     Buffer Size: 46911      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:19:57,219][train][INFO][train.py>_log] ==> #451000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 7.893    Value Loss: 7.826    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 377637     Buffer Size: 47014      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:23:14,436][train][INFO][train.py>_log] ==> #452000     Total Loss: 4.355    [weighted Loss:4.355    Policy Loss: 9.464    Value Loss: 7.311    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 378871     Buffer Size: 47204      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:26:31,576][train][INFO][train.py>_log] ==> #453000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 7.223    Value Loss: 7.097    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 380017     Buffer Size: 47266      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:29:48,678][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 8.091    Value Loss: 7.077    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 381230     Buffer Size: 47272      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:33:03,562][train][INFO][train.py>_log] ==> #455000     Total Loss: 4.715    [weighted Loss:4.715    Policy Loss: 9.165    Value Loss: 7.395    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 382264     Buffer Size: 47159      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:36:19,787][train][INFO][train.py>_log] ==> #456000     Total Loss: 4.466    [weighted Loss:4.466    Policy Loss: 8.276    Value Loss: 7.396    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 383304     Buffer Size: 46966      Transition Number: 1500.159k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:39:37,315][train][INFO][train.py>_log] ==> #457000     Total Loss: 4.991    [weighted Loss:4.991    Policy Loss: 8.392    Value Loss: 7.595    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 384268     Buffer Size: 46654      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:42:52,288][train][INFO][train.py>_log] ==> #458000     Total Loss: 4.348    [weighted Loss:4.348    Policy Loss: 7.749    Value Loss: 7.184    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 385275     Buffer Size: 46316      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:46:11,072][train][INFO][train.py>_log] ==> #459000     Total Loss: 5.478    [weighted Loss:5.478    Policy Loss: 10.045   Value Loss: 7.284    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 386183     Buffer Size: 45859      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:49:29,377][train][INFO][train.py>_log] ==> #460000     Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 7.871    Value Loss: 7.299    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 387073     Buffer Size: 45445      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:52:45,198][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 8.884    Value Loss: 7.218    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 388376     Buffer Size: 45517      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:56:02,331][train][INFO][train.py>_log] ==> #462000     Total Loss: 3.726    [weighted Loss:3.726    Policy Loss: 7.066    Value Loss: 7.067    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 389790     Buffer Size: 45656      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 02:59:20,910][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 6.441    Value Loss: 7.268    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 391349     Buffer Size: 46097      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:02:37,833][train][INFO][train.py>_log] ==> #464000     Total Loss: 3.267    [weighted Loss:3.267    Policy Loss: 8.222    Value Loss: 7.525    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 392919     Buffer Size: 46548      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:05:53,334][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.354    [weighted Loss:3.354    Policy Loss: 7.058    Value Loss: 7.721    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 394243     Buffer Size: 46770      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:09:12,515][train][INFO][train.py>_log] ==> #466000     Total Loss: 4.069    [weighted Loss:4.069    Policy Loss: 8.481    Value Loss: 7.680    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 395642     Buffer Size: 47023      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:12:30,672][train][INFO][train.py>_log] ==> #467000     Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 7.273    Value Loss: 7.036    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 396709     Buffer Size: 47136      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:15:44,747][train][INFO][train.py>_log] ==> #468000     Total Loss: 1.989    [weighted Loss:1.989    Policy Loss: 6.930    Value Loss: 7.038    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 397689     Buffer Size: 47170      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:19:03,041][train][INFO][train.py>_log] ==> #469000     Total Loss: 4.882    [weighted Loss:4.882    Policy Loss: 7.157    Value Loss: 6.963    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 398872     Buffer Size: 47392      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:22:20,773][train][INFO][train.py>_log] ==> #470000     Total Loss: 3.687    [weighted Loss:3.687    Policy Loss: 8.060    Value Loss: 7.189    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 400125     Buffer Size: 47547      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:25:39,036][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 6.966    Value Loss: 7.234    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 401465     Buffer Size: 47466      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:28:55,503][train][INFO][train.py>_log] ==> #472000     Total Loss: 3.181    [weighted Loss:3.181    Policy Loss: 7.438    Value Loss: 7.346    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 402848     Buffer Size: 47420      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:32:16,047][train][INFO][train.py>_log] ==> #473000     Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 6.880    Value Loss: 7.292    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 403720     Buffer Size: 46941      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:35:31,568][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 6.301    Value Loss: 7.132    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 404604     Buffer Size: 46489      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:38:49,574][train][INFO][train.py>_log] ==> #475000     Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 8.183    Value Loss: 7.226    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 405617     Buffer Size: 46194      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:42:03,432][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 7.832    Value Loss: 7.528    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 406536     Buffer Size: 45989      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:45:21,324][train][INFO][train.py>_log] ==> #477000     Total Loss: 3.333    [weighted Loss:3.333    Policy Loss: 7.439    Value Loss: 7.408    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 407718     Buffer Size: 46211      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:48:39,924][train][INFO][train.py>_log] ==> #478000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 6.796    Value Loss: 7.316    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 408972     Buffer Size: 46489      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:51:57,731][train][INFO][train.py>_log] ==> #479000     Total Loss: 3.047    [weighted Loss:3.047    Policy Loss: 7.747    Value Loss: 6.999    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 410016     Buffer Size: 46356      Transition Number: 1500.137k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:55:14,765][train][INFO][train.py>_log] ==> #480000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 6.360    Value Loss: 7.306    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 411035     Buffer Size: 46018      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 03:58:34,289][train][INFO][train.py>_log] ==> #481000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 7.042    Value Loss: 7.358    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 412153     Buffer Size: 44510      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:01:53,765][train][INFO][train.py>_log] ==> #482000     Total Loss: 1.642    [weighted Loss:1.642    Policy Loss: 6.086    Value Loss: 7.188    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 413266     Buffer Size: 43105      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:05:15,645][train][INFO][train.py>_log] ==> #483000     Total Loss: 4.237    [weighted Loss:4.237    Policy Loss: 6.380    Value Loss: 7.281    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 414162     Buffer Size: 42053      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:08:35,630][train][INFO][train.py>_log] ==> #484000     Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 5.397    Value Loss: 7.478    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 415082     Buffer Size: 40953      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:11:52,626][train][INFO][train.py>_log] ==> #485000     Total Loss: 3.028    [weighted Loss:3.028    Policy Loss: 6.610    Value Loss: 7.164    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 416055     Buffer Size: 40800      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:15:13,214][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 6.154    Value Loss: 7.318    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 417046     Buffer Size: 40658      Transition Number: 1500.165k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:18:34,583][train][INFO][train.py>_log] ==> #487000     Total Loss: 3.675    [weighted Loss:3.675    Policy Loss: 7.298    Value Loss: 7.296    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 418444     Buffer Size: 40758      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:21:54,076][train][INFO][train.py>_log] ==> #488000     Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 6.597    Value Loss: 7.455    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 419798     Buffer Size: 40825      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:25:11,460][train][INFO][train.py>_log] ==> #489000     Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 6.316    Value Loss: 7.307    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 420816     Buffer Size: 40730      Transition Number: 1500.122k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:28:29,741][train][INFO][train.py>_log] ==> #490000     Total Loss: 1.224    [weighted Loss:1.224    Policy Loss: 6.547    Value Loss: 6.957    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 421812     Buffer Size: 40539      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:31:44,517][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 7.458    Value Loss: 7.193    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 422888     Buffer Size: 40566      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:35:04,374][train][INFO][train.py>_log] ==> #492000     Total Loss: 4.116    [weighted Loss:4.116    Policy Loss: 6.811    Value Loss: 7.594    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 423972     Buffer Size: 40609      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:38:20,583][train][INFO][train.py>_log] ==> #493000     Total Loss: 3.850    [weighted Loss:3.850    Policy Loss: 7.727    Value Loss: 7.349    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 424959     Buffer Size: 40589      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:41:38,839][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 7.572    Value Loss: 7.173    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 425956     Buffer Size: 40604      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:44:57,030][train][INFO][train.py>_log] ==> #495000     Total Loss: 1.247    [weighted Loss:1.247    Policy Loss: 6.021    Value Loss: 7.196    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 427071     Buffer Size: 40808      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:48:18,794][train][INFO][train.py>_log] ==> #496000     Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 8.011    Value Loss: 7.359    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 428262     Buffer Size: 41020      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:51:35,924][train][INFO][train.py>_log] ==> #497000     Total Loss: 4.899    [weighted Loss:4.899    Policy Loss: 7.615    Value Loss: 7.592    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 429395     Buffer Size: 40808      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:54:55,782][train][INFO][train.py>_log] ==> #498000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 7.529    Value Loss: 7.418    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 430556     Buffer Size: 40523      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 04:58:14,510][train][INFO][train.py>_log] ==> #499000     Total Loss: 4.164    [weighted Loss:4.164    Policy Loss: 7.330    Value Loss: 7.385    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 431803     Buffer Size: 40215      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:01:34,412][train][INFO][train.py>_log] ==> #500000     Total Loss: 4.589    [weighted Loss:4.589    Policy Loss: 8.053    Value Loss: 7.649    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 433118     Buffer Size: 39935      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:04:54,925][train][INFO][train.py>_log] ==> #501000     Total Loss: 3.733    [weighted Loss:3.733    Policy Loss: 8.567    Value Loss: 7.315    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 434414     Buffer Size: 39877      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:08:12,299][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 8.327    Value Loss: 7.388    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 435723     Buffer Size: 39840      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:11:31,758][train][INFO][train.py>_log] ==> #503000     Total Loss: 4.478    [weighted Loss:4.478    Policy Loss: 8.367    Value Loss: 7.183    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 436944     Buffer Size: 40014      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:14:50,285][train][INFO][train.py>_log] ==> #504000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 9.206    Value Loss: 7.534    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 438154     Buffer Size: 40151      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:18:12,275][train][INFO][train.py>_log] ==> #505000     Total Loss: 3.194    [weighted Loss:3.194    Policy Loss: 6.894    Value Loss: 7.271    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 439287     Buffer Size: 40079      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:21:29,867][train][INFO][train.py>_log] ==> #506000     Total Loss: 4.034    [weighted Loss:4.034    Policy Loss: 6.854    Value Loss: 7.504    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 440431     Buffer Size: 39926      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:24:49,838][train][INFO][train.py>_log] ==> #507000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 8.099    Value Loss: 7.454    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 441535     Buffer Size: 39746      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:28:12,139][train][INFO][train.py>_log] ==> #508000     Total Loss: 1.898    [weighted Loss:1.898    Policy Loss: 7.264    Value Loss: 7.258    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 442689     Buffer Size: 39601      Transition Number: 1500.166k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:31:30,122][train][INFO][train.py>_log] ==> #509000     Total Loss: 2.475    [weighted Loss:2.475    Policy Loss: 7.701    Value Loss: 7.419    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 443854     Buffer Size: 39812      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:34:48,410][train][INFO][train.py>_log] ==> #510000     Total Loss: 3.952    [weighted Loss:3.952    Policy Loss: 6.434    Value Loss: 7.383    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 445056     Buffer Size: 40072      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:38:05,628][train][INFO][train.py>_log] ==> #511000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 7.423    Value Loss: 7.145    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 445859     Buffer Size: 39940      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:41:22,652][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 6.923    Value Loss: 7.052    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 446698     Buffer Size: 39786      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:44:42,048][train][INFO][train.py>_log] ==> #513000     Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 6.846    Value Loss: 7.345    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 447721     Buffer Size: 39624      Transition Number: 1500.119k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:47:59,923][train][INFO][train.py>_log] ==> #514000     Total Loss: 2.683    [weighted Loss:2.683    Policy Loss: 6.297    Value Loss: 7.359    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 448751     Buffer Size: 39440      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:51:17,963][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 6.556    Value Loss: 7.241    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 449953     Buffer Size: 39587      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:54:38,602][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 6.984    Value Loss: 6.957    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 451179     Buffer Size: 39713      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-11 05:57:58,656][train][INFO][train.py>_log] ==> #517000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 6.656    Value Loss: 6.880    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 452149     Buffer Size: 39588      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:01:18,609][train][INFO][train.py>_log] ==> #518000     Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 6.245    Value Loss: 7.163    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 453123     Buffer Size: 39513      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:04:39,484][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 6.847    Value Loss: 7.242    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 454675     Buffer Size: 40131      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:08:00,296][train][INFO][train.py>_log] ==> #520000     Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 6.849    Value Loss: 7.245    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 456258     Buffer Size: 40750      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:11:19,633][train][INFO][train.py>_log] ==> #521000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 7.195    Value Loss: 7.183    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 457470     Buffer Size: 40970      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:14:37,710][train][INFO][train.py>_log] ==> #522000     Total Loss: 4.347    [weighted Loss:4.347    Policy Loss: 6.214    Value Loss: 7.287    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 458752     Buffer Size: 41143      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:17:59,602][train][INFO][train.py>_log] ==> #523000     Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 6.799    Value Loss: 6.893    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 459629     Buffer Size: 40703      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:21:21,531][train][INFO][train.py>_log] ==> #524000     Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 6.618    Value Loss: 7.391    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 460465     Buffer Size: 40308      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:24:38,621][train][INFO][train.py>_log] ==> #525000     Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 8.472    Value Loss: 7.389    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 461461     Buffer Size: 40276      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:28:02,215][train][INFO][train.py>_log] ==> #526000     Total Loss: 4.239    [weighted Loss:4.239    Policy Loss: 7.127    Value Loss: 6.918    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 462440     Buffer Size: 40235      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:31:22,281][train][INFO][train.py>_log] ==> #527000     Total Loss: 3.131    [weighted Loss:3.131    Policy Loss: 7.319    Value Loss: 7.018    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 463381     Buffer Size: 40041      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:34:39,372][train][INFO][train.py>_log] ==> #528000     Total Loss: 3.984    [weighted Loss:3.984    Policy Loss: 7.474    Value Loss: 7.225    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 464272     Buffer Size: 39901      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:37:58,618][train][INFO][train.py>_log] ==> #529000     Total Loss: 3.923    [weighted Loss:3.923    Policy Loss: 7.034    Value Loss: 7.097    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 465288     Buffer Size: 39915      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:41:15,092][train][INFO][train.py>_log] ==> #530000     Total Loss: 3.356    [weighted Loss:3.356    Policy Loss: 6.956    Value Loss: 7.184    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 466260     Buffer Size: 39879      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:44:38,893][train][INFO][train.py>_log] ==> #531000     Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 7.683    Value Loss: 7.044    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 468110     Buffer Size: 40509      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:47:56,669][train][INFO][train.py>_log] ==> #532000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 8.308    Value Loss: 7.364    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 470111     Buffer Size: 41288      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:51:15,813][train][INFO][train.py>_log] ==> #533000     Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 7.730    Value Loss: 7.026    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 471916     Buffer Size: 41909      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:54:34,982][train][INFO][train.py>_log] ==> #534000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 7.495    Value Loss: 6.867    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 473724     Buffer Size: 42476      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 06:57:53,129][train][INFO][train.py>_log] ==> #535000     Total Loss: 3.362    [weighted Loss:3.362    Policy Loss: 7.662    Value Loss: 6.685    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 474692     Buffer Size: 42282      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:01:12,342][train][INFO][train.py>_log] ==> #536000     Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 7.195    Value Loss: 6.943    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 475711     Buffer Size: 41973      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:04:34,116][train][INFO][train.py>_log] ==> #537000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 8.357    Value Loss: 7.329    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 476548     Buffer Size: 41538      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:07:54,342][train][INFO][train.py>_log] ==> #538000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 5.744    Value Loss: 6.865    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 477396     Buffer Size: 41144      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:11:12,480][train][INFO][train.py>_log] ==> #539000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 7.698    Value Loss: 6.879    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 478228     Buffer Size: 40830      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:14:30,820][train][INFO][train.py>_log] ==> #540000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 6.614    Value Loss: 6.725    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 479110     Buffer Size: 40539      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:17:51,866][train][INFO][train.py>_log] ==> #541000     Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 7.726    Value Loss: 6.996    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 480123     Buffer Size: 40442      Transition Number: 1500.066k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:21:10,366][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 7.131    Value Loss: 7.020    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 481182     Buffer Size: 40399      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:24:31,330][train][INFO][train.py>_log] ==> #543000     Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 6.481    Value Loss: 6.537    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 482628     Buffer Size: 40668      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:27:52,590][train][INFO][train.py>_log] ==> #544000     Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 7.876    Value Loss: 6.878    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 484075     Buffer Size: 40921      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:31:10,906][train][INFO][train.py>_log] ==> #545000     Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 8.071    Value Loss: 6.706    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 485204     Buffer Size: 40878      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:34:27,155][train][INFO][train.py>_log] ==> #546000     Total Loss: 3.341    [weighted Loss:3.341    Policy Loss: 7.066    Value Loss: 7.082    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 486327     Buffer Size: 40952      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:37:48,086][train][INFO][train.py>_log] ==> #547000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 7.977    Value Loss: 7.312    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 487258     Buffer Size: 41053      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:41:07,118][train][INFO][train.py>_log] ==> #548000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 8.340    Value Loss: 7.113    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 488192     Buffer Size: 41077      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:44:25,765][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 9.019    Value Loss: 7.294    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 489329     Buffer Size: 41134      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:47:46,835][train][INFO][train.py>_log] ==> #550000     Total Loss: 5.169    [weighted Loss:5.169    Policy Loss: 9.624    Value Loss: 7.099    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 490531     Buffer Size: 41174      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:51:04,197][train][INFO][train.py>_log] ==> #551000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 8.506    Value Loss: 7.537    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 491797     Buffer Size: 41233      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:54:22,636][train][INFO][train.py>_log] ==> #552000     Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 9.250    Value Loss: 7.435    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 493055     Buffer Size: 41388      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-11 07:57:42,779][train][INFO][train.py>_log] ==> #553000     Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 8.935    Value Loss: 6.999    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 494532     Buffer Size: 41830      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:01:01,375][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 8.914    Value Loss: 7.373    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 496030     Buffer Size: 41991      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:04:22,526][train][INFO][train.py>_log] ==> #555000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 7.667    Value Loss: 7.120    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 497240     Buffer Size: 41608      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:07:40,708][train][INFO][train.py>_log] ==> #556000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 8.499    Value Loss: 7.550    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 498428     Buffer Size: 41405      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:11:01,742][train][INFO][train.py>_log] ==> #557000     Total Loss: 3.737    [weighted Loss:3.737    Policy Loss: 7.657    Value Loss: 7.142    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 499786     Buffer Size: 41431      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:14:22,113][train][INFO][train.py>_log] ==> #558000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 8.049    Value Loss: 7.536    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 501139     Buffer Size: 41748      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:17:40,146][train][INFO][train.py>_log] ==> #559000     Total Loss: 4.162    [weighted Loss:4.162    Policy Loss: 9.295    Value Loss: 7.483    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 502352     Buffer Size: 42090      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:20:57,952][train][INFO][train.py>_log] ==> #560000     Total Loss: 2.956    [weighted Loss:2.956    Policy Loss: 8.412    Value Loss: 7.606    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 503542     Buffer Size: 42329      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:24:14,917][train][INFO][train.py>_log] ==> #561000     Total Loss: 3.654    [weighted Loss:3.654    Policy Loss: 8.784    Value Loss: 7.409    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 504983     Buffer Size: 42741      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:27:32,318][train][INFO][train.py>_log] ==> #562000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 8.683    Value Loss: 7.348    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 506434     Buffer Size: 43218      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:30:49,836][train][INFO][train.py>_log] ==> #563000     Total Loss: 2.216    [weighted Loss:2.216    Policy Loss: 8.177    Value Loss: 7.485    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 507621     Buffer Size: 43481      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:34:06,573][train][INFO][train.py>_log] ==> #564000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 9.609    Value Loss: 7.452    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 508787     Buffer Size: 43661      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:37:24,938][train][INFO][train.py>_log] ==> #565000     Total Loss: 3.851    [weighted Loss:3.851    Policy Loss: 7.588    Value Loss: 7.004    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 510081     Buffer Size: 43903      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:40:40,915][train][INFO][train.py>_log] ==> #566000     Total Loss: 4.029    [weighted Loss:4.029    Policy Loss: 9.526    Value Loss: 7.630    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 511408     Buffer Size: 43574      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:44:00,751][train][INFO][train.py>_log] ==> #567000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 9.018    Value Loss: 7.217    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 512897     Buffer Size: 43093      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:47:19,164][train][INFO][train.py>_log] ==> #568000     Total Loss: 4.228    [weighted Loss:4.228    Policy Loss: 9.148    Value Loss: 7.777    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 514388     Buffer Size: 42751      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:50:41,300][train][INFO][train.py>_log] ==> #569000     Total Loss: 3.442    [weighted Loss:3.442    Policy Loss: 7.970    Value Loss: 7.327    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 515711     Buffer Size: 42319      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:53:58,086][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 8.031    Value Loss: 7.482    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 517001     Buffer Size: 42456      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-11 08:57:15,444][train][INFO][train.py>_log] ==> #571000     Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 9.514    Value Loss: 7.604    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 518345     Buffer Size: 42821      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:00:36,444][train][INFO][train.py>_log] ==> #572000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.532    Value Loss: 7.553    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 519784     Buffer Size: 43359      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:03:49,809][train][INFO][train.py>_log] ==> #573000     Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 9.115    Value Loss: 7.558    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 520872     Buffer Size: 43647      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:07:05,943][train][INFO][train.py>_log] ==> #574000     Total Loss: 3.970    [weighted Loss:3.970    Policy Loss: 8.598    Value Loss: 7.090    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 521974     Buffer Size: 43900      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:10:22,714][train][INFO][train.py>_log] ==> #575000     Total Loss: 4.883    [weighted Loss:4.883    Policy Loss: 8.323    Value Loss: 7.660    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 523527     Buffer Size: 44542      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:13:40,361][train][INFO][train.py>_log] ==> #576000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 8.341    Value Loss: 7.507    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 525062     Buffer Size: 45039      Transition Number: 1500.142k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:16:54,621][train][INFO][train.py>_log] ==> #577000     Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 7.697    Value Loss: 7.884    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 526228     Buffer Size: 45209      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:20:12,391][train][INFO][train.py>_log] ==> #578000     Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 7.758    Value Loss: 7.638    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 527486     Buffer Size: 45090      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:23:31,130][train][INFO][train.py>_log] ==> #579000     Total Loss: 3.898    [weighted Loss:3.898    Policy Loss: 7.532    Value Loss: 7.588    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 528328     Buffer Size: 44650      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:26:49,381][train][INFO][train.py>_log] ==> #580000     Total Loss: 3.968    [weighted Loss:3.968    Policy Loss: 7.823    Value Loss: 7.804    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 529197     Buffer Size: 44242      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:30:08,167][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 7.335    Value Loss: 7.324    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 530080     Buffer Size: 44067      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:33:26,673][train][INFO][train.py>_log] ==> #582000     Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 7.635    Value Loss: 7.364    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 531009     Buffer Size: 43970      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:36:43,706][train][INFO][train.py>_log] ==> #583000     Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 7.417    Value Loss: 7.147    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 531998     Buffer Size: 44073      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:40:00,604][train][INFO][train.py>_log] ==> #584000     Total Loss: 3.026    [weighted Loss:3.026    Policy Loss: 8.257    Value Loss: 7.105    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 533059     Buffer Size: 44014      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:43:20,920][train][INFO][train.py>_log] ==> #585000     Total Loss: 3.107    [weighted Loss:3.107    Policy Loss: 7.301    Value Loss: 7.127    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 534145     Buffer Size: 43965      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:46:40,621][train][INFO][train.py>_log] ==> #586000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 7.201    Value Loss: 7.458    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 535259     Buffer Size: 43859      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:49:57,025][train][INFO][train.py>_log] ==> #587000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 6.593    Value Loss: 7.671    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 536367     Buffer Size: 43748      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:53:17,089][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 7.242    Value Loss: 7.310    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 537476     Buffer Size: 43488      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:56:33,055][train][INFO][train.py>_log] ==> #589000     Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 7.140    Value Loss: 7.291    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 538359     Buffer Size: 43038      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 09:59:52,365][train][INFO][train.py>_log] ==> #590000     Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 8.151    Value Loss: 7.427    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 539281     Buffer Size: 42663      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:03:15,068][train][INFO][train.py>_log] ==> #591000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 5.973    Value Loss: 7.389    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 540347     Buffer Size: 42510      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:06:35,998][train][INFO][train.py>_log] ==> #592000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 8.411    Value Loss: 7.411    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 541396     Buffer Size: 42307      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:09:54,786][train][INFO][train.py>_log] ==> #593000     Total Loss: 3.822    [weighted Loss:3.822    Policy Loss: 7.164    Value Loss: 7.051    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 542782     Buffer Size: 42334      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:13:12,906][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 7.963    Value Loss: 7.623    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 544221     Buffer Size: 42482      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:16:29,804][train][INFO][train.py>_log] ==> #595000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 7.443    Value Loss: 7.520    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 545921     Buffer Size: 42981      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:19:51,448][train][INFO][train.py>_log] ==> #596000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 7.124    Value Loss: 7.445    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 547690     Buffer Size: 43377      Transition Number: 1500.067k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:23:08,614][train][INFO][train.py>_log] ==> #597000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 6.705    Value Loss: 7.545    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 548594     Buffer Size: 43012      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:26:27,622][train][INFO][train.py>_log] ==> #598000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 7.316    Value Loss: 7.379    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 549568     Buffer Size: 42644      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:29:49,874][train][INFO][train.py>_log] ==> #599000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 6.726    Value Loss: 7.050    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 551067     Buffer Size: 42857      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:33:09,518][train][INFO][train.py>_log] ==> #600000     Total Loss: 3.838    [weighted Loss:3.838    Policy Loss: 8.336    Value Loss: 7.220    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 552519     Buffer Size: 43044      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:36:27,502][train][INFO][train.py>_log] ==> #601000     Total Loss: 4.059    [weighted Loss:4.059    Policy Loss: 6.183    Value Loss: 7.433    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 553968     Buffer Size: 43204      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:39:45,223][train][INFO][train.py>_log] ==> #602000     Total Loss: 3.567    [weighted Loss:3.567    Policy Loss: 7.094    Value Loss: 7.545    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 555447     Buffer Size: 43251      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:43:06,752][train][INFO][train.py>_log] ==> #603000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 7.845    Value Loss: 7.542    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 556634     Buffer Size: 42960      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:46:28,675][train][INFO][train.py>_log] ==> #604000     Total Loss: 3.955    [weighted Loss:3.955    Policy Loss: 7.887    Value Loss: 7.723    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 557794     Buffer Size: 42732      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:49:46,806][train][INFO][train.py>_log] ==> #605000     Total Loss: 3.441    [weighted Loss:3.441    Policy Loss: 7.973    Value Loss: 7.431    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 558884     Buffer Size: 42576      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:53:05,996][train][INFO][train.py>_log] ==> #606000     Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 6.882    Value Loss: 7.265    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 559947     Buffer Size: 42317      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:56:23,275][train][INFO][train.py>_log] ==> #607000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 8.252    Value Loss: 7.246    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 560889     Buffer Size: 41940      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-11 10:59:43,106][train][INFO][train.py>_log] ==> #608000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 7.046    Value Loss: 7.606    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 561862     Buffer Size: 41597      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:03:01,811][train][INFO][train.py>_log] ==> #609000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 7.572    Value Loss: 7.543    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 562783     Buffer Size: 41433      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:06:22,856][train][INFO][train.py>_log] ==> #610000     Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 6.071    Value Loss: 7.189    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 563726     Buffer Size: 41132      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:09:41,152][train][INFO][train.py>_log] ==> #611000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 7.637    Value Loss: 7.174    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 564613     Buffer Size: 40558      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:13:03,888][train][INFO][train.py>_log] ==> #612000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 7.041    Value Loss: 7.163    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 565566     Buffer Size: 40089      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:16:29,178][train][INFO][train.py>_log] ==> #613000     Total Loss: 3.244    [weighted Loss:3.244    Policy Loss: 7.200    Value Loss: 7.175    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 566371     Buffer Size: 39709      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:19:46,436][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 5.669    Value Loss: 6.993    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 567164     Buffer Size: 39380      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:23:07,505][train][INFO][train.py>_log] ==> #615000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 6.792    Value Loss: 6.852    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 567944     Buffer Size: 39338      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:26:28,859][train][INFO][train.py>_log] ==> #616000     Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 6.072    Value Loss: 6.934    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 568749     Buffer Size: 39257      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:29:45,325][train][INFO][train.py>_log] ==> #617000     Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 7.772    Value Loss: 7.587    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 569555     Buffer Size: 39170      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:33:04,488][train][INFO][train.py>_log] ==> #618000     Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 6.954    Value Loss: 6.922    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 570340     Buffer Size: 39044      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:36:25,751][train][INFO][train.py>_log] ==> #619000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 6.846    Value Loss: 7.348    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 571430     Buffer Size: 39033      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:39:48,904][train][INFO][train.py>_log] ==> #620000     Total Loss: 3.336    [weighted Loss:3.336    Policy Loss: 6.000    Value Loss: 6.943    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 572488     Buffer Size: 38996      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:43:09,541][train][INFO][train.py>_log] ==> #621000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 6.511    Value Loss: 7.033    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 573462     Buffer Size: 38906      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:46:28,852][train][INFO][train.py>_log] ==> #622000     Total Loss: 3.211    [weighted Loss:3.211    Policy Loss: 7.543    Value Loss: 7.328    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 574477     Buffer Size: 38819      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:49:51,066][train][INFO][train.py>_log] ==> #623000     Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 7.946    Value Loss: 7.029    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 575842     Buffer Size: 38989      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:53:11,794][train][INFO][train.py>_log] ==> #624000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 7.455    Value Loss: 7.204    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 577172     Buffer Size: 39295      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:56:32,359][train][INFO][train.py>_log] ==> #625000     Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.797    Value Loss: 7.084    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 578106     Buffer Size: 39279      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-11 11:59:52,733][train][INFO][train.py>_log] ==> #626000     Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 7.291    Value Loss: 7.437    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 579026     Buffer Size: 39259      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:03:15,082][train][INFO][train.py>_log] ==> #627000     Total Loss: 3.006    [weighted Loss:3.006    Policy Loss: 8.027    Value Loss: 7.386    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 579949     Buffer Size: 39138      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:06:34,704][train][INFO][train.py>_log] ==> #628000     Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 7.694    Value Loss: 7.409    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 580856     Buffer Size: 38932      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:09:59,161][train][INFO][train.py>_log] ==> #629000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 8.017    Value Loss: 7.245    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 581793     Buffer Size: 38420      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:13:19,097][train][INFO][train.py>_log] ==> #630000     Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 8.326    Value Loss: 7.347    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 582701     Buffer Size: 37801      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:16:40,991][train][INFO][train.py>_log] ==> #631000     Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 7.635    Value Loss: 7.132    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 584343     Buffer Size: 37630      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:20:03,349][train][INFO][train.py>_log] ==> #632000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 7.749    Value Loss: 7.081    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 585989     Buffer Size: 37816      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:23:20,356][train][INFO][train.py>_log] ==> #633000     Total Loss: 3.185    [weighted Loss:3.185    Policy Loss: 8.128    Value Loss: 7.119    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 586826     Buffer Size: 37773      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:26:41,815][train][INFO][train.py>_log] ==> #634000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 8.504    Value Loss: 7.003    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 587720     Buffer Size: 37508      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:30:03,933][train][INFO][train.py>_log] ==> #635000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 9.410    Value Loss: 7.120    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 588703     Buffer Size: 37060      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:33:24,011][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 8.864    Value Loss: 7.270    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 589666     Buffer Size: 36608      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:36:45,567][train][INFO][train.py>_log] ==> #637000     Total Loss: 3.316    [weighted Loss:3.316    Policy Loss: 10.027   Value Loss: 7.241    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 590817     Buffer Size: 36286      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:40:08,469][train][INFO][train.py>_log] ==> #638000     Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 9.432    Value Loss: 7.248    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 591950     Buffer Size: 36042      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:43:29,371][train][INFO][train.py>_log] ==> #639000     Total Loss: 3.875    [weighted Loss:3.875    Policy Loss: 8.833    Value Loss: 7.146    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 593147     Buffer Size: 36025      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:46:51,471][train][INFO][train.py>_log] ==> #640000     Total Loss: 4.368    [weighted Loss:4.368    Policy Loss: 9.535    Value Loss: 6.995    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 594348     Buffer Size: 36050      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:50:16,831][train][INFO][train.py>_log] ==> #641000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 8.821    Value Loss: 7.520    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 595756     Buffer Size: 36290      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:53:41,958][train][INFO][train.py>_log] ==> #642000     Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 9.636    Value Loss: 7.396    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 597089     Buffer Size: 36587      Transition Number: 1500.112k Batch Size: 256        Lr: 0.10000 
[2022-01-11 12:57:02,574][train][INFO][train.py>_log] ==> #643000     Total Loss: 3.830    [weighted Loss:3.830    Policy Loss: 9.126    Value Loss: 7.340    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 598504     Buffer Size: 36997      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:00:27,348][train][INFO][train.py>_log] ==> #644000     Total Loss: 3.834    [weighted Loss:3.834    Policy Loss: 9.643    Value Loss: 7.265    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 600034     Buffer Size: 37502      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:03:46,657][train][INFO][train.py>_log] ==> #645000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 7.863    Value Loss: 7.518    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 601311     Buffer Size: 37777      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:07:05,506][train][INFO][train.py>_log] ==> #646000     Total Loss: 3.734    [weighted Loss:3.734    Policy Loss: 8.971    Value Loss: 7.314    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 602583     Buffer Size: 38084      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:10:26,617][train][INFO][train.py>_log] ==> #647000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 7.940    Value Loss: 7.088    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 604251     Buffer Size: 38749      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:13:45,093][train][INFO][train.py>_log] ==> #648000     Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 8.324    Value Loss: 7.204    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 605846     Buffer Size: 39492      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:17:02,853][train][INFO][train.py>_log] ==> #649000     Total Loss: 3.494    [weighted Loss:3.494    Policy Loss: 10.218   Value Loss: 7.199    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 606662     Buffer Size: 39562      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:20:23,234][train][INFO][train.py>_log] ==> #650000     Total Loss: 0.958    [weighted Loss:0.958    Policy Loss: 7.732    Value Loss: 7.281    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 607539     Buffer Size: 39623      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:23:44,675][train][INFO][train.py>_log] ==> #651000     Total Loss: 3.621    [weighted Loss:3.621    Policy Loss: 8.138    Value Loss: 6.958    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 608519     Buffer Size: 39783      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:27:00,897][train][INFO][train.py>_log] ==> #652000     Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 7.848    Value Loss: 7.147    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 609428     Buffer Size: 39904      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:30:22,576][train][INFO][train.py>_log] ==> #653000     Total Loss: 1.101    [weighted Loss:1.101    Policy Loss: 7.489    Value Loss: 6.881    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 610371     Buffer Size: 40023      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:33:41,798][train][INFO][train.py>_log] ==> #654000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 7.240    Value Loss: 7.224    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 611315     Buffer Size: 39946      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:37:02,736][train][INFO][train.py>_log] ==> #655000     Total Loss: 3.228    [weighted Loss:3.228    Policy Loss: 8.903    Value Loss: 7.165    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 612444     Buffer Size: 40004      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:40:22,243][train][INFO][train.py>_log] ==> #656000     Total Loss: 3.114    [weighted Loss:3.114    Policy Loss: 7.339    Value Loss: 7.179    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 613531     Buffer Size: 40077      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:43:43,722][train][INFO][train.py>_log] ==> #657000     Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 8.757    Value Loss: 7.538    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 614981     Buffer Size: 40511      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:47:08,467][train][INFO][train.py>_log] ==> #658000     Total Loss: 4.298    [weighted Loss:4.298    Policy Loss: 9.595    Value Loss: 7.710    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 616416     Buffer Size: 40596      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:50:27,064][train][INFO][train.py>_log] ==> #659000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 8.464    Value Loss: 7.767    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 617864     Buffer Size: 40646      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:53:49,496][train][INFO][train.py>_log] ==> #660000     Total Loss: 1.774    [weighted Loss:1.774    Policy Loss: 8.172    Value Loss: 7.312    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 619316     Buffer Size: 41107      Transition Number: 1500.082k Batch Size: 256        Lr: 0.10000 
[2022-01-11 13:57:09,808][train][INFO][train.py>_log] ==> #661000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 8.932    Value Loss: 7.242    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 620386     Buffer Size: 41270      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:00:30,631][train][INFO][train.py>_log] ==> #662000     Total Loss: 1.333    [weighted Loss:1.333    Policy Loss: 8.146    Value Loss: 7.587    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 621483     Buffer Size: 41454      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:03:48,570][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 8.525    Value Loss: 7.093    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 622541     Buffer Size: 41558      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:07:07,086][train][INFO][train.py>_log] ==> #664000     Total Loss: 3.721    [weighted Loss:3.721    Policy Loss: 8.611    Value Loss: 7.541    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 623598     Buffer Size: 41660      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:10:27,348][train][INFO][train.py>_log] ==> #665000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 9.228    Value Loss: 7.114    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 624551     Buffer Size: 41703      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:13:46,218][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 8.218    Value Loss: 7.405    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 625504     Buffer Size: 41090      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:17:05,409][train][INFO][train.py>_log] ==> #667000     Total Loss: 3.856    [weighted Loss:3.856    Policy Loss: 9.114    Value Loss: 7.297    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 626708     Buffer Size: 40652      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:20:28,818][train][INFO][train.py>_log] ==> #668000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 10.044   Value Loss: 7.494    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 627930     Buffer Size: 40917      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:23:48,545][train][INFO][train.py>_log] ==> #669000     Total Loss: 4.232    [weighted Loss:4.232    Policy Loss: 9.849    Value Loss: 7.409    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 629064     Buffer Size: 41161      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:27:05,882][train][INFO][train.py>_log] ==> #670000     Total Loss: 4.077    [weighted Loss:4.077    Policy Loss: 9.041    Value Loss: 7.510    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 630165     Buffer Size: 41305      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:30:25,647][train][INFO][train.py>_log] ==> #671000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 9.240    Value Loss: 7.642    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 631167     Buffer Size: 41338      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:33:43,719][train][INFO][train.py>_log] ==> #672000     Total Loss: 4.310    [weighted Loss:4.310    Policy Loss: 8.934    Value Loss: 7.328    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 632176     Buffer Size: 41205      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:37:01,485][train][INFO][train.py>_log] ==> #673000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 7.852    Value Loss: 7.377    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 633583     Buffer Size: 41475      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:40:22,197][train][INFO][train.py>_log] ==> #674000     Total Loss: 4.338    [weighted Loss:4.338    Policy Loss: 8.682    Value Loss: 7.534    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 635018     Buffer Size: 41768      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:43:41,193][train][INFO][train.py>_log] ==> #675000     Total Loss: 3.264    [weighted Loss:3.264    Policy Loss: 9.234    Value Loss: 7.755    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 636270     Buffer Size: 41877      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:46:59,701][train][INFO][train.py>_log] ==> #676000     Total Loss: 2.165    [weighted Loss:2.165    Policy Loss: 8.133    Value Loss: 7.490    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 637513     Buffer Size: 41801      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:50:18,495][train][INFO][train.py>_log] ==> #677000     Total Loss: 4.093    [weighted Loss:4.093    Policy Loss: 8.127    Value Loss: 7.128    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 638779     Buffer Size: 41722      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:53:37,244][train][INFO][train.py>_log] ==> #678000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 8.194    Value Loss: 7.585    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 640042     Buffer Size: 41570      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 14:56:56,251][train][INFO][train.py>_log] ==> #679000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 8.054    Value Loss: 7.275    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 641326     Buffer Size: 41420      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:00:16,438][train][INFO][train.py>_log] ==> #680000     Total Loss: 4.040    [weighted Loss:4.040    Policy Loss: 9.350    Value Loss: 8.014    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 642609     Buffer Size: 41425      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:03:31,916][train][INFO][train.py>_log] ==> #681000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 8.784    Value Loss: 7.470    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 643793     Buffer Size: 41388      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:06:50,612][train][INFO][train.py>_log] ==> #682000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 8.932    Value Loss: 7.222    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 645090     Buffer Size: 41124      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:10:12,549][train][INFO][train.py>_log] ==> #683000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 8.463    Value Loss: 7.054    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 646275     Buffer Size: 40667      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:13:30,921][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.844    [weighted Loss:2.844    Policy Loss: 7.798    Value Loss: 7.407    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 647381     Buffer Size: 40770      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:16:48,157][train][INFO][train.py>_log] ==> #685000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 8.864    Value Loss: 7.612    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 648441     Buffer Size: 40994      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:20:07,606][train][INFO][train.py>_log] ==> #686000     Total Loss: 3.622    [weighted Loss:3.622    Policy Loss: 6.617    Value Loss: 7.079    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 649536     Buffer Size: 41111      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:23:26,485][train][INFO][train.py>_log] ==> #687000     Total Loss: 4.194    [weighted Loss:4.194    Policy Loss: 9.310    Value Loss: 7.963    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 650580     Buffer Size: 41216      Transition Number: 1500.093k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:26:46,569][train][INFO][train.py>_log] ==> #688000     Total Loss: 1.366    [weighted Loss:1.366    Policy Loss: 7.560    Value Loss: 7.408    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 651630     Buffer Size: 41313      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:30:08,639][train][INFO][train.py>_log] ==> #689000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 8.747    Value Loss: 7.513    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 652624     Buffer Size: 41355      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:33:30,211][train][INFO][train.py>_log] ==> #690000     Total Loss: 4.311    [weighted Loss:4.311    Policy Loss: 7.920    Value Loss: 7.362    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 653643     Buffer Size: 41276      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:36:48,936][train][INFO][train.py>_log] ==> #691000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 7.573    Value Loss: 7.186    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 654909     Buffer Size: 41432      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:40:08,098][train][INFO][train.py>_log] ==> #692000     Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 9.251    Value Loss: 7.620    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 656155     Buffer Size: 41255      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:43:28,743][train][INFO][train.py>_log] ==> #693000     Total Loss: 4.763    [weighted Loss:4.763    Policy Loss: 8.272    Value Loss: 7.235    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 657198     Buffer Size: 40972      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:46:49,369][train][INFO][train.py>_log] ==> #694000     Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 8.715    Value Loss: 7.738    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 658252     Buffer Size: 40654      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:50:12,800][train][INFO][train.py>_log] ==> #695000     Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 8.508    Value Loss: 7.408    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 659699     Buffer Size: 40579      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:53:34,962][train][INFO][train.py>_log] ==> #696000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 9.678    Value Loss: 7.561    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 661079     Buffer Size: 40757      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 15:56:56,783][train][INFO][train.py>_log] ==> #697000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 8.495    Value Loss: 7.664    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 662178     Buffer Size: 40805      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:00:16,286][train][INFO][train.py>_log] ==> #698000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 8.245    Value Loss: 7.283    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 663294     Buffer Size: 40874      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:03:34,922][train][INFO][train.py>_log] ==> #699000     Total Loss: 4.301    [weighted Loss:4.301    Policy Loss: 8.352    Value Loss: 7.267    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 664507     Buffer Size: 41023      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:06:52,197][train][INFO][train.py>_log] ==> #700000     Total Loss: 4.247    [weighted Loss:4.247    Policy Loss: 9.749    Value Loss: 7.550    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 665693     Buffer Size: 41244      Transition Number: 1500.140k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:10:11,755][train][INFO][train.py>_log] ==> #701000     Total Loss: 3.194    [weighted Loss:3.194    Policy Loss: 8.482    Value Loss: 7.504    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 667188     Buffer Size: 41730      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:13:28,067][train][INFO][train.py>_log] ==> #702000     Total Loss: 3.632    [weighted Loss:3.632    Policy Loss: 9.851    Value Loss: 7.248    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 668644     Buffer Size: 42025      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:16:45,966][train][INFO][train.py>_log] ==> #703000     Total Loss: 5.367    [weighted Loss:5.367    Policy Loss: 10.225   Value Loss: 7.543    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 669981     Buffer Size: 42229      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:20:06,484][train][INFO][train.py>_log] ==> #704000     Total Loss: 4.546    [weighted Loss:4.546    Policy Loss: 9.256    Value Loss: 7.541    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 671325     Buffer Size: 42405      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:23:27,274][train][INFO][train.py>_log] ==> #705000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 8.875    Value Loss: 7.322    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 672513     Buffer Size: 42464      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:26:47,423][train][INFO][train.py>_log] ==> #706000     Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 8.663    Value Loss: 7.173    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 673665     Buffer Size: 42551      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:30:08,578][train][INFO][train.py>_log] ==> #707000     Total Loss: 4.825    [weighted Loss:4.825    Policy Loss: 8.705    Value Loss: 7.479    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 675562     Buffer Size: 43354      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:33:25,606][train][INFO][train.py>_log] ==> #708000     Total Loss: 4.651    [weighted Loss:4.651    Policy Loss: 8.864    Value Loss: 7.557    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 677529     Buffer Size: 43860      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:36:39,385][train][INFO][train.py>_log] ==> #709000     Total Loss: 3.481    [weighted Loss:3.481    Policy Loss: 8.953    Value Loss: 7.459    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 678774     Buffer Size: 43764      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:39:56,544][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 8.940    Value Loss: 7.617    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 680080     Buffer Size: 43798      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:43:15,002][train][INFO][train.py>_log] ==> #711000     Total Loss: 5.453    [weighted Loss:5.453    Policy Loss: 9.165    Value Loss: 7.905    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 681657     Buffer Size: 44095      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:46:30,621][train][INFO][train.py>_log] ==> #712000     Total Loss: 4.058    [weighted Loss:4.058    Policy Loss: 8.801    Value Loss: 7.254    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 683203     Buffer Size: 44437      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:49:49,064][train][INFO][train.py>_log] ==> #713000     Total Loss: 2.747    [weighted Loss:2.747    Policy Loss: 7.883    Value Loss: 7.385    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 684529     Buffer Size: 44528      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:53:08,597][train][INFO][train.py>_log] ==> #714000     Total Loss: 4.807    [weighted Loss:4.807    Policy Loss: 8.424    Value Loss: 7.326    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 685878     Buffer Size: 44581      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:56:24,702][train][INFO][train.py>_log] ==> #715000     Total Loss: 4.434    [weighted Loss:4.434    Policy Loss: 8.310    Value Loss: 7.306    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 687160     Buffer Size: 44570      Transition Number: 1500.084k Batch Size: 256        Lr: 0.10000 
[2022-01-11 16:59:45,880][train][INFO][train.py>_log] ==> #716000     Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 8.045    Value Loss: 7.357    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 688423     Buffer Size: 44656      Transition Number: 1500.136k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:03:03,381][train][INFO][train.py>_log] ==> #717000     Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 8.360    Value Loss: 7.554    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 689541     Buffer Size: 44539      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:06:22,789][train][INFO][train.py>_log] ==> #718000     Total Loss: 3.504    [weighted Loss:3.504    Policy Loss: 8.696    Value Loss: 7.430    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 690731     Buffer Size: 44502      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:09:40,742][train][INFO][train.py>_log] ==> #719000     Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 8.257    Value Loss: 7.221    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 691691     Buffer Size: 44370      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:13:00,557][train][INFO][train.py>_log] ==> #720000     Total Loss: 4.364    [weighted Loss:4.364    Policy Loss: 7.586    Value Loss: 7.303    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 692684     Buffer Size: 44263      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:16:18,035][train][INFO][train.py>_log] ==> #721000     Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 9.794    Value Loss: 7.271    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 693711     Buffer Size: 44246      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:19:38,014][train][INFO][train.py>_log] ==> #722000     Total Loss: 3.635    [weighted Loss:3.635    Policy Loss: 8.804    Value Loss: 7.384    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 694783     Buffer Size: 44248      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:22:55,546][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.812    [weighted Loss:2.812    Policy Loss: 10.275   Value Loss: 7.793    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 695952     Buffer Size: 44344      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:26:13,375][train][INFO][train.py>_log] ==> #724000     Total Loss: 1.146    [weighted Loss:1.146    Policy Loss: 9.088    Value Loss: 7.748    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 697171     Buffer Size: 44527      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:29:33,128][train][INFO][train.py>_log] ==> #725000     Total Loss: 3.599    [weighted Loss:3.599    Policy Loss: 9.587    Value Loss: 7.213    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 698060     Buffer Size: 44496      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:32:51,383][train][INFO][train.py>_log] ==> #726000     Total Loss: 3.508    [weighted Loss:3.508    Policy Loss: 9.886    Value Loss: 7.632    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 698997     Buffer Size: 44188      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:36:13,256][train][INFO][train.py>_log] ==> #727000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 9.411    Value Loss: 7.340    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 700448     Buffer Size: 44300      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:39:35,464][train][INFO][train.py>_log] ==> #728000     Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 8.242    Value Loss: 7.453    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 701828     Buffer Size: 44591      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:42:53,023][train][INFO][train.py>_log] ==> #729000     Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 8.594    Value Loss: 7.312    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 703226     Buffer Size: 44916      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:46:11,788][train][INFO][train.py>_log] ==> #730000     Total Loss: 3.259    [weighted Loss:3.259    Policy Loss: 10.187   Value Loss: 8.057    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 704694     Buffer Size: 45034      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:49:29,232][train][INFO][train.py>_log] ==> #731000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 8.807    Value Loss: 7.102    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 706124     Buffer Size: 45112      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:52:46,512][train][INFO][train.py>_log] ==> #732000     Total Loss: 3.747    [weighted Loss:3.747    Policy Loss: 9.150    Value Loss: 7.833    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 707570     Buffer Size: 45411      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:56:04,658][train][INFO][train.py>_log] ==> #733000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 8.917    Value Loss: 7.622    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 708785     Buffer Size: 45542      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-11 17:59:21,549][train][INFO][train.py>_log] ==> #734000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 9.094    Value Loss: 7.659    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 709984     Buffer Size: 45549      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:02:36,586][train][INFO][train.py>_log] ==> #735000     Total Loss: 3.234    [weighted Loss:3.234    Policy Loss: 8.171    Value Loss: 7.189    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 711166     Buffer Size: 45546      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:05:52,546][train][INFO][train.py>_log] ==> #736000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 9.689    Value Loss: 7.815    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 712349     Buffer Size: 45316      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:09:13,575][train][INFO][train.py>_log] ==> #737000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 9.539    Value Loss: 7.669    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 714165     Buffer Size: 45568      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:12:32,376][train][INFO][train.py>_log] ==> #738000     Total Loss: 3.792    [weighted Loss:3.792    Policy Loss: 9.163    Value Loss: 7.216    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 715987     Buffer Size: 45987      Transition Number: 1500.143k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:15:51,414][train][INFO][train.py>_log] ==> #739000     Total Loss: 4.394    [weighted Loss:4.394    Policy Loss: 9.053    Value Loss: 7.875    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 717959     Buffer Size: 46563      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:19:09,686][train][INFO][train.py>_log] ==> #740000     Total Loss: 5.534    [weighted Loss:5.534    Policy Loss: 9.874    Value Loss: 7.698    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 719935     Buffer Size: 47296      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:22:28,422][train][INFO][train.py>_log] ==> #741000     Total Loss: 3.448    [weighted Loss:3.448    Policy Loss: 9.958    Value Loss: 7.479    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 721549     Buffer Size: 47766      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:25:45,842][train][INFO][train.py>_log] ==> #742000     Total Loss: 3.454    [weighted Loss:3.454    Policy Loss: 9.480    Value Loss: 7.513    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 723158     Buffer Size: 47588      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:29:03,218][train][INFO][train.py>_log] ==> #743000     Total Loss: 3.990    [weighted Loss:3.990    Policy Loss: 10.016   Value Loss: 7.360    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 724537     Buffer Size: 47106      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:32:20,969][train][INFO][train.py>_log] ==> #744000     Total Loss: 3.927    [weighted Loss:3.927    Policy Loss: 9.836    Value Loss: 7.911    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 725946     Buffer Size: 47106      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:35:37,868][train][INFO][train.py>_log] ==> #745000     Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 9.067    Value Loss: 7.720    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 727082     Buffer Size: 46950      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:38:59,840][train][INFO][train.py>_log] ==> #746000     Total Loss: 3.982    [weighted Loss:3.982    Policy Loss: 10.927   Value Loss: 7.551    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 728229     Buffer Size: 46511      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:42:16,716][train][INFO][train.py>_log] ==> #747000     Total Loss: 2.639    [weighted Loss:2.639    Policy Loss: 9.584    Value Loss: 7.657    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 729448     Buffer Size: 46134      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:45:35,695][train][INFO][train.py>_log] ==> #748000     Total Loss: 3.994    [weighted Loss:3.994    Policy Loss: 9.351    Value Loss: 7.594    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 730701     Buffer Size: 46049      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:48:54,592][train][INFO][train.py>_log] ==> #749000     Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 9.491    Value Loss: 7.421    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 731864     Buffer Size: 45892      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:52:11,783][train][INFO][train.py>_log] ==> #750000     Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 9.251    Value Loss: 7.531    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 733017     Buffer Size: 45831      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:55:29,650][train][INFO][train.py>_log] ==> #751000     Total Loss: 2.881    [weighted Loss:2.881    Policy Loss: 9.036    Value Loss: 7.637    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 734118     Buffer Size: 45616      Transition Number: 1500.094k Batch Size: 256        Lr: 0.10000 
[2022-01-11 18:58:48,575][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 8.748    Value Loss: 7.719    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 735245     Buffer Size: 45583      Transition Number: 1500.076k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:02:07,774][train][INFO][train.py>_log] ==> #753000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 8.237    Value Loss: 7.761    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 736181     Buffer Size: 45450      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:05:22,705][train][INFO][train.py>_log] ==> #754000     Total Loss: 3.907    [weighted Loss:3.907    Policy Loss: 10.010   Value Loss: 7.499    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 737155     Buffer Size: 45454      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:08:44,892][train][INFO][train.py>_log] ==> #755000     Total Loss: 1.948    [weighted Loss:1.948    Policy Loss: 8.987    Value Loss: 7.451    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 738685     Buffer Size: 45943      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:12:04,621][train][INFO][train.py>_log] ==> #756000     Total Loss: 4.562    [weighted Loss:4.562    Policy Loss: 9.535    Value Loss: 7.386    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 740173     Buffer Size: 46299      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:15:21,737][train][INFO][train.py>_log] ==> #757000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 8.886    Value Loss: 7.621    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 741463     Buffer Size: 46533      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:18:40,583][train][INFO][train.py>_log] ==> #758000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 9.958    Value Loss: 7.413    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 742850     Buffer Size: 46729      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:22:01,188][train][INFO][train.py>_log] ==> #759000     Total Loss: 4.039    [weighted Loss:4.039    Policy Loss: 7.722    Value Loss: 7.598    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 744410     Buffer Size: 47089      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:25:16,898][train][INFO][train.py>_log] ==> #760000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 9.376    Value Loss: 7.602    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 745991     Buffer Size: 47688      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:28:34,681][train][INFO][train.py>_log] ==> #761000     Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 8.078    Value Loss: 7.391    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 747152     Buffer Size: 47891      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:31:50,958][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 8.338    Value Loss: 7.377    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 748345     Buffer Size: 47770      Transition Number: 1500.086k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:35:04,614][train][INFO][train.py>_log] ==> #763000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 7.695    Value Loss: 7.445    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 749177     Buffer Size: 47317      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:38:25,356][train][INFO][train.py>_log] ==> #764000     Total Loss: 3.492    [weighted Loss:3.492    Policy Loss: 9.769    Value Loss: 7.318    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 750036     Buffer Size: 46812      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:41:44,262][train][INFO][train.py>_log] ==> #765000     Total Loss: 3.456    [weighted Loss:3.456    Policy Loss: 8.089    Value Loss: 7.363    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 751119     Buffer Size: 46444      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:45:01,986][train][INFO][train.py>_log] ==> #766000     Total Loss: 3.086    [weighted Loss:3.086    Policy Loss: 8.082    Value Loss: 7.485    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 752218     Buffer Size: 46155      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:48:19,171][train][INFO][train.py>_log] ==> #767000     Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 8.671    Value Loss: 7.363    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 753121     Buffer Size: 45668      Transition Number: 1500.079k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:51:38,949][train][INFO][train.py>_log] ==> #768000     Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 8.738    Value Loss: 7.907    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 754029     Buffer Size: 45322      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:54:57,512][train][INFO][train.py>_log] ==> #769000     Total Loss: 3.176    [weighted Loss:3.176    Policy Loss: 10.493   Value Loss: 7.775    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 755075     Buffer Size: 45136      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 19:58:18,593][train][INFO][train.py>_log] ==> #770000     Total Loss: 3.135    [weighted Loss:3.135    Policy Loss: 9.075    Value Loss: 7.530    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 756057     Buffer Size: 44966      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:01:40,159][train][INFO][train.py>_log] ==> #771000     Total Loss: 3.624    [weighted Loss:3.624    Policy Loss: 9.208    Value Loss: 7.338    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 757141     Buffer Size: 44826      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:05:00,981][train][INFO][train.py>_log] ==> #772000     Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 8.356    Value Loss: 7.037    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 758188     Buffer Size: 44185      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:08:22,177][train][INFO][train.py>_log] ==> #773000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 8.090    Value Loss: 7.172    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 759237     Buffer Size: 43528      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:11:41,363][train][INFO][train.py>_log] ==> #774000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 9.100    Value Loss: 7.387    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 760290     Buffer Size: 42790      Transition Number: 1500.032k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:15:01,120][train][INFO][train.py>_log] ==> #775000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 8.569    Value Loss: 7.290    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 761477     Buffer Size: 42030      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:18:23,154][train][INFO][train.py>_log] ==> #776000     Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 9.078    Value Loss: 7.807    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 762610     Buffer Size: 41439      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:21:40,122][train][INFO][train.py>_log] ==> #777000     Total Loss: 1.309    [weighted Loss:1.309    Policy Loss: 9.745    Value Loss: 7.664    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 763574     Buffer Size: 40834      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:24:58,378][train][INFO][train.py>_log] ==> #778000     Total Loss: 4.590    [weighted Loss:4.590    Policy Loss: 10.111   Value Loss: 7.666    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 764507     Buffer Size: 40395      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:28:20,766][train][INFO][train.py>_log] ==> #779000     Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 9.683    Value Loss: 7.370    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 765925     Buffer Size: 40366      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:31:43,222][train][INFO][train.py>_log] ==> #780000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 9.532    Value Loss: 7.473    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 767399     Buffer Size: 40565      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:35:05,228][train][INFO][train.py>_log] ==> #781000     Total Loss: 4.256    [weighted Loss:4.256    Policy Loss: 9.214    Value Loss: 7.352    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 768714     Buffer Size: 40724      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:38:28,524][train][INFO][train.py>_log] ==> #782000     Total Loss: 1.253    [weighted Loss:1.253    Policy Loss: 10.102   Value Loss: 7.384    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 770038     Buffer Size: 40805      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:41:48,342][train][INFO][train.py>_log] ==> #783000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 9.574    Value Loss: 7.604    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 771557     Buffer Size: 41062      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:45:09,060][train][INFO][train.py>_log] ==> #784000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 9.918    Value Loss: 7.513    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 773056     Buffer Size: 41346      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:48:30,297][train][INFO][train.py>_log] ==> #785000     Total Loss: 4.137    [weighted Loss:4.137    Policy Loss: 10.029   Value Loss: 8.078    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 774392     Buffer Size: 41459      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:51:51,595][train][INFO][train.py>_log] ==> #786000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 8.521    Value Loss: 7.286    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 775756     Buffer Size: 41711      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:55:11,750][train][INFO][train.py>_log] ==> #787000     Total Loss: 3.878    [weighted Loss:3.878    Policy Loss: 9.036    Value Loss: 7.478    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 776795     Buffer Size: 41680      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-11 20:58:32,959][train][INFO][train.py>_log] ==> #788000     Total Loss: 3.403    [weighted Loss:3.403    Policy Loss: 8.267    Value Loss: 7.831    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 777821     Buffer Size: 41750      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:01:52,456][train][INFO][train.py>_log] ==> #789000     Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 9.479    Value Loss: 7.252    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 778859     Buffer Size: 41802      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:05:11,003][train][INFO][train.py>_log] ==> #790000     Total Loss: 4.513    [weighted Loss:4.513    Policy Loss: 10.143   Value Loss: 7.526    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 779997     Buffer Size: 41490      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:08:34,609][train][INFO][train.py>_log] ==> #791000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 8.735    Value Loss: 7.485    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 781234     Buffer Size: 41152      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:11:54,743][train][INFO][train.py>_log] ==> #792000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 9.264    Value Loss: 7.312    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 782441     Buffer Size: 41078      Transition Number: 1500.201k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:15:14,343][train][INFO][train.py>_log] ==> #793000     Total Loss: 3.320    [weighted Loss:3.320    Policy Loss: 9.178    Value Loss: 7.889    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 783445     Buffer Size: 40829      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:18:37,218][train][INFO][train.py>_log] ==> #794000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 9.253    Value Loss: 7.621    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 784547     Buffer Size: 40352      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:21:57,093][train][INFO][train.py>_log] ==> #795000     Total Loss: 3.700    [weighted Loss:3.700    Policy Loss: 8.901    Value Loss: 7.472    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 785553     Buffer Size: 39804      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:25:20,387][train][INFO][train.py>_log] ==> #796000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 8.401    Value Loss: 7.502    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 786586     Buffer Size: 39568      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:28:41,544][train][INFO][train.py>_log] ==> #797000     Total Loss: 4.261    [weighted Loss:4.261    Policy Loss: 8.723    Value Loss: 7.440    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 787607     Buffer Size: 39395      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:32:00,053][train][INFO][train.py>_log] ==> #798000     Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 8.980    Value Loss: 7.144    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 788654     Buffer Size: 39541      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:35:24,133][train][INFO][train.py>_log] ==> #799000     Total Loss: 4.826    [weighted Loss:4.826    Policy Loss: 8.452    Value Loss: 7.540    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 789672     Buffer Size: 39657      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:38:46,438][train][INFO][train.py>_log] ==> #800000     Total Loss: 3.063    [weighted Loss:3.063    Policy Loss: 8.985    Value Loss: 7.396    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 790702     Buffer Size: 39587      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:42:06,358][train][INFO][train.py>_log] ==> #801000     Total Loss: 5.444    [weighted Loss:5.444    Policy Loss: 9.652    Value Loss: 7.417    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 791697     Buffer Size: 39503      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:45:28,287][train][INFO][train.py>_log] ==> #802000     Total Loss: 4.147    [weighted Loss:4.147    Policy Loss: 8.925    Value Loss: 7.559    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 792661     Buffer Size: 39551      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:48:50,042][train][INFO][train.py>_log] ==> #803000     Total Loss: 4.993    [weighted Loss:4.993    Policy Loss: 9.645    Value Loss: 7.148    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 793835     Buffer Size: 39758      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:52:11,651][train][INFO][train.py>_log] ==> #804000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 9.645    Value Loss: 7.253    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 794977     Buffer Size: 39838      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:55:32,353][train][INFO][train.py>_log] ==> #805000     Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 10.508   Value Loss: 7.588    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 796295     Buffer Size: 40114      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-11 21:58:55,916][train][INFO][train.py>_log] ==> #806000     Total Loss: 4.459    [weighted Loss:4.459    Policy Loss: 9.336    Value Loss: 7.494    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 797650     Buffer Size: 40364      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:02:14,646][train][INFO][train.py>_log] ==> #807000     Total Loss: 4.649    [weighted Loss:4.649    Policy Loss: 8.918    Value Loss: 7.408    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 798993     Buffer Size: 40640      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:05:34,225][train][INFO][train.py>_log] ==> #808000     Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 10.406   Value Loss: 7.583    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 800371     Buffer Size: 40911      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:08:56,663][train][INFO][train.py>_log] ==> #809000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 10.128   Value Loss: 7.043    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 801946     Buffer Size: 41352      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:12:18,047][train][INFO][train.py>_log] ==> #810000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 9.201    Value Loss: 7.658    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 803499     Buffer Size: 41720      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:15:35,730][train][INFO][train.py>_log] ==> #811000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 8.522    Value Loss: 7.180    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 804897     Buffer Size: 42012      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:18:56,709][train][INFO][train.py>_log] ==> #812000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 9.469    Value Loss: 7.346    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 806286     Buffer Size: 42421      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:22:16,780][train][INFO][train.py>_log] ==> #813000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 10.321   Value Loss: 7.180    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 807331     Buffer Size: 42443      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:25:36,463][train][INFO][train.py>_log] ==> #814000     Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 8.919    Value Loss: 7.525    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 808394     Buffer Size: 42095      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:28:59,758][train][INFO][train.py>_log] ==> #815000     Total Loss: 4.610    [weighted Loss:4.610    Policy Loss: 11.474   Value Loss: 7.909    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 809839     Buffer Size: 42047      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:32:18,911][train][INFO][train.py>_log] ==> #816000     Total Loss: 3.496    [weighted Loss:3.496    Policy Loss: 9.792    Value Loss: 7.412    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 811297     Buffer Size: 42167      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:35:37,674][train][INFO][train.py>_log] ==> #817000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 9.648    Value Loss: 7.485    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 812805     Buffer Size: 42362      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:39:00,370][train][INFO][train.py>_log] ==> #818000     Total Loss: 3.458    [weighted Loss:3.458    Policy Loss: 9.332    Value Loss: 7.449    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 814379     Buffer Size: 42387      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:42:19,659][train][INFO][train.py>_log] ==> #819000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 8.452    Value Loss: 7.609    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 815556     Buffer Size: 42131      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:45:41,053][train][INFO][train.py>_log] ==> #820000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 10.315   Value Loss: 7.412    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 816743     Buffer Size: 41973      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:49:03,965][train][INFO][train.py>_log] ==> #821000     Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 9.032    Value Loss: 7.766    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 818323     Buffer Size: 42233      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:52:25,408][train][INFO][train.py>_log] ==> #822000     Total Loss: 3.957    [weighted Loss:3.957    Policy Loss: 9.223    Value Loss: 7.312    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 819978     Buffer Size: 42738      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:55:46,717][train][INFO][train.py>_log] ==> #823000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 7.398    Value Loss: 7.140    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 820973     Buffer Size: 42712      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-11 22:59:05,319][train][INFO][train.py>_log] ==> #824000     Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 9.108    Value Loss: 7.733    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 821980     Buffer Size: 42668      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:02:25,143][train][INFO][train.py>_log] ==> #825000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 8.142    Value Loss: 7.290    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 822953     Buffer Size: 42555      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:05:45,257][train][INFO][train.py>_log] ==> #826000     Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 8.905    Value Loss: 7.271    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 823996     Buffer Size: 42414      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:09:06,169][train][INFO][train.py>_log] ==> #827000     Total Loss: 3.368    [weighted Loss:3.368    Policy Loss: 8.990    Value Loss: 7.493    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 825096     Buffer Size: 42310      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:12:26,851][train][INFO][train.py>_log] ==> #828000     Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 9.303    Value Loss: 7.538    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 826149     Buffer Size: 42314      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:15:47,754][train][INFO][train.py>_log] ==> #829000     Total Loss: 1.527    [weighted Loss:1.527    Policy Loss: 9.632    Value Loss: 7.000    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 827640     Buffer Size: 42701      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:19:08,622][train][INFO][train.py>_log] ==> #830000     Total Loss: 4.352    [weighted Loss:4.352    Policy Loss: 9.120    Value Loss: 7.412    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 829130     Buffer Size: 43137      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:22:25,750][train][INFO][train.py>_log] ==> #831000     Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 8.618    Value Loss: 7.498    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 830371     Buffer Size: 43363      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:25:42,366][train][INFO][train.py>_log] ==> #832000     Total Loss: 2.769    [weighted Loss:2.769    Policy Loss: 9.620    Value Loss: 7.586    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 831586     Buffer Size: 43518      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:29:02,734][train][INFO][train.py>_log] ==> #833000     Total Loss: 2.967    [weighted Loss:2.967    Policy Loss: 7.303    Value Loss: 7.200    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 833284     Buffer Size: 44110      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:32:22,632][train][INFO][train.py>_log] ==> #834000     Total Loss: 5.090    [weighted Loss:5.090    Policy Loss: 9.739    Value Loss: 7.275    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 835029     Buffer Size: 44826      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:35:40,060][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 7.831    Value Loss: 7.795    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 836492     Buffer Size: 45274      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:38:56,940][train][INFO][train.py>_log] ==> #836000     Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 8.384    Value Loss: 7.448    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 837933     Buffer Size: 45698      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:42:14,423][train][INFO][train.py>_log] ==> #837000     Total Loss: 3.650    [weighted Loss:3.650    Policy Loss: 8.294    Value Loss: 7.420    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 839259     Buffer Size: 46006      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:45:29,290][train][INFO][train.py>_log] ==> #838000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 8.897    Value Loss: 7.074    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 840577     Buffer Size: 46275      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:48:48,676][train][INFO][train.py>_log] ==> #839000     Total Loss: 3.815    [weighted Loss:3.815    Policy Loss: 9.098    Value Loss: 7.339    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 841703     Buffer Size: 46217      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:52:08,307][train][INFO][train.py>_log] ==> #840000     Total Loss: 3.733    [weighted Loss:3.733    Policy Loss: 9.374    Value Loss: 7.314    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 842819     Buffer Size: 46026      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:55:26,747][train][INFO][train.py>_log] ==> #841000     Total Loss: 3.025    [weighted Loss:3.025    Policy Loss: 8.656    Value Loss: 7.561    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 844044     Buffer Size: 45949      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-11 23:58:47,243][train][INFO][train.py>_log] ==> #842000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 9.775    Value Loss: 7.455    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 845300     Buffer Size: 45852      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:02:04,098][train][INFO][train.py>_log] ==> #843000     Total Loss: 3.979    [weighted Loss:3.979    Policy Loss: 9.106    Value Loss: 7.569    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 846334     Buffer Size: 45537      Transition Number: 1500.182k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:05:23,890][train][INFO][train.py>_log] ==> #844000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 8.885    Value Loss: 7.784    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 847348     Buffer Size: 45093      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:08:44,703][train][INFO][train.py>_log] ==> #845000     Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 9.353    Value Loss: 7.283    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 848402     Buffer Size: 44620      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:12:06,013][train][INFO][train.py>_log] ==> #846000     Total Loss: 4.281    [weighted Loss:4.281    Policy Loss: 8.937    Value Loss: 7.245    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 849483     Buffer Size: 44267      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:15:27,099][train][INFO][train.py>_log] ==> #847000     Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 10.899   Value Loss: 7.580    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 850492     Buffer Size: 43959      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:18:46,765][train][INFO][train.py>_log] ==> #848000     Total Loss: 3.023    [weighted Loss:3.023    Policy Loss: 8.604    Value Loss: 7.247    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 851487     Buffer Size: 43936      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:22:05,586][train][INFO][train.py>_log] ==> #849000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 10.169   Value Loss: 7.680    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 853203     Buffer Size: 44500      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:25:24,337][train][INFO][train.py>_log] ==> #850000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 10.508   Value Loss: 7.427    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 854980     Buffer Size: 44821      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:28:42,688][train][INFO][train.py>_log] ==> #851000     Total Loss: 3.781    [weighted Loss:3.781    Policy Loss: 10.199   Value Loss: 7.792    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 856560     Buffer Size: 44938      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:32:03,294][train][INFO][train.py>_log] ==> #852000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 9.910    Value Loss: 7.322    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 858124     Buffer Size: 44956      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:35:23,103][train][INFO][train.py>_log] ==> #853000     Total Loss: 3.548    [weighted Loss:3.548    Policy Loss: 10.536   Value Loss: 7.363    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 859683     Buffer Size: 45046      Transition Number: 1500.098k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:38:44,873][train][INFO][train.py>_log] ==> #854000     Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 9.614    Value Loss: 7.529    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 861258     Buffer Size: 45375      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:42:04,176][train][INFO][train.py>_log] ==> #855000     Total Loss: 4.216    [weighted Loss:4.216    Policy Loss: 11.903   Value Loss: 7.336    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 862822     Buffer Size: 45677      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:45:21,126][train][INFO][train.py>_log] ==> #856000     Total Loss: 3.145    [weighted Loss:3.145    Policy Loss: 10.488   Value Loss: 7.572    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 864434     Buffer Size: 45704      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:48:42,584][train][INFO][train.py>_log] ==> #857000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 10.942   Value Loss: 7.700    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 865956     Buffer Size: 45712      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:52:02,080][train][INFO][train.py>_log] ==> #858000     Total Loss: 3.656    [weighted Loss:3.656    Policy Loss: 9.536    Value Loss: 7.287    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 867494     Buffer Size: 46231      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:55:20,476][train][INFO][train.py>_log] ==> #859000     Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 9.240    Value Loss: 7.525    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 868895     Buffer Size: 46611      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 00:58:38,369][train][INFO][train.py>_log] ==> #860000     Total Loss: 3.581    [weighted Loss:3.581    Policy Loss: 9.640    Value Loss: 7.182    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 870266     Buffer Size: 46951      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:01:53,654][train][INFO][train.py>_log] ==> #861000     Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 9.233    Value Loss: 7.574    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 871489     Buffer Size: 47174      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:05:09,682][train][INFO][train.py>_log] ==> #862000     Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 9.968    Value Loss: 7.863    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 872739     Buffer Size: 47341      Transition Number: 1500.127k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:08:26,474][train][INFO][train.py>_log] ==> #863000     Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 8.955    Value Loss: 7.639    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 874274     Buffer Size: 47702      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:11:46,805][train][INFO][train.py>_log] ==> #864000     Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 9.736    Value Loss: 7.352    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 875826     Buffer Size: 47734      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:15:05,759][train][INFO][train.py>_log] ==> #865000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 10.320   Value Loss: 7.719    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 877195     Buffer Size: 47706      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:18:23,641][train][INFO][train.py>_log] ==> #866000     Total Loss: 4.411    [weighted Loss:4.411    Policy Loss: 9.485    Value Loss: 7.366    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 878582     Buffer Size: 47804      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:21:42,818][train][INFO][train.py>_log] ==> #867000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 9.673    Value Loss: 7.533    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 879925     Buffer Size: 47895      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:25:00,816][train][INFO][train.py>_log] ==> #868000     Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 9.251    Value Loss: 7.259    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 881193     Buffer Size: 47492      Transition Number: 1500.147k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:28:20,191][train][INFO][train.py>_log] ==> #869000     Total Loss: 3.783    [weighted Loss:3.783    Policy Loss: 10.164   Value Loss: 7.345    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 882464     Buffer Size: 47079      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:31:37,534][train][INFO][train.py>_log] ==> #870000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 9.804    Value Loss: 7.408    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 883651     Buffer Size: 46859      Transition Number: 1500.142k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:34:56,887][train][INFO][train.py>_log] ==> #871000     Total Loss: 1.185    [weighted Loss:1.185    Policy Loss: 8.845    Value Loss: 7.552    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 885523     Buffer Size: 47250      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:38:16,640][train][INFO][train.py>_log] ==> #872000     Total Loss: 3.568    [weighted Loss:3.568    Policy Loss: 9.814    Value Loss: 7.212    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 887377     Buffer Size: 47673      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:41:35,686][train][INFO][train.py>_log] ==> #873000     Total Loss: 3.404    [weighted Loss:3.404    Policy Loss: 9.854    Value Loss: 7.038    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 888747     Buffer Size: 47726      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:44:50,404][train][INFO][train.py>_log] ==> #874000     Total Loss: 5.508    [weighted Loss:5.508    Policy Loss: 9.587    Value Loss: 7.730    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 890016     Buffer Size: 47913      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:48:10,203][train][INFO][train.py>_log] ==> #875000     Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 10.184   Value Loss: 7.484    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 891312     Buffer Size: 48045      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:51:28,582][train][INFO][train.py>_log] ==> #876000     Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 9.376    Value Loss: 7.621    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 892616     Buffer Size: 48157      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:54:47,534][train][INFO][train.py>_log] ==> #877000     Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 10.812   Value Loss: 7.683    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 894165     Buffer Size: 48454      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-12 01:58:04,010][train][INFO][train.py>_log] ==> #878000     Total Loss: 3.865    [weighted Loss:3.865    Policy Loss: 9.418    Value Loss: 7.660    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 895704     Buffer Size: 48937      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:01:18,287][train][INFO][train.py>_log] ==> #879000     Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 10.116   Value Loss: 7.158    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 896917     Buffer Size: 49139      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:04:34,006][train][INFO][train.py>_log] ==> #880000     Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 10.417   Value Loss: 7.563    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 898082     Buffer Size: 49277      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:07:51,284][train][INFO][train.py>_log] ==> #881000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 9.910    Value Loss: 7.613    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 900164     Buffer Size: 50260      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:11:05,834][train][INFO][train.py>_log] ==> #882000     Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 9.679    Value Loss: 7.224    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 902254     Buffer Size: 51299      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:14:21,831][train][INFO][train.py>_log] ==> #883000     Total Loss: 3.756    [weighted Loss:3.756    Policy Loss: 9.934    Value Loss: 7.378    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 904403     Buffer Size: 52139      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:17:40,138][train][INFO][train.py>_log] ==> #884000     Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 9.794    Value Loss: 7.505    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 906593     Buffer Size: 52612      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:20:54,890][train][INFO][train.py>_log] ==> #885000     Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 9.928    Value Loss: 7.470    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 907930     Buffer Size: 52398      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-12 02:24:10,296][train][INFO][train.py>_log] ==> #886000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 9.185    Value Loss: 7.363    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 909302     Buffer Size: 52247      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
