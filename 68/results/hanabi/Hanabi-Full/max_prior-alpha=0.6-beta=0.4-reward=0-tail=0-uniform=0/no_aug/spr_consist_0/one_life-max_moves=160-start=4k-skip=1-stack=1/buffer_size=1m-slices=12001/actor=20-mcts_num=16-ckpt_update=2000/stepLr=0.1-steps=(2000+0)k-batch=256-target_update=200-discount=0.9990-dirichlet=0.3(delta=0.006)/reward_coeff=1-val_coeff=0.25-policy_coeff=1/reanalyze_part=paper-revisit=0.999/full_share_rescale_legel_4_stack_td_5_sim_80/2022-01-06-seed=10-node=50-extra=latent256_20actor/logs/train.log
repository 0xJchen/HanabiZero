[2022-01-06 13:24:42,364][train][INFO][train.py>_log] ==> #0          Total Loss: 55.928   [weighted Loss:55.928   Policy Loss: 14.827   Value Loss: 37.125   Reward Loss: 31.820   Consistency Loss: 0.000    ] Replay Episodes Collected: 593        Buffer Size: 593        Transition Number: 6.492   k Batch Size: 256        Lr: 0.00000 
[2022-01-06 13:27:31,488][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.530    [weighted Loss:4.530    Policy Loss: 13.780   Value Loss: 3.804    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 4532       Buffer Size: 4532       Transition Number: 56.070  k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:30:20,199][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.923    [weighted Loss:6.923    Policy Loss: 13.985   Value Loss: 3.649    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 8294       Buffer Size: 8294       Transition Number: 103.072 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:33:10,340][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.327    [weighted Loss:3.327    Policy Loss: 11.076   Value Loss: 3.350    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 13169      Buffer Size: 13169      Transition Number: 152.180 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:35:58,300][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.705    [weighted Loss:5.705    Policy Loss: 13.816   Value Loss: 3.447    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 17926      Buffer Size: 17926      Transition Number: 199.020 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:38:51,873][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.535    [weighted Loss:5.535    Policy Loss: 13.688   Value Loss: 3.095    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 20399      Buffer Size: 20399      Transition Number: 243.939 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:41:45,389][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.672    [weighted Loss:5.672    Policy Loss: 13.553   Value Loss: 3.190    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 22944      Buffer Size: 22944      Transition Number: 292.889 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:44:36,946][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.169    [weighted Loss:5.169    Policy Loss: 13.312   Value Loss: 3.075    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 25713      Buffer Size: 25713      Transition Number: 338.757 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:47:27,594][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.275    [weighted Loss:4.275    Policy Loss: 14.056   Value Loss: 3.132    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 28511      Buffer Size: 28511      Transition Number: 383.390 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:50:03,856][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.093    [weighted Loss:5.093    Policy Loss: 13.159   Value Loss: 3.306    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 30236      Buffer Size: 30236      Transition Number: 421.053 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:52:37,617][train][INFO][train.py>_log] ==> #10000      Total Loss: 6.386    [weighted Loss:6.386    Policy Loss: 13.616   Value Loss: 2.885    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 31911      Buffer Size: 31911      Transition Number: 461.882 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:55:11,436][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.693    [weighted Loss:4.693    Policy Loss: 12.299   Value Loss: 3.079    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 33588      Buffer Size: 33588      Transition Number: 500.109 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 13:57:44,810][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.707    [weighted Loss:4.707    Policy Loss: 12.571   Value Loss: 2.979    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 35212      Buffer Size: 35212      Transition Number: 538.574 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:00:21,050][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.581    [weighted Loss:4.581    Policy Loss: 11.382   Value Loss: 3.048    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 38342      Buffer Size: 38342      Transition Number: 583.581 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:02:57,409][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.742    [weighted Loss:4.742    Policy Loss: 13.306   Value Loss: 3.192    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 41571      Buffer Size: 41571      Transition Number: 625.299 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:05:33,069][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.424    [weighted Loss:4.424    Policy Loss: 12.516   Value Loss: 3.378    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 43765      Buffer Size: 43765      Transition Number: 659.317 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:08:11,376][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.849    [weighted Loss:3.849    Policy Loss: 11.513   Value Loss: 3.083    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 46039      Buffer Size: 46039      Transition Number: 700.597 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:10:45,237][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 10.848   Value Loss: 3.124    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 47344      Buffer Size: 47344      Transition Number: 737.392 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:13:19,543][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.842    [weighted Loss:3.842    Policy Loss: 10.929   Value Loss: 3.397    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 48591      Buffer Size: 48591      Transition Number: 772.528 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:15:57,176][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.561    [weighted Loss:4.561    Policy Loss: 10.196   Value Loss: 3.537    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 49432      Buffer Size: 49432      Transition Number: 804.791 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:18:31,014][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.580    [weighted Loss:3.580    Policy Loss: 7.890    Value Loss: 3.889    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 50276      Buffer Size: 50276      Transition Number: 843.763 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:21:07,926][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 7.633    Value Loss: 3.344    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 50957      Buffer Size: 50957      Transition Number: 880.333 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:23:45,592][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.081    [weighted Loss:3.081    Policy Loss: 6.324    Value Loss: 4.084    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 51625      Buffer Size: 51625      Transition Number: 916.238 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:26:32,291][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 6.898    Value Loss: 3.738    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 52258      Buffer Size: 52258      Transition Number: 956.396 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:29:14,684][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 6.128    Value Loss: 3.834    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 52900      Buffer Size: 52900      Transition Number: 997.777 k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:31:56,104][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.933    [weighted Loss:1.933    Policy Loss: 5.654    Value Loss: 3.986    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 53510      Buffer Size: 53510      Transition Number: 1037.161k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:34:39,019][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 6.003    Value Loss: 3.829    Reward Loss: 0.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 54128      Buffer Size: 54128      Transition Number: 1076.774k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:37:18,733][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 5.476    Value Loss: 4.305    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 54735      Buffer Size: 54735      Transition Number: 1117.951k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:39:59,527][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 5.004    Value Loss: 3.845    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 55350      Buffer Size: 55350      Transition Number: 1159.177k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:42:37,620][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.308    [weighted Loss:1.308    Policy Loss: 4.792    Value Loss: 3.861    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 55936      Buffer Size: 55936      Transition Number: 1201.040k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:45:23,864][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 4.722    Value Loss: 3.890    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 56532      Buffer Size: 56532      Transition Number: 1243.573k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:48:10,685][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 4.862    Value Loss: 4.028    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 57166      Buffer Size: 57166      Transition Number: 1286.918k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:51:02,431][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 4.327    Value Loss: 3.693    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 57828      Buffer Size: 57828      Transition Number: 1332.394k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:53:51,598][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 4.276    Value Loss: 3.878    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 58437      Buffer Size: 58437      Transition Number: 1373.972k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:56:40,773][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 4.338    Value Loss: 3.945    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 59111      Buffer Size: 59111      Transition Number: 1419.793k Batch Size: 256        Lr: 0.10000 
[2022-01-06 14:59:37,418][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 4.809    Value Loss: 3.985    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 59797      Buffer Size: 59797      Transition Number: 1463.951k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:02:34,112][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 4.692    Value Loss: 3.758    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 60480      Buffer Size: 59664      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:05:36,699][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.490    [weighted Loss:1.490    Policy Loss: 4.306    Value Loss: 4.391    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 61229      Buffer Size: 56588      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:08:41,513][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.282    [weighted Loss:1.282    Policy Loss: 4.378    Value Loss: 3.924    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 61978      Buffer Size: 53579      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:11:47,026][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 4.298    Value Loss: 4.213    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 62743      Buffer Size: 49585      Transition Number: 1500.070k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:14:54,354][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 4.908    Value Loss: 4.577    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 63525      Buffer Size: 45425      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:18:02,527][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.478    [weighted Loss:1.478    Policy Loss: 4.753    Value Loss: 4.190    Reward Loss: 0.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 64303      Buffer Size: 43600      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:21:12,906][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.506    [weighted Loss:1.506    Policy Loss: 4.403    Value Loss: 4.346    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 65103      Buffer Size: 41913      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:24:20,449][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 4.360    Value Loss: 4.223    Reward Loss: 0.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 65874      Buffer Size: 39611      Transition Number: 1500.065k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:27:29,220][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 5.038    Value Loss: 4.023    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 66632      Buffer Size: 37519      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:30:37,693][train][INFO][train.py>_log] ==> #45000      Total Loss: 0.934    [weighted Loss:0.934    Policy Loss: 4.433    Value Loss: 4.478    Reward Loss: 0.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 67429      Buffer Size: 36182      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:33:46,452][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 4.323    Value Loss: 4.643    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 68243      Buffer Size: 34894      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:36:55,553][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 4.125    Value Loss: 4.528    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 69026      Buffer Size: 33540      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:40:06,307][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 4.145    Value Loss: 4.425    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 69799      Buffer Size: 30704      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:43:15,285][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 5.004    Value Loss: 4.663    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 70565      Buffer Size: 27873      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:46:27,375][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 4.599    Value Loss: 4.661    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 71344      Buffer Size: 25921      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:49:37,144][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 5.224    Value Loss: 4.529    Reward Loss: 0.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 72120      Buffer Size: 24601      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:52:49,979][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.574    [weighted Loss:1.574    Policy Loss: 4.115    Value Loss: 4.522    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 72893      Buffer Size: 23741      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:55:59,443][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 5.381    Value Loss: 4.548    Reward Loss: 0.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 73681      Buffer Size: 23378      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-06 15:59:09,536][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.055    [weighted Loss:1.055    Policy Loss: 3.623    Value Loss: 4.496    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 74453      Buffer Size: 23224      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:02:19,235][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 5.052    Value Loss: 4.608    Reward Loss: 0.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 75231      Buffer Size: 23184      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:05:31,132][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 4.280    Value Loss: 4.642    Reward Loss: 0.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 76052      Buffer Size: 23205      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:08:41,823][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 5.183    Value Loss: 4.930    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 76861      Buffer Size: 23279      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:11:55,847][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.878    [weighted Loss:2.878    Policy Loss: 5.296    Value Loss: 4.685    Reward Loss: 0.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 77782      Buffer Size: 23403      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:15:08,536][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.852    [weighted Loss:1.852    Policy Loss: 5.224    Value Loss: 4.437    Reward Loss: 0.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 78629      Buffer Size: 23559      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:18:19,070][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 5.512    Value Loss: 4.924    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 79531      Buffer Size: 23768      Transition Number: 1500.171k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:21:29,411][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.677    [weighted Loss:2.677    Policy Loss: 5.426    Value Loss: 4.602    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 80749      Buffer Size: 24302      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:24:41,999][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 5.943    Value Loss: 4.915    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 81970      Buffer Size: 24796      Transition Number: 1500.112k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:27:55,184][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.081    [weighted Loss:3.081    Policy Loss: 6.781    Value Loss: 5.127    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 83213      Buffer Size: 25313      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:31:06,906][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 5.412    Value Loss: 4.972    Reward Loss: 0.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 84400      Buffer Size: 25800      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:34:18,688][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.081    [weighted Loss:3.081    Policy Loss: 6.044    Value Loss: 4.863    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 85373      Buffer Size: 26054      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:37:26,836][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.404    [weighted Loss:1.404    Policy Loss: 4.442    Value Loss: 5.031    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 86357      Buffer Size: 26339      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:40:35,773][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 5.103    Value Loss: 4.995    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 87208      Buffer Size: 26462      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:43:44,713][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 4.007    Value Loss: 5.168    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 88078      Buffer Size: 26596      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:46:55,271][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.575    [weighted Loss:1.575    Policy Loss: 4.162    Value Loss: 5.025    Reward Loss: 0.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 89068      Buffer Size: 26778      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:50:04,875][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 4.173    Value Loss: 5.142    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 89985      Buffer Size: 26939      Transition Number: 1500.176k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:53:16,358][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 4.375    Value Loss: 5.044    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 90879      Buffer Size: 27017      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:56:33,450][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.165    [weighted Loss:2.165    Policy Loss: 3.719    Value Loss: 4.979    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 91812      Buffer Size: 27104      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-06 16:59:44,298][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 4.571    Value Loss: 5.098    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 92665      Buffer Size: 27185      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:02:53,066][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 4.373    Value Loss: 5.059    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 93517      Buffer Size: 27283      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:06:01,708][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.005    [weighted Loss:1.005    Policy Loss: 3.682    Value Loss: 5.046    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 94331      Buffer Size: 27322      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:09:12,559][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 3.813    Value Loss: 4.892    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 95163      Buffer Size: 27353      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:12:23,286][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 4.398    Value Loss: 5.252    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 96006      Buffer Size: 27378      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:15:34,575][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 4.733    Value Loss: 5.159    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 96856      Buffer Size: 27435      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:18:45,582][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 4.324    Value Loss: 5.271    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 97687      Buffer Size: 27494      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:21:56,297][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 4.089    Value Loss: 4.875    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 98544      Buffer Size: 27581      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:25:07,825][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 3.899    Value Loss: 5.090    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 99375      Buffer Size: 27637      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:28:17,996][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 4.158    Value Loss: 4.993    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 100223     Buffer Size: 27715      Transition Number: 1499.928k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:31:27,222][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.683    [weighted Loss:1.683    Policy Loss: 4.250    Value Loss: 5.324    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 101018     Buffer Size: 27703      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:34:39,323][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 4.014    Value Loss: 4.831    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 101811     Buffer Size: 27678      Transition Number: 1500.172k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:37:48,443][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 4.142    Value Loss: 5.210    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 102593     Buffer Size: 27692      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:41:00,488][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 4.125    Value Loss: 4.890    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 103400     Buffer Size: 27680      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:44:12,873][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 4.550    Value Loss: 5.474    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 104252     Buffer Size: 27683      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:47:24,623][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 4.201    Value Loss: 4.943    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 105081     Buffer Size: 27653      Transition Number: 1500.132k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:50:36,578][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 4.150    Value Loss: 5.446    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 105847     Buffer Size: 27568      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:53:47,566][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.921    [weighted Loss:2.921    Policy Loss: 4.931    Value Loss: 5.160    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 106647     Buffer Size: 27419      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-06 17:57:00,732][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 3.833    Value Loss: 5.061    Reward Loss: 0.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 107434     Buffer Size: 27026      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:00:14,390][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 3.843    Value Loss: 5.069    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 108241     Buffer Size: 26523      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:03:29,044][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.204    [weighted Loss:1.204    Policy Loss: 4.453    Value Loss: 4.927    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 109082     Buffer Size: 26057      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:06:42,527][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 4.002    Value Loss: 5.180    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 109942     Buffer Size: 25640      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:09:56,714][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 4.210    Value Loss: 5.260    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 110873     Buffer Size: 25465      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:13:10,136][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 4.096    Value Loss: 5.222    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 111735     Buffer Size: 25307      Transition Number: 1500.140k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:16:23,933][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 4.338    Value Loss: 5.093    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 112675     Buffer Size: 25398      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:19:37,740][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 4.435    Value Loss: 5.272    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 113609     Buffer Size: 25426      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:22:51,443][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.494    [weighted Loss:2.494    Policy Loss: 4.581    Value Loss: 4.980    Reward Loss: 0.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 114573     Buffer Size: 25389      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:26:07,688][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 4.544    Value Loss: 5.253    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 115494     Buffer Size: 25373      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:29:21,107][train][INFO][train.py>_log] ==> #101000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 5.194    Value Loss: 5.357    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 116379     Buffer Size: 25355      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:32:36,902][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.692    [weighted Loss:1.692    Policy Loss: 4.497    Value Loss: 5.306    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 117232     Buffer Size: 25317      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:35:51,398][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 4.382    Value Loss: 5.188    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 118068     Buffer Size: 25331      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:39:06,519][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 4.900    Value Loss: 5.324    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 118972     Buffer Size: 25360      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:42:18,470][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 4.230    Value Loss: 5.378    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 119877     Buffer Size: 25447      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:45:32,350][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 4.335    Value Loss: 5.201    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 120796     Buffer Size: 25527      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:48:46,249][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 4.607    Value Loss: 5.596    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 121746     Buffer Size: 25687      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:51:59,192][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 4.971    Value Loss: 5.526    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 122728     Buffer Size: 25827      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:55:14,346][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 4.449    Value Loss: 5.392    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 123604     Buffer Size: 25870      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-06 18:58:26,488][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 4.413    Value Loss: 5.516    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 124478     Buffer Size: 25893      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:01:39,651][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 3.805    Value Loss: 5.686    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 125342     Buffer Size: 25936      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:04:54,122][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 4.334    Value Loss: 5.405    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 126219     Buffer Size: 25992      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:08:07,489][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.400    [weighted Loss:2.400    Policy Loss: 4.704    Value Loss: 5.261    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 127112     Buffer Size: 26149      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:11:20,892][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.374    [weighted Loss:2.374    Policy Loss: 4.272    Value Loss: 5.517    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 128010     Buffer Size: 26314      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:14:34,709][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 4.557    Value Loss: 5.612    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 128940     Buffer Size: 26450      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:17:47,770][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 4.445    Value Loss: 5.691    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 129831     Buffer Size: 26562      Transition Number: 1500.093k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:21:01,327][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 4.157    Value Loss: 5.543    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 130705     Buffer Size: 26642      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:24:13,596][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.112    [weighted Loss:2.112    Policy Loss: 4.508    Value Loss: 5.369    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 131638     Buffer Size: 26735      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:27:28,182][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.639    [weighted Loss:2.639    Policy Loss: 4.790    Value Loss: 5.525    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 132560     Buffer Size: 26876      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:30:43,970][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 5.209    Value Loss: 5.472    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 133489     Buffer Size: 27024      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:33:55,204][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 4.147    Value Loss: 5.746    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 134430     Buffer Size: 27214      Transition Number: 1499.930k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:37:07,544][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 3.975    Value Loss: 5.277    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 135347     Buffer Size: 27384      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:40:20,542][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.297    [weighted Loss:1.297    Policy Loss: 4.663    Value Loss: 5.728    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 136161     Buffer Size: 27437      Transition Number: 1499.928k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:43:34,570][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 3.864    Value Loss: 5.765    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 137012     Buffer Size: 27471      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:46:48,186][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 4.721    Value Loss: 5.556    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 137779     Buffer Size: 27427      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:50:02,232][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 4.682    Value Loss: 5.381    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 138612     Buffer Size: 27322      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:53:15,136][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.359    [weighted Loss:2.359    Policy Loss: 3.990    Value Loss: 5.950    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 139370     Buffer Size: 27156      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:56:28,793][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 4.526    Value Loss: 6.018    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 140182     Buffer Size: 26945      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-06 19:59:43,470][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.600    [weighted Loss:2.600    Policy Loss: 4.574    Value Loss: 5.599    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 140925     Buffer Size: 26777      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:02:57,638][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.759    [weighted Loss:2.759    Policy Loss: 4.274    Value Loss: 5.821    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 141690     Buffer Size: 26586      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:06:12,866][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 4.387    Value Loss: 5.654    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 142547     Buffer Size: 26514      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:09:28,269][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 4.600    Value Loss: 5.893    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 143381     Buffer Size: 26474      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:12:45,940][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 4.343    Value Loss: 5.711    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 144419     Buffer Size: 26607      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:16:01,970][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 4.842    Value Loss: 5.711    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 145431     Buffer Size: 26721      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:19:17,241][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 4.608    Value Loss: 6.039    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 146330     Buffer Size: 26689      Transition Number: 1500.165k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:22:33,000][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 4.494    Value Loss: 6.016    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 147182     Buffer Size: 26628      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:25:46,920][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 5.273    Value Loss: 5.596    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 147972     Buffer Size: 26440      Transition Number: 1500.064k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:29:02,509][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 4.490    Value Loss: 5.726    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 148776     Buffer Size: 26270      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:32:19,008][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 4.474    Value Loss: 5.973    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 149613     Buffer Size: 26160      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:35:36,913][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.772    [weighted Loss:2.772    Policy Loss: 4.291    Value Loss: 6.176    Reward Loss: 0.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 150447     Buffer Size: 26081      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:38:52,603][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 5.010    Value Loss: 5.575    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 151239     Buffer Size: 25989      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:42:08,390][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 5.046    Value Loss: 5.707    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 152075     Buffer Size: 25895      Transition Number: 1500.072k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:45:25,492][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.528    [weighted Loss:1.528    Policy Loss: 4.120    Value Loss: 5.703    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 152897     Buffer Size: 25761      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:48:41,284][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 4.729    Value Loss: 5.864    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 153695     Buffer Size: 25619      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:51:58,487][train][INFO][train.py>_log] ==> #145000     Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 4.494    Value Loss: 5.908    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 154487     Buffer Size: 25490      Transition Number: 1500.054k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:55:14,654][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 4.467    Value Loss: 5.992    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 155295     Buffer Size: 25370      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-06 20:58:32,408][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 4.581    Value Loss: 5.736    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 156137     Buffer Size: 25268      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:01:50,034][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.674    [weighted Loss:2.674    Policy Loss: 4.520    Value Loss: 5.531    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 156935     Buffer Size: 25127      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:05:07,384][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 4.150    Value Loss: 6.009    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 157743     Buffer Size: 25012      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:08:25,645][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 4.576    Value Loss: 5.628    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 158584     Buffer Size: 24886      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:11:40,714][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 4.519    Value Loss: 5.941    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 159392     Buffer Size: 24770      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:14:59,666][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 4.278    Value Loss: 5.790    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 160249     Buffer Size: 24645      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:18:18,836][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 4.179    Value Loss: 5.792    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 161067     Buffer Size: 24621      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:21:35,627][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 4.331    Value Loss: 5.614    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 161907     Buffer Size: 24600      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:24:52,382][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 4.527    Value Loss: 5.627    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 162717     Buffer Size: 24610      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:28:07,909][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 4.229    Value Loss: 5.410    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 163553     Buffer Size: 24632      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:31:26,533][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 4.166    Value Loss: 6.022    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 164793     Buffer Size: 25106      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:34:45,232][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 4.230    Value Loss: 5.687    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 166087     Buffer Size: 25590      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:38:00,560][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 3.638    Value Loss: 6.331    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 167035     Buffer Size: 25780      Transition Number: 1500.108k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:41:15,555][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 4.285    Value Loss: 5.696    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 167992     Buffer Size: 25928      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:44:33,549][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 4.659    Value Loss: 5.896    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 168893     Buffer Size: 26002      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:47:48,901][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 4.874    Value Loss: 5.654    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 169814     Buffer Size: 25987      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:51:03,211][train][INFO][train.py>_log] ==> #163000     Total Loss: 1.622    [weighted Loss:1.622    Policy Loss: 4.138    Value Loss: 5.984    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 170793     Buffer Size: 25926      Transition Number: 1500.158k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:54:21,399][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 4.397    Value Loss: 6.257    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 171777     Buffer Size: 25930      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-06 21:57:37,151][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 4.641    Value Loss: 6.219    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 172632     Buffer Size: 25913      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:00:54,013][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 4.690    Value Loss: 6.052    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 173506     Buffer Size: 25947      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:04:08,662][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.963    [weighted Loss:1.963    Policy Loss: 5.237    Value Loss: 5.787    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 174308     Buffer Size: 25986      Transition Number: 1500.174k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:07:25,210][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 4.059    Value Loss: 5.957    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 175140     Buffer Size: 26013      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:10:40,021][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 4.565    Value Loss: 5.847    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 175971     Buffer Size: 26048      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:13:56,573][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 4.494    Value Loss: 5.604    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 176824     Buffer Size: 26073      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:17:12,502][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 4.577    Value Loss: 5.902    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 177823     Buffer Size: 26260      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:20:30,958][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.306    [weighted Loss:2.306    Policy Loss: 5.397    Value Loss: 5.759    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 178811     Buffer Size: 26442      Transition Number: 1500.122k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:23:48,704][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 5.054    Value Loss: 5.685    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 179760     Buffer Size: 26594      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:27:04,482][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.611    [weighted Loss:2.611    Policy Loss: 4.336    Value Loss: 6.296    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 180730     Buffer Size: 26754      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:30:21,235][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 4.922    Value Loss: 6.097    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 181780     Buffer Size: 26991      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:33:36,787][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 4.969    Value Loss: 5.875    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 182830     Buffer Size: 27237      Transition Number: 1500.081k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:36:53,468][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 4.560    Value Loss: 5.636    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 183875     Buffer Size: 27462      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:40:08,433][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 4.672    Value Loss: 5.727    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 184896     Buffer Size: 27695      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:43:23,645][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 4.376    Value Loss: 5.949    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 185753     Buffer Size: 27750      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:46:40,050][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 3.688    Value Loss: 5.513    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 186593     Buffer Size: 27804      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:49:56,675][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 3.979    Value Loss: 5.805    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 187412     Buffer Size: 27780      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:53:12,192][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.429    [weighted Loss:1.429    Policy Loss: 3.692    Value Loss: 6.099    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 188228     Buffer Size: 27745      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:56:29,717][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 3.528    Value Loss: 5.778    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 189055     Buffer Size: 27744      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-06 22:59:46,873][train][INFO][train.py>_log] ==> #184000     Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 5.002    Value Loss: 5.856    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 189914     Buffer Size: 27753      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:03:02,249][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.032    [weighted Loss:2.032    Policy Loss: 4.319    Value Loss: 5.952    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 190730     Buffer Size: 27779      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:06:19,752][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.618    [weighted Loss:2.618    Policy Loss: 4.650    Value Loss: 5.781    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 191592     Buffer Size: 27681      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:09:36,480][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 4.132    Value Loss: 5.791    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 192446     Buffer Size: 27210      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:12:53,218][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 4.045    Value Loss: 6.028    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 193294     Buffer Size: 26845      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:16:09,606][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 3.673    Value Loss: 5.723    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 194110     Buffer Size: 26713      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:19:26,027][train][INFO][train.py>_log] ==> #190000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 4.131    Value Loss: 5.956    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 194941     Buffer Size: 26600      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:22:42,682][train][INFO][train.py>_log] ==> #191000     Total Loss: 1.640    [weighted Loss:1.640    Policy Loss: 3.795    Value Loss: 5.831    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 195808     Buffer Size: 26536      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:26:01,537][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 4.014    Value Loss: 6.019    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 196650     Buffer Size: 26456      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:29:17,590][train][INFO][train.py>_log] ==> #193000     Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 4.313    Value Loss: 6.096    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 197491     Buffer Size: 26307      Transition Number: 1500.066k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:32:34,967][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.619    [weighted Loss:2.619    Policy Loss: 4.143    Value Loss: 5.732    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 198347     Buffer Size: 26199      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:35:53,479][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 4.723    Value Loss: 5.496    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 199172     Buffer Size: 26161      Transition Number: 1500.270k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:39:09,877][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.125    [weighted Loss:2.125    Policy Loss: 3.643    Value Loss: 5.602    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 199986     Buffer Size: 26131      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:42:26,433][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.320    [weighted Loss:2.320    Policy Loss: 4.363    Value Loss: 5.879    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 200794     Buffer Size: 26071      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:45:44,508][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 3.777    Value Loss: 5.893    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 201629     Buffer Size: 26008      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:49:01,823][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.690    [weighted Loss:2.690    Policy Loss: 4.183    Value Loss: 5.686    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 202472     Buffer Size: 25963      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:52:19,526][train][INFO][train.py>_log] ==> #200000     Total Loss: 3.281    [weighted Loss:3.281    Policy Loss: 4.337    Value Loss: 5.811    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 203301     Buffer Size: 25850      Transition Number: 1499.932k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:55:34,825][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 4.011    Value Loss: 5.334    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 204229     Buffer Size: 25772      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-06 23:58:49,711][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 3.949    Value Loss: 5.928    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 205154     Buffer Size: 25748      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:02:07,093][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.487    [weighted Loss:2.487    Policy Loss: 4.391    Value Loss: 6.062    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 205969     Buffer Size: 25598      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:05:23,779][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.232    [weighted Loss:2.232    Policy Loss: 3.719    Value Loss: 5.882    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 206800     Buffer Size: 25392      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:08:42,958][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 4.753    Value Loss: 5.577    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 207642     Buffer Size: 25105      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:11:59,407][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.584    [weighted Loss:2.584    Policy Loss: 3.805    Value Loss: 5.583    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 208480     Buffer Size: 24847      Transition Number: 1500.154k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:15:16,355][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 4.598    Value Loss: 5.196    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 209300     Buffer Size: 24561      Transition Number: 1500.134k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:18:32,472][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 4.015    Value Loss: 5.607    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 210123     Buffer Size: 24417      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:21:50,182][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 4.401    Value Loss: 5.345    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 210937     Buffer Size: 24338      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:25:08,570][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.715    [weighted Loss:1.715    Policy Loss: 3.887    Value Loss: 5.261    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 211813     Buffer Size: 24333      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:28:28,310][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.326    [weighted Loss:2.326    Policy Loss: 4.212    Value Loss: 5.457    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 212664     Buffer Size: 24344      Transition Number: 1500.093k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:31:46,330][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.509    [weighted Loss:2.509    Policy Loss: 3.655    Value Loss: 5.543    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 213513     Buffer Size: 24338      Transition Number: 1500.099k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:35:08,180][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 4.282    Value Loss: 5.499    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 214360     Buffer Size: 24284      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:38:26,246][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.191    [weighted Loss:2.191    Policy Loss: 4.399    Value Loss: 5.503    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 215165     Buffer Size: 24224      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:41:44,063][train][INFO][train.py>_log] ==> #215000     Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 4.376    Value Loss: 5.352    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 216037     Buffer Size: 24229      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:45:03,451][train][INFO][train.py>_log] ==> #216000     Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 3.857    Value Loss: 5.879    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 216899     Buffer Size: 24250      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:48:20,314][train][INFO][train.py>_log] ==> #217000     Total Loss: 1.768    [weighted Loss:1.768    Policy Loss: 3.640    Value Loss: 5.092    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 217743     Buffer Size: 24249      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:51:38,820][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 3.557    Value Loss: 5.457    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 218625     Buffer Size: 24272      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:54:56,884][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.147    Value Loss: 5.506    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 219503     Buffer Size: 24272      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-07 00:58:16,114][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 4.465    Value Loss: 5.583    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 220365     Buffer Size: 24254      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:01:33,454][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 4.768    Value Loss: 5.634    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 221233     Buffer Size: 24268      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:04:52,506][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 4.239    Value Loss: 5.290    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 222131     Buffer Size: 24278      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:08:12,819][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 4.474    Value Loss: 5.276    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 222987     Buffer Size: 24276      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:11:31,657][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 4.330    Value Loss: 5.500    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 223866     Buffer Size: 24294      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:14:52,076][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 5.149    Value Loss: 5.445    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 224747     Buffer Size: 24310      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:18:10,028][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 4.852    Value Loss: 5.475    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 225617     Buffer Size: 24340      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:21:29,781][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.175    [weighted Loss:3.175    Policy Loss: 5.214    Value Loss: 5.595    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 226538     Buffer Size: 24393      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:24:49,616][train][INFO][train.py>_log] ==> #228000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 4.931    Value Loss: 5.573    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 227441     Buffer Size: 24419      Transition Number: 1499.935k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:28:07,783][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.174    [weighted Loss:3.174    Policy Loss: 5.928    Value Loss: 6.228    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 228463     Buffer Size: 24541      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:31:27,549][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 5.997    Value Loss: 5.699    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 229504     Buffer Size: 24627      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:34:45,434][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 4.998    Value Loss: 5.575    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 230569     Buffer Size: 24821      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:38:03,443][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.316    [weighted Loss:2.316    Policy Loss: 4.806    Value Loss: 6.028    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 231627     Buffer Size: 25075      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:41:20,997][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 4.609    Value Loss: 7.023    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 232566     Buffer Size: 25243      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:44:38,844][train][INFO][train.py>_log] ==> #234000     Total Loss: 0.881    [weighted Loss:0.881    Policy Loss: 3.867    Value Loss: 5.492    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 233563     Buffer Size: 25391      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:47:58,233][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 4.753    Value Loss: 6.237    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 234402     Buffer Size: 25423      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:51:16,285][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 4.450    Value Loss: 5.584    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 235229     Buffer Size: 25464      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:54:35,285][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 4.688    Value Loss: 5.694    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 236063     Buffer Size: 25487      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-07 01:57:51,778][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.082    [weighted Loss:2.082    Policy Loss: 4.235    Value Loss: 6.334    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 236898     Buffer Size: 25499      Transition Number: 1500.076k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:01:09,592][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 4.965    Value Loss: 5.822    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 237742     Buffer Size: 25501      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:04:29,948][train][INFO][train.py>_log] ==> #240000     Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 4.276    Value Loss: 5.685    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 238605     Buffer Size: 25506      Transition Number: 1500.079k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:07:48,255][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.306    [weighted Loss:2.306    Policy Loss: 4.491    Value Loss: 5.927    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 239433     Buffer Size: 25519      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:11:07,072][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 4.584    Value Loss: 5.596    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 240301     Buffer Size: 25559      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:14:25,831][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 4.206    Value Loss: 6.018    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 241305     Buffer Size: 25755      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:17:43,791][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 4.718    Value Loss: 6.195    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 242344     Buffer Size: 25928      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:21:02,552][train][INFO][train.py>_log] ==> #245000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 4.227    Value Loss: 5.816    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 243418     Buffer Size: 26132      Transition Number: 1499.936k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:24:21,281][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 5.024    Value Loss: 6.185    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 244507     Buffer Size: 26369      Transition Number: 1500.166k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:27:38,384][train][INFO][train.py>_log] ==> #247000     Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 4.935    Value Loss: 5.998    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 245846     Buffer Size: 26844      Transition Number: 1500.138k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:30:54,615][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.897    [weighted Loss:2.897    Policy Loss: 5.056    Value Loss: 6.110    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 247085     Buffer Size: 27268      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:34:12,635][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 4.345    Value Loss: 6.281    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 248118     Buffer Size: 27503      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:37:30,144][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.218    [weighted Loss:1.218    Policy Loss: 4.459    Value Loss: 5.993    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 249228     Buffer Size: 27744      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:40:46,179][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.637    [weighted Loss:1.637    Policy Loss: 4.537    Value Loss: 6.462    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 250049     Buffer Size: 27761      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:44:03,544][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.412    [weighted Loss:2.412    Policy Loss: 4.259    Value Loss: 6.153    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 250865     Buffer Size: 27775      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:47:19,034][train][INFO][train.py>_log] ==> #253000     Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 4.401    Value Loss: 5.788    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 251684     Buffer Size: 27762      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:50:35,513][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 4.673    Value Loss: 6.016    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 252548     Buffer Size: 27772      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:53:53,245][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 4.394    Value Loss: 5.994    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 253387     Buffer Size: 27767      Transition Number: 1500.059k Batch Size: 256        Lr: 0.10000 
[2022-01-07 02:57:10,701][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 4.407    Value Loss: 6.319    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 254257     Buffer Size: 27741      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:00:28,722][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 4.057    Value Loss: 6.288    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 255094     Buffer Size: 27741      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:03:48,139][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 3.936    Value Loss: 6.003    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 255947     Buffer Size: 27630      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:07:08,256][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 4.478    Value Loss: 6.351    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 256786     Buffer Size: 27399      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:10:26,560][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 4.261    Value Loss: 5.915    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 257615     Buffer Size: 27193      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:13:44,096][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.352    [weighted Loss:3.352    Policy Loss: 5.166    Value Loss: 5.814    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 258442     Buffer Size: 26929      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:17:04,855][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 4.695    Value Loss: 6.059    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 259296     Buffer Size: 26757      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:20:22,394][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.115    [weighted Loss:2.115    Policy Loss: 4.440    Value Loss: 5.872    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 260239     Buffer Size: 26692      Transition Number: 1500.072k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:23:39,057][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 5.587    Value Loss: 5.871    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 261144     Buffer Size: 26779      Transition Number: 1500.052k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:27:00,309][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 4.659    Value Loss: 6.119    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 262175     Buffer Size: 27003      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:30:18,808][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 4.779    Value Loss: 6.657    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 263289     Buffer Size: 27285      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:33:36,558][train][INFO][train.py>_log] ==> #267000     Total Loss: 3.504    [weighted Loss:3.504    Policy Loss: 4.931    Value Loss: 6.531    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 264193     Buffer Size: 27366      Transition Number: 1500.118k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:36:54,599][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 4.741    Value Loss: 5.902    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 265081     Buffer Size: 27451      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:40:12,855][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 5.327    Value Loss: 5.950    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 265909     Buffer Size: 27483      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:43:30,924][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.014    [weighted Loss:3.014    Policy Loss: 5.073    Value Loss: 5.819    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 266765     Buffer Size: 27497      Transition Number: 1500.118k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:46:50,851][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 4.587    Value Loss: 6.195    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 267652     Buffer Size: 27532      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:50:08,862][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 5.011    Value Loss: 6.442    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 268540     Buffer Size: 27430      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:53:24,960][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 4.999    Value Loss: 5.864    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 269436     Buffer Size: 27334      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-07 03:56:44,372][train][INFO][train.py>_log] ==> #274000     Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 4.465    Value Loss: 6.303    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 270362     Buffer Size: 27226      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:00:05,201][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.618    [weighted Loss:2.618    Policy Loss: 4.729    Value Loss: 6.305    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 271229     Buffer Size: 27011      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:03:25,905][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 4.469    Value Loss: 6.216    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 272104     Buffer Size: 26614      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:06:46,181][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 4.412    Value Loss: 6.370    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 272954     Buffer Size: 26192      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:10:04,997][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.186    [weighted Loss:3.186    Policy Loss: 5.183    Value Loss: 5.562    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 273810     Buffer Size: 25915      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:13:23,533][train][INFO][train.py>_log] ==> #279000     Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 4.393    Value Loss: 6.015    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 274734     Buffer Size: 25764      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:16:42,954][train][INFO][train.py>_log] ==> #280000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 4.965    Value Loss: 6.169    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 275660     Buffer Size: 25803      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:20:01,911][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 4.348    Value Loss: 6.192    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 276549     Buffer Size: 25859      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:23:18,956][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 4.723    Value Loss: 5.986    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 277416     Buffer Size: 25909      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:26:38,290][train][INFO][train.py>_log] ==> #283000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 5.238    Value Loss: 6.113    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 278312     Buffer Size: 25965      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:29:57,188][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.380    [weighted Loss:2.380    Policy Loss: 5.114    Value Loss: 5.911    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 279213     Buffer Size: 26028      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:33:16,735][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 4.340    Value Loss: 6.396    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 280340     Buffer Size: 26283      Transition Number: 1500.040k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:36:36,079][train][INFO][train.py>_log] ==> #286000     Total Loss: 1.941    [weighted Loss:1.941    Policy Loss: 6.107    Value Loss: 5.917    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 281463     Buffer Size: 26543      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:39:54,151][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.995    [weighted Loss:2.995    Policy Loss: 4.754    Value Loss: 6.031    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 282509     Buffer Size: 26755      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:43:13,822][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.398    [weighted Loss:1.398    Policy Loss: 4.338    Value Loss: 6.190    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 283572     Buffer Size: 26992      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:46:32,559][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 4.379    Value Loss: 6.545    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 284557     Buffer Size: 27169      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:49:52,629][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 4.891    Value Loss: 6.345    Reward Loss: 1.152    Consistency Loss: 0.000    ] Replay Episodes Collected: 285558     Buffer Size: 27342      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:53:13,589][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 3.958    Value Loss: 6.731    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 286538     Buffer Size: 27501      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:56:31,751][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 4.402    Value Loss: 6.403    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 287475     Buffer Size: 27585      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-07 04:59:50,712][train][INFO][train.py>_log] ==> #293000     Total Loss: 1.967    [weighted Loss:1.967    Policy Loss: 3.802    Value Loss: 6.154    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 288336     Buffer Size: 27540      Transition Number: 1500.259k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:03:09,888][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.783    [weighted Loss:2.783    Policy Loss: 4.431    Value Loss: 6.664    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 289199     Buffer Size: 27364      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:06:28,846][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 4.034    Value Loss: 5.918    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 290243     Buffer Size: 27323      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:09:48,351][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 4.870    Value Loss: 6.358    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 291264     Buffer Size: 27384      Transition Number: 1499.934k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:13:06,024][train][INFO][train.py>_log] ==> #297000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 4.800    Value Loss: 6.180    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 292217     Buffer Size: 27458      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:16:25,011][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 3.943    Value Loss: 6.130    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 293198     Buffer Size: 27578      Transition Number: 1500.116k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:19:42,391][train][INFO][train.py>_log] ==> #299000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 4.495    Value Loss: 6.240    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 294074     Buffer Size: 27644      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:23:01,345][train][INFO][train.py>_log] ==> #300000     Total Loss: 1.997    [weighted Loss:1.997    Policy Loss: 4.063    Value Loss: 6.562    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 295003     Buffer Size: 27689      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:26:19,931][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.877    [weighted Loss:2.877    Policy Loss: 5.186    Value Loss: 6.591    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 295890     Buffer Size: 27754      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:29:38,519][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.415    [weighted Loss:1.415    Policy Loss: 5.010    Value Loss: 6.157    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 296852     Buffer Size: 27791      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:32:58,715][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.623    [weighted Loss:2.623    Policy Loss: 4.612    Value Loss: 6.003    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 297934     Buffer Size: 27938      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:36:18,302][train][INFO][train.py>_log] ==> #304000     Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 5.288    Value Loss: 6.440    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 299038     Buffer Size: 28150      Transition Number: 1500.066k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:39:34,958][train][INFO][train.py>_log] ==> #305000     Total Loss: 3.138    [weighted Loss:3.138    Policy Loss: 6.116    Value Loss: 6.137    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 300095     Buffer Size: 28389      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:42:53,716][train][INFO][train.py>_log] ==> #306000     Total Loss: 2.772    [weighted Loss:2.772    Policy Loss: 5.721    Value Loss: 6.218    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 301177     Buffer Size: 28630      Transition Number: 1500.018k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:46:10,462][train][INFO][train.py>_log] ==> #307000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 6.135    Value Loss: 6.425    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 302341     Buffer Size: 28937      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:49:27,283][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 5.944    Value Loss: 6.137    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 303531     Buffer Size: 29219      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:52:45,788][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.886    [weighted Loss:2.886    Policy Loss: 5.892    Value Loss: 6.475    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 304812     Buffer Size: 29538      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:56:04,639][train][INFO][train.py>_log] ==> #310000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 7.234    Value Loss: 6.703    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 306085     Buffer Size: 29885      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-07 05:59:21,698][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 5.757    Value Loss: 6.426    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 307398     Buffer Size: 30296      Transition Number: 1500.107k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:02:39,531][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 4.949    Value Loss: 6.438    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 308748     Buffer Size: 30753      Transition Number: 1500.121k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:05:58,975][train][INFO][train.py>_log] ==> #313000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 5.546    Value Loss: 6.513    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 310202     Buffer Size: 31306      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:09:15,774][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 6.377    Value Loss: 6.782    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 311645     Buffer Size: 31731      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:12:33,765][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 5.824    Value Loss: 6.687    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 312838     Buffer Size: 31833      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:15:51,943][train][INFO][train.py>_log] ==> #316000     Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 4.921    Value Loss: 6.549    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 314024     Buffer Size: 31924      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:19:09,405][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.563    [weighted Loss:1.563    Policy Loss: 5.422    Value Loss: 6.622    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 315127     Buffer Size: 31995      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:22:26,600][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.383    [weighted Loss:1.383    Policy Loss: 5.186    Value Loss: 6.466    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 316189     Buffer Size: 32068      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:25:45,489][train][INFO][train.py>_log] ==> #319000     Total Loss: 3.934    [weighted Loss:3.934    Policy Loss: 5.580    Value Loss: 6.619    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 317364     Buffer Size: 32242      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:29:00,407][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 5.579    Value Loss: 6.322    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 318493     Buffer Size: 32416      Transition Number: 1500.216k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:32:18,080][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 4.786    Value Loss: 7.036    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 319788     Buffer Size: 32727      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:35:35,205][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 5.151    Value Loss: 6.822    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 321068     Buffer Size: 33104      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:38:51,254][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.660    [weighted Loss:2.660    Policy Loss: 4.872    Value Loss: 7.011    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 322124     Buffer Size: 33341      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:42:09,083][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.053    [weighted Loss:2.053    Policy Loss: 4.612    Value Loss: 6.684    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 323153     Buffer Size: 33483      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:45:26,354][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 4.915    Value Loss: 6.500    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 324066     Buffer Size: 33411      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:48:43,417][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 4.859    Value Loss: 6.411    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 324989     Buffer Size: 33304      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:52:00,756][train][INFO][train.py>_log] ==> #327000     Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 4.911    Value Loss: 6.631    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 325878     Buffer Size: 33277      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:55:19,249][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 5.015    Value Loss: 6.308    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 326837     Buffer Size: 33279      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-07 06:58:35,242][train][INFO][train.py>_log] ==> #329000     Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 5.322    Value Loss: 6.743    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 327974     Buffer Size: 33507      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:01:52,313][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.812    [weighted Loss:2.812    Policy Loss: 4.683    Value Loss: 6.636    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 329069     Buffer Size: 33717      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:05:08,910][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 5.076    Value Loss: 6.993    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 330105     Buffer Size: 33861      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:08:24,557][train][INFO][train.py>_log] ==> #332000     Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 4.453    Value Loss: 6.692    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 331196     Buffer Size: 33989      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:11:42,360][train][INFO][train.py>_log] ==> #333000     Total Loss: 2.582    [weighted Loss:2.582    Policy Loss: 6.222    Value Loss: 7.176    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 332071     Buffer Size: 33825      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:14:59,454][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.385    [weighted Loss:2.385    Policy Loss: 4.736    Value Loss: 6.652    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 332948     Buffer Size: 33617      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:18:17,016][train][INFO][train.py>_log] ==> #335000     Total Loss: 3.599    [weighted Loss:3.599    Policy Loss: 6.710    Value Loss: 6.823    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 333932     Buffer Size: 33523      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:21:34,371][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 4.840    Value Loss: 6.389    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 334900     Buffer Size: 33412      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:24:54,848][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 5.374    Value Loss: 6.635    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 335927     Buffer Size: 33289      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:28:14,652][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 5.031    Value Loss: 6.770    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 336988     Buffer Size: 33117      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:31:31,679][train][INFO][train.py>_log] ==> #339000     Total Loss: 3.394    [weighted Loss:3.394    Policy Loss: 6.218    Value Loss: 6.523    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 337914     Buffer Size: 32839      Transition Number: 1500.192k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:34:49,527][train][INFO][train.py>_log] ==> #340000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 4.504    Value Loss: 6.429    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 338819     Buffer Size: 32534      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:38:08,028][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.475    [weighted Loss:2.475    Policy Loss: 4.605    Value Loss: 6.475    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 340473     Buffer Size: 32820      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:41:26,634][train][INFO][train.py>_log] ==> #342000     Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 4.894    Value Loss: 6.658    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 342145     Buffer Size: 33088      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:44:45,098][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.158    [weighted Loss:2.158    Policy Loss: 5.449    Value Loss: 6.793    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 343685     Buffer Size: 33211      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:48:03,331][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.196    [weighted Loss:1.196    Policy Loss: 5.276    Value Loss: 6.510    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 345280     Buffer Size: 33402      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:51:19,189][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 4.412    Value Loss: 6.645    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 346308     Buffer Size: 33243      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:54:40,111][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.908    [weighted Loss:2.908    Policy Loss: 5.685    Value Loss: 6.508    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 347305     Buffer Size: 33102      Transition Number: 1500.103k Batch Size: 256        Lr: 0.10000 
[2022-01-07 07:57:59,962][train][INFO][train.py>_log] ==> #347000     Total Loss: 0.963    [weighted Loss:0.963    Policy Loss: 4.456    Value Loss: 6.586    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 348410     Buffer Size: 33043      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:01:17,223][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 5.230    Value Loss: 6.566    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 349508     Buffer Size: 33033      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:04:35,989][train][INFO][train.py>_log] ==> #349000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 4.642    Value Loss: 6.513    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 350427     Buffer Size: 32819      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:07:53,003][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 5.212    Value Loss: 6.270    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 351362     Buffer Size: 32560      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:11:13,017][train][INFO][train.py>_log] ==> #351000     Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 4.318    Value Loss: 6.639    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 352259     Buffer Size: 32138      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:14:31,264][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 3.895    Value Loss: 6.500    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 353124     Buffer Size: 31770      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:17:51,224][train][INFO][train.py>_log] ==> #353000     Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 4.839    Value Loss: 6.307    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 353963     Buffer Size: 31572      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:21:07,511][train][INFO][train.py>_log] ==> #354000     Total Loss: 1.102    [weighted Loss:1.102    Policy Loss: 4.596    Value Loss: 6.104    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 354772     Buffer Size: 31391      Transition Number: 1500.052k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:24:27,291][train][INFO][train.py>_log] ==> #355000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 4.805    Value Loss: 5.883    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 355624     Buffer Size: 31300      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:27:45,843][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 4.781    Value Loss: 6.121    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 356501     Buffer Size: 31248      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:31:03,547][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 5.109    Value Loss: 6.434    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 357409     Buffer Size: 31231      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:34:23,225][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.838    [weighted Loss:2.838    Policy Loss: 4.899    Value Loss: 6.726    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 358344     Buffer Size: 31149      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:37:42,177][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 4.550    Value Loss: 6.054    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 359226     Buffer Size: 30882      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:41:03,111][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.844    [weighted Loss:1.844    Policy Loss: 6.571    Value Loss: 6.506    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 360104     Buffer Size: 30637      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:44:22,901][train][INFO][train.py>_log] ==> #361000     Total Loss: 3.416    [weighted Loss:3.416    Policy Loss: 5.593    Value Loss: 7.156    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 360956     Buffer Size: 30416      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:47:42,684][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 4.992    Value Loss: 6.698    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 361820     Buffer Size: 30228      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:51:02,741][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 6.178    Value Loss: 6.611    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 362766     Buffer Size: 30240      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:54:23,329][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.813    [weighted Loss:2.813    Policy Loss: 5.316    Value Loss: 6.478    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 363680     Buffer Size: 30241      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-07 08:57:43,583][train][INFO][train.py>_log] ==> #365000     Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 5.201    Value Loss: 6.375    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 364524     Buffer Size: 30134      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:01:03,788][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 5.537    Value Loss: 6.324    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 365399     Buffer Size: 29988      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:04:24,567][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 5.637    Value Loss: 6.103    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 366431     Buffer Size: 29942      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:07:47,677][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 5.032    Value Loss: 6.265    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 367497     Buffer Size: 29954      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:11:06,957][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 4.857    Value Loss: 6.541    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 368499     Buffer Size: 30019      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:14:26,815][train][INFO][train.py>_log] ==> #370000     Total Loss: 1.410    [weighted Loss:1.410    Policy Loss: 4.538    Value Loss: 6.202    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 369522     Buffer Size: 29695      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:17:46,516][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 4.877    Value Loss: 6.308    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 370385     Buffer Size: 28950      Transition Number: 1500.262k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:21:05,861][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 4.664    Value Loss: 6.575    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 371249     Buffer Size: 28210      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:24:28,045][train][INFO][train.py>_log] ==> #373000     Total Loss: 1.256    [weighted Loss:1.256    Policy Loss: 4.851    Value Loss: 6.582    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 372112     Buffer Size: 27470      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:27:52,145][train][INFO][train.py>_log] ==> #374000     Total Loss: 1.852    [weighted Loss:1.852    Policy Loss: 5.085    Value Loss: 5.962    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 373006     Buffer Size: 27056      Transition Number: 1500.224k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:31:12,733][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 4.834    Value Loss: 6.533    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 373959     Buffer Size: 26961      Transition Number: 1500.403k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:34:32,996][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.012    [weighted Loss:1.012    Policy Loss: 4.789    Value Loss: 6.065    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 374900     Buffer Size: 26861      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:37:52,078][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 5.172    Value Loss: 6.604    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 375860     Buffer Size: 26793      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:41:14,625][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.771    [weighted Loss:2.771    Policy Loss: 5.729    Value Loss: 6.494    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 376873     Buffer Size: 26800      Transition Number: 1500.071k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:44:36,995][train][INFO][train.py>_log] ==> #379000     Total Loss: 1.781    [weighted Loss:1.781    Policy Loss: 5.116    Value Loss: 5.951    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 377923     Buffer Size: 26886      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:47:57,791][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 5.671    Value Loss: 6.659    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 378953     Buffer Size: 26990      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:51:19,028][train][INFO][train.py>_log] ==> #381000     Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 4.875    Value Loss: 6.083    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 380012     Buffer Size: 27154      Transition Number: 1500.113k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:54:40,807][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.571    [weighted Loss:2.571    Policy Loss: 5.580    Value Loss: 6.050    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 381032     Buffer Size: 27283      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-07 09:58:01,173][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 4.991    Value Loss: 6.345    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 381928     Buffer Size: 27330      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:01:21,733][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.232    [weighted Loss:2.232    Policy Loss: 5.204    Value Loss: 6.707    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 382853     Buffer Size: 27376      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:04:40,487][train][INFO][train.py>_log] ==> #385000     Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 4.710    Value Loss: 6.492    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 383757     Buffer Size: 27422      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:08:03,451][train][INFO][train.py>_log] ==> #386000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 4.805    Value Loss: 6.232    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 384673     Buffer Size: 27416      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:11:23,308][train][INFO][train.py>_log] ==> #387000     Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 6.078    Value Loss: 6.308    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 385526     Buffer Size: 27346      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:14:45,435][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 5.497    Value Loss: 6.663    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 386417     Buffer Size: 27315      Transition Number: 1500.115k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:18:05,242][train][INFO][train.py>_log] ==> #389000     Total Loss: 1.606    [weighted Loss:1.606    Policy Loss: 5.352    Value Loss: 6.591    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 387333     Buffer Size: 27366      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:21:26,583][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 5.064    Value Loss: 6.279    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 388260     Buffer Size: 27437      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:24:46,718][train][INFO][train.py>_log] ==> #391000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 5.054    Value Loss: 6.306    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 389228     Buffer Size: 27541      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:28:06,115][train][INFO][train.py>_log] ==> #392000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 5.785    Value Loss: 6.459    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 390211     Buffer Size: 27595      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:31:26,477][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 5.779    Value Loss: 6.314    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 391109     Buffer Size: 27576      Transition Number: 1500.129k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:34:48,458][train][INFO][train.py>_log] ==> #394000     Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 5.305    Value Loss: 6.242    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 392009     Buffer Size: 27584      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:38:10,511][train][INFO][train.py>_log] ==> #395000     Total Loss: 1.984    [weighted Loss:1.984    Policy Loss: 5.625    Value Loss: 6.380    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 392904     Buffer Size: 27606      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:41:31,562][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 5.609    Value Loss: 6.337    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 393821     Buffer Size: 27541      Transition Number: 1500.084k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:44:51,940][train][INFO][train.py>_log] ==> #397000     Total Loss: 1.606    [weighted Loss:1.606    Policy Loss: 5.825    Value Loss: 6.025    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 394748     Buffer Size: 27458      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:48:12,404][train][INFO][train.py>_log] ==> #398000     Total Loss: 3.760    [weighted Loss:3.760    Policy Loss: 7.421    Value Loss: 6.584    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 395692     Buffer Size: 27362      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:51:33,492][train][INFO][train.py>_log] ==> #399000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 5.909    Value Loss: 6.404    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 397376     Buffer Size: 27978      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:54:53,953][train][INFO][train.py>_log] ==> #400000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 5.644    Value Loss: 6.383    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 399087     Buffer Size: 28766      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-07 10:58:12,517][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 5.717    Value Loss: 6.657    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 400283     Buffer Size: 29147      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:01:29,952][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 5.528    Value Loss: 6.782    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 401513     Buffer Size: 29517      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:04:49,830][train][INFO][train.py>_log] ==> #403000     Total Loss: 3.058    [weighted Loss:3.058    Policy Loss: 5.391    Value Loss: 6.522    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 402432     Buffer Size: 29582      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:08:07,148][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 5.105    Value Loss: 6.926    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 403306     Buffer Size: 29563      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:11:27,372][train][INFO][train.py>_log] ==> #405000     Total Loss: 3.143    [weighted Loss:3.143    Policy Loss: 5.701    Value Loss: 6.371    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 404288     Buffer Size: 29579      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:14:48,647][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.658    [weighted Loss:2.658    Policy Loss: 6.187    Value Loss: 6.441    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 405240     Buffer Size: 29544      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:18:08,776][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 5.990    Value Loss: 7.150    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 406193     Buffer Size: 29508      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:21:29,044][train][INFO][train.py>_log] ==> #408000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 5.649    Value Loss: 6.572    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 407172     Buffer Size: 29468      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:24:48,694][train][INFO][train.py>_log] ==> #409000     Total Loss: 3.299    [weighted Loss:3.299    Policy Loss: 5.582    Value Loss: 6.777    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 408232     Buffer Size: 29542      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:28:07,441][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 5.017    Value Loss: 7.021    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 409262     Buffer Size: 29560      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:31:25,649][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 5.898    Value Loss: 6.819    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 410232     Buffer Size: 29555      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:34:46,575][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 5.717    Value Loss: 6.508    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 411237     Buffer Size: 29609      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:38:05,250][train][INFO][train.py>_log] ==> #413000     Total Loss: 3.402    [weighted Loss:3.402    Policy Loss: 6.080    Value Loss: 7.183    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 412140     Buffer Size: 29611      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:41:25,680][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 5.233    Value Loss: 6.896    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 413040     Buffer Size: 29616      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:44:47,966][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 5.825    Value Loss: 6.639    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 413933     Buffer Size: 29578      Transition Number: 1500.087k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:48:08,115][train][INFO][train.py>_log] ==> #416000     Total Loss: 2.649    [weighted Loss:2.649    Policy Loss: 5.963    Value Loss: 6.400    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 414793     Buffer Size: 29555      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:51:26,783][train][INFO][train.py>_log] ==> #417000     Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 6.749    Value Loss: 6.477    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 415737     Buffer Size: 29641      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:54:48,016][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 5.705    Value Loss: 6.338    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 416662     Buffer Size: 29669      Transition Number: 1500.124k Batch Size: 256        Lr: 0.10000 
[2022-01-07 11:58:09,568][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 5.571    Value Loss: 6.705    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 417706     Buffer Size: 29771      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:01:27,754][train][INFO][train.py>_log] ==> #420000     Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 6.768    Value Loss: 6.553    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 418731     Buffer Size: 29834      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:04:48,585][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 5.608    Value Loss: 6.399    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 419789     Buffer Size: 29972      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:08:07,498][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 6.530    Value Loss: 6.263    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 420946     Buffer Size: 30199      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:11:24,329][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 5.932    Value Loss: 7.362    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 421956     Buffer Size: 30329      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:14:44,579][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 6.047    Value Loss: 6.298    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 422998     Buffer Size: 30446      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:18:05,258][train][INFO][train.py>_log] ==> #425000     Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 5.075    Value Loss: 6.863    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 423950     Buffer Size: 30481      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:21:24,595][train][INFO][train.py>_log] ==> #426000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 6.336    Value Loss: 6.484    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 424910     Buffer Size: 30534      Transition Number: 1500.158k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:24:46,052][train][INFO][train.py>_log] ==> #427000     Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 5.214    Value Loss: 6.518    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 425869     Buffer Size: 30561      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:28:05,736][train][INFO][train.py>_log] ==> #428000     Total Loss: 3.166    [weighted Loss:3.166    Policy Loss: 5.579    Value Loss: 6.409    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 426804     Buffer Size: 30201      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:31:24,552][train][INFO][train.py>_log] ==> #429000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 5.677    Value Loss: 6.650    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 427716     Buffer Size: 29518      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:34:46,274][train][INFO][train.py>_log] ==> #430000     Total Loss: 2.666    [weighted Loss:2.666    Policy Loss: 5.022    Value Loss: 6.517    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 428625     Buffer Size: 28957      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:38:05,524][train][INFO][train.py>_log] ==> #431000     Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 5.835    Value Loss: 6.557    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 429485     Buffer Size: 28594      Transition Number: 1500.162k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:41:26,361][train][INFO][train.py>_log] ==> #432000     Total Loss: 2.758    [weighted Loss:2.758    Policy Loss: 5.539    Value Loss: 6.573    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 430348     Buffer Size: 28381      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:44:45,944][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.825    [weighted Loss:2.825    Policy Loss: 5.511    Value Loss: 6.150    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 431200     Buffer Size: 28329      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:48:06,319][train][INFO][train.py>_log] ==> #434000     Total Loss: 2.849    [weighted Loss:2.849    Policy Loss: 5.862    Value Loss: 6.545    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 432102     Buffer Size: 28262      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:51:26,153][train][INFO][train.py>_log] ==> #435000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 5.230    Value Loss: 6.450    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 433032     Buffer Size: 28205      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:54:46,000][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.825    [weighted Loss:2.825    Policy Loss: 5.189    Value Loss: 6.112    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 433957     Buffer Size: 28170      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-07 12:58:06,891][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 5.650    Value Loss: 6.869    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 434890     Buffer Size: 28152      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:01:26,349][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 5.552    Value Loss: 6.636    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 435816     Buffer Size: 28026      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:04:48,185][train][INFO][train.py>_log] ==> #439000     Total Loss: 3.239    [weighted Loss:3.239    Policy Loss: 6.013    Value Loss: 6.622    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 436734     Buffer Size: 27895      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:08:07,473][train][INFO][train.py>_log] ==> #440000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 6.654    Value Loss: 6.887    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 437657     Buffer Size: 27780      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:11:29,507][train][INFO][train.py>_log] ==> #441000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 5.935    Value Loss: 6.312    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 438742     Buffer Size: 27842      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:14:51,226][train][INFO][train.py>_log] ==> #442000     Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 6.761    Value Loss: 6.580    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 439845     Buffer Size: 27994      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:18:12,015][train][INFO][train.py>_log] ==> #443000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 6.127    Value Loss: 6.652    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 441179     Buffer Size: 28391      Transition Number: 1500.249k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:21:32,074][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 6.685    Value Loss: 7.111    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 442561     Buffer Size: 28857      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:24:51,683][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.274    [weighted Loss:3.274    Policy Loss: 5.766    Value Loss: 6.671    Reward Loss: 1.274    Consistency Loss: 0.000    ] Replay Episodes Collected: 443496     Buffer Size: 28948      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:28:09,759][train][INFO][train.py>_log] ==> #446000     Total Loss: 2.286    [weighted Loss:2.286    Policy Loss: 5.785    Value Loss: 6.670    Reward Loss: 1.270    Consistency Loss: 0.000    ] Replay Episodes Collected: 444447     Buffer Size: 28998      Transition Number: 1500.133k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:31:31,394][train][INFO][train.py>_log] ==> #447000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 5.614    Value Loss: 6.576    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 445385     Buffer Size: 29028      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:34:52,929][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.897    [weighted Loss:2.897    Policy Loss: 5.140    Value Loss: 6.443    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 446361     Buffer Size: 28976      Transition Number: 1500.053k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:38:13,395][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.660    [weighted Loss:2.660    Policy Loss: 5.562    Value Loss: 6.675    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 447269     Buffer Size: 28876      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:41:35,283][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.440    [weighted Loss:2.440    Policy Loss: 4.946    Value Loss: 6.389    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 448215     Buffer Size: 28703      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:44:58,110][train][INFO][train.py>_log] ==> #451000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 6.722    Value Loss: 6.969    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 449111     Buffer Size: 28431      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:48:19,660][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 5.509    Value Loss: 6.256    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 449979     Buffer Size: 28257      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:51:42,487][train][INFO][train.py>_log] ==> #453000     Total Loss: 1.931    [weighted Loss:1.931    Policy Loss: 5.587    Value Loss: 6.904    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 452398     Buffer Size: 29558      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:55:05,093][train][INFO][train.py>_log] ==> #454000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 6.029    Value Loss: 6.699    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 454841     Buffer Size: 30991      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-07 13:58:23,889][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 5.651    Value Loss: 6.378    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 456751     Buffer Size: 31920      Transition Number: 1500.091k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:01:42,888][train][INFO][train.py>_log] ==> #456000     Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 5.736    Value Loss: 6.429    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 458683     Buffer Size: 32871      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:04:59,877][train][INFO][train.py>_log] ==> #457000     Total Loss: 2.750    [weighted Loss:2.750    Policy Loss: 5.824    Value Loss: 6.703    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 459724     Buffer Size: 32992      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:08:17,031][train][INFO][train.py>_log] ==> #458000     Total Loss: 2.530    [weighted Loss:2.530    Policy Loss: 6.186    Value Loss: 6.561    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 460745     Buffer Size: 33087      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:11:35,158][train][INFO][train.py>_log] ==> #459000     Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 5.631    Value Loss: 6.549    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 461732     Buffer Size: 33133      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:14:55,020][train][INFO][train.py>_log] ==> #460000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 7.032    Value Loss: 6.449    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 462700     Buffer Size: 33233      Transition Number: 1500.103k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:18:12,418][train][INFO][train.py>_log] ==> #461000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 5.405    Value Loss: 6.769    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 463846     Buffer Size: 33513      Transition Number: 1500.090k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:21:28,205][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 6.248    Value Loss: 6.601    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 464991     Buffer Size: 33778      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:24:48,377][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 5.422    Value Loss: 6.960    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 466089     Buffer Size: 33991      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:28:05,206][train][INFO][train.py>_log] ==> #464000     Total Loss: 3.842    [weighted Loss:3.842    Policy Loss: 6.089    Value Loss: 6.589    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 467183     Buffer Size: 34179      Transition Number: 1500.126k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:31:21,515][train][INFO][train.py>_log] ==> #465000     Total Loss: 2.742    [weighted Loss:2.742    Policy Loss: 6.028    Value Loss: 6.825    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 468091     Buffer Size: 34186      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:34:42,028][train][INFO][train.py>_log] ==> #466000     Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 5.936    Value Loss: 6.886    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 469039     Buffer Size: 34159      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:38:00,586][train][INFO][train.py>_log] ==> #467000     Total Loss: 3.645    [weighted Loss:3.645    Policy Loss: 6.743    Value Loss: 6.928    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 469991     Buffer Size: 34201      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:41:19,736][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.306    [weighted Loss:2.306    Policy Loss: 5.816    Value Loss: 6.406    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 470939     Buffer Size: 34256      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:44:41,140][train][INFO][train.py>_log] ==> #469000     Total Loss: 3.593    [weighted Loss:3.593    Policy Loss: 7.439    Value Loss: 6.976    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 471969     Buffer Size: 34364      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:47:58,699][train][INFO][train.py>_log] ==> #470000     Total Loss: 2.017    [weighted Loss:2.017    Policy Loss: 5.628    Value Loss: 6.717    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 473027     Buffer Size: 34332      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:51:16,983][train][INFO][train.py>_log] ==> #471000     Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 7.083    Value Loss: 6.411    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 474071     Buffer Size: 34301      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:54:39,625][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 4.838    Value Loss: 6.872    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 475115     Buffer Size: 34084      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-07 14:57:59,303][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 5.869    Value Loss: 6.909    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 476106     Buffer Size: 33772      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:01:19,670][train][INFO][train.py>_log] ==> #474000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 6.229    Value Loss: 6.619    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 477097     Buffer Size: 33742      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:04:37,027][train][INFO][train.py>_log] ==> #475000     Total Loss: 3.111    [weighted Loss:3.111    Policy Loss: 5.397    Value Loss: 6.873    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 478083     Buffer Size: 33768      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:07:54,987][train][INFO][train.py>_log] ==> #476000     Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 5.548    Value Loss: 6.631    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 479049     Buffer Size: 33774      Transition Number: 1500.115k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:11:14,377][train][INFO][train.py>_log] ==> #477000     Total Loss: 3.150    [weighted Loss:3.150    Policy Loss: 5.966    Value Loss: 6.924    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 480008     Buffer Size: 33803      Transition Number: 1500.091k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:14:35,026][train][INFO][train.py>_log] ==> #478000     Total Loss: 2.589    [weighted Loss:2.589    Policy Loss: 5.553    Value Loss: 6.621    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 480967     Buffer Size: 33841      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:17:54,521][train][INFO][train.py>_log] ==> #479000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 6.063    Value Loss: 6.758    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 482015     Buffer Size: 33963      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:21:15,692][train][INFO][train.py>_log] ==> #480000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.327    Value Loss: 6.813    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 483049     Buffer Size: 34112      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:24:36,621][train][INFO][train.py>_log] ==> #481000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 6.271    Value Loss: 6.251    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 484029     Buffer Size: 34199      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:27:56,717][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 5.544    Value Loss: 6.633    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 484986     Buffer Size: 33269      Transition Number: 1500.005k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:31:16,651][train][INFO][train.py>_log] ==> #483000     Total Loss: 0.876    [weighted Loss:0.876    Policy Loss: 6.007    Value Loss: 6.748    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 485903     Buffer Size: 31760      Transition Number: 1500.122k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:34:36,339][train][INFO][train.py>_log] ==> #484000     Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 5.891    Value Loss: 6.930    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 486829     Buffer Size: 30658      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:37:58,451][train][INFO][train.py>_log] ==> #485000     Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 5.948    Value Loss: 6.641    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 487732     Buffer Size: 29691      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:41:17,981][train][INFO][train.py>_log] ==> #486000     Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 5.473    Value Loss: 6.496    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 488627     Buffer Size: 29233      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:44:41,588][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 5.449    Value Loss: 6.808    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 489592     Buffer Size: 29153      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:48:01,758][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 5.794    Value Loss: 6.781    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 490526     Buffer Size: 29117      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:51:23,997][train][INFO][train.py>_log] ==> #489000     Total Loss: 3.597    [weighted Loss:3.597    Policy Loss: 5.966    Value Loss: 6.872    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 491606     Buffer Size: 29251      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:54:44,428][train][INFO][train.py>_log] ==> #490000     Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 5.723    Value Loss: 6.676    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 492684     Buffer Size: 29238      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-07 15:58:05,324][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.571    [weighted Loss:2.571    Policy Loss: 5.953    Value Loss: 6.977    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 493731     Buffer Size: 29092      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:01:27,946][train][INFO][train.py>_log] ==> #492000     Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 5.903    Value Loss: 6.309    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 494750     Buffer Size: 29004      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:04:49,871][train][INFO][train.py>_log] ==> #493000     Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 6.811    Value Loss: 6.797    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 496003     Buffer Size: 29105      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:08:10,003][train][INFO][train.py>_log] ==> #494000     Total Loss: 2.606    [weighted Loss:2.606    Policy Loss: 5.221    Value Loss: 6.896    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 497226     Buffer Size: 29327      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:11:31,381][train][INFO][train.py>_log] ==> #495000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 6.350    Value Loss: 7.426    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 498354     Buffer Size: 29501      Transition Number: 1499.933k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:14:54,375][train][INFO][train.py>_log] ==> #496000     Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 5.323    Value Loss: 6.843    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 499524     Buffer Size: 29705      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:18:14,182][train][INFO][train.py>_log] ==> #497000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 5.807    Value Loss: 6.619    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 500555     Buffer Size: 29756      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:21:34,161][train][INFO][train.py>_log] ==> #498000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 5.980    Value Loss: 6.706    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 501546     Buffer Size: 29762      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:24:56,688][train][INFO][train.py>_log] ==> #499000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 5.885    Value Loss: 6.761    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 502580     Buffer Size: 29726      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:28:16,095][train][INFO][train.py>_log] ==> #500000     Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 6.447    Value Loss: 6.712    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 503566     Buffer Size: 29667      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:31:35,706][train][INFO][train.py>_log] ==> #501000     Total Loss: 1.383    [weighted Loss:1.383    Policy Loss: 6.150    Value Loss: 6.720    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 504537     Buffer Size: 29589      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:34:55,582][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 5.333    Value Loss: 7.104    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 505534     Buffer Size: 29578      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:38:15,986][train][INFO][train.py>_log] ==> #503000     Total Loss: 2.501    [weighted Loss:2.501    Policy Loss: 6.498    Value Loss: 6.872    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 506443     Buffer Size: 29498      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:41:36,822][train][INFO][train.py>_log] ==> #504000     Total Loss: 2.614    [weighted Loss:2.614    Policy Loss: 5.781    Value Loss: 6.445    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 507359     Buffer Size: 29417      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:44:57,513][train][INFO][train.py>_log] ==> #505000     Total Loss: 1.293    [weighted Loss:1.293    Policy Loss: 5.586    Value Loss: 6.620    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 508439     Buffer Size: 29527      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:48:19,839][train][INFO][train.py>_log] ==> #506000     Total Loss: 2.714    [weighted Loss:2.714    Policy Loss: 6.644    Value Loss: 6.441    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 509533     Buffer Size: 29622      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:51:39,393][train][INFO][train.py>_log] ==> #507000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 5.820    Value Loss: 6.667    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 510516     Buffer Size: 29627      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:55:02,670][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 6.140    Value Loss: 6.675    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 511522     Buffer Size: 29577      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-07 16:58:23,153][train][INFO][train.py>_log] ==> #509000     Total Loss: 1.319    [weighted Loss:1.319    Policy Loss: 5.292    Value Loss: 6.723    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 512436     Buffer Size: 29462      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:01:45,016][train][INFO][train.py>_log] ==> #510000     Total Loss: 3.266    [weighted Loss:3.266    Policy Loss: 5.922    Value Loss: 6.632    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 513395     Buffer Size: 29417      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:05:04,897][train][INFO][train.py>_log] ==> #511000     Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 4.713    Value Loss: 6.888    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 514344     Buffer Size: 29423      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:08:26,704][train][INFO][train.py>_log] ==> #512000     Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 5.793    Value Loss: 6.609    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 515325     Buffer Size: 29465      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:11:48,151][train][INFO][train.py>_log] ==> #513000     Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 6.177    Value Loss: 6.868    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 516204     Buffer Size: 29485      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:15:10,601][train][INFO][train.py>_log] ==> #514000     Total Loss: 3.105    [weighted Loss:3.105    Policy Loss: 5.698    Value Loss: 6.582    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 517146     Buffer Size: 29518      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:18:31,660][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 5.683    Value Loss: 6.946    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 518026     Buffer Size: 29550      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:21:53,295][train][INFO][train.py>_log] ==> #516000     Total Loss: 3.855    [weighted Loss:3.855    Policy Loss: 6.685    Value Loss: 6.572    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 518971     Buffer Size: 29529      Transition Number: 1500.152k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:25:13,309][train][INFO][train.py>_log] ==> #517000     Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 6.121    Value Loss: 6.728    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 520215     Buffer Size: 29740      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:28:33,238][train][INFO][train.py>_log] ==> #518000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 6.013    Value Loss: 6.803    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 521452     Buffer Size: 29897      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:31:53,069][train][INFO][train.py>_log] ==> #519000     Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 5.765    Value Loss: 6.723    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 522592     Buffer Size: 29971      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:35:17,248][train][INFO][train.py>_log] ==> #520000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 6.344    Value Loss: 7.228    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 523743     Buffer Size: 30052      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:38:36,938][train][INFO][train.py>_log] ==> #521000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 5.031    Value Loss: 6.848    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 524750     Buffer Size: 30043      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:41:57,604][train][INFO][train.py>_log] ==> #522000     Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 5.877    Value Loss: 6.834    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 525736     Buffer Size: 29853      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:45:20,333][train][INFO][train.py>_log] ==> #523000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 6.048    Value Loss: 6.622    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 526803     Buffer Size: 29720      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:48:41,161][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 5.568    Value Loss: 7.027    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 527897     Buffer Size: 29691      Transition Number: 1500.083k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:52:00,929][train][INFO][train.py>_log] ==> #525000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 5.928    Value Loss: 6.864    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 528791     Buffer Size: 29489      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:55:22,251][train][INFO][train.py>_log] ==> #526000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 6.073    Value Loss: 6.820    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 529667     Buffer Size: 29345      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-07 17:58:42,984][train][INFO][train.py>_log] ==> #527000     Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 6.315    Value Loss: 7.072    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 530856     Buffer Size: 29470      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:02:04,492][train][INFO][train.py>_log] ==> #528000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 5.784    Value Loss: 6.669    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 532080     Buffer Size: 29650      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:05:27,237][train][INFO][train.py>_log] ==> #529000     Total Loss: 2.805    [weighted Loss:2.805    Policy Loss: 7.008    Value Loss: 6.895    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 533084     Buffer Size: 29672      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:08:48,496][train][INFO][train.py>_log] ==> #530000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 5.863    Value Loss: 6.758    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 534081     Buffer Size: 29704      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:12:11,363][train][INFO][train.py>_log] ==> #531000     Total Loss: 2.648    [weighted Loss:2.648    Policy Loss: 6.652    Value Loss: 6.711    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 535111     Buffer Size: 29717      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:15:34,139][train][INFO][train.py>_log] ==> #532000     Total Loss: 3.483    [weighted Loss:3.483    Policy Loss: 6.466    Value Loss: 6.797    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 536151     Buffer Size: 29802      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:18:55,168][train][INFO][train.py>_log] ==> #533000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 6.467    Value Loss: 6.816    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 537273     Buffer Size: 29982      Transition Number: 1500.017k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:22:16,635][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 5.954    Value Loss: 6.569    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 538417     Buffer Size: 30036      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:25:36,254][train][INFO][train.py>_log] ==> #535000     Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 5.986    Value Loss: 7.180    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 539438     Buffer Size: 30019      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:28:58,899][train][INFO][train.py>_log] ==> #536000     Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 5.717    Value Loss: 7.078    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 540464     Buffer Size: 30066      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:32:19,890][train][INFO][train.py>_log] ==> #537000     Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 6.174    Value Loss: 7.385    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 541359     Buffer Size: 29999      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:35:41,280][train][INFO][train.py>_log] ==> #538000     Total Loss: 3.422    [weighted Loss:3.422    Policy Loss: 5.803    Value Loss: 6.725    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 542269     Buffer Size: 29966      Transition Number: 1499.945k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:39:01,149][train][INFO][train.py>_log] ==> #539000     Total Loss: 2.806    [weighted Loss:2.806    Policy Loss: 6.230    Value Loss: 7.163    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 543171     Buffer Size: 29932      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:42:23,761][train][INFO][train.py>_log] ==> #540000     Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 5.719    Value Loss: 6.870    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 544091     Buffer Size: 29866      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:45:44,591][train][INFO][train.py>_log] ==> #541000     Total Loss: 2.608    [weighted Loss:2.608    Policy Loss: 6.724    Value Loss: 6.644    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 545040     Buffer Size: 29884      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:49:06,650][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 5.883    Value Loss: 6.739    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 546014     Buffer Size: 29919      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:52:27,531][train][INFO][train.py>_log] ==> #543000     Total Loss: 3.295    [weighted Loss:3.295    Policy Loss: 6.813    Value Loss: 7.081    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 546933     Buffer Size: 29919      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:55:49,662][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 6.119    Value Loss: 7.072    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 547883     Buffer Size: 29929      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-07 18:59:11,044][train][INFO][train.py>_log] ==> #545000     Total Loss: 3.742    [weighted Loss:3.742    Policy Loss: 7.843    Value Loss: 6.707    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 548895     Buffer Size: 30012      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:02:34,517][train][INFO][train.py>_log] ==> #546000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 6.330    Value Loss: 6.681    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 549930     Buffer Size: 29888      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:05:56,299][train][INFO][train.py>_log] ==> #547000     Total Loss: 3.571    [weighted Loss:3.571    Policy Loss: 6.789    Value Loss: 6.769    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 550910     Buffer Size: 29638      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:09:19,134][train][INFO][train.py>_log] ==> #548000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.476    Value Loss: 6.733    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 551887     Buffer Size: 29467      Transition Number: 1500.062k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:12:41,581][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 7.133    Value Loss: 6.957    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 553013     Buffer Size: 29454      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:16:06,266][train][INFO][train.py>_log] ==> #550000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 7.618    Value Loss: 6.711    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 554124     Buffer Size: 29517      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:19:28,690][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.205    [weighted Loss:3.205    Policy Loss: 6.267    Value Loss: 6.999    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 555298     Buffer Size: 29693      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:22:50,414][train][INFO][train.py>_log] ==> #552000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 7.025    Value Loss: 7.104    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 556521     Buffer Size: 29839      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:26:15,285][train][INFO][train.py>_log] ==> #553000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 6.396    Value Loss: 7.079    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 557541     Buffer Size: 29756      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:29:38,379][train][INFO][train.py>_log] ==> #554000     Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 6.648    Value Loss: 7.206    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 558601     Buffer Size: 29846      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:32:57,589][train][INFO][train.py>_log] ==> #555000     Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 6.059    Value Loss: 7.003    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 559763     Buffer Size: 30114      Transition Number: 1500.312k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:36:19,013][train][INFO][train.py>_log] ==> #556000     Total Loss: 1.095    [weighted Loss:1.095    Policy Loss: 5.304    Value Loss: 6.989    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 560926     Buffer Size: 30132      Transition Number: 1499.938k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:39:40,786][train][INFO][train.py>_log] ==> #557000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 6.264    Value Loss: 7.090    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 561874     Buffer Size: 29922      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:43:02,860][train][INFO][train.py>_log] ==> #558000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 5.376    Value Loss: 6.608    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 562845     Buffer Size: 29848      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:46:24,300][train][INFO][train.py>_log] ==> #559000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 6.418    Value Loss: 7.061    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 563782     Buffer Size: 29806      Transition Number: 1500.198k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:49:47,226][train][INFO][train.py>_log] ==> #560000     Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 5.878    Value Loss: 6.988    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 564736     Buffer Size: 29745      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:53:07,306][train][INFO][train.py>_log] ==> #561000     Total Loss: 3.311    [weighted Loss:3.311    Policy Loss: 6.943    Value Loss: 6.571    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 565683     Buffer Size: 29715      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:56:29,852][train][INFO][train.py>_log] ==> #562000     Total Loss: 0.829    [weighted Loss:0.829    Policy Loss: 6.493    Value Loss: 6.499    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 566712     Buffer Size: 29638      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-07 19:59:49,433][train][INFO][train.py>_log] ==> #563000     Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 6.833    Value Loss: 7.151    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 567904     Buffer Size: 29686      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:03:12,407][train][INFO][train.py>_log] ==> #564000     Total Loss: 3.337    [weighted Loss:3.337    Policy Loss: 6.020    Value Loss: 7.342    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 569174     Buffer Size: 29876      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:06:34,676][train][INFO][train.py>_log] ==> #565000     Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 6.156    Value Loss: 7.058    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 570324     Buffer Size: 30015      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:09:56,124][train][INFO][train.py>_log] ==> #566000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 6.113    Value Loss: 6.992    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 571526     Buffer Size: 30267      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:13:17,564][train][INFO][train.py>_log] ==> #567000     Total Loss: 2.530    [weighted Loss:2.530    Policy Loss: 6.349    Value Loss: 6.802    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 572516     Buffer Size: 30354      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:16:38,918][train][INFO][train.py>_log] ==> #568000     Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 5.859    Value Loss: 7.157    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 573531     Buffer Size: 30453      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:19:58,603][train][INFO][train.py>_log] ==> #569000     Total Loss: 3.761    [weighted Loss:3.761    Policy Loss: 6.306    Value Loss: 6.465    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 574508     Buffer Size: 30545      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:23:18,491][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 5.259    Value Loss: 6.789    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 575522     Buffer Size: 30595      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:26:37,562][train][INFO][train.py>_log] ==> #571000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 5.691    Value Loss: 6.931    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 576592     Buffer Size: 30707      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:29:57,718][train][INFO][train.py>_log] ==> #572000     Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 6.385    Value Loss: 7.045    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 577686     Buffer Size: 30859      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:33:18,058][train][INFO][train.py>_log] ==> #573000     Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 6.349    Value Loss: 6.583    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 578700     Buffer Size: 30962      Transition Number: 1500.174k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:36:39,502][train][INFO][train.py>_log] ==> #574000     Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 6.807    Value Loss: 6.665    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 579776     Buffer Size: 31011      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:39:59,926][train][INFO][train.py>_log] ==> #575000     Total Loss: 1.433    [weighted Loss:1.433    Policy Loss: 6.369    Value Loss: 6.573    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 580800     Buffer Size: 31063      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:43:21,412][train][INFO][train.py>_log] ==> #576000     Total Loss: 3.794    [weighted Loss:3.794    Policy Loss: 6.194    Value Loss: 7.394    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 581851     Buffer Size: 31115      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:46:42,568][train][INFO][train.py>_log] ==> #577000     Total Loss: 3.447    [weighted Loss:3.447    Policy Loss: 6.653    Value Loss: 7.026    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 582856     Buffer Size: 31153      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:50:02,302][train][INFO][train.py>_log] ==> #578000     Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 6.921    Value Loss: 7.285    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 583847     Buffer Size: 31078      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:53:22,915][train][INFO][train.py>_log] ==> #579000     Total Loss: 2.352    [weighted Loss:2.352    Policy Loss: 7.200    Value Loss: 7.553    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 584956     Buffer Size: 31063      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-07 20:56:44,179][train][INFO][train.py>_log] ==> #580000     Total Loss: 3.447    [weighted Loss:3.447    Policy Loss: 6.848    Value Loss: 7.093    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 586065     Buffer Size: 31012      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:00:06,301][train][INFO][train.py>_log] ==> #581000     Total Loss: 5.452    [weighted Loss:5.452    Policy Loss: 8.456    Value Loss: 7.117    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 587189     Buffer Size: 30917      Transition Number: 1500.142k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:03:28,130][train][INFO][train.py>_log] ==> #582000     Total Loss: 1.463    [weighted Loss:1.463    Policy Loss: 6.173    Value Loss: 6.900    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 588299     Buffer Size: 30945      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:06:49,992][train][INFO][train.py>_log] ==> #583000     Total Loss: 3.209    [weighted Loss:3.209    Policy Loss: 8.209    Value Loss: 7.054    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 589301     Buffer Size: 30936      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:10:11,013][train][INFO][train.py>_log] ==> #584000     Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 6.822    Value Loss: 6.925    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 590317     Buffer Size: 30828      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:13:31,072][train][INFO][train.py>_log] ==> #585000     Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 6.465    Value Loss: 7.257    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 591435     Buffer Size: 30820      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:16:53,450][train][INFO][train.py>_log] ==> #586000     Total Loss: 3.850    [weighted Loss:3.850    Policy Loss: 6.551    Value Loss: 6.949    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 592578     Buffer Size: 30934      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:20:12,122][train][INFO][train.py>_log] ==> #587000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 6.657    Value Loss: 6.865    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 593631     Buffer Size: 31057      Transition Number: 1500.012k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:23:33,012][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.838    [weighted Loss:2.838    Policy Loss: 6.290    Value Loss: 7.017    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 594684     Buffer Size: 31172      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:26:56,246][train][INFO][train.py>_log] ==> #589000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 6.716    Value Loss: 7.231    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 595700     Buffer Size: 31238      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:30:16,137][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 6.141    Value Loss: 7.126    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 596703     Buffer Size: 31258      Transition Number: 1500.054k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:33:38,223][train][INFO][train.py>_log] ==> #591000     Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 6.547    Value Loss: 6.961    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 597586     Buffer Size: 31186      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:37:00,584][train][INFO][train.py>_log] ==> #592000     Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 7.153    Value Loss: 7.074    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 598503     Buffer Size: 30974      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:40:21,934][train][INFO][train.py>_log] ==> #593000     Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 7.519    Value Loss: 7.750    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 599640     Buffer Size: 30888      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:43:44,313][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 7.621    Value Loss: 7.335    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 600763     Buffer Size: 30796      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:47:05,945][train][INFO][train.py>_log] ==> #595000     Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 6.182    Value Loss: 7.382    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 602253     Buffer Size: 31055      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:50:27,131][train][INFO][train.py>_log] ==> #596000     Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 6.046    Value Loss: 6.945    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 603712     Buffer Size: 31430      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:53:44,911][train][INFO][train.py>_log] ==> #597000     Total Loss: 2.815    [weighted Loss:2.815    Policy Loss: 6.400    Value Loss: 7.204    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 604685     Buffer Size: 31456      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-07 21:57:05,929][train][INFO][train.py>_log] ==> #598000     Total Loss: 2.832    [weighted Loss:2.832    Policy Loss: 5.843    Value Loss: 7.322    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 605693     Buffer Size: 31462      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:00:23,934][train][INFO][train.py>_log] ==> #599000     Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 8.087    Value Loss: 7.292    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 606582     Buffer Size: 31431      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:03:40,808][train][INFO][train.py>_log] ==> #600000     Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 5.799    Value Loss: 7.597    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 607489     Buffer Size: 31329      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:07:01,734][train][INFO][train.py>_log] ==> #601000     Total Loss: 3.881    [weighted Loss:3.881    Policy Loss: 6.534    Value Loss: 7.295    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 608676     Buffer Size: 31401      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:10:19,630][train][INFO][train.py>_log] ==> #602000     Total Loss: 3.807    [weighted Loss:3.807    Policy Loss: 7.194    Value Loss: 7.423    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 609854     Buffer Size: 31498      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:13:38,012][train][INFO][train.py>_log] ==> #603000     Total Loss: 3.619    [weighted Loss:3.619    Policy Loss: 6.657    Value Loss: 6.726    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 610837     Buffer Size: 31454      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:16:59,603][train][INFO][train.py>_log] ==> #604000     Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 6.261    Value Loss: 7.298    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 611894     Buffer Size: 31408      Transition Number: 1500.196k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:20:20,336][train][INFO][train.py>_log] ==> #605000     Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 7.082    Value Loss: 7.374    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 612824     Buffer Size: 31345      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:23:39,696][train][INFO][train.py>_log] ==> #606000     Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 5.744    Value Loss: 6.969    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 613763     Buffer Size: 31300      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:27:00,997][train][INFO][train.py>_log] ==> #607000     Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 6.478    Value Loss: 7.423    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 614689     Buffer Size: 31227      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:30:20,829][train][INFO][train.py>_log] ==> #608000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 6.277    Value Loss: 7.434    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 615601     Buffer Size: 31101      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:33:39,906][train][INFO][train.py>_log] ==> #609000     Total Loss: 1.963    [weighted Loss:1.963    Policy Loss: 5.963    Value Loss: 7.184    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 616484     Buffer Size: 30960      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:37:01,323][train][INFO][train.py>_log] ==> #610000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 5.462    Value Loss: 7.073    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 617410     Buffer Size: 30804      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:40:23,482][train][INFO][train.py>_log] ==> #611000     Total Loss: 2.949    [weighted Loss:2.949    Policy Loss: 6.428    Value Loss: 7.524    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 618389     Buffer Size: 30680      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:43:45,541][train][INFO][train.py>_log] ==> #612000     Total Loss: 2.993    [weighted Loss:2.993    Policy Loss: 6.472    Value Loss: 7.114    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 619380     Buffer Size: 30602      Transition Number: 1500.121k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:47:12,002][train][INFO][train.py>_log] ==> #613000     Total Loss: 1.337    [weighted Loss:1.337    Policy Loss: 6.903    Value Loss: 7.293    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 621452     Buffer Size: 31583      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:50:32,979][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.867    [weighted Loss:2.867    Policy Loss: 6.804    Value Loss: 7.604    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 623558     Buffer Size: 32551      Transition Number: 1500.072k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:53:51,229][train][INFO][train.py>_log] ==> #615000     Total Loss: 2.626    [weighted Loss:2.626    Policy Loss: 6.582    Value Loss: 7.404    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 625166     Buffer Size: 33026      Transition Number: 1500.202k Batch Size: 256        Lr: 0.10000 
[2022-01-07 22:57:12,232][train][INFO][train.py>_log] ==> #616000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 6.006    Value Loss: 7.168    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 626789     Buffer Size: 33537      Transition Number: 1500.148k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:00:31,498][train][INFO][train.py>_log] ==> #617000     Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 7.271    Value Loss: 6.628    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 627699     Buffer Size: 33433      Transition Number: 1500.173k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:03:51,802][train][INFO][train.py>_log] ==> #618000     Total Loss: 1.513    [weighted Loss:1.513    Policy Loss: 6.136    Value Loss: 6.914    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 628655     Buffer Size: 33345      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:07:12,472][train][INFO][train.py>_log] ==> #619000     Total Loss: 1.964    [weighted Loss:1.964    Policy Loss: 6.913    Value Loss: 6.916    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 629645     Buffer Size: 33332      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:10:33,283][train][INFO][train.py>_log] ==> #620000     Total Loss: 3.556    [weighted Loss:3.556    Policy Loss: 7.081    Value Loss: 7.489    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 630640     Buffer Size: 33385      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:13:51,831][train][INFO][train.py>_log] ==> #621000     Total Loss: 3.081    [weighted Loss:3.081    Policy Loss: 7.420    Value Loss: 6.955    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 631600     Buffer Size: 33446      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:17:13,331][train][INFO][train.py>_log] ==> #622000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 7.986    Value Loss: 7.160    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 632589     Buffer Size: 33406      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:20:33,339][train][INFO][train.py>_log] ==> #623000     Total Loss: 2.153    [weighted Loss:2.153    Policy Loss: 7.310    Value Loss: 6.746    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 633777     Buffer Size: 33423      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:23:55,922][train][INFO][train.py>_log] ==> #624000     Total Loss: 3.162    [weighted Loss:3.162    Policy Loss: 8.171    Value Loss: 7.176    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 634980     Buffer Size: 33311      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:27:19,404][train][INFO][train.py>_log] ==> #625000     Total Loss: 3.497    [weighted Loss:3.497    Policy Loss: 8.074    Value Loss: 7.440    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 636346     Buffer Size: 33180      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:30:40,478][train][INFO][train.py>_log] ==> #626000     Total Loss: 3.800    [weighted Loss:3.800    Policy Loss: 7.834    Value Loss: 7.426    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 637644     Buffer Size: 33260      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:33:59,869][train][INFO][train.py>_log] ==> #627000     Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 7.751    Value Loss: 7.678    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 638878     Buffer Size: 33458      Transition Number: 1500.050k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:37:19,552][train][INFO][train.py>_log] ==> #628000     Total Loss: 2.702    [weighted Loss:2.702    Policy Loss: 7.900    Value Loss: 7.577    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 640092     Buffer Size: 33702      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:40:38,028][train][INFO][train.py>_log] ==> #629000     Total Loss: 0.875    [weighted Loss:0.875    Policy Loss: 7.687    Value Loss: 7.418    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 641323     Buffer Size: 33968      Transition Number: 1499.937k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:43:57,699][train][INFO][train.py>_log] ==> #630000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 7.696    Value Loss: 7.283    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 642538     Buffer Size: 34045      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:47:19,126][train][INFO][train.py>_log] ==> #631000     Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 6.598    Value Loss: 7.597    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 643860     Buffer Size: 34162      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:50:39,977][train][INFO][train.py>_log] ==> #632000     Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 7.621    Value Loss: 7.321    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 645185     Buffer Size: 34416      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:53:56,236][train][INFO][train.py>_log] ==> #633000     Total Loss: 2.316    [weighted Loss:2.316    Policy Loss: 5.950    Value Loss: 7.505    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 646304     Buffer Size: 34568      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-07 23:57:17,820][train][INFO][train.py>_log] ==> #634000     Total Loss: 2.891    [weighted Loss:2.891    Policy Loss: 6.648    Value Loss: 7.635    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 647484     Buffer Size: 34744      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:00:37,914][train][INFO][train.py>_log] ==> #635000     Total Loss: 1.590    [weighted Loss:1.590    Policy Loss: 7.639    Value Loss: 7.357    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 648508     Buffer Size: 34823      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:03:56,158][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 6.560    Value Loss: 7.714    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 649524     Buffer Size: 34939      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:07:16,099][train][INFO][train.py>_log] ==> #637000     Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 7.874    Value Loss: 7.116    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 650513     Buffer Size: 35029      Transition Number: 1500.105k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:10:35,764][train][INFO][train.py>_log] ==> #638000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 6.472    Value Loss: 7.157    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 651507     Buffer Size: 35114      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:13:53,137][train][INFO][train.py>_log] ==> #639000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 7.209    Value Loss: 7.253    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 652710     Buffer Size: 35380      Transition Number: 1499.967k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:17:13,292][train][INFO][train.py>_log] ==> #640000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 6.567    Value Loss: 7.530    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 653921     Buffer Size: 35630      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:20:33,455][train][INFO][train.py>_log] ==> #641000     Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 6.530    Value Loss: 7.428    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 655118     Buffer Size: 35871      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:23:52,479][train][INFO][train.py>_log] ==> #642000     Total Loss: 3.277    [weighted Loss:3.277    Policy Loss: 6.186    Value Loss: 7.496    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 656375     Buffer Size: 35377      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:27:13,883][train][INFO][train.py>_log] ==> #643000     Total Loss: 1.771    [weighted Loss:1.771    Policy Loss: 6.077    Value Loss: 7.262    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 657478     Buffer Size: 34411      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:30:34,379][train][INFO][train.py>_log] ==> #644000     Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 6.044    Value Loss: 7.228    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 658596     Buffer Size: 33772      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:33:54,264][train][INFO][train.py>_log] ==> #645000     Total Loss: 1.069    [weighted Loss:1.069    Policy Loss: 5.697    Value Loss: 7.502    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 659618     Buffer Size: 33201      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:37:15,039][train][INFO][train.py>_log] ==> #646000     Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 5.206    Value Loss: 7.170    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 660623     Buffer Size: 33135      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:40:34,037][train][INFO][train.py>_log] ==> #647000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 6.082    Value Loss: 7.021    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 661571     Buffer Size: 33155      Transition Number: 1499.986k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:43:54,499][train][INFO][train.py>_log] ==> #648000     Total Loss: 2.641    [weighted Loss:2.641    Policy Loss: 4.945    Value Loss: 7.271    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 662512     Buffer Size: 33154      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:47:16,034][train][INFO][train.py>_log] ==> #649000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 5.945    Value Loss: 6.982    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 663433     Buffer Size: 33090      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:50:36,465][train][INFO][train.py>_log] ==> #650000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 5.499    Value Loss: 6.993    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 664353     Buffer Size: 33053      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:53:53,763][train][INFO][train.py>_log] ==> #651000     Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 5.850    Value Loss: 7.296    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 665231     Buffer Size: 32988      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-08 00:57:14,905][train][INFO][train.py>_log] ==> #652000     Total Loss: 3.257    [weighted Loss:3.257    Policy Loss: 5.217    Value Loss: 7.140    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 666152     Buffer Size: 32840      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:00:35,479][train][INFO][train.py>_log] ==> #653000     Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 5.836    Value Loss: 7.193    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 667031     Buffer Size: 32588      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:03:55,388][train][INFO][train.py>_log] ==> #654000     Total Loss: 3.085    [weighted Loss:3.085    Policy Loss: 5.766    Value Loss: 7.240    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 667912     Buffer Size: 32292      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:07:16,809][train][INFO][train.py>_log] ==> #655000     Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 5.772    Value Loss: 6.764    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 668907     Buffer Size: 32012      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:10:35,840][train][INFO][train.py>_log] ==> #656000     Total Loss: 3.028    [weighted Loss:3.028    Policy Loss: 5.906    Value Loss: 6.997    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 669920     Buffer Size: 31808      Transition Number: 1500.183k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:13:56,774][train][INFO][train.py>_log] ==> #657000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 6.835    Value Loss: 6.923    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 671025     Buffer Size: 31732      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:17:17,283][train][INFO][train.py>_log] ==> #658000     Total Loss: 1.563    [weighted Loss:1.563    Policy Loss: 6.734    Value Loss: 7.384    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 672153     Buffer Size: 31662      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:20:37,709][train][INFO][train.py>_log] ==> #659000     Total Loss: 3.537    [weighted Loss:3.537    Policy Loss: 7.517    Value Loss: 7.096    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 673278     Buffer Size: 31534      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:23:57,767][train][INFO][train.py>_log] ==> #660000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 6.846    Value Loss: 6.749    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 674395     Buffer Size: 31403      Transition Number: 1499.951k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:27:19,241][train][INFO][train.py>_log] ==> #661000     Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 7.612    Value Loss: 7.381    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 675523     Buffer Size: 31249      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:30:40,620][train][INFO][train.py>_log] ==> #662000     Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 6.317    Value Loss: 7.332    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 676647     Buffer Size: 31108      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:34:00,482][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 8.205    Value Loss: 7.291    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 678242     Buffer Size: 31498      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:37:22,060][train][INFO][train.py>_log] ==> #664000     Total Loss: 3.590    [weighted Loss:3.590    Policy Loss: 7.103    Value Loss: 7.226    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 679855     Buffer Size: 31931      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:40:41,359][train][INFO][train.py>_log] ==> #665000     Total Loss: 2.676    [weighted Loss:2.676    Policy Loss: 6.766    Value Loss: 7.529    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 681075     Buffer Size: 32131      Transition Number: 1500.229k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:44:01,142][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 7.686    Value Loss: 7.377    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 682343     Buffer Size: 32363      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:47:19,104][train][INFO][train.py>_log] ==> #667000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 6.068    Value Loss: 7.364    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 683920     Buffer Size: 32847      Transition Number: 1500.092k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:50:38,472][train][INFO][train.py>_log] ==> #668000     Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 9.199    Value Loss: 7.689    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 685502     Buffer Size: 33258      Transition Number: 1500.044k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:53:57,066][train][INFO][train.py>_log] ==> #669000     Total Loss: 2.758    [weighted Loss:2.758    Policy Loss: 7.121    Value Loss: 7.004    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 687057     Buffer Size: 33571      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-08 01:57:19,420][train][INFO][train.py>_log] ==> #670000     Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 6.025    Value Loss: 7.243    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 688667     Buffer Size: 33875      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:00:37,197][train][INFO][train.py>_log] ==> #671000     Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 6.107    Value Loss: 7.459    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 689694     Buffer Size: 33725      Transition Number: 1499.952k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:03:56,550][train][INFO][train.py>_log] ==> #672000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 5.445    Value Loss: 7.035    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 690740     Buffer Size: 33657      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:07:16,151][train][INFO][train.py>_log] ==> #673000     Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 5.946    Value Loss: 7.152    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 691738     Buffer Size: 33585      Transition Number: 1500.041k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:10:35,496][train][INFO][train.py>_log] ==> #674000     Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 5.606    Value Loss: 7.607    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 692753     Buffer Size: 33520      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:13:56,688][train][INFO][train.py>_log] ==> #675000     Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 6.242    Value Loss: 7.673    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 693709     Buffer Size: 33476      Transition Number: 1500.223k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:17:16,194][train][INFO][train.py>_log] ==> #676000     Total Loss: 3.077    [weighted Loss:3.077    Policy Loss: 5.572    Value Loss: 7.693    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 694655     Buffer Size: 33474      Transition Number: 1500.071k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:20:37,079][train][INFO][train.py>_log] ==> #677000     Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 6.818    Value Loss: 7.169    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 695585     Buffer Size: 33405      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:23:57,092][train][INFO][train.py>_log] ==> #678000     Total Loss: 2.714    [weighted Loss:2.714    Policy Loss: 5.503    Value Loss: 7.391    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 696516     Buffer Size: 33401      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:27:16,850][train][INFO][train.py>_log] ==> #679000     Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 6.677    Value Loss: 7.660    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 697429     Buffer Size: 33413      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:30:38,579][train][INFO][train.py>_log] ==> #680000     Total Loss: 3.571    [weighted Loss:3.571    Policy Loss: 6.142    Value Loss: 7.243    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 698375     Buffer Size: 33433      Transition Number: 1499.956k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:33:59,574][train][INFO][train.py>_log] ==> #681000     Total Loss: 2.859    [weighted Loss:2.859    Policy Loss: 6.768    Value Loss: 7.444    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 699391     Buffer Size: 33545      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:37:21,542][train][INFO][train.py>_log] ==> #682000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 7.275    Value Loss: 7.553    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 700451     Buffer Size: 33674      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:40:42,298][train][INFO][train.py>_log] ==> #683000     Total Loss: 3.069    [weighted Loss:3.069    Policy Loss: 5.946    Value Loss: 7.134    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 701476     Buffer Size: 33781      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:44:01,961][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 6.659    Value Loss: 7.568    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 702470     Buffer Size: 33780      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:47:23,532][train][INFO][train.py>_log] ==> #685000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 4.946    Value Loss: 7.534    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 703828     Buffer Size: 34109      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:50:42,617][train][INFO][train.py>_log] ==> #686000     Total Loss: 3.223    [weighted Loss:3.223    Policy Loss: 6.162    Value Loss: 7.737    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 705138     Buffer Size: 34305      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:54:01,520][train][INFO][train.py>_log] ==> #687000     Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 6.271    Value Loss: 7.443    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 706103     Buffer Size: 34187      Transition Number: 1500.121k Batch Size: 256        Lr: 0.10000 
[2022-01-08 02:57:22,236][train][INFO][train.py>_log] ==> #688000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 5.112    Value Loss: 7.192    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 707095     Buffer Size: 34081      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:00:41,817][train][INFO][train.py>_log] ==> #689000     Total Loss: 1.948    [weighted Loss:1.948    Policy Loss: 5.089    Value Loss: 7.352    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 707979     Buffer Size: 33865      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:04:01,167][train][INFO][train.py>_log] ==> #690000     Total Loss: 2.996    [weighted Loss:2.996    Policy Loss: 5.401    Value Loss: 7.370    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 708854     Buffer Size: 33635      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:07:22,049][train][INFO][train.py>_log] ==> #691000     Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 5.119    Value Loss: 7.002    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 709751     Buffer Size: 33440      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:10:44,539][train][INFO][train.py>_log] ==> #692000     Total Loss: 1.087    [weighted Loss:1.087    Policy Loss: 5.218    Value Loss: 7.140    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 710659     Buffer Size: 32962      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:14:06,991][train][INFO][train.py>_log] ==> #693000     Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 6.722    Value Loss: 7.105    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 711557     Buffer Size: 32358      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:17:28,683][train][INFO][train.py>_log] ==> #694000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 6.126    Value Loss: 6.955    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 712476     Buffer Size: 31888      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:20:49,071][train][INFO][train.py>_log] ==> #695000     Total Loss: 1.410    [weighted Loss:1.410    Policy Loss: 7.863    Value Loss: 6.896    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 713458     Buffer Size: 31607      Transition Number: 1499.940k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:24:09,499][train][INFO][train.py>_log] ==> #696000     Total Loss: 1.527    [weighted Loss:1.527    Policy Loss: 6.848    Value Loss: 6.848    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 714418     Buffer Size: 31235      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:27:29,674][train][INFO][train.py>_log] ==> #697000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 5.993    Value Loss: 6.938    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 715362     Buffer Size: 30675      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:30:51,342][train][INFO][train.py>_log] ==> #698000     Total Loss: 1.535    [weighted Loss:1.535    Policy Loss: 6.592    Value Loss: 6.824    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 716308     Buffer Size: 30090      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:34:12,276][train][INFO][train.py>_log] ==> #699000     Total Loss: 1.365    [weighted Loss:1.365    Policy Loss: 6.931    Value Loss: 7.285    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 717386     Buffer Size: 29669      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:37:33,298][train][INFO][train.py>_log] ==> #700000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 7.242    Value Loss: 7.062    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 718472     Buffer Size: 29349      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:40:55,701][train][INFO][train.py>_log] ==> #701000     Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 7.782    Value Loss: 6.832    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 719825     Buffer Size: 29593      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:44:18,222][train][INFO][train.py>_log] ==> #702000     Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 7.148    Value Loss: 7.260    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 721214     Buffer Size: 29875      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:47:40,498][train][INFO][train.py>_log] ==> #703000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 7.332    Value Loss: 6.928    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 723252     Buffer Size: 30819      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:50:59,516][train][INFO][train.py>_log] ==> #704000     Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 9.630    Value Loss: 7.718    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 725328     Buffer Size: 31847      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:54:19,519][train][INFO][train.py>_log] ==> #705000     Total Loss: 3.216    [weighted Loss:3.216    Policy Loss: 6.754    Value Loss: 7.706    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 727060     Buffer Size: 32587      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-08 03:57:36,704][train][INFO][train.py>_log] ==> #706000     Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 7.901    Value Loss: 6.947    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 728795     Buffer Size: 33345      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:00:53,820][train][INFO][train.py>_log] ==> #707000     Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 6.917    Value Loss: 7.342    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 730327     Buffer Size: 33911      Transition Number: 1500.014k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:04:13,127][train][INFO][train.py>_log] ==> #708000     Total Loss: 1.768    [weighted Loss:1.768    Policy Loss: 7.642    Value Loss: 7.294    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 731851     Buffer Size: 34460      Transition Number: 1500.066k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:07:29,521][train][INFO][train.py>_log] ==> #709000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 6.140    Value Loss: 7.124    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 733041     Buffer Size: 34687      Transition Number: 1500.006k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:10:47,751][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.509    [weighted Loss:2.509    Policy Loss: 6.619    Value Loss: 7.615    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 734147     Buffer Size: 34787      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:14:07,105][train][INFO][train.py>_log] ==> #711000     Total Loss: 3.087    [weighted Loss:3.087    Policy Loss: 5.712    Value Loss: 7.357    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 735140     Buffer Size: 34775      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:17:25,328][train][INFO][train.py>_log] ==> #712000     Total Loss: 3.209    [weighted Loss:3.209    Policy Loss: 6.668    Value Loss: 7.179    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 736187     Buffer Size: 34799      Transition Number: 1500.043k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:20:45,799][train][INFO][train.py>_log] ==> #713000     Total Loss: 2.850    [weighted Loss:2.850    Policy Loss: 6.122    Value Loss: 7.371    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 737095     Buffer Size: 34760      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:24:06,697][train][INFO][train.py>_log] ==> #714000     Total Loss: 2.407    [weighted Loss:2.407    Policy Loss: 5.207    Value Loss: 7.464    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 738029     Buffer Size: 34439      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:27:25,851][train][INFO][train.py>_log] ==> #715000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 5.790    Value Loss: 7.382    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 738975     Buffer Size: 34078      Transition Number: 1500.114k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:30:48,172][train][INFO][train.py>_log] ==> #716000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 6.716    Value Loss: 7.137    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 739890     Buffer Size: 33969      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:34:08,960][train][INFO][train.py>_log] ==> #717000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 5.732    Value Loss: 7.163    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 740937     Buffer Size: 34016      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:37:27,351][train][INFO][train.py>_log] ==> #718000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 6.353    Value Loss: 7.126    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 741953     Buffer Size: 34139      Transition Number: 1500.089k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:40:47,197][train][INFO][train.py>_log] ==> #719000     Total Loss: 3.888    [weighted Loss:3.888    Policy Loss: 6.151    Value Loss: 7.584    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 743046     Buffer Size: 34338      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:44:09,677][train][INFO][train.py>_log] ==> #720000     Total Loss: 1.504    [weighted Loss:1.504    Policy Loss: 5.901    Value Loss: 7.447    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 744162     Buffer Size: 34536      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:47:30,454][train][INFO][train.py>_log] ==> #721000     Total Loss: 3.805    [weighted Loss:3.805    Policy Loss: 7.208    Value Loss: 7.325    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 745149     Buffer Size: 34619      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:50:51,550][train][INFO][train.py>_log] ==> #722000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 6.023    Value Loss: 7.128    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 746090     Buffer Size: 34671      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:54:10,882][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 6.865    Value Loss: 6.969    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 747455     Buffer Size: 35091      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-08 04:57:30,168][train][INFO][train.py>_log] ==> #724000     Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 6.108    Value Loss: 7.130    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 748851     Buffer Size: 35480      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:00:49,683][train][INFO][train.py>_log] ==> #725000     Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 7.377    Value Loss: 7.710    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 749812     Buffer Size: 35527      Transition Number: 1499.992k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:04:10,796][train][INFO][train.py>_log] ==> #726000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 5.997    Value Loss: 7.170    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 750800     Buffer Size: 35564      Transition Number: 1499.962k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:07:28,725][train][INFO][train.py>_log] ==> #727000     Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 6.803    Value Loss: 7.311    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 751740     Buffer Size: 35586      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:10:45,954][train][INFO][train.py>_log] ==> #728000     Total Loss: 3.621    [weighted Loss:3.621    Policy Loss: 7.276    Value Loss: 7.163    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 752674     Buffer Size: 35506      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:14:07,967][train][INFO][train.py>_log] ==> #729000     Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 6.114    Value Loss: 7.641    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 753654     Buffer Size: 35427      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:17:25,079][train][INFO][train.py>_log] ==> #730000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 6.404    Value Loss: 7.861    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 754631     Buffer Size: 35187      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:20:45,050][train][INFO][train.py>_log] ==> #731000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 6.243    Value Loss: 7.323    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 755593     Buffer Size: 34901      Transition Number: 1500.096k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:24:06,237][train][INFO][train.py>_log] ==> #732000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 6.309    Value Loss: 6.740    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 756561     Buffer Size: 34270      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:27:26,119][train][INFO][train.py>_log] ==> #733000     Total Loss: 2.735    [weighted Loss:2.735    Policy Loss: 5.524    Value Loss: 6.906    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 757566     Buffer Size: 33342      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:30:46,029][train][INFO][train.py>_log] ==> #734000     Total Loss: 4.263    [weighted Loss:4.263    Policy Loss: 7.819    Value Loss: 7.339    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 758569     Buffer Size: 32459      Transition Number: 1500.042k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:34:09,798][train][INFO][train.py>_log] ==> #735000     Total Loss: 2.813    [weighted Loss:2.813    Policy Loss: 6.805    Value Loss: 6.822    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 759723     Buffer Size: 31891      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:37:29,598][train][INFO][train.py>_log] ==> #736000     Total Loss: 1.623    [weighted Loss:1.623    Policy Loss: 8.664    Value Loss: 7.557    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 760833     Buffer Size: 31406      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:40:50,883][train][INFO][train.py>_log] ==> #737000     Total Loss: 3.235    [weighted Loss:3.235    Policy Loss: 7.229    Value Loss: 7.446    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 762143     Buffer Size: 31172      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:44:12,637][train][INFO][train.py>_log] ==> #738000     Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 8.191    Value Loss: 7.695    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 763439     Buffer Size: 31069      Transition Number: 1500.080k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:47:33,021][train][INFO][train.py>_log] ==> #739000     Total Loss: 2.358    [weighted Loss:2.358    Policy Loss: 7.006    Value Loss: 7.658    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 764814     Buffer Size: 31265      Transition Number: 1500.027k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:50:52,030][train][INFO][train.py>_log] ==> #740000     Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 7.122    Value Loss: 7.094    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 766191     Buffer Size: 31516      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:54:13,846][train][INFO][train.py>_log] ==> #741000     Total Loss: 1.535    [weighted Loss:1.535    Policy Loss: 6.234    Value Loss: 7.410    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 767255     Buffer Size: 31593      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-08 05:57:33,014][train][INFO][train.py>_log] ==> #742000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 7.224    Value Loss: 7.526    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 768367     Buffer Size: 31675      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:00:52,201][train][INFO][train.py>_log] ==> #743000     Total Loss: 3.655    [weighted Loss:3.655    Policy Loss: 6.811    Value Loss: 7.316    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 769423     Buffer Size: 31775      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:04:14,723][train][INFO][train.py>_log] ==> #744000     Total Loss: 3.150    [weighted Loss:3.150    Policy Loss: 7.046    Value Loss: 6.977    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 770517     Buffer Size: 31890      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:07:35,528][train][INFO][train.py>_log] ==> #745000     Total Loss: 3.256    [weighted Loss:3.256    Policy Loss: 8.259    Value Loss: 7.631    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 771735     Buffer Size: 32149      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:10:56,530][train][INFO][train.py>_log] ==> #746000     Total Loss: 2.936    [weighted Loss:2.936    Policy Loss: 7.687    Value Loss: 7.555    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 772976     Buffer Size: 32333      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:14:17,389][train][INFO][train.py>_log] ==> #747000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 6.762    Value Loss: 7.541    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 774104     Buffer Size: 32408      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:17:35,646][train][INFO][train.py>_log] ==> #748000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 7.539    Value Loss: 7.726    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 775229     Buffer Size: 32445      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:20:55,990][train][INFO][train.py>_log] ==> #749000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 6.955    Value Loss: 7.550    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 776771     Buffer Size: 32830      Transition Number: 1500.115k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:24:18,021][train][INFO][train.py>_log] ==> #750000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 8.141    Value Loss: 7.434    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 778335     Buffer Size: 33335      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:27:36,864][train][INFO][train.py>_log] ==> #751000     Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 7.904    Value Loss: 7.670    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 779744     Buffer Size: 33729      Transition Number: 1500.074k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:30:55,928][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.130    [weighted Loss:1.130    Policy Loss: 7.674    Value Loss: 7.740    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 781057     Buffer Size: 33753      Transition Number: 1500.059k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:34:17,654][train][INFO][train.py>_log] ==> #753000     Total Loss: 2.374    [weighted Loss:2.374    Policy Loss: 6.857    Value Loss: 7.342    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 782425     Buffer Size: 33704      Transition Number: 1499.950k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:37:37,349][train][INFO][train.py>_log] ==> #754000     Total Loss: 0.860    [weighted Loss:0.860    Policy Loss: 8.949    Value Loss: 7.449    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 783767     Buffer Size: 33973      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:40:55,403][train][INFO][train.py>_log] ==> #755000     Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 6.771    Value Loss: 7.449    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 785756     Buffer Size: 34877      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:44:16,517][train][INFO][train.py>_log] ==> #756000     Total Loss: 4.742    [weighted Loss:4.742    Policy Loss: 8.226    Value Loss: 7.577    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 787684     Buffer Size: 35785      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:47:32,224][train][INFO][train.py>_log] ==> #757000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 7.570    Value Loss: 7.641    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 789074     Buffer Size: 36220      Transition Number: 1500.058k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:50:47,752][train][INFO][train.py>_log] ==> #758000     Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 7.181    Value Loss: 7.724    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 790459     Buffer Size: 36601      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:54:06,133][train][INFO][train.py>_log] ==> #759000     Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 5.538    Value Loss: 7.319    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 791401     Buffer Size: 36576      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-08 06:57:25,243][train][INFO][train.py>_log] ==> #760000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 6.451    Value Loss: 7.444    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 792343     Buffer Size: 36552      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:00:45,565][train][INFO][train.py>_log] ==> #761000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 6.631    Value Loss: 7.576    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 793454     Buffer Size: 36656      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:04:03,250][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 6.884    Value Loss: 7.222    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 794557     Buffer Size: 36758      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:07:21,854][train][INFO][train.py>_log] ==> #763000     Total Loss: 3.516    [weighted Loss:3.516    Policy Loss: 6.250    Value Loss: 7.823    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 795903     Buffer Size: 37072      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:10:38,468][train][INFO][train.py>_log] ==> #764000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 8.271    Value Loss: 7.569    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 797261     Buffer Size: 37282      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:13:55,537][train][INFO][train.py>_log] ==> #765000     Total Loss: 2.864    [weighted Loss:2.864    Policy Loss: 7.106    Value Loss: 7.379    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 798523     Buffer Size: 37450      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:17:16,909][train][INFO][train.py>_log] ==> #766000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 6.988    Value Loss: 7.658    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 799800     Buffer Size: 37449      Transition Number: 1500.086k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:20:34,659][train][INFO][train.py>_log] ==> #767000     Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 6.008    Value Loss: 7.779    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 801022     Buffer Size: 37392      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:23:52,255][train][INFO][train.py>_log] ==> #768000     Total Loss: 3.023    [weighted Loss:3.023    Policy Loss: 7.257    Value Loss: 7.319    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 802188     Buffer Size: 37256      Transition Number: 1500.093k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:27:13,784][train][INFO][train.py>_log] ==> #769000     Total Loss: 0.947    [weighted Loss:0.947    Policy Loss: 7.621    Value Loss: 7.627    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 803550     Buffer Size: 37251      Transition Number: 1500.037k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:30:31,998][train][INFO][train.py>_log] ==> #770000     Total Loss: 3.941    [weighted Loss:3.941    Policy Loss: 6.999    Value Loss: 7.540    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 804903     Buffer Size: 37509      Transition Number: 1500.119k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:33:49,188][train][INFO][train.py>_log] ==> #771000     Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 7.576    Value Loss: 7.727    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 806251     Buffer Size: 37761      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:37:08,624][train][INFO][train.py>_log] ==> #772000     Total Loss: 2.613    [weighted Loss:2.613    Policy Loss: 6.972    Value Loss: 7.533    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 807566     Buffer Size: 37994      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:40:24,172][train][INFO][train.py>_log] ==> #773000     Total Loss: 2.305    [weighted Loss:2.305    Policy Loss: 8.549    Value Loss: 7.431    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 809107     Buffer Size: 38452      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:43:39,965][train][INFO][train.py>_log] ==> #774000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 7.190    Value Loss: 7.514    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 810653     Buffer Size: 38790      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:46:56,122][train][INFO][train.py>_log] ==> #775000     Total Loss: 4.230    [weighted Loss:4.230    Policy Loss: 7.530    Value Loss: 7.713    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 811905     Buffer Size: 38874      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:50:14,019][train][INFO][train.py>_log] ==> #776000     Total Loss: 1.736    [weighted Loss:1.736    Policy Loss: 7.695    Value Loss: 7.508    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 813159     Buffer Size: 39033      Transition Number: 1500.080k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:53:31,724][train][INFO][train.py>_log] ==> #777000     Total Loss: 2.382    [weighted Loss:2.382    Policy Loss: 7.277    Value Loss: 7.504    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 814346     Buffer Size: 39128      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-08 07:56:49,177][train][INFO][train.py>_log] ==> #778000     Total Loss: 3.808    [weighted Loss:3.808    Policy Loss: 7.267    Value Loss: 7.618    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 815553     Buffer Size: 38899      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:00:07,339][train][INFO][train.py>_log] ==> #779000     Total Loss: 2.773    [weighted Loss:2.773    Policy Loss: 7.537    Value Loss: 7.571    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 816820     Buffer Size: 38641      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:03:24,610][train][INFO][train.py>_log] ==> #780000     Total Loss: 3.986    [weighted Loss:3.986    Policy Loss: 7.039    Value Loss: 7.327    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 818098     Buffer Size: 38511      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:06:43,452][train][INFO][train.py>_log] ==> #781000     Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 6.885    Value Loss: 7.395    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 819135     Buffer Size: 38281      Transition Number: 1500.063k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:10:02,382][train][INFO][train.py>_log] ==> #782000     Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 7.199    Value Loss: 7.448    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 820145     Buffer Size: 37990      Transition Number: 1500.046k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:13:23,067][train][INFO][train.py>_log] ==> #783000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 7.230    Value Loss: 7.931    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 821476     Buffer Size: 37956      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:16:46,228][train][INFO][train.py>_log] ==> #784000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 7.062    Value Loss: 7.719    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 822764     Buffer Size: 37550      Transition Number: 1500.188k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:20:04,951][train][INFO][train.py>_log] ==> #785000     Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 7.961    Value Loss: 7.800    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 824010     Buffer Size: 36961      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:23:21,516][train][INFO][train.py>_log] ==> #786000     Total Loss: 3.609    [weighted Loss:3.609    Policy Loss: 8.205    Value Loss: 7.444    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 825291     Buffer Size: 36686      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:26:40,951][train][INFO][train.py>_log] ==> #787000     Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 8.140    Value Loss: 7.893    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 826384     Buffer Size: 36416      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:29:57,009][train][INFO][train.py>_log] ==> #788000     Total Loss: 3.929    [weighted Loss:3.929    Policy Loss: 8.799    Value Loss: 8.059    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 827440     Buffer Size: 36364      Transition Number: 1500.035k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:33:14,422][train][INFO][train.py>_log] ==> #789000     Total Loss: 3.350    [weighted Loss:3.350    Policy Loss: 7.022    Value Loss: 7.870    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 828746     Buffer Size: 36703      Transition Number: 1499.954k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:36:33,254][train][INFO][train.py>_log] ==> #790000     Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 8.147    Value Loss: 7.787    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 830111     Buffer Size: 36962      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:39:51,671][train][INFO][train.py>_log] ==> #791000     Total Loss: 3.731    [weighted Loss:3.731    Policy Loss: 7.922    Value Loss: 7.928    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 831635     Buffer Size: 37330      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:43:09,862][train][INFO][train.py>_log] ==> #792000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 7.630    Value Loss: 8.057    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 833137     Buffer Size: 37512      Transition Number: 1500.068k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:46:30,163][train][INFO][train.py>_log] ==> #793000     Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 6.208    Value Loss: 7.673    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 834244     Buffer Size: 37312      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:49:49,077][train][INFO][train.py>_log] ==> #794000     Total Loss: 1.953    [weighted Loss:1.953    Policy Loss: 6.359    Value Loss: 7.613    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 835396     Buffer Size: 37129      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:53:08,109][train][INFO][train.py>_log] ==> #795000     Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 5.813    Value Loss: 7.995    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 836329     Buffer Size: 36860      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:56:28,453][train][INFO][train.py>_log] ==> #796000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 6.154    Value Loss: 7.822    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 837300     Buffer Size: 36607      Transition Number: 1500.117k Batch Size: 256        Lr: 0.10000 
[2022-01-08 08:59:47,144][train][INFO][train.py>_log] ==> #797000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 5.546    Value Loss: 7.411    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 838177     Buffer Size: 36348      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:03:09,185][train][INFO][train.py>_log] ==> #798000     Total Loss: 2.670    [weighted Loss:2.670    Policy Loss: 5.894    Value Loss: 7.499    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 839110     Buffer Size: 35987      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:06:29,301][train][INFO][train.py>_log] ==> #799000     Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 7.419    Value Loss: 7.656    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 840073     Buffer Size: 35613      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:09:49,275][train][INFO][train.py>_log] ==> #800000     Total Loss: 2.929    [weighted Loss:2.929    Policy Loss: 6.729    Value Loss: 7.511    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 841013     Buffer Size: 35262      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:13:09,210][train][INFO][train.py>_log] ==> #801000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 6.687    Value Loss: 7.434    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 841897     Buffer Size: 34891      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:16:32,081][train][INFO][train.py>_log] ==> #802000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 6.882    Value Loss: 7.813    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 842809     Buffer Size: 34437      Transition Number: 1500.090k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:19:48,665][train][INFO][train.py>_log] ==> #803000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 6.953    Value Loss: 7.315    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 843726     Buffer Size: 33871      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:23:10,457][train][INFO][train.py>_log] ==> #804000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 6.368    Value Loss: 7.403    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 844679     Buffer Size: 33400      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:26:34,454][train][INFO][train.py>_log] ==> #805000     Total Loss: 3.377    [weighted Loss:3.377    Policy Loss: 7.273    Value Loss: 7.196    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 845742     Buffer Size: 33199      Transition Number: 1500.102k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:29:54,569][train][INFO][train.py>_log] ==> #806000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 6.528    Value Loss: 7.041    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 846819     Buffer Size: 33037      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:33:15,496][train][INFO][train.py>_log] ==> #807000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 7.528    Value Loss: 7.410    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 848141     Buffer Size: 33092      Transition Number: 1500.073k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:36:36,185][train][INFO][train.py>_log] ==> #808000     Total Loss: 3.141    [weighted Loss:3.141    Policy Loss: 7.607    Value Loss: 7.993    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 849431     Buffer Size: 33154      Transition Number: 1500.057k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:39:56,484][train][INFO][train.py>_log] ==> #809000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 6.959    Value Loss: 7.263    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 850581     Buffer Size: 33027      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:43:15,597][train][INFO][train.py>_log] ==> #810000     Total Loss: 3.285    [weighted Loss:3.285    Policy Loss: 8.025    Value Loss: 7.391    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 851753     Buffer Size: 33031      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:46:37,552][train][INFO][train.py>_log] ==> #811000     Total Loss: 1.425    [weighted Loss:1.425    Policy Loss: 8.251    Value Loss: 7.793    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 852817     Buffer Size: 33035      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:49:58,120][train][INFO][train.py>_log] ==> #812000     Total Loss: 3.448    [weighted Loss:3.448    Policy Loss: 6.583    Value Loss: 7.201    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 853860     Buffer Size: 32878      Transition Number: 1499.999k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:53:18,046][train][INFO][train.py>_log] ==> #813000     Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 6.178    Value Loss: 7.011    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 854991     Buffer Size: 32698      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:56:37,880][train][INFO][train.py>_log] ==> #814000     Total Loss: 1.051    [weighted Loss:1.051    Policy Loss: 6.531    Value Loss: 7.339    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 856106     Buffer Size: 32533      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-08 09:59:57,388][train][INFO][train.py>_log] ==> #815000     Total Loss: 3.518    [weighted Loss:3.518    Policy Loss: 8.698    Value Loss: 7.512    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 857165     Buffer Size: 32382      Transition Number: 1500.145k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:03:17,515][train][INFO][train.py>_log] ==> #816000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 6.787    Value Loss: 7.325    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 858249     Buffer Size: 32265      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:06:38,530][train][INFO][train.py>_log] ==> #817000     Total Loss: 3.841    [weighted Loss:3.841    Policy Loss: 8.417    Value Loss: 7.337    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 859476     Buffer Size: 32385      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:09:58,089][train][INFO][train.py>_log] ==> #818000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 7.753    Value Loss: 7.193    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 860732     Buffer Size: 32410      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:13:20,756][train][INFO][train.py>_log] ==> #819000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 7.677    Value Loss: 7.295    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 862589     Buffer Size: 32811      Transition Number: 1499.959k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:16:42,881][train][INFO][train.py>_log] ==> #820000     Total Loss: 2.490    [weighted Loss:2.490    Policy Loss: 8.754    Value Loss: 7.320    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 864423     Buffer Size: 33158      Transition Number: 1500.061k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:20:02,344][train][INFO][train.py>_log] ==> #821000     Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 7.030    Value Loss: 7.219    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 866000     Buffer Size: 33229      Transition Number: 1500.013k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:23:24,077][train][INFO][train.py>_log] ==> #822000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 7.575    Value Loss: 7.281    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 867632     Buffer Size: 33584      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:26:45,536][train][INFO][train.py>_log] ==> #823000     Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 7.046    Value Loss: 7.321    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 869194     Buffer Size: 33956      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:30:03,915][train][INFO][train.py>_log] ==> #824000     Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 7.243    Value Loss: 7.328    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 870734     Buffer Size: 34442      Transition Number: 1500.016k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:33:22,581][train][INFO][train.py>_log] ==> #825000     Total Loss: 3.286    [weighted Loss:3.286    Policy Loss: 6.560    Value Loss: 7.304    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 871832     Buffer Size: 34599      Transition Number: 1499.965k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:36:40,706][train][INFO][train.py>_log] ==> #826000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 6.563    Value Loss: 7.679    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 872978     Buffer Size: 34795      Transition Number: 1500.030k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:39:59,253][train][INFO][train.py>_log] ==> #827000     Total Loss: 1.950    [weighted Loss:1.950    Policy Loss: 6.290    Value Loss: 7.271    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 873979     Buffer Size: 34865      Transition Number: 1499.957k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:43:16,897][train][INFO][train.py>_log] ==> #828000     Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 5.920    Value Loss: 6.841    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 874957     Buffer Size: 34903      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:46:39,293][train][INFO][train.py>_log] ==> #829000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 7.262    Value Loss: 7.528    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 875908     Buffer Size: 34904      Transition Number: 1500.004k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:50:00,398][train][INFO][train.py>_log] ==> #830000     Total Loss: 2.742    [weighted Loss:2.742    Policy Loss: 7.460    Value Loss: 7.062    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 876919     Buffer Size: 34985      Transition Number: 1499.969k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:53:19,553][train][INFO][train.py>_log] ==> #831000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 7.189    Value Loss: 7.268    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 878086     Buffer Size: 35206      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:56:39,466][train][INFO][train.py>_log] ==> #832000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 7.191    Value Loss: 7.247    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 879246     Buffer Size: 35418      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-08 10:59:59,938][train][INFO][train.py>_log] ==> #833000     Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 7.195    Value Loss: 7.514    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 880299     Buffer Size: 35532      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:03:19,497][train][INFO][train.py>_log] ==> #834000     Total Loss: 2.894    [weighted Loss:2.894    Policy Loss: 7.076    Value Loss: 7.291    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 881357     Buffer Size: 35532      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:06:39,899][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 8.080    Value Loss: 7.544    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 882405     Buffer Size: 35503      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:10:01,221][train][INFO][train.py>_log] ==> #836000     Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 7.534    Value Loss: 7.136    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 883442     Buffer Size: 35283      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:13:19,875][train][INFO][train.py>_log] ==> #837000     Total Loss: 2.350    [weighted Loss:2.350    Policy Loss: 7.526    Value Loss: 7.542    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 884412     Buffer Size: 35026      Transition Number: 1500.023k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:16:39,911][train][INFO][train.py>_log] ==> #838000     Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 7.268    Value Loss: 7.260    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 885373     Buffer Size: 34852      Transition Number: 1500.024k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:19:59,897][train][INFO][train.py>_log] ==> #839000     Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 6.422    Value Loss: 7.493    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 886472     Buffer Size: 34771      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:23:20,953][train][INFO][train.py>_log] ==> #840000     Total Loss: 3.459    [weighted Loss:3.459    Policy Loss: 6.726    Value Loss: 7.258    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 887572     Buffer Size: 34817      Transition Number: 1500.114k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:26:42,897][train][INFO][train.py>_log] ==> #841000     Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 6.659    Value Loss: 7.746    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 888551     Buffer Size: 34790      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:30:02,053][train][INFO][train.py>_log] ==> #842000     Total Loss: 3.387    [weighted Loss:3.387    Policy Loss: 6.277    Value Loss: 7.725    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 889545     Buffer Size: 34670      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:33:20,676][train][INFO][train.py>_log] ==> #843000     Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 7.956    Value Loss: 7.064    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 890459     Buffer Size: 34513      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:36:41,333][train][INFO][train.py>_log] ==> #844000     Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 6.750    Value Loss: 7.471    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 891396     Buffer Size: 34354      Transition Number: 1499.971k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:40:02,534][train][INFO][train.py>_log] ==> #845000     Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 7.598    Value Loss: 7.273    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 892334     Buffer Size: 34225      Transition Number: 1500.008k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:43:20,017][train][INFO][train.py>_log] ==> #846000     Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 6.684    Value Loss: 7.508    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 893259     Buffer Size: 34029      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:46:45,167][train][INFO][train.py>_log] ==> #847000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 7.498    Value Loss: 7.168    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 894233     Buffer Size: 33719      Transition Number: 1499.960k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:50:05,329][train][INFO][train.py>_log] ==> #848000     Total Loss: 3.426    [weighted Loss:3.426    Policy Loss: 8.211    Value Loss: 7.224    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 895168     Buffer Size: 33106      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:53:25,776][train][INFO][train.py>_log] ==> #849000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 7.548    Value Loss: 6.908    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 896197     Buffer Size: 32393      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-08 11:56:48,411][train][INFO][train.py>_log] ==> #850000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 8.301    Value Loss: 7.125    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 897237     Buffer Size: 31786      Transition Number: 1500.034k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:00:12,334][train][INFO][train.py>_log] ==> #851000     Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 8.224    Value Loss: 6.996    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 898600     Buffer Size: 31484      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:03:34,124][train][INFO][train.py>_log] ==> #852000     Total Loss: 2.228    [weighted Loss:2.228    Policy Loss: 7.645    Value Loss: 7.287    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 899943     Buffer Size: 31271      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:06:55,502][train][INFO][train.py>_log] ==> #853000     Total Loss: 1.299    [weighted Loss:1.299    Policy Loss: 7.366    Value Loss: 7.067    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 901369     Buffer Size: 31147      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:10:15,665][train][INFO][train.py>_log] ==> #854000     Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 7.431    Value Loss: 7.078    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 902727     Buffer Size: 31208      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:13:36,455][train][INFO][train.py>_log] ==> #855000     Total Loss: 1.270    [weighted Loss:1.270    Policy Loss: 7.323    Value Loss: 7.406    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 904120     Buffer Size: 31453      Transition Number: 1499.984k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:16:59,694][train][INFO][train.py>_log] ==> #856000     Total Loss: 3.166    [weighted Loss:3.166    Policy Loss: 7.532    Value Loss: 7.091    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 905548     Buffer Size: 31770      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:20:17,547][train][INFO][train.py>_log] ==> #857000     Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 7.138    Value Loss: 7.743    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 906725     Buffer Size: 31973      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:23:37,667][train][INFO][train.py>_log] ==> #858000     Total Loss: 3.128    [weighted Loss:3.128    Policy Loss: 7.291    Value Loss: 7.361    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 907951     Buffer Size: 32185      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:26:58,279][train][INFO][train.py>_log] ==> #859000     Total Loss: 3.654    [weighted Loss:3.654    Policy Loss: 8.361    Value Loss: 7.707    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 909099     Buffer Size: 32338      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:30:18,359][train][INFO][train.py>_log] ==> #860000     Total Loss: 3.157    [weighted Loss:3.157    Policy Loss: 7.835    Value Loss: 7.856    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 910285     Buffer Size: 32363      Transition Number: 1500.220k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:33:38,694][train][INFO][train.py>_log] ==> #861000     Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 7.870    Value Loss: 7.187    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 911407     Buffer Size: 32333      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:36:58,307][train][INFO][train.py>_log] ==> #862000     Total Loss: 1.487    [weighted Loss:1.487    Policy Loss: 7.517    Value Loss: 7.581    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 912550     Buffer Size: 32387      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:40:18,169][train][INFO][train.py>_log] ==> #863000     Total Loss: 1.919    [weighted Loss:1.919    Policy Loss: 7.272    Value Loss: 7.633    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 913498     Buffer Size: 32287      Transition Number: 1499.980k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:43:36,401][train][INFO][train.py>_log] ==> #864000     Total Loss: 2.546    [weighted Loss:2.546    Policy Loss: 7.046    Value Loss: 7.108    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 914477     Buffer Size: 32221      Transition Number: 1499.942k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:46:58,203][train][INFO][train.py>_log] ==> #865000     Total Loss: 3.438    [weighted Loss:3.438    Policy Loss: 6.538    Value Loss: 7.221    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 916259     Buffer Size: 32872      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:50:17,850][train][INFO][train.py>_log] ==> #866000     Total Loss: 3.319    [weighted Loss:3.319    Policy Loss: 7.548    Value Loss: 7.380    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 918043     Buffer Size: 33587      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:53:34,269][train][INFO][train.py>_log] ==> #867000     Total Loss: 0.418    [weighted Loss:0.418    Policy Loss: 7.549    Value Loss: 7.314    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 919233     Buffer Size: 33844      Transition Number: 1499.964k Batch Size: 256        Lr: 0.10000 
[2022-01-08 12:56:53,915][train][INFO][train.py>_log] ==> #868000     Total Loss: 3.127    [weighted Loss:3.127    Policy Loss: 8.033    Value Loss: 7.533    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 920434     Buffer Size: 33978      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:00:13,446][train][INFO][train.py>_log] ==> #869000     Total Loss: 1.311    [weighted Loss:1.311    Policy Loss: 7.266    Value Loss: 7.648    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 921540     Buffer Size: 33984      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:03:37,724][train][INFO][train.py>_log] ==> #870000     Total Loss: 2.882    [weighted Loss:2.882    Policy Loss: 7.097    Value Loss: 7.201    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 922664     Buffer Size: 34067      Transition Number: 1500.075k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:06:58,245][train][INFO][train.py>_log] ==> #871000     Total Loss: 2.882    [weighted Loss:2.882    Policy Loss: 7.580    Value Loss: 7.499    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 923679     Buffer Size: 34084      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:10:17,240][train][INFO][train.py>_log] ==> #872000     Total Loss: 2.735    [weighted Loss:2.735    Policy Loss: 7.777    Value Loss: 7.360    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 924672     Buffer Size: 34149      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:13:36,371][train][INFO][train.py>_log] ==> #873000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 8.312    Value Loss: 7.570    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 925913     Buffer Size: 34437      Transition Number: 1499.982k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:16:55,012][train][INFO][train.py>_log] ==> #874000     Total Loss: 0.986    [weighted Loss:0.986    Policy Loss: 7.336    Value Loss: 7.512    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 927123     Buffer Size: 34696      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:20:13,843][train][INFO][train.py>_log] ==> #875000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 7.876    Value Loss: 7.349    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 928138     Buffer Size: 34759      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:23:32,437][train][INFO][train.py>_log] ==> #876000     Total Loss: 1.593    [weighted Loss:1.593    Policy Loss: 6.877    Value Loss: 7.172    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 929139     Buffer Size: 34825      Transition Number: 1500.147k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:26:52,600][train][INFO][train.py>_log] ==> #877000     Total Loss: 3.700    [weighted Loss:3.700    Policy Loss: 6.779    Value Loss: 7.492    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 930038     Buffer Size: 34811      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:30:12,390][train][INFO][train.py>_log] ==> #878000     Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 8.239    Value Loss: 7.279    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 930983     Buffer Size: 34732      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:33:31,709][train][INFO][train.py>_log] ==> #879000     Total Loss: 3.105    [weighted Loss:3.105    Policy Loss: 7.401    Value Loss: 7.573    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 932303     Buffer Size: 34996      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:36:50,874][train][INFO][train.py>_log] ==> #880000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 8.507    Value Loss: 7.293    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 933650     Buffer Size: 35015      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:40:11,682][train][INFO][train.py>_log] ==> #881000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 7.093    Value Loss: 7.979    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 935303     Buffer Size: 35272      Transition Number: 1500.085k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:43:32,612][train][INFO][train.py>_log] ==> #882000     Total Loss: 2.608    [weighted Loss:2.608    Policy Loss: 8.495    Value Loss: 8.248    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 936998     Buffer Size: 35519      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:46:53,630][train][INFO][train.py>_log] ==> #883000     Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 8.226    Value Loss: 7.681    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 938543     Buffer Size: 35681      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:50:10,988][train][INFO][train.py>_log] ==> #884000     Total Loss: 2.582    [weighted Loss:2.582    Policy Loss: 7.205    Value Loss: 7.444    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 940017     Buffer Size: 35790      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:53:29,734][train][INFO][train.py>_log] ==> #885000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 7.760    Value Loss: 7.620    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 941099     Buffer Size: 35555      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-08 13:56:49,584][train][INFO][train.py>_log] ==> #886000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 7.902    Value Loss: 7.409    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 942196     Buffer Size: 35421      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:00:09,780][train][INFO][train.py>_log] ==> #887000     Total Loss: 3.145    [weighted Loss:3.145    Policy Loss: 7.141    Value Loss: 7.541    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 943776     Buffer Size: 35743      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:03:26,636][train][INFO][train.py>_log] ==> #888000     Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 6.987    Value Loss: 7.654    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 945412     Buffer Size: 36198      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:06:47,755][train][INFO][train.py>_log] ==> #889000     Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 7.161    Value Loss: 7.958    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 946700     Buffer Size: 36345      Transition Number: 1500.094k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:10:06,741][train][INFO][train.py>_log] ==> #890000     Total Loss: 3.088    [weighted Loss:3.088    Policy Loss: 7.506    Value Loss: 7.398    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 947980     Buffer Size: 36497      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:13:24,278][train][INFO][train.py>_log] ==> #891000     Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 7.364    Value Loss: 7.465    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 949143     Buffer Size: 36537      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:16:42,731][train][INFO][train.py>_log] ==> #892000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 6.395    Value Loss: 7.978    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 950366     Buffer Size: 36762      Transition Number: 1500.124k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:20:02,788][train][INFO][train.py>_log] ==> #893000     Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 7.552    Value Loss: 7.688    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 951299     Buffer Size: 36731      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:23:20,244][train][INFO][train.py>_log] ==> #894000     Total Loss: 3.650    [weighted Loss:3.650    Policy Loss: 7.971    Value Loss: 7.567    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 952230     Buffer Size: 36047      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:26:40,787][train][INFO][train.py>_log] ==> #895000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 6.888    Value Loss: 7.260    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 953544     Buffer Size: 35603      Transition Number: 1499.963k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:29:58,502][train][INFO][train.py>_log] ==> #896000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 7.810    Value Loss: 7.343    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 954813     Buffer Size: 35608      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:33:16,249][train][INFO][train.py>_log] ==> #897000     Total Loss: 2.158    [weighted Loss:2.158    Policy Loss: 7.596    Value Loss: 7.537    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 955940     Buffer Size: 35565      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:36:36,934][train][INFO][train.py>_log] ==> #898000     Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 7.244    Value Loss: 7.875    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 957094     Buffer Size: 35610      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:39:55,659][train][INFO][train.py>_log] ==> #899000     Total Loss: 2.081    [weighted Loss:2.081    Policy Loss: 6.532    Value Loss: 7.668    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 958408     Buffer Size: 35825      Transition Number: 1500.020k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:43:15,663][train][INFO][train.py>_log] ==> #900000     Total Loss: 4.811    [weighted Loss:4.811    Policy Loss: 7.319    Value Loss: 7.447    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 959780     Buffer Size: 36137      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:46:34,647][train][INFO][train.py>_log] ==> #901000     Total Loss: 2.682    [weighted Loss:2.682    Policy Loss: 7.339    Value Loss: 7.972    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 961363     Buffer Size: 36688      Transition Number: 1500.048k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:49:51,146][train][INFO][train.py>_log] ==> #902000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 7.078    Value Loss: 7.303    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 962900     Buffer Size: 36998      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:53:09,486][train][INFO][train.py>_log] ==> #903000     Total Loss: 2.890    [weighted Loss:2.890    Policy Loss: 6.896    Value Loss: 7.378    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 964142     Buffer Size: 37026      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:56:29,001][train][INFO][train.py>_log] ==> #904000     Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 6.936    Value Loss: 7.541    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 965421     Buffer Size: 37267      Transition Number: 1500.022k Batch Size: 256        Lr: 0.10000 
[2022-01-08 14:59:45,662][train][INFO][train.py>_log] ==> #905000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 7.927    Value Loss: 7.532    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 966528     Buffer Size: 37378      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:03:04,957][train][INFO][train.py>_log] ==> #906000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 7.797    Value Loss: 7.804    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 967634     Buffer Size: 37544      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:06:22,798][train][INFO][train.py>_log] ==> #907000     Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 7.762    Value Loss: 7.254    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 968921     Buffer Size: 37864      Transition Number: 1499.991k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:09:43,812][train][INFO][train.py>_log] ==> #908000     Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 7.664    Value Loss: 7.560    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 970271     Buffer Size: 37860      Transition Number: 1500.033k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:13:02,218][train][INFO][train.py>_log] ==> #909000     Total Loss: 2.200    [weighted Loss:2.200    Policy Loss: 7.267    Value Loss: 7.841    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 971773     Buffer Size: 38040      Transition Number: 1500.001k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:16:22,171][train][INFO][train.py>_log] ==> #910000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 6.916    Value Loss: 7.778    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 973257     Buffer Size: 37918      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:19:40,225][train][INFO][train.py>_log] ==> #911000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 7.952    Value Loss: 7.684    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 974712     Buffer Size: 37748      Transition Number: 1500.026k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:23:01,740][train][INFO][train.py>_log] ==> #912000     Total Loss: 4.050    [weighted Loss:4.050    Policy Loss: 8.117    Value Loss: 7.608    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 976197     Buffer Size: 37681      Transition Number: 1500.156k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:26:19,628][train][INFO][train.py>_log] ==> #913000     Total Loss: 4.972    [weighted Loss:4.972    Policy Loss: 8.285    Value Loss: 7.713    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 977364     Buffer Size: 37444      Transition Number: 1499.975k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:29:37,970][train][INFO][train.py>_log] ==> #914000     Total Loss: 4.316    [weighted Loss:4.316    Policy Loss: 8.742    Value Loss: 7.884    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 978545     Buffer Size: 37525      Transition Number: 1500.029k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:32:55,172][train][INFO][train.py>_log] ==> #915000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 8.390    Value Loss: 8.520    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 979679     Buffer Size: 37578      Transition Number: 1499.943k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:36:18,695][train][INFO][train.py>_log] ==> #916000     Total Loss: 0.880    [weighted Loss:0.880    Policy Loss: 7.055    Value Loss: 7.597    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 980840     Buffer Size: 37244      Transition Number: 1499.944k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:39:38,713][train][INFO][train.py>_log] ==> #917000     Total Loss: 3.143    [weighted Loss:3.143    Policy Loss: 8.383    Value Loss: 7.829    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 981826     Buffer Size: 36694      Transition Number: 1499.995k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:42:56,325][train][INFO][train.py>_log] ==> #918000     Total Loss: 0.826    [weighted Loss:0.826    Policy Loss: 7.174    Value Loss: 7.895    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 982864     Buffer Size: 36369      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:46:19,258][train][INFO][train.py>_log] ==> #919000     Total Loss: 4.458    [weighted Loss:4.458    Policy Loss: 7.712    Value Loss: 7.812    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 983832     Buffer Size: 36062      Transition Number: 1500.010k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:49:39,162][train][INFO][train.py>_log] ==> #920000     Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 7.020    Value Loss: 7.405    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 984807     Buffer Size: 35826      Transition Number: 1500.009k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:52:57,236][train][INFO][train.py>_log] ==> #921000     Total Loss: 2.320    [weighted Loss:2.320    Policy Loss: 7.547    Value Loss: 7.691    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 985726     Buffer Size: 35595      Transition Number: 1499.970k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:56:19,163][train][INFO][train.py>_log] ==> #922000     Total Loss: 3.973    [weighted Loss:3.973    Policy Loss: 7.270    Value Loss: 7.247    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 986676     Buffer Size: 35538      Transition Number: 1500.182k Batch Size: 256        Lr: 0.10000 
[2022-01-08 15:59:37,883][train][INFO][train.py>_log] ==> #923000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 8.043    Value Loss: 7.801    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 987773     Buffer Size: 35680      Transition Number: 1500.045k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:02:58,043][train][INFO][train.py>_log] ==> #924000     Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 7.437    Value Loss: 7.522    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 988879     Buffer Size: 35576      Transition Number: 1500.036k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:06:16,939][train][INFO][train.py>_log] ==> #925000     Total Loss: 1.271    [weighted Loss:1.271    Policy Loss: 7.656    Value Loss: 7.836    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 990038     Buffer Size: 35436      Transition Number: 1499.961k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:09:38,324][train][INFO][train.py>_log] ==> #926000     Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 7.557    Value Loss: 7.466    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 991219     Buffer Size: 35413      Transition Number: 1500.028k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:12:58,004][train][INFO][train.py>_log] ==> #927000     Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 6.926    Value Loss: 7.930    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 992430     Buffer Size: 35469      Transition Number: 1500.000k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:16:18,951][train][INFO][train.py>_log] ==> #928000     Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 7.115    Value Loss: 7.497    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 993657     Buffer Size: 35391      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:19:36,163][train][INFO][train.py>_log] ==> #929000     Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 7.102    Value Loss: 7.199    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 994510     Buffer Size: 35020      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:22:55,005][train][INFO][train.py>_log] ==> #930000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 6.778    Value Loss: 7.688    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 995389     Buffer Size: 34472      Transition Number: 1500.049k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:26:16,370][train][INFO][train.py>_log] ==> #931000     Total Loss: 3.904    [weighted Loss:3.904    Policy Loss: 7.927    Value Loss: 7.539    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 996266     Buffer Size: 33807      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:29:36,213][train][INFO][train.py>_log] ==> #932000     Total Loss: 2.571    [weighted Loss:2.571    Policy Loss: 7.192    Value Loss: 7.265    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 997146     Buffer Size: 33372      Transition Number: 1499.988k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:32:56,760][train][INFO][train.py>_log] ==> #933000     Total Loss: 3.223    [weighted Loss:3.223    Policy Loss: 6.307    Value Loss: 6.988    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 998113     Buffer Size: 33086      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:36:20,609][train][INFO][train.py>_log] ==> #934000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 6.269    Value Loss: 7.319    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 999082     Buffer Size: 32889      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:39:40,866][train][INFO][train.py>_log] ==> #935000     Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 6.870    Value Loss: 7.656    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000292    Buffer Size: 32983      Transition Number: 1499.978k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:42:57,535][train][INFO][train.py>_log] ==> #936000     Total Loss: 3.302    [weighted Loss:3.302    Policy Loss: 6.715    Value Loss: 7.170    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 1001541    Buffer Size: 33025      Transition Number: 1499.976k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:46:18,311][train][INFO][train.py>_log] ==> #937000     Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 6.643    Value Loss: 7.234    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002588    Buffer Size: 32834      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:49:35,875][train][INFO][train.py>_log] ==> #938000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 7.246    Value Loss: 7.311    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1003616    Buffer Size: 32468      Transition Number: 1499.977k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:52:55,889][train][INFO][train.py>_log] ==> #939000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 7.457    Value Loss: 7.163    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1004574    Buffer Size: 31951      Transition Number: 1500.175k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:56:17,117][train][INFO][train.py>_log] ==> #940000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 6.908    Value Loss: 6.943    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 1005525    Buffer Size: 31487      Transition Number: 1500.047k Batch Size: 256        Lr: 0.10000 
[2022-01-08 16:59:37,497][train][INFO][train.py>_log] ==> #941000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 7.273    Value Loss: 6.961    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 1006472    Buffer Size: 31012      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:02:57,086][train][INFO][train.py>_log] ==> #942000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 6.739    Value Loss: 6.730    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 1007398    Buffer Size: 30650      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:06:17,790][train][INFO][train.py>_log] ==> #943000     Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 7.066    Value Loss: 7.005    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 1008292    Buffer Size: 30335      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:09:39,002][train][INFO][train.py>_log] ==> #944000     Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 8.005    Value Loss: 6.785    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 1009187    Buffer Size: 30062      Transition Number: 1499.983k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:12:59,926][train][INFO][train.py>_log] ==> #945000     Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 7.518    Value Loss: 7.210    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 1010263    Buffer Size: 29980      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:16:22,014][train][INFO][train.py>_log] ==> #946000     Total Loss: 3.205    [weighted Loss:3.205    Policy Loss: 6.827    Value Loss: 6.736    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 1011366    Buffer Size: 29980      Transition Number: 1499.989k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:19:44,110][train][INFO][train.py>_log] ==> #947000     Total Loss: 1.219    [weighted Loss:1.219    Policy Loss: 7.536    Value Loss: 6.835    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 1012369    Buffer Size: 29931      Transition Number: 1499.968k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:23:06,046][train][INFO][train.py>_log] ==> #948000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 7.995    Value Loss: 6.837    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013386    Buffer Size: 29949      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:26:29,902][train][INFO][train.py>_log] ==> #949000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 8.479    Value Loss: 7.122    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 1014438    Buffer Size: 30006      Transition Number: 1499.958k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:29:51,536][train][INFO][train.py>_log] ==> #950000     Total Loss: 3.051    [weighted Loss:3.051    Policy Loss: 8.523    Value Loss: 7.135    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1015451    Buffer Size: 30088      Transition Number: 1500.060k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:33:13,235][train][INFO][train.py>_log] ==> #951000     Total Loss: 0.880    [weighted Loss:0.880    Policy Loss: 8.596    Value Loss: 6.413    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 1016553    Buffer Size: 30219      Transition Number: 1500.178k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:36:36,659][train][INFO][train.py>_log] ==> #952000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 7.797    Value Loss: 6.742    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 1017699    Buffer Size: 30246      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:39:57,089][train][INFO][train.py>_log] ==> #953000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 7.608    Value Loss: 6.617    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 1019054    Buffer Size: 30446      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:43:19,044][train][INFO][train.py>_log] ==> #954000     Total Loss: 1.973    [weighted Loss:1.973    Policy Loss: 8.795    Value Loss: 7.884    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1020384    Buffer Size: 30583      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:46:43,038][train][INFO][train.py>_log] ==> #955000     Total Loss: 1.787    [weighted Loss:1.787    Policy Loss: 7.619    Value Loss: 6.893    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 1021551    Buffer Size: 30553      Transition Number: 1499.946k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:50:04,295][train][INFO][train.py>_log] ==> #956000     Total Loss: 3.395    [weighted Loss:3.395    Policy Loss: 7.412    Value Loss: 6.809    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 1022694    Buffer Size: 30494      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:53:27,633][train][INFO][train.py>_log] ==> #957000     Total Loss: 0.912    [weighted Loss:0.912    Policy Loss: 7.411    Value Loss: 7.099    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 1024051    Buffer Size: 30598      Transition Number: 1499.981k Batch Size: 256        Lr: 0.10000 
[2022-01-08 17:56:50,240][train][INFO][train.py>_log] ==> #958000     Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 7.660    Value Loss: 7.212    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025378    Buffer Size: 30912      Transition Number: 1499.974k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:00:11,245][train][INFO][train.py>_log] ==> #959000     Total Loss: 1.673    [weighted Loss:1.673    Policy Loss: 7.306    Value Loss: 6.739    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 1026667    Buffer Size: 31258      Transition Number: 1499.966k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:03:28,978][train][INFO][train.py>_log] ==> #960000     Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 7.940    Value Loss: 7.373    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 1027908    Buffer Size: 31600      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:06:50,287][train][INFO][train.py>_log] ==> #961000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 7.345    Value Loss: 7.638    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 1029104    Buffer Size: 31902      Transition Number: 1499.996k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:10:10,599][train][INFO][train.py>_log] ==> #962000     Total Loss: 1.106    [weighted Loss:1.106    Policy Loss: 7.598    Value Loss: 6.980    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030298    Buffer Size: 32104      Transition Number: 1500.101k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:13:30,204][train][INFO][train.py>_log] ==> #963000     Total Loss: 1.781    [weighted Loss:1.781    Policy Loss: 9.628    Value Loss: 7.125    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1031549    Buffer Size: 32357      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:16:52,565][train][INFO][train.py>_log] ==> #964000     Total Loss: 2.817    [weighted Loss:2.817    Policy Loss: 7.602    Value Loss: 7.030    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032825    Buffer Size: 32391      Transition Number: 1500.003k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:20:10,761][train][INFO][train.py>_log] ==> #965000     Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 8.735    Value Loss: 7.503    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 1033994    Buffer Size: 32323      Transition Number: 1499.972k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:23:31,321][train][INFO][train.py>_log] ==> #966000     Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 9.493    Value Loss: 7.306    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035168    Buffer Size: 32409      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:26:53,457][train][INFO][train.py>_log] ==> #967000     Total Loss: 0.553    [weighted Loss:0.553    Policy Loss: 9.572    Value Loss: 7.147    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 1036644    Buffer Size: 32821      Transition Number: 1499.949k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:30:12,343][train][INFO][train.py>_log] ==> #968000     Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 7.585    Value Loss: 7.180    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 1038093    Buffer Size: 33303      Transition Number: 1500.039k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:33:33,428][train][INFO][train.py>_log] ==> #969000     Total Loss: 1.571    [weighted Loss:1.571    Policy Loss: 8.545    Value Loss: 7.553    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 1039557    Buffer Size: 33783      Transition Number: 1500.002k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:36:53,180][train][INFO][train.py>_log] ==> #970000     Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 8.857    Value Loss: 7.482    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 1041007    Buffer Size: 34235      Transition Number: 1499.955k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:40:11,137][train][INFO][train.py>_log] ==> #971000     Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 8.187    Value Loss: 7.082    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 1042358    Buffer Size: 34629      Transition Number: 1500.021k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:43:29,113][train][INFO][train.py>_log] ==> #972000     Total Loss: 4.307    [weighted Loss:4.307    Policy Loss: 8.263    Value Loss: 7.312    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043696    Buffer Size: 35056      Transition Number: 1499.997k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:46:46,792][train][INFO][train.py>_log] ==> #973000     Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 8.162    Value Loss: 7.656    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 1044846    Buffer Size: 35300      Transition Number: 1500.007k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:50:07,859][train][INFO][train.py>_log] ==> #974000     Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 8.504    Value Loss: 7.583    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 1046038    Buffer Size: 35395      Transition Number: 1500.011k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:53:28,053][train][INFO][train.py>_log] ==> #975000     Total Loss: 0.860    [weighted Loss:0.860    Policy Loss: 7.764    Value Loss: 7.251    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 1047402    Buffer Size: 35654      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-08 18:56:47,699][train][INFO][train.py>_log] ==> #976000     Total Loss: 2.632    [weighted Loss:2.632    Policy Loss: 8.107    Value Loss: 7.402    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048733    Buffer Size: 35961      Transition Number: 1500.055k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:00:07,506][train][INFO][train.py>_log] ==> #977000     Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 7.514    Value Loss: 7.400    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 1049902    Buffer Size: 36102      Transition Number: 1499.953k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:03:30,325][train][INFO][train.py>_log] ==> #978000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 8.216    Value Loss: 7.376    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 1051114    Buffer Size: 36267      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:06:48,210][train][INFO][train.py>_log] ==> #979000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 7.079    Value Loss: 7.498    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 1052497    Buffer Size: 36536      Transition Number: 1500.051k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:10:06,291][train][INFO][train.py>_log] ==> #980000     Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 7.723    Value Loss: 7.253    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 1053753    Buffer Size: 36720      Transition Number: 1499.973k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:13:26,473][train][INFO][train.py>_log] ==> #981000     Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 6.989    Value Loss: 7.354    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 1054950    Buffer Size: 36743      Transition Number: 1499.941k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:16:46,104][train][INFO][train.py>_log] ==> #982000     Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 7.851    Value Loss: 7.881    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1056129    Buffer Size: 36595      Transition Number: 1499.987k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:20:03,708][train][INFO][train.py>_log] ==> #983000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 7.393    Value Loss: 7.433    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 1057257    Buffer Size: 36454      Transition Number: 1499.948k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:23:24,763][train][INFO][train.py>_log] ==> #984000     Total Loss: 0.868    [weighted Loss:0.868    Policy Loss: 7.333    Value Loss: 7.494    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 1058336    Buffer Size: 36422      Transition Number: 1499.998k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:26:46,080][train][INFO][train.py>_log] ==> #985000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 7.428    Value Loss: 7.377    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 1059647    Buffer Size: 36527      Transition Number: 1499.993k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:30:06,962][train][INFO][train.py>_log] ==> #986000     Total Loss: 3.076    [weighted Loss:3.076    Policy Loss: 7.793    Value Loss: 7.401    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 1060982    Buffer Size: 36489      Transition Number: 1500.019k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:33:25,976][train][INFO][train.py>_log] ==> #987000     Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 8.059    Value Loss: 7.542    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1062247    Buffer Size: 36474      Transition Number: 1500.038k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:36:46,824][train][INFO][train.py>_log] ==> #988000     Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 7.942    Value Loss: 7.441    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063514    Buffer Size: 36490      Transition Number: 1499.939k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:40:06,453][train][INFO][train.py>_log] ==> #989000     Total Loss: 3.423    [weighted Loss:3.423    Policy Loss: 8.255    Value Loss: 7.531    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 1064753    Buffer Size: 36481      Transition Number: 1500.015k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:43:24,891][train][INFO][train.py>_log] ==> #990000     Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 7.500    Value Loss: 7.468    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 1065949    Buffer Size: 36510      Transition Number: 1500.031k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:46:46,001][train][INFO][train.py>_log] ==> #991000     Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 7.341    Value Loss: 7.440    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 1067131    Buffer Size: 36441      Transition Number: 1499.990k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:50:05,101][train][INFO][train.py>_log] ==> #992000     Total Loss: 3.025    [weighted Loss:3.025    Policy Loss: 7.273    Value Loss: 7.246    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 1068276    Buffer Size: 36347      Transition Number: 1499.994k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:53:24,538][train][INFO][train.py>_log] ==> #993000     Total Loss: 1.617    [weighted Loss:1.617    Policy Loss: 7.751    Value Loss: 7.231    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069898    Buffer Size: 36690      Transition Number: 1499.947k Batch Size: 256        Lr: 0.10000 
[2022-01-08 19:56:48,191][train][INFO][train.py>_log] ==> #994000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 7.642    Value Loss: 7.768    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 1071478    Buffer Size: 37071      Transition Number: 1500.105k Batch Size: 256        Lr: 0.10000 
[2022-01-08 20:00:08,161][train][INFO][train.py>_log] ==> #995000     Total Loss: 3.356    [weighted Loss:3.356    Policy Loss: 7.876    Value Loss: 7.828    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1073177    Buffer Size: 37464      Transition Number: 1500.025k Batch Size: 256        Lr: 0.10000 
[2022-01-08 20:03:25,597][train][INFO][train.py>_log] ==> #996000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 7.367    Value Loss: 7.634    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 1074808    Buffer Size: 37630      Transition Number: 1500.061k Batch Size: 256        Lr: 0.10000 
[2022-01-08 20:06:44,936][train][INFO][train.py>_log] ==> #997000     Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 7.633    Value Loss: 7.670    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1077105    Buffer Size: 38474      Transition Number: 1499.985k Batch Size: 256        Lr: 0.10000 
[2022-01-08 20:10:01,926][train][INFO][train.py>_log] ==> #998000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 6.877    Value Loss: 7.228    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 1079400    Buffer Size: 39333      Transition Number: 1500.056k Batch Size: 256        Lr: 0.10000 
[2022-01-08 20:13:18,422][train][INFO][train.py>_log] ==> #999000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 8.056    Value Loss: 7.867    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1081544    Buffer Size: 40058      Transition Number: 1499.979k Batch Size: 256        Lr: 0.10000 
[2022-01-08 20:16:39,288][train][INFO][train.py>_log] ==> #1000000    Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 7.577    Value Loss: 7.616    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1083699    Buffer Size: 40810      Transition Number: 1500.069k Batch Size: 256        Lr: 0.10000 
[2022-01-08 20:19:54,948][train][INFO][train.py>_log] ==> #1001000    Total Loss: 3.014    [weighted Loss:3.014    Policy Loss: 7.557    Value Loss: 7.790    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1085190    Buffer Size: 41051      Transition Number: 1499.949k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:23:11,461][train][INFO][train.py>_log] ==> #1002000    Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 6.330    Value Loss: 6.947    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 1086765    Buffer Size: 41407      Transition Number: 1500.007k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:26:27,202][train][INFO][train.py>_log] ==> #1003000    Total Loss: 1.903    [weighted Loss:1.903    Policy Loss: 5.923    Value Loss: 7.383    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1087672    Buffer Size: 41141      Transition Number: 1499.960k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:29:44,647][train][INFO][train.py>_log] ==> #1004000    Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 5.774    Value Loss: 7.606    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 1088532    Buffer Size: 40790      Transition Number: 1500.034k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:33:05,643][train][INFO][train.py>_log] ==> #1005000    Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 5.318    Value Loss: 7.667    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089326    Buffer Size: 40390      Transition Number: 1499.980k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:36:24,679][train][INFO][train.py>_log] ==> #1006000    Total Loss: 1.401    [weighted Loss:1.401    Policy Loss: 5.534    Value Loss: 7.294    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 1090138    Buffer Size: 40077      Transition Number: 1499.969k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:39:42,148][train][INFO][train.py>_log] ==> #1007000    Total Loss: 0.912    [weighted Loss:0.912    Policy Loss: 5.484    Value Loss: 7.234    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 1090946    Buffer Size: 39729      Transition Number: 1499.960k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:43:02,553][train][INFO][train.py>_log] ==> #1008000    Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 5.411    Value Loss: 6.997    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1091738    Buffer Size: 39273      Transition Number: 1499.994k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:46:21,408][train][INFO][train.py>_log] ==> #1009000    Total Loss: 2.123    [weighted Loss:2.123    Policy Loss: 4.961    Value Loss: 6.994    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092522    Buffer Size: 38851      Transition Number: 1499.952k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:49:39,490][train][INFO][train.py>_log] ==> #1010000    Total Loss: 2.081    [weighted Loss:2.081    Policy Loss: 5.329    Value Loss: 7.039    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 1093317    Buffer Size: 38505      Transition Number: 1499.980k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:53:00,205][train][INFO][train.py>_log] ==> #1011000    Total Loss: 1.013    [weighted Loss:1.013    Policy Loss: 4.996    Value Loss: 7.084    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 1094117    Buffer Size: 38193      Transition Number: 1499.948k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:56:22,027][train][INFO][train.py>_log] ==> #1012000    Total Loss: 2.190    [weighted Loss:2.190    Policy Loss: 5.297    Value Loss: 6.720    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 1094929    Buffer Size: 37906      Transition Number: 1499.968k Batch Size: 256        Lr: 0.01000 
[2022-01-08 20:59:41,470][train][INFO][train.py>_log] ==> #1013000    Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 4.740    Value Loss: 7.040    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 1095720    Buffer Size: 37664      Transition Number: 1499.969k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:03:00,743][train][INFO][train.py>_log] ==> #1014000    Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 5.202    Value Loss: 7.149    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 1096495    Buffer Size: 37292      Transition Number: 1500.052k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:06:22,173][train][INFO][train.py>_log] ==> #1015000    Total Loss: 1.007    [weighted Loss:1.007    Policy Loss: 5.151    Value Loss: 6.846    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 1097312    Buffer Size: 36838      Transition Number: 1499.993k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:09:42,887][train][INFO][train.py>_log] ==> #1016000    Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 4.803    Value Loss: 6.382    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098143    Buffer Size: 36395      Transition Number: 1499.990k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:13:02,841][train][INFO][train.py>_log] ==> #1017000    Total Loss: 0.817    [weighted Loss:0.817    Policy Loss: 4.906    Value Loss: 6.703    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098956    Buffer Size: 35968      Transition Number: 1499.962k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:16:26,748][train][INFO][train.py>_log] ==> #1018000    Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 5.070    Value Loss: 6.743    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 1099773    Buffer Size: 35570      Transition Number: 1500.001k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:19:45,913][train][INFO][train.py>_log] ==> #1019000    Total Loss: 0.819    [weighted Loss:0.819    Policy Loss: 4.622    Value Loss: 6.636    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100584    Buffer Size: 35164      Transition Number: 1499.945k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:23:12,444][train][INFO][train.py>_log] ==> #1020000    Total Loss: 1.937    [weighted Loss:1.937    Policy Loss: 5.216    Value Loss: 6.701    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 1101418    Buffer Size: 34820      Transition Number: 1500.127k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:26:31,655][train][INFO][train.py>_log] ==> #1021000    Total Loss: 1.341    [weighted Loss:1.341    Policy Loss: 4.977    Value Loss: 6.254    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 1102219    Buffer Size: 34501      Transition Number: 1499.942k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:29:51,386][train][INFO][train.py>_log] ==> #1022000    Total Loss: 1.406    [weighted Loss:1.406    Policy Loss: 5.104    Value Loss: 6.428    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103037    Buffer Size: 34007      Transition Number: 1500.155k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:33:12,418][train][INFO][train.py>_log] ==> #1023000    Total Loss: 1.084    [weighted Loss:1.084    Policy Loss: 5.135    Value Loss: 6.139    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103859    Buffer Size: 33263      Transition Number: 1500.000k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:36:35,664][train][INFO][train.py>_log] ==> #1024000    Total Loss: 1.209    [weighted Loss:1.209    Policy Loss: 5.086    Value Loss: 6.122    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 1104694    Buffer Size: 32540      Transition Number: 1500.078k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:39:57,268][train][INFO][train.py>_log] ==> #1025000    Total Loss: 1.135    [weighted Loss:1.135    Policy Loss: 5.073    Value Loss: 6.108    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1105497    Buffer Size: 31741      Transition Number: 1500.005k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:43:18,830][train][INFO][train.py>_log] ==> #1026000    Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 5.292    Value Loss: 6.658    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 1106307    Buffer Size: 30778      Transition Number: 1499.978k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:46:42,972][train][INFO][train.py>_log] ==> #1027000    Total Loss: 0.969    [weighted Loss:0.969    Policy Loss: 5.469    Value Loss: 6.275    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 1107161    Buffer Size: 29318      Transition Number: 1500.096k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:50:03,789][train][INFO][train.py>_log] ==> #1028000    Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 5.374    Value Loss: 6.240    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 1107973    Buffer Size: 27922      Transition Number: 1500.064k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:53:23,543][train][INFO][train.py>_log] ==> #1029000    Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 5.379    Value Loss: 5.720    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 1108824    Buffer Size: 26636      Transition Number: 1499.997k Batch Size: 256        Lr: 0.01000 
[2022-01-08 21:56:47,117][train][INFO][train.py>_log] ==> #1030000    Total Loss: 1.411    [weighted Loss:1.411    Policy Loss: 5.834    Value Loss: 5.449    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 1109646    Buffer Size: 25520      Transition Number: 1500.000k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:00:10,695][train][INFO][train.py>_log] ==> #1031000    Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 6.259    Value Loss: 5.079    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 1110473    Buffer Size: 24859      Transition Number: 1499.996k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:03:32,551][train][INFO][train.py>_log] ==> #1032000    Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 6.410    Value Loss: 4.950    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111317    Buffer Size: 24271      Transition Number: 1499.954k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:06:56,652][train][INFO][train.py>_log] ==> #1033000    Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 6.499    Value Loss: 5.230    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 1112148    Buffer Size: 24169      Transition Number: 1499.937k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:10:21,793][train][INFO][train.py>_log] ==> #1034000    Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 7.157    Value Loss: 5.117    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113008    Buffer Size: 24101      Transition Number: 1499.943k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:13:44,205][train][INFO][train.py>_log] ==> #1035000    Total Loss: 0.353    [weighted Loss:0.353    Policy Loss: 7.279    Value Loss: 4.886    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113864    Buffer Size: 24111      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:17:08,502][train][INFO][train.py>_log] ==> #1036000    Total Loss: 2.316    [weighted Loss:2.316    Policy Loss: 7.945    Value Loss: 5.144    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 1114732    Buffer Size: 24119      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:20:27,391][train][INFO][train.py>_log] ==> #1037000    Total Loss: 0.594    [weighted Loss:0.594    Policy Loss: 7.226    Value Loss: 5.386    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 1115597    Buffer Size: 24155      Transition Number: 1499.943k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:23:50,044][train][INFO][train.py>_log] ==> #1038000    Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 7.606    Value Loss: 5.821    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 1116485    Buffer Size: 24181      Transition Number: 1499.955k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:27:15,151][train][INFO][train.py>_log] ==> #1039000    Total Loss: 0.811    [weighted Loss:0.811    Policy Loss: 8.096    Value Loss: 5.267    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117361    Buffer Size: 24223      Transition Number: 1499.975k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:30:38,524][train][INFO][train.py>_log] ==> #1040000    Total Loss: 3.693    [weighted Loss:3.693    Policy Loss: 8.002    Value Loss: 5.691    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 1118264    Buffer Size: 24253      Transition Number: 1499.974k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:33:59,640][train][INFO][train.py>_log] ==> #1041000    Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 7.916    Value Loss: 5.528    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 1119153    Buffer Size: 24296      Transition Number: 1499.970k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:37:25,072][train][INFO][train.py>_log] ==> #1042000    Total Loss: 1.006    [weighted Loss:1.006    Policy Loss: 8.310    Value Loss: 5.467    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 1120037    Buffer Size: 24344      Transition Number: 1499.959k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:40:48,682][train][INFO][train.py>_log] ==> #1043000    Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 7.900    Value Loss: 5.735    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1120978    Buffer Size: 24431      Transition Number: 1499.969k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:44:11,656][train][INFO][train.py>_log] ==> #1044000    Total Loss: 0.884    [weighted Loss:0.884    Policy Loss: 7.947    Value Loss: 5.408    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 1121908    Buffer Size: 24509      Transition Number: 1499.986k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:47:32,912][train][INFO][train.py>_log] ==> #1045000    Total Loss: 1.931    [weighted Loss:1.931    Policy Loss: 7.637    Value Loss: 6.120    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 1122813    Buffer Size: 24581      Transition Number: 1499.937k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:50:57,038][train][INFO][train.py>_log] ==> #1046000    Total Loss: 1.193    [weighted Loss:1.193    Policy Loss: 7.352    Value Loss: 5.707    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 1123730    Buffer Size: 24658      Transition Number: 1499.958k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:54:20,792][train][INFO][train.py>_log] ==> #1047000    Total Loss: 0.912    [weighted Loss:0.912    Policy Loss: 7.286    Value Loss: 5.616    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 1124620    Buffer Size: 24720      Transition Number: 1500.173k Batch Size: 256        Lr: 0.01000 
[2022-01-08 22:57:41,946][train][INFO][train.py>_log] ==> #1048000    Total Loss: 1.712    [weighted Loss:1.712    Policy Loss: 6.901    Value Loss: 5.268    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 1125501    Buffer Size: 24768      Transition Number: 1499.964k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:01:07,609][train][INFO][train.py>_log] ==> #1049000    Total Loss: 0.587    [weighted Loss:0.587    Policy Loss: 6.774    Value Loss: 5.594    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126366    Buffer Size: 24791      Transition Number: 1499.966k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:04:32,634][train][INFO][train.py>_log] ==> #1050000    Total Loss: 0.541    [weighted Loss:0.541    Policy Loss: 6.535    Value Loss: 5.738    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 1127278    Buffer Size: 24809      Transition Number: 1499.958k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:07:56,839][train][INFO][train.py>_log] ==> #1051000    Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 6.593    Value Loss: 5.324    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128182    Buffer Size: 24834      Transition Number: 1500.143k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:11:20,434][train][INFO][train.py>_log] ==> #1052000    Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 6.537    Value Loss: 5.494    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 1129075    Buffer Size: 24853      Transition Number: 1499.961k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:14:43,526][train][INFO][train.py>_log] ==> #1053000    Total Loss: 0.796    [weighted Loss:0.796    Policy Loss: 6.001    Value Loss: 5.442    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 1129949    Buffer Size: 24866      Transition Number: 1500.025k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:18:06,398][train][INFO][train.py>_log] ==> #1054000    Total Loss: 1.048    [weighted Loss:1.048    Policy Loss: 6.210    Value Loss: 5.820    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 1130818    Buffer Size: 24890      Transition Number: 1499.983k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:21:29,199][train][INFO][train.py>_log] ==> #1055000    Total Loss: 1.803    [weighted Loss:1.803    Policy Loss: 6.558    Value Loss: 5.814    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 1131704    Buffer Size: 24915      Transition Number: 1499.946k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:24:54,429][train][INFO][train.py>_log] ==> #1056000    Total Loss: 2.443    [weighted Loss:2.443    Policy Loss: 6.310    Value Loss: 5.362    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 1132618    Buffer Size: 24934      Transition Number: 1500.012k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:28:18,850][train][INFO][train.py>_log] ==> #1057000    Total Loss: 2.336    [weighted Loss:2.336    Policy Loss: 6.846    Value Loss: 6.044    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133518    Buffer Size: 24954      Transition Number: 1499.977k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:31:42,472][train][INFO][train.py>_log] ==> #1058000    Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 6.289    Value Loss: 6.141    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 1134409    Buffer Size: 24972      Transition Number: 1499.954k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:35:07,600][train][INFO][train.py>_log] ==> #1059000    Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 6.602    Value Loss: 5.975    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135260    Buffer Size: 24994      Transition Number: 1499.969k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:38:30,447][train][INFO][train.py>_log] ==> #1060000    Total Loss: 1.851    [weighted Loss:1.851    Policy Loss: 6.110    Value Loss: 5.410    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 1136129    Buffer Size: 25014      Transition Number: 1500.016k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:41:52,984][train][INFO][train.py>_log] ==> #1061000    Total Loss: 1.466    [weighted Loss:1.466    Policy Loss: 6.454    Value Loss: 5.920    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 1136970    Buffer Size: 25038      Transition Number: 1499.989k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:45:16,466][train][INFO][train.py>_log] ==> #1062000    Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 6.427    Value Loss: 5.579    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 1137888    Buffer Size: 25060      Transition Number: 1499.974k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:48:39,885][train][INFO][train.py>_log] ==> #1063000    Total Loss: 1.399    [weighted Loss:1.399    Policy Loss: 7.029    Value Loss: 5.498    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 1138785    Buffer Size: 25057      Transition Number: 1500.035k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:52:02,896][train][INFO][train.py>_log] ==> #1064000    Total Loss: 1.019    [weighted Loss:1.019    Policy Loss: 6.415    Value Loss: 5.608    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139673    Buffer Size: 25051      Transition Number: 1499.931k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:55:26,836][train][INFO][train.py>_log] ==> #1065000    Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 6.676    Value Loss: 5.820    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 1140573    Buffer Size: 25042      Transition Number: 1500.139k Batch Size: 256        Lr: 0.01000 
[2022-01-08 23:58:49,379][train][INFO][train.py>_log] ==> #1066000    Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 6.499    Value Loss: 5.495    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 1141492    Buffer Size: 25036      Transition Number: 1500.041k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:02:14,029][train][INFO][train.py>_log] ==> #1067000    Total Loss: 1.139    [weighted Loss:1.139    Policy Loss: 6.860    Value Loss: 5.275    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 1142372    Buffer Size: 25019      Transition Number: 1499.940k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:05:38,903][train][INFO][train.py>_log] ==> #1068000    Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 6.495    Value Loss: 5.177    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 1143288    Buffer Size: 25004      Transition Number: 1499.965k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:09:02,493][train][INFO][train.py>_log] ==> #1069000    Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 7.280    Value Loss: 5.933    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144160    Buffer Size: 24982      Transition Number: 1499.985k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:12:25,630][train][INFO][train.py>_log] ==> #1070000    Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 6.515    Value Loss: 5.616    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 1145047    Buffer Size: 24965      Transition Number: 1499.959k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:15:51,539][train][INFO][train.py>_log] ==> #1071000    Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 6.991    Value Loss: 5.684    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 1145948    Buffer Size: 24899      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:19:16,599][train][INFO][train.py>_log] ==> #1072000    Total Loss: 1.506    [weighted Loss:1.506    Policy Loss: 6.998    Value Loss: 5.706    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 1146811    Buffer Size: 24839      Transition Number: 1499.969k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:22:41,078][train][INFO][train.py>_log] ==> #1073000    Total Loss: 0.805    [weighted Loss:0.805    Policy Loss: 6.745    Value Loss: 5.557    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147688    Buffer Size: 24776      Transition Number: 1499.955k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:26:05,411][train][INFO][train.py>_log] ==> #1074000    Total Loss: 1.478    [weighted Loss:1.478    Policy Loss: 6.873    Value Loss: 5.600    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 1148598    Buffer Size: 24723      Transition Number: 1499.938k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:29:29,295][train][INFO][train.py>_log] ==> #1075000    Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 7.263    Value Loss: 5.689    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 1149481    Buffer Size: 24699      Transition Number: 1499.983k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:32:50,921][train][INFO][train.py>_log] ==> #1076000    Total Loss: 2.382    [weighted Loss:2.382    Policy Loss: 7.388    Value Loss: 5.270    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 1150349    Buffer Size: 24686      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:36:15,552][train][INFO][train.py>_log] ==> #1077000    Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 7.639    Value Loss: 5.459    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 1151220    Buffer Size: 24712      Transition Number: 1500.153k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:39:37,135][train][INFO][train.py>_log] ==> #1078000    Total Loss: 2.465    [weighted Loss:2.465    Policy Loss: 7.410    Value Loss: 5.406    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152107    Buffer Size: 24730      Transition Number: 1499.947k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:43:00,772][train][INFO][train.py>_log] ==> #1079000    Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 7.954    Value Loss: 5.640    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 1153004    Buffer Size: 24748      Transition Number: 1499.962k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:46:28,704][train][INFO][train.py>_log] ==> #1080000    Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 7.606    Value Loss: 5.260    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 1153946    Buffer Size: 24767      Transition Number: 1499.945k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:49:53,365][train][INFO][train.py>_log] ==> #1081000    Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 7.762    Value Loss: 5.450    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 1154833    Buffer Size: 24791      Transition Number: 1499.964k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:53:16,304][train][INFO][train.py>_log] ==> #1082000    Total Loss: 1.149    [weighted Loss:1.149    Policy Loss: 7.061    Value Loss: 5.595    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 1155691    Buffer Size: 24810      Transition Number: 1499.963k Batch Size: 256        Lr: 0.01000 
[2022-01-09 00:56:42,664][train][INFO][train.py>_log] ==> #1083000    Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 7.544    Value Loss: 5.671    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 1156680    Buffer Size: 24827      Transition Number: 1499.997k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:00:07,447][train][INFO][train.py>_log] ==> #1084000    Total Loss: 1.168    [weighted Loss:1.168    Policy Loss: 7.148    Value Loss: 5.139    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 1157564    Buffer Size: 24848      Transition Number: 1500.228k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:03:30,366][train][INFO][train.py>_log] ==> #1085000    Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 7.633    Value Loss: 5.716    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 1158448    Buffer Size: 24867      Transition Number: 1500.108k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:06:54,606][train][INFO][train.py>_log] ==> #1086000    Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 7.266    Value Loss: 5.502    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 1159358    Buffer Size: 24888      Transition Number: 1499.968k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:10:16,531][train][INFO][train.py>_log] ==> #1087000    Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 7.791    Value Loss: 5.308    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 1160237    Buffer Size: 24900      Transition Number: 1499.981k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:13:37,860][train][INFO][train.py>_log] ==> #1088000    Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 7.181    Value Loss: 5.321    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 1161149    Buffer Size: 24917      Transition Number: 1499.941k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:17:02,129][train][INFO][train.py>_log] ==> #1089000    Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 7.741    Value Loss: 5.375    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 1162052    Buffer Size: 24941      Transition Number: 1499.962k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:20:26,814][train][INFO][train.py>_log] ==> #1090000    Total Loss: 1.854    [weighted Loss:1.854    Policy Loss: 7.631    Value Loss: 5.538    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 1162987    Buffer Size: 24962      Transition Number: 1499.944k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:23:49,575][train][INFO][train.py>_log] ==> #1091000    Total Loss: 1.253    [weighted Loss:1.253    Policy Loss: 7.496    Value Loss: 6.130    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 1163901    Buffer Size: 24986      Transition Number: 1500.039k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:27:14,325][train][INFO][train.py>_log] ==> #1092000    Total Loss: 1.273    [weighted Loss:1.273    Policy Loss: 7.487    Value Loss: 5.507    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 1164827    Buffer Size: 25013      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:30:39,810][train][INFO][train.py>_log] ==> #1093000    Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 7.991    Value Loss: 5.991    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 1165746    Buffer Size: 25043      Transition Number: 1500.040k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:34:02,221][train][INFO][train.py>_log] ==> #1094000    Total Loss: 0.218    [weighted Loss:0.218    Policy Loss: 7.863    Value Loss: 5.199    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1166666    Buffer Size: 25063      Transition Number: 1499.939k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:37:23,878][train][INFO][train.py>_log] ==> #1095000    Total Loss: 1.236    [weighted Loss:1.236    Policy Loss: 7.874    Value Loss: 6.025    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 1167588    Buffer Size: 25092      Transition Number: 1500.000k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:40:46,311][train][INFO][train.py>_log] ==> #1096000    Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 7.604    Value Loss: 5.546    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 1168521    Buffer Size: 25126      Transition Number: 1500.039k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:44:09,779][train][INFO][train.py>_log] ==> #1097000    Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 8.225    Value Loss: 5.975    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 1169435    Buffer Size: 25141      Transition Number: 1499.941k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:47:33,490][train][INFO][train.py>_log] ==> #1098000    Total Loss: 2.589    [weighted Loss:2.589    Policy Loss: 7.847    Value Loss: 5.914    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 1170385    Buffer Size: 25165      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:50:57,142][train][INFO][train.py>_log] ==> #1099000    Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 7.408    Value Loss: 5.726    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 1171314    Buffer Size: 25185      Transition Number: 1499.993k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:54:21,328][train][INFO][train.py>_log] ==> #1100000    Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 8.089    Value Loss: 5.673    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 1172255    Buffer Size: 25221      Transition Number: 1499.970k Batch Size: 256        Lr: 0.01000 
[2022-01-09 01:57:42,665][train][INFO][train.py>_log] ==> #1101000    Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 7.424    Value Loss: 5.631    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 1173146    Buffer Size: 25253      Transition Number: 1499.971k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:01:05,401][train][INFO][train.py>_log] ==> #1102000    Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 7.772    Value Loss: 5.673    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 1174061    Buffer Size: 25285      Transition Number: 1499.955k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:04:29,797][train][INFO][train.py>_log] ==> #1103000    Total Loss: 0.859    [weighted Loss:0.859    Policy Loss: 6.996    Value Loss: 5.769    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 1175006    Buffer Size: 25317      Transition Number: 1500.085k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:07:53,207][train][INFO][train.py>_log] ==> #1104000    Total Loss: 2.051    [weighted Loss:2.051    Policy Loss: 7.863    Value Loss: 5.569    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 1175934    Buffer Size: 25326      Transition Number: 1499.994k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:11:18,309][train][INFO][train.py>_log] ==> #1105000    Total Loss: 1.281    [weighted Loss:1.281    Policy Loss: 7.757    Value Loss: 5.650    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 1176862    Buffer Size: 25322      Transition Number: 1500.139k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:14:41,768][train][INFO][train.py>_log] ==> #1106000    Total Loss: 1.486    [weighted Loss:1.486    Policy Loss: 7.493    Value Loss: 5.807    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1177793    Buffer Size: 25320      Transition Number: 1499.963k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:18:07,265][train][INFO][train.py>_log] ==> #1107000    Total Loss: 2.606    [weighted Loss:2.606    Policy Loss: 7.693    Value Loss: 5.495    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 1178717    Buffer Size: 25321      Transition Number: 1499.993k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:21:33,146][train][INFO][train.py>_log] ==> #1108000    Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 7.465    Value Loss: 5.596    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 1179666    Buffer Size: 25311      Transition Number: 1500.052k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:24:58,511][train][INFO][train.py>_log] ==> #1109000    Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 7.787    Value Loss: 5.247    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 1180574    Buffer Size: 25326      Transition Number: 1499.996k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:28:22,150][train][INFO][train.py>_log] ==> #1110000    Total Loss: 1.252    [weighted Loss:1.252    Policy Loss: 7.532    Value Loss: 5.636    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 1181541    Buffer Size: 25354      Transition Number: 1500.044k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:31:48,646][train][INFO][train.py>_log] ==> #1111000    Total Loss: 2.149    [weighted Loss:2.149    Policy Loss: 7.427    Value Loss: 5.395    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1182471    Buffer Size: 25389      Transition Number: 1499.966k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:35:13,812][train][INFO][train.py>_log] ==> #1112000    Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 7.813    Value Loss: 5.473    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 1183438    Buffer Size: 25396      Transition Number: 1499.955k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:38:36,564][train][INFO][train.py>_log] ==> #1113000    Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 7.673    Value Loss: 5.372    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 1184355    Buffer Size: 25412      Transition Number: 1500.086k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:42:01,021][train][INFO][train.py>_log] ==> #1114000    Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 7.679    Value Loss: 5.685    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 1185272    Buffer Size: 25431      Transition Number: 1499.945k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:45:24,814][train][INFO][train.py>_log] ==> #1115000    Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 7.556    Value Loss: 5.261    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1186224    Buffer Size: 25471      Transition Number: 1499.963k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:48:46,609][train][INFO][train.py>_log] ==> #1116000    Total Loss: 1.435    [weighted Loss:1.435    Policy Loss: 8.189    Value Loss: 5.430    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 1187187    Buffer Size: 25499      Transition Number: 1499.943k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:52:13,620][train][INFO][train.py>_log] ==> #1117000    Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 8.299    Value Loss: 5.580    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 1188148    Buffer Size: 25528      Transition Number: 1500.116k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:55:37,034][train][INFO][train.py>_log] ==> #1118000    Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 7.736    Value Loss: 5.809    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 1189101    Buffer Size: 25550      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 02:59:00,992][train][INFO][train.py>_log] ==> #1119000    Total Loss: 3.063    [weighted Loss:3.063    Policy Loss: 8.435    Value Loss: 6.422    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 1190063    Buffer Size: 25617      Transition Number: 1499.957k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:02:24,054][train][INFO][train.py>_log] ==> #1120000    Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 8.179    Value Loss: 5.719    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1191067    Buffer Size: 25662      Transition Number: 1499.964k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:05:49,673][train][INFO][train.py>_log] ==> #1121000    Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 8.699    Value Loss: 5.812    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 1192043    Buffer Size: 25698      Transition Number: 1500.117k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:09:10,309][train][INFO][train.py>_log] ==> #1122000    Total Loss: 1.903    [weighted Loss:1.903    Policy Loss: 8.136    Value Loss: 5.888    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 1193025    Buffer Size: 25742      Transition Number: 1499.951k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:12:32,694][train][INFO][train.py>_log] ==> #1123000    Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 7.760    Value Loss: 5.914    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 1194002    Buffer Size: 25791      Transition Number: 1500.056k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:15:57,998][train][INFO][train.py>_log] ==> #1124000    Total Loss: 1.173    [weighted Loss:1.173    Policy Loss: 7.664    Value Loss: 6.180    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1194980    Buffer Size: 25845      Transition Number: 1499.956k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:19:22,826][train][INFO][train.py>_log] ==> #1125000    Total Loss: 0.897    [weighted Loss:0.897    Policy Loss: 8.565    Value Loss: 5.874    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 1195954    Buffer Size: 25871      Transition Number: 1499.980k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:22:47,382][train][INFO][train.py>_log] ==> #1126000    Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 7.779    Value Loss: 6.003    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 1196932    Buffer Size: 25897      Transition Number: 1499.982k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:26:11,616][train][INFO][train.py>_log] ==> #1127000    Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 7.117    Value Loss: 6.135    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 1197874    Buffer Size: 25918      Transition Number: 1499.975k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:29:36,318][train][INFO][train.py>_log] ==> #1128000    Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 7.465    Value Loss: 5.410    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 1198801    Buffer Size: 25922      Transition Number: 1499.951k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:32:59,488][train][INFO][train.py>_log] ==> #1129000    Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 7.419    Value Loss: 6.192    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 1199695    Buffer Size: 25926      Transition Number: 1499.938k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:36:23,561][train][INFO][train.py>_log] ==> #1130000    Total Loss: 2.076    [weighted Loss:2.076    Policy Loss: 7.471    Value Loss: 6.439    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1200653    Buffer Size: 25937      Transition Number: 1500.056k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:39:47,593][train][INFO][train.py>_log] ==> #1131000    Total Loss: 1.720    [weighted Loss:1.720    Policy Loss: 7.011    Value Loss: 5.676    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 1201600    Buffer Size: 25939      Transition Number: 1500.031k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:43:11,767][train][INFO][train.py>_log] ==> #1132000    Total Loss: 0.946    [weighted Loss:0.946    Policy Loss: 7.191    Value Loss: 6.373    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 1202504    Buffer Size: 25964      Transition Number: 1499.998k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:46:38,270][train][INFO][train.py>_log] ==> #1133000    Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 7.008    Value Loss: 6.017    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 1203412    Buffer Size: 25979      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:50:03,245][train][INFO][train.py>_log] ==> #1134000    Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 8.019    Value Loss: 6.091    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 1204332    Buffer Size: 25999      Transition Number: 1499.991k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:53:27,309][train][INFO][train.py>_log] ==> #1135000    Total Loss: 1.781    [weighted Loss:1.781    Policy Loss: 7.621    Value Loss: 5.490    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1205271    Buffer Size: 26038      Transition Number: 1499.990k Batch Size: 256        Lr: 0.01000 
[2022-01-09 03:56:53,640][train][INFO][train.py>_log] ==> #1136000    Total Loss: 1.467    [weighted Loss:1.467    Policy Loss: 7.881    Value Loss: 5.678    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 1206254    Buffer Size: 26074      Transition Number: 1499.991k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:00:18,627][train][INFO][train.py>_log] ==> #1137000    Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 7.521    Value Loss: 5.750    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 1207171    Buffer Size: 26068      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:03:41,125][train][INFO][train.py>_log] ==> #1138000    Total Loss: 2.959    [weighted Loss:2.959    Policy Loss: 7.438    Value Loss: 5.918    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 1208088    Buffer Size: 26052      Transition Number: 1499.996k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:07:04,903][train][INFO][train.py>_log] ==> #1139000    Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 7.416    Value Loss: 6.346    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 1209002    Buffer Size: 26045      Transition Number: 1499.998k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:10:28,065][train][INFO][train.py>_log] ==> #1140000    Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 7.448    Value Loss: 5.725    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 1209894    Buffer Size: 26031      Transition Number: 1499.985k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:13:49,758][train][INFO][train.py>_log] ==> #1141000    Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 7.487    Value Loss: 6.169    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 1210786    Buffer Size: 26019      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:17:15,052][train][INFO][train.py>_log] ==> #1142000    Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 7.478    Value Loss: 5.759    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 1211672    Buffer Size: 25992      Transition Number: 1499.951k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:20:40,164][train][INFO][train.py>_log] ==> #1143000    Total Loss: 1.170    [weighted Loss:1.170    Policy Loss: 7.536    Value Loss: 6.156    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 1212543    Buffer Size: 25934      Transition Number: 1499.959k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:24:03,921][train][INFO][train.py>_log] ==> #1144000    Total Loss: 2.340    [weighted Loss:2.340    Policy Loss: 7.825    Value Loss: 5.858    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 1213446    Buffer Size: 25889      Transition Number: 1500.053k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:27:29,041][train][INFO][train.py>_log] ==> #1145000    Total Loss: 0.532    [weighted Loss:0.532    Policy Loss: 7.256    Value Loss: 6.198    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 1214369    Buffer Size: 25810      Transition Number: 1499.972k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:30:52,263][train][INFO][train.py>_log] ==> #1146000    Total Loss: 2.071    [weighted Loss:2.071    Policy Loss: 7.570    Value Loss: 5.348    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 1215284    Buffer Size: 25729      Transition Number: 1500.004k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:34:17,182][train][INFO][train.py>_log] ==> #1147000    Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 8.039    Value Loss: 5.695    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216150    Buffer Size: 25620      Transition Number: 1500.145k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:37:39,142][train][INFO][train.py>_log] ==> #1148000    Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 7.538    Value Loss: 5.803    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 1217048    Buffer Size: 25525      Transition Number: 1500.060k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:41:03,223][train][INFO][train.py>_log] ==> #1149000    Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 8.099    Value Loss: 5.848    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 1217942    Buffer Size: 25436      Transition Number: 1500.192k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:44:27,470][train][INFO][train.py>_log] ==> #1150000    Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 7.485    Value Loss: 5.504    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218829    Buffer Size: 25333      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:47:50,640][train][INFO][train.py>_log] ==> #1151000    Total Loss: 0.958    [weighted Loss:0.958    Policy Loss: 7.335    Value Loss: 5.807    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 1219708    Buffer Size: 25239      Transition Number: 1499.970k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:51:14,597][train][INFO][train.py>_log] ==> #1152000    Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 7.537    Value Loss: 5.597    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 1220597    Buffer Size: 25165      Transition Number: 1499.963k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:54:39,947][train][INFO][train.py>_log] ==> #1153000    Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 7.680    Value Loss: 5.525    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 1221511    Buffer Size: 25079      Transition Number: 1499.957k Batch Size: 256        Lr: 0.01000 
[2022-01-09 04:58:02,734][train][INFO][train.py>_log] ==> #1154000    Total Loss: 2.339    [weighted Loss:2.339    Policy Loss: 7.562    Value Loss: 5.262    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 1222409    Buffer Size: 25009      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:01:26,431][train][INFO][train.py>_log] ==> #1155000    Total Loss: 1.838    [weighted Loss:1.838    Policy Loss: 7.819    Value Loss: 5.989    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223285    Buffer Size: 24951      Transition Number: 1499.947k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:04:53,672][train][INFO][train.py>_log] ==> #1156000    Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 7.675    Value Loss: 5.354    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 1224169    Buffer Size: 24899      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:08:18,016][train][INFO][train.py>_log] ==> #1157000    Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 7.343    Value Loss: 5.958    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225050    Buffer Size: 24848      Transition Number: 1500.046k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:11:41,289][train][INFO][train.py>_log] ==> #1158000    Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 7.973    Value Loss: 5.332    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225951    Buffer Size: 24783      Transition Number: 1499.991k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:15:06,565][train][INFO][train.py>_log] ==> #1159000    Total Loss: 1.782    [weighted Loss:1.782    Policy Loss: 8.296    Value Loss: 5.808    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 1226880    Buffer Size: 24734      Transition Number: 1499.978k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:18:32,255][train][INFO][train.py>_log] ==> #1160000    Total Loss: 1.296    [weighted Loss:1.296    Policy Loss: 7.855    Value Loss: 5.205    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1227816    Buffer Size: 24700      Transition Number: 1500.117k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:21:57,143][train][INFO][train.py>_log] ==> #1161000    Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 8.281    Value Loss: 5.816    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 1228721    Buffer Size: 24672      Transition Number: 1499.944k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:25:20,794][train][INFO][train.py>_log] ==> #1162000    Total Loss: 2.623    [weighted Loss:2.623    Policy Loss: 7.846    Value Loss: 4.922    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 1229626    Buffer Size: 24643      Transition Number: 1499.947k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:28:45,739][train][INFO][train.py>_log] ==> #1163000    Total Loss: 1.373    [weighted Loss:1.373    Policy Loss: 8.425    Value Loss: 5.075    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 1230547    Buffer Size: 24584      Transition Number: 1499.935k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:32:10,941][train][INFO][train.py>_log] ==> #1164000    Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 8.160    Value Loss: 5.351    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 1231467    Buffer Size: 24561      Transition Number: 1499.957k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:35:35,288][train][INFO][train.py>_log] ==> #1165000    Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 8.129    Value Loss: 6.080    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1232365    Buffer Size: 24531      Transition Number: 1500.053k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:38:59,998][train][INFO][train.py>_log] ==> #1166000    Total Loss: 2.416    [weighted Loss:2.416    Policy Loss: 7.987    Value Loss: 5.169    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 1233284    Buffer Size: 24516      Transition Number: 1500.184k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:42:23,713][train][INFO][train.py>_log] ==> #1167000    Total Loss: 0.864    [weighted Loss:0.864    Policy Loss: 8.667    Value Loss: 5.132    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 1234169    Buffer Size: 24494      Transition Number: 1499.964k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:45:48,968][train][INFO][train.py>_log] ==> #1168000    Total Loss: 1.671    [weighted Loss:1.671    Policy Loss: 8.257    Value Loss: 4.952    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 1235098    Buffer Size: 24474      Transition Number: 1499.950k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:49:14,415][train][INFO][train.py>_log] ==> #1169000    Total Loss: 3.470    [weighted Loss:3.470    Policy Loss: 8.605    Value Loss: 4.922    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236031    Buffer Size: 24492      Transition Number: 1499.971k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:52:38,647][train][INFO][train.py>_log] ==> #1170000    Total Loss: 1.430    [weighted Loss:1.430    Policy Loss: 8.292    Value Loss: 5.697    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236972    Buffer Size: 24523      Transition Number: 1500.246k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:56:03,395][train][INFO][train.py>_log] ==> #1171000    Total Loss: 1.203    [weighted Loss:1.203    Policy Loss: 8.899    Value Loss: 5.465    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 1237910    Buffer Size: 24567      Transition Number: 1499.964k Batch Size: 256        Lr: 0.01000 
[2022-01-09 05:59:27,247][train][INFO][train.py>_log] ==> #1172000    Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 8.497    Value Loss: 5.854    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 1238850    Buffer Size: 24626      Transition Number: 1500.057k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:02:52,262][train][INFO][train.py>_log] ==> #1173000    Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 8.663    Value Loss: 5.160    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 1239819    Buffer Size: 24672      Transition Number: 1499.977k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:06:16,815][train][INFO][train.py>_log] ==> #1174000    Total Loss: 0.806    [weighted Loss:0.806    Policy Loss: 8.534    Value Loss: 5.564    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 1240773    Buffer Size: 24736      Transition Number: 1499.959k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:09:40,188][train][INFO][train.py>_log] ==> #1175000    Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 9.034    Value Loss: 5.717    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241727    Buffer Size: 24782      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:13:03,128][train][INFO][train.py>_log] ==> #1176000    Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 8.494    Value Loss: 5.302    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 1242632    Buffer Size: 24809      Transition Number: 1499.987k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:16:27,838][train][INFO][train.py>_log] ==> #1177000    Total Loss: 1.785    [weighted Loss:1.785    Policy Loss: 8.494    Value Loss: 5.469    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1243530    Buffer Size: 24830      Transition Number: 1499.951k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:19:51,599][train][INFO][train.py>_log] ==> #1178000    Total Loss: 0.899    [weighted Loss:0.899    Policy Loss: 8.395    Value Loss: 5.367    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 1244465    Buffer Size: 24837      Transition Number: 1500.118k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:23:16,534][train][INFO][train.py>_log] ==> #1179000    Total Loss: 2.800    [weighted Loss:2.800    Policy Loss: 8.683    Value Loss: 5.281    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1245402    Buffer Size: 24838      Transition Number: 1500.109k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:26:38,782][train][INFO][train.py>_log] ==> #1180000    Total Loss: 1.488    [weighted Loss:1.488    Policy Loss: 8.211    Value Loss: 5.280    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 1246326    Buffer Size: 24857      Transition Number: 1500.030k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:30:02,197][train][INFO][train.py>_log] ==> #1181000    Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 8.667    Value Loss: 5.467    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 1247243    Buffer Size: 24885      Transition Number: 1499.964k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:33:26,704][train][INFO][train.py>_log] ==> #1182000    Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 8.437    Value Loss: 5.543    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 1248145    Buffer Size: 24901      Transition Number: 1499.949k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:36:52,834][train][INFO][train.py>_log] ==> #1183000    Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 8.409    Value Loss: 5.728    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 1249051    Buffer Size: 24928      Transition Number: 1499.973k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:40:17,034][train][INFO][train.py>_log] ==> #1184000    Total Loss: 0.344    [weighted Loss:0.344    Policy Loss: 7.704    Value Loss: 5.225    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 1250020    Buffer Size: 24963      Transition Number: 1499.996k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:43:41,000][train][INFO][train.py>_log] ==> #1185000    Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 7.809    Value Loss: 5.527    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 1250937    Buffer Size: 24990      Transition Number: 1500.037k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:47:05,345][train][INFO][train.py>_log] ==> #1186000    Total Loss: 1.304    [weighted Loss:1.304    Policy Loss: 8.091    Value Loss: 5.277    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 1251888    Buffer Size: 25005      Transition Number: 1499.971k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:50:29,490][train][INFO][train.py>_log] ==> #1187000    Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 8.621    Value Loss: 5.451    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252835    Buffer Size: 25019      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:53:56,759][train][INFO][train.py>_log] ==> #1188000    Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 8.388    Value Loss: 5.715    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 1253806    Buffer Size: 25044      Transition Number: 1500.044k Batch Size: 256        Lr: 0.01000 
[2022-01-09 06:57:22,536][train][INFO][train.py>_log] ==> #1189000    Total Loss: 0.501    [weighted Loss:0.501    Policy Loss: 8.225    Value Loss: 5.289    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 1254734    Buffer Size: 25069      Transition Number: 1499.986k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:00:47,209][train][INFO][train.py>_log] ==> #1190000    Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 8.722    Value Loss: 5.423    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1255707    Buffer Size: 25116      Transition Number: 1500.218k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:04:14,536][train][INFO][train.py>_log] ==> #1191000    Total Loss: 0.756    [weighted Loss:0.756    Policy Loss: 7.980    Value Loss: 5.693    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 1256654    Buffer Size: 25129      Transition Number: 1500.066k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:07:39,921][train][INFO][train.py>_log] ==> #1192000    Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 7.641    Value Loss: 6.152    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 1257633    Buffer Size: 25147      Transition Number: 1500.057k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:11:03,898][train][INFO][train.py>_log] ==> #1193000    Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 7.772    Value Loss: 5.745    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 1258576    Buffer Size: 25151      Transition Number: 1499.949k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:14:29,030][train][INFO][train.py>_log] ==> #1194000    Total Loss: 3.122    [weighted Loss:3.122    Policy Loss: 7.666    Value Loss: 5.637    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 1259494    Buffer Size: 25161      Transition Number: 1499.945k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:17:53,870][train][INFO][train.py>_log] ==> #1195000    Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 7.819    Value Loss: 5.635    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 1260425    Buffer Size: 25184      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:21:18,460][train][INFO][train.py>_log] ==> #1196000    Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 8.257    Value Loss: 5.496    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 1261369    Buffer Size: 25168      Transition Number: 1499.985k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:24:43,239][train][INFO][train.py>_log] ==> #1197000    Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 8.126    Value Loss: 5.997    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 1262264    Buffer Size: 25152      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:28:08,011][train][INFO][train.py>_log] ==> #1198000    Total Loss: 2.879    [weighted Loss:2.879    Policy Loss: 8.073    Value Loss: 5.569    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 1263223    Buffer Size: 25112      Transition Number: 1499.980k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:31:32,463][train][INFO][train.py>_log] ==> #1199000    Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 7.352    Value Loss: 6.311    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 1264155    Buffer Size: 25081      Transition Number: 1500.000k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:34:55,880][train][INFO][train.py>_log] ==> #1200000    Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 8.279    Value Loss: 5.748    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 1265065    Buffer Size: 25060      Transition Number: 1499.976k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:38:19,498][train][INFO][train.py>_log] ==> #1201000    Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 8.267    Value Loss: 5.514    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 1265972    Buffer Size: 25042      Transition Number: 1499.954k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:41:42,586][train][INFO][train.py>_log] ==> #1202000    Total Loss: 2.626    [weighted Loss:2.626    Policy Loss: 8.048    Value Loss: 5.633    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266896    Buffer Size: 25025      Transition Number: 1500.154k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:45:05,546][train][INFO][train.py>_log] ==> #1203000    Total Loss: 1.085    [weighted Loss:1.085    Policy Loss: 7.974    Value Loss: 5.302    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 1267881    Buffer Size: 25044      Transition Number: 1499.977k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:48:29,074][train][INFO][train.py>_log] ==> #1204000    Total Loss: 1.830    [weighted Loss:1.830    Policy Loss: 7.562    Value Loss: 5.532    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 1268836    Buffer Size: 25071      Transition Number: 1499.972k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:51:54,583][train][INFO][train.py>_log] ==> #1205000    Total Loss: 1.098    [weighted Loss:1.098    Policy Loss: 8.325    Value Loss: 5.513    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 1269741    Buffer Size: 25089      Transition Number: 1500.037k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:55:19,721][train][INFO][train.py>_log] ==> #1206000    Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 8.539    Value Loss: 5.822    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 1270686    Buffer Size: 25102      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 07:58:43,029][train][INFO][train.py>_log] ==> #1207000    Total Loss: 1.058    [weighted Loss:1.058    Policy Loss: 8.255    Value Loss: 5.537    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 1271580    Buffer Size: 25095      Transition Number: 1500.069k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:02:09,405][train][INFO][train.py>_log] ==> #1208000    Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 8.631    Value Loss: 5.483    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 1272531    Buffer Size: 25096      Transition Number: 1499.947k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:05:35,050][train][INFO][train.py>_log] ==> #1209000    Total Loss: 1.329    [weighted Loss:1.329    Policy Loss: 7.717    Value Loss: 5.484    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 1273467    Buffer Size: 25091      Transition Number: 1499.968k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:08:59,442][train][INFO][train.py>_log] ==> #1210000    Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 7.680    Value Loss: 5.680    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 1274388    Buffer Size: 25079      Transition Number: 1499.970k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:12:25,178][train][INFO][train.py>_log] ==> #1211000    Total Loss: 1.589    [weighted Loss:1.589    Policy Loss: 7.634    Value Loss: 5.310    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 1275348    Buffer Size: 25069      Transition Number: 1499.966k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:15:49,879][train][INFO][train.py>_log] ==> #1212000    Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 8.007    Value Loss: 5.394    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 1276289    Buffer Size: 25065      Transition Number: 1499.950k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:19:15,359][train][INFO][train.py>_log] ==> #1213000    Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 8.293    Value Loss: 5.455    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 1277215    Buffer Size: 25076      Transition Number: 1499.961k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:22:40,272][train][INFO][train.py>_log] ==> #1214000    Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 8.567    Value Loss: 5.098    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 1278151    Buffer Size: 25085      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:26:04,553][train][INFO][train.py>_log] ==> #1215000    Total Loss: 1.613    [weighted Loss:1.613    Policy Loss: 8.355    Value Loss: 4.993    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 1279053    Buffer Size: 25065      Transition Number: 1499.962k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:29:27,786][train][INFO][train.py>_log] ==> #1216000    Total Loss: 1.340    [weighted Loss:1.340    Policy Loss: 8.298    Value Loss: 5.584    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1279993    Buffer Size: 25049      Transition Number: 1500.039k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:32:53,110][train][INFO][train.py>_log] ==> #1217000    Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 8.832    Value Loss: 5.178    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 1280937    Buffer Size: 25018      Transition Number: 1500.036k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:36:18,559][train][INFO][train.py>_log] ==> #1218000    Total Loss: 1.202    [weighted Loss:1.202    Policy Loss: 8.949    Value Loss: 5.435    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 1281890    Buffer Size: 24987      Transition Number: 1499.957k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:39:42,587][train][INFO][train.py>_log] ==> #1219000    Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 8.464    Value Loss: 5.071    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 1282792    Buffer Size: 24973      Transition Number: 1499.955k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:43:05,882][train][INFO][train.py>_log] ==> #1220000    Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 9.269    Value Loss: 5.452    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 1283700    Buffer Size: 24972      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:46:34,645][train][INFO][train.py>_log] ==> #1221000    Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 8.672    Value Loss: 6.067    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 1284631    Buffer Size: 24961      Transition Number: 1500.019k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:49:59,483][train][INFO][train.py>_log] ==> #1222000    Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 8.670    Value Loss: 5.858    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1285583    Buffer Size: 24947      Transition Number: 1499.990k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:53:24,637][train][INFO][train.py>_log] ==> #1223000    Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 9.052    Value Loss: 5.404    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 1286496    Buffer Size: 24944      Transition Number: 1499.979k Batch Size: 256        Lr: 0.01000 
[2022-01-09 08:56:51,351][train][INFO][train.py>_log] ==> #1224000    Total Loss: 1.543    [weighted Loss:1.543    Policy Loss: 8.787    Value Loss: 5.381    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 1287463    Buffer Size: 24941      Transition Number: 1499.978k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:00:18,188][train][INFO][train.py>_log] ==> #1225000    Total Loss: 1.306    [weighted Loss:1.306    Policy Loss: 9.289    Value Loss: 5.520    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 1288386    Buffer Size: 24942      Transition Number: 1500.161k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:03:42,772][train][INFO][train.py>_log] ==> #1226000    Total Loss: 1.433    [weighted Loss:1.433    Policy Loss: 9.015    Value Loss: 5.621    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 1289311    Buffer Size: 24951      Transition Number: 1500.040k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:07:09,773][train][INFO][train.py>_log] ==> #1227000    Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 9.229    Value Loss: 6.117    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 1290278    Buffer Size: 24948      Transition Number: 1499.958k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:10:32,928][train][INFO][train.py>_log] ==> #1228000    Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 8.274    Value Loss: 5.631    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 1291216    Buffer Size: 24942      Transition Number: 1500.036k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:13:59,440][train][INFO][train.py>_log] ==> #1229000    Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 9.140    Value Loss: 5.196    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 1292162    Buffer Size: 24944      Transition Number: 1499.982k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:17:26,764][train][INFO][train.py>_log] ==> #1230000    Total Loss: 1.133    [weighted Loss:1.133    Policy Loss: 9.011    Value Loss: 5.904    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 1293128    Buffer Size: 24914      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:20:51,431][train][INFO][train.py>_log] ==> #1231000    Total Loss: 1.687    [weighted Loss:1.687    Policy Loss: 9.110    Value Loss: 5.815    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 1294212    Buffer Size: 25014      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:24:15,693][train][INFO][train.py>_log] ==> #1232000    Total Loss: 0.737    [weighted Loss:0.737    Policy Loss: 9.162    Value Loss: 6.047    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 1295265    Buffer Size: 25141      Transition Number: 1499.981k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:27:39,069][train][INFO][train.py>_log] ==> #1233000    Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 8.402    Value Loss: 6.429    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 1296204    Buffer Size: 25181      Transition Number: 1500.088k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:31:02,166][train][INFO][train.py>_log] ==> #1234000    Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 9.086    Value Loss: 5.685    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 1297157    Buffer Size: 25229      Transition Number: 1499.983k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:34:26,909][train][INFO][train.py>_log] ==> #1235000    Total Loss: 1.549    [weighted Loss:1.549    Policy Loss: 9.126    Value Loss: 5.624    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 1298061    Buffer Size: 25238      Transition Number: 1499.977k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:37:50,297][train][INFO][train.py>_log] ==> #1236000    Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 8.898    Value Loss: 6.020    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299009    Buffer Size: 25252      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:41:14,360][train][INFO][train.py>_log] ==> #1237000    Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 9.115    Value Loss: 5.614    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299943    Buffer Size: 25256      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:44:40,424][train][INFO][train.py>_log] ==> #1238000    Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 8.805    Value Loss: 5.489    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 1300863    Buffer Size: 25258      Transition Number: 1499.990k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:48:06,723][train][INFO][train.py>_log] ==> #1239000    Total Loss: 2.090    [weighted Loss:2.090    Policy Loss: 8.312    Value Loss: 5.724    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 1301813    Buffer Size: 25273      Transition Number: 1499.981k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:51:30,139][train][INFO][train.py>_log] ==> #1240000    Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 8.130    Value Loss: 5.630    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 1302744    Buffer Size: 25272      Transition Number: 1500.195k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:54:57,141][train][INFO][train.py>_log] ==> #1241000    Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 8.637    Value Loss: 6.152    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 1303737    Buffer Size: 25286      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-09 09:58:23,088][train][INFO][train.py>_log] ==> #1242000    Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 8.155    Value Loss: 5.316    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304694    Buffer Size: 25312      Transition Number: 1500.243k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:01:46,889][train][INFO][train.py>_log] ==> #1243000    Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 8.761    Value Loss: 6.071    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 1305657    Buffer Size: 25326      Transition Number: 1499.994k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:05:11,767][train][INFO][train.py>_log] ==> #1244000    Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 8.316    Value Loss: 5.882    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 1306591    Buffer Size: 25355      Transition Number: 1499.941k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:08:35,245][train][INFO][train.py>_log] ==> #1245000    Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 8.672    Value Loss: 6.164    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 1307545    Buffer Size: 25407      Transition Number: 1499.946k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:11:58,024][train][INFO][train.py>_log] ==> #1246000    Total Loss: 3.244    [weighted Loss:3.244    Policy Loss: 8.258    Value Loss: 5.702    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 1308480    Buffer Size: 25446      Transition Number: 1500.064k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:15:23,293][train][INFO][train.py>_log] ==> #1247000    Total Loss: 1.852    [weighted Loss:1.852    Policy Loss: 8.400    Value Loss: 5.854    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 1309426    Buffer Size: 25485      Transition Number: 1499.979k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:18:45,174][train][INFO][train.py>_log] ==> #1248000    Total Loss: 1.266    [weighted Loss:1.266    Policy Loss: 8.278    Value Loss: 5.660    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 1310381    Buffer Size: 25534      Transition Number: 1499.958k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:22:08,549][train][INFO][train.py>_log] ==> #1249000    Total Loss: 1.550    [weighted Loss:1.550    Policy Loss: 9.070    Value Loss: 5.706    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 1311319    Buffer Size: 25575      Transition Number: 1499.990k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:25:32,751][train][INFO][train.py>_log] ==> #1250000    Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 8.219    Value Loss: 6.008    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1312303    Buffer Size: 25615      Transition Number: 1499.997k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:28:58,173][train][INFO][train.py>_log] ==> #1251000    Total Loss: 1.452    [weighted Loss:1.452    Policy Loss: 8.344    Value Loss: 5.796    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 1313292    Buffer Size: 25656      Transition Number: 1499.968k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:32:21,533][train][INFO][train.py>_log] ==> #1252000    Total Loss: 1.543    [weighted Loss:1.543    Policy Loss: 8.455    Value Loss: 5.811    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 1314248    Buffer Size: 25714      Transition Number: 1499.958k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:35:45,243][train][INFO][train.py>_log] ==> #1253000    Total Loss: 1.696    [weighted Loss:1.696    Policy Loss: 8.841    Value Loss: 5.975    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 1315230    Buffer Size: 25798      Transition Number: 1500.000k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:39:08,091][train][INFO][train.py>_log] ==> #1254000    Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 8.967    Value Loss: 5.901    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 1316254    Buffer Size: 25899      Transition Number: 1499.982k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:42:32,022][train][INFO][train.py>_log] ==> #1255000    Total Loss: 1.542    [weighted Loss:1.542    Policy Loss: 8.881    Value Loss: 6.113    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 1317271    Buffer Size: 25984      Transition Number: 1500.004k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:45:57,862][train][INFO][train.py>_log] ==> #1256000    Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 9.045    Value Loss: 5.885    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 1318300    Buffer Size: 26063      Transition Number: 1500.007k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:49:20,919][train][INFO][train.py>_log] ==> #1257000    Total Loss: 1.251    [weighted Loss:1.251    Policy Loss: 8.292    Value Loss: 6.508    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 1319287    Buffer Size: 26122      Transition Number: 1499.976k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:52:43,945][train][INFO][train.py>_log] ==> #1258000    Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 8.238    Value Loss: 5.799    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 1320274    Buffer Size: 26065      Transition Number: 1499.991k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:56:10,522][train][INFO][train.py>_log] ==> #1259000    Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 8.185    Value Loss: 6.040    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 1321223    Buffer Size: 25969      Transition Number: 1499.952k Batch Size: 256        Lr: 0.01000 
[2022-01-09 10:59:35,399][train][INFO][train.py>_log] ==> #1260000    Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 8.502    Value Loss: 6.176    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 1322185    Buffer Size: 25957      Transition Number: 1499.948k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:03:02,984][train][INFO][train.py>_log] ==> #1261000    Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 8.233    Value Loss: 6.131    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 1323126    Buffer Size: 25921      Transition Number: 1499.976k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:06:29,512][train][INFO][train.py>_log] ==> #1262000    Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 8.116    Value Loss: 5.914    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 1324079    Buffer Size: 25933      Transition Number: 1499.952k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:09:54,601][train][INFO][train.py>_log] ==> #1263000    Total Loss: 0.973    [weighted Loss:0.973    Policy Loss: 8.025    Value Loss: 5.973    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 1325036    Buffer Size: 25934      Transition Number: 1499.985k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:13:19,151][train][INFO][train.py>_log] ==> #1264000    Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 7.724    Value Loss: 5.982    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 1325941    Buffer Size: 25949      Transition Number: 1499.979k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:16:44,613][train][INFO][train.py>_log] ==> #1265000    Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 8.283    Value Loss: 5.791    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 1326877    Buffer Size: 25959      Transition Number: 1499.987k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:20:07,959][train][INFO][train.py>_log] ==> #1266000    Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 7.883    Value Loss: 6.117    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1327807    Buffer Size: 25952      Transition Number: 1499.941k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:23:33,687][train][INFO][train.py>_log] ==> #1267000    Total Loss: 0.560    [weighted Loss:0.560    Policy Loss: 8.244    Value Loss: 6.169    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 1328794    Buffer Size: 25967      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:26:59,571][train][INFO][train.py>_log] ==> #1268000    Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 8.290    Value Loss: 5.698    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 1329729    Buffer Size: 25954      Transition Number: 1500.036k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:30:24,538][train][INFO][train.py>_log] ==> #1269000    Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 7.809    Value Loss: 5.818    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 1330685    Buffer Size: 25967      Transition Number: 1500.232k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:33:49,586][train][INFO][train.py>_log] ==> #1270000    Total Loss: 1.997    [weighted Loss:1.997    Policy Loss: 7.751    Value Loss: 6.122    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 1331638    Buffer Size: 25987      Transition Number: 1499.997k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:37:14,263][train][INFO][train.py>_log] ==> #1271000    Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 7.707    Value Loss: 6.108    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332610    Buffer Size: 26013      Transition Number: 1499.996k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:40:37,496][train][INFO][train.py>_log] ==> #1272000    Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 8.223    Value Loss: 5.758    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 1333582    Buffer Size: 26017      Transition Number: 1499.980k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:44:00,642][train][INFO][train.py>_log] ==> #1273000    Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 7.494    Value Loss: 5.724    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 1334546    Buffer Size: 26043      Transition Number: 1499.951k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:47:25,877][train][INFO][train.py>_log] ==> #1274000    Total Loss: 2.891    [weighted Loss:2.891    Policy Loss: 8.353    Value Loss: 5.828    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 1335527    Buffer Size: 26050      Transition Number: 1500.011k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:50:48,768][train][INFO][train.py>_log] ==> #1275000    Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 8.134    Value Loss: 6.165    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 1336501    Buffer Size: 26047      Transition Number: 1499.973k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:54:13,183][train][INFO][train.py>_log] ==> #1276000    Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 8.170    Value Loss: 5.998    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1337464    Buffer Size: 26050      Transition Number: 1499.966k Batch Size: 256        Lr: 0.01000 
[2022-01-09 11:57:36,191][train][INFO][train.py>_log] ==> #1277000    Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 8.119    Value Loss: 6.114    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 1338402    Buffer Size: 26050      Transition Number: 1499.952k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:01:00,404][train][INFO][train.py>_log] ==> #1278000    Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 7.720    Value Loss: 5.910    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 1339344    Buffer Size: 26030      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:04:25,750][train][INFO][train.py>_log] ==> #1279000    Total Loss: 2.666    [weighted Loss:2.666    Policy Loss: 8.191    Value Loss: 6.026    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 1340267    Buffer Size: 26016      Transition Number: 1500.170k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:07:48,052][train][INFO][train.py>_log] ==> #1280000    Total Loss: 2.165    [weighted Loss:2.165    Policy Loss: 8.275    Value Loss: 5.907    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 1341202    Buffer Size: 25969      Transition Number: 1499.970k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:11:11,995][train][INFO][train.py>_log] ==> #1281000    Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 7.424    Value Loss: 5.917    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 1342177    Buffer Size: 25943      Transition Number: 1499.944k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:14:35,486][train][INFO][train.py>_log] ==> #1282000    Total Loss: 1.410    [weighted Loss:1.410    Policy Loss: 7.968    Value Loss: 6.204    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 1343196    Buffer Size: 25945      Transition Number: 1499.963k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:18:00,546][train][INFO][train.py>_log] ==> #1283000    Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 7.565    Value Loss: 5.980    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 1344164    Buffer Size: 25920      Transition Number: 1500.015k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:21:24,218][train][INFO][train.py>_log] ==> #1284000    Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 7.951    Value Loss: 5.537    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1345121    Buffer Size: 25925      Transition Number: 1499.989k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:24:49,070][train][INFO][train.py>_log] ==> #1285000    Total Loss: 2.707    [weighted Loss:2.707    Policy Loss: 8.048    Value Loss: 5.599    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 1346109    Buffer Size: 25950      Transition Number: 1499.961k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:28:13,120][train][INFO][train.py>_log] ==> #1286000    Total Loss: 0.876    [weighted Loss:0.876    Policy Loss: 7.733    Value Loss: 6.611    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 1347106    Buffer Size: 25990      Transition Number: 1499.994k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:31:36,396][train][INFO][train.py>_log] ==> #1287000    Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 8.203    Value Loss: 5.918    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1348169    Buffer Size: 26087      Transition Number: 1500.028k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:35:00,810][train][INFO][train.py>_log] ==> #1288000    Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 7.850    Value Loss: 6.141    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1349207    Buffer Size: 26205      Transition Number: 1499.952k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:38:23,159][train][INFO][train.py>_log] ==> #1289000    Total Loss: 1.548    [weighted Loss:1.548    Policy Loss: 8.304    Value Loss: 6.280    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350217    Buffer Size: 26306      Transition Number: 1499.940k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:41:48,245][train][INFO][train.py>_log] ==> #1290000    Total Loss: 3.406    [weighted Loss:3.406    Policy Loss: 8.346    Value Loss: 6.605    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 1351249    Buffer Size: 26420      Transition Number: 1499.957k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:45:10,714][train][INFO][train.py>_log] ==> #1291000    Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 7.833    Value Loss: 6.128    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 1352360    Buffer Size: 26609      Transition Number: 1500.068k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:48:32,907][train][INFO][train.py>_log] ==> #1292000    Total Loss: 2.125    [weighted Loss:2.125    Policy Loss: 8.150    Value Loss: 6.529    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 1353453    Buffer Size: 26783      Transition Number: 1499.958k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:51:54,733][train][INFO][train.py>_log] ==> #1293000    Total Loss: 1.746    [weighted Loss:1.746    Policy Loss: 8.095    Value Loss: 6.585    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 1354462    Buffer Size: 26895      Transition Number: 1500.028k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:55:17,909][train][INFO][train.py>_log] ==> #1294000    Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 7.613    Value Loss: 6.484    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 1355531    Buffer Size: 27031      Transition Number: 1499.956k Batch Size: 256        Lr: 0.01000 
[2022-01-09 12:58:40,724][train][INFO][train.py>_log] ==> #1295000    Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 7.907    Value Loss: 6.593    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 1356539    Buffer Size: 27136      Transition Number: 1499.973k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:02:05,314][train][INFO][train.py>_log] ==> #1296000    Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 7.811    Value Loss: 6.386    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 1357557    Buffer Size: 27224      Transition Number: 1499.971k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:05:26,621][train][INFO][train.py>_log] ==> #1297000    Total Loss: 0.924    [weighted Loss:0.924    Policy Loss: 7.912    Value Loss: 6.647    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 1358517    Buffer Size: 27277      Transition Number: 1499.994k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:08:52,668][train][INFO][train.py>_log] ==> #1298000    Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 7.322    Value Loss: 6.515    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 1359527    Buffer Size: 27334      Transition Number: 1499.983k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:12:14,845][train][INFO][train.py>_log] ==> #1299000    Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 7.665    Value Loss: 6.926    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 1360568    Buffer Size: 27439      Transition Number: 1500.044k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:15:38,492][train][INFO][train.py>_log] ==> #1300000    Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 7.555    Value Loss: 6.793    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1361608    Buffer Size: 27513      Transition Number: 1500.037k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:19:02,475][train][INFO][train.py>_log] ==> #1301000    Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 7.386    Value Loss: 7.002    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 1362662    Buffer Size: 27637      Transition Number: 1499.996k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:22:24,294][train][INFO][train.py>_log] ==> #1302000    Total Loss: 0.965    [weighted Loss:0.965    Policy Loss: 7.481    Value Loss: 6.954    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 1363699    Buffer Size: 27743      Transition Number: 1499.974k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:25:47,480][train][INFO][train.py>_log] ==> #1303000    Total Loss: 0.774    [weighted Loss:0.774    Policy Loss: 7.010    Value Loss: 6.436    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 1364720    Buffer Size: 27818      Transition Number: 1499.960k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:29:11,050][train][INFO][train.py>_log] ==> #1304000    Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 7.422    Value Loss: 7.147    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 1365732    Buffer Size: 27911      Transition Number: 1499.948k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:32:31,576][train][INFO][train.py>_log] ==> #1305000    Total Loss: 3.111    [weighted Loss:3.111    Policy Loss: 7.153    Value Loss: 6.607    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 1366669    Buffer Size: 27969      Transition Number: 1499.975k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:35:54,034][train][INFO][train.py>_log] ==> #1306000    Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 7.045    Value Loss: 6.282    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 1367628    Buffer Size: 28021      Transition Number: 1499.944k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:39:16,472][train][INFO][train.py>_log] ==> #1307000    Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 7.696    Value Loss: 6.770    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1368670    Buffer Size: 28134      Transition Number: 1499.984k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:42:38,400][train][INFO][train.py>_log] ==> #1308000    Total Loss: 2.305    [weighted Loss:2.305    Policy Loss: 7.061    Value Loss: 6.783    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1369713    Buffer Size: 28241      Transition Number: 1499.968k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:46:00,648][train][INFO][train.py>_log] ==> #1309000    Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 7.533    Value Loss: 7.091    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370697    Buffer Size: 28287      Transition Number: 1499.952k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:49:24,506][train][INFO][train.py>_log] ==> #1310000    Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 7.464    Value Loss: 7.034    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 1371679    Buffer Size: 28311      Transition Number: 1499.984k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:52:46,193][train][INFO][train.py>_log] ==> #1311000    Total Loss: 1.158    [weighted Loss:1.158    Policy Loss: 7.118    Value Loss: 6.822    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 1372665    Buffer Size: 28361      Transition Number: 1499.972k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:56:08,135][train][INFO][train.py>_log] ==> #1312000    Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 7.274    Value Loss: 6.588    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373622    Buffer Size: 28410      Transition Number: 1500.174k Batch Size: 256        Lr: 0.01000 
[2022-01-09 13:59:32,053][train][INFO][train.py>_log] ==> #1313000    Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 7.547    Value Loss: 6.689    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 1374596    Buffer Size: 28417      Transition Number: 1500.184k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:02:53,646][train][INFO][train.py>_log] ==> #1314000    Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 7.190    Value Loss: 6.956    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375540    Buffer Size: 28421      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:06:15,984][train][INFO][train.py>_log] ==> #1315000    Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 7.229    Value Loss: 6.672    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1376460    Buffer Size: 28353      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:09:38,010][train][INFO][train.py>_log] ==> #1316000    Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 7.271    Value Loss: 7.380    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1377390    Buffer Size: 28266      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:12:59,019][train][INFO][train.py>_log] ==> #1317000    Total Loss: 3.660    [weighted Loss:3.660    Policy Loss: 7.046    Value Loss: 7.084    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 1378292    Buffer Size: 28190      Transition Number: 1499.978k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:16:23,833][train][INFO][train.py>_log] ==> #1318000    Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 6.702    Value Loss: 7.149    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 1379213    Buffer Size: 28104      Transition Number: 1499.946k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:19:45,273][train][INFO][train.py>_log] ==> #1319000    Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 7.564    Value Loss: 7.028    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 1380146    Buffer Size: 27976      Transition Number: 1499.945k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:23:07,324][train][INFO][train.py>_log] ==> #1320000    Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 7.258    Value Loss: 6.954    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 1381059    Buffer Size: 27837      Transition Number: 1500.090k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:26:31,805][train][INFO][train.py>_log] ==> #1321000    Total Loss: 1.138    [weighted Loss:1.138    Policy Loss: 7.535    Value Loss: 7.527    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 1381970    Buffer Size: 27760      Transition Number: 1499.975k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:29:55,415][train][INFO][train.py>_log] ==> #1322000    Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 7.658    Value Loss: 7.004    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 1382912    Buffer Size: 27687      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:33:19,106][train][INFO][train.py>_log] ==> #1323000    Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 7.687    Value Loss: 6.692    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 1383924    Buffer Size: 27669      Transition Number: 1500.019k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:36:44,454][train][INFO][train.py>_log] ==> #1324000    Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 8.358    Value Loss: 7.389    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 1384922    Buffer Size: 27664      Transition Number: 1500.006k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:40:05,389][train][INFO][train.py>_log] ==> #1325000    Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 8.531    Value Loss: 7.183    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 1386178    Buffer Size: 27912      Transition Number: 1500.056k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:43:30,066][train][INFO][train.py>_log] ==> #1326000    Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 8.506    Value Loss: 7.116    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 1387475    Buffer Size: 28157      Transition Number: 1499.957k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:46:53,203][train][INFO][train.py>_log] ==> #1327000    Total Loss: 1.859    [weighted Loss:1.859    Policy Loss: 8.613    Value Loss: 7.120    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 1388708    Buffer Size: 28335      Transition Number: 1499.955k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:50:13,923][train][INFO][train.py>_log] ==> #1328000    Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 7.644    Value Loss: 6.682    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 1389941    Buffer Size: 28518      Transition Number: 1499.986k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:53:37,923][train][INFO][train.py>_log] ==> #1329000    Total Loss: 1.158    [weighted Loss:1.158    Policy Loss: 8.452    Value Loss: 7.538    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1391110    Buffer Size: 28661      Transition Number: 1499.987k Batch Size: 256        Lr: 0.01000 
[2022-01-09 14:57:01,898][train][INFO][train.py>_log] ==> #1330000    Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 8.040    Value Loss: 7.687    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1392300    Buffer Size: 28764      Transition Number: 1500.179k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:00:25,079][train][INFO][train.py>_log] ==> #1331000    Total Loss: 1.597    [weighted Loss:1.597    Policy Loss: 8.250    Value Loss: 7.078    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1393410    Buffer Size: 28835      Transition Number: 1500.033k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:03:47,029][train][INFO][train.py>_log] ==> #1332000    Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 8.397    Value Loss: 7.348    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1394476    Buffer Size: 28918      Transition Number: 1499.960k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:07:10,774][train][INFO][train.py>_log] ==> #1333000    Total Loss: 2.326    [weighted Loss:2.326    Policy Loss: 8.176    Value Loss: 7.276    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1395680    Buffer Size: 29106      Transition Number: 1499.946k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:10:32,337][train][INFO][train.py>_log] ==> #1334000    Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 8.097    Value Loss: 6.820    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1396859    Buffer Size: 29293      Transition Number: 1499.990k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:13:55,293][train][INFO][train.py>_log] ==> #1335000    Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 7.998    Value Loss: 7.461    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 1398077    Buffer Size: 29455      Transition Number: 1499.984k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:17:17,522][train][INFO][train.py>_log] ==> #1336000    Total Loss: 1.537    [weighted Loss:1.537    Policy Loss: 7.395    Value Loss: 7.038    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 1399282    Buffer Size: 29593      Transition Number: 1500.051k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:20:40,339][train][INFO][train.py>_log] ==> #1337000    Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 7.735    Value Loss: 7.571    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 1400474    Buffer Size: 29790      Transition Number: 1499.962k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:24:01,339][train][INFO][train.py>_log] ==> #1338000    Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 7.483    Value Loss: 7.204    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 1401670    Buffer Size: 29983      Transition Number: 1499.998k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:27:25,199][train][INFO][train.py>_log] ==> #1339000    Total Loss: 3.592    [weighted Loss:3.592    Policy Loss: 7.471    Value Loss: 7.271    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1402782    Buffer Size: 30097      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:30:45,996][train][INFO][train.py>_log] ==> #1340000    Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 7.032    Value Loss: 7.580    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1403852    Buffer Size: 30198      Transition Number: 1499.973k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:34:09,235][train][INFO][train.py>_log] ==> #1341000    Total Loss: 2.032    [weighted Loss:2.032    Policy Loss: 6.940    Value Loss: 7.345    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 1404812    Buffer Size: 30208      Transition Number: 1500.130k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:37:30,883][train][INFO][train.py>_log] ==> #1342000    Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 6.893    Value Loss: 7.291    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 1405759    Buffer Size: 30220      Transition Number: 1499.969k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:40:53,984][train][INFO][train.py>_log] ==> #1343000    Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 7.228    Value Loss: 7.234    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406689    Buffer Size: 30252      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:44:17,059][train][INFO][train.py>_log] ==> #1344000    Total Loss: 1.387    [weighted Loss:1.387    Policy Loss: 6.761    Value Loss: 7.576    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 1407600    Buffer Size: 30267      Transition Number: 1499.973k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:47:35,334][train][INFO][train.py>_log] ==> #1345000    Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 7.054    Value Loss: 7.308    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 1408521    Buffer Size: 30312      Transition Number: 1500.008k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:50:55,832][train][INFO][train.py>_log] ==> #1346000    Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 7.170    Value Loss: 7.606    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1409405    Buffer Size: 30344      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:54:17,472][train][INFO][train.py>_log] ==> #1347000    Total Loss: 3.703    [weighted Loss:3.703    Policy Loss: 6.894    Value Loss: 7.080    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1410325    Buffer Size: 30368      Transition Number: 1499.945k Batch Size: 256        Lr: 0.01000 
[2022-01-09 15:57:39,429][train][INFO][train.py>_log] ==> #1348000    Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 6.788    Value Loss: 6.943    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411244    Buffer Size: 30386      Transition Number: 1500.027k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:01:02,222][train][INFO][train.py>_log] ==> #1349000    Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 6.472    Value Loss: 6.888    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 1412138    Buffer Size: 30372      Transition Number: 1500.040k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:04:25,965][train][INFO][train.py>_log] ==> #1350000    Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 6.491    Value Loss: 7.082    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 1413029    Buffer Size: 30347      Transition Number: 1499.965k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:07:49,729][train][INFO][train.py>_log] ==> #1351000    Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 6.396    Value Loss: 7.357    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 1413910    Buffer Size: 30277      Transition Number: 1499.984k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:11:13,629][train][INFO][train.py>_log] ==> #1352000    Total Loss: 1.298    [weighted Loss:1.298    Policy Loss: 6.193    Value Loss: 7.124    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 1414808    Buffer Size: 30197      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:14:37,448][train][INFO][train.py>_log] ==> #1353000    Total Loss: 2.292    [weighted Loss:2.292    Policy Loss: 6.080    Value Loss: 7.085    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 1415710    Buffer Size: 29985      Transition Number: 1499.978k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:18:00,473][train][INFO][train.py>_log] ==> #1354000    Total Loss: 2.658    [weighted Loss:2.658    Policy Loss: 6.492    Value Loss: 7.242    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 1416606    Buffer Size: 29696      Transition Number: 1499.993k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:21:23,141][train][INFO][train.py>_log] ==> #1355000    Total Loss: 1.221    [weighted Loss:1.221    Policy Loss: 6.380    Value Loss: 7.205    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 1417581    Buffer Size: 29467      Transition Number: 1500.007k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:24:45,737][train][INFO][train.py>_log] ==> #1356000    Total Loss: 2.817    [weighted Loss:2.817    Policy Loss: 6.580    Value Loss: 7.065    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 1418529    Buffer Size: 29233      Transition Number: 1500.053k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:28:07,829][train][INFO][train.py>_log] ==> #1357000    Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 6.315    Value Loss: 6.468    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 1419476    Buffer Size: 29025      Transition Number: 1500.052k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:31:30,766][train][INFO][train.py>_log] ==> #1358000    Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 6.939    Value Loss: 6.779    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 1420406    Buffer Size: 28836      Transition Number: 1499.990k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:34:54,264][train][INFO][train.py>_log] ==> #1359000    Total Loss: 1.683    [weighted Loss:1.683    Policy Loss: 6.446    Value Loss: 6.551    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 1421340    Buffer Size: 28679      Transition Number: 1499.985k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:38:16,030][train][INFO][train.py>_log] ==> #1360000    Total Loss: 1.720    [weighted Loss:1.720    Policy Loss: 7.174    Value Loss: 6.693    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 1422241    Buffer Size: 28555      Transition Number: 1499.972k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:41:38,500][train][INFO][train.py>_log] ==> #1361000    Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 7.020    Value Loss: 7.343    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1423167    Buffer Size: 28417      Transition Number: 1499.951k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:45:00,467][train][INFO][train.py>_log] ==> #1362000    Total Loss: 0.972    [weighted Loss:0.972    Policy Loss: 6.830    Value Loss: 7.340    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424073    Buffer Size: 28217      Transition Number: 1499.961k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:48:24,226][train][INFO][train.py>_log] ==> #1363000    Total Loss: 1.363    [weighted Loss:1.363    Policy Loss: 6.450    Value Loss: 6.787    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424986    Buffer Size: 28019      Transition Number: 1499.960k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:51:45,986][train][INFO][train.py>_log] ==> #1364000    Total Loss: 2.130    [weighted Loss:2.130    Policy Loss: 6.872    Value Loss: 6.965    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1425903    Buffer Size: 27774      Transition Number: 1499.990k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:55:11,280][train][INFO][train.py>_log] ==> #1365000    Total Loss: 1.251    [weighted Loss:1.251    Policy Loss: 7.034    Value Loss: 6.820    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1426807    Buffer Size: 27547      Transition Number: 1499.989k Batch Size: 256        Lr: 0.01000 
[2022-01-09 16:58:33,832][train][INFO][train.py>_log] ==> #1366000    Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 7.227    Value Loss: 6.389    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1427711    Buffer Size: 27271      Transition Number: 1499.991k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:01:55,857][train][INFO][train.py>_log] ==> #1367000    Total Loss: 2.933    [weighted Loss:2.933    Policy Loss: 7.113    Value Loss: 6.712    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 1428614    Buffer Size: 27040      Transition Number: 1499.965k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:05:19,853][train][INFO][train.py>_log] ==> #1368000    Total Loss: 2.330    [weighted Loss:2.330    Policy Loss: 7.831    Value Loss: 6.846    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 1429514    Buffer Size: 26859      Transition Number: 1499.945k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:08:45,151][train][INFO][train.py>_log] ==> #1369000    Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 7.415    Value Loss: 5.962    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 1430445    Buffer Size: 26733      Transition Number: 1500.004k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:12:08,656][train][INFO][train.py>_log] ==> #1370000    Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 7.908    Value Loss: 6.350    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 1431397    Buffer Size: 26698      Transition Number: 1500.109k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:15:34,173][train][INFO][train.py>_log] ==> #1371000    Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 7.367    Value Loss: 6.843    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 1432348    Buffer Size: 26676      Transition Number: 1500.154k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:18:58,924][train][INFO][train.py>_log] ==> #1372000    Total Loss: 2.826    [weighted Loss:2.826    Policy Loss: 8.091    Value Loss: 6.594    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 1433273    Buffer Size: 26668      Transition Number: 1499.951k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:22:24,605][train][INFO][train.py>_log] ==> #1373000    Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 8.061    Value Loss: 6.313    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 1434276    Buffer Size: 26729      Transition Number: 1499.982k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:25:47,406][train][INFO][train.py>_log] ==> #1374000    Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 7.697    Value Loss: 6.644    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435230    Buffer Size: 26745      Transition Number: 1500.095k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:29:10,673][train][INFO][train.py>_log] ==> #1375000    Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 7.321    Value Loss: 6.410    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 1436194    Buffer Size: 26761      Transition Number: 1499.985k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:32:36,192][train][INFO][train.py>_log] ==> #1376000    Total Loss: 1.741    [weighted Loss:1.741    Policy Loss: 7.655    Value Loss: 6.749    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 1437170    Buffer Size: 26773      Transition Number: 1499.984k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:36:03,036][train][INFO][train.py>_log] ==> #1377000    Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 7.624    Value Loss: 6.457    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 1438110    Buffer Size: 26773      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:39:26,473][train][INFO][train.py>_log] ==> #1378000    Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 7.443    Value Loss: 6.320    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 1439052    Buffer Size: 26786      Transition Number: 1499.979k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:42:51,238][train][INFO][train.py>_log] ==> #1379000    Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 7.465    Value Loss: 6.652    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 1439951    Buffer Size: 26804      Transition Number: 1499.986k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:46:14,762][train][INFO][train.py>_log] ==> #1380000    Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 7.133    Value Loss: 6.575    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440879    Buffer Size: 26833      Transition Number: 1499.984k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:49:37,736][train][INFO][train.py>_log] ==> #1381000    Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 7.598    Value Loss: 6.656    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1441780    Buffer Size: 26827      Transition Number: 1499.949k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:53:01,515][train][INFO][train.py>_log] ==> #1382000    Total Loss: 0.705    [weighted Loss:0.705    Policy Loss: 7.010    Value Loss: 6.123    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 1442688    Buffer Size: 26810      Transition Number: 1499.968k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:56:27,273][train][INFO][train.py>_log] ==> #1383000    Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 7.534    Value Loss: 5.967    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 1443607    Buffer Size: 26790      Transition Number: 1500.068k Batch Size: 256        Lr: 0.01000 
[2022-01-09 17:59:49,596][train][INFO][train.py>_log] ==> #1384000    Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 7.357    Value Loss: 6.072    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 1444499    Buffer Size: 26706      Transition Number: 1500.129k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:03:14,250][train][INFO][train.py>_log] ==> #1385000    Total Loss: 1.857    [weighted Loss:1.857    Policy Loss: 7.844    Value Loss: 6.255    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 1445385    Buffer Size: 26630      Transition Number: 1499.987k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:06:40,795][train][INFO][train.py>_log] ==> #1386000    Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 7.786    Value Loss: 6.427    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1446300    Buffer Size: 26559      Transition Number: 1499.949k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:10:04,905][train][INFO][train.py>_log] ==> #1387000    Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 7.385    Value Loss: 6.684    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 1447188    Buffer Size: 26497      Transition Number: 1499.947k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:13:31,227][train][INFO][train.py>_log] ==> #1388000    Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 7.474    Value Loss: 6.241    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 1448096    Buffer Size: 26425      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:16:57,871][train][INFO][train.py>_log] ==> #1389000    Total Loss: 1.113    [weighted Loss:1.113    Policy Loss: 7.223    Value Loss: 5.970    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 1448979    Buffer Size: 26344      Transition Number: 1499.980k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:20:21,443][train][INFO][train.py>_log] ==> #1390000    Total Loss: 1.461    [weighted Loss:1.461    Policy Loss: 7.452    Value Loss: 6.241    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1449863    Buffer Size: 26264      Transition Number: 1499.950k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:23:48,371][train][INFO][train.py>_log] ==> #1391000    Total Loss: 0.725    [weighted Loss:0.725    Policy Loss: 7.121    Value Loss: 6.115    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 1450798    Buffer Size: 26186      Transition Number: 1500.063k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:27:15,575][train][INFO][train.py>_log] ==> #1392000    Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 7.453    Value Loss: 5.866    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451692    Buffer Size: 26105      Transition Number: 1500.045k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:30:39,652][train][INFO][train.py>_log] ==> #1393000    Total Loss: 2.837    [weighted Loss:2.837    Policy Loss: 7.254    Value Loss: 6.181    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1452597    Buffer Size: 26009      Transition Number: 1499.963k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:34:07,461][train][INFO][train.py>_log] ==> #1394000    Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 7.644    Value Loss: 5.882    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1453510    Buffer Size: 25921      Transition Number: 1499.968k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:37:34,741][train][INFO][train.py>_log] ==> #1395000    Total Loss: 1.942    [weighted Loss:1.942    Policy Loss: 6.927    Value Loss: 5.726    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 1454392    Buffer Size: 25806      Transition Number: 1499.971k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:40:59,217][train][INFO][train.py>_log] ==> #1396000    Total Loss: 0.986    [weighted Loss:0.986    Policy Loss: 7.431    Value Loss: 5.660    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 1455277    Buffer Size: 25696      Transition Number: 1499.983k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:44:25,167][train][INFO][train.py>_log] ==> #1397000    Total Loss: 2.216    [weighted Loss:2.216    Policy Loss: 7.599    Value Loss: 5.816    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 1456184    Buffer Size: 25542      Transition Number: 1499.944k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:47:50,728][train][INFO][train.py>_log] ==> #1398000    Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 7.170    Value Loss: 6.044    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 1457096    Buffer Size: 25396      Transition Number: 1499.970k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:51:15,195][train][INFO][train.py>_log] ==> #1399000    Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 8.299    Value Loss: 6.168    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 1458003    Buffer Size: 25264      Transition Number: 1500.186k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:54:40,755][train][INFO][train.py>_log] ==> #1400000    Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 7.550    Value Loss: 5.474    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 1458905    Buffer Size: 25101      Transition Number: 1499.947k Batch Size: 256        Lr: 0.01000 
[2022-01-09 18:58:06,066][train][INFO][train.py>_log] ==> #1401000    Total Loss: 0.399    [weighted Loss:0.399    Policy Loss: 7.363    Value Loss: 5.278    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 1459822    Buffer Size: 24919      Transition Number: 1500.104k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:01:34,000][train][INFO][train.py>_log] ==> #1402000    Total Loss: 2.469    [weighted Loss:2.469    Policy Loss: 8.103    Value Loss: 5.305    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 1460729    Buffer Size: 24745      Transition Number: 1499.961k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:05:01,095][train][INFO][train.py>_log] ==> #1403000    Total Loss: 1.181    [weighted Loss:1.181    Policy Loss: 7.909    Value Loss: 5.357    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 1461627    Buffer Size: 24591      Transition Number: 1499.993k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:08:25,188][train][INFO][train.py>_log] ==> #1404000    Total Loss: 2.384    [weighted Loss:2.384    Policy Loss: 8.852    Value Loss: 5.593    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 1462545    Buffer Size: 24451      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:11:49,612][train][INFO][train.py>_log] ==> #1405000    Total Loss: 0.750    [weighted Loss:0.750    Policy Loss: 8.315    Value Loss: 5.231    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 1463456    Buffer Size: 24330      Transition Number: 1499.975k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:15:15,944][train][INFO][train.py>_log] ==> #1406000    Total Loss: 1.302    [weighted Loss:1.302    Policy Loss: 8.836    Value Loss: 5.287    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 1464372    Buffer Size: 24216      Transition Number: 1499.975k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:18:42,570][train][INFO][train.py>_log] ==> #1407000    Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 8.565    Value Loss: 5.593    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 1465265    Buffer Size: 24127      Transition Number: 1499.947k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:22:07,061][train][INFO][train.py>_log] ==> #1408000    Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 8.355    Value Loss: 5.379    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 1466166    Buffer Size: 24037      Transition Number: 1499.972k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:25:34,406][train][INFO][train.py>_log] ==> #1409000    Total Loss: 2.741    [weighted Loss:2.741    Policy Loss: 8.801    Value Loss: 5.047    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 1467091    Buffer Size: 23966      Transition Number: 1499.970k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:29:00,484][train][INFO][train.py>_log] ==> #1410000    Total Loss: 1.651    [weighted Loss:1.651    Policy Loss: 8.113    Value Loss: 5.048    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 1468057    Buffer Size: 23907      Transition Number: 1499.942k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:32:26,615][train][INFO][train.py>_log] ==> #1411000    Total Loss: 1.206    [weighted Loss:1.206    Policy Loss: 9.132    Value Loss: 5.132    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 1469021    Buffer Size: 23915      Transition Number: 1500.049k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:35:56,070][train][INFO][train.py>_log] ==> #1412000    Total Loss: 0.905    [weighted Loss:0.905    Policy Loss: 9.058    Value Loss: 5.374    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 1469957    Buffer Size: 23908      Transition Number: 1500.064k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:39:19,418][train][INFO][train.py>_log] ==> #1413000    Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 9.040    Value Loss: 5.447    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 1470853    Buffer Size: 23907      Transition Number: 1499.977k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:42:43,958][train][INFO][train.py>_log] ==> #1414000    Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 9.002    Value Loss: 4.993    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 1471812    Buffer Size: 23916      Transition Number: 1500.050k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:46:11,177][train][INFO][train.py>_log] ==> #1415000    Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 9.241    Value Loss: 5.306    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 1472755    Buffer Size: 23940      Transition Number: 1499.974k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:49:37,687][train][INFO][train.py>_log] ==> #1416000    Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 9.514    Value Loss: 5.244    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 1473690    Buffer Size: 23952      Transition Number: 1499.970k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:53:03,486][train][INFO][train.py>_log] ==> #1417000    Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 9.213    Value Loss: 5.033    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 1474671    Buffer Size: 23950      Transition Number: 1500.088k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:56:32,834][train][INFO][train.py>_log] ==> #1418000    Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 10.029   Value Loss: 5.144    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 1475618    Buffer Size: 23962      Transition Number: 1499.978k Batch Size: 256        Lr: 0.01000 
[2022-01-09 19:59:59,888][train][INFO][train.py>_log] ==> #1419000    Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 8.823    Value Loss: 5.487    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 1476593    Buffer Size: 23982      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:03:25,398][train][INFO][train.py>_log] ==> #1420000    Total Loss: 1.530    [weighted Loss:1.530    Policy Loss: 9.616    Value Loss: 5.236    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 1477587    Buffer Size: 24018      Transition Number: 1500.058k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:06:50,265][train][INFO][train.py>_log] ==> #1421000    Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 8.634    Value Loss: 5.570    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 1478506    Buffer Size: 24054      Transition Number: 1500.144k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:10:16,436][train][INFO][train.py>_log] ==> #1422000    Total Loss: 1.795    [weighted Loss:1.795    Policy Loss: 9.357    Value Loss: 5.179    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 1479453    Buffer Size: 24084      Transition Number: 1500.046k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:13:39,961][train][INFO][train.py>_log] ==> #1423000    Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 9.012    Value Loss: 5.377    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 1480366    Buffer Size: 24127      Transition Number: 1500.089k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:17:06,843][train][INFO][train.py>_log] ==> #1424000    Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 9.316    Value Loss: 4.998    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 1481293    Buffer Size: 24168      Transition Number: 1499.957k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:20:32,304][train][INFO][train.py>_log] ==> #1425000    Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 9.049    Value Loss: 5.105    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 1482216    Buffer Size: 24198      Transition Number: 1499.981k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:23:58,264][train][INFO][train.py>_log] ==> #1426000    Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 9.082    Value Loss: 5.475    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 1483181    Buffer Size: 24230      Transition Number: 1500.018k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:27:24,813][train][INFO][train.py>_log] ==> #1427000    Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 8.850    Value Loss: 5.045    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 1484162    Buffer Size: 24252      Transition Number: 1500.089k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:30:51,147][train][INFO][train.py>_log] ==> #1428000    Total Loss: 1.468    [weighted Loss:1.468    Policy Loss: 9.043    Value Loss: 5.373    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485086    Buffer Size: 24283      Transition Number: 1499.954k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:34:16,226][train][INFO][train.py>_log] ==> #1429000    Total Loss: 1.110    [weighted Loss:1.110    Policy Loss: 8.699    Value Loss: 5.219    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 1486030    Buffer Size: 24311      Transition Number: 1499.967k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:37:43,635][train][INFO][train.py>_log] ==> #1430000    Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 8.912    Value Loss: 5.175    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 1486999    Buffer Size: 24334      Transition Number: 1499.989k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:41:08,376][train][INFO][train.py>_log] ==> #1431000    Total Loss: 1.057    [weighted Loss:1.057    Policy Loss: 8.796    Value Loss: 5.011    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 1487896    Buffer Size: 24350      Transition Number: 1499.985k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:44:34,580][train][INFO][train.py>_log] ==> #1432000    Total Loss: 1.175    [weighted Loss:1.175    Policy Loss: 8.653    Value Loss: 5.223    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 1488830    Buffer Size: 24364      Transition Number: 1499.987k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:48:01,094][train][INFO][train.py>_log] ==> #1433000    Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 8.958    Value Loss: 4.868    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 1489833    Buffer Size: 24377      Transition Number: 1499.981k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:51:26,867][train][INFO][train.py>_log] ==> #1434000    Total Loss: 0.888    [weighted Loss:0.888    Policy Loss: 8.510    Value Loss: 5.324    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 1490755    Buffer Size: 24390      Transition Number: 1500.019k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:54:56,921][train][INFO][train.py>_log] ==> #1435000    Total Loss: 1.475    [weighted Loss:1.475    Policy Loss: 8.760    Value Loss: 5.191    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 1491756    Buffer Size: 24375      Transition Number: 1500.127k Batch Size: 256        Lr: 0.01000 
[2022-01-09 20:58:22,031][train][INFO][train.py>_log] ==> #1436000    Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 8.120    Value Loss: 5.402    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 1492695    Buffer Size: 24349      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:01:48,351][train][INFO][train.py>_log] ==> #1437000    Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 8.957    Value Loss: 5.483    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 1493630    Buffer Size: 24306      Transition Number: 1499.994k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:05:14,846][train][INFO][train.py>_log] ==> #1438000    Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 8.917    Value Loss: 5.180    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 1494590    Buffer Size: 24264      Transition Number: 1500.005k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:08:44,024][train][INFO][train.py>_log] ==> #1439000    Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 8.702    Value Loss: 5.083    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 1495554    Buffer Size: 24219      Transition Number: 1499.952k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:12:12,527][train][INFO][train.py>_log] ==> #1440000    Total Loss: 1.741    [weighted Loss:1.741    Policy Loss: 8.888    Value Loss: 5.616    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 1496553    Buffer Size: 24164      Transition Number: 1500.007k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:15:39,051][train][INFO][train.py>_log] ==> #1441000    Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 9.137    Value Loss: 5.382    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 1497501    Buffer Size: 24138      Transition Number: 1499.944k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:19:06,658][train][INFO][train.py>_log] ==> #1442000    Total Loss: 1.636    [weighted Loss:1.636    Policy Loss: 8.819    Value Loss: 5.385    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 1498502    Buffer Size: 24122      Transition Number: 1499.966k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:22:32,994][train][INFO][train.py>_log] ==> #1443000    Total Loss: 1.471    [weighted Loss:1.471    Policy Loss: 9.123    Value Loss: 5.294    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 1499485    Buffer Size: 24129      Transition Number: 1500.050k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:25:56,856][train][INFO][train.py>_log] ==> #1444000    Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 9.020    Value Loss: 5.579    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 1500439    Buffer Size: 24143      Transition Number: 1499.987k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:29:21,564][train][INFO][train.py>_log] ==> #1445000    Total Loss: 1.787    [weighted Loss:1.787    Policy Loss: 9.361    Value Loss: 5.154    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 1501369    Buffer Size: 24169      Transition Number: 1499.942k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:32:47,498][train][INFO][train.py>_log] ==> #1446000    Total Loss: 0.937    [weighted Loss:0.937    Policy Loss: 9.649    Value Loss: 5.369    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 1502356    Buffer Size: 24216      Transition Number: 1499.942k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:36:15,234][train][INFO][train.py>_log] ==> #1447000    Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 9.262    Value Loss: 5.479    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 1503507    Buffer Size: 24344      Transition Number: 1499.984k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:39:42,940][train][INFO][train.py>_log] ==> #1448000    Total Loss: 1.228    [weighted Loss:1.228    Policy Loss: 9.387    Value Loss: 5.340    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 1504576    Buffer Size: 24481      Transition Number: 1499.972k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:43:08,933][train][INFO][train.py>_log] ==> #1449000    Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 9.032    Value Loss: 5.200    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 1505555    Buffer Size: 24525      Transition Number: 1499.963k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:46:34,355][train][INFO][train.py>_log] ==> #1450000    Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 9.517    Value Loss: 5.566    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 1506554    Buffer Size: 24555      Transition Number: 1499.954k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:50:00,350][train][INFO][train.py>_log] ==> #1451000    Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 9.499    Value Loss: 5.420    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 1507475    Buffer Size: 24564      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:53:26,829][train][INFO][train.py>_log] ==> #1452000    Total Loss: 1.722    [weighted Loss:1.722    Policy Loss: 9.027    Value Loss: 5.780    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1508445    Buffer Size: 24581      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-09 21:56:51,684][train][INFO][train.py>_log] ==> #1453000    Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 8.627    Value Loss: 5.695    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 1509387    Buffer Size: 24612      Transition Number: 1499.974k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:00:15,651][train][INFO][train.py>_log] ==> #1454000    Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 8.710    Value Loss: 5.725    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 1510344    Buffer Size: 24641      Transition Number: 1499.959k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:03:43,275][train][INFO][train.py>_log] ==> #1455000    Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 8.545    Value Loss: 5.824    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 1511300    Buffer Size: 24651      Transition Number: 1499.987k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:07:09,473][train][INFO][train.py>_log] ==> #1456000    Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 9.197    Value Loss: 5.017    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 1512275    Buffer Size: 24650      Transition Number: 1499.971k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:10:34,967][train][INFO][train.py>_log] ==> #1457000    Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 8.847    Value Loss: 5.698    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 1513223    Buffer Size: 24646      Transition Number: 1499.996k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:14:00,806][train][INFO][train.py>_log] ==> #1458000    Total Loss: 1.294    [weighted Loss:1.294    Policy Loss: 8.263    Value Loss: 5.635    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 1514181    Buffer Size: 24637      Transition Number: 1499.974k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:17:26,661][train][INFO][train.py>_log] ==> #1459000    Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 8.034    Value Loss: 5.260    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 1515116    Buffer Size: 24631      Transition Number: 1500.061k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:20:51,295][train][INFO][train.py>_log] ==> #1460000    Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 8.498    Value Loss: 5.718    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 1516036    Buffer Size: 24634      Transition Number: 1499.945k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:24:18,393][train][INFO][train.py>_log] ==> #1461000    Total Loss: 2.701    [weighted Loss:2.701    Policy Loss: 9.044    Value Loss: 5.512    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 1517000    Buffer Size: 24623      Transition Number: 1500.072k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:27:43,698][train][INFO][train.py>_log] ==> #1462000    Total Loss: 2.161    [weighted Loss:2.161    Policy Loss: 7.937    Value Loss: 5.778    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 1517957    Buffer Size: 24598      Transition Number: 1499.960k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:31:10,456][train][INFO][train.py>_log] ==> #1463000    Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 8.241    Value Loss: 5.619    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 1518870    Buffer Size: 24562      Transition Number: 1499.942k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:34:38,593][train][INFO][train.py>_log] ==> #1464000    Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 8.201    Value Loss: 4.992    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 1519825    Buffer Size: 24521      Transition Number: 1499.964k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:38:06,648][train][INFO][train.py>_log] ==> #1465000    Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 8.708    Value Loss: 5.586    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 1520790    Buffer Size: 24513      Transition Number: 1499.943k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:41:33,403][train][INFO][train.py>_log] ==> #1466000    Total Loss: 1.250    [weighted Loss:1.250    Policy Loss: 8.882    Value Loss: 5.494    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 1521729    Buffer Size: 24504      Transition Number: 1499.941k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:45:00,404][train][INFO][train.py>_log] ==> #1467000    Total Loss: 0.620    [weighted Loss:0.620    Policy Loss: 8.142    Value Loss: 5.654    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 1522657    Buffer Size: 24493      Transition Number: 1500.030k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:48:27,234][train][INFO][train.py>_log] ==> #1468000    Total Loss: 0.975    [weighted Loss:0.975    Policy Loss: 8.294    Value Loss: 5.204    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 1523593    Buffer Size: 24459      Transition Number: 1499.991k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:51:53,228][train][INFO][train.py>_log] ==> #1469000    Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 7.968    Value Loss: 5.385    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524524    Buffer Size: 24394      Transition Number: 1500.027k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:55:22,735][train][INFO][train.py>_log] ==> #1470000    Total Loss: 1.589    [weighted Loss:1.589    Policy Loss: 7.825    Value Loss: 5.814    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 1525501    Buffer Size: 24320      Transition Number: 1499.941k Batch Size: 256        Lr: 0.01000 
[2022-01-09 22:58:50,818][train][INFO][train.py>_log] ==> #1471000    Total Loss: 1.118    [weighted Loss:1.118    Policy Loss: 8.402    Value Loss: 5.730    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 1526411    Buffer Size: 24233      Transition Number: 1499.952k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:02:18,102][train][INFO][train.py>_log] ==> #1472000    Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 7.796    Value Loss: 5.847    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 1527362    Buffer Size: 24086      Transition Number: 1500.041k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:05:44,900][train][INFO][train.py>_log] ==> #1473000    Total Loss: 0.752    [weighted Loss:0.752    Policy Loss: 8.542    Value Loss: 5.758    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 1528292    Buffer Size: 23939      Transition Number: 1500.009k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:09:11,888][train][INFO][train.py>_log] ==> #1474000    Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 7.759    Value Loss: 4.870    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 1529210    Buffer Size: 23853      Transition Number: 1499.986k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:12:41,370][train][INFO][train.py>_log] ==> #1475000    Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 8.554    Value Loss: 5.081    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 1530181    Buffer Size: 23803      Transition Number: 1499.962k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:16:08,778][train][INFO][train.py>_log] ==> #1476000    Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 8.357    Value Loss: 5.433    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 1531127    Buffer Size: 23782      Transition Number: 1500.052k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:19:36,591][train][INFO][train.py>_log] ==> #1477000    Total Loss: 1.113    [weighted Loss:1.113    Policy Loss: 9.005    Value Loss: 5.163    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 1532050    Buffer Size: 23771      Transition Number: 1499.968k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:23:02,137][train][INFO][train.py>_log] ==> #1478000    Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 9.073    Value Loss: 5.055    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 1533000    Buffer Size: 23752      Transition Number: 1500.031k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:26:30,133][train][INFO][train.py>_log] ==> #1479000    Total Loss: 1.528    [weighted Loss:1.528    Policy Loss: 8.521    Value Loss: 5.163    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 1534010    Buffer Size: 23798      Transition Number: 1499.980k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:29:57,620][train][INFO][train.py>_log] ==> #1480000    Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 8.699    Value Loss: 5.426    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 1535033    Buffer Size: 23856      Transition Number: 1499.994k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:33:24,223][train][INFO][train.py>_log] ==> #1481000    Total Loss: 1.146    [weighted Loss:1.146    Policy Loss: 7.971    Value Loss: 5.162    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 1535991    Buffer Size: 23931      Transition Number: 1500.014k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:36:53,475][train][INFO][train.py>_log] ==> #1482000    Total Loss: 2.017    [weighted Loss:2.017    Policy Loss: 8.944    Value Loss: 5.434    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 1536998    Buffer Size: 24009      Transition Number: 1499.955k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:40:19,013][train][INFO][train.py>_log] ==> #1483000    Total Loss: 1.312    [weighted Loss:1.312    Policy Loss: 8.815    Value Loss: 5.635    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 1538031    Buffer Size: 24108      Transition Number: 1499.955k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:43:44,508][train][INFO][train.py>_log] ==> #1484000    Total Loss: 0.260    [weighted Loss:0.260    Policy Loss: 8.565    Value Loss: 5.736    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 1539037    Buffer Size: 24201      Transition Number: 1500.008k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:47:12,809][train][INFO][train.py>_log] ==> #1485000    Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 8.904    Value Loss: 5.418    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 1540024    Buffer Size: 24281      Transition Number: 1499.988k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:50:39,092][train][INFO][train.py>_log] ==> #1486000    Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 9.144    Value Loss: 5.419    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 1541027    Buffer Size: 24378      Transition Number: 1499.979k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:54:04,335][train][INFO][train.py>_log] ==> #1487000    Total Loss: 1.359    [weighted Loss:1.359    Policy Loss: 8.263    Value Loss: 5.420    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 1541966    Buffer Size: 24468      Transition Number: 1499.961k Batch Size: 256        Lr: 0.01000 
[2022-01-09 23:57:31,243][train][INFO][train.py>_log] ==> #1488000    Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 8.794    Value Loss: 5.853    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 1542985    Buffer Size: 24568      Transition Number: 1499.992k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:00:57,075][train][INFO][train.py>_log] ==> #1489000    Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 8.603    Value Loss: 5.624    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 1543966    Buffer Size: 24663      Transition Number: 1499.930k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:04:25,814][train][INFO][train.py>_log] ==> #1490000    Total Loss: 1.007    [weighted Loss:1.007    Policy Loss: 8.546    Value Loss: 5.906    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 1544933    Buffer Size: 24740      Transition Number: 1499.961k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:07:51,620][train][INFO][train.py>_log] ==> #1491000    Total Loss: 1.930    [weighted Loss:1.930    Policy Loss: 8.263    Value Loss: 5.434    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1545910    Buffer Size: 24792      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:11:17,169][train][INFO][train.py>_log] ==> #1492000    Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 8.014    Value Loss: 5.434    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 1546889    Buffer Size: 24839      Transition Number: 1500.016k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:14:42,067][train][INFO][train.py>_log] ==> #1493000    Total Loss: 1.452    [weighted Loss:1.452    Policy Loss: 8.160    Value Loss: 5.904    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 1547810    Buffer Size: 24864      Transition Number: 1500.073k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:18:07,251][train][INFO][train.py>_log] ==> #1494000    Total Loss: 2.333    [weighted Loss:2.333    Policy Loss: 7.673    Value Loss: 6.204    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 1548750    Buffer Size: 24891      Transition Number: 1500.038k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:21:35,089][train][INFO][train.py>_log] ==> #1495000    Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 7.970    Value Loss: 5.339    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 1549707    Buffer Size: 24946      Transition Number: 1500.088k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:25:04,825][train][INFO][train.py>_log] ==> #1496000    Total Loss: 0.910    [weighted Loss:0.910    Policy Loss: 7.454    Value Loss: 5.660    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1550659    Buffer Size: 24977      Transition Number: 1499.958k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:28:30,024][train][INFO][train.py>_log] ==> #1497000    Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 7.682    Value Loss: 5.531    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 1551598    Buffer Size: 24990      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:31:54,830][train][INFO][train.py>_log] ==> #1498000    Total Loss: 1.250    [weighted Loss:1.250    Policy Loss: 7.824    Value Loss: 5.510    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 1552500    Buffer Size: 24993      Transition Number: 1499.989k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:35:20,201][train][INFO][train.py>_log] ==> #1499000    Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 8.020    Value Loss: 6.110    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 1553454    Buffer Size: 24995      Transition Number: 1499.954k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:38:47,306][train][INFO][train.py>_log] ==> #1500000    Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 7.658    Value Loss: 5.306    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 1554385    Buffer Size: 25012      Transition Number: 1499.953k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:42:12,730][train][INFO][train.py>_log] ==> #1501000    Total Loss: 0.987    [weighted Loss:0.987    Policy Loss: 7.646    Value Loss: 5.700    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 1555303    Buffer Size: 25020      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:45:39,238][train][INFO][train.py>_log] ==> #1502000    Total Loss: 0.401    [weighted Loss:0.401    Policy Loss: 7.650    Value Loss: 5.370    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 1556287    Buffer Size: 25028      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:49:03,697][train][INFO][train.py>_log] ==> #1503000    Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 7.888    Value Loss: 5.989    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 1557241    Buffer Size: 25015      Transition Number: 1500.366k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:52:29,534][train][INFO][train.py>_log] ==> #1504000    Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 7.532    Value Loss: 5.309    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 1558160    Buffer Size: 24970      Transition Number: 1499.999k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:55:56,570][train][INFO][train.py>_log] ==> #1505000    Total Loss: 1.757    [weighted Loss:1.757    Policy Loss: 7.465    Value Loss: 5.695    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 1559094    Buffer Size: 24894      Transition Number: 1499.997k Batch Size: 256        Lr: 0.01000 
[2022-01-10 00:59:22,255][train][INFO][train.py>_log] ==> #1506000    Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 7.643    Value Loss: 5.691    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 1560018    Buffer Size: 24806      Transition Number: 1499.993k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:02:48,730][train][INFO][train.py>_log] ==> #1507000    Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 7.601    Value Loss: 5.527    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 1560960    Buffer Size: 24709      Transition Number: 1500.023k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:06:15,545][train][INFO][train.py>_log] ==> #1508000    Total Loss: 0.940    [weighted Loss:0.940    Policy Loss: 7.460    Value Loss: 5.714    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 1561924    Buffer Size: 24619      Transition Number: 1500.047k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:09:42,717][train][INFO][train.py>_log] ==> #1509000    Total Loss: 0.869    [weighted Loss:0.869    Policy Loss: 7.469    Value Loss: 6.047    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 1562828    Buffer Size: 24497      Transition Number: 1499.971k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:13:12,772][train][INFO][train.py>_log] ==> #1510000    Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 7.284    Value Loss: 5.669    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 1563787    Buffer Size: 24378      Transition Number: 1500.067k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:16:42,448][train][INFO][train.py>_log] ==> #1511000    Total Loss: 1.513    [weighted Loss:1.513    Policy Loss: 7.990    Value Loss: 5.606    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 1564762    Buffer Size: 24257      Transition Number: 1499.995k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:20:11,474][train][INFO][train.py>_log] ==> #1512000    Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 7.614    Value Loss: 5.332    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 1565703    Buffer Size: 24162      Transition Number: 1499.996k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:23:38,974][train][INFO][train.py>_log] ==> #1513000    Total Loss: 0.947    [weighted Loss:0.947    Policy Loss: 7.448    Value Loss: 5.256    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 1566651    Buffer Size: 24056      Transition Number: 1499.956k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:27:05,897][train][INFO][train.py>_log] ==> #1514000    Total Loss: 1.043    [weighted Loss:1.043    Policy Loss: 7.597    Value Loss: 5.355    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 1567540    Buffer Size: 23969      Transition Number: 1500.041k Batch Size: 256        Lr: 0.01000 
[2022-01-10 01:30:31,781][train][INFO][train.py>_log] ==> #1515000    Total Loss: 1.678    [weighted Loss:1.678    Policy Loss: 8.208    Value Loss: 5.329    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 1568455    Buffer Size: 23899      Transition Number: 1499.961k Batch Size: 256        Lr: 0.01000 
