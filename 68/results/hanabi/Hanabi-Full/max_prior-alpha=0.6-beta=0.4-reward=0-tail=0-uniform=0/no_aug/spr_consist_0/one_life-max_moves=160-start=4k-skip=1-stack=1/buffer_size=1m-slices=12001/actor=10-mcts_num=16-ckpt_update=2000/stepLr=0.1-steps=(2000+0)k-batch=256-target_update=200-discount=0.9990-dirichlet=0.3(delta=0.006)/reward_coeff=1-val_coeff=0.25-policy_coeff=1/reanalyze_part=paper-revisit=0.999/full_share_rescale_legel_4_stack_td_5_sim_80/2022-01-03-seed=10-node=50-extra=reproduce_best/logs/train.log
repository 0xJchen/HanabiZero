[2022-01-03 06:33:56,676][train][INFO][train.py>_log] ==> #0          Total Loss: 56.688   [weighted Loss:56.688   Policy Loss: 15.588   Value Loss: 37.125   Reward Loss: 31.820   Consistency Loss: 0.000    ] Replay Episodes Collected: 473        Buffer Size: 473        Transition Number: 5.538   k Batch Size: 256        Lr: 0.00000 
[2022-01-03 06:36:11,418][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.001    [weighted Loss:5.001    Policy Loss: 15.085   Value Loss: 3.719    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 2144       Buffer Size: 2144       Transition Number: 26.501  k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:38:20,473][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.800    [weighted Loss:6.800    Policy Loss: 14.567   Value Loss: 3.694    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 3738       Buffer Size: 3738       Transition Number: 46.967  k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:40:24,276][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.610    [weighted Loss:5.610    Policy Loss: 13.506   Value Loss: 3.414    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 5440       Buffer Size: 5440       Transition Number: 66.664  k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:42:26,910][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.371    [weighted Loss:6.371    Policy Loss: 14.713   Value Loss: 3.371    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 7094       Buffer Size: 7094       Transition Number: 85.721  k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:44:32,744][train][INFO][train.py>_log] ==> #5000       Total Loss: 6.107    [weighted Loss:6.107    Policy Loss: 13.284   Value Loss: 3.187    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 8674       Buffer Size: 8674       Transition Number: 104.328 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:46:38,471][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.070    [weighted Loss:5.070    Policy Loss: 13.200   Value Loss: 3.119    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 10295      Buffer Size: 10295      Transition Number: 123.511 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:48:42,945][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.466    [weighted Loss:4.466    Policy Loss: 14.091   Value Loss: 3.170    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 11387      Buffer Size: 11387      Transition Number: 142.649 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:50:46,275][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.707    [weighted Loss:5.707    Policy Loss: 13.397   Value Loss: 3.142    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 12434      Buffer Size: 12434      Transition Number: 160.819 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:52:51,336][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.985    [weighted Loss:4.985    Policy Loss: 12.473   Value Loss: 3.236    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 13528      Buffer Size: 13528      Transition Number: 177.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:54:56,999][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.511    [weighted Loss:4.511    Policy Loss: 14.661   Value Loss: 3.066    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 14704      Buffer Size: 14704      Transition Number: 196.748 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:57:01,132][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 13.241   Value Loss: 2.985    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 15280      Buffer Size: 15280      Transition Number: 214.158 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 06:59:05,053][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.780    [weighted Loss:3.780    Policy Loss: 14.262   Value Loss: 2.990    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 15771      Buffer Size: 15771      Transition Number: 230.478 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:01:10,100][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.921    [weighted Loss:3.921    Policy Loss: 11.937   Value Loss: 3.027    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 16322      Buffer Size: 16322      Transition Number: 245.820 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:03:13,069][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.504    [weighted Loss:5.504    Policy Loss: 13.850   Value Loss: 3.037    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 16864      Buffer Size: 16864      Transition Number: 262.891 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:05:18,667][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.561    [weighted Loss:5.561    Policy Loss: 11.334   Value Loss: 3.307    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 18002      Buffer Size: 18002      Transition Number: 282.623 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:07:22,882][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.767    [weighted Loss:5.767    Policy Loss: 13.143   Value Loss: 3.285    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 19144      Buffer Size: 19144      Transition Number: 300.519 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:09:28,569][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 11.511   Value Loss: 3.531    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 19786      Buffer Size: 19786      Transition Number: 314.468 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:11:31,212][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.025    [weighted Loss:4.025    Policy Loss: 10.966   Value Loss: 3.366    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 20380      Buffer Size: 20380      Transition Number: 329.919 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:13:35,954][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.854    [weighted Loss:4.854    Policy Loss: 10.060   Value Loss: 3.935    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 20973      Buffer Size: 20973      Transition Number: 347.229 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:15:41,447][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 9.185    Value Loss: 4.076    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 21515      Buffer Size: 21515      Transition Number: 364.397 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:17:47,967][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 9.298    Value Loss: 4.003    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 21878      Buffer Size: 21878      Transition Number: 379.476 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:19:54,194][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 7.961    Value Loss: 3.708    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 22261      Buffer Size: 22261      Transition Number: 395.072 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:22:02,145][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.541    [weighted Loss:3.541    Policy Loss: 8.145    Value Loss: 4.188    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 22745      Buffer Size: 22745      Transition Number: 413.887 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:24:10,416][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.508    [weighted Loss:3.508    Policy Loss: 8.323    Value Loss: 4.292    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 23172      Buffer Size: 23172      Transition Number: 430.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:26:16,562][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 7.612    Value Loss: 4.120    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 23618      Buffer Size: 23618      Transition Number: 447.664 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:28:23,471][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 7.517    Value Loss: 4.184    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 24033      Buffer Size: 24033      Transition Number: 463.808 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:30:29,615][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 6.899    Value Loss: 4.512    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 24545      Buffer Size: 24545      Transition Number: 481.141 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:32:36,280][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 6.801    Value Loss: 4.049    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 25074      Buffer Size: 25074      Transition Number: 498.904 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:34:51,833][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.911    [weighted Loss:3.911    Policy Loss: 8.417    Value Loss: 4.652    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 25501      Buffer Size: 25501      Transition Number: 516.727 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:36:58,958][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.020    [weighted Loss:3.020    Policy Loss: 8.141    Value Loss: 4.352    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 25894      Buffer Size: 25894      Transition Number: 533.288 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:39:05,716][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.122    [weighted Loss:4.122    Policy Loss: 7.501    Value Loss: 4.898    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 26325      Buffer Size: 26325      Transition Number: 550.882 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:41:15,762][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.133    [weighted Loss:3.133    Policy Loss: 7.526    Value Loss: 4.679    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 26771      Buffer Size: 26771      Transition Number: 568.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:43:31,121][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.387    [weighted Loss:3.387    Policy Loss: 7.897    Value Loss: 4.424    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 27238      Buffer Size: 27238      Transition Number: 586.537 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:45:39,373][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.565    [weighted Loss:1.565    Policy Loss: 7.796    Value Loss: 4.690    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 27664      Buffer Size: 27664      Transition Number: 603.506 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:47:47,765][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 7.857    Value Loss: 4.732    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 28072      Buffer Size: 28072      Transition Number: 620.301 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:49:55,235][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.567    [weighted Loss:3.567    Policy Loss: 6.166    Value Loss: 4.627    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 28485      Buffer Size: 28485      Transition Number: 637.116 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:52:06,396][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.696    [weighted Loss:3.696    Policy Loss: 7.662    Value Loss: 4.644    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 28836      Buffer Size: 28836      Transition Number: 654.712 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:54:16,928][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 6.357    Value Loss: 4.749    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 29192      Buffer Size: 29192      Transition Number: 672.692 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:56:27,042][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 7.011    Value Loss: 5.242    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 29528      Buffer Size: 29528      Transition Number: 689.804 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 07:58:37,389][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 6.519    Value Loss: 5.037    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 29856      Buffer Size: 29856      Transition Number: 706.766 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:00:49,773][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.090    [weighted Loss:2.090    Policy Loss: 5.808    Value Loss: 4.933    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 30184      Buffer Size: 30184      Transition Number: 723.046 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:03:01,558][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.336    [weighted Loss:3.336    Policy Loss: 5.684    Value Loss: 4.971    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 30541      Buffer Size: 30541      Transition Number: 742.001 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:05:14,604][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 6.135    Value Loss: 4.804    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 30892      Buffer Size: 30892      Transition Number: 759.664 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:07:26,791][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.107    [weighted Loss:3.107    Policy Loss: 6.288    Value Loss: 5.072    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 31253      Buffer Size: 31253      Transition Number: 778.528 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:09:39,731][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 6.111    Value Loss: 4.820    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 31557      Buffer Size: 31557      Transition Number: 794.618 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:11:52,743][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 6.161    Value Loss: 5.137    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 31914      Buffer Size: 31914      Transition Number: 812.782 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:14:06,496][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 6.182    Value Loss: 5.067    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 32277      Buffer Size: 32277      Transition Number: 830.888 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:16:19,797][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 5.420    Value Loss: 5.135    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 32647      Buffer Size: 32647      Transition Number: 849.768 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:18:36,929][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.704    [weighted Loss:2.704    Policy Loss: 5.515    Value Loss: 4.981    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 32958      Buffer Size: 32958      Transition Number: 867.092 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:20:55,272][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.937    [weighted Loss:1.937    Policy Loss: 5.854    Value Loss: 4.977    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 33280      Buffer Size: 33280      Transition Number: 885.394 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:23:14,682][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 5.522    Value Loss: 5.087    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 33649      Buffer Size: 33649      Transition Number: 905.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:25:36,148][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 5.744    Value Loss: 4.994    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 33975      Buffer Size: 33975      Transition Number: 924.843 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:27:55,637][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.993    [weighted Loss:2.993    Policy Loss: 6.224    Value Loss: 5.070    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 34332      Buffer Size: 34332      Transition Number: 944.257 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:30:13,843][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 5.993    Value Loss: 5.173    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 34682      Buffer Size: 34682      Transition Number: 961.941 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:32:37,319][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.808    [weighted Loss:2.808    Policy Loss: 5.933    Value Loss: 5.149    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 35099      Buffer Size: 35099      Transition Number: 982.188 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:35:04,154][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 6.026    Value Loss: 5.147    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 35529      Buffer Size: 35325      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:37:30,630][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 6.323    Value Loss: 5.078    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 35843      Buffer Size: 34227      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:40:02,646][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 5.808    Value Loss: 5.335    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 36220      Buffer Size: 32918      Transition Number: 1000.028k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:42:33,619][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.340    [weighted Loss:2.340    Policy Loss: 5.643    Value Loss: 5.072    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 36608      Buffer Size: 31536      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:45:03,693][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.496    [weighted Loss:2.496    Policy Loss: 5.738    Value Loss: 5.009    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 37001      Buffer Size: 30146      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:47:36,996][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 5.842    Value Loss: 5.220    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 37414      Buffer Size: 28791      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:50:07,825][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.670    [weighted Loss:2.670    Policy Loss: 5.333    Value Loss: 5.267    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 37819      Buffer Size: 27512      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:52:39,684][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 6.324    Value Loss: 5.032    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 38173      Buffer Size: 26716      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:55:11,915][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.409    [weighted Loss:1.409    Policy Loss: 5.959    Value Loss: 5.317    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 38545      Buffer Size: 25887      Transition Number: 1000.140k Batch Size: 256        Lr: 0.10000 
[2022-01-03 08:57:41,086][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 5.250    Value Loss: 5.280    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 38899      Buffer Size: 24976      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:00:14,854][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 5.441    Value Loss: 5.258    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 39275      Buffer Size: 24189      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:02:45,930][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 4.888    Value Loss: 5.430    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 39657      Buffer Size: 23949      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:05:19,273][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 5.290    Value Loss: 5.572    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 40041      Buffer Size: 23632      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:07:54,039][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.672    [weighted Loss:1.672    Policy Loss: 5.138    Value Loss: 5.401    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 40362      Buffer Size: 23206      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:10:30,740][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 5.496    Value Loss: 5.164    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 40739      Buffer Size: 22178      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:13:06,494][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 4.752    Value Loss: 5.611    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 41113      Buffer Size: 21367      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:15:42,931][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 5.066    Value Loss: 5.652    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 41476      Buffer Size: 20959      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:18:19,928][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 5.028    Value Loss: 5.482    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 41856      Buffer Size: 20605      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:20:55,613][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 4.856    Value Loss: 5.785    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 42235      Buffer Size: 20415      Transition Number: 1000.087k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:23:31,082][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 4.831    Value Loss: 5.426    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 42611      Buffer Size: 20276      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:26:08,079][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 4.864    Value Loss: 5.847    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 42985      Buffer Size: 20080      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:28:46,924][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 4.795    Value Loss: 5.501    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 43348      Buffer Size: 19891      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:31:24,992][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 5.395    Value Loss: 5.432    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 43735      Buffer Size: 19689      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:34:05,153][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 4.543    Value Loss: 5.550    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 44455      Buffer Size: 19732      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:36:44,011][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 5.014    Value Loss: 5.722    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 45240      Buffer Size: 19897      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:39:18,828][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 4.629    Value Loss: 5.597    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 45937      Buffer Size: 20103      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:41:57,387][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.555    [weighted Loss:1.555    Policy Loss: 6.100    Value Loss: 5.693    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 46665      Buffer Size: 20288      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:44:35,409][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 4.222    Value Loss: 5.672    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 47038      Buffer Size: 20145      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:47:14,375][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 5.971    Value Loss: 5.377    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 47432      Buffer Size: 19938      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:49:50,148][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.795    [weighted Loss:1.795    Policy Loss: 4.372    Value Loss: 5.450    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 48391      Buffer Size: 20359      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:52:29,035][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 5.215    Value Loss: 5.595    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 49281      Buffer Size: 20735      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:55:06,639][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.596    [weighted Loss:1.596    Policy Loss: 4.908    Value Loss: 5.564    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 49764      Buffer Size: 20783      Transition Number: 999.930 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 09:57:44,439][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 5.987    Value Loss: 5.666    Reward Loss: 0.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 50281      Buffer Size: 20857      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:00:17,458][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.694    [weighted Loss:2.694    Policy Loss: 6.098    Value Loss: 5.854    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 50695      Buffer Size: 20892      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:02:50,973][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 5.524    Value Loss: 5.888    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 51115      Buffer Size: 20898      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:05:26,520][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.714    [weighted Loss:2.714    Policy Loss: 5.459    Value Loss: 5.696    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 51596      Buffer Size: 20944      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:08:03,048][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.220    [weighted Loss:2.220    Policy Loss: 5.197    Value Loss: 5.743    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 52052      Buffer Size: 20993      Transition Number: 1000.106k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:10:40,355][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.936    [weighted Loss:2.936    Policy Loss: 5.700    Value Loss: 5.755    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 52630      Buffer Size: 21152      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:13:17,903][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 6.405    Value Loss: 6.176    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 53188      Buffer Size: 21294      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:15:56,265][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.776    [weighted Loss:2.776    Policy Loss: 5.500    Value Loss: 6.105    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 54016      Buffer Size: 21661      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:18:30,786][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.550    [weighted Loss:3.550    Policy Loss: 6.601    Value Loss: 6.064    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 54862      Buffer Size: 22071      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:21:08,129][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.735    [weighted Loss:2.735    Policy Loss: 6.254    Value Loss: 5.982    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 55331      Buffer Size: 22183      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:23:43,532][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 7.133    Value Loss: 5.802    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 55775      Buffer Size: 22261      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:26:19,248][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.098    [weighted Loss:3.098    Policy Loss: 6.752    Value Loss: 5.982    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 56277      Buffer Size: 22377      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:28:53,217][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.894    [weighted Loss:2.894    Policy Loss: 6.287    Value Loss: 5.885    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 56785      Buffer Size: 22480      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:31:32,476][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 7.519    Value Loss: 5.844    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 57223      Buffer Size: 22526      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:34:07,437][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 7.122    Value Loss: 5.919    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 57700      Buffer Size: 22538      Transition Number: 1000.007k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:36:43,930][train][INFO][train.py>_log] ==> #103000     Total Loss: 4.351    [weighted Loss:4.351    Policy Loss: 7.451    Value Loss: 5.965    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 58526      Buffer Size: 22880      Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:39:20,462][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.354    [weighted Loss:3.354    Policy Loss: 7.580    Value Loss: 6.234    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 59355      Buffer Size: 23318      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:41:58,070][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 6.998    Value Loss: 6.136    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 60075      Buffer Size: 23638      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:44:33,358][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.582    [weighted Loss:2.582    Policy Loss: 7.375    Value Loss: 6.236    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 60781      Buffer Size: 23931      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:47:08,404][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 7.708    Value Loss: 6.080    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 61341      Buffer Size: 24068      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:49:48,508][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 7.886    Value Loss: 6.076    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 61977      Buffer Size: 24247      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:52:25,636][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 7.354    Value Loss: 6.126    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 62516      Buffer Size: 24406      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:55:01,625][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.966    [weighted Loss:3.966    Policy Loss: 8.015    Value Loss: 6.899    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 63053      Buffer Size: 24562      Transition Number: 1000.024k Batch Size: 256        Lr: 0.10000 
[2022-01-03 10:57:33,925][train][INFO][train.py>_log] ==> #111000     Total Loss: 4.781    [weighted Loss:4.781    Policy Loss: 8.140    Value Loss: 6.393    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 63523      Buffer Size: 24656      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:00:08,936][train][INFO][train.py>_log] ==> #112000     Total Loss: 3.456    [weighted Loss:3.456    Policy Loss: 7.665    Value Loss: 6.242    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 64013      Buffer Size: 24774      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:02:44,443][train][INFO][train.py>_log] ==> #113000     Total Loss: 3.484    [weighted Loss:3.484    Policy Loss: 8.223    Value Loss: 6.082    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 64450      Buffer Size: 24845      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:05:21,978][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.852    [weighted Loss:3.852    Policy Loss: 7.974    Value Loss: 6.394    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 64913      Buffer Size: 24916      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:07:57,269][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.493    [weighted Loss:3.493    Policy Loss: 7.998    Value Loss: 6.448    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 65443      Buffer Size: 25084      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:10:33,946][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.172    [weighted Loss:4.172    Policy Loss: 8.500    Value Loss: 6.171    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 66013      Buffer Size: 25281      Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:13:11,730][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.282    [weighted Loss:4.282    Policy Loss: 8.308    Value Loss: 6.297    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 66628      Buffer Size: 25527      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:15:46,916][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.729    [weighted Loss:3.729    Policy Loss: 7.849    Value Loss: 6.147    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 67247      Buffer Size: 25777      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:18:21,088][train][INFO][train.py>_log] ==> #119000     Total Loss: 5.045    [weighted Loss:5.045    Policy Loss: 8.734    Value Loss: 6.457    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 68035      Buffer Size: 26163      Transition Number: 1000.025k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:20:58,754][train][INFO][train.py>_log] ==> #120000     Total Loss: 5.028    [weighted Loss:5.028    Policy Loss: 8.867    Value Loss: 6.492    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 68846      Buffer Size: 26563      Transition Number: 1000.061k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:23:31,438][train][INFO][train.py>_log] ==> #121000     Total Loss: 4.265    [weighted Loss:4.265    Policy Loss: 8.637    Value Loss: 6.304    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 69374      Buffer Size: 26749      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:26:08,408][train][INFO][train.py>_log] ==> #122000     Total Loss: 4.226    [weighted Loss:4.226    Policy Loss: 8.514    Value Loss: 6.543    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 69970      Buffer Size: 26976      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:28:41,795][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.537    [weighted Loss:3.537    Policy Loss: 8.184    Value Loss: 6.343    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 70391      Buffer Size: 27040      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:31:18,663][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.803    [weighted Loss:3.803    Policy Loss: 8.346    Value Loss: 6.460    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 70807      Buffer Size: 27080      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:33:52,060][train][INFO][train.py>_log] ==> #125000     Total Loss: 4.798    [weighted Loss:4.798    Policy Loss: 9.210    Value Loss: 6.474    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 71158      Buffer Size: 26816      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:36:29,023][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.164    [weighted Loss:4.164    Policy Loss: 8.459    Value Loss: 6.693    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 71546      Buffer Size: 26442      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:39:05,151][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 8.542    Value Loss: 6.555    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 72059      Buffer Size: 26193      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:41:39,727][train][INFO][train.py>_log] ==> #128000     Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 7.427    Value Loss: 6.222    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 72552      Buffer Size: 25947      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:44:15,401][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 8.610    Value Loss: 6.422    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 72959      Buffer Size: 25955      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:46:51,542][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.050    [weighted Loss:3.050    Policy Loss: 8.215    Value Loss: 6.254    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 73379      Buffer Size: 25997      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:49:29,287][train][INFO][train.py>_log] ==> #131000     Total Loss: 4.486    [weighted Loss:4.486    Policy Loss: 8.259    Value Loss: 6.754    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 73799      Buffer Size: 25576      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:52:05,564][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 7.972    Value Loss: 6.243    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 74256      Buffer Size: 25107      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:54:42,150][train][INFO][train.py>_log] ==> #133000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 8.061    Value Loss: 6.564    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 75164      Buffer Size: 25478      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:57:20,900][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.869    [weighted Loss:2.869    Policy Loss: 8.083    Value Loss: 6.659    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 76109      Buffer Size: 25915      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 11:59:56,993][train][INFO][train.py>_log] ==> #135000     Total Loss: 4.079    [weighted Loss:4.079    Policy Loss: 8.244    Value Loss: 6.352    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 76503      Buffer Size: 25879      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:02:32,542][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.131    [weighted Loss:3.131    Policy Loss: 8.009    Value Loss: 6.384    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 76890      Buffer Size: 25830      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:05:13,284][train][INFO][train.py>_log] ==> #137000     Total Loss: 4.304    [weighted Loss:4.304    Policy Loss: 7.857    Value Loss: 6.258    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 77317      Buffer Size: 25792      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:07:48,671][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 8.360    Value Loss: 6.423    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 77734      Buffer Size: 25735      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:10:27,837][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.874    [weighted Loss:3.874    Policy Loss: 7.502    Value Loss: 6.719    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 78144      Buffer Size: 25585      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:13:05,963][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 7.773    Value Loss: 6.529    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 78542      Buffer Size: 25408      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:15:43,649][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.894    [weighted Loss:2.894    Policy Loss: 7.676    Value Loss: 6.388    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 78985      Buffer Size: 25116      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:18:19,804][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.325    [weighted Loss:3.325    Policy Loss: 7.802    Value Loss: 6.541    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 79407      Buffer Size: 24743      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:20:58,530][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.520    [weighted Loss:3.520    Policy Loss: 8.056    Value Loss: 6.764    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 79838      Buffer Size: 24588      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:23:36,950][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 7.551    Value Loss: 6.209    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 80289      Buffer Size: 24576      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:26:15,616][train][INFO][train.py>_log] ==> #145000     Total Loss: 3.013    [weighted Loss:3.013    Policy Loss: 7.797    Value Loss: 6.302    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 80775      Buffer Size: 24579      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:28:54,255][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.895    [weighted Loss:3.895    Policy Loss: 8.299    Value Loss: 6.472    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 81245      Buffer Size: 24521      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:31:33,192][train][INFO][train.py>_log] ==> #147000     Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 7.398    Value Loss: 6.580    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 81988      Buffer Size: 24762      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:34:12,415][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.968    [weighted Loss:3.968    Policy Loss: 8.296    Value Loss: 6.861    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 82699      Buffer Size: 24985      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:36:50,035][train][INFO][train.py>_log] ==> #149000     Total Loss: 4.579    [weighted Loss:4.579    Policy Loss: 7.884    Value Loss: 6.662    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 83227      Buffer Size: 24748      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:39:28,345][train][INFO][train.py>_log] ==> #150000     Total Loss: 4.316    [weighted Loss:4.316    Policy Loss: 8.606    Value Loss: 6.625    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 83779      Buffer Size: 24467      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:42:09,379][train][INFO][train.py>_log] ==> #151000     Total Loss: 3.959    [weighted Loss:3.959    Policy Loss: 7.266    Value Loss: 6.661    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 84242      Buffer Size: 24208      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:44:50,625][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 7.489    Value Loss: 6.713    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 84677      Buffer Size: 23944      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:47:27,453][train][INFO][train.py>_log] ==> #153000     Total Loss: 4.360    [weighted Loss:4.360    Policy Loss: 8.083    Value Loss: 6.878    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 85127      Buffer Size: 23836      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:50:05,974][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.324    [weighted Loss:2.324    Policy Loss: 8.992    Value Loss: 6.853    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 85605      Buffer Size: 23682      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:52:45,030][train][INFO][train.py>_log] ==> #155000     Total Loss: 4.717    [weighted Loss:4.717    Policy Loss: 9.970    Value Loss: 6.587    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 86212      Buffer Size: 23712      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:55:24,848][train][INFO][train.py>_log] ==> #156000     Total Loss: 4.336    [weighted Loss:4.336    Policy Loss: 9.742    Value Loss: 6.801    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 86808      Buffer Size: 23742      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 12:58:06,889][train][INFO][train.py>_log] ==> #157000     Total Loss: 4.259    [weighted Loss:4.259    Policy Loss: 8.980    Value Loss: 7.228    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 87230      Buffer Size: 23684      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:00:47,937][train][INFO][train.py>_log] ==> #158000     Total Loss: 4.727    [weighted Loss:4.727    Policy Loss: 8.405    Value Loss: 7.083    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 87642      Buffer Size: 23605      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:03:27,555][train][INFO][train.py>_log] ==> #159000     Total Loss: 4.831    [weighted Loss:4.831    Policy Loss: 9.281    Value Loss: 6.610    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 88038      Buffer Size: 23545      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:06:08,297][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 8.479    Value Loss: 6.881    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 88422      Buffer Size: 23460      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:08:48,347][train][INFO][train.py>_log] ==> #161000     Total Loss: 5.032    [weighted Loss:5.032    Policy Loss: 9.112    Value Loss: 6.784    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 88794      Buffer Size: 23324      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:11:28,280][train][INFO][train.py>_log] ==> #162000     Total Loss: 5.126    [weighted Loss:5.126    Policy Loss: 9.138    Value Loss: 7.021    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 89179      Buffer Size: 23133      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:14:05,674][train][INFO][train.py>_log] ==> #163000     Total Loss: 4.212    [weighted Loss:4.212    Policy Loss: 9.700    Value Loss: 6.876    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 89589      Buffer Size: 22915      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:16:45,660][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 7.951    Value Loss: 6.534    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 89993      Buffer Size: 22697      Transition Number: 1000.079k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:19:29,063][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.299    [weighted Loss:3.299    Policy Loss: 8.788    Value Loss: 6.887    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 90365      Buffer Size: 22306      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:22:09,088][train][INFO][train.py>_log] ==> #166000     Total Loss: 4.265    [weighted Loss:4.265    Policy Loss: 7.845    Value Loss: 6.564    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 90767      Buffer Size: 21882      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:24:48,684][train][INFO][train.py>_log] ==> #167000     Total Loss: 4.288    [weighted Loss:4.288    Policy Loss: 9.218    Value Loss: 6.441    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 91164      Buffer Size: 21713      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:27:28,745][train][INFO][train.py>_log] ==> #168000     Total Loss: 5.114    [weighted Loss:5.114    Policy Loss: 8.436    Value Loss: 6.899    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 91576      Buffer Size: 21533      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:30:12,613][train][INFO][train.py>_log] ==> #169000     Total Loss: 4.042    [weighted Loss:4.042    Policy Loss: 9.626    Value Loss: 6.797    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 92480      Buffer Size: 21966      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:32:51,972][train][INFO][train.py>_log] ==> #170000     Total Loss: 4.136    [weighted Loss:4.136    Policy Loss: 9.214    Value Loss: 6.538    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 93485      Buffer Size: 22542      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:35:32,275][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.837    [weighted Loss:3.837    Policy Loss: 10.021   Value Loss: 6.569    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 94287      Buffer Size: 22933      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:38:12,531][train][INFO][train.py>_log] ==> #172000     Total Loss: 4.717    [weighted Loss:4.717    Policy Loss: 9.586    Value Loss: 6.846    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 95085      Buffer Size: 23266      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:40:52,062][train][INFO][train.py>_log] ==> #173000     Total Loss: 4.820    [weighted Loss:4.820    Policy Loss: 9.675    Value Loss: 6.587    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 95655      Buffer Size: 23349      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:43:33,736][train][INFO][train.py>_log] ==> #174000     Total Loss: 4.097    [weighted Loss:4.097    Policy Loss: 8.938    Value Loss: 6.823    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 96279      Buffer Size: 23482      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:46:17,127][train][INFO][train.py>_log] ==> #175000     Total Loss: 5.180    [weighted Loss:5.180    Policy Loss: 9.218    Value Loss: 6.451    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 96896      Buffer Size: 23651      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:48:56,274][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.793    [weighted Loss:3.793    Policy Loss: 9.307    Value Loss: 6.921    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 97496      Buffer Size: 23801      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:51:36,717][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 9.049    Value Loss: 6.949    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 97886      Buffer Size: 23775      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:54:17,976][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.421    [weighted Loss:3.421    Policy Loss: 9.121    Value Loss: 6.769    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 98300      Buffer Size: 23407      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:56:59,000][train][INFO][train.py>_log] ==> #179000     Total Loss: 4.469    [weighted Loss:4.469    Policy Loss: 8.953    Value Loss: 6.344    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 98758      Buffer Size: 22901      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-01-03 13:59:43,238][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.890    [weighted Loss:2.890    Policy Loss: 8.987    Value Loss: 6.706    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 99233      Buffer Size: 22792      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:02:24,046][train][INFO][train.py>_log] ==> #181000     Total Loss: 3.426    [weighted Loss:3.426    Policy Loss: 8.731    Value Loss: 6.719    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 99669      Buffer Size: 22857      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:05:03,348][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.003    [weighted Loss:3.003    Policy Loss: 9.211    Value Loss: 7.115    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 100118     Buffer Size: 22890      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:07:42,247][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.481    [weighted Loss:3.481    Policy Loss: 10.140   Value Loss: 6.504    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 100536     Buffer Size: 22873      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:10:22,356][train][INFO][train.py>_log] ==> #184000     Total Loss: 4.326    [weighted Loss:4.326    Policy Loss: 9.248    Value Loss: 7.200    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 100969     Buffer Size: 22895      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:13:03,846][train][INFO][train.py>_log] ==> #185000     Total Loss: 4.703    [weighted Loss:4.703    Policy Loss: 9.180    Value Loss: 6.781    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 101444     Buffer Size: 22963      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:15:39,329][train][INFO][train.py>_log] ==> #186000     Total Loss: 4.516    [weighted Loss:4.516    Policy Loss: 9.245    Value Loss: 6.646    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 101905     Buffer Size: 22972      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:18:19,267][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.754    [weighted Loss:3.754    Policy Loss: 8.608    Value Loss: 6.732    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 102312     Buffer Size: 22965      Transition Number: 1000.027k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:21:03,383][train][INFO][train.py>_log] ==> #188000     Total Loss: 5.350    [weighted Loss:5.350    Policy Loss: 8.645    Value Loss: 6.443    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 102745     Buffer Size: 22946      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:23:45,956][train][INFO][train.py>_log] ==> #189000     Total Loss: 5.087    [weighted Loss:5.087    Policy Loss: 8.869    Value Loss: 7.249    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 103173     Buffer Size: 22916      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:26:27,662][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.629    [weighted Loss:3.629    Policy Loss: 9.376    Value Loss: 7.374    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 103601     Buffer Size: 22865      Transition Number: 1000.013k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:29:11,070][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 8.565    Value Loss: 7.274    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 104051     Buffer Size: 22851      Transition Number: 1000.028k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:31:51,682][train][INFO][train.py>_log] ==> #192000     Total Loss: 4.502    [weighted Loss:4.502    Policy Loss: 8.399    Value Loss: 6.891    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 104520     Buffer Size: 22618      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:34:31,457][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 7.346    Value Loss: 6.767    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 104956     Buffer Size: 22403      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:37:12,604][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.786    [weighted Loss:3.786    Policy Loss: 7.997    Value Loss: 6.747    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 105418     Buffer Size: 22278      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:39:51,944][train][INFO][train.py>_log] ==> #195000     Total Loss: 4.501    [weighted Loss:4.501    Policy Loss: 8.273    Value Loss: 6.844    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 106053     Buffer Size: 22353      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:42:32,314][train][INFO][train.py>_log] ==> #196000     Total Loss: 4.461    [weighted Loss:4.461    Policy Loss: 7.922    Value Loss: 6.793    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 106702     Buffer Size: 22506      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:45:13,440][train][INFO][train.py>_log] ==> #197000     Total Loss: 4.070    [weighted Loss:4.070    Policy Loss: 7.881    Value Loss: 6.868    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 107145     Buffer Size: 22520      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:47:52,964][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.028    [weighted Loss:3.028    Policy Loss: 8.355    Value Loss: 7.001    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 107610     Buffer Size: 22514      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:50:34,719][train][INFO][train.py>_log] ==> #199000     Total Loss: 4.134    [weighted Loss:4.134    Policy Loss: 8.434    Value Loss: 6.767    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 108064     Buffer Size: 22469      Transition Number: 999.941 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:53:17,892][train][INFO][train.py>_log] ==> #200000     Total Loss: 4.532    [weighted Loss:4.532    Policy Loss: 9.448    Value Loss: 6.647    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 108480     Buffer Size: 22303      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-03 14:56:00,712][train][INFO][train.py>_log] ==> #201000     Total Loss: 4.438    [weighted Loss:4.438    Policy Loss: 7.949    Value Loss: 6.323    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 108955     Buffer Size: 22180      Transition Number: 999.998 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 14:58:44,028][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.771    [weighted Loss:3.771    Policy Loss: 8.680    Value Loss: 6.634    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 109420     Buffer Size: 22217      Transition Number: 1000.000k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:01:25,110][train][INFO][train.py>_log] ==> #203000     Total Loss: 4.252    [weighted Loss:4.252    Policy Loss: 8.503    Value Loss: 6.611    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 109963     Buffer Size: 22298      Transition Number: 999.958 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:04:06,877][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.909    [weighted Loss:3.909    Policy Loss: 8.960    Value Loss: 7.013    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 110465     Buffer Size: 22394      Transition Number: 999.990 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:06:49,386][train][INFO][train.py>_log] ==> #205000     Total Loss: 4.806    [weighted Loss:4.806    Policy Loss: 8.500    Value Loss: 6.923    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 110920     Buffer Size: 22459      Transition Number: 999.957 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:09:31,045][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.992    [weighted Loss:3.992    Policy Loss: 8.221    Value Loss: 6.396    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 111411     Buffer Size: 22544      Transition Number: 999.979 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:12:10,104][train][INFO][train.py>_log] ==> #207000     Total Loss: 4.324    [weighted Loss:4.324    Policy Loss: 9.034    Value Loss: 6.996    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 111827     Buffer Size: 22590      Transition Number: 999.954 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:14:50,085][train][INFO][train.py>_log] ==> #208000     Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 10.890   Value Loss: 7.361    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 112258     Buffer Size: 22608      Transition Number: 1000.047k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:17:33,096][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 8.665    Value Loss: 6.917    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 112690     Buffer Size: 22643      Transition Number: 999.986 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:20:16,142][train][INFO][train.py>_log] ==> #210000     Total Loss: 4.898    [weighted Loss:4.898    Policy Loss: 9.641    Value Loss: 6.942    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 113123     Buffer Size: 22694      Transition Number: 999.953 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:22:57,947][train][INFO][train.py>_log] ==> #211000     Total Loss: 3.972    [weighted Loss:3.972    Policy Loss: 9.065    Value Loss: 7.250    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 113582     Buffer Size: 22762      Transition Number: 999.957 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:25:36,760][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 9.116    Value Loss: 6.915    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 114019     Buffer Size: 22797      Transition Number: 999.988 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:28:16,706][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 9.480    Value Loss: 6.773    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 114475     Buffer Size: 22855      Transition Number: 999.989 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:30:57,059][train][INFO][train.py>_log] ==> #214000     Total Loss: 4.191    [weighted Loss:4.191    Policy Loss: 9.458    Value Loss: 7.097    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 114968     Buffer Size: 22476      Transition Number: 1000.012k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:33:34,374][train][INFO][train.py>_log] ==> #215000     Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 9.190    Value Loss: 6.859    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 115384     Buffer Size: 21951      Transition Number: 999.968 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:36:18,794][train][INFO][train.py>_log] ==> #216000     Total Loss: 4.945    [weighted Loss:4.945    Policy Loss: 9.891    Value Loss: 7.048    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 115828     Buffer Size: 21612      Transition Number: 999.991 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:39:01,792][train][INFO][train.py>_log] ==> #217000     Total Loss: 4.543    [weighted Loss:4.543    Policy Loss: 9.455    Value Loss: 6.869    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 116280     Buffer Size: 21298      Transition Number: 999.951 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:41:43,874][train][INFO][train.py>_log] ==> #218000     Total Loss: 5.299    [weighted Loss:5.299    Policy Loss: 9.978    Value Loss: 6.999    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 116767     Buffer Size: 21142      Transition Number: 999.989 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:44:27,441][train][INFO][train.py>_log] ==> #219000     Total Loss: 4.778    [weighted Loss:4.778    Policy Loss: 10.003   Value Loss: 6.998    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 117242     Buffer Size: 21017      Transition Number: 1000.112k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:47:11,873][train][INFO][train.py>_log] ==> #220000     Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 9.867    Value Loss: 7.030    Reward Loss: 1.152    Consistency Loss: 0.000    ] Replay Episodes Collected: 117732     Buffer Size: 20883      Transition Number: 999.996 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:49:56,062][train][INFO][train.py>_log] ==> #221000     Total Loss: 4.200    [weighted Loss:4.200    Policy Loss: 8.970    Value Loss: 6.945    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 118348     Buffer Size: 20893      Transition Number: 999.992 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:52:37,338][train][INFO][train.py>_log] ==> #222000     Total Loss: 5.032    [weighted Loss:5.032    Policy Loss: 9.743    Value Loss: 7.098    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 118964     Buffer Size: 21062      Transition Number: 999.970 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:55:19,619][train][INFO][train.py>_log] ==> #223000     Total Loss: 4.726    [weighted Loss:4.726    Policy Loss: 8.913    Value Loss: 7.291    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 119393     Buffer Size: 21085      Transition Number: 999.939 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 15:58:01,156][train][INFO][train.py>_log] ==> #224000     Total Loss: 5.076    [weighted Loss:5.076    Policy Loss: 10.113   Value Loss: 7.377    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 119819     Buffer Size: 21072      Transition Number: 999.971 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:00:40,525][train][INFO][train.py>_log] ==> #225000     Total Loss: 5.120    [weighted Loss:5.120    Policy Loss: 9.292    Value Loss: 6.920    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 120279     Buffer Size: 21076      Transition Number: 999.969 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:03:26,221][train][INFO][train.py>_log] ==> #226000     Total Loss: 4.216    [weighted Loss:4.216    Policy Loss: 9.398    Value Loss: 6.862    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 120754     Buffer Size: 21073      Transition Number: 1000.004k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:06:11,575][train][INFO][train.py>_log] ==> #227000     Total Loss: 4.558    [weighted Loss:4.558    Policy Loss: 9.915    Value Loss: 7.093    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 121250     Buffer Size: 21084      Transition Number: 1000.053k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:08:51,899][train][INFO][train.py>_log] ==> #228000     Total Loss: 5.847    [weighted Loss:5.847    Policy Loss: 9.903    Value Loss: 7.110    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 121709     Buffer Size: 21114      Transition Number: 999.958 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:11:35,305][train][INFO][train.py>_log] ==> #229000     Total Loss: 4.102    [weighted Loss:4.102    Policy Loss: 9.720    Value Loss: 6.988    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 122147     Buffer Size: 21121      Transition Number: 999.959 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:14:18,368][train][INFO][train.py>_log] ==> #230000     Total Loss: 4.437    [weighted Loss:4.437    Policy Loss: 9.259    Value Loss: 6.880    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 122589     Buffer Size: 21083      Transition Number: 999.964 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:17:02,647][train][INFO][train.py>_log] ==> #231000     Total Loss: 4.105    [weighted Loss:4.105    Policy Loss: 10.477   Value Loss: 6.779    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 123063     Buffer Size: 21094      Transition Number: 999.939 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:19:42,885][train][INFO][train.py>_log] ==> #232000     Total Loss: 4.356    [weighted Loss:4.356    Policy Loss: 10.090   Value Loss: 6.799    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 123529     Buffer Size: 21143      Transition Number: 999.984 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:22:23,389][train][INFO][train.py>_log] ==> #233000     Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 9.966    Value Loss: 7.054    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 124010     Buffer Size: 21201      Transition Number: 1000.079k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:25:05,808][train][INFO][train.py>_log] ==> #234000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 10.276   Value Loss: 7.229    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 124505     Buffer Size: 21253      Transition Number: 999.985 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:27:46,865][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 10.239   Value Loss: 6.630    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 125081     Buffer Size: 21362      Transition Number: 999.960 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:30:29,647][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.284    [weighted Loss:3.284    Policy Loss: 10.398   Value Loss: 7.697    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 125623     Buffer Size: 21456      Transition Number: 999.972 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:33:11,535][train][INFO][train.py>_log] ==> #237000     Total Loss: 5.695    [weighted Loss:5.695    Policy Loss: 10.399   Value Loss: 6.919    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 126127     Buffer Size: 21504      Transition Number: 999.935 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:35:52,226][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 9.822    Value Loss: 7.206    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 126655     Buffer Size: 21559      Transition Number: 999.992 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:38:35,185][train][INFO][train.py>_log] ==> #239000     Total Loss: 5.962    [weighted Loss:5.962    Policy Loss: 10.135   Value Loss: 7.258    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 127181     Buffer Size: 21570      Transition Number: 999.988 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:41:16,945][train][INFO][train.py>_log] ==> #240000     Total Loss: 4.537    [weighted Loss:4.537    Policy Loss: 9.991    Value Loss: 7.242    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 127728     Buffer Size: 21476      Transition Number: 999.981 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:44:03,004][train][INFO][train.py>_log] ==> #241000     Total Loss: 5.965    [weighted Loss:5.965    Policy Loss: 10.815   Value Loss: 7.546    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 128332     Buffer Size: 21462      Transition Number: 1000.033k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:46:45,214][train][INFO][train.py>_log] ==> #242000     Total Loss: 4.805    [weighted Loss:4.805    Policy Loss: 10.734   Value Loss: 6.852    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 128942     Buffer Size: 21587      Transition Number: 1000.026k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:49:28,567][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.765    [weighted Loss:3.765    Policy Loss: 9.633    Value Loss: 7.174    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 129570     Buffer Size: 21748      Transition Number: 999.964 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:52:11,347][train][INFO][train.py>_log] ==> #244000     Total Loss: 4.410    [weighted Loss:4.410    Policy Loss: 10.648   Value Loss: 7.284    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 130212     Buffer Size: 21927      Transition Number: 999.959 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:54:53,142][train][INFO][train.py>_log] ==> #245000     Total Loss: 3.346    [weighted Loss:3.346    Policy Loss: 10.418   Value Loss: 7.163    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 130797     Buffer Size: 22063      Transition Number: 999.945 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 16:57:34,276][train][INFO][train.py>_log] ==> #246000     Total Loss: 5.045    [weighted Loss:5.045    Policy Loss: 10.260   Value Loss: 7.348    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 131409     Buffer Size: 22174      Transition Number: 999.986 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:00:12,497][train][INFO][train.py>_log] ==> #247000     Total Loss: 4.076    [weighted Loss:4.076    Policy Loss: 9.943    Value Loss: 7.337    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 131919     Buffer Size: 22189      Transition Number: 1000.000k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:02:56,950][train][INFO][train.py>_log] ==> #248000     Total Loss: 4.184    [weighted Loss:4.184    Policy Loss: 9.089    Value Loss: 6.969    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 132432     Buffer Size: 22181      Transition Number: 1000.080k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:05:35,326][train][INFO][train.py>_log] ==> #249000     Total Loss: 4.421    [weighted Loss:4.421    Policy Loss: 10.828   Value Loss: 7.093    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 132971     Buffer Size: 22246      Transition Number: 999.971 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:08:20,196][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.461    [weighted Loss:2.461    Policy Loss: 9.369    Value Loss: 6.970    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 133534     Buffer Size: 22324      Transition Number: 999.969 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:11:01,208][train][INFO][train.py>_log] ==> #251000     Total Loss: 4.625    [weighted Loss:4.625    Policy Loss: 10.555   Value Loss: 7.122    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 134145     Buffer Size: 22453      Transition Number: 999.963 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:13:43,090][train][INFO][train.py>_log] ==> #252000     Total Loss: 3.676    [weighted Loss:3.676    Policy Loss: 10.058   Value Loss: 7.230    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 134736     Buffer Size: 22588      Transition Number: 999.966 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:16:24,758][train][INFO][train.py>_log] ==> #253000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 9.863    Value Loss: 7.348    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 135225     Buffer Size: 22653      Transition Number: 999.940 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:19:07,746][train][INFO][train.py>_log] ==> #254000     Total Loss: 4.805    [weighted Loss:4.805    Policy Loss: 9.558    Value Loss: 7.204    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 135745     Buffer Size: 22720      Transition Number: 999.989 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:21:50,227][train][INFO][train.py>_log] ==> #255000     Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 9.073    Value Loss: 7.297    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 136158     Buffer Size: 22708      Transition Number: 1000.106k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:24:33,502][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 9.215    Value Loss: 7.050    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 136571     Buffer Size: 22666      Transition Number: 999.986 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:27:13,363][train][INFO][train.py>_log] ==> #257000     Total Loss: 4.194    [weighted Loss:4.194    Policy Loss: 9.362    Value Loss: 6.887    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 137002     Buffer Size: 22641      Transition Number: 1000.063k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:29:54,447][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 9.898    Value Loss: 7.082    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 137434     Buffer Size: 22598      Transition Number: 1000.006k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:32:36,395][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 9.328    Value Loss: 7.147    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 137928     Buffer Size: 22616      Transition Number: 999.948 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:35:18,419][train][INFO][train.py>_log] ==> #260000     Total Loss: 4.501    [weighted Loss:4.501    Policy Loss: 9.841    Value Loss: 7.313    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 138447     Buffer Size: 22687      Transition Number: 1000.136k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:38:01,353][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.411    [weighted Loss:3.411    Policy Loss: 9.483    Value Loss: 7.176    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 138914     Buffer Size: 22705      Transition Number: 999.978 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:40:42,310][train][INFO][train.py>_log] ==> #262000     Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 8.838    Value Loss: 6.963    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 139375     Buffer Size: 22696      Transition Number: 999.970 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:43:20,259][train][INFO][train.py>_log] ==> #263000     Total Loss: 4.660    [weighted Loss:4.660    Policy Loss: 9.333    Value Loss: 7.530    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 139787     Buffer Size: 22652      Transition Number: 1000.118k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:45:59,753][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.674    [weighted Loss:3.674    Policy Loss: 9.391    Value Loss: 7.029    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 140219     Buffer Size: 22623      Transition Number: 999.973 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:48:41,083][train][INFO][train.py>_log] ==> #265000     Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 9.966    Value Loss: 7.157    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 140650     Buffer Size: 22485      Transition Number: 999.981 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:51:23,108][train][INFO][train.py>_log] ==> #266000     Total Loss: 4.633    [weighted Loss:4.633    Policy Loss: 9.252    Value Loss: 7.568    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 141069     Buffer Size: 22304      Transition Number: 999.982 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:54:02,289][train][INFO][train.py>_log] ==> #267000     Total Loss: 5.307    [weighted Loss:5.307    Policy Loss: 10.447   Value Loss: 7.373    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 141527     Buffer Size: 22277      Transition Number: 999.997 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:56:46,918][train][INFO][train.py>_log] ==> #268000     Total Loss: 4.061    [weighted Loss:4.061    Policy Loss: 9.669    Value Loss: 7.615    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 142023     Buffer Size: 22336      Transition Number: 999.994 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 17:59:26,522][train][INFO][train.py>_log] ==> #269000     Total Loss: 4.649    [weighted Loss:4.649    Policy Loss: 10.576   Value Loss: 7.783    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 142518     Buffer Size: 22399      Transition Number: 999.941 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:02:08,879][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.977    [weighted Loss:3.977    Policy Loss: 9.972    Value Loss: 6.971    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 143060     Buffer Size: 22476      Transition Number: 999.949 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:04:50,696][train][INFO][train.py>_log] ==> #271000     Total Loss: 3.457    [weighted Loss:3.457    Policy Loss: 10.272   Value Loss: 7.087    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 143519     Buffer Size: 22460      Transition Number: 999.990 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:07:32,762][train][INFO][train.py>_log] ==> #272000     Total Loss: 4.003    [weighted Loss:4.003    Policy Loss: 9.690    Value Loss: 6.838    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 143952     Buffer Size: 22436      Transition Number: 999.964 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:10:13,802][train][INFO][train.py>_log] ==> #273000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 9.605    Value Loss: 7.565    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 144450     Buffer Size: 22468      Transition Number: 999.985 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:12:57,600][train][INFO][train.py>_log] ==> #274000     Total Loss: 4.461    [weighted Loss:4.461    Policy Loss: 9.682    Value Loss: 7.282    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 144915     Buffer Size: 22481      Transition Number: 999.990 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:15:39,243][train][INFO][train.py>_log] ==> #275000     Total Loss: 4.598    [weighted Loss:4.598    Policy Loss: 9.537    Value Loss: 7.435    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 145473     Buffer Size: 22526      Transition Number: 999.993 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:18:21,208][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 10.301   Value Loss: 7.031    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 145995     Buffer Size: 22574      Transition Number: 999.939 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:20:59,251][train][INFO][train.py>_log] ==> #277000     Total Loss: 3.189    [weighted Loss:3.189    Policy Loss: 9.969    Value Loss: 7.090    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 146443     Buffer Size: 22558      Transition Number: 999.973 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:23:39,751][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.413    [weighted Loss:3.413    Policy Loss: 11.053   Value Loss: 7.373    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 146938     Buffer Size: 22555      Transition Number: 999.976 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:26:18,770][train][INFO][train.py>_log] ==> #279000     Total Loss: 5.210    [weighted Loss:5.210    Policy Loss: 10.322   Value Loss: 7.378    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 147560     Buffer Size: 22607      Transition Number: 999.957 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:28:58,887][train][INFO][train.py>_log] ==> #280000     Total Loss: 5.930    [weighted Loss:5.930    Policy Loss: 11.133   Value Loss: 7.334    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 148196     Buffer Size: 22673      Transition Number: 1000.065k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:31:39,611][train][INFO][train.py>_log] ==> #281000     Total Loss: 4.791    [weighted Loss:4.791    Policy Loss: 10.541   Value Loss: 7.559    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 148784     Buffer Size: 22733      Transition Number: 999.992 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:34:20,252][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.756    [weighted Loss:2.756    Policy Loss: 10.441   Value Loss: 7.105    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 149426     Buffer Size: 22832      Transition Number: 999.966 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:37:02,705][train][INFO][train.py>_log] ==> #283000     Total Loss: 5.240    [weighted Loss:5.240    Policy Loss: 10.313   Value Loss: 7.363    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 149950     Buffer Size: 22839      Transition Number: 999.974 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:39:44,075][train][INFO][train.py>_log] ==> #284000     Total Loss: 4.201    [weighted Loss:4.201    Policy Loss: 10.024   Value Loss: 7.335    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 150491     Buffer Size: 22812      Transition Number: 999.980 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:42:26,116][train][INFO][train.py>_log] ==> #285000     Total Loss: 4.906    [weighted Loss:4.906    Policy Loss: 9.592    Value Loss: 7.685    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 150948     Buffer Size: 22714      Transition Number: 1000.040k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:45:09,084][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 10.592   Value Loss: 7.403    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 151443     Buffer Size: 22605      Transition Number: 1000.114k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:47:53,765][train][INFO][train.py>_log] ==> #287000     Total Loss: 5.210    [weighted Loss:5.210    Policy Loss: 9.982    Value Loss: 7.113    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 151956     Buffer Size: 22471      Transition Number: 999.993 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:50:36,417][train][INFO][train.py>_log] ==> #288000     Total Loss: 5.588    [weighted Loss:5.588    Policy Loss: 9.769    Value Loss: 7.135    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 152451     Buffer Size: 22366      Transition Number: 999.991 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:53:18,918][train][INFO][train.py>_log] ==> #289000     Total Loss: 4.161    [weighted Loss:4.161    Policy Loss: 9.198    Value Loss: 7.090    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 152909     Buffer Size: 22232      Transition Number: 999.964 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:56:00,185][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.199    [weighted Loss:3.199    Policy Loss: 10.697   Value Loss: 7.255    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 153372     Buffer Size: 22105      Transition Number: 999.980 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 18:58:41,012][train][INFO][train.py>_log] ==> #291000     Total Loss: 5.677    [weighted Loss:5.677    Policy Loss: 11.010   Value Loss: 7.167    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 153844     Buffer Size: 22035      Transition Number: 1000.009k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:01:26,153][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.496    [weighted Loss:2.496    Policy Loss: 10.523   Value Loss: 7.330    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 154350     Buffer Size: 21992      Transition Number: 999.985 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:04:14,344][train][INFO][train.py>_log] ==> #293000     Total Loss: 4.938    [weighted Loss:4.938    Policy Loss: 10.136   Value Loss: 7.220    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 154877     Buffer Size: 21954      Transition Number: 1000.006k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:06:59,163][train][INFO][train.py>_log] ==> #294000     Total Loss: 3.789    [weighted Loss:3.789    Policy Loss: 10.890   Value Loss: 7.224    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 155416     Buffer Size: 21934      Transition Number: 1000.114k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:09:44,168][train][INFO][train.py>_log] ==> #295000     Total Loss: 4.618    [weighted Loss:4.618    Policy Loss: 11.231   Value Loss: 7.198    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 155994     Buffer Size: 21904      Transition Number: 1000.000k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:12:30,383][train][INFO][train.py>_log] ==> #296000     Total Loss: 4.064    [weighted Loss:4.064    Policy Loss: 11.123   Value Loss: 7.190    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 156564     Buffer Size: 21890      Transition Number: 999.992 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:15:17,110][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.025    [weighted Loss:3.025    Policy Loss: 10.760   Value Loss: 7.139    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 157121     Buffer Size: 21916      Transition Number: 999.990 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:17:59,773][train][INFO][train.py>_log] ==> #298000     Total Loss: 4.779    [weighted Loss:4.779    Policy Loss: 10.250   Value Loss: 7.219    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 157689     Buffer Size: 21964      Transition Number: 999.956 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:20:40,247][train][INFO][train.py>_log] ==> #299000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 11.108   Value Loss: 7.211    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 158197     Buffer Size: 22033      Transition Number: 999.953 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:23:22,746][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 9.298    Value Loss: 7.203    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 158732     Buffer Size: 22133      Transition Number: 999.968 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:26:04,591][train][INFO][train.py>_log] ==> #301000     Total Loss: 4.036    [weighted Loss:4.036    Policy Loss: 11.464   Value Loss: 7.230    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 159252     Buffer Size: 22180      Transition Number: 1000.193k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:28:46,345][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.715    [weighted Loss:2.715    Policy Loss: 10.014   Value Loss: 7.167    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 159732     Buffer Size: 22211      Transition Number: 999.987 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:31:28,687][train][INFO][train.py>_log] ==> #303000     Total Loss: 4.420    [weighted Loss:4.420    Policy Loss: 11.006   Value Loss: 7.399    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 160227     Buffer Size: 22235      Transition Number: 1000.053k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:34:10,982][train][INFO][train.py>_log] ==> #304000     Total Loss: 4.832    [weighted Loss:4.832    Policy Loss: 10.093   Value Loss: 7.179    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 160714     Buffer Size: 22220      Transition Number: 1000.033k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:36:54,411][train][INFO][train.py>_log] ==> #305000     Total Loss: 5.565    [weighted Loss:5.565    Policy Loss: 10.376   Value Loss: 7.305    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 161156     Buffer Size: 22196      Transition Number: 999.995 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:39:37,090][train][INFO][train.py>_log] ==> #306000     Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 9.725    Value Loss: 7.437    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 161619     Buffer Size: 22198      Transition Number: 999.983 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:42:17,125][train][INFO][train.py>_log] ==> #307000     Total Loss: 4.211    [weighted Loss:4.211    Policy Loss: 10.220   Value Loss: 7.093    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 162112     Buffer Size: 22260      Transition Number: 999.982 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:44:58,073][train][INFO][train.py>_log] ==> #308000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 10.366   Value Loss: 7.084    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 162587     Buffer Size: 22293      Transition Number: 999.964 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:47:42,116][train][INFO][train.py>_log] ==> #309000     Total Loss: 3.989    [weighted Loss:3.989    Policy Loss: 10.516   Value Loss: 7.438    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 163063     Buffer Size: 22327      Transition Number: 999.985 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:50:26,401][train][INFO][train.py>_log] ==> #310000     Total Loss: 4.563    [weighted Loss:4.563    Policy Loss: 11.516   Value Loss: 7.687    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 163568     Buffer Size: 22376      Transition Number: 999.961 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:53:06,723][train][INFO][train.py>_log] ==> #311000     Total Loss: 5.442    [weighted Loss:5.442    Policy Loss: 10.183   Value Loss: 7.279    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 164127     Buffer Size: 22441      Transition Number: 999.982 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:55:50,674][train][INFO][train.py>_log] ==> #312000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 9.450    Value Loss: 6.989    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 164679     Buffer Size: 22482      Transition Number: 999.982 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 19:58:32,655][train][INFO][train.py>_log] ==> #313000     Total Loss: 5.693    [weighted Loss:5.693    Policy Loss: 10.559   Value Loss: 7.161    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 165277     Buffer Size: 22526      Transition Number: 999.998 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:01:13,868][train][INFO][train.py>_log] ==> #314000     Total Loss: 5.962    [weighted Loss:5.962    Policy Loss: 11.001   Value Loss: 7.231    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 165888     Buffer Size: 22613      Transition Number: 999.996 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:03:56,927][train][INFO][train.py>_log] ==> #315000     Total Loss: 4.752    [weighted Loss:4.752    Policy Loss: 10.789   Value Loss: 7.303    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 166548     Buffer Size: 22813      Transition Number: 999.950 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:06:37,650][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.740    [weighted Loss:3.740    Policy Loss: 10.910   Value Loss: 7.293    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 167212     Buffer Size: 22992      Transition Number: 999.968 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:09:19,332][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 10.816   Value Loss: 7.303    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 167725     Buffer Size: 23040      Transition Number: 1000.011k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:12:00,149][train][INFO][train.py>_log] ==> #318000     Total Loss: 4.172    [weighted Loss:4.172    Policy Loss: 10.505   Value Loss: 7.417    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 168274     Buffer Size: 23106      Transition Number: 999.983 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:14:39,091][train][INFO][train.py>_log] ==> #319000     Total Loss: 4.019    [weighted Loss:4.019    Policy Loss: 9.934    Value Loss: 6.939    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 168673     Buffer Size: 23022      Transition Number: 999.967 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:17:25,330][train][INFO][train.py>_log] ==> #320000     Total Loss: 4.792    [weighted Loss:4.792    Policy Loss: 9.167    Value Loss: 7.166    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 169094     Buffer Size: 22949      Transition Number: 1000.067k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:20:08,353][train][INFO][train.py>_log] ==> #321000     Total Loss: 3.598    [weighted Loss:3.598    Policy Loss: 10.061   Value Loss: 7.243    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 169565     Buffer Size: 22932      Transition Number: 1000.000k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:22:52,331][train][INFO][train.py>_log] ==> #322000     Total Loss: 4.695    [weighted Loss:4.695    Policy Loss: 9.443    Value Loss: 7.534    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 170033     Buffer Size: 22867      Transition Number: 1000.028k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:25:36,743][train][INFO][train.py>_log] ==> #323000     Total Loss: 4.683    [weighted Loss:4.683    Policy Loss: 9.899    Value Loss: 7.345    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 170492     Buffer Size: 22694      Transition Number: 999.987 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:28:18,943][train][INFO][train.py>_log] ==> #324000     Total Loss: 3.478    [weighted Loss:3.478    Policy Loss: 9.905    Value Loss: 7.306    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 170961     Buffer Size: 22526      Transition Number: 999.970 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:31:00,708][train][INFO][train.py>_log] ==> #325000     Total Loss: 4.817    [weighted Loss:4.817    Policy Loss: 9.954    Value Loss: 7.349    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 171397     Buffer Size: 22385      Transition Number: 999.986 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:33:47,524][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 10.775   Value Loss: 7.388    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 171868     Buffer Size: 22267      Transition Number: 999.970 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:36:30,933][train][INFO][train.py>_log] ==> #327000     Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 9.853    Value Loss: 7.616    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 172358     Buffer Size: 22236      Transition Number: 1000.104k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:39:16,238][train][INFO][train.py>_log] ==> #328000     Total Loss: 4.348    [weighted Loss:4.348    Policy Loss: 9.567    Value Loss: 7.031    Reward Loss: 1.270    Consistency Loss: 0.000    ] Replay Episodes Collected: 172847     Buffer Size: 22203      Transition Number: 999.990 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:41:59,141][train][INFO][train.py>_log] ==> #329000     Total Loss: 3.695    [weighted Loss:3.695    Policy Loss: 9.520    Value Loss: 7.346    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 173332     Buffer Size: 22215      Transition Number: 1000.028k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:44:43,141][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.745    [weighted Loss:3.745    Policy Loss: 10.818   Value Loss: 7.464    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 173831     Buffer Size: 22222      Transition Number: 999.957 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:47:26,066][train][INFO][train.py>_log] ==> #331000     Total Loss: 4.388    [weighted Loss:4.388    Policy Loss: 10.359   Value Loss: 7.272    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 174375     Buffer Size: 22261      Transition Number: 999.955 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:50:09,023][train][INFO][train.py>_log] ==> #332000     Total Loss: 5.537    [weighted Loss:5.537    Policy Loss: 10.343   Value Loss: 7.291    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 174876     Buffer Size: 22269      Transition Number: 1000.087k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:52:55,682][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.708    [weighted Loss:3.708    Policy Loss: 9.903    Value Loss: 7.489    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 175388     Buffer Size: 22311      Transition Number: 1000.031k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:55:38,652][train][INFO][train.py>_log] ==> #334000     Total Loss: 4.684    [weighted Loss:4.684    Policy Loss: 9.646    Value Loss: 7.456    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 175871     Buffer Size: 22335      Transition Number: 999.959 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 20:58:20,610][train][INFO][train.py>_log] ==> #335000     Total Loss: 3.720    [weighted Loss:3.720    Policy Loss: 10.146   Value Loss: 7.056    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 176350     Buffer Size: 22325      Transition Number: 999.990 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:01:00,846][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.281    [weighted Loss:3.281    Policy Loss: 10.338   Value Loss: 7.297    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 176832     Buffer Size: 22317      Transition Number: 999.962 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:03:42,945][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 9.634    Value Loss: 7.200    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 177335     Buffer Size: 22306      Transition Number: 999.990 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:06:27,079][train][INFO][train.py>_log] ==> #338000     Total Loss: 4.676    [weighted Loss:4.676    Policy Loss: 10.400   Value Loss: 7.528    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 177834     Buffer Size: 22286      Transition Number: 1000.044k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:09:10,568][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.750    [weighted Loss:2.750    Policy Loss: 9.976    Value Loss: 7.017    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 178351     Buffer Size: 22218      Transition Number: 999.949 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:11:55,086][train][INFO][train.py>_log] ==> #340000     Total Loss: 4.205    [weighted Loss:4.205    Policy Loss: 9.514    Value Loss: 7.552    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 178856     Buffer Size: 22160      Transition Number: 999.972 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:14:39,645][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 9.653    Value Loss: 6.740    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 179309     Buffer Size: 22058      Transition Number: 999.974 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:17:26,127][train][INFO][train.py>_log] ==> #342000     Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 10.127   Value Loss: 6.900    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 179791     Buffer Size: 21985      Transition Number: 999.990 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:20:10,765][train][INFO][train.py>_log] ==> #343000     Total Loss: 3.635    [weighted Loss:3.635    Policy Loss: 10.203   Value Loss: 6.984    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 180309     Buffer Size: 21965      Transition Number: 999.985 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:22:53,954][train][INFO][train.py>_log] ==> #344000     Total Loss: 4.089    [weighted Loss:4.089    Policy Loss: 10.939   Value Loss: 7.144    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 180832     Buffer Size: 21966      Transition Number: 1000.069k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:25:39,774][train][INFO][train.py>_log] ==> #345000     Total Loss: 4.648    [weighted Loss:4.648    Policy Loss: 10.705   Value Loss: 7.211    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 181389     Buffer Size: 22011      Transition Number: 999.935 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:28:22,782][train][INFO][train.py>_log] ==> #346000     Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 11.895   Value Loss: 7.670    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 181946     Buffer Size: 22078      Transition Number: 999.985 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:31:07,990][train][INFO][train.py>_log] ==> #347000     Total Loss: 4.051    [weighted Loss:4.051    Policy Loss: 10.394   Value Loss: 7.783    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 182415     Buffer Size: 22037      Transition Number: 999.992 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:33:52,409][train][INFO][train.py>_log] ==> #348000     Total Loss: 5.496    [weighted Loss:5.496    Policy Loss: 10.716   Value Loss: 7.175    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 182900     Buffer Size: 22039      Transition Number: 999.947 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:36:38,227][train][INFO][train.py>_log] ==> #349000     Total Loss: 4.569    [weighted Loss:4.569    Policy Loss: 11.160   Value Loss: 7.361    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 183617     Buffer Size: 22280      Transition Number: 1000.001k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:39:21,359][train][INFO][train.py>_log] ==> #350000     Total Loss: 4.554    [weighted Loss:4.554    Policy Loss: 10.478   Value Loss: 7.306    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 184301     Buffer Size: 22480      Transition Number: 999.984 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:42:05,172][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 10.985   Value Loss: 7.703    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 184848     Buffer Size: 22515      Transition Number: 1000.109k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:44:49,793][train][INFO][train.py>_log] ==> #352000     Total Loss: 5.154    [weighted Loss:5.154    Policy Loss: 10.095   Value Loss: 6.775    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 185411     Buffer Size: 22572      Transition Number: 999.975 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:47:33,146][train][INFO][train.py>_log] ==> #353000     Total Loss: 4.797    [weighted Loss:4.797    Policy Loss: 10.827   Value Loss: 7.528    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 185932     Buffer Size: 22599      Transition Number: 999.957 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:50:16,909][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 9.294    Value Loss: 7.170    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 186462     Buffer Size: 22603      Transition Number: 999.955 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:53:03,418][train][INFO][train.py>_log] ==> #355000     Total Loss: 4.447    [weighted Loss:4.447    Policy Loss: 9.966    Value Loss: 7.132    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 187120     Buffer Size: 22700      Transition Number: 999.971 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:55:45,916][train][INFO][train.py>_log] ==> #356000     Total Loss: 5.833    [weighted Loss:5.833    Policy Loss: 11.115   Value Loss: 7.528    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 187784     Buffer Size: 22801      Transition Number: 1000.016k Batch Size: 256        Lr: 0.08000 
[2022-01-03 21:58:24,953][train][INFO][train.py>_log] ==> #357000     Total Loss: 4.443    [weighted Loss:4.443    Policy Loss: 13.340   Value Loss: 7.790    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 188337     Buffer Size: 22761      Transition Number: 1000.004k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:01:07,717][train][INFO][train.py>_log] ==> #358000     Total Loss: 4.714    [weighted Loss:4.714    Policy Loss: 10.547   Value Loss: 7.089    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 188922     Buffer Size: 22710      Transition Number: 1000.030k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:03:52,502][train][INFO][train.py>_log] ==> #359000     Total Loss: 4.367    [weighted Loss:4.367    Policy Loss: 11.359   Value Loss: 6.976    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 189509     Buffer Size: 22617      Transition Number: 999.982 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:06:37,668][train][INFO][train.py>_log] ==> #360000     Total Loss: 3.328    [weighted Loss:3.328    Policy Loss: 10.516   Value Loss: 7.553    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 190082     Buffer Size: 22573      Transition Number: 1000.019k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:09:18,317][train][INFO][train.py>_log] ==> #361000     Total Loss: 5.378    [weighted Loss:5.378    Policy Loss: 11.361   Value Loss: 7.133    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 190580     Buffer Size: 22541      Transition Number: 999.988 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:12:04,861][train][INFO][train.py>_log] ==> #362000     Total Loss: 4.702    [weighted Loss:4.702    Policy Loss: 10.612   Value Loss: 7.664    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 191105     Buffer Size: 22573      Transition Number: 999.958 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:14:47,048][train][INFO][train.py>_log] ==> #363000     Total Loss: 5.559    [weighted Loss:5.559    Policy Loss: 11.609   Value Loss: 7.078    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 191680     Buffer Size: 22699      Transition Number: 1000.070k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:17:33,760][train][INFO][train.py>_log] ==> #364000     Total Loss: 4.197    [weighted Loss:4.197    Policy Loss: 10.312   Value Loss: 7.080    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 192259     Buffer Size: 22788      Transition Number: 999.984 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:20:18,223][train][INFO][train.py>_log] ==> #365000     Total Loss: 3.175    [weighted Loss:3.175    Policy Loss: 10.716   Value Loss: 7.285    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 192783     Buffer Size: 22863      Transition Number: 1000.024k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:23:04,535][train][INFO][train.py>_log] ==> #366000     Total Loss: 4.037    [weighted Loss:4.037    Policy Loss: 10.796   Value Loss: 7.484    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 193349     Buffer Size: 22950      Transition Number: 1000.024k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:25:44,815][train][INFO][train.py>_log] ==> #367000     Total Loss: 3.958    [weighted Loss:3.958    Policy Loss: 11.454   Value Loss: 7.213    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 193817     Buffer Size: 22979      Transition Number: 999.963 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:28:28,274][train][INFO][train.py>_log] ==> #368000     Total Loss: 4.446    [weighted Loss:4.446    Policy Loss: 10.233   Value Loss: 7.232    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 194305     Buffer Size: 23002      Transition Number: 999.993 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:31:12,442][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 10.398   Value Loss: 7.560    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 194734     Buffer Size: 22976      Transition Number: 999.994 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:33:52,240][train][INFO][train.py>_log] ==> #370000     Total Loss: 3.636    [weighted Loss:3.636    Policy Loss: 10.420   Value Loss: 7.870    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 195156     Buffer Size: 22945      Transition Number: 999.996 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:36:36,194][train][INFO][train.py>_log] ==> #371000     Total Loss: 4.575    [weighted Loss:4.575    Policy Loss: 10.506   Value Loss: 7.281    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 195606     Buffer Size: 22931      Transition Number: 1000.081k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:39:19,124][train][INFO][train.py>_log] ==> #372000     Total Loss: 3.156    [weighted Loss:3.156    Policy Loss: 10.033   Value Loss: 6.956    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 196053     Buffer Size: 22900      Transition Number: 999.942 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:42:01,321][train][INFO][train.py>_log] ==> #373000     Total Loss: 3.257    [weighted Loss:3.257    Policy Loss: 10.219   Value Loss: 6.898    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 196585     Buffer Size: 22937      Transition Number: 999.967 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:44:43,104][train][INFO][train.py>_log] ==> #374000     Total Loss: 4.686    [weighted Loss:4.686    Policy Loss: 10.630   Value Loss: 7.504    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 197105     Buffer Size: 22947      Transition Number: 999.996 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:47:27,776][train][INFO][train.py>_log] ==> #375000     Total Loss: 3.819    [weighted Loss:3.819    Policy Loss: 10.687   Value Loss: 7.244    Reward Loss: 1.152    Consistency Loss: 0.000    ] Replay Episodes Collected: 197569     Buffer Size: 22885      Transition Number: 999.999 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:50:08,942][train][INFO][train.py>_log] ==> #376000     Total Loss: 4.478    [weighted Loss:4.478    Policy Loss: 9.971    Value Loss: 7.510    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 198010     Buffer Size: 22832      Transition Number: 999.964 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:52:51,620][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 10.306   Value Loss: 6.915    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 198505     Buffer Size: 22839      Transition Number: 999.983 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:55:32,199][train][INFO][train.py>_log] ==> #378000     Total Loss: 5.245    [weighted Loss:5.245    Policy Loss: 10.499   Value Loss: 7.624    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 198994     Buffer Size: 22847      Transition Number: 999.995 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 22:58:13,696][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 10.899   Value Loss: 7.316    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 199495     Buffer Size: 22879      Transition Number: 999.961 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:01:01,020][train][INFO][train.py>_log] ==> #380000     Total Loss: 5.093    [weighted Loss:5.093    Policy Loss: 10.265   Value Loss: 6.910    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 199992     Buffer Size: 22867      Transition Number: 999.959 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:03:43,899][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 10.812   Value Loss: 7.409    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 200474     Buffer Size: 22867      Transition Number: 999.976 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:06:27,976][train][INFO][train.py>_log] ==> #382000     Total Loss: 4.556    [weighted Loss:4.556    Policy Loss: 10.006   Value Loss: 7.629    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 201004     Buffer Size: 22890      Transition Number: 999.967 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:09:12,207][train][INFO][train.py>_log] ==> #383000     Total Loss: 4.737    [weighted Loss:4.737    Policy Loss: 11.766   Value Loss: 7.699    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 201714     Buffer Size: 23060      Transition Number: 999.992 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:11:54,129][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 10.849   Value Loss: 7.346    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 202409     Buffer Size: 23270      Transition Number: 999.972 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:14:32,499][train][INFO][train.py>_log] ==> #385000     Total Loss: 4.438    [weighted Loss:4.438    Policy Loss: 10.855   Value Loss: 7.819    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 202910     Buffer Size: 23334      Transition Number: 999.935 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:17:14,983][train][INFO][train.py>_log] ==> #386000     Total Loss: 4.500    [weighted Loss:4.500    Policy Loss: 10.641   Value Loss: 7.406    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 203463     Buffer Size: 23405      Transition Number: 999.991 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:19:58,236][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 10.633   Value Loss: 7.438    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 204034     Buffer Size: 23451      Transition Number: 999.974 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:22:43,108][train][INFO][train.py>_log] ==> #388000     Total Loss: 5.121    [weighted Loss:5.121    Policy Loss: 10.835   Value Loss: 7.078    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 204614     Buffer Size: 23476      Transition Number: 1000.112k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:25:25,335][train][INFO][train.py>_log] ==> #389000     Total Loss: 5.291    [weighted Loss:5.291    Policy Loss: 10.632   Value Loss: 7.417    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 205158     Buffer Size: 23470      Transition Number: 999.969 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:28:11,477][train][INFO][train.py>_log] ==> #390000     Total Loss: 4.767    [weighted Loss:4.767    Policy Loss: 10.259   Value Loss: 7.455    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 205757     Buffer Size: 23543      Transition Number: 1000.131k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:30:53,875][train][INFO][train.py>_log] ==> #391000     Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 10.392   Value Loss: 7.320    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 206244     Buffer Size: 23553      Transition Number: 999.968 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:33:34,654][train][INFO][train.py>_log] ==> #392000     Total Loss: 4.313    [weighted Loss:4.313    Policy Loss: 11.338   Value Loss: 7.488    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 206711     Buffer Size: 23469      Transition Number: 999.997 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:36:17,172][train][INFO][train.py>_log] ==> #393000     Total Loss: 5.025    [weighted Loss:5.025    Policy Loss: 10.378   Value Loss: 7.823    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 207559     Buffer Size: 23575      Transition Number: 999.960 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:38:59,255][train][INFO][train.py>_log] ==> #394000     Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 10.025   Value Loss: 7.504    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 208408     Buffer Size: 23812      Transition Number: 999.988 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:41:41,095][train][INFO][train.py>_log] ==> #395000     Total Loss: 4.064    [weighted Loss:4.064    Policy Loss: 11.167   Value Loss: 7.845    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 209002     Buffer Size: 23891      Transition Number: 999.943 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:44:26,390][train][INFO][train.py>_log] ==> #396000     Total Loss: 4.275    [weighted Loss:4.275    Policy Loss: 10.245   Value Loss: 7.926    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 209549     Buffer Size: 23883      Transition Number: 999.998 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:47:10,530][train][INFO][train.py>_log] ==> #397000     Total Loss: 4.953    [weighted Loss:4.953    Policy Loss: 11.095   Value Loss: 7.927    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 210078     Buffer Size: 23896      Transition Number: 999.940 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:49:55,554][train][INFO][train.py>_log] ==> #398000     Total Loss: 3.869    [weighted Loss:3.869    Policy Loss: 9.855    Value Loss: 7.350    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 210612     Buffer Size: 23827      Transition Number: 999.981 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:52:41,043][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.726    [weighted Loss:3.726    Policy Loss: 10.950   Value Loss: 7.476    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 211190     Buffer Size: 23724      Transition Number: 999.959 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:55:26,119][train][INFO][train.py>_log] ==> #400000     Total Loss: 3.714    [weighted Loss:3.714    Policy Loss: 9.432    Value Loss: 7.357    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 211759     Buffer Size: 23673      Transition Number: 999.949 k Batch Size: 256        Lr: 0.08000 
[2022-01-03 23:58:13,141][train][INFO][train.py>_log] ==> #401000     Total Loss: 4.241    [weighted Loss:4.241    Policy Loss: 9.442    Value Loss: 7.100    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 212246     Buffer Size: 23603      Transition Number: 999.996 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:00:54,500][train][INFO][train.py>_log] ==> #402000     Total Loss: 4.575    [weighted Loss:4.575    Policy Loss: 9.922    Value Loss: 7.485    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 212730     Buffer Size: 23519      Transition Number: 999.987 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:03:34,023][train][INFO][train.py>_log] ==> #403000     Total Loss: 3.322    [weighted Loss:3.322    Policy Loss: 9.774    Value Loss: 7.263    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 213223     Buffer Size: 23472      Transition Number: 999.973 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:06:18,493][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 9.775    Value Loss: 7.417    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 213726     Buffer Size: 23428      Transition Number: 999.987 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:09:02,213][train][INFO][train.py>_log] ==> #405000     Total Loss: 3.925    [weighted Loss:3.925    Policy Loss: 10.761   Value Loss: 8.147    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 214185     Buffer Size: 23393      Transition Number: 999.988 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:11:46,950][train][INFO][train.py>_log] ==> #406000     Total Loss: 3.458    [weighted Loss:3.458    Policy Loss: 10.222   Value Loss: 7.425    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 214645     Buffer Size: 23348      Transition Number: 999.976 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:14:32,994][train][INFO][train.py>_log] ==> #407000     Total Loss: 4.883    [weighted Loss:4.883    Policy Loss: 9.862    Value Loss: 7.457    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 215224     Buffer Size: 23310      Transition Number: 1000.035k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:17:15,793][train][INFO][train.py>_log] ==> #408000     Total Loss: 3.138    [weighted Loss:3.138    Policy Loss: 10.341   Value Loss: 7.084    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 215740     Buffer Size: 23272      Transition Number: 999.954 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:20:00,027][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 10.104   Value Loss: 7.253    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 216206     Buffer Size: 23221      Transition Number: 999.982 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:22:45,828][train][INFO][train.py>_log] ==> #410000     Total Loss: 4.415    [weighted Loss:4.415    Policy Loss: 9.564    Value Loss: 7.335    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 216689     Buffer Size: 23178      Transition Number: 999.958 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:25:28,742][train][INFO][train.py>_log] ==> #411000     Total Loss: 4.793    [weighted Loss:4.793    Policy Loss: 9.062    Value Loss: 7.048    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 217109     Buffer Size: 23146      Transition Number: 999.983 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:28:16,466][train][INFO][train.py>_log] ==> #412000     Total Loss: 4.902    [weighted Loss:4.902    Policy Loss: 10.132   Value Loss: 7.213    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 217581     Buffer Size: 23123      Transition Number: 999.972 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:31:03,590][train][INFO][train.py>_log] ==> #413000     Total Loss: 3.215    [weighted Loss:3.215    Policy Loss: 9.166    Value Loss: 7.047    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 218131     Buffer Size: 23224      Transition Number: 999.950 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:33:45,501][train][INFO][train.py>_log] ==> #414000     Total Loss: 4.561    [weighted Loss:4.561    Policy Loss: 10.809   Value Loss: 7.313    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 218709     Buffer Size: 23352      Transition Number: 1000.024k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:36:30,308][train][INFO][train.py>_log] ==> #415000     Total Loss: 3.609    [weighted Loss:3.609    Policy Loss: 10.584   Value Loss: 7.350    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 219275     Buffer Size: 23431      Transition Number: 999.980 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:39:13,042][train][INFO][train.py>_log] ==> #416000     Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 10.142   Value Loss: 7.352    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 219847     Buffer Size: 23520      Transition Number: 999.986 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:41:54,125][train][INFO][train.py>_log] ==> #417000     Total Loss: 4.746    [weighted Loss:4.746    Policy Loss: 9.357    Value Loss: 7.121    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 220316     Buffer Size: 23460      Transition Number: 999.974 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:44:38,718][train][INFO][train.py>_log] ==> #418000     Total Loss: 3.777    [weighted Loss:3.777    Policy Loss: 9.699    Value Loss: 7.035    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 220786     Buffer Size: 23435      Transition Number: 999.980 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:47:24,523][train][INFO][train.py>_log] ==> #419000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 9.278    Value Loss: 7.172    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 221266     Buffer Size: 23457      Transition Number: 999.936 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:50:08,286][train][INFO][train.py>_log] ==> #420000     Total Loss: 4.040    [weighted Loss:4.040    Policy Loss: 10.058   Value Loss: 7.423    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 221740     Buffer Size: 23454      Transition Number: 999.964 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:52:52,367][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 9.700    Value Loss: 7.143    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 222224     Buffer Size: 23446      Transition Number: 1000.063k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:55:38,271][train][INFO][train.py>_log] ==> #422000     Total Loss: 3.452    [weighted Loss:3.452    Policy Loss: 10.925   Value Loss: 7.561    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 222739     Buffer Size: 23420      Transition Number: 999.967 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 00:58:23,093][train][INFO][train.py>_log] ==> #423000     Total Loss: 3.991    [weighted Loss:3.991    Policy Loss: 9.799    Value Loss: 7.917    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 223238     Buffer Size: 23420      Transition Number: 1000.038k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:01:03,742][train][INFO][train.py>_log] ==> #424000     Total Loss: 4.544    [weighted Loss:4.544    Policy Loss: 10.131   Value Loss: 7.726    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 223713     Buffer Size: 23415      Transition Number: 999.950 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:03:48,936][train][INFO][train.py>_log] ==> #425000     Total Loss: 3.938    [weighted Loss:3.938    Policy Loss: 9.463    Value Loss: 7.460    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 224210     Buffer Size: 23408      Transition Number: 999.992 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:06:33,910][train][INFO][train.py>_log] ==> #426000     Total Loss: 4.678    [weighted Loss:4.678    Policy Loss: 9.747    Value Loss: 7.250    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 224745     Buffer Size: 23311      Transition Number: 999.997 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:09:18,130][train][INFO][train.py>_log] ==> #427000     Total Loss: 4.817    [weighted Loss:4.817    Policy Loss: 9.739    Value Loss: 7.410    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 225247     Buffer Size: 23113      Transition Number: 999.969 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:12:03,864][train][INFO][train.py>_log] ==> #428000     Total Loss: 4.385    [weighted Loss:4.385    Policy Loss: 9.693    Value Loss: 7.354    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 225776     Buffer Size: 22996      Transition Number: 1000.033k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:14:48,709][train][INFO][train.py>_log] ==> #429000     Total Loss: 4.636    [weighted Loss:4.636    Policy Loss: 9.792    Value Loss: 7.250    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 226285     Buffer Size: 22944      Transition Number: 999.975 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:17:31,202][train][INFO][train.py>_log] ==> #430000     Total Loss: 3.545    [weighted Loss:3.545    Policy Loss: 10.980   Value Loss: 7.644    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 226781     Buffer Size: 22885      Transition Number: 999.995 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:20:15,316][train][INFO][train.py>_log] ==> #431000     Total Loss: 6.062    [weighted Loss:6.062    Policy Loss: 10.613   Value Loss: 7.243    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 227296     Buffer Size: 22829      Transition Number: 999.970 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:23:05,053][train][INFO][train.py>_log] ==> #432000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 10.518   Value Loss: 7.552    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 227805     Buffer Size: 22783      Transition Number: 1000.233k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:25:51,340][train][INFO][train.py>_log] ==> #433000     Total Loss: 4.150    [weighted Loss:4.150    Policy Loss: 10.144   Value Loss: 7.151    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 228293     Buffer Size: 22692      Transition Number: 999.968 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:28:36,853][train][INFO][train.py>_log] ==> #434000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 10.843   Value Loss: 7.270    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 228813     Buffer Size: 22665      Transition Number: 999.986 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:31:20,816][train][INFO][train.py>_log] ==> #435000     Total Loss: 3.316    [weighted Loss:3.316    Policy Loss: 10.186   Value Loss: 7.339    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 229373     Buffer Size: 22726      Transition Number: 999.972 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:34:04,673][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 10.908   Value Loss: 7.167    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 229924     Buffer Size: 22516      Transition Number: 999.992 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:36:51,060][train][INFO][train.py>_log] ==> #437000     Total Loss: 4.104    [weighted Loss:4.104    Policy Loss: 10.553   Value Loss: 7.302    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 230415     Buffer Size: 22195      Transition Number: 999.999 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:39:39,368][train][INFO][train.py>_log] ==> #438000     Total Loss: 3.402    [weighted Loss:3.402    Policy Loss: 11.041   Value Loss: 7.374    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 230939     Buffer Size: 22000      Transition Number: 999.999 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:42:26,750][train][INFO][train.py>_log] ==> #439000     Total Loss: 1.687    [weighted Loss:1.687    Policy Loss: 11.728   Value Loss: 7.438    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 231466     Buffer Size: 21964      Transition Number: 999.943 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:45:11,148][train][INFO][train.py>_log] ==> #440000     Total Loss: 5.916    [weighted Loss:5.916    Policy Loss: 11.136   Value Loss: 7.397    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 231989     Buffer Size: 21948      Transition Number: 999.938 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:47:56,907][train][INFO][train.py>_log] ==> #441000     Total Loss: 5.281    [weighted Loss:5.281    Policy Loss: 12.173   Value Loss: 7.671    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 232485     Buffer Size: 21924      Transition Number: 999.957 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:50:41,181][train][INFO][train.py>_log] ==> #442000     Total Loss: 3.902    [weighted Loss:3.902    Policy Loss: 11.075   Value Loss: 7.434    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 232984     Buffer Size: 21875      Transition Number: 999.971 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:53:25,329][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.656    [weighted Loss:3.656    Policy Loss: 11.658   Value Loss: 7.037    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 233439     Buffer Size: 21783      Transition Number: 999.982 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:56:11,411][train][INFO][train.py>_log] ==> #444000     Total Loss: 5.056    [weighted Loss:5.056    Policy Loss: 11.204   Value Loss: 7.309    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 233906     Buffer Size: 21720      Transition Number: 999.976 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 01:58:56,133][train][INFO][train.py>_log] ==> #445000     Total Loss: 5.094    [weighted Loss:5.094    Policy Loss: 10.596   Value Loss: 6.991    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 234385     Buffer Size: 21706      Transition Number: 1000.038k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:01:39,512][train][INFO][train.py>_log] ==> #446000     Total Loss: 5.888    [weighted Loss:5.888    Policy Loss: 11.154   Value Loss: 7.374    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 234888     Buffer Size: 21699      Transition Number: 999.941 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:04:27,593][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.463    [weighted Loss:3.463    Policy Loss: 10.702   Value Loss: 7.479    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 235470     Buffer Size: 21749      Transition Number: 1000.026k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:07:11,632][train][INFO][train.py>_log] ==> #448000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 11.363   Value Loss: 7.077    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 236053     Buffer Size: 21809      Transition Number: 999.989 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:09:59,973][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.738    [weighted Loss:2.738    Policy Loss: 10.699   Value Loss: 7.175    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 236559     Buffer Size: 21853      Transition Number: 999.960 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:12:46,562][train][INFO][train.py>_log] ==> #450000     Total Loss: 5.072    [weighted Loss:5.072    Policy Loss: 11.278   Value Loss: 7.743    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 237098     Buffer Size: 21857      Transition Number: 1000.024k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:15:32,736][train][INFO][train.py>_log] ==> #451000     Total Loss: 4.825    [weighted Loss:4.825    Policy Loss: 11.089   Value Loss: 7.647    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 237660     Buffer Size: 21860      Transition Number: 1000.096k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:18:17,521][train][INFO][train.py>_log] ==> #452000     Total Loss: 4.034    [weighted Loss:4.034    Policy Loss: 10.079   Value Loss: 6.911    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 238153     Buffer Size: 21870      Transition Number: 999.981 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:21:03,805][train][INFO][train.py>_log] ==> #453000     Total Loss: 2.801    [weighted Loss:2.801    Policy Loss: 11.626   Value Loss: 7.528    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 238805     Buffer Size: 22038      Transition Number: 999.961 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:23:50,276][train][INFO][train.py>_log] ==> #454000     Total Loss: 3.298    [weighted Loss:3.298    Policy Loss: 11.448   Value Loss: 7.474    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 239478     Buffer Size: 22228      Transition Number: 999.969 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:26:35,647][train][INFO][train.py>_log] ==> #455000     Total Loss: 4.194    [weighted Loss:4.194    Policy Loss: 11.181   Value Loss: 7.668    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 240285     Buffer Size: 22507      Transition Number: 999.998 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:29:19,920][train][INFO][train.py>_log] ==> #456000     Total Loss: 5.573    [weighted Loss:5.573    Policy Loss: 11.610   Value Loss: 7.391    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 241110     Buffer Size: 22724      Transition Number: 999.970 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:32:04,987][train][INFO][train.py>_log] ==> #457000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 11.384   Value Loss: 7.709    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 241610     Buffer Size: 22678      Transition Number: 999.974 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:34:47,450][train][INFO][train.py>_log] ==> #458000     Total Loss: 4.085    [weighted Loss:4.085    Policy Loss: 11.701   Value Loss: 8.002    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 242104     Buffer Size: 22614      Transition Number: 999.964 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:37:32,769][train][INFO][train.py>_log] ==> #459000     Total Loss: 3.636    [weighted Loss:3.636    Policy Loss: 11.299   Value Loss: 7.415    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 242639     Buffer Size: 22589      Transition Number: 999.986 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:40:20,973][train][INFO][train.py>_log] ==> #460000     Total Loss: 4.635    [weighted Loss:4.635    Policy Loss: 11.059   Value Loss: 7.201    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 243178     Buffer Size: 22637      Transition Number: 999.998 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:43:05,270][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 10.584   Value Loss: 7.108    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 243722     Buffer Size: 22689      Transition Number: 1000.005k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:45:50,200][train][INFO][train.py>_log] ==> #462000     Total Loss: 3.452    [weighted Loss:3.452    Policy Loss: 10.380   Value Loss: 7.411    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 244261     Buffer Size: 22738      Transition Number: 999.990 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:48:37,355][train][INFO][train.py>_log] ==> #463000     Total Loss: 5.158    [weighted Loss:5.158    Policy Loss: 11.475   Value Loss: 7.529    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 244833     Buffer Size: 22793      Transition Number: 1000.008k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:51:18,693][train][INFO][train.py>_log] ==> #464000     Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 10.193   Value Loss: 7.683    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 245375     Buffer Size: 22851      Transition Number: 999.991 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:53:59,932][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.915    [weighted Loss:3.915    Policy Loss: 10.209   Value Loss: 7.094    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 245849     Buffer Size: 22873      Transition Number: 999.968 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:56:42,071][train][INFO][train.py>_log] ==> #466000     Total Loss: 3.546    [weighted Loss:3.546    Policy Loss: 10.238   Value Loss: 7.638    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 246322     Buffer Size: 22878      Transition Number: 1000.017k Batch Size: 256        Lr: 0.06400 
[2022-01-04 02:59:27,496][train][INFO][train.py>_log] ==> #467000     Total Loss: 2.931    [weighted Loss:2.931    Policy Loss: 10.520   Value Loss: 7.223    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 246798     Buffer Size: 22840      Transition Number: 999.969 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:02:10,729][train][INFO][train.py>_log] ==> #468000     Total Loss: 4.558    [weighted Loss:4.558    Policy Loss: 10.762   Value Loss: 7.607    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 247293     Buffer Size: 22789      Transition Number: 999.996 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:04:55,550][train][INFO][train.py>_log] ==> #469000     Total Loss: 6.016    [weighted Loss:6.016    Policy Loss: 9.711    Value Loss: 6.860    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 247724     Buffer Size: 22738      Transition Number: 1000.052k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:07:42,522][train][INFO][train.py>_log] ==> #470000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 10.118   Value Loss: 7.456    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 248180     Buffer Size: 22688      Transition Number: 999.969 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:10:29,198][train][INFO][train.py>_log] ==> #471000     Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 10.411   Value Loss: 7.342    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 248674     Buffer Size: 22659      Transition Number: 1000.029k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:13:17,386][train][INFO][train.py>_log] ==> #472000     Total Loss: 4.404    [weighted Loss:4.404    Policy Loss: 10.761   Value Loss: 7.121    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 249175     Buffer Size: 22633      Transition Number: 999.974 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:16:03,665][train][INFO][train.py>_log] ==> #473000     Total Loss: 4.375    [weighted Loss:4.375    Policy Loss: 10.156   Value Loss: 7.319    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 249591     Buffer Size: 22569      Transition Number: 999.978 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:18:49,147][train][INFO][train.py>_log] ==> #474000     Total Loss: 4.216    [weighted Loss:4.216    Policy Loss: 10.474   Value Loss: 7.452    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 250035     Buffer Size: 22510      Transition Number: 999.984 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:21:33,800][train][INFO][train.py>_log] ==> #475000     Total Loss: 3.693    [weighted Loss:3.693    Policy Loss: 9.486    Value Loss: 6.669    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 250451     Buffer Size: 22430      Transition Number: 1000.034k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:24:18,483][train][INFO][train.py>_log] ==> #476000     Total Loss: 4.013    [weighted Loss:4.013    Policy Loss: 9.340    Value Loss: 7.199    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 250855     Buffer Size: 22355      Transition Number: 999.967 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:27:04,245][train][INFO][train.py>_log] ==> #477000     Total Loss: 3.803    [weighted Loss:3.803    Policy Loss: 10.001   Value Loss: 7.349    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 251315     Buffer Size: 22292      Transition Number: 999.989 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:29:50,331][train][INFO][train.py>_log] ==> #478000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 9.877    Value Loss: 7.237    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 251784     Buffer Size: 22204      Transition Number: 999.999 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:32:37,607][train][INFO][train.py>_log] ==> #479000     Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 10.043   Value Loss: 7.152    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 252250     Buffer Size: 22109      Transition Number: 999.951 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:35:23,027][train][INFO][train.py>_log] ==> #480000     Total Loss: 4.290    [weighted Loss:4.290    Policy Loss: 10.017   Value Loss: 7.525    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 252692     Buffer Size: 22051      Transition Number: 999.999 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:38:11,566][train][INFO][train.py>_log] ==> #481000     Total Loss: 4.253    [weighted Loss:4.253    Policy Loss: 10.623   Value Loss: 7.177    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 253123     Buffer Size: 22001      Transition Number: 1000.017k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:40:58,968][train][INFO][train.py>_log] ==> #482000     Total Loss: 3.123    [weighted Loss:3.123    Policy Loss: 10.198   Value Loss: 7.894    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 253577     Buffer Size: 21936      Transition Number: 999.981 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:43:45,100][train][INFO][train.py>_log] ==> #483000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 10.080   Value Loss: 6.982    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 254190     Buffer Size: 22001      Transition Number: 1000.103k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:46:29,110][train][INFO][train.py>_log] ==> #484000     Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 9.878    Value Loss: 7.173    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 254793     Buffer Size: 22067      Transition Number: 999.963 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:49:15,090][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.374    [weighted Loss:2.374    Policy Loss: 11.117   Value Loss: 7.586    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 255347     Buffer Size: 22145      Transition Number: 1000.065k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:51:59,061][train][INFO][train.py>_log] ==> #486000     Total Loss: 4.178    [weighted Loss:4.178    Policy Loss: 9.781    Value Loss: 7.019    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 255922     Buffer Size: 22263      Transition Number: 999.935 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:54:44,833][train][INFO][train.py>_log] ==> #487000     Total Loss: 3.829    [weighted Loss:3.829    Policy Loss: 11.266   Value Loss: 7.521    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 256524     Buffer Size: 22384      Transition Number: 999.982 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 03:57:32,835][train][INFO][train.py>_log] ==> #488000     Total Loss: 4.980    [weighted Loss:4.980    Policy Loss: 10.236   Value Loss: 7.119    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 257170     Buffer Size: 22493      Transition Number: 1000.057k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:00:16,862][train][INFO][train.py>_log] ==> #489000     Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 11.277   Value Loss: 7.278    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 257728     Buffer Size: 22537      Transition Number: 1000.044k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:03:02,189][train][INFO][train.py>_log] ==> #490000     Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 10.461   Value Loss: 7.011    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 258293     Buffer Size: 22544      Transition Number: 1000.026k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:05:47,281][train][INFO][train.py>_log] ==> #491000     Total Loss: 3.982    [weighted Loss:3.982    Policy Loss: 10.586   Value Loss: 7.414    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 258828     Buffer Size: 22532      Transition Number: 1000.012k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:08:29,103][train][INFO][train.py>_log] ==> #492000     Total Loss: 4.507    [weighted Loss:4.507    Policy Loss: 10.826   Value Loss: 7.743    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 259370     Buffer Size: 22542      Transition Number: 999.961 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:11:16,982][train][INFO][train.py>_log] ==> #493000     Total Loss: 4.935    [weighted Loss:4.935    Policy Loss: 10.227   Value Loss: 7.136    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 259911     Buffer Size: 22545      Transition Number: 999.961 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:14:03,435][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.741    [weighted Loss:3.741    Policy Loss: 10.720   Value Loss: 7.416    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 260480     Buffer Size: 22583      Transition Number: 999.962 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:16:45,967][train][INFO][train.py>_log] ==> #495000     Total Loss: 4.304    [weighted Loss:4.304    Policy Loss: 10.050   Value Loss: 7.057    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 260965     Buffer Size: 22517      Transition Number: 1000.043k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:19:34,734][train][INFO][train.py>_log] ==> #496000     Total Loss: 5.433    [weighted Loss:5.433    Policy Loss: 10.304   Value Loss: 7.359    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 261482     Buffer Size: 22373      Transition Number: 1000.004k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:22:17,501][train][INFO][train.py>_log] ==> #497000     Total Loss: 3.153    [weighted Loss:3.153    Policy Loss: 10.123   Value Loss: 7.402    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 261971     Buffer Size: 22221      Transition Number: 1000.008k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:25:04,453][train][INFO][train.py>_log] ==> #498000     Total Loss: 4.835    [weighted Loss:4.835    Policy Loss: 10.731   Value Loss: 7.651    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 262476     Buffer Size: 21941      Transition Number: 999.944 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:27:50,008][train][INFO][train.py>_log] ==> #499000     Total Loss: 3.882    [weighted Loss:3.882    Policy Loss: 10.039   Value Loss: 7.457    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 263188     Buffer Size: 21917      Transition Number: 1000.052k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:30:34,518][train][INFO][train.py>_log] ==> #500000     Total Loss: 4.020    [weighted Loss:4.020    Policy Loss: 11.674   Value Loss: 7.471    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 263868     Buffer Size: 22084      Transition Number: 999.971 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:33:18,860][train][INFO][train.py>_log] ==> #501000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 10.510   Value Loss: 7.459    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 264724     Buffer Size: 22397      Transition Number: 999.979 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:36:01,962][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 10.350   Value Loss: 7.413    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 265578     Buffer Size: 22693      Transition Number: 1000.023k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:38:44,148][train][INFO][train.py>_log] ==> #503000     Total Loss: 4.543    [weighted Loss:4.543    Policy Loss: 9.832    Value Loss: 6.968    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 266084     Buffer Size: 22698      Transition Number: 999.977 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:41:29,451][train][INFO][train.py>_log] ==> #504000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 10.625   Value Loss: 7.573    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 266587     Buffer Size: 22648      Transition Number: 1000.077k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:44:12,204][train][INFO][train.py>_log] ==> #505000     Total Loss: 5.127    [weighted Loss:5.127    Policy Loss: 10.693   Value Loss: 7.807    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 267021     Buffer Size: 22595      Transition Number: 999.996 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:46:55,657][train][INFO][train.py>_log] ==> #506000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 10.193   Value Loss: 7.530    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 267489     Buffer Size: 22521      Transition Number: 999.979 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:49:42,135][train][INFO][train.py>_log] ==> #507000     Total Loss: 4.470    [weighted Loss:4.470    Policy Loss: 9.955    Value Loss: 7.116    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 268077     Buffer Size: 22561      Transition Number: 999.950 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:52:29,507][train][INFO][train.py>_log] ==> #508000     Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 10.780   Value Loss: 7.144    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 268661     Buffer Size: 22639      Transition Number: 999.941 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:55:10,888][train][INFO][train.py>_log] ==> #509000     Total Loss: 2.159    [weighted Loss:2.159    Policy Loss: 10.732   Value Loss: 7.419    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 269162     Buffer Size: 22684      Transition Number: 999.960 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 04:57:57,916][train][INFO][train.py>_log] ==> #510000     Total Loss: 4.176    [weighted Loss:4.176    Policy Loss: 10.295   Value Loss: 7.311    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 269712     Buffer Size: 22755      Transition Number: 999.988 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:00:40,597][train][INFO][train.py>_log] ==> #511000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 10.593   Value Loss: 7.312    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 270282     Buffer Size: 22840      Transition Number: 999.992 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:03:24,177][train][INFO][train.py>_log] ==> #512000     Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 10.959   Value Loss: 7.628    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 270863     Buffer Size: 22960      Transition Number: 999.969 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:06:07,834][train][INFO][train.py>_log] ==> #513000     Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 10.754   Value Loss: 7.698    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 271352     Buffer Size: 23023      Transition Number: 999.965 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:08:53,995][train][INFO][train.py>_log] ==> #514000     Total Loss: 3.598    [weighted Loss:3.598    Policy Loss: 10.399   Value Loss: 7.713    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 271854     Buffer Size: 23032      Transition Number: 999.965 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:11:38,628][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 9.940    Value Loss: 7.315    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 272374     Buffer Size: 23065      Transition Number: 999.954 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:14:24,253][train][INFO][train.py>_log] ==> #516000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 11.696   Value Loss: 7.898    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 272905     Buffer Size: 23147      Transition Number: 1000.052k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:17:10,853][train][INFO][train.py>_log] ==> #517000     Total Loss: 4.153    [weighted Loss:4.153    Policy Loss: 9.348    Value Loss: 7.404    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 273427     Buffer Size: 23241      Transition Number: 999.983 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:19:55,840][train][INFO][train.py>_log] ==> #518000     Total Loss: 4.957    [weighted Loss:4.957    Policy Loss: 10.465   Value Loss: 7.825    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 273982     Buffer Size: 23369      Transition Number: 999.989 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:22:40,569][train][INFO][train.py>_log] ==> #519000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 9.428    Value Loss: 7.424    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 274446     Buffer Size: 23420      Transition Number: 999.965 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:25:23,669][train][INFO][train.py>_log] ==> #520000     Total Loss: 3.167    [weighted Loss:3.167    Policy Loss: 10.323   Value Loss: 7.492    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 274901     Buffer Size: 23436      Transition Number: 999.995 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:28:07,512][train][INFO][train.py>_log] ==> #521000     Total Loss: 1.784    [weighted Loss:1.784    Policy Loss: 9.703    Value Loss: 7.619    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 275613     Buffer Size: 23667      Transition Number: 999.992 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:30:50,257][train][INFO][train.py>_log] ==> #522000     Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 10.453   Value Loss: 8.023    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 276350     Buffer Size: 23938      Transition Number: 999.952 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:33:31,102][train][INFO][train.py>_log] ==> #523000     Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 10.152   Value Loss: 7.593    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 277028     Buffer Size: 24156      Transition Number: 999.969 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:36:12,644][train][INFO][train.py>_log] ==> #524000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 10.181   Value Loss: 7.722    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 277736     Buffer Size: 24403      Transition Number: 999.964 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:38:56,574][train][INFO][train.py>_log] ==> #525000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 9.489    Value Loss: 7.605    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 278186     Buffer Size: 24391      Transition Number: 1000.028k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:41:42,072][train][INFO][train.py>_log] ==> #526000     Total Loss: 2.771    [weighted Loss:2.771    Policy Loss: 9.302    Value Loss: 7.390    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 278667     Buffer Size: 24286      Transition Number: 999.988 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:44:25,608][train][INFO][train.py>_log] ==> #527000     Total Loss: 4.701    [weighted Loss:4.701    Policy Loss: 9.516    Value Loss: 7.515    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 279130     Buffer Size: 24190      Transition Number: 999.999 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:47:10,313][train][INFO][train.py>_log] ==> #528000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 9.789    Value Loss: 7.567    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 279612     Buffer Size: 24123      Transition Number: 999.981 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:49:53,526][train][INFO][train.py>_log] ==> #529000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 10.320   Value Loss: 7.527    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 280136     Buffer Size: 24046      Transition Number: 999.969 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:52:38,641][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 9.397    Value Loss: 8.331    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 280607     Buffer Size: 23955      Transition Number: 1000.000k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:55:25,130][train][INFO][train.py>_log] ==> #531000     Total Loss: 4.422    [weighted Loss:4.422    Policy Loss: 9.863    Value Loss: 7.610    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 281093     Buffer Size: 23853      Transition Number: 999.994 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 05:58:12,418][train][INFO][train.py>_log] ==> #532000     Total Loss: 3.652    [weighted Loss:3.652    Policy Loss: 9.140    Value Loss: 7.571    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 281569     Buffer Size: 23772      Transition Number: 999.962 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:00:58,179][train][INFO][train.py>_log] ==> #533000     Total Loss: 3.623    [weighted Loss:3.623    Policy Loss: 9.939    Value Loss: 6.967    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 281997     Buffer Size: 23661      Transition Number: 999.972 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:03:46,843][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 9.183    Value Loss: 7.541    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 282445     Buffer Size: 23559      Transition Number: 999.938 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:06:30,132][train][INFO][train.py>_log] ==> #535000     Total Loss: 3.413    [weighted Loss:3.413    Policy Loss: 9.263    Value Loss: 7.335    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 282845     Buffer Size: 23448      Transition Number: 999.973 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:09:15,216][train][INFO][train.py>_log] ==> #536000     Total Loss: 3.077    [weighted Loss:3.077    Policy Loss: 8.879    Value Loss: 7.449    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 283279     Buffer Size: 23328      Transition Number: 999.969 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:12:00,056][train][INFO][train.py>_log] ==> #537000     Total Loss: 5.559    [weighted Loss:5.559    Policy Loss: 11.118   Value Loss: 7.058    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 283832     Buffer Size: 23350      Transition Number: 999.980 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:14:46,982][train][INFO][train.py>_log] ==> #538000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 9.808    Value Loss: 7.375    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 284434     Buffer Size: 23433      Transition Number: 999.949 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:17:31,228][train][INFO][train.py>_log] ==> #539000     Total Loss: 3.822    [weighted Loss:3.822    Policy Loss: 10.955   Value Loss: 7.215    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 285005     Buffer Size: 23503      Transition Number: 999.994 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:20:12,293][train][INFO][train.py>_log] ==> #540000     Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 12.226   Value Loss: 8.003    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 285605     Buffer Size: 23573      Transition Number: 999.958 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:22:53,210][train][INFO][train.py>_log] ==> #541000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 10.131   Value Loss: 7.729    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 286125     Buffer Size: 23623      Transition Number: 999.974 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:25:36,298][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.539    [weighted Loss:2.539    Policy Loss: 9.136    Value Loss: 7.546    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 286668     Buffer Size: 23476      Transition Number: 999.960 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:28:21,153][train][INFO][train.py>_log] ==> #543000     Total Loss: 3.112    [weighted Loss:3.112    Policy Loss: 9.424    Value Loss: 7.369    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 287149     Buffer Size: 23299      Transition Number: 1000.010k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:31:06,769][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 8.895    Value Loss: 7.173    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 287657     Buffer Size: 22996      Transition Number: 999.975 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:33:54,022][train][INFO][train.py>_log] ==> #545000     Total Loss: 4.344    [weighted Loss:4.344    Policy Loss: 9.097    Value Loss: 7.475    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 288213     Buffer Size: 22735      Transition Number: 1000.028k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:36:38,650][train][INFO][train.py>_log] ==> #546000     Total Loss: 3.991    [weighted Loss:3.991    Policy Loss: 9.034    Value Loss: 7.588    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 288789     Buffer Size: 22735      Transition Number: 999.993 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:39:22,511][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 9.371    Value Loss: 7.267    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 289367     Buffer Size: 22809      Transition Number: 999.995 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:42:05,557][train][INFO][train.py>_log] ==> #548000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 9.169    Value Loss: 7.302    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 289919     Buffer Size: 22876      Transition Number: 999.987 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:44:53,095][train][INFO][train.py>_log] ==> #549000     Total Loss: 3.922    [weighted Loss:3.922    Policy Loss: 9.633    Value Loss: 7.337    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 290440     Buffer Size: 22947      Transition Number: 999.984 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:47:37,699][train][INFO][train.py>_log] ==> #550000     Total Loss: 2.882    [weighted Loss:2.882    Policy Loss: 9.197    Value Loss: 7.037    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 290999     Buffer Size: 22917      Transition Number: 999.971 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:50:24,417][train][INFO][train.py>_log] ==> #551000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 9.752    Value Loss: 7.342    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 291561     Buffer Size: 22902      Transition Number: 999.945 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:53:09,695][train][INFO][train.py>_log] ==> #552000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 9.649    Value Loss: 7.539    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 292154     Buffer Size: 22953      Transition Number: 999.985 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:55:52,580][train][INFO][train.py>_log] ==> #553000     Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 10.214   Value Loss: 7.151    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 292621     Buffer Size: 22898      Transition Number: 1000.017k Batch Size: 256        Lr: 0.06400 
[2022-01-04 06:58:40,579][train][INFO][train.py>_log] ==> #554000     Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 9.136    Value Loss: 7.394    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 293099     Buffer Size: 22811      Transition Number: 999.982 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:01:23,997][train][INFO][train.py>_log] ==> #555000     Total Loss: 3.959    [weighted Loss:3.959    Policy Loss: 10.324   Value Loss: 7.374    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 293550     Buffer Size: 22692      Transition Number: 999.963 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:04:07,014][train][INFO][train.py>_log] ==> #556000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 10.428   Value Loss: 7.346    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 293986     Buffer Size: 22637      Transition Number: 999.990 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:06:53,126][train][INFO][train.py>_log] ==> #557000     Total Loss: 2.728    [weighted Loss:2.728    Policy Loss: 10.343   Value Loss: 7.640    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 294585     Buffer Size: 22738      Transition Number: 999.942 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:09:39,117][train][INFO][train.py>_log] ==> #558000     Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 9.529    Value Loss: 7.314    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 295175     Buffer Size: 22820      Transition Number: 999.977 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:12:23,706][train][INFO][train.py>_log] ==> #559000     Total Loss: 4.427    [weighted Loss:4.427    Policy Loss: 9.687    Value Loss: 7.435    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 295765     Buffer Size: 22891      Transition Number: 999.998 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:15:07,996][train][INFO][train.py>_log] ==> #560000     Total Loss: 4.171    [weighted Loss:4.171    Policy Loss: 11.999   Value Loss: 7.363    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 296370     Buffer Size: 22922      Transition Number: 1000.057k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:17:52,898][train][INFO][train.py>_log] ==> #561000     Total Loss: 4.411    [weighted Loss:4.411    Policy Loss: 9.233    Value Loss: 7.141    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 297241     Buffer Size: 23242      Transition Number: 999.951 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:20:34,839][train][INFO][train.py>_log] ==> #562000     Total Loss: 5.593    [weighted Loss:5.593    Policy Loss: 10.195   Value Loss: 7.172    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 298073     Buffer Size: 23583      Transition Number: 999.982 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:23:17,201][train][INFO][train.py>_log] ==> #563000     Total Loss: 3.134    [weighted Loss:3.134    Policy Loss: 10.027   Value Loss: 7.495    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 298637     Buffer Size: 23685      Transition Number: 999.988 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:26:01,420][train][INFO][train.py>_log] ==> #564000     Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 10.244   Value Loss: 7.613    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 299189     Buffer Size: 23530      Transition Number: 1000.042k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:28:46,555][train][INFO][train.py>_log] ==> #565000     Total Loss: 3.153    [weighted Loss:3.153    Policy Loss: 9.570    Value Loss: 7.806    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 299654     Buffer Size: 23333      Transition Number: 1000.128k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:31:31,380][train][INFO][train.py>_log] ==> #566000     Total Loss: 5.280    [weighted Loss:5.280    Policy Loss: 10.287   Value Loss: 7.830    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 300164     Buffer Size: 23145      Transition Number: 999.995 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:34:16,162][train][INFO][train.py>_log] ==> #567000     Total Loss: 3.371    [weighted Loss:3.371    Policy Loss: 9.327    Value Loss: 7.692    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 300655     Buffer Size: 22921      Transition Number: 1000.103k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:36:58,673][train][INFO][train.py>_log] ==> #568000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 10.424   Value Loss: 7.922    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 301126     Buffer Size: 22923      Transition Number: 1000.054k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:39:43,175][train][INFO][train.py>_log] ==> #569000     Total Loss: 2.783    [weighted Loss:2.783    Policy Loss: 10.285   Value Loss: 7.338    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 301605     Buffer Size: 22942      Transition Number: 999.945 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:42:28,822][train][INFO][train.py>_log] ==> #570000     Total Loss: 3.368    [weighted Loss:3.368    Policy Loss: 9.610    Value Loss: 7.505    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 302120     Buffer Size: 22963      Transition Number: 999.943 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:45:12,310][train][INFO][train.py>_log] ==> #571000     Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 9.936    Value Loss: 7.684    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 302632     Buffer Size: 22982      Transition Number: 999.939 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:47:58,125][train][INFO][train.py>_log] ==> #572000     Total Loss: 5.059    [weighted Loss:5.059    Policy Loss: 11.345   Value Loss: 7.637    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 303139     Buffer Size: 22981      Transition Number: 999.981 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:50:44,834][train][INFO][train.py>_log] ==> #573000     Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 9.924    Value Loss: 7.520    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 303655     Buffer Size: 23001      Transition Number: 999.960 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:53:33,154][train][INFO][train.py>_log] ==> #574000     Total Loss: 4.475    [weighted Loss:4.475    Policy Loss: 9.489    Value Loss: 7.702    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 304162     Buffer Size: 23033      Transition Number: 999.975 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:56:20,130][train][INFO][train.py>_log] ==> #575000     Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 10.092   Value Loss: 7.568    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 304682     Buffer Size: 23076      Transition Number: 999.979 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 07:59:01,404][train][INFO][train.py>_log] ==> #576000     Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 9.632    Value Loss: 7.219    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 305202     Buffer Size: 23153      Transition Number: 1000.039k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:01:43,831][train][INFO][train.py>_log] ==> #577000     Total Loss: 4.111    [weighted Loss:4.111    Policy Loss: 9.536    Value Loss: 7.608    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 305735     Buffer Size: 23257      Transition Number: 1000.000k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:04:27,925][train][INFO][train.py>_log] ==> #578000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 9.135    Value Loss: 7.498    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 306283     Buffer Size: 23387      Transition Number: 999.981 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:07:13,515][train][INFO][train.py>_log] ==> #579000     Total Loss: 3.334    [weighted Loss:3.334    Policy Loss: 10.142   Value Loss: 7.010    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 306799     Buffer Size: 23452      Transition Number: 999.990 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:09:59,828][train][INFO][train.py>_log] ==> #580000     Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 10.399   Value Loss: 7.882    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 307306     Buffer Size: 23382      Transition Number: 999.954 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:12:44,508][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 9.830    Value Loss: 7.546    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 307777     Buffer Size: 23292      Transition Number: 1000.040k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:15:25,382][train][INFO][train.py>_log] ==> #582000     Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 9.588    Value Loss: 7.448    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 308257     Buffer Size: 23220      Transition Number: 1000.090k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:18:07,355][train][INFO][train.py>_log] ==> #583000     Total Loss: 3.143    [weighted Loss:3.143    Policy Loss: 10.843   Value Loss: 7.619    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 308754     Buffer Size: 23116      Transition Number: 999.982 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:20:51,059][train][INFO][train.py>_log] ==> #584000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 9.250    Value Loss: 6.968    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 309266     Buffer Size: 23057      Transition Number: 999.994 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:23:33,555][train][INFO][train.py>_log] ==> #585000     Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 10.866   Value Loss: 8.088    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 309800     Buffer Size: 23051      Transition Number: 999.993 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:26:18,463][train][INFO][train.py>_log] ==> #586000     Total Loss: 4.056    [weighted Loss:4.056    Policy Loss: 9.908    Value Loss: 7.172    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 310346     Buffer Size: 23113      Transition Number: 1000.055k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:29:00,688][train][INFO][train.py>_log] ==> #587000     Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 10.193   Value Loss: 7.494    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 310871     Buffer Size: 23133      Transition Number: 999.992 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:31:44,447][train][INFO][train.py>_log] ==> #588000     Total Loss: 3.872    [weighted Loss:3.872    Policy Loss: 9.568    Value Loss: 7.486    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 311401     Buffer Size: 23117      Transition Number: 999.961 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:34:30,604][train][INFO][train.py>_log] ==> #589000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 9.565    Value Loss: 7.656    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 311931     Buffer Size: 23093      Transition Number: 999.988 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:37:12,895][train][INFO][train.py>_log] ==> #590000     Total Loss: 3.637    [weighted Loss:3.637    Policy Loss: 9.961    Value Loss: 7.420    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 312459     Buffer Size: 23059      Transition Number: 1000.016k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:39:55,805][train][INFO][train.py>_log] ==> #591000     Total Loss: 3.880    [weighted Loss:3.880    Policy Loss: 10.764   Value Loss: 7.873    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 313026     Buffer Size: 23041      Transition Number: 1000.030k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:42:40,663][train][INFO][train.py>_log] ==> #592000     Total Loss: 4.593    [weighted Loss:4.593    Policy Loss: 10.502   Value Loss: 7.921    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 313546     Buffer Size: 22993      Transition Number: 999.964 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:45:26,768][train][INFO][train.py>_log] ==> #593000     Total Loss: 4.305    [weighted Loss:4.305    Policy Loss: 10.336   Value Loss: 7.370    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 314107     Buffer Size: 22997      Transition Number: 1000.184k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:48:13,308][train][INFO][train.py>_log] ==> #594000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 10.115   Value Loss: 7.946    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 314675     Buffer Size: 22988      Transition Number: 999.978 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:50:51,897][train][INFO][train.py>_log] ==> #595000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 10.543   Value Loss: 7.469    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 315229     Buffer Size: 22998      Transition Number: 1000.062k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:53:35,852][train][INFO][train.py>_log] ==> #596000     Total Loss: 3.919    [weighted Loss:3.919    Policy Loss: 10.171   Value Loss: 7.248    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 315789     Buffer Size: 23081      Transition Number: 1000.112k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:56:19,122][train][INFO][train.py>_log] ==> #597000     Total Loss: 4.470    [weighted Loss:4.470    Policy Loss: 10.319   Value Loss: 7.499    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 316348     Buffer Size: 23169      Transition Number: 999.971 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 08:59:03,612][train][INFO][train.py>_log] ==> #598000     Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 9.882    Value Loss: 7.535    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 316944     Buffer Size: 23276      Transition Number: 999.974 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 09:01:48,046][train][INFO][train.py>_log] ==> #599000     Total Loss: 3.687    [weighted Loss:3.687    Policy Loss: 10.282   Value Loss: 7.416    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 317466     Buffer Size: 23315      Transition Number: 999.993 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 09:04:33,248][train][INFO][train.py>_log] ==> #600000     Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 10.041   Value Loss: 7.769    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 317987     Buffer Size: 23222      Transition Number: 999.991 k Batch Size: 256        Lr: 0.06400 
[2022-01-04 09:07:19,577][train][INFO][train.py>_log] ==> #601000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 10.794   Value Loss: 7.108    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 318460     Buffer Size: 23134      Transition Number: 999.992 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:10:05,237][train][INFO][train.py>_log] ==> #602000     Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 9.820    Value Loss: 7.074    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 318957     Buffer Size: 23069      Transition Number: 999.958 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:12:51,208][train][INFO][train.py>_log] ==> #603000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 9.930    Value Loss: 7.281    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 319422     Buffer Size: 22952      Transition Number: 999.998 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:15:38,582][train][INFO][train.py>_log] ==> #604000     Total Loss: 2.783    [weighted Loss:2.783    Policy Loss: 10.075   Value Loss: 7.529    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 319904     Buffer Size: 22526      Transition Number: 999.976 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:18:23,428][train][INFO][train.py>_log] ==> #605000     Total Loss: 3.310    [weighted Loss:3.310    Policy Loss: 9.591    Value Loss: 7.451    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 320367     Buffer Size: 22226      Transition Number: 1000.012k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:21:09,405][train][INFO][train.py>_log] ==> #606000     Total Loss: 4.433    [weighted Loss:4.433    Policy Loss: 10.372   Value Loss: 7.389    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 320815     Buffer Size: 22106      Transition Number: 999.960 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:23:56,898][train][INFO][train.py>_log] ==> #607000     Total Loss: 4.129    [weighted Loss:4.129    Policy Loss: 9.925    Value Loss: 7.549    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 321466     Buffer Size: 22179      Transition Number: 1000.034k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:26:39,376][train][INFO][train.py>_log] ==> #608000     Total Loss: 4.220    [weighted Loss:4.220    Policy Loss: 10.394   Value Loss: 7.321    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 322099     Buffer Size: 22309      Transition Number: 1000.077k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:29:27,342][train][INFO][train.py>_log] ==> #609000     Total Loss: 4.809    [weighted Loss:4.809    Policy Loss: 10.569   Value Loss: 7.988    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 322622     Buffer Size: 22360      Transition Number: 1000.119k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:32:08,570][train][INFO][train.py>_log] ==> #610000     Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 10.228   Value Loss: 7.385    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 323167     Buffer Size: 22406      Transition Number: 999.958 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:34:52,736][train][INFO][train.py>_log] ==> #611000     Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 10.368   Value Loss: 7.449    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 323650     Buffer Size: 22414      Transition Number: 999.946 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:37:38,561][train][INFO][train.py>_log] ==> #612000     Total Loss: 3.538    [weighted Loss:3.538    Policy Loss: 9.904    Value Loss: 7.687    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 324139     Buffer Size: 22388      Transition Number: 999.978 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:40:25,384][train][INFO][train.py>_log] ==> #613000     Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 9.695    Value Loss: 7.313    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 324608     Buffer Size: 22381      Transition Number: 999.943 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:43:12,674][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.709    [weighted Loss:2.709    Policy Loss: 10.293   Value Loss: 7.697    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 325088     Buffer Size: 22383      Transition Number: 999.994 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:45:58,699][train][INFO][train.py>_log] ==> #615000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 9.490    Value Loss: 6.900    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 325554     Buffer Size: 22372      Transition Number: 999.992 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:48:43,415][train][INFO][train.py>_log] ==> #616000     Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 10.380   Value Loss: 7.360    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 326024     Buffer Size: 22317      Transition Number: 1000.032k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:51:29,053][train][INFO][train.py>_log] ==> #617000     Total Loss: 4.508    [weighted Loss:4.508    Policy Loss: 10.204   Value Loss: 7.399    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 326475     Buffer Size: 22248      Transition Number: 1000.026k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:54:15,663][train][INFO][train.py>_log] ==> #618000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 10.250   Value Loss: 7.091    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 326924     Buffer Size: 22172      Transition Number: 999.955 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:57:01,252][train][INFO][train.py>_log] ==> #619000     Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 9.666    Value Loss: 7.403    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 327394     Buffer Size: 22140      Transition Number: 999.964 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 09:59:46,811][train][INFO][train.py>_log] ==> #620000     Total Loss: 4.031    [weighted Loss:4.031    Policy Loss: 9.714    Value Loss: 7.816    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 327890     Buffer Size: 22072      Transition Number: 1000.066k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:02:31,390][train][INFO][train.py>_log] ==> #621000     Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 11.250   Value Loss: 7.773    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 328479     Buffer Size: 22123      Transition Number: 999.984 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:05:14,450][train][INFO][train.py>_log] ==> #622000     Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 10.291   Value Loss: 7.713    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 329076     Buffer Size: 22217      Transition Number: 999.990 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:07:57,839][train][INFO][train.py>_log] ==> #623000     Total Loss: 3.652    [weighted Loss:3.652    Policy Loss: 10.193   Value Loss: 7.570    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 329769     Buffer Size: 22383      Transition Number: 1000.051k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:10:42,326][train][INFO][train.py>_log] ==> #624000     Total Loss: 4.275    [weighted Loss:4.275    Policy Loss: 10.323   Value Loss: 7.662    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 330439     Buffer Size: 22559      Transition Number: 1000.012k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:13:28,175][train][INFO][train.py>_log] ==> #625000     Total Loss: 3.661    [weighted Loss:3.661    Policy Loss: 9.928    Value Loss: 7.608    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 331098     Buffer Size: 22720      Transition Number: 999.972 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:16:14,803][train][INFO][train.py>_log] ==> #626000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 10.763   Value Loss: 7.539    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 331771     Buffer Size: 22884      Transition Number: 1000.025k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:18:57,041][train][INFO][train.py>_log] ==> #627000     Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 10.111   Value Loss: 7.514    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 332433     Buffer Size: 23027      Transition Number: 999.983 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:21:38,143][train][INFO][train.py>_log] ==> #628000     Total Loss: 4.401    [weighted Loss:4.401    Policy Loss: 10.421   Value Loss: 7.930    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 333063     Buffer Size: 23103      Transition Number: 999.984 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:24:22,764][train][INFO][train.py>_log] ==> #629000     Total Loss: 3.701    [weighted Loss:3.701    Policy Loss: 9.553    Value Loss: 7.746    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 333508     Buffer Size: 23049      Transition Number: 999.953 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:27:08,820][train][INFO][train.py>_log] ==> #630000     Total Loss: 3.897    [weighted Loss:3.897    Policy Loss: 9.589    Value Loss: 7.717    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 333997     Buffer Size: 23005      Transition Number: 999.935 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:29:54,353][train][INFO][train.py>_log] ==> #631000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 9.983    Value Loss: 7.228    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 334462     Buffer Size: 22917      Transition Number: 999.964 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:32:39,630][train][INFO][train.py>_log] ==> #632000     Total Loss: 3.953    [weighted Loss:3.953    Policy Loss: 10.888   Value Loss: 7.263    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 334915     Buffer Size: 22837      Transition Number: 1000.035k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:35:25,744][train][INFO][train.py>_log] ==> #633000     Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 11.030   Value Loss: 7.678    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 335442     Buffer Size: 22833      Transition Number: 999.985 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:38:10,653][train][INFO][train.py>_log] ==> #634000     Total Loss: 4.143    [weighted Loss:4.143    Policy Loss: 10.341   Value Loss: 7.552    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 335963     Buffer Size: 22821      Transition Number: 999.991 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:40:57,226][train][INFO][train.py>_log] ==> #635000     Total Loss: 2.318    [weighted Loss:2.318    Policy Loss: 10.525   Value Loss: 7.861    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 336493     Buffer Size: 22816      Transition Number: 999.968 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:43:44,607][train][INFO][train.py>_log] ==> #636000     Total Loss: 3.633    [weighted Loss:3.633    Policy Loss: 11.405   Value Loss: 7.707    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 337034     Buffer Size: 22780      Transition Number: 999.933 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:46:30,776][train][INFO][train.py>_log] ==> #637000     Total Loss: 1.997    [weighted Loss:1.997    Policy Loss: 10.649   Value Loss: 7.375    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 337569     Buffer Size: 22756      Transition Number: 999.985 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:49:15,850][train][INFO][train.py>_log] ==> #638000     Total Loss: 3.591    [weighted Loss:3.591    Policy Loss: 10.841   Value Loss: 8.053    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 338115     Buffer Size: 22732      Transition Number: 999.998 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:51:58,970][train][INFO][train.py>_log] ==> #639000     Total Loss: 4.367    [weighted Loss:4.367    Policy Loss: 10.549   Value Loss: 7.878    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 338698     Buffer Size: 22757      Transition Number: 999.979 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:54:45,452][train][INFO][train.py>_log] ==> #640000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 10.816   Value Loss: 7.558    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 339289     Buffer Size: 22755      Transition Number: 999.992 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 10:57:33,893][train][INFO][train.py>_log] ==> #641000     Total Loss: 0.864    [weighted Loss:0.864    Policy Loss: 9.893    Value Loss: 7.442    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 339793     Buffer Size: 22708      Transition Number: 999.990 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:00:21,305][train][INFO][train.py>_log] ==> #642000     Total Loss: 1.587    [weighted Loss:1.587    Policy Loss: 10.391   Value Loss: 7.844    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 340330     Buffer Size: 22698      Transition Number: 999.985 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:03:07,978][train][INFO][train.py>_log] ==> #643000     Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 10.275   Value Loss: 7.796    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 340930     Buffer Size: 22786      Transition Number: 1000.000k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:05:52,559][train][INFO][train.py>_log] ==> #644000     Total Loss: 4.147    [weighted Loss:4.147    Policy Loss: 10.875   Value Loss: 7.528    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 341539     Buffer Size: 22892      Transition Number: 1000.068k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:08:36,108][train][INFO][train.py>_log] ==> #645000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 10.107   Value Loss: 7.483    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 342356     Buffer Size: 23190      Transition Number: 999.969 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:11:16,732][train][INFO][train.py>_log] ==> #646000     Total Loss: 5.090    [weighted Loss:5.090    Policy Loss: 11.776   Value Loss: 7.326    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 343194     Buffer Size: 23548      Transition Number: 999.978 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:14:02,497][train][INFO][train.py>_log] ==> #647000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 10.141   Value Loss: 7.950    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 344017     Buffer Size: 23867      Transition Number: 999.996 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:16:46,506][train][INFO][train.py>_log] ==> #648000     Total Loss: 4.482    [weighted Loss:4.482    Policy Loss: 10.732   Value Loss: 7.187    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 344834     Buffer Size: 24191      Transition Number: 999.976 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:19:26,064][train][INFO][train.py>_log] ==> #649000     Total Loss: 4.248    [weighted Loss:4.248    Policy Loss: 10.269   Value Loss: 7.222    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 345411     Buffer Size: 24283      Transition Number: 999.979 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:22:10,311][train][INFO][train.py>_log] ==> #650000     Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 10.290   Value Loss: 7.504    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 346036     Buffer Size: 24249      Transition Number: 1000.028k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:24:51,891][train][INFO][train.py>_log] ==> #651000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 9.975    Value Loss: 7.381    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 346509     Buffer Size: 24186      Transition Number: 999.949 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:27:35,339][train][INFO][train.py>_log] ==> #652000     Total Loss: 3.966    [weighted Loss:3.966    Policy Loss: 9.502    Value Loss: 7.332    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 346991     Buffer Size: 24149      Transition Number: 999.989 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:30:20,211][train][INFO][train.py>_log] ==> #653000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 10.345   Value Loss: 7.702    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 347427     Buffer Size: 24083      Transition Number: 999.944 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:33:04,168][train][INFO][train.py>_log] ==> #654000     Total Loss: 3.541    [weighted Loss:3.541    Policy Loss: 10.688   Value Loss: 7.778    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 347886     Buffer Size: 24075      Transition Number: 1000.000k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:35:51,817][train][INFO][train.py>_log] ==> #655000     Total Loss: 5.201    [weighted Loss:5.201    Policy Loss: 10.912   Value Loss: 7.953    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 348440     Buffer Size: 24120      Transition Number: 999.960 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:38:35,917][train][INFO][train.py>_log] ==> #656000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 10.068   Value Loss: 7.639    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 348975     Buffer Size: 24146      Transition Number: 999.973 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:41:19,254][train][INFO][train.py>_log] ==> #657000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 11.523   Value Loss: 7.415    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 349485     Buffer Size: 24165      Transition Number: 999.974 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:44:05,567][train][INFO][train.py>_log] ==> #658000     Total Loss: 2.647    [weighted Loss:2.647    Policy Loss: 8.802    Value Loss: 7.163    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 350034     Buffer Size: 24234      Transition Number: 999.943 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:46:48,835][train][INFO][train.py>_log] ==> #659000     Total Loss: 3.648    [weighted Loss:3.648    Policy Loss: 9.990    Value Loss: 7.394    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 350564     Buffer Size: 24300      Transition Number: 999.965 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:49:32,466][train][INFO][train.py>_log] ==> #660000     Total Loss: 4.732    [weighted Loss:4.732    Policy Loss: 10.252   Value Loss: 7.550    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 351087     Buffer Size: 24373      Transition Number: 999.952 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:52:18,044][train][INFO][train.py>_log] ==> #661000     Total Loss: 4.648    [weighted Loss:4.648    Policy Loss: 10.438   Value Loss: 7.403    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 351626     Buffer Size: 24442      Transition Number: 999.977 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:54:59,653][train][INFO][train.py>_log] ==> #662000     Total Loss: 4.277    [weighted Loss:4.277    Policy Loss: 10.462   Value Loss: 7.501    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 352148     Buffer Size: 24498      Transition Number: 999.973 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 11:57:40,760][train][INFO][train.py>_log] ==> #663000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 9.974    Value Loss: 7.072    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 352638     Buffer Size: 24450      Transition Number: 1000.011k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:00:24,496][train][INFO][train.py>_log] ==> #664000     Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 10.115   Value Loss: 7.581    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 353137     Buffer Size: 24341      Transition Number: 999.989 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:03:11,769][train][INFO][train.py>_log] ==> #665000     Total Loss: 4.590    [weighted Loss:4.590    Policy Loss: 10.123   Value Loss: 7.442    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 353650     Buffer Size: 24251      Transition Number: 999.979 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:05:57,432][train][INFO][train.py>_log] ==> #666000     Total Loss: 4.535    [weighted Loss:4.535    Policy Loss: 11.240   Value Loss: 7.847    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 354188     Buffer Size: 24149      Transition Number: 999.993 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:08:42,005][train][INFO][train.py>_log] ==> #667000     Total Loss: 3.850    [weighted Loss:3.850    Policy Loss: 10.496   Value Loss: 7.532    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 354759     Buffer Size: 24032      Transition Number: 999.959 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:11:27,501][train][INFO][train.py>_log] ==> #668000     Total Loss: 3.135    [weighted Loss:3.135    Policy Loss: 10.117   Value Loss: 7.570    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 355342     Buffer Size: 23946      Transition Number: 1000.009k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:14:14,548][train][INFO][train.py>_log] ==> #669000     Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 10.134   Value Loss: 7.479    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 356340     Buffer Size: 24280      Transition Number: 999.950 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:16:55,028][train][INFO][train.py>_log] ==> #670000     Total Loss: 4.480    [weighted Loss:4.480    Policy Loss: 10.014   Value Loss: 7.425    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 357416     Buffer Size: 24724      Transition Number: 1000.118k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:19:38,634][train][INFO][train.py>_log] ==> #671000     Total Loss: 5.534    [weighted Loss:5.534    Policy Loss: 10.795   Value Loss: 7.470    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 358027     Buffer Size: 24755      Transition Number: 999.980 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:22:21,554][train][INFO][train.py>_log] ==> #672000     Total Loss: 3.211    [weighted Loss:3.211    Policy Loss: 9.732    Value Loss: 7.360    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 358627     Buffer Size: 24886      Transition Number: 999.988 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:25:05,394][train][INFO][train.py>_log] ==> #673000     Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 10.072   Value Loss: 7.687    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 359080     Buffer Size: 24895      Transition Number: 999.992 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:27:48,367][train][INFO][train.py>_log] ==> #674000     Total Loss: 3.277    [weighted Loss:3.277    Policy Loss: 10.495   Value Loss: 7.512    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 359560     Buffer Size: 24924      Transition Number: 999.976 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:30:34,289][train][INFO][train.py>_log] ==> #675000     Total Loss: 3.602    [weighted Loss:3.602    Policy Loss: 9.435    Value Loss: 7.289    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 360015     Buffer Size: 24915      Transition Number: 999.959 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:33:18,256][train][INFO][train.py>_log] ==> #676000     Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 9.613    Value Loss: 7.596    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 360477     Buffer Size: 24862      Transition Number: 999.987 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:36:03,356][train][INFO][train.py>_log] ==> #677000     Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 10.291   Value Loss: 7.681    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 360983     Buffer Size: 24845      Transition Number: 1000.005k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:38:48,409][train][INFO][train.py>_log] ==> #678000     Total Loss: 3.538    [weighted Loss:3.538    Policy Loss: 10.914   Value Loss: 7.813    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 361465     Buffer Size: 24826      Transition Number: 999.985 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:41:33,818][train][INFO][train.py>_log] ==> #679000     Total Loss: 3.333    [weighted Loss:3.333    Policy Loss: 10.493   Value Loss: 7.765    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 362077     Buffer Size: 24902      Transition Number: 999.992 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:44:21,243][train][INFO][train.py>_log] ==> #680000     Total Loss: 3.533    [weighted Loss:3.533    Policy Loss: 10.338   Value Loss: 7.331    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 362694     Buffer Size: 24987      Transition Number: 1000.015k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:47:05,480][train][INFO][train.py>_log] ==> #681000     Total Loss: 4.294    [weighted Loss:4.294    Policy Loss: 9.498    Value Loss: 7.323    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 363262     Buffer Size: 25036      Transition Number: 1000.043k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:49:48,556][train][INFO][train.py>_log] ==> #682000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 9.801    Value Loss: 7.721    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 363864     Buffer Size: 25043      Transition Number: 999.981 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:52:34,011][train][INFO][train.py>_log] ==> #683000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 9.788    Value Loss: 7.660    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 364408     Buffer Size: 25014      Transition Number: 999.961 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:55:20,853][train][INFO][train.py>_log] ==> #684000     Total Loss: 4.587    [weighted Loss:4.587    Policy Loss: 10.960   Value Loss: 7.828    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 364966     Buffer Size: 25026      Transition Number: 999.997 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 12:58:03,523][train][INFO][train.py>_log] ==> #685000     Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 10.403   Value Loss: 7.478    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 365621     Buffer Size: 25162      Transition Number: 999.969 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:00:45,369][train][INFO][train.py>_log] ==> #686000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 10.528   Value Loss: 7.485    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 366326     Buffer Size: 25263      Transition Number: 999.982 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:03:29,297][train][INFO][train.py>_log] ==> #687000     Total Loss: 2.938    [weighted Loss:2.938    Policy Loss: 9.545    Value Loss: 7.719    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 366818     Buffer Size: 25172      Transition Number: 999.962 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:06:14,698][train][INFO][train.py>_log] ==> #688000     Total Loss: 3.665    [weighted Loss:3.665    Policy Loss: 10.109   Value Loss: 7.868    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 367312     Buffer Size: 24863      Transition Number: 999.972 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:08:58,147][train][INFO][train.py>_log] ==> #689000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 10.497   Value Loss: 8.111    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 367843     Buffer Size: 24590      Transition Number: 1000.000k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:11:42,312][train][INFO][train.py>_log] ==> #690000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 10.295   Value Loss: 7.732    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 368386     Buffer Size: 24378      Transition Number: 999.996 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:14:26,266][train][INFO][train.py>_log] ==> #691000     Total Loss: 4.280    [weighted Loss:4.280    Policy Loss: 10.686   Value Loss: 7.528    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 368959     Buffer Size: 24161      Transition Number: 999.969 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:17:10,418][train][INFO][train.py>_log] ==> #692000     Total Loss: 2.799    [weighted Loss:2.799    Policy Loss: 9.892    Value Loss: 7.455    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 369546     Buffer Size: 24126      Transition Number: 1000.109k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:19:54,931][train][INFO][train.py>_log] ==> #693000     Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 10.795   Value Loss: 8.097    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 370129     Buffer Size: 24105      Transition Number: 1000.018k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:22:41,395][train][INFO][train.py>_log] ==> #694000     Total Loss: 4.026    [weighted Loss:4.026    Policy Loss: 10.186   Value Loss: 7.900    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 370738     Buffer Size: 24183      Transition Number: 1000.085k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:25:26,249][train][INFO][train.py>_log] ==> #695000     Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 10.113   Value Loss: 7.730    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 371334     Buffer Size: 24274      Transition Number: 999.954 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:28:10,072][train][INFO][train.py>_log] ==> #696000     Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 10.596   Value Loss: 7.723    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 371918     Buffer Size: 24405      Transition Number: 999.989 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:30:53,464][train][INFO][train.py>_log] ==> #697000     Total Loss: 2.090    [weighted Loss:2.090    Policy Loss: 10.825   Value Loss: 7.771    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 372407     Buffer Size: 24454      Transition Number: 999.966 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:33:39,016][train][INFO][train.py>_log] ==> #698000     Total Loss: 4.303    [weighted Loss:4.303    Policy Loss: 10.693   Value Loss: 7.152    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 372910     Buffer Size: 24435      Transition Number: 999.983 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:36:23,708][train][INFO][train.py>_log] ==> #699000     Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 10.842   Value Loss: 7.358    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 373547     Buffer Size: 24503      Transition Number: 999.983 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:39:08,576][train][INFO][train.py>_log] ==> #700000     Total Loss: 3.279    [weighted Loss:3.279    Policy Loss: 10.734   Value Loss: 7.764    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 374152     Buffer Size: 24576      Transition Number: 999.988 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:41:52,466][train][INFO][train.py>_log] ==> #701000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 10.278   Value Loss: 7.632    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 374838     Buffer Size: 24716      Transition Number: 1000.006k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:44:34,974][train][INFO][train.py>_log] ==> #702000     Total Loss: 3.293    [weighted Loss:3.293    Policy Loss: 9.954    Value Loss: 7.506    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 375520     Buffer Size: 24883      Transition Number: 999.981 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:47:18,184][train][INFO][train.py>_log] ==> #703000     Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 11.522   Value Loss: 7.970    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 376214     Buffer Size: 25013      Transition Number: 999.964 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:49:58,991][train][INFO][train.py>_log] ==> #704000     Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 11.127   Value Loss: 7.668    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 376935     Buffer Size: 25154      Transition Number: 1000.050k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:52:40,867][train][INFO][train.py>_log] ==> #705000     Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 10.640   Value Loss: 7.413    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 377505     Buffer Size: 25229      Transition Number: 1000.097k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:55:28,562][train][INFO][train.py>_log] ==> #706000     Total Loss: 4.199    [weighted Loss:4.199    Policy Loss: 10.488   Value Loss: 7.825    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 378146     Buffer Size: 25333      Transition Number: 999.951 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 13:58:12,992][train][INFO][train.py>_log] ==> #707000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 11.170   Value Loss: 7.761    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 378678     Buffer Size: 25363      Transition Number: 1000.017k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:00:55,644][train][INFO][train.py>_log] ==> #708000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 9.893    Value Loss: 7.596    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 379201     Buffer Size: 25356      Transition Number: 999.960 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:03:40,882][train][INFO][train.py>_log] ==> #709000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 11.579   Value Loss: 7.946    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 379738     Buffer Size: 25369      Transition Number: 999.962 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:06:24,834][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 10.388   Value Loss: 8.051    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 380306     Buffer Size: 25361      Transition Number: 1000.013k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:09:11,313][train][INFO][train.py>_log] ==> #711000     Total Loss: 2.886    [weighted Loss:2.886    Policy Loss: 10.685   Value Loss: 8.012    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 381457     Buffer Size: 25741      Transition Number: 1000.068k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:11:53,514][train][INFO][train.py>_log] ==> #712000     Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 10.658   Value Loss: 7.894    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 382627     Buffer Size: 25841      Transition Number: 1000.004k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:14:38,400][train][INFO][train.py>_log] ==> #713000     Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 10.675   Value Loss: 7.682    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 383409     Buffer Size: 25730      Transition Number: 1000.031k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:17:21,076][train][INFO][train.py>_log] ==> #714000     Total Loss: 3.091    [weighted Loss:3.091    Policy Loss: 10.058   Value Loss: 7.673    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 384182     Buffer Size: 25880      Transition Number: 999.968 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:20:03,298][train][INFO][train.py>_log] ==> #715000     Total Loss: 3.743    [weighted Loss:3.743    Policy Loss: 9.940    Value Loss: 7.910    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 384777     Buffer Size: 25905      Transition Number: 1000.026k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:22:46,313][train][INFO][train.py>_log] ==> #716000     Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 11.309   Value Loss: 8.378    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 385340     Buffer Size: 25991      Transition Number: 999.988 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:25:32,755][train][INFO][train.py>_log] ==> #717000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 9.217    Value Loss: 7.623    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 385851     Buffer Size: 26037      Transition Number: 999.938 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:28:16,688][train][INFO][train.py>_log] ==> #718000     Total Loss: 3.063    [weighted Loss:3.063    Policy Loss: 10.206   Value Loss: 8.107    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 386410     Buffer Size: 26130      Transition Number: 999.993 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:31:00,794][train][INFO][train.py>_log] ==> #719000     Total Loss: 3.740    [weighted Loss:3.740    Policy Loss: 10.461   Value Loss: 7.824    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 386981     Buffer Size: 26199      Transition Number: 999.966 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:33:44,492][train][INFO][train.py>_log] ==> #720000     Total Loss: 3.821    [weighted Loss:3.821    Policy Loss: 10.812   Value Loss: 7.620    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 387520     Buffer Size: 26220      Transition Number: 1000.005k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:36:30,547][train][INFO][train.py>_log] ==> #721000     Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 10.166   Value Loss: 7.702    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 388125     Buffer Size: 26254      Transition Number: 999.983 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:39:14,672][train][INFO][train.py>_log] ==> #722000     Total Loss: 0.747    [weighted Loss:0.747    Policy Loss: 11.203   Value Loss: 8.030    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 388742     Buffer Size: 26249      Transition Number: 1000.032k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:42:01,911][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.956    [weighted Loss:2.956    Policy Loss: 10.170   Value Loss: 7.941    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 389283     Buffer Size: 26188      Transition Number: 999.990 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:44:43,034][train][INFO][train.py>_log] ==> #724000     Total Loss: 3.616    [weighted Loss:3.616    Policy Loss: 10.594   Value Loss: 7.622    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 389814     Buffer Size: 26149      Transition Number: 1000.034k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:47:27,362][train][INFO][train.py>_log] ==> #725000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 10.287   Value Loss: 7.697    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 390322     Buffer Size: 26088      Transition Number: 999.995 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:50:11,227][train][INFO][train.py>_log] ==> #726000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 9.898    Value Loss: 7.536    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 390834     Buffer Size: 26079      Transition Number: 1000.048k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:52:54,836][train][INFO][train.py>_log] ==> #727000     Total Loss: 4.421    [weighted Loss:4.421    Policy Loss: 10.753   Value Loss: 7.624    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 391395     Buffer Size: 25999      Transition Number: 999.977 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:55:37,814][train][INFO][train.py>_log] ==> #728000     Total Loss: 2.912    [weighted Loss:2.912    Policy Loss: 10.325   Value Loss: 7.607    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 391953     Buffer Size: 25853      Transition Number: 999.981 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 14:58:23,251][train][INFO][train.py>_log] ==> #729000     Total Loss: 3.168    [weighted Loss:3.168    Policy Loss: 10.787   Value Loss: 7.376    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 392436     Buffer Size: 25748      Transition Number: 999.955 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:01:07,527][train][INFO][train.py>_log] ==> #730000     Total Loss: 4.604    [weighted Loss:4.604    Policy Loss: 11.519   Value Loss: 8.023    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 392889     Buffer Size: 25742      Transition Number: 999.965 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:03:54,696][train][INFO][train.py>_log] ==> #731000     Total Loss: 4.617    [weighted Loss:4.617    Policy Loss: 10.320   Value Loss: 7.665    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 393642     Buffer Size: 25962      Transition Number: 1000.024k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:06:36,118][train][INFO][train.py>_log] ==> #732000     Total Loss: 1.311    [weighted Loss:1.311    Policy Loss: 10.355   Value Loss: 7.828    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 394419     Buffer Size: 26187      Transition Number: 1000.074k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:09:16,156][train][INFO][train.py>_log] ==> #733000     Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 10.916   Value Loss: 8.364    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 395082     Buffer Size: 26309      Transition Number: 999.971 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:11:58,391][train][INFO][train.py>_log] ==> #734000     Total Loss: 1.188    [weighted Loss:1.188    Policy Loss: 11.114   Value Loss: 7.626    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 395779     Buffer Size: 26407      Transition Number: 999.983 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:14:43,744][train][INFO][train.py>_log] ==> #735000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 10.452   Value Loss: 7.590    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 396337     Buffer Size: 26380      Transition Number: 999.978 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:17:29,534][train][INFO][train.py>_log] ==> #736000     Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 10.436   Value Loss: 7.853    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 396893     Buffer Size: 26328      Transition Number: 999.998 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:20:12,550][train][INFO][train.py>_log] ==> #737000     Total Loss: 3.955    [weighted Loss:3.955    Policy Loss: 10.614   Value Loss: 7.354    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 397594     Buffer Size: 26419      Transition Number: 999.978 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:22:55,750][train][INFO][train.py>_log] ==> #738000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 11.665   Value Loss: 7.623    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 398308     Buffer Size: 26563      Transition Number: 999.956 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:25:39,390][train][INFO][train.py>_log] ==> #739000     Total Loss: 4.123    [weighted Loss:4.123    Policy Loss: 10.986   Value Loss: 7.867    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 399011     Buffer Size: 26709      Transition Number: 999.949 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:28:22,183][train][INFO][train.py>_log] ==> #740000     Total Loss: 4.476    [weighted Loss:4.476    Policy Loss: 11.330   Value Loss: 7.796    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 399740     Buffer Size: 26920      Transition Number: 999.982 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:31:05,516][train][INFO][train.py>_log] ==> #741000     Total Loss: 3.685    [weighted Loss:3.685    Policy Loss: 11.526   Value Loss: 7.997    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 400272     Buffer Size: 26912      Transition Number: 1000.087k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:33:50,589][train][INFO][train.py>_log] ==> #742000     Total Loss: 2.938    [weighted Loss:2.938    Policy Loss: 11.136   Value Loss: 7.524    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 400827     Buffer Size: 26850      Transition Number: 999.946 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:36:34,046][train][INFO][train.py>_log] ==> #743000     Total Loss: 4.505    [weighted Loss:4.505    Policy Loss: 11.409   Value Loss: 7.741    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 401383     Buffer Size: 26764      Transition Number: 999.999 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:39:18,901][train][INFO][train.py>_log] ==> #744000     Total Loss: 3.134    [weighted Loss:3.134    Policy Loss: 10.501   Value Loss: 8.060    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 401971     Buffer Size: 26641      Transition Number: 999.993 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:42:05,418][train][INFO][train.py>_log] ==> #745000     Total Loss: 5.114    [weighted Loss:5.114    Policy Loss: 11.993   Value Loss: 8.066    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 402478     Buffer Size: 26506      Transition Number: 1000.048k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:44:47,864][train][INFO][train.py>_log] ==> #746000     Total Loss: 4.402    [weighted Loss:4.402    Policy Loss: 11.078   Value Loss: 7.660    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 402974     Buffer Size: 26361      Transition Number: 999.989 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:47:32,623][train][INFO][train.py>_log] ==> #747000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 10.573   Value Loss: 7.455    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 403522     Buffer Size: 26258      Transition Number: 999.971 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:50:14,891][train][INFO][train.py>_log] ==> #748000     Total Loss: 5.178    [weighted Loss:5.178    Policy Loss: 11.174   Value Loss: 7.897    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 404064     Buffer Size: 26189      Transition Number: 1000.077k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:52:56,503][train][INFO][train.py>_log] ==> #749000     Total Loss: 5.037    [weighted Loss:5.037    Policy Loss: 11.413   Value Loss: 7.897    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 404601     Buffer Size: 26171      Transition Number: 999.961 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:55:40,902][train][INFO][train.py>_log] ==> #750000     Total Loss: 3.948    [weighted Loss:3.948    Policy Loss: 11.282   Value Loss: 7.781    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 405192     Buffer Size: 26220      Transition Number: 1000.031k Batch Size: 256        Lr: 0.05120 
[2022-01-04 15:58:24,170][train][INFO][train.py>_log] ==> #751000     Total Loss: 3.717    [weighted Loss:3.717    Policy Loss: 10.532   Value Loss: 8.065    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 405797     Buffer Size: 26294      Transition Number: 999.996 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:01:09,729][train][INFO][train.py>_log] ==> #752000     Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 10.584   Value Loss: 7.929    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 406450     Buffer Size: 26388      Transition Number: 999.992 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:03:54,302][train][INFO][train.py>_log] ==> #753000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 11.284   Value Loss: 7.910    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 407004     Buffer Size: 26183      Transition Number: 999.997 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:06:39,881][train][INFO][train.py>_log] ==> #754000     Total Loss: 4.607    [weighted Loss:4.607    Policy Loss: 10.885   Value Loss: 7.919    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 407583     Buffer Size: 25683      Transition Number: 1000.058k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:09:24,643][train][INFO][train.py>_log] ==> #755000     Total Loss: 3.983    [weighted Loss:3.983    Policy Loss: 11.185   Value Loss: 7.796    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 408163     Buffer Size: 25224      Transition Number: 1000.029k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:12:09,818][train][INFO][train.py>_log] ==> #756000     Total Loss: 4.148    [weighted Loss:4.148    Policy Loss: 11.213   Value Loss: 7.617    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 408748     Buffer Size: 25015      Transition Number: 1000.000k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:14:58,283][train][INFO][train.py>_log] ==> #757000     Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 11.665   Value Loss: 7.978    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 409413     Buffer Size: 24980      Transition Number: 999.997 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:17:45,947][train][INFO][train.py>_log] ==> #758000     Total Loss: 3.666    [weighted Loss:3.666    Policy Loss: 11.526   Value Loss: 7.500    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 410114     Buffer Size: 25099      Transition Number: 999.956 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:20:30,811][train][INFO][train.py>_log] ==> #759000     Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 11.280   Value Loss: 7.894    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 410660     Buffer Size: 25106      Transition Number: 1000.081k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:23:18,886][train][INFO][train.py>_log] ==> #760000     Total Loss: 3.052    [weighted Loss:3.052    Policy Loss: 10.124   Value Loss: 8.070    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 411201     Buffer Size: 25068      Transition Number: 1000.077k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:26:04,191][train][INFO][train.py>_log] ==> #761000     Total Loss: 4.292    [weighted Loss:4.292    Policy Loss: 11.049   Value Loss: 7.295    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 411706     Buffer Size: 25037      Transition Number: 1000.104k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:28:47,939][train][INFO][train.py>_log] ==> #762000     Total Loss: 3.519    [weighted Loss:3.519    Policy Loss: 10.808   Value Loss: 7.513    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 412224     Buffer Size: 25021      Transition Number: 999.977 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:31:31,663][train][INFO][train.py>_log] ==> #763000     Total Loss: 3.581    [weighted Loss:3.581    Policy Loss: 10.936   Value Loss: 7.821    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 412743     Buffer Size: 24999      Transition Number: 999.991 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:34:17,429][train][INFO][train.py>_log] ==> #764000     Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 10.181   Value Loss: 7.389    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 413261     Buffer Size: 24926      Transition Number: 999.986 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:37:02,760][train][INFO][train.py>_log] ==> #765000     Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 10.334   Value Loss: 7.629    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 413762     Buffer Size: 24860      Transition Number: 999.969 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:39:45,681][train][INFO][train.py>_log] ==> #766000     Total Loss: 2.727    [weighted Loss:2.727    Policy Loss: 10.760   Value Loss: 7.841    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 414270     Buffer Size: 24834      Transition Number: 999.987 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:42:27,105][train][INFO][train.py>_log] ==> #767000     Total Loss: 4.273    [weighted Loss:4.273    Policy Loss: 10.601   Value Loss: 7.823    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 414829     Buffer Size: 24865      Transition Number: 1000.025k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:45:11,605][train][INFO][train.py>_log] ==> #768000     Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 10.298   Value Loss: 7.748    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 415402     Buffer Size: 24920      Transition Number: 1000.027k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:47:57,461][train][INFO][train.py>_log] ==> #769000     Total Loss: 3.309    [weighted Loss:3.309    Policy Loss: 10.935   Value Loss: 7.526    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 415940     Buffer Size: 24949      Transition Number: 999.978 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:50:41,305][train][INFO][train.py>_log] ==> #770000     Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 11.127   Value Loss: 8.191    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 416488     Buffer Size: 24941      Transition Number: 1000.023k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:53:25,638][train][INFO][train.py>_log] ==> #771000     Total Loss: 3.658    [weighted Loss:3.658    Policy Loss: 10.763   Value Loss: 7.886    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 417009     Buffer Size: 24935      Transition Number: 999.991 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:56:06,784][train][INFO][train.py>_log] ==> #772000     Total Loss: 3.718    [weighted Loss:3.718    Policy Loss: 10.868   Value Loss: 7.803    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 417530     Buffer Size: 24975      Transition Number: 999.990 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 16:58:53,371][train][INFO][train.py>_log] ==> #773000     Total Loss: 3.616    [weighted Loss:3.616    Policy Loss: 10.790   Value Loss: 7.433    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 418042     Buffer Size: 24962      Transition Number: 1000.101k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:01:37,623][train][INFO][train.py>_log] ==> #774000     Total Loss: 4.393    [weighted Loss:4.393    Policy Loss: 10.980   Value Loss: 7.527    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 418584     Buffer Size: 24724      Transition Number: 999.960 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:04:22,275][train][INFO][train.py>_log] ==> #775000     Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 10.762   Value Loss: 7.296    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 419068     Buffer Size: 24463      Transition Number: 999.998 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:07:08,426][train][INFO][train.py>_log] ==> #776000     Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 10.545   Value Loss: 7.335    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 419564     Buffer Size: 24261      Transition Number: 999.990 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:09:56,706][train][INFO][train.py>_log] ==> #777000     Total Loss: 3.887    [weighted Loss:3.887    Policy Loss: 10.981   Value Loss: 7.545    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 420503     Buffer Size: 24504      Transition Number: 999.956 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:12:42,146][train][INFO][train.py>_log] ==> #778000     Total Loss: 4.222    [weighted Loss:4.222    Policy Loss: 11.222   Value Loss: 7.790    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 421415     Buffer Size: 24868      Transition Number: 999.981 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:15:29,695][train][INFO][train.py>_log] ==> #779000     Total Loss: 3.718    [weighted Loss:3.718    Policy Loss: 12.022   Value Loss: 8.195    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 421902     Buffer Size: 24791      Transition Number: 999.966 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:18:16,771][train][INFO][train.py>_log] ==> #780000     Total Loss: 4.271    [weighted Loss:4.271    Policy Loss: 10.980   Value Loss: 7.603    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 422396     Buffer Size: 24596      Transition Number: 999.960 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:21:02,368][train][INFO][train.py>_log] ==> #781000     Total Loss: 5.921    [weighted Loss:5.921    Policy Loss: 11.199   Value Loss: 7.404    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 422920     Buffer Size: 24407      Transition Number: 999.963 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:23:48,005][train][INFO][train.py>_log] ==> #782000     Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 11.162   Value Loss: 7.947    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 423453     Buffer Size: 24260      Transition Number: 999.988 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:26:32,829][train][INFO][train.py>_log] ==> #783000     Total Loss: 3.567    [weighted Loss:3.567    Policy Loss: 10.788   Value Loss: 7.419    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 424069     Buffer Size: 24158      Transition Number: 999.978 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:29:18,521][train][INFO][train.py>_log] ==> #784000     Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 10.646   Value Loss: 7.686    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 424689     Buffer Size: 24222      Transition Number: 1000.077k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:32:05,631][train][INFO][train.py>_log] ==> #785000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 11.244   Value Loss: 7.781    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 425349     Buffer Size: 24308      Transition Number: 999.985 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:34:50,061][train][INFO][train.py>_log] ==> #786000     Total Loss: 4.761    [weighted Loss:4.761    Policy Loss: 11.881   Value Loss: 7.777    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 426027     Buffer Size: 24419      Transition Number: 1000.003k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:37:31,739][train][INFO][train.py>_log] ==> #787000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 10.772   Value Loss: 7.734    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 426733     Buffer Size: 24552      Transition Number: 1000.010k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:40:16,308][train][INFO][train.py>_log] ==> #788000     Total Loss: 2.700    [weighted Loss:2.700    Policy Loss: 11.083   Value Loss: 7.636    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 427431     Buffer Size: 24719      Transition Number: 999.985 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:43:05,364][train][INFO][train.py>_log] ==> #789000     Total Loss: 3.565    [weighted Loss:3.565    Policy Loss: 10.589   Value Loss: 7.765    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 427970     Buffer Size: 24759      Transition Number: 999.985 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:45:51,790][train][INFO][train.py>_log] ==> #790000     Total Loss: 4.305    [weighted Loss:4.305    Policy Loss: 11.399   Value Loss: 7.786    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 428526     Buffer Size: 24758      Transition Number: 999.985 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:48:36,592][train][INFO][train.py>_log] ==> #791000     Total Loss: 4.294    [weighted Loss:4.294    Policy Loss: 10.499   Value Loss: 7.602    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 429067     Buffer Size: 24756      Transition Number: 999.995 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:51:24,147][train][INFO][train.py>_log] ==> #792000     Total Loss: 3.754    [weighted Loss:3.754    Policy Loss: 11.332   Value Loss: 7.441    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 429617     Buffer Size: 24730      Transition Number: 1000.010k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:54:08,746][train][INFO][train.py>_log] ==> #793000     Total Loss: 4.343    [weighted Loss:4.343    Policy Loss: 11.280   Value Loss: 7.684    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 430158     Buffer Size: 24666      Transition Number: 999.977 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:56:53,898][train][INFO][train.py>_log] ==> #794000     Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 9.947    Value Loss: 7.361    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 430680     Buffer Size: 24588      Transition Number: 1000.000k Batch Size: 256        Lr: 0.05120 
[2022-01-04 17:59:42,178][train][INFO][train.py>_log] ==> #795000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 10.528   Value Loss: 7.749    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 431237     Buffer Size: 24517      Transition Number: 1000.029k Batch Size: 256        Lr: 0.05120 
[2022-01-04 18:02:32,034][train][INFO][train.py>_log] ==> #796000     Total Loss: 1.937    [weighted Loss:1.937    Policy Loss: 11.322   Value Loss: 7.811    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 431806     Buffer Size: 24472      Transition Number: 1000.047k Batch Size: 256        Lr: 0.05120 
[2022-01-04 18:05:18,219][train][INFO][train.py>_log] ==> #797000     Total Loss: 3.789    [weighted Loss:3.789    Policy Loss: 10.954   Value Loss: 7.469    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 432335     Buffer Size: 24452      Transition Number: 1000.000k Batch Size: 256        Lr: 0.05120 
[2022-01-04 18:08:07,435][train][INFO][train.py>_log] ==> #798000     Total Loss: 3.302    [weighted Loss:3.302    Policy Loss: 10.100   Value Loss: 7.520    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 432910     Buffer Size: 24420      Transition Number: 999.976 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 18:10:53,339][train][INFO][train.py>_log] ==> #799000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 10.805   Value Loss: 7.688    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 433404     Buffer Size: 24302      Transition Number: 1000.012k Batch Size: 256        Lr: 0.05120 
[2022-01-04 18:13:38,716][train][INFO][train.py>_log] ==> #800000     Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 10.846   Value Loss: 7.592    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 433888     Buffer Size: 24146      Transition Number: 999.973 k Batch Size: 256        Lr: 0.05120 
[2022-01-04 18:16:21,338][train][INFO][train.py>_log] ==> #801000     Total Loss: 3.585    [weighted Loss:3.585    Policy Loss: 11.275   Value Loss: 7.597    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 434438     Buffer Size: 24065      Transition Number: 999.994 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:19:08,748][train][INFO][train.py>_log] ==> #802000     Total Loss: 3.177    [weighted Loss:3.177    Policy Loss: 10.335   Value Loss: 7.554    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 435013     Buffer Size: 24110      Transition Number: 999.980 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:21:55,483][train][INFO][train.py>_log] ==> #803000     Total Loss: 4.085    [weighted Loss:4.085    Policy Loss: 10.166   Value Loss: 7.733    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 435538     Buffer Size: 24103      Transition Number: 999.982 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:24:39,861][train][INFO][train.py>_log] ==> #804000     Total Loss: 3.931    [weighted Loss:3.931    Policy Loss: 10.653   Value Loss: 7.644    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 436054     Buffer Size: 24101      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:27:26,569][train][INFO][train.py>_log] ==> #805000     Total Loss: 3.769    [weighted Loss:3.769    Policy Loss: 11.059   Value Loss: 7.838    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 436584     Buffer Size: 24101      Transition Number: 999.952 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:30:12,302][train][INFO][train.py>_log] ==> #806000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 10.900   Value Loss: 7.548    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 437137     Buffer Size: 24120      Transition Number: 999.990 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:32:59,287][train][INFO][train.py>_log] ==> #807000     Total Loss: 2.789    [weighted Loss:2.789    Policy Loss: 10.097   Value Loss: 7.391    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 437707     Buffer Size: 24164      Transition Number: 1000.020k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:35:45,645][train][INFO][train.py>_log] ==> #808000     Total Loss: 3.956    [weighted Loss:3.956    Policy Loss: 10.676   Value Loss: 7.538    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 438270     Buffer Size: 24206      Transition Number: 999.972 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:38:31,910][train][INFO][train.py>_log] ==> #809000     Total Loss: 3.929    [weighted Loss:3.929    Policy Loss: 10.544   Value Loss: 7.561    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 438773     Buffer Size: 24160      Transition Number: 999.957 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:41:15,019][train][INFO][train.py>_log] ==> #810000     Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 10.317   Value Loss: 7.440    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 439283     Buffer Size: 24115      Transition Number: 999.992 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:44:03,477][train][INFO][train.py>_log] ==> #811000     Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 10.343   Value Loss: 7.749    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 439729     Buffer Size: 24002      Transition Number: 999.995 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:46:47,842][train][INFO][train.py>_log] ==> #812000     Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 10.417   Value Loss: 7.576    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 440153     Buffer Size: 23912      Transition Number: 999.990 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:49:32,626][train][INFO][train.py>_log] ==> #813000     Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 10.461   Value Loss: 7.676    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 440571     Buffer Size: 23818      Transition Number: 999.989 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:52:16,244][train][INFO][train.py>_log] ==> #814000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 10.409   Value Loss: 7.796    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 441012     Buffer Size: 23738      Transition Number: 1000.047k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:54:59,055][train][INFO][train.py>_log] ==> #815000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 10.531   Value Loss: 7.638    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 441484     Buffer Size: 23690      Transition Number: 999.982 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 18:57:44,935][train][INFO][train.py>_log] ==> #816000     Total Loss: 4.054    [weighted Loss:4.054    Policy Loss: 10.099   Value Loss: 7.630    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 441955     Buffer Size: 23631      Transition Number: 1000.016k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:00:30,886][train][INFO][train.py>_log] ==> #817000     Total Loss: 4.154    [weighted Loss:4.154    Policy Loss: 10.001   Value Loss: 7.529    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 442395     Buffer Size: 23566      Transition Number: 999.962 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:03:16,216][train][INFO][train.py>_log] ==> #818000     Total Loss: 3.478    [weighted Loss:3.478    Policy Loss: 10.258   Value Loss: 7.594    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 442857     Buffer Size: 23536      Transition Number: 999.964 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:06:05,532][train][INFO][train.py>_log] ==> #819000     Total Loss: 3.644    [weighted Loss:3.644    Policy Loss: 9.810    Value Loss: 7.622    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 443389     Buffer Size: 23373      Transition Number: 999.984 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:08:50,873][train][INFO][train.py>_log] ==> #820000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 10.068   Value Loss: 7.556    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 443895     Buffer Size: 22921      Transition Number: 999.966 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:11:34,594][train][INFO][train.py>_log] ==> #821000     Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 10.244   Value Loss: 7.516    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 444374     Buffer Size: 22726      Transition Number: 999.948 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:14:22,725][train][INFO][train.py>_log] ==> #822000     Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 9.764    Value Loss: 7.526    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 444890     Buffer Size: 22758      Transition Number: 999.991 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:17:10,002][train][INFO][train.py>_log] ==> #823000     Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 10.041   Value Loss: 7.824    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 445362     Buffer Size: 22711      Transition Number: 1000.007k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:19:54,881][train][INFO][train.py>_log] ==> #824000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 10.477   Value Loss: 7.927    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 445840     Buffer Size: 22613      Transition Number: 999.990 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:22:42,887][train][INFO][train.py>_log] ==> #825000     Total Loss: 1.407    [weighted Loss:1.407    Policy Loss: 10.376   Value Loss: 7.594    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 446247     Buffer Size: 22506      Transition Number: 999.985 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:25:31,282][train][INFO][train.py>_log] ==> #826000     Total Loss: 3.305    [weighted Loss:3.305    Policy Loss: 10.149   Value Loss: 7.595    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 446674     Buffer Size: 22347      Transition Number: 999.968 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:28:18,108][train][INFO][train.py>_log] ==> #827000     Total Loss: 3.720    [weighted Loss:3.720    Policy Loss: 10.616   Value Loss: 7.622    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 447109     Buffer Size: 22160      Transition Number: 1000.128k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:31:04,716][train][INFO][train.py>_log] ==> #828000     Total Loss: 3.791    [weighted Loss:3.791    Policy Loss: 10.974   Value Loss: 7.680    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 447560     Buffer Size: 21949      Transition Number: 1000.043k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:33:54,731][train][INFO][train.py>_log] ==> #829000     Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 10.311   Value Loss: 7.532    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 448056     Buffer Size: 21774      Transition Number: 999.992 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:36:41,610][train][INFO][train.py>_log] ==> #830000     Total Loss: 4.326    [weighted Loss:4.326    Policy Loss: 11.740   Value Loss: 8.356    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 448539     Buffer Size: 21593      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:39:30,306][train][INFO][train.py>_log] ==> #831000     Total Loss: 1.359    [weighted Loss:1.359    Policy Loss: 10.224   Value Loss: 7.829    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 449057     Buffer Size: 21462      Transition Number: 999.948 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:42:14,715][train][INFO][train.py>_log] ==> #832000     Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 11.059   Value Loss: 7.838    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 449586     Buffer Size: 21449      Transition Number: 999.979 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:45:01,017][train][INFO][train.py>_log] ==> #833000     Total Loss: 3.646    [weighted Loss:3.646    Policy Loss: 10.239   Value Loss: 7.249    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 450054     Buffer Size: 21375      Transition Number: 999.978 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:47:48,628][train][INFO][train.py>_log] ==> #834000     Total Loss: 3.262    [weighted Loss:3.262    Policy Loss: 10.489   Value Loss: 7.591    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 450528     Buffer Size: 21311      Transition Number: 999.964 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:50:36,052][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.705    [weighted Loss:2.705    Policy Loss: 11.022   Value Loss: 7.467    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 451042     Buffer Size: 21255      Transition Number: 999.970 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:53:23,167][train][INFO][train.py>_log] ==> #836000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 11.478   Value Loss: 7.494    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 451532     Buffer Size: 21206      Transition Number: 999.984 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:56:10,305][train][INFO][train.py>_log] ==> #837000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 10.869   Value Loss: 7.561    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 452068     Buffer Size: 21206      Transition Number: 999.993 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 19:58:55,328][train][INFO][train.py>_log] ==> #838000     Total Loss: 3.111    [weighted Loss:3.111    Policy Loss: 10.723   Value Loss: 7.825    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 452619     Buffer Size: 21207      Transition Number: 999.979 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:01:41,374][train][INFO][train.py>_log] ==> #839000     Total Loss: 4.581    [weighted Loss:4.581    Policy Loss: 11.202   Value Loss: 7.694    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 453174     Buffer Size: 21200      Transition Number: 999.965 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:04:28,945][train][INFO][train.py>_log] ==> #840000     Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 10.739   Value Loss: 7.066    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 453705     Buffer Size: 21171      Transition Number: 999.954 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:07:19,059][train][INFO][train.py>_log] ==> #841000     Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 11.504   Value Loss: 7.435    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 454272     Buffer Size: 21210      Transition Number: 999.970 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:10:06,017][train][INFO][train.py>_log] ==> #842000     Total Loss: 2.358    [weighted Loss:2.358    Policy Loss: 11.435   Value Loss: 7.655    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 454829     Buffer Size: 21265      Transition Number: 1000.015k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:12:53,959][train][INFO][train.py>_log] ==> #843000     Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 11.525   Value Loss: 7.775    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 455560     Buffer Size: 21418      Transition Number: 999.955 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:15:44,208][train][INFO][train.py>_log] ==> #844000     Total Loss: 3.679    [weighted Loss:3.679    Policy Loss: 10.491   Value Loss: 7.424    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 456250     Buffer Size: 21496      Transition Number: 999.989 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:18:29,998][train][INFO][train.py>_log] ==> #845000     Total Loss: 4.420    [weighted Loss:4.420    Policy Loss: 10.796   Value Loss: 7.024    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 456943     Buffer Size: 21624      Transition Number: 999.982 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:21:15,826][train][INFO][train.py>_log] ==> #846000     Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 12.277   Value Loss: 7.815    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 457660     Buffer Size: 21802      Transition Number: 1000.028k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:24:01,113][train][INFO][train.py>_log] ==> #847000     Total Loss: 4.015    [weighted Loss:4.015    Policy Loss: 11.692   Value Loss: 7.518    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 458324     Buffer Size: 21918      Transition Number: 999.957 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:26:47,683][train][INFO][train.py>_log] ==> #848000     Total Loss: 2.639    [weighted Loss:2.639    Policy Loss: 11.155   Value Loss: 7.675    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 458979     Buffer Size: 22005      Transition Number: 1000.035k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:29:36,604][train][INFO][train.py>_log] ==> #849000     Total Loss: 3.095    [weighted Loss:3.095    Policy Loss: 10.742   Value Loss: 7.615    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 459501     Buffer Size: 21966      Transition Number: 999.958 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:32:25,571][train][INFO][train.py>_log] ==> #850000     Total Loss: 0.923    [weighted Loss:0.923    Policy Loss: 10.964   Value Loss: 7.745    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 459989     Buffer Size: 21920      Transition Number: 999.985 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:35:14,415][train][INFO][train.py>_log] ==> #851000     Total Loss: 4.878    [weighted Loss:4.878    Policy Loss: 10.339   Value Loss: 7.390    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 460567     Buffer Size: 21960      Transition Number: 999.987 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:38:03,386][train][INFO][train.py>_log] ==> #852000     Total Loss: 4.282    [weighted Loss:4.282    Policy Loss: 12.211   Value Loss: 7.945    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 461150     Buffer Size: 22008      Transition Number: 999.991 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:40:50,626][train][INFO][train.py>_log] ==> #853000     Total Loss: 1.574    [weighted Loss:1.574    Policy Loss: 10.803   Value Loss: 7.215    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 461791     Buffer Size: 22176      Transition Number: 999.987 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:43:38,653][train][INFO][train.py>_log] ==> #854000     Total Loss: 3.495    [weighted Loss:3.495    Policy Loss: 11.110   Value Loss: 7.707    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 462500     Buffer Size: 22411      Transition Number: 999.998 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:46:26,511][train][INFO][train.py>_log] ==> #855000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 10.318   Value Loss: 7.315    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 463078     Buffer Size: 22536      Transition Number: 999.987 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:49:12,739][train][INFO][train.py>_log] ==> #856000     Total Loss: 4.409    [weighted Loss:4.409    Policy Loss: 11.403   Value Loss: 7.323    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 463650     Buffer Size: 22651      Transition Number: 1000.020k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:51:59,250][train][INFO][train.py>_log] ==> #857000     Total Loss: 3.610    [weighted Loss:3.610    Policy Loss: 11.063   Value Loss: 8.070    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 464226     Buffer Size: 22740      Transition Number: 999.973 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:54:43,192][train][INFO][train.py>_log] ==> #858000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 10.974   Value Loss: 7.579    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 464773     Buffer Size: 22833      Transition Number: 1000.064k Batch Size: 256        Lr: 0.04096 
[2022-01-04 20:57:30,220][train][INFO][train.py>_log] ==> #859000     Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 10.785   Value Loss: 7.374    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 465327     Buffer Size: 22909      Transition Number: 999.983 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:00:13,608][train][INFO][train.py>_log] ==> #860000     Total Loss: 1.339    [weighted Loss:1.339    Policy Loss: 10.404   Value Loss: 7.361    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 465872     Buffer Size: 22995      Transition Number: 1000.059k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:02:56,521][train][INFO][train.py>_log] ==> #861000     Total Loss: 4.399    [weighted Loss:4.399    Policy Loss: 11.168   Value Loss: 7.719    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 466328     Buffer Size: 22980      Transition Number: 1000.045k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:05:41,873][train][INFO][train.py>_log] ==> #862000     Total Loss: 4.072    [weighted Loss:4.072    Policy Loss: 10.453   Value Loss: 7.613    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 466828     Buffer Size: 22990      Transition Number: 1000.014k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:08:25,381][train][INFO][train.py>_log] ==> #863000     Total Loss: 2.938    [weighted Loss:2.938    Policy Loss: 10.836   Value Loss: 7.560    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 467303     Buffer Size: 22965      Transition Number: 999.955 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:11:07,815][train][INFO][train.py>_log] ==> #864000     Total Loss: 2.837    [weighted Loss:2.837    Policy Loss: 11.215   Value Loss: 7.950    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 467758     Buffer Size: 22934      Transition Number: 999.955 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:13:50,800][train][INFO][train.py>_log] ==> #865000     Total Loss: 4.084    [weighted Loss:4.084    Policy Loss: 10.651   Value Loss: 7.420    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 468229     Buffer Size: 22953      Transition Number: 999.977 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:16:38,736][train][INFO][train.py>_log] ==> #866000     Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 9.999    Value Loss: 7.060    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 468747     Buffer Size: 22987      Transition Number: 999.990 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:19:19,876][train][INFO][train.py>_log] ==> #867000     Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 10.289   Value Loss: 7.592    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 469247     Buffer Size: 23037      Transition Number: 999.980 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:22:07,795][train][INFO][train.py>_log] ==> #868000     Total Loss: 1.213    [weighted Loss:1.213    Policy Loss: 10.442   Value Loss: 7.368    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 469772     Buffer Size: 23109      Transition Number: 999.956 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:24:50,564][train][INFO][train.py>_log] ==> #869000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 11.091   Value Loss: 7.204    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 470332     Buffer Size: 23244      Transition Number: 999.992 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:27:33,682][train][INFO][train.py>_log] ==> #870000     Total Loss: 1.614    [weighted Loss:1.614    Policy Loss: 10.947   Value Loss: 7.538    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 470910     Buffer Size: 23380      Transition Number: 999.949 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:30:17,888][train][INFO][train.py>_log] ==> #871000     Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 11.136   Value Loss: 7.782    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 471413     Buffer Size: 23406      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:33:03,366][train][INFO][train.py>_log] ==> #872000     Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 11.134   Value Loss: 7.312    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 471938     Buffer Size: 23433      Transition Number: 999.968 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:35:46,161][train][INFO][train.py>_log] ==> #873000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 11.347   Value Loss: 7.734    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 472417     Buffer Size: 23408      Transition Number: 999.951 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:38:30,124][train][INFO][train.py>_log] ==> #874000     Total Loss: 3.084    [weighted Loss:3.084    Policy Loss: 10.734   Value Loss: 7.338    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 472899     Buffer Size: 23363      Transition Number: 999.961 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:41:17,805][train][INFO][train.py>_log] ==> #875000     Total Loss: 4.556    [weighted Loss:4.556    Policy Loss: 11.004   Value Loss: 7.309    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 473356     Buffer Size: 23349      Transition Number: 999.974 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:44:05,766][train][INFO][train.py>_log] ==> #876000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 10.744   Value Loss: 7.429    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 473831     Buffer Size: 23330      Transition Number: 1000.032k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:46:54,395][train][INFO][train.py>_log] ==> #877000     Total Loss: 2.779    [weighted Loss:2.779    Policy Loss: 10.811   Value Loss: 7.611    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 474270     Buffer Size: 23294      Transition Number: 999.964 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:49:43,719][train][INFO][train.py>_log] ==> #878000     Total Loss: 2.841    [weighted Loss:2.841    Policy Loss: 11.358   Value Loss: 7.624    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 474719     Buffer Size: 23260      Transition Number: 999.982 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:52:31,687][train][INFO][train.py>_log] ==> #879000     Total Loss: 4.831    [weighted Loss:4.831    Policy Loss: 10.667   Value Loss: 7.416    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 475260     Buffer Size: 23251      Transition Number: 999.991 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:55:19,751][train][INFO][train.py>_log] ==> #880000     Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 11.665   Value Loss: 7.931    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 475782     Buffer Size: 23221      Transition Number: 1000.013k Batch Size: 256        Lr: 0.04096 
[2022-01-04 21:58:05,555][train][INFO][train.py>_log] ==> #881000     Total Loss: 3.788    [weighted Loss:3.788    Policy Loss: 11.025   Value Loss: 7.659    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 476292     Buffer Size: 23202      Transition Number: 999.995 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:00:54,645][train][INFO][train.py>_log] ==> #882000     Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 11.213   Value Loss: 7.485    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 476833     Buffer Size: 23208      Transition Number: 999.955 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:03:42,480][train][INFO][train.py>_log] ==> #883000     Total Loss: 3.705    [weighted Loss:3.705    Policy Loss: 11.295   Value Loss: 7.686    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 477312     Buffer Size: 23146      Transition Number: 999.970 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:06:28,137][train][INFO][train.py>_log] ==> #884000     Total Loss: 2.959    [weighted Loss:2.959    Policy Loss: 11.780   Value Loss: 7.469    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 477795     Buffer Size: 23073      Transition Number: 1000.005k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:09:15,194][train][INFO][train.py>_log] ==> #885000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 11.436   Value Loss: 7.391    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 478231     Buffer Size: 22886      Transition Number: 999.948 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:12:06,580][train][INFO][train.py>_log] ==> #886000     Total Loss: 4.778    [weighted Loss:4.778    Policy Loss: 10.991   Value Loss: 7.620    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 478693     Buffer Size: 22664      Transition Number: 999.996 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:14:54,983][train][INFO][train.py>_log] ==> #887000     Total Loss: 3.364    [weighted Loss:3.364    Policy Loss: 11.433   Value Loss: 7.763    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 479184     Buffer Size: 22485      Transition Number: 999.989 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:17:44,257][train][INFO][train.py>_log] ==> #888000     Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 11.373   Value Loss: 7.591    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 479690     Buffer Size: 22255      Transition Number: 999.949 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:20:34,038][train][INFO][train.py>_log] ==> #889000     Total Loss: 4.181    [weighted Loss:4.181    Policy Loss: 10.941   Value Loss: 7.506    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 480256     Buffer Size: 22149      Transition Number: 1000.001k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:23:22,512][train][INFO][train.py>_log] ==> #890000     Total Loss: 3.144    [weighted Loss:3.144    Policy Loss: 11.193   Value Loss: 7.542    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 480845     Buffer Size: 22070      Transition Number: 999.969 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:26:09,700][train][INFO][train.py>_log] ==> #891000     Total Loss: 1.550    [weighted Loss:1.550    Policy Loss: 11.037   Value Loss: 7.609    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 481507     Buffer Size: 22115      Transition Number: 999.979 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:28:54,331][train][INFO][train.py>_log] ==> #892000     Total Loss: 3.819    [weighted Loss:3.819    Policy Loss: 11.526   Value Loss: 7.082    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 482172     Buffer Size: 22260      Transition Number: 999.992 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:31:42,519][train][INFO][train.py>_log] ==> #893000     Total Loss: 3.170    [weighted Loss:3.170    Policy Loss: 11.311   Value Loss: 7.564    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 482773     Buffer Size: 22308      Transition Number: 1000.090k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:34:32,104][train][INFO][train.py>_log] ==> #894000     Total Loss: 3.480    [weighted Loss:3.480    Policy Loss: 11.851   Value Loss: 7.427    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 483398     Buffer Size: 22334      Transition Number: 999.997 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:37:19,973][train][INFO][train.py>_log] ==> #895000     Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 12.404   Value Loss: 7.868    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 483947     Buffer Size: 22244      Transition Number: 999.967 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:40:07,725][train][INFO][train.py>_log] ==> #896000     Total Loss: 3.459    [weighted Loss:3.459    Policy Loss: 12.541   Value Loss: 8.246    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 484460     Buffer Size: 22090      Transition Number: 999.992 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:42:49,567][train][INFO][train.py>_log] ==> #897000     Total Loss: 0.862    [weighted Loss:0.862    Policy Loss: 11.371   Value Loss: 7.489    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 484961     Buffer Size: 22024      Transition Number: 999.984 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:45:35,055][train][INFO][train.py>_log] ==> #898000     Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 12.079   Value Loss: 7.696    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 485493     Buffer Size: 21975      Transition Number: 999.977 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:48:20,336][train][INFO][train.py>_log] ==> #899000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 11.740   Value Loss: 7.757    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 486024     Buffer Size: 21935      Transition Number: 999.963 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:51:08,990][train][INFO][train.py>_log] ==> #900000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 12.367   Value Loss: 7.611    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 486583     Buffer Size: 21905      Transition Number: 999.988 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:53:54,182][train][INFO][train.py>_log] ==> #901000     Total Loss: 3.391    [weighted Loss:3.391    Policy Loss: 12.207   Value Loss: 7.754    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 487152     Buffer Size: 21935      Transition Number: 1000.054k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:56:43,881][train][INFO][train.py>_log] ==> #902000     Total Loss: 3.666    [weighted Loss:3.666    Policy Loss: 12.246   Value Loss: 7.534    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 487722     Buffer Size: 21956      Transition Number: 999.954 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 22:59:34,177][train][INFO][train.py>_log] ==> #903000     Total Loss: 4.251    [weighted Loss:4.251    Policy Loss: 12.202   Value Loss: 7.649    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 488304     Buffer Size: 22017      Transition Number: 1000.031k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:02:17,179][train][INFO][train.py>_log] ==> #904000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 11.526   Value Loss: 7.355    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 488890     Buffer Size: 22086      Transition Number: 999.980 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:05:06,250][train][INFO][train.py>_log] ==> #905000     Total Loss: 3.168    [weighted Loss:3.168    Policy Loss: 12.263   Value Loss: 7.749    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 489445     Buffer Size: 22158      Transition Number: 1000.048k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:07:56,065][train][INFO][train.py>_log] ==> #906000     Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 11.882   Value Loss: 7.594    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 490011     Buffer Size: 22214      Transition Number: 1000.013k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:10:43,164][train][INFO][train.py>_log] ==> #907000     Total Loss: 3.446    [weighted Loss:3.446    Policy Loss: 12.103   Value Loss: 7.441    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 490558     Buffer Size: 22246      Transition Number: 999.936 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:13:31,583][train][INFO][train.py>_log] ==> #908000     Total Loss: 2.882    [weighted Loss:2.882    Policy Loss: 11.962   Value Loss: 7.580    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 491098     Buffer Size: 22277      Transition Number: 999.977 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:16:19,710][train][INFO][train.py>_log] ==> #909000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 11.215   Value Loss: 7.480    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 491592     Buffer Size: 22274      Transition Number: 999.959 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:19:04,793][train][INFO][train.py>_log] ==> #910000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 10.913   Value Loss: 7.880    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 492085     Buffer Size: 22264      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:21:52,045][train][INFO][train.py>_log] ==> #911000     Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 11.155   Value Loss: 7.355    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 492627     Buffer Size: 22197      Transition Number: 999.959 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:24:38,567][train][INFO][train.py>_log] ==> #912000     Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 12.418   Value Loss: 7.871    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 493148     Buffer Size: 22146      Transition Number: 999.956 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:27:27,830][train][INFO][train.py>_log] ==> #913000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 11.783   Value Loss: 7.498    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 493803     Buffer Size: 22272      Transition Number: 999.993 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:30:15,113][train][INFO][train.py>_log] ==> #914000     Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 11.085   Value Loss: 7.782    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 494455     Buffer Size: 22387      Transition Number: 1000.000k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:33:01,035][train][INFO][train.py>_log] ==> #915000     Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 11.435   Value Loss: 7.767    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 495089     Buffer Size: 22522      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:35:48,908][train][INFO][train.py>_log] ==> #916000     Total Loss: 3.228    [weighted Loss:3.228    Policy Loss: 12.235   Value Loss: 8.044    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 495762     Buffer Size: 22668      Transition Number: 999.975 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:38:32,419][train][INFO][train.py>_log] ==> #917000     Total Loss: 3.918    [weighted Loss:3.918    Policy Loss: 11.369   Value Loss: 7.528    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 496302     Buffer Size: 22776      Transition Number: 1000.141k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:41:19,152][train][INFO][train.py>_log] ==> #918000     Total Loss: 3.736    [weighted Loss:3.736    Policy Loss: 11.334   Value Loss: 7.789    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 496888     Buffer Size: 22881      Transition Number: 1000.078k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:44:06,192][train][INFO][train.py>_log] ==> #919000     Total Loss: 5.482    [weighted Loss:5.482    Policy Loss: 11.913   Value Loss: 7.601    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 497578     Buffer Size: 23084      Transition Number: 1000.046k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:46:51,398][train][INFO][train.py>_log] ==> #920000     Total Loss: 5.214    [weighted Loss:5.214    Policy Loss: 11.862   Value Loss: 8.044    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 498251     Buffer Size: 23237      Transition Number: 1000.028k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:49:35,695][train][INFO][train.py>_log] ==> #921000     Total Loss: 3.663    [weighted Loss:3.663    Policy Loss: 10.932   Value Loss: 7.742    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 498919     Buffer Size: 23371      Transition Number: 999.960 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:52:19,529][train][INFO][train.py>_log] ==> #922000     Total Loss: 1.242    [weighted Loss:1.242    Policy Loss: 11.306   Value Loss: 7.368    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 499594     Buffer Size: 23526      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:55:04,894][train][INFO][train.py>_log] ==> #923000     Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 11.755   Value Loss: 7.476    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 500365     Buffer Size: 23747      Transition Number: 999.995 k Batch Size: 256        Lr: 0.04096 
[2022-01-04 23:57:47,157][train][INFO][train.py>_log] ==> #924000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 10.756   Value Loss: 7.765    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 501107     Buffer Size: 23981      Transition Number: 999.992 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:00:29,609][train][INFO][train.py>_log] ==> #925000     Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 11.885   Value Loss: 8.205    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 501746     Buffer Size: 24160      Transition Number: 999.964 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:03:14,802][train][INFO][train.py>_log] ==> #926000     Total Loss: 4.040    [weighted Loss:4.040    Policy Loss: 12.060   Value Loss: 7.745    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 502435     Buffer Size: 24370      Transition Number: 999.970 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:06:00,261][train][INFO][train.py>_log] ==> #927000     Total Loss: 3.017    [weighted Loss:3.017    Policy Loss: 11.380   Value Loss: 7.781    Reward Loss: 1.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 503098     Buffer Size: 24570      Transition Number: 999.986 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:08:43,327][train][INFO][train.py>_log] ==> #928000     Total Loss: 3.930    [weighted Loss:3.930    Policy Loss: 11.457   Value Loss: 7.520    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 503772     Buffer Size: 24771      Transition Number: 999.982 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:11:25,383][train][INFO][train.py>_log] ==> #929000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 11.561   Value Loss: 7.541    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 504356     Buffer Size: 24887      Transition Number: 999.981 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:14:08,381][train][INFO][train.py>_log] ==> #930000     Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 10.942   Value Loss: 8.014    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 504980     Buffer Size: 24999      Transition Number: 999.969 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:16:52,266][train][INFO][train.py>_log] ==> #931000     Total Loss: 3.000    [weighted Loss:3.000    Policy Loss: 11.610   Value Loss: 7.685    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 505632     Buffer Size: 25065      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:19:34,931][train][INFO][train.py>_log] ==> #932000     Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 11.501   Value Loss: 7.844    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 506261     Buffer Size: 25132      Transition Number: 999.990 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:22:16,562][train][INFO][train.py>_log] ==> #933000     Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 10.947   Value Loss: 7.408    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 506975     Buffer Size: 25223      Transition Number: 999.987 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:25:01,045][train][INFO][train.py>_log] ==> #934000     Total Loss: 2.626    [weighted Loss:2.626    Policy Loss: 11.883   Value Loss: 8.277    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 507717     Buffer Size: 25310      Transition Number: 999.947 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:27:44,243][train][INFO][train.py>_log] ==> #935000     Total Loss: 4.127    [weighted Loss:4.127    Policy Loss: 11.163   Value Loss: 7.745    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 508395     Buffer Size: 25383      Transition Number: 1000.023k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:30:28,122][train][INFO][train.py>_log] ==> #936000     Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 11.080   Value Loss: 7.619    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 509075     Buffer Size: 25490      Transition Number: 1000.051k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:33:08,183][train][INFO][train.py>_log] ==> #937000     Total Loss: 0.282    [weighted Loss:0.282    Policy Loss: 11.407   Value Loss: 7.783    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 509591     Buffer Size: 25522      Transition Number: 1000.007k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:35:50,625][train][INFO][train.py>_log] ==> #938000     Total Loss: 1.854    [weighted Loss:1.854    Policy Loss: 11.441   Value Loss: 7.932    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 510152     Buffer Size: 25585      Transition Number: 999.986 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:38:33,671][train][INFO][train.py>_log] ==> #939000     Total Loss: 3.553    [weighted Loss:3.553    Policy Loss: 11.174   Value Loss: 7.553    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 510693     Buffer Size: 25602      Transition Number: 999.960 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:41:19,429][train][INFO][train.py>_log] ==> #940000     Total Loss: 3.391    [weighted Loss:3.391    Policy Loss: 10.976   Value Loss: 7.448    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 511280     Buffer Size: 25644      Transition Number: 1000.017k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:44:02,841][train][INFO][train.py>_log] ==> #941000     Total Loss: 4.579    [weighted Loss:4.579    Policy Loss: 11.422   Value Loss: 8.073    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 511778     Buffer Size: 25634      Transition Number: 999.996 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:46:50,413][train][INFO][train.py>_log] ==> #942000     Total Loss: 4.556    [weighted Loss:4.556    Policy Loss: 11.304   Value Loss: 7.631    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 512290     Buffer Size: 25632      Transition Number: 999.975 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:49:33,618][train][INFO][train.py>_log] ==> #943000     Total Loss: 2.949    [weighted Loss:2.949    Policy Loss: 11.455   Value Loss: 7.979    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 512861     Buffer Size: 25623      Transition Number: 999.975 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:52:15,688][train][INFO][train.py>_log] ==> #944000     Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 11.067   Value Loss: 7.719    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 513445     Buffer Size: 25640      Transition Number: 999.991 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:55:02,746][train][INFO][train.py>_log] ==> #945000     Total Loss: 1.230    [weighted Loss:1.230    Policy Loss: 10.899   Value Loss: 7.457    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 514146     Buffer Size: 25768      Transition Number: 999.962 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 00:57:46,646][train][INFO][train.py>_log] ==> #946000     Total Loss: 3.138    [weighted Loss:3.138    Policy Loss: 10.657   Value Loss: 7.780    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 514871     Buffer Size: 25903      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:00:31,655][train][INFO][train.py>_log] ==> #947000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 10.536   Value Loss: 7.396    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 515474     Buffer Size: 25967      Transition Number: 999.994 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:03:16,159][train][INFO][train.py>_log] ==> #948000     Total Loss: 2.826    [weighted Loss:2.826    Policy Loss: 11.069   Value Loss: 7.606    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 516099     Buffer Size: 26049      Transition Number: 1000.054k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:06:00,943][train][INFO][train.py>_log] ==> #949000     Total Loss: 3.619    [weighted Loss:3.619    Policy Loss: 10.783   Value Loss: 7.604    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 516640     Buffer Size: 26081      Transition Number: 999.987 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:08:45,944][train][INFO][train.py>_log] ==> #950000     Total Loss: 4.450    [weighted Loss:4.450    Policy Loss: 10.919   Value Loss: 7.683    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 517215     Buffer Size: 26114      Transition Number: 999.989 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:11:31,637][train][INFO][train.py>_log] ==> #951000     Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 10.745   Value Loss: 7.631    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 517782     Buffer Size: 26183      Transition Number: 999.993 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:14:15,151][train][INFO][train.py>_log] ==> #952000     Total Loss: 4.450    [weighted Loss:4.450    Policy Loss: 11.638   Value Loss: 7.770    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 518325     Buffer Size: 26218      Transition Number: 999.952 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:16:59,792][train][INFO][train.py>_log] ==> #953000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 11.745   Value Loss: 7.668    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 518802     Buffer Size: 26195      Transition Number: 1000.001k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:19:48,004][train][INFO][train.py>_log] ==> #954000     Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 10.271   Value Loss: 7.290    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 519326     Buffer Size: 26174      Transition Number: 1000.012k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:22:30,124][train][INFO][train.py>_log] ==> #955000     Total Loss: 3.574    [weighted Loss:3.574    Policy Loss: 11.900   Value Loss: 8.213    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 519857     Buffer Size: 26076      Transition Number: 999.946 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:25:16,718][train][INFO][train.py>_log] ==> #956000     Total Loss: 3.984    [weighted Loss:3.984    Policy Loss: 10.733   Value Loss: 7.842    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 520404     Buffer Size: 25987      Transition Number: 999.956 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:27:56,612][train][INFO][train.py>_log] ==> #957000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 11.486   Value Loss: 8.044    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 520920     Buffer Size: 25904      Transition Number: 999.956 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:30:35,666][train][INFO][train.py>_log] ==> #958000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 11.707   Value Loss: 7.476    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 521433     Buffer Size: 25816      Transition Number: 999.996 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:33:23,072][train][INFO][train.py>_log] ==> #959000     Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 10.975   Value Loss: 7.854    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 521986     Buffer Size: 25770      Transition Number: 999.963 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:36:05,667][train][INFO][train.py>_log] ==> #960000     Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 11.185   Value Loss: 8.170    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 522517     Buffer Size: 25741      Transition Number: 999.970 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:38:47,516][train][INFO][train.py>_log] ==> #961000     Total Loss: 4.696    [weighted Loss:4.696    Policy Loss: 12.093   Value Loss: 8.073    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 522961     Buffer Size: 25620      Transition Number: 999.968 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:41:29,089][train][INFO][train.py>_log] ==> #962000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 11.639   Value Loss: 7.898    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 523437     Buffer Size: 25454      Transition Number: 999.990 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:44:15,686][train][INFO][train.py>_log] ==> #963000     Total Loss: 3.590    [weighted Loss:3.590    Policy Loss: 11.577   Value Loss: 7.372    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 523961     Buffer Size: 25309      Transition Number: 999.958 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:47:02,611][train][INFO][train.py>_log] ==> #964000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 11.967   Value Loss: 8.253    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 524507     Buffer Size: 25180      Transition Number: 999.983 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:49:45,605][train][INFO][train.py>_log] ==> #965000     Total Loss: 4.354    [weighted Loss:4.354    Policy Loss: 11.954   Value Loss: 7.659    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 525035     Buffer Size: 25033      Transition Number: 999.994 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:52:29,035][train][INFO][train.py>_log] ==> #966000     Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 11.335   Value Loss: 7.550    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 525579     Buffer Size: 24836      Transition Number: 999.982 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:55:13,679][train][INFO][train.py>_log] ==> #967000     Total Loss: 3.545    [weighted Loss:3.545    Policy Loss: 12.470   Value Loss: 7.625    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 526081     Buffer Size: 24668      Transition Number: 999.963 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 01:57:59,338][train][INFO][train.py>_log] ==> #968000     Total Loss: 4.106    [weighted Loss:4.106    Policy Loss: 11.553   Value Loss: 7.482    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 526618     Buffer Size: 24503      Transition Number: 999.980 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:00:44,854][train][INFO][train.py>_log] ==> #969000     Total Loss: 4.560    [weighted Loss:4.560    Policy Loss: 12.406   Value Loss: 7.741    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 527189     Buffer Size: 24426      Transition Number: 1000.046k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:03:27,813][train][INFO][train.py>_log] ==> #970000     Total Loss: 3.560    [weighted Loss:3.560    Policy Loss: 12.426   Value Loss: 7.761    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 527783     Buffer Size: 24370      Transition Number: 1000.096k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:06:11,892][train][INFO][train.py>_log] ==> #971000     Total Loss: 2.173    [weighted Loss:2.173    Policy Loss: 12.135   Value Loss: 8.015    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 528418     Buffer Size: 24332      Transition Number: 999.988 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:08:57,340][train][INFO][train.py>_log] ==> #972000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 11.237   Value Loss: 7.658    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 529023     Buffer Size: 24320      Transition Number: 999.990 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:11:42,164][train][INFO][train.py>_log] ==> #973000     Total Loss: 1.463    [weighted Loss:1.463    Policy Loss: 11.609   Value Loss: 7.344    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 529618     Buffer Size: 24273      Transition Number: 999.997 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:14:24,111][train][INFO][train.py>_log] ==> #974000     Total Loss: 3.714    [weighted Loss:3.714    Policy Loss: 11.462   Value Loss: 7.456    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 530210     Buffer Size: 24240      Transition Number: 1000.023k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:17:09,981][train][INFO][train.py>_log] ==> #975000     Total Loss: 4.061    [weighted Loss:4.061    Policy Loss: 12.131   Value Loss: 7.848    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 530716     Buffer Size: 24054      Transition Number: 999.953 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:19:55,942][train][INFO][train.py>_log] ==> #976000     Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 11.239   Value Loss: 7.700    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 531223     Buffer Size: 23875      Transition Number: 1000.199k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:22:41,152][train][INFO][train.py>_log] ==> #977000     Total Loss: 2.596    [weighted Loss:2.596    Policy Loss: 12.025   Value Loss: 7.716    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 531725     Buffer Size: 23702      Transition Number: 999.973 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:25:25,212][train][INFO][train.py>_log] ==> #978000     Total Loss: 1.186    [weighted Loss:1.186    Policy Loss: 10.902   Value Loss: 7.553    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 532240     Buffer Size: 23542      Transition Number: 999.988 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:28:09,973][train][INFO][train.py>_log] ==> #979000     Total Loss: 2.672    [weighted Loss:2.672    Policy Loss: 10.869   Value Loss: 7.974    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 532953     Buffer Size: 23573      Transition Number: 999.997 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:30:53,038][train][INFO][train.py>_log] ==> #980000     Total Loss: 3.637    [weighted Loss:3.637    Policy Loss: 11.207   Value Loss: 7.745    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 533615     Buffer Size: 23656      Transition Number: 1000.041k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:33:39,493][train][INFO][train.py>_log] ==> #981000     Total Loss: 3.925    [weighted Loss:3.925    Policy Loss: 11.599   Value Loss: 7.955    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 534250     Buffer Size: 23737      Transition Number: 999.957 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:36:20,282][train][INFO][train.py>_log] ==> #982000     Total Loss: 3.303    [weighted Loss:3.303    Policy Loss: 11.898   Value Loss: 7.813    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 534873     Buffer Size: 23825      Transition Number: 999.967 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:39:04,989][train][INFO][train.py>_log] ==> #983000     Total Loss: 3.707    [weighted Loss:3.707    Policy Loss: 11.225   Value Loss: 7.869    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 535458     Buffer Size: 23842      Transition Number: 999.983 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:41:50,519][train][INFO][train.py>_log] ==> #984000     Total Loss: 4.681    [weighted Loss:4.681    Policy Loss: 11.610   Value Loss: 8.322    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 536026     Buffer Size: 23899      Transition Number: 999.982 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:44:34,240][train][INFO][train.py>_log] ==> #985000     Total Loss: 4.019    [weighted Loss:4.019    Policy Loss: 11.712   Value Loss: 7.007    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 536536     Buffer Size: 23886      Transition Number: 1000.054k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:47:20,681][train][INFO][train.py>_log] ==> #986000     Total Loss: 3.872    [weighted Loss:3.872    Policy Loss: 11.735   Value Loss: 7.864    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 537038     Buffer Size: 23835      Transition Number: 1000.015k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:50:06,353][train][INFO][train.py>_log] ==> #987000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 11.615   Value Loss: 7.401    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 537582     Buffer Size: 23742      Transition Number: 999.974 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:52:49,519][train][INFO][train.py>_log] ==> #988000     Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 11.656   Value Loss: 7.696    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 538110     Buffer Size: 23549      Transition Number: 1000.047k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:55:36,870][train][INFO][train.py>_log] ==> #989000     Total Loss: 3.786    [weighted Loss:3.786    Policy Loss: 11.418   Value Loss: 7.787    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 538687     Buffer Size: 23464      Transition Number: 999.992 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 02:58:25,538][train][INFO][train.py>_log] ==> #990000     Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 11.878   Value Loss: 8.248    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 539314     Buffer Size: 23450      Transition Number: 1000.066k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:01:12,808][train][INFO][train.py>_log] ==> #991000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 12.286   Value Loss: 7.549    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 539926     Buffer Size: 23442      Transition Number: 999.975 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:03:59,608][train][INFO][train.py>_log] ==> #992000     Total Loss: 1.348    [weighted Loss:1.348    Policy Loss: 11.968   Value Loss: 7.713    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 540554     Buffer Size: 23474      Transition Number: 999.983 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:06:42,916][train][INFO][train.py>_log] ==> #993000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 11.633   Value Loss: 7.606    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 541132     Buffer Size: 23501      Transition Number: 1000.095k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:09:28,526][train][INFO][train.py>_log] ==> #994000     Total Loss: 2.286    [weighted Loss:2.286    Policy Loss: 11.882   Value Loss: 7.499    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 541727     Buffer Size: 23549      Transition Number: 999.975 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:12:15,214][train][INFO][train.py>_log] ==> #995000     Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 11.956   Value Loss: 7.996    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 542306     Buffer Size: 23612      Transition Number: 999.999 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:15:02,247][train][INFO][train.py>_log] ==> #996000     Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 11.797   Value Loss: 7.543    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 542872     Buffer Size: 23671      Transition Number: 1000.079k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:17:48,633][train][INFO][train.py>_log] ==> #997000     Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 11.845   Value Loss: 7.885    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 543413     Buffer Size: 23687      Transition Number: 999.971 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:20:31,706][train][INFO][train.py>_log] ==> #998000     Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 12.138   Value Loss: 7.767    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 543989     Buffer Size: 23693      Transition Number: 999.981 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:23:18,397][train][INFO][train.py>_log] ==> #999000     Total Loss: 3.597    [weighted Loss:3.597    Policy Loss: 11.900   Value Loss: 7.338    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 544596     Buffer Size: 23734      Transition Number: 1000.066k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:26:05,804][train][INFO][train.py>_log] ==> #1000000    Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 11.976   Value Loss: 7.749    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 545217     Buffer Size: 23792      Transition Number: 999.956 k Batch Size: 256        Lr: 0.04096 
[2022-01-05 03:28:50,860][train][INFO][train.py>_log] ==> #1001000    Total Loss: 2.690    [weighted Loss:2.690    Policy Loss: 11.509   Value Loss: 7.568    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 545988     Buffer Size: 24008      Transition Number: 999.961 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:31:34,825][train][INFO][train.py>_log] ==> #1002000    Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 12.468   Value Loss: 7.689    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 546787     Buffer Size: 24247      Transition Number: 1000.041k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:34:19,027][train][INFO][train.py>_log] ==> #1003000    Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 11.937   Value Loss: 7.637    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 547372     Buffer Size: 24358      Transition Number: 999.976 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:37:02,351][train][INFO][train.py>_log] ==> #1004000    Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 11.376   Value Loss: 7.735    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 547982     Buffer Size: 24472      Transition Number: 999.952 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:39:45,516][train][INFO][train.py>_log] ==> #1005000    Total Loss: 3.837    [weighted Loss:3.837    Policy Loss: 11.702   Value Loss: 7.460    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 548451     Buffer Size: 24473      Transition Number: 1000.022k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:42:27,943][train][INFO][train.py>_log] ==> #1006000    Total Loss: 4.292    [weighted Loss:4.292    Policy Loss: 12.085   Value Loss: 7.510    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 548957     Buffer Size: 24435      Transition Number: 999.970 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:45:11,396][train][INFO][train.py>_log] ==> #1007000    Total Loss: 3.673    [weighted Loss:3.673    Policy Loss: 11.603   Value Loss: 7.381    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 549456     Buffer Size: 24395      Transition Number: 1000.039k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:47:55,031][train][INFO][train.py>_log] ==> #1008000    Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 11.902   Value Loss: 7.780    Reward Loss: 1.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 549960     Buffer Size: 24333      Transition Number: 1000.104k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:50:42,702][train][INFO][train.py>_log] ==> #1009000    Total Loss: 1.130    [weighted Loss:1.130    Policy Loss: 11.191   Value Loss: 7.090    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 550450     Buffer Size: 24326      Transition Number: 999.973 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:53:28,983][train][INFO][train.py>_log] ==> #1010000    Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 11.870   Value Loss: 7.294    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 550962     Buffer Size: 24335      Transition Number: 999.946 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:56:17,668][train][INFO][train.py>_log] ==> #1011000    Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 11.462   Value Loss: 7.713    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 551509     Buffer Size: 24282      Transition Number: 999.990 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 03:59:04,657][train][INFO][train.py>_log] ==> #1012000    Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 11.774   Value Loss: 7.909    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 552066     Buffer Size: 24212      Transition Number: 1000.047k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:01:50,938][train][INFO][train.py>_log] ==> #1013000    Total Loss: 3.664    [weighted Loss:3.664    Policy Loss: 12.139   Value Loss: 7.791    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 552868     Buffer Size: 24385      Transition Number: 1000.085k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:04:33,247][train][INFO][train.py>_log] ==> #1014000    Total Loss: 4.029    [weighted Loss:4.029    Policy Loss: 11.769   Value Loss: 7.135    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 553638     Buffer Size: 24558      Transition Number: 999.954 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:07:12,989][train][INFO][train.py>_log] ==> #1015000    Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 12.664   Value Loss: 7.432    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 554176     Buffer Size: 24536      Transition Number: 999.983 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:09:57,234][train][INFO][train.py>_log] ==> #1016000    Total Loss: 1.794    [weighted Loss:1.794    Policy Loss: 12.222   Value Loss: 7.653    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 554708     Buffer Size: 24487      Transition Number: 999.984 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:12:42,368][train][INFO][train.py>_log] ==> #1017000    Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 11.159   Value Loss: 7.283    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 555252     Buffer Size: 24512      Transition Number: 1000.032k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:15:24,777][train][INFO][train.py>_log] ==> #1018000    Total Loss: 3.174    [weighted Loss:3.174    Policy Loss: 12.101   Value Loss: 7.435    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 555779     Buffer Size: 24520      Transition Number: 999.995 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:18:08,497][train][INFO][train.py>_log] ==> #1019000    Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 11.645   Value Loss: 7.512    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 556302     Buffer Size: 24529      Transition Number: 999.988 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:20:53,186][train][INFO][train.py>_log] ==> #1020000    Total Loss: 3.414    [weighted Loss:3.414    Policy Loss: 12.040   Value Loss: 7.332    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 556829     Buffer Size: 24530      Transition Number: 999.976 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:23:39,371][train][INFO][train.py>_log] ==> #1021000    Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 11.341   Value Loss: 7.360    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 557420     Buffer Size: 24457      Transition Number: 999.985 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:26:28,121][train][INFO][train.py>_log] ==> #1022000    Total Loss: 0.765    [weighted Loss:0.765    Policy Loss: 11.901   Value Loss: 7.615    Reward Loss: 1.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 558003     Buffer Size: 24374      Transition Number: 1000.221k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:29:14,585][train][INFO][train.py>_log] ==> #1023000    Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 11.673   Value Loss: 7.731    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 558524     Buffer Size: 24250      Transition Number: 1000.116k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:31:58,731][train][INFO][train.py>_log] ==> #1024000    Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 11.240   Value Loss: 7.229    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 559032     Buffer Size: 24120      Transition Number: 1000.014k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:34:42,811][train][INFO][train.py>_log] ==> #1025000    Total Loss: 3.719    [weighted Loss:3.719    Policy Loss: 12.046   Value Loss: 7.770    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 559483     Buffer Size: 24039      Transition Number: 999.946 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:37:29,192][train][INFO][train.py>_log] ==> #1026000    Total Loss: 2.640    [weighted Loss:2.640    Policy Loss: 11.225   Value Loss: 7.650    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 559979     Buffer Size: 23968      Transition Number: 999.978 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:40:13,175][train][INFO][train.py>_log] ==> #1027000    Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 11.823   Value Loss: 8.073    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 560542     Buffer Size: 23977      Transition Number: 999.983 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:42:59,264][train][INFO][train.py>_log] ==> #1028000    Total Loss: 3.592    [weighted Loss:3.592    Policy Loss: 12.165   Value Loss: 7.867    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 561096     Buffer Size: 23994      Transition Number: 999.985 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:45:45,768][train][INFO][train.py>_log] ==> #1029000    Total Loss: 3.852    [weighted Loss:3.852    Policy Loss: 11.986   Value Loss: 7.783    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 561729     Buffer Size: 24086      Transition Number: 999.986 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:48:27,543][train][INFO][train.py>_log] ==> #1030000    Total Loss: 1.066    [weighted Loss:1.066    Policy Loss: 12.790   Value Loss: 7.644    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 562345     Buffer Size: 24172      Transition Number: 999.974 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:51:13,736][train][INFO][train.py>_log] ==> #1031000    Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 12.321   Value Loss: 7.537    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 562998     Buffer Size: 24226      Transition Number: 999.953 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:54:01,044][train][INFO][train.py>_log] ==> #1032000    Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 12.663   Value Loss: 7.718    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 563669     Buffer Size: 24279      Transition Number: 999.993 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:56:45,508][train][INFO][train.py>_log] ==> #1033000    Total Loss: 2.185    [weighted Loss:2.185    Policy Loss: 11.807   Value Loss: 7.727    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 564308     Buffer Size: 24329      Transition Number: 999.954 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 04:59:29,718][train][INFO][train.py>_log] ==> #1034000    Total Loss: 4.205    [weighted Loss:4.205    Policy Loss: 11.972   Value Loss: 7.210    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 564965     Buffer Size: 24392      Transition Number: 999.995 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:02:13,483][train][INFO][train.py>_log] ==> #1035000    Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 12.460   Value Loss: 8.035    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 565560     Buffer Size: 24390      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:05:00,769][train][INFO][train.py>_log] ==> #1036000    Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 11.294   Value Loss: 7.213    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 566171     Buffer Size: 24393      Transition Number: 1000.000k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:07:48,164][train][INFO][train.py>_log] ==> #1037000    Total Loss: 4.585    [weighted Loss:4.585    Policy Loss: 11.678   Value Loss: 7.387    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 566720     Buffer Size: 24388      Transition Number: 999.977 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:10:34,456][train][INFO][train.py>_log] ==> #1038000    Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 11.807   Value Loss: 7.574    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 567284     Buffer Size: 24376      Transition Number: 999.958 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:13:23,268][train][INFO][train.py>_log] ==> #1039000    Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 11.996   Value Loss: 7.467    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 567893     Buffer Size: 24403      Transition Number: 999.960 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:16:10,257][train][INFO][train.py>_log] ==> #1040000    Total Loss: 4.077    [weighted Loss:4.077    Policy Loss: 12.260   Value Loss: 7.627    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 568475     Buffer Size: 24409      Transition Number: 999.961 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:18:54,211][train][INFO][train.py>_log] ==> #1041000    Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 11.831   Value Loss: 7.862    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 569112     Buffer Size: 24452      Transition Number: 999.965 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:21:39,594][train][INFO][train.py>_log] ==> #1042000    Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 12.166   Value Loss: 7.534    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 569766     Buffer Size: 24477      Transition Number: 1000.004k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:24:22,731][train][INFO][train.py>_log] ==> #1043000    Total Loss: 4.570    [weighted Loss:4.570    Policy Loss: 11.939   Value Loss: 7.454    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 570407     Buffer Size: 24380      Transition Number: 1000.026k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:27:10,078][train][INFO][train.py>_log] ==> #1044000    Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 12.970   Value Loss: 7.586    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 571059     Buffer Size: 24241      Transition Number: 999.989 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:29:55,270][train][INFO][train.py>_log] ==> #1045000    Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 11.647   Value Loss: 7.440    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 571826     Buffer Size: 24400      Transition Number: 999.971 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:32:37,808][train][INFO][train.py>_log] ==> #1046000    Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 13.202   Value Loss: 7.698    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 572637     Buffer Size: 24588      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:35:22,923][train][INFO][train.py>_log] ==> #1047000    Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 11.728   Value Loss: 7.722    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 573287     Buffer Size: 24735      Transition Number: 999.988 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:38:04,835][train][INFO][train.py>_log] ==> #1048000    Total Loss: 3.539    [weighted Loss:3.539    Policy Loss: 11.510   Value Loss: 7.522    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 573940     Buffer Size: 24857      Transition Number: 1000.034k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:40:47,026][train][INFO][train.py>_log] ==> #1049000    Total Loss: 3.350    [weighted Loss:3.350    Policy Loss: 12.366   Value Loss: 7.707    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 574552     Buffer Size: 24978      Transition Number: 999.974 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:43:30,211][train][INFO][train.py>_log] ==> #1050000    Total Loss: 2.649    [weighted Loss:2.649    Policy Loss: 11.607   Value Loss: 7.637    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 575166     Buffer Size: 25099      Transition Number: 1000.101k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:46:14,209][train][INFO][train.py>_log] ==> #1051000    Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 11.610   Value Loss: 7.122    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 575795     Buffer Size: 25198      Transition Number: 999.986 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:48:58,275][train][INFO][train.py>_log] ==> #1052000    Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 12.058   Value Loss: 7.651    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 576435     Buffer Size: 25313      Transition Number: 999.986 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:51:41,393][train][INFO][train.py>_log] ==> #1053000    Total Loss: 1.580    [weighted Loss:1.580    Policy Loss: 11.867   Value Loss: 7.552    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 576991     Buffer Size: 25369      Transition Number: 999.997 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:54:22,968][train][INFO][train.py>_log] ==> #1054000    Total Loss: 3.875    [weighted Loss:3.875    Policy Loss: 12.112   Value Loss: 7.812    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 577582     Buffer Size: 25389      Transition Number: 1000.041k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:57:09,449][train][INFO][train.py>_log] ==> #1055000    Total Loss: 3.932    [weighted Loss:3.932    Policy Loss: 12.607   Value Loss: 7.276    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 578256     Buffer Size: 25227      Transition Number: 999.990 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 05:59:55,255][train][INFO][train.py>_log] ==> #1056000    Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 11.712   Value Loss: 7.206    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 578855     Buffer Size: 25098      Transition Number: 1000.006k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:02:40,370][train][INFO][train.py>_log] ==> #1057000    Total Loss: 3.529    [weighted Loss:3.529    Policy Loss: 12.689   Value Loss: 7.544    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 579473     Buffer Size: 25183      Transition Number: 999.985 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:05:26,807][train][INFO][train.py>_log] ==> #1058000    Total Loss: 3.411    [weighted Loss:3.411    Policy Loss: 13.129   Value Loss: 7.558    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 580131     Buffer Size: 25282      Transition Number: 1000.003k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:08:10,321][train][INFO][train.py>_log] ==> #1059000    Total Loss: 1.787    [weighted Loss:1.787    Policy Loss: 12.129   Value Loss: 7.365    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 580718     Buffer Size: 25338      Transition Number: 999.988 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:10:53,833][train][INFO][train.py>_log] ==> #1060000    Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 12.110   Value Loss: 7.193    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 581277     Buffer Size: 25351      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:13:39,532][train][INFO][train.py>_log] ==> #1061000    Total Loss: 4.877    [weighted Loss:4.877    Policy Loss: 11.679   Value Loss: 7.273    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 581814     Buffer Size: 25364      Transition Number: 999.952 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:16:24,947][train][INFO][train.py>_log] ==> #1062000    Total Loss: 2.596    [weighted Loss:2.596    Policy Loss: 12.301   Value Loss: 7.221    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 582349     Buffer Size: 25360      Transition Number: 999.981 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:19:07,777][train][INFO][train.py>_log] ==> #1063000    Total Loss: 2.805    [weighted Loss:2.805    Policy Loss: 12.440   Value Loss: 7.495    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 582891     Buffer Size: 25331      Transition Number: 999.995 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:21:51,424][train][INFO][train.py>_log] ==> #1064000    Total Loss: 3.853    [weighted Loss:3.853    Policy Loss: 12.927   Value Loss: 7.710    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 583427     Buffer Size: 25307      Transition Number: 999.939 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:24:36,628][train][INFO][train.py>_log] ==> #1065000    Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 11.944   Value Loss: 7.063    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 584091     Buffer Size: 25449      Transition Number: 1000.027k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:27:19,865][train][INFO][train.py>_log] ==> #1066000    Total Loss: 3.464    [weighted Loss:3.464    Policy Loss: 13.438   Value Loss: 7.465    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 584745     Buffer Size: 25595      Transition Number: 999.958 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:30:04,822][train][INFO][train.py>_log] ==> #1067000    Total Loss: 2.386    [weighted Loss:2.386    Policy Loss: 12.430   Value Loss: 7.941    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 585427     Buffer Size: 25785      Transition Number: 999.976 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:32:45,041][train][INFO][train.py>_log] ==> #1068000    Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 13.022   Value Loss: 7.389    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 586077     Buffer Size: 25928      Transition Number: 999.941 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:35:28,428][train][INFO][train.py>_log] ==> #1069000    Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 12.468   Value Loss: 7.351    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 586700     Buffer Size: 26004      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:38:11,979][train][INFO][train.py>_log] ==> #1070000    Total Loss: 4.810    [weighted Loss:4.810    Policy Loss: 12.778   Value Loss: 7.574    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 587305     Buffer Size: 26059      Transition Number: 1000.011k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:40:56,270][train][INFO][train.py>_log] ==> #1071000    Total Loss: 4.371    [weighted Loss:4.371    Policy Loss: 12.834   Value Loss: 7.629    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 587928     Buffer Size: 26037      Transition Number: 1000.023k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:43:38,624][train][INFO][train.py>_log] ==> #1072000    Total Loss: 3.567    [weighted Loss:3.567    Policy Loss: 12.959   Value Loss: 7.295    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 588524     Buffer Size: 26005      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:46:21,445][train][INFO][train.py>_log] ==> #1073000    Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 12.438   Value Loss: 7.590    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 589111     Buffer Size: 25973      Transition Number: 1000.016k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:49:07,764][train][INFO][train.py>_log] ==> #1074000    Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 12.477   Value Loss: 7.066    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 589741     Buffer Size: 25928      Transition Number: 999.983 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:51:54,422][train][INFO][train.py>_log] ==> #1075000    Total Loss: 4.087    [weighted Loss:4.087    Policy Loss: 12.774   Value Loss: 7.142    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 590320     Buffer Size: 25863      Transition Number: 999.999 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:54:43,850][train][INFO][train.py>_log] ==> #1076000    Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 12.782   Value Loss: 7.127    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 590912     Buffer Size: 25773      Transition Number: 999.970 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 06:57:31,821][train][INFO][train.py>_log] ==> #1077000    Total Loss: 4.173    [weighted Loss:4.173    Policy Loss: 12.905   Value Loss: 7.732    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 591499     Buffer Size: 25754      Transition Number: 999.997 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:00:16,825][train][INFO][train.py>_log] ==> #1078000    Total Loss: 2.877    [weighted Loss:2.877    Policy Loss: 12.812   Value Loss: 7.729    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 592096     Buffer Size: 25747      Transition Number: 1000.015k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:03:03,980][train][INFO][train.py>_log] ==> #1079000    Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 12.450   Value Loss: 6.994    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 592757     Buffer Size: 25810      Transition Number: 999.961 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:05:49,829][train][INFO][train.py>_log] ==> #1080000    Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 12.394   Value Loss: 7.160    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 593405     Buffer Size: 25896      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:08:36,110][train][INFO][train.py>_log] ==> #1081000    Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 12.659   Value Loss: 6.985    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 594122     Buffer Size: 26001      Transition Number: 999.956 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:11:18,582][train][INFO][train.py>_log] ==> #1082000    Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 12.791   Value Loss: 7.141    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 594766     Buffer Size: 26076      Transition Number: 1000.061k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:14:01,540][train][INFO][train.py>_log] ==> #1083000    Total Loss: 4.544    [weighted Loss:4.544    Policy Loss: 12.859   Value Loss: 7.045    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 595430     Buffer Size: 26094      Transition Number: 999.999 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:16:42,895][train][INFO][train.py>_log] ==> #1084000    Total Loss: 3.346    [weighted Loss:3.346    Policy Loss: 12.893   Value Loss: 7.312    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 596116     Buffer Size: 26131      Transition Number: 999.999 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:19:26,963][train][INFO][train.py>_log] ==> #1085000    Total Loss: 6.389    [weighted Loss:6.389    Policy Loss: 13.518   Value Loss: 7.195    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 596662     Buffer Size: 26070      Transition Number: 1000.001k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:22:09,552][train][INFO][train.py>_log] ==> #1086000    Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 13.041   Value Loss: 7.015    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 597203     Buffer Size: 26003      Transition Number: 999.934 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:24:53,484][train][INFO][train.py>_log] ==> #1087000    Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 13.116   Value Loss: 7.808    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 597872     Buffer Size: 25855      Transition Number: 999.970 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:27:38,046][train][INFO][train.py>_log] ==> #1088000    Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 12.852   Value Loss: 7.244    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 598530     Buffer Size: 25729      Transition Number: 1000.020k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:30:24,812][train][INFO][train.py>_log] ==> #1089000    Total Loss: 5.679    [weighted Loss:5.679    Policy Loss: 13.248   Value Loss: 7.842    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 599116     Buffer Size: 25685      Transition Number: 999.965 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:33:07,613][train][INFO][train.py>_log] ==> #1090000    Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 13.986   Value Loss: 7.526    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 599722     Buffer Size: 25648      Transition Number: 999.973 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:35:53,957][train][INFO][train.py>_log] ==> #1091000    Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 12.560   Value Loss: 7.003    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 600266     Buffer Size: 25582      Transition Number: 999.994 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:38:43,023][train][INFO][train.py>_log] ==> #1092000    Total Loss: 3.917    [weighted Loss:3.917    Policy Loss: 12.659   Value Loss: 7.955    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 600835     Buffer Size: 25509      Transition Number: 1000.000k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:41:29,979][train][INFO][train.py>_log] ==> #1093000    Total Loss: 4.660    [weighted Loss:4.660    Policy Loss: 13.609   Value Loss: 7.895    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 601386     Buffer Size: 25447      Transition Number: 1000.033k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:44:18,188][train][INFO][train.py>_log] ==> #1094000    Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 13.395   Value Loss: 7.261    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 601951     Buffer Size: 25370      Transition Number: 1000.031k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:47:00,758][train][INFO][train.py>_log] ==> #1095000    Total Loss: 2.443    [weighted Loss:2.443    Policy Loss: 12.264   Value Loss: 7.331    Reward Loss: 1.278    Consistency Loss: 0.000    ] Replay Episodes Collected: 602505     Buffer Size: 25337      Transition Number: 999.985 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:49:44,355][train][INFO][train.py>_log] ==> #1096000    Total Loss: 3.554    [weighted Loss:3.554    Policy Loss: 12.498   Value Loss: 7.666    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 603037     Buffer Size: 25258      Transition Number: 999.987 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:52:31,658][train][INFO][train.py>_log] ==> #1097000    Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 13.055   Value Loss: 7.489    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 603570     Buffer Size: 25176      Transition Number: 999.982 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:55:17,046][train][INFO][train.py>_log] ==> #1098000    Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 12.748   Value Loss: 7.415    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 604113     Buffer Size: 25073      Transition Number: 999.987 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 07:58:03,991][train][INFO][train.py>_log] ==> #1099000    Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 12.554   Value Loss: 7.698    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 604650     Buffer Size: 24983      Transition Number: 1000.023k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:00:45,926][train][INFO][train.py>_log] ==> #1100000    Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 12.183   Value Loss: 7.040    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 605186     Buffer Size: 24887      Transition Number: 999.998 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:03:33,338][train][INFO][train.py>_log] ==> #1101000    Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 12.598   Value Loss: 7.215    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 605705     Buffer Size: 24844      Transition Number: 999.984 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:06:20,914][train][INFO][train.py>_log] ==> #1102000    Total Loss: 3.956    [weighted Loss:3.956    Policy Loss: 13.113   Value Loss: 7.421    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 606237     Buffer Size: 24823      Transition Number: 999.976 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:09:09,795][train][INFO][train.py>_log] ==> #1103000    Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 12.958   Value Loss: 7.707    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 606789     Buffer Size: 24813      Transition Number: 1000.031k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:11:57,558][train][INFO][train.py>_log] ==> #1104000    Total Loss: 1.312    [weighted Loss:1.312    Policy Loss: 12.707   Value Loss: 7.080    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 607349     Buffer Size: 24814      Transition Number: 1000.047k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:14:45,608][train][INFO][train.py>_log] ==> #1105000    Total Loss: 3.695    [weighted Loss:3.695    Policy Loss: 13.333   Value Loss: 7.461    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 607877     Buffer Size: 24796      Transition Number: 999.992 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:17:31,692][train][INFO][train.py>_log] ==> #1106000    Total Loss: 1.268    [weighted Loss:1.268    Policy Loss: 13.330   Value Loss: 7.392    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 608444     Buffer Size: 24747      Transition Number: 999.983 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:20:16,653][train][INFO][train.py>_log] ==> #1107000    Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 12.783   Value Loss: 7.631    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 608953     Buffer Size: 24608      Transition Number: 999.980 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:23:04,326][train][INFO][train.py>_log] ==> #1108000    Total Loss: 3.705    [weighted Loss:3.705    Policy Loss: 12.449   Value Loss: 7.339    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 609480     Buffer Size: 24468      Transition Number: 999.994 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:25:53,868][train][INFO][train.py>_log] ==> #1109000    Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 12.587   Value Loss: 7.264    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 609973     Buffer Size: 24289      Transition Number: 999.995 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:28:36,349][train][INFO][train.py>_log] ==> #1110000    Total Loss: 4.272    [weighted Loss:4.272    Policy Loss: 12.193   Value Loss: 7.427    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 610479     Buffer Size: 24131      Transition Number: 999.938 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:31:20,074][train][INFO][train.py>_log] ==> #1111000    Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 12.529   Value Loss: 7.392    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 610978     Buffer Size: 24021      Transition Number: 999.952 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:34:08,293][train][INFO][train.py>_log] ==> #1112000    Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 12.633   Value Loss: 7.444    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 611487     Buffer Size: 23926      Transition Number: 1000.128k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:36:56,164][train][INFO][train.py>_log] ==> #1113000    Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 12.070   Value Loss: 7.151    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 611946     Buffer Size: 23797      Transition Number: 999.988 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:39:41,768][train][INFO][train.py>_log] ==> #1114000    Total Loss: 2.908    [weighted Loss:2.908    Policy Loss: 12.461   Value Loss: 7.087    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 612417     Buffer Size: 23680      Transition Number: 1000.004k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:42:26,575][train][INFO][train.py>_log] ==> #1115000    Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 12.783   Value Loss: 7.682    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 612958     Buffer Size: 23617      Transition Number: 999.980 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:45:14,819][train][INFO][train.py>_log] ==> #1116000    Total Loss: 2.830    [weighted Loss:2.830    Policy Loss: 12.274   Value Loss: 7.324    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 613586     Buffer Size: 23600      Transition Number: 1000.134k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:47:59,994][train][INFO][train.py>_log] ==> #1117000    Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 12.343   Value Loss: 7.092    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 614097     Buffer Size: 23571      Transition Number: 1000.041k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:50:44,976][train][INFO][train.py>_log] ==> #1118000    Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 12.757   Value Loss: 6.852    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 614635     Buffer Size: 23547      Transition Number: 1000.052k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:53:30,866][train][INFO][train.py>_log] ==> #1119000    Total Loss: 1.204    [weighted Loss:1.204    Policy Loss: 11.685   Value Loss: 7.376    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 615084     Buffer Size: 23433      Transition Number: 999.990 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:56:18,771][train][INFO][train.py>_log] ==> #1120000    Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 12.537   Value Loss: 7.543    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 615541     Buffer Size: 23303      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 08:59:06,103][train][INFO][train.py>_log] ==> #1121000    Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 11.847   Value Loss: 7.356    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 616007     Buffer Size: 23148      Transition Number: 999.953 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:01:53,512][train][INFO][train.py>_log] ==> #1122000    Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 12.908   Value Loss: 7.506    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 616480     Buffer Size: 22993      Transition Number: 999.966 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:04:42,718][train][INFO][train.py>_log] ==> #1123000    Total Loss: 3.942    [weighted Loss:3.942    Policy Loss: 12.448   Value Loss: 7.289    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 616975     Buffer Size: 22808      Transition Number: 999.997 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:07:33,993][train][INFO][train.py>_log] ==> #1124000    Total Loss: 1.881    [weighted Loss:1.881    Policy Loss: 12.442   Value Loss: 7.114    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 617507     Buffer Size: 22641      Transition Number: 1000.067k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:10:19,623][train][INFO][train.py>_log] ==> #1125000    Total Loss: 2.707    [weighted Loss:2.707    Policy Loss: 12.323   Value Loss: 7.281    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 617965     Buffer Size: 22479      Transition Number: 1000.000k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:13:05,191][train][INFO][train.py>_log] ==> #1126000    Total Loss: 2.975    [weighted Loss:2.975    Policy Loss: 12.538   Value Loss: 7.256    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 618460     Buffer Size: 22279      Transition Number: 999.970 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:15:52,792][train][INFO][train.py>_log] ==> #1127000    Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 13.051   Value Loss: 7.922    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 619087     Buffer Size: 22319      Transition Number: 999.953 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:18:39,411][train][INFO][train.py>_log] ==> #1128000    Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 12.816   Value Loss: 7.527    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 619711     Buffer Size: 22379      Transition Number: 1000.017k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:21:28,842][train][INFO][train.py>_log] ==> #1129000    Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 12.733   Value Loss: 7.276    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 620426     Buffer Size: 22413      Transition Number: 999.977 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:24:16,926][train][INFO][train.py>_log] ==> #1130000    Total Loss: 2.619    [weighted Loss:2.619    Policy Loss: 13.260   Value Loss: 7.703    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 621148     Buffer Size: 22475      Transition Number: 1000.031k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:27:03,109][train][INFO][train.py>_log] ==> #1131000    Total Loss: 3.570    [weighted Loss:3.570    Policy Loss: 12.275   Value Loss: 7.195    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 621837     Buffer Size: 22536      Transition Number: 1000.035k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:29:46,626][train][INFO][train.py>_log] ==> #1132000    Total Loss: 3.213    [weighted Loss:3.213    Policy Loss: 12.119   Value Loss: 7.220    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 622500     Buffer Size: 22592      Transition Number: 999.999 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:32:31,735][train][INFO][train.py>_log] ==> #1133000    Total Loss: 2.861    [weighted Loss:2.861    Policy Loss: 11.885   Value Loss: 7.134    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 622933     Buffer Size: 22545      Transition Number: 999.968 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:35:16,854][train][INFO][train.py>_log] ==> #1134000    Total Loss: 1.405    [weighted Loss:1.405    Policy Loss: 11.990   Value Loss: 7.385    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 623419     Buffer Size: 22463      Transition Number: 999.972 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:38:06,583][train][INFO][train.py>_log] ==> #1135000    Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 11.678   Value Loss: 7.342    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 623877     Buffer Size: 22349      Transition Number: 999.955 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:40:48,941][train][INFO][train.py>_log] ==> #1136000    Total Loss: 3.656    [weighted Loss:3.656    Policy Loss: 12.118   Value Loss: 7.190    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 624308     Buffer Size: 22264      Transition Number: 1000.043k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:43:36,362][train][INFO][train.py>_log] ==> #1137000    Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 12.715   Value Loss: 8.034    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 624783     Buffer Size: 22208      Transition Number: 999.999 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:46:27,398][train][INFO][train.py>_log] ==> #1138000    Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 12.582   Value Loss: 7.140    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 625303     Buffer Size: 22161      Transition Number: 999.990 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:49:14,328][train][INFO][train.py>_log] ==> #1139000    Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 12.606   Value Loss: 7.178    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 625834     Buffer Size: 22132      Transition Number: 999.979 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:52:02,815][train][INFO][train.py>_log] ==> #1140000    Total Loss: 0.617    [weighted Loss:0.617    Policy Loss: 12.589   Value Loss: 7.377    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 626334     Buffer Size: 22122      Transition Number: 1000.037k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:54:51,322][train][INFO][train.py>_log] ==> #1141000    Total Loss: 3.211    [weighted Loss:3.211    Policy Loss: 12.273   Value Loss: 7.036    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 626827     Buffer Size: 22093      Transition Number: 1000.113k Batch Size: 256        Lr: 0.03277 
[2022-01-05 09:57:41,298][train][INFO][train.py>_log] ==> #1142000    Total Loss: 5.077    [weighted Loss:5.077    Policy Loss: 12.755   Value Loss: 7.942    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 627344     Buffer Size: 22062      Transition Number: 999.950 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:00:30,799][train][INFO][train.py>_log] ==> #1143000    Total Loss: 4.120    [weighted Loss:4.120    Policy Loss: 12.033   Value Loss: 7.532    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 627829     Buffer Size: 22010      Transition Number: 999.964 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:03:18,805][train][INFO][train.py>_log] ==> #1144000    Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 11.854   Value Loss: 7.235    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 628274     Buffer Size: 21958      Transition Number: 1000.031k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:06:04,170][train][INFO][train.py>_log] ==> #1145000    Total Loss: 3.328    [weighted Loss:3.328    Policy Loss: 11.825   Value Loss: 7.381    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 628701     Buffer Size: 21891      Transition Number: 1000.045k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:08:52,249][train][INFO][train.py>_log] ==> #1146000    Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 12.221   Value Loss: 7.052    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 629171     Buffer Size: 21802      Transition Number: 999.991 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:11:41,262][train][INFO][train.py>_log] ==> #1147000    Total Loss: 2.475    [weighted Loss:2.475    Policy Loss: 11.563   Value Loss: 7.448    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 629642     Buffer Size: 21740      Transition Number: 999.998 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:14:30,381][train][INFO][train.py>_log] ==> #1148000    Total Loss: 4.185    [weighted Loss:4.185    Policy Loss: 11.883   Value Loss: 7.320    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 630105     Buffer Size: 21640      Transition Number: 999.997 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:17:16,291][train][INFO][train.py>_log] ==> #1149000    Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 12.112   Value Loss: 7.593    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 630527     Buffer Size: 21573      Transition Number: 999.989 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:20:03,464][train][INFO][train.py>_log] ==> #1150000    Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 11.178   Value Loss: 7.383    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 630957     Buffer Size: 21503      Transition Number: 999.963 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:22:53,167][train][INFO][train.py>_log] ==> #1151000    Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 11.914   Value Loss: 7.464    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 631409     Buffer Size: 21436      Transition Number: 999.992 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:25:39,834][train][INFO][train.py>_log] ==> #1152000    Total Loss: 2.191    [weighted Loss:2.191    Policy Loss: 11.963   Value Loss: 7.708    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 631843     Buffer Size: 21394      Transition Number: 1000.051k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:28:29,132][train][INFO][train.py>_log] ==> #1153000    Total Loss: 3.217    [weighted Loss:3.217    Policy Loss: 11.378   Value Loss: 7.454    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 632346     Buffer Size: 21351      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:31:17,467][train][INFO][train.py>_log] ==> #1154000    Total Loss: 1.851    [weighted Loss:1.851    Policy Loss: 11.546   Value Loss: 7.193    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 632845     Buffer Size: 21333      Transition Number: 999.960 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:34:05,976][train][INFO][train.py>_log] ==> #1155000    Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 12.100   Value Loss: 7.522    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 633311     Buffer Size: 21315      Transition Number: 999.992 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:36:55,694][train][INFO][train.py>_log] ==> #1156000    Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 12.211   Value Loss: 7.307    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 633765     Buffer Size: 21295      Transition Number: 999.997 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:39:45,644][train][INFO][train.py>_log] ==> #1157000    Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 11.371   Value Loss: 6.751    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 634234     Buffer Size: 21229      Transition Number: 999.977 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:42:31,328][train][INFO][train.py>_log] ==> #1158000    Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 11.680   Value Loss: 7.695    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 634692     Buffer Size: 21138      Transition Number: 1000.035k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:45:21,502][train][INFO][train.py>_log] ==> #1159000    Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 11.612   Value Loss: 7.527    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 635195     Buffer Size: 21074      Transition Number: 1000.000k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:48:06,777][train][INFO][train.py>_log] ==> #1160000    Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 11.462   Value Loss: 7.421    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 635664     Buffer Size: 21000      Transition Number: 1000.067k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:50:54,483][train][INFO][train.py>_log] ==> #1161000    Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 11.734   Value Loss: 7.279    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 636135     Buffer Size: 21013      Transition Number: 999.960 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:53:42,428][train][INFO][train.py>_log] ==> #1162000    Total Loss: 3.523    [weighted Loss:3.523    Policy Loss: 12.255   Value Loss: 7.005    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 636617     Buffer Size: 21038      Transition Number: 999.985 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:56:28,210][train][INFO][train.py>_log] ==> #1163000    Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 11.864   Value Loss: 7.202    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 637220     Buffer Size: 21122      Transition Number: 999.989 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 10:59:16,258][train][INFO][train.py>_log] ==> #1164000    Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 11.840   Value Loss: 7.584    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 637779     Buffer Size: 21189      Transition Number: 999.982 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:02:03,191][train][INFO][train.py>_log] ==> #1165000    Total Loss: 3.663    [weighted Loss:3.663    Policy Loss: 11.816   Value Loss: 7.602    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 638244     Buffer Size: 21183      Transition Number: 999.999 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:04:51,776][train][INFO][train.py>_log] ==> #1166000    Total Loss: 1.179    [weighted Loss:1.179    Policy Loss: 11.839   Value Loss: 7.594    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 638708     Buffer Size: 21166      Transition Number: 999.991 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:07:37,367][train][INFO][train.py>_log] ==> #1167000    Total Loss: 2.958    [weighted Loss:2.958    Policy Loss: 12.903   Value Loss: 7.277    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 639185     Buffer Size: 21160      Transition Number: 999.996 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:10:25,811][train][INFO][train.py>_log] ==> #1168000    Total Loss: 4.116    [weighted Loss:4.116    Policy Loss: 12.029   Value Loss: 7.080    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 639692     Buffer Size: 21114      Transition Number: 999.954 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:13:15,171][train][INFO][train.py>_log] ==> #1169000    Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 11.909   Value Loss: 7.151    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 640150     Buffer Size: 20967      Transition Number: 999.999 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:16:04,206][train][INFO][train.py>_log] ==> #1170000    Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 11.569   Value Loss: 7.575    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 640616     Buffer Size: 20791      Transition Number: 999.977 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:18:53,060][train][INFO][train.py>_log] ==> #1171000    Total Loss: 2.713    [weighted Loss:2.713    Policy Loss: 11.772   Value Loss: 6.991    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 641075     Buffer Size: 20576      Transition Number: 1000.064k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:21:39,119][train][INFO][train.py>_log] ==> #1172000    Total Loss: 4.570    [weighted Loss:4.570    Policy Loss: 11.787   Value Loss: 6.931    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 641518     Buffer Size: 20344      Transition Number: 999.993 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:24:26,796][train][INFO][train.py>_log] ==> #1173000    Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 11.916   Value Loss: 6.876    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 641966     Buffer Size: 20162      Transition Number: 999.976 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:27:15,747][train][INFO][train.py>_log] ==> #1174000    Total Loss: 2.440    [weighted Loss:2.440    Policy Loss: 12.146   Value Loss: 7.020    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 642432     Buffer Size: 19994      Transition Number: 1000.024k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:30:04,604][train][INFO][train.py>_log] ==> #1175000    Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 11.820   Value Loss: 7.204    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 643095     Buffer Size: 20095      Transition Number: 999.980 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:32:50,556][train][INFO][train.py>_log] ==> #1176000    Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 12.535   Value Loss: 7.592    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 643764     Buffer Size: 20245      Transition Number: 999.950 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:35:41,220][train][INFO][train.py>_log] ==> #1177000    Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 12.873   Value Loss: 7.938    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 644325     Buffer Size: 20330      Transition Number: 999.972 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:38:30,193][train][INFO][train.py>_log] ==> #1178000    Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 11.861   Value Loss: 6.732    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 644865     Buffer Size: 20414      Transition Number: 999.969 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:41:19,634][train][INFO][train.py>_log] ==> #1179000    Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 12.068   Value Loss: 6.798    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 645437     Buffer Size: 20450      Transition Number: 999.970 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:44:09,306][train][INFO][train.py>_log] ==> #1180000    Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 11.926   Value Loss: 7.273    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 645992     Buffer Size: 20491      Transition Number: 999.963 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:46:59,555][train][INFO][train.py>_log] ==> #1181000    Total Loss: 2.583    [weighted Loss:2.583    Policy Loss: 11.706   Value Loss: 7.218    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 646559     Buffer Size: 20543      Transition Number: 999.991 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:49:50,308][train][INFO][train.py>_log] ==> #1182000    Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 12.197   Value Loss: 7.339    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 647177     Buffer Size: 20593      Transition Number: 1000.043k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:52:39,833][train][INFO][train.py>_log] ==> #1183000    Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 12.664   Value Loss: 7.356    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 647787     Buffer Size: 20670      Transition Number: 999.972 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:55:26,423][train][INFO][train.py>_log] ==> #1184000    Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 12.489   Value Loss: 7.137    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 648367     Buffer Size: 20740      Transition Number: 999.945 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 11:58:17,619][train][INFO][train.py>_log] ==> #1185000    Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 12.206   Value Loss: 7.332    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 648889     Buffer Size: 20768      Transition Number: 1000.030k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:01:06,217][train][INFO][train.py>_log] ==> #1186000    Total Loss: 3.315    [weighted Loss:3.315    Policy Loss: 12.325   Value Loss: 7.450    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 649391     Buffer Size: 20805      Transition Number: 999.939 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:03:53,586][train][INFO][train.py>_log] ==> #1187000    Total Loss: 1.197    [weighted Loss:1.197    Policy Loss: 12.412   Value Loss: 7.473    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 649930     Buffer Size: 20876      Transition Number: 999.991 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:06:40,267][train][INFO][train.py>_log] ==> #1188000    Total Loss: 1.933    [weighted Loss:1.933    Policy Loss: 12.801   Value Loss: 8.022    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 650461     Buffer Size: 20925      Transition Number: 999.974 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:09:25,633][train][INFO][train.py>_log] ==> #1189000    Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 11.917   Value Loss: 7.670    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 650967     Buffer Size: 20989      Transition Number: 1000.087k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:12:12,545][train][INFO][train.py>_log] ==> #1190000    Total Loss: 2.619    [weighted Loss:2.619    Policy Loss: 12.430   Value Loss: 7.242    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 651507     Buffer Size: 21063      Transition Number: 999.992 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:15:01,352][train][INFO][train.py>_log] ==> #1191000    Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 12.792   Value Loss: 7.921    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 652079     Buffer Size: 21148      Transition Number: 1000.000k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:17:49,448][train][INFO][train.py>_log] ==> #1192000    Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 12.269   Value Loss: 6.929    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 652632     Buffer Size: 21258      Transition Number: 1000.014k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:20:38,562][train][INFO][train.py>_log] ==> #1193000    Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 11.927   Value Loss: 7.342    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 653181     Buffer Size: 21348      Transition Number: 1000.049k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:23:25,845][train][INFO][train.py>_log] ==> #1194000    Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 12.062   Value Loss: 7.274    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 653730     Buffer Size: 21423      Transition Number: 999.981 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:26:16,497][train][INFO][train.py>_log] ==> #1195000    Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 12.332   Value Loss: 7.103    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 654357     Buffer Size: 21544      Transition Number: 999.933 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:29:03,736][train][INFO][train.py>_log] ==> #1196000    Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 12.332   Value Loss: 7.162    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 654973     Buffer Size: 21670      Transition Number: 1000.007k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:31:47,125][train][INFO][train.py>_log] ==> #1197000    Total Loss: 2.494    [weighted Loss:2.494    Policy Loss: 13.294   Value Loss: 7.432    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 655589     Buffer Size: 21850      Transition Number: 999.938 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:34:32,469][train][INFO][train.py>_log] ==> #1198000    Total Loss: 3.915    [weighted Loss:3.915    Policy Loss: 12.919   Value Loss: 7.927    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 656248     Buffer Size: 22014      Transition Number: 999.994 k Batch Size: 256        Lr: 0.03277 
[2022-01-05 12:37:20,410][train][INFO][train.py>_log] ==> #1199000    Total Loss: 1.751    [weighted Loss:1.751    Policy Loss: 12.541   Value Loss: 7.877    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 656843     Buffer Size: 22128      Transition Number: 999.998 k Batch Size: 256        Lr: 0.03277 
