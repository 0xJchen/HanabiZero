[2022-01-17 12:05:08,976][train][INFO][train.py>_log] ==> #0          Total Loss: 56.092   [weighted Loss:56.092   Policy Loss: 14.991   Value Loss: 37.125   Reward Loss: 31.820   Consistency Loss: 0.000    ] Replay Episodes Collected: 1703       Buffer Size: 1703       Transition Number: 18.868  k Batch Size: 256        Lr: 0.00000 
[2022-01-17 12:07:21,295][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.690    [weighted Loss:5.690    Policy Loss: 14.810   Value Loss: 4.177    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 8507       Buffer Size: 8507       Transition Number: 105.115 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:09:21,622][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.612    [weighted Loss:5.612    Policy Loss: 13.515   Value Loss: 3.669    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 14615      Buffer Size: 14615      Transition Number: 181.044 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:11:19,982][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.694    [weighted Loss:5.694    Policy Loss: 12.827   Value Loss: 3.306    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 22814      Buffer Size: 22814      Transition Number: 253.537 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:13:21,671][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.198    [weighted Loss:4.198    Policy Loss: 12.764   Value Loss: 3.412    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 31474      Buffer Size: 31474      Transition Number: 329.683 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:15:23,857][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.644    [weighted Loss:4.644    Policy Loss: 13.667   Value Loss: 3.478    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 37696      Buffer Size: 37696      Transition Number: 406.130 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:17:22,495][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.975    [weighted Loss:5.975    Policy Loss: 13.861   Value Loss: 3.472    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 43649      Buffer Size: 43649      Transition Number: 481.153 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:19:24,980][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.418    [weighted Loss:4.418    Policy Loss: 13.348   Value Loss: 3.229    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 49807      Buffer Size: 49807      Transition Number: 560.329 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:21:22,230][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.742    [weighted Loss:3.742    Policy Loss: 13.238   Value Loss: 3.457    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 55919      Buffer Size: 55919      Transition Number: 637.457 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:23:27,993][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.087    [weighted Loss:5.087    Policy Loss: 13.799   Value Loss: 3.395    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 63024      Buffer Size: 63024      Transition Number: 716.013 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:25:38,060][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.768    [weighted Loss:5.768    Policy Loss: 12.499   Value Loss: 3.314    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 70848      Buffer Size: 70848      Transition Number: 802.128 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:27:51,063][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.747    [weighted Loss:3.747    Policy Loss: 13.628   Value Loss: 2.831    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 76889      Buffer Size: 76889      Transition Number: 893.411 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:30:09,754][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 12.683   Value Loss: 2.679    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 83022      Buffer Size: 83022      Transition Number: 987.498 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:32:47,003][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.698    [weighted Loss:4.698    Policy Loss: 13.558   Value Loss: 3.518    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 94444      Buffer Size: 94444      Transition Number: 1097.725k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:35:37,247][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.466    [weighted Loss:4.466    Policy Loss: 12.719   Value Loss: 3.437    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 107179     Buffer Size: 105737     Transition Number: 1200.298k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:38:28,321][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.961    [weighted Loss:3.961    Policy Loss: 12.475   Value Loss: 3.162    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 116782     Buffer Size: 106238     Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:41:20,589][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.615    [weighted Loss:3.615    Policy Loss: 12.134   Value Loss: 3.442    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 126328     Buffer Size: 104784     Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:44:05,916][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.145    [weighted Loss:3.145    Policy Loss: 11.041   Value Loss: 3.128    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 131784     Buffer Size: 99631      Transition Number: 1200.241k Batch Size: 256        Lr: 0.10000 
[2022-01-17 12:46:53,148][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.619    [weighted Loss:3.619    Policy Loss: 10.854   Value Loss: 3.214    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 137167     Buffer Size: 97065      Transition Number: 1200.177k Batch Size: 256        Lr: 0.10000 
