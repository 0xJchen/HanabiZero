[2022-01-17 15:33:38,616][train][INFO][train.py>_log] ==> #0          Total Loss: 48.550   [weighted Loss:48.550   Policy Loss: 14.078   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1919       Buffer Size: 1919       Transition Number: 22.177  k Batch Size: 256        Lr: 0.00000 
[2022-01-17 15:35:19,489][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.853    [weighted Loss:5.853    Policy Loss: 13.082   Value Loss: 3.262    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 8637       Buffer Size: 8637       Transition Number: 107.365 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:37:03,854][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.875    [weighted Loss:5.875    Policy Loss: 13.242   Value Loss: 3.054    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 14923      Buffer Size: 14923      Transition Number: 185.299 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:38:45,240][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.998    [weighted Loss:4.998    Policy Loss: 10.861   Value Loss: 3.024    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 24010      Buffer Size: 24010      Transition Number: 265.896 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:40:27,030][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.094    [weighted Loss:4.094    Policy Loss: 10.484   Value Loss: 2.859    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 33271      Buffer Size: 33271      Transition Number: 348.571 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:42:19,088][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.817    [weighted Loss:3.817    Policy Loss: 10.693   Value Loss: 2.890    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 45930      Buffer Size: 45930      Transition Number: 439.066 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:44:23,658][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.042    [weighted Loss:4.042    Policy Loss: 11.106   Value Loss: 2.860    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 60730      Buffer Size: 60730      Transition Number: 542.565 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:46:27,316][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.697    [weighted Loss:3.697    Policy Loss: 10.253   Value Loss: 2.672    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 71433      Buffer Size: 71433      Transition Number: 644.214 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:48:43,142][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.894    [weighted Loss:3.894    Policy Loss: 11.162   Value Loss: 3.122    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 83593      Buffer Size: 83593      Transition Number: 761.760 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:51:08,884][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.285    [weighted Loss:4.285    Policy Loss: 12.123   Value Loss: 2.929    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 95697      Buffer Size: 95697      Transition Number: 891.406 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:53:46,224][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.146    [weighted Loss:4.146    Policy Loss: 11.785   Value Loss: 2.871    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 109133     Buffer Size: 106095     Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:56:34,462][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.495    [weighted Loss:4.495    Policy Loss: 12.052   Value Loss: 2.465    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 123166     Buffer Size: 107321     Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:59:27,512][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 12.125   Value Loss: 2.589    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 137164     Buffer Size: 103237     Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:02:22,837][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.512    [weighted Loss:3.512    Policy Loss: 11.878   Value Loss: 2.760    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 151672     Buffer Size: 93773      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:05:21,064][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.243    [weighted Loss:3.243    Policy Loss: 11.896   Value Loss: 2.648    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 165990     Buffer Size: 90070      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:08:07,436][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 11.803   Value Loss: 2.778    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 178204     Buffer Size: 87000      Transition Number: 1000.247k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:10:56,494][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.382    [weighted Loss:2.382    Policy Loss: 12.352   Value Loss: 2.836    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 189859     Buffer Size: 84434      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:13:36,043][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 12.227   Value Loss: 2.991    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 196234     Buffer Size: 78745      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:16:19,170][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.614    [weighted Loss:2.614    Policy Loss: 12.288   Value Loss: 3.253    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 202602     Buffer Size: 72934      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:18:53,878][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.666    [weighted Loss:3.666    Policy Loss: 10.699   Value Loss: 3.501    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 205630     Buffer Size: 66355      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:21:35,592][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 10.445   Value Loss: 3.653    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 208818     Buffer Size: 58167      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:24:21,200][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 9.338    Value Loss: 3.634    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 211459     Buffer Size: 49276      Transition Number: 1000.249k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:27:07,940][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 9.074    Value Loss: 3.559    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 214081     Buffer Size: 41222      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:29:56,703][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 10.783   Value Loss: 3.526    Reward Loss: 0.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 216639     Buffer Size: 32881      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:32:46,809][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 7.975    Value Loss: 3.427    Reward Loss: 0.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 219191     Buffer Size: 26239      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:35:36,658][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.696    [weighted Loss:3.696    Policy Loss: 8.046    Value Loss: 3.377    Reward Loss: 0.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 221448     Buffer Size: 22428      Transition Number: 1000.241k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:38:27,201][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 6.157    Value Loss: 3.309    Reward Loss: 0.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 223958     Buffer Size: 19351      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:41:16,344][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 6.620    Value Loss: 3.265    Reward Loss: 0.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 226022     Buffer Size: 18568      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:44:09,253][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 4.945    Value Loss: 3.244    Reward Loss: 0.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 228678     Buffer Size: 17708      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:46:58,233][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 5.147    Value Loss: 3.304    Reward Loss: 0.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 230464     Buffer Size: 17144      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:49:52,707][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 4.682    Value Loss: 3.478    Reward Loss: 0.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 232670     Buffer Size: 16410      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:52:45,933][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.423    [weighted Loss:1.423    Policy Loss: 4.566    Value Loss: 3.349    Reward Loss: 0.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 234638     Buffer Size: 15939      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:55:40,686][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 4.410    Value Loss: 3.451    Reward Loss: 0.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 236785     Buffer Size: 15564      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-01-17 16:58:34,183][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 4.851    Value Loss: 3.563    Reward Loss: 0.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 238893     Buffer Size: 15250      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:01:26,910][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 5.750    Value Loss: 3.254    Reward Loss: 0.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 241022     Buffer Size: 14873      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:04:19,646][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.736    [weighted Loss:1.736    Policy Loss: 5.936    Value Loss: 3.364    Reward Loss: 0.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 242708     Buffer Size: 14670      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:07:15,033][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 5.250    Value Loss: 3.422    Reward Loss: 0.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 244954     Buffer Size: 14621      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:10:10,431][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.191    [weighted Loss:2.191    Policy Loss: 5.735    Value Loss: 3.479    Reward Loss: 0.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 246788     Buffer Size: 14671      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:13:04,066][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 5.540    Value Loss: 3.071    Reward Loss: 0.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 248854     Buffer Size: 14599      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:15:56,729][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 5.322    Value Loss: 3.333    Reward Loss: 0.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 250979     Buffer Size: 15092      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:18:46,507][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 5.148    Value Loss: 3.503    Reward Loss: 0.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 253155     Buffer Size: 15613      Transition Number: 1000.113k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:21:37,123][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.934    [weighted Loss:1.934    Policy Loss: 5.675    Value Loss: 3.427    Reward Loss: 0.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 255321     Buffer Size: 15883      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:24:27,333][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 4.571    Value Loss: 3.183    Reward Loss: 0.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 257287     Buffer Size: 16120      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:27:18,934][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.539    [weighted Loss:1.539    Policy Loss: 4.346    Value Loss: 3.612    Reward Loss: 0.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 259240     Buffer Size: 16232      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:30:09,881][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.908    [weighted Loss:1.908    Policy Loss: 4.467    Value Loss: 3.518    Reward Loss: 0.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 261151     Buffer Size: 16353      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:33:02,809][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 4.898    Value Loss: 3.646    Reward Loss: 0.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 263185     Buffer Size: 16441      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:35:57,395][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.399    [weighted Loss:1.399    Policy Loss: 4.158    Value Loss: 3.848    Reward Loss: 0.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 265320     Buffer Size: 16573      Transition Number: 999.930 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:38:48,900][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 4.667    Value Loss: 3.785    Reward Loss: 0.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 267590     Buffer Size: 16219      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:41:41,463][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.437    [weighted Loss:1.437    Policy Loss: 4.037    Value Loss: 3.748    Reward Loss: 0.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 269583     Buffer Size: 16039      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:44:40,229][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 4.012    Value Loss: 3.521    Reward Loss: 0.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 272126     Buffer Size: 16013      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:47:36,005][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.757    [weighted Loss:1.757    Policy Loss: 4.508    Value Loss: 3.836    Reward Loss: 0.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 274357     Buffer Size: 16273      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:50:26,645][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 4.244    Value Loss: 3.946    Reward Loss: 0.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 276751     Buffer Size: 16698      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:53:22,688][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.139    [weighted Loss:1.139    Policy Loss: 3.852    Value Loss: 3.755    Reward Loss: 0.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 279218     Buffer Size: 17052      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:56:16,640][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.017    [weighted Loss:1.017    Policy Loss: 4.799    Value Loss: 3.669    Reward Loss: 0.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 281257     Buffer Size: 17210      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 17:59:10,773][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 4.699    Value Loss: 4.056    Reward Loss: 0.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 283544     Buffer Size: 17249      Transition Number: 1000.665k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:02:06,719][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 4.186    Value Loss: 4.064    Reward Loss: 0.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 285817     Buffer Size: 17264      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:05:00,261][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.674    [weighted Loss:1.674    Policy Loss: 5.476    Value Loss: 3.789    Reward Loss: 0.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 287905     Buffer Size: 17165      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:07:53,305][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 4.846    Value Loss: 3.838    Reward Loss: 0.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 290011     Buffer Size: 16754      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:10:50,180][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 4.834    Value Loss: 3.889    Reward Loss: 0.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 292333     Buffer Size: 16356      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:13:45,482][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 5.094    Value Loss: 3.687    Reward Loss: 0.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 294933     Buffer Size: 16691      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:16:42,345][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.930    [weighted Loss:1.930    Policy Loss: 4.607    Value Loss: 4.191    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 297892     Buffer Size: 17211      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:19:37,765][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 4.555    Value Loss: 3.938    Reward Loss: 0.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 299875     Buffer Size: 17122      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:22:33,492][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 4.372    Value Loss: 3.975    Reward Loss: 0.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 302204     Buffer Size: 16952      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:25:35,118][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.328    [weighted Loss:1.328    Policy Loss: 4.529    Value Loss: 4.025    Reward Loss: 0.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 306145     Buffer Size: 18696      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:28:28,567][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 4.452    Value Loss: 3.604    Reward Loss: 0.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 309951     Buffer Size: 20645      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:31:16,403][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.125    [weighted Loss:2.125    Policy Loss: 4.580    Value Loss: 3.752    Reward Loss: 0.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 311895     Buffer Size: 20773      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:34:10,684][train][INFO][train.py>_log] ==> #66000      Total Loss: 0.561    [weighted Loss:0.561    Policy Loss: 3.726    Value Loss: 3.524    Reward Loss: 0.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 314007     Buffer Size: 20601      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:37:07,088][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.627    [weighted Loss:1.627    Policy Loss: 4.707    Value Loss: 3.714    Reward Loss: 0.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 316253     Buffer Size: 19830      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:40:01,873][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.297    [weighted Loss:1.297    Policy Loss: 3.644    Value Loss: 3.678    Reward Loss: 0.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 318433     Buffer Size: 19487      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:42:57,202][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 4.262    Value Loss: 3.856    Reward Loss: 0.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 320710     Buffer Size: 19621      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:45:53,743][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 3.516    Value Loss: 3.632    Reward Loss: 0.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 322902     Buffer Size: 18686      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:48:52,932][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 4.412    Value Loss: 3.680    Reward Loss: 0.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 325359     Buffer Size: 16818      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:51:47,458][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 3.661    Value Loss: 3.720    Reward Loss: 0.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 327472     Buffer Size: 16110      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:54:43,237][train][INFO][train.py>_log] ==> #73000      Total Loss: 0.611    [weighted Loss:0.611    Policy Loss: 3.890    Value Loss: 3.484    Reward Loss: 0.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 329904     Buffer Size: 16382      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-01-17 18:57:40,682][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 4.129    Value Loss: 3.803    Reward Loss: 0.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 332399     Buffer Size: 16668      Transition Number: 1003.306k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:00:35,433][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 3.936    Value Loss: 3.799    Reward Loss: 0.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 334831     Buffer Size: 16820      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:03:30,185][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 4.080    Value Loss: 3.931    Reward Loss: 0.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 336943     Buffer Size: 17013      Transition Number: 1000.064k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:06:26,230][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.000    [weighted Loss:1.000    Policy Loss: 3.412    Value Loss: 3.870    Reward Loss: 0.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 339253     Buffer Size: 17038      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:09:20,891][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.580    [weighted Loss:1.580    Policy Loss: 4.782    Value Loss: 3.886    Reward Loss: 0.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 341463     Buffer Size: 16985      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:12:17,203][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.179    [weighted Loss:1.179    Policy Loss: 4.505    Value Loss: 3.865    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 343752     Buffer Size: 17043      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:15:13,392][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.528    [weighted Loss:1.528    Policy Loss: 4.173    Value Loss: 4.058    Reward Loss: 0.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 346110     Buffer Size: 16904      Transition Number: 999.927 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:18:10,389][train][INFO][train.py>_log] ==> #81000      Total Loss: 1.355    [weighted Loss:1.355    Policy Loss: 4.518    Value Loss: 3.729    Reward Loss: 0.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 348521     Buffer Size: 17002      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:21:07,136][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.922    [weighted Loss:1.922    Policy Loss: 5.048    Value Loss: 3.970    Reward Loss: 0.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 350818     Buffer Size: 16956      Transition Number: 1000.013k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:24:04,394][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 4.240    Value Loss: 3.801    Reward Loss: 0.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 353292     Buffer Size: 16864      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:26:59,885][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 4.258    Value Loss: 3.919    Reward Loss: 0.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 355541     Buffer Size: 16916      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:29:55,137][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 4.204    Value Loss: 4.117    Reward Loss: 0.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 357972     Buffer Size: 17019      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:32:55,257][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 5.003    Value Loss: 4.131    Reward Loss: 0.362    Consistency Loss: 0.000    ] Replay Episodes Collected: 360288     Buffer Size: 17145      Transition Number: 1001.330k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:35:54,136][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.800    [weighted Loss:1.800    Policy Loss: 4.348    Value Loss: 3.908    Reward Loss: 0.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 362590     Buffer Size: 17168      Transition Number: 1000.167k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:38:50,754][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.571    [weighted Loss:1.571    Policy Loss: 3.889    Value Loss: 3.821    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 364898     Buffer Size: 17135      Transition Number: 999.928 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:41:44,643][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 4.525    Value Loss: 4.010    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 367171     Buffer Size: 17039      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:44:39,805][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.481    [weighted Loss:1.481    Policy Loss: 4.462    Value Loss: 4.020    Reward Loss: 0.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 369449     Buffer Size: 16927      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:47:34,878][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 4.449    Value Loss: 3.992    Reward Loss: 0.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 371748     Buffer Size: 16952      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:50:31,628][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.845    [weighted Loss:1.845    Policy Loss: 4.051    Value Loss: 3.933    Reward Loss: 0.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 374002     Buffer Size: 17091      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:53:29,935][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.745    [weighted Loss:1.745    Policy Loss: 4.472    Value Loss: 4.316    Reward Loss: 0.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 376732     Buffer Size: 17255      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:56:25,278][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 4.342    Value Loss: 3.692    Reward Loss: 0.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 379162     Buffer Size: 17606      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 19:59:21,056][train][INFO][train.py>_log] ==> #95000      Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 4.174    Value Loss: 3.832    Reward Loss: 0.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 381646     Buffer Size: 17650      Transition Number: 1001.078k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:02:16,543][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 4.138    Value Loss: 3.850    Reward Loss: 0.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 384089     Buffer Size: 17852      Transition Number: 999.925 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:05:15,849][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 4.348    Value Loss: 4.065    Reward Loss: 0.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 386340     Buffer Size: 17948      Transition Number: 1000.254k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:08:12,454][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.418    [weighted Loss:1.418    Policy Loss: 4.328    Value Loss: 4.198    Reward Loss: 0.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 388653     Buffer Size: 18021      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:11:08,102][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 4.301    Value Loss: 4.226    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 391205     Buffer Size: 18313      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:14:06,556][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 4.980    Value Loss: 4.051    Reward Loss: 0.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 393920     Buffer Size: 18332      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:17:05,345][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 4.484    Value Loss: 4.037    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 396567     Buffer Size: 18570      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:20:05,733][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 4.961    Value Loss: 4.003    Reward Loss: 0.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 399530     Buffer Size: 18948      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:23:00,368][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.922    [weighted Loss:1.922    Policy Loss: 4.777    Value Loss: 4.131    Reward Loss: 0.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 401911     Buffer Size: 18898      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:25:57,541][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 4.979    Value Loss: 3.816    Reward Loss: 0.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 404428     Buffer Size: 18877      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:29:09,462][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 5.736    Value Loss: 4.209    Reward Loss: 0.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 413597     Buffer Size: 25391      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:32:17,782][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 4.357    Value Loss: 3.891    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 423408     Buffer Size: 32515      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:35:09,782][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 4.675    Value Loss: 4.069    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 425661     Buffer Size: 32416      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:38:03,105][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 4.097    Value Loss: 3.919    Reward Loss: 0.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 428053     Buffer Size: 32217      Transition Number: 1000.087k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:40:56,940][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 4.217    Value Loss: 4.201    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 430366     Buffer Size: 31683      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:43:53,920][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.491    [weighted Loss:1.491    Policy Loss: 4.293    Value Loss: 4.090    Reward Loss: 0.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 432784     Buffer Size: 31513      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:46:49,120][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.687    [weighted Loss:1.687    Policy Loss: 4.425    Value Loss: 4.279    Reward Loss: 0.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 435033     Buffer Size: 31475      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:49:45,643][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.153    [weighted Loss:2.153    Policy Loss: 5.004    Value Loss: 4.090    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 437397     Buffer Size: 27735      Transition Number: 1000.451k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:52:47,009][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 4.486    Value Loss: 4.424    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 441090     Buffer Size: 22113      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:55:48,300][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 4.577    Value Loss: 4.428    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 444472     Buffer Size: 19857      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 20:58:47,235][train][INFO][train.py>_log] ==> #115000     Total Loss: 1.190    [weighted Loss:1.190    Policy Loss: 4.587    Value Loss: 4.373    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 448315     Buffer Size: 21154      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:01:45,266][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 4.366    Value Loss: 4.394    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 451992     Buffer Size: 22561      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:04:40,153][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.856    [weighted Loss:1.856    Policy Loss: 4.289    Value Loss: 4.239    Reward Loss: 0.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 454293     Buffer Size: 22305      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:07:37,575][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 4.215    Value Loss: 4.460    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 456577     Buffer Size: 22168      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:10:35,652][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.714    [weighted Loss:1.714    Policy Loss: 3.787    Value Loss: 4.236    Reward Loss: 0.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 458503     Buffer Size: 22050      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:13:36,370][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 4.249    Value Loss: 4.006    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 460769     Buffer Size: 20903      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:16:38,115][train][INFO][train.py>_log] ==> #121000     Total Loss: 1.242    [weighted Loss:1.242    Policy Loss: 4.137    Value Loss: 3.962    Reward Loss: 0.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 463246     Buffer Size: 19841      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:19:40,157][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 4.887    Value Loss: 4.078    Reward Loss: 0.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 465742     Buffer Size: 18423      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:22:39,920][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 4.432    Value Loss: 3.991    Reward Loss: 0.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 468612     Buffer Size: 17389      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:25:43,490][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.462    [weighted Loss:1.462    Policy Loss: 4.444    Value Loss: 4.446    Reward Loss: 0.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 471512     Buffer Size: 17621      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:28:41,024][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 4.672    Value Loss: 4.147    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 473964     Buffer Size: 17730      Transition Number: 1000.086k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:31:41,528][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 4.323    Value Loss: 4.379    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 476118     Buffer Size: 18023      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:34:42,232][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 4.315    Value Loss: 4.300    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 478677     Buffer Size: 18287      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:37:41,092][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 3.906    Value Loss: 4.386    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 481128     Buffer Size: 18347      Transition Number: 1000.035k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:40:42,681][train][INFO][train.py>_log] ==> #129000     Total Loss: 1.381    [weighted Loss:1.381    Policy Loss: 3.790    Value Loss: 4.332    Reward Loss: 0.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 483604     Buffer Size: 18332      Transition Number: 1000.125k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:43:44,368][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 3.985    Value Loss: 4.365    Reward Loss: 0.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 486093     Buffer Size: 17965      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:46:42,279][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 3.821    Value Loss: 4.271    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 487966     Buffer Size: 17641      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:49:40,516][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 3.281    Value Loss: 4.330    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 490409     Buffer Size: 17101      Transition Number: 999.927 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:52:35,943][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.301    [weighted Loss:1.301    Policy Loss: 3.754    Value Loss: 4.157    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 492533     Buffer Size: 16947      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:55:35,525][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 3.729    Value Loss: 4.001    Reward Loss: 0.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 494637     Buffer Size: 16663      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 21:58:43,082][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.774    [weighted Loss:1.774    Policy Loss: 3.715    Value Loss: 4.084    Reward Loss: 0.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 499941     Buffer Size: 19445      Transition Number: 1000.086k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:01:45,016][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.312    [weighted Loss:1.312    Policy Loss: 3.718    Value Loss: 4.068    Reward Loss: 0.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 505002     Buffer Size: 22190      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:04:38,143][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.169    [weighted Loss:1.169    Policy Loss: 3.716    Value Loss: 4.003    Reward Loss: 0.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 507214     Buffer Size: 22084      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:07:36,097][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.390    [weighted Loss:1.390    Policy Loss: 3.253    Value Loss: 4.122    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 509416     Buffer Size: 21992      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:10:31,122][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 3.506    Value Loss: 4.184    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 511398     Buffer Size: 22080      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:13:28,450][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 4.106    Value Loss: 4.094    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 513699     Buffer Size: 22044      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:16:25,129][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.337    [weighted Loss:1.337    Policy Loss: 3.889    Value Loss: 4.269    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 516061     Buffer Size: 22168      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:19:24,291][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.399    [weighted Loss:1.399    Policy Loss: 3.131    Value Loss: 4.155    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 518326     Buffer Size: 20194      Transition Number: 1000.170k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:22:24,375][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.151    [weighted Loss:1.151    Policy Loss: 3.330    Value Loss: 4.132    Reward Loss: 0.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 520585     Buffer Size: 18023      Transition Number: 1000.209k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:25:23,912][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.667    [weighted Loss:1.667    Policy Loss: 3.848    Value Loss: 4.356    Reward Loss: 0.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 522790     Buffer Size: 16553      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:28:23,681][train][INFO][train.py>_log] ==> #145000     Total Loss: 0.674    [weighted Loss:0.674    Policy Loss: 3.902    Value Loss: 4.097    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 525365     Buffer Size: 16658      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:31:22,562][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.359    [weighted Loss:1.359    Policy Loss: 3.187    Value Loss: 4.190    Reward Loss: 0.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 527754     Buffer Size: 16832      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:34:17,992][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.321    [weighted Loss:1.321    Policy Loss: 3.249    Value Loss: 4.135    Reward Loss: 0.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 529844     Buffer Size: 17043      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:37:16,282][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.269    [weighted Loss:1.269    Policy Loss: 3.682    Value Loss: 4.319    Reward Loss: 0.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 532251     Buffer Size: 17166      Transition Number: 1000.195k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:40:14,433][train][INFO][train.py>_log] ==> #149000     Total Loss: 1.348    [weighted Loss:1.348    Policy Loss: 3.416    Value Loss: 4.028    Reward Loss: 0.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 534669     Buffer Size: 17238      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:43:14,241][train][INFO][train.py>_log] ==> #150000     Total Loss: 1.160    [weighted Loss:1.160    Policy Loss: 3.767    Value Loss: 4.105    Reward Loss: 0.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 537059     Buffer Size: 17278      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:46:14,337][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.104    [weighted Loss:1.104    Policy Loss: 3.457    Value Loss: 4.263    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 539237     Buffer Size: 17276      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:49:14,550][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.187    [weighted Loss:1.187    Policy Loss: 3.297    Value Loss: 4.246    Reward Loss: 0.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 541413     Buffer Size: 17286      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:52:16,232][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.463    [weighted Loss:1.463    Policy Loss: 3.273    Value Loss: 4.251    Reward Loss: 0.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 545574     Buffer Size: 18741      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:55:15,035][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 3.648    Value Loss: 4.353    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 549203     Buffer Size: 20036      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 22:58:10,820][train][INFO][train.py>_log] ==> #155000     Total Loss: 1.551    [weighted Loss:1.551    Policy Loss: 3.592    Value Loss: 4.013    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 551168     Buffer Size: 20022      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:01:07,795][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.671    [weighted Loss:1.671    Policy Loss: 4.213    Value Loss: 4.216    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 553415     Buffer Size: 19839      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:04:05,250][train][INFO][train.py>_log] ==> #157000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 3.327    Value Loss: 4.163    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 556053     Buffer Size: 19925      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:07:00,109][train][INFO][train.py>_log] ==> #158000     Total Loss: 1.570    [weighted Loss:1.570    Policy Loss: 3.731    Value Loss: 4.390    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 558231     Buffer Size: 20151      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:09:59,853][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.083    [weighted Loss:1.083    Policy Loss: 3.886    Value Loss: 4.136    Reward Loss: 0.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 560589     Buffer Size: 20057      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:12:59,736][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 3.645    Value Loss: 4.179    Reward Loss: 0.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 562734     Buffer Size: 19424      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:16:00,878][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.327    [weighted Loss:1.327    Policy Loss: 3.552    Value Loss: 4.217    Reward Loss: 0.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 565331     Buffer Size: 17623      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:19:03,265][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.353    [weighted Loss:1.353    Policy Loss: 3.334    Value Loss: 4.196    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 567835     Buffer Size: 17352      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:22:00,982][train][INFO][train.py>_log] ==> #163000     Total Loss: 0.959    [weighted Loss:0.959    Policy Loss: 3.293    Value Loss: 4.353    Reward Loss: 0.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 569886     Buffer Size: 17457      Transition Number: 1001.293k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:25:00,084][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.364    [weighted Loss:1.364    Policy Loss: 4.986    Value Loss: 4.035    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 572159     Buffer Size: 17249      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:28:01,755][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 3.915    Value Loss: 4.409    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 575413     Buffer Size: 18022      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:30:59,719][train][INFO][train.py>_log] ==> #166000     Total Loss: 0.909    [weighted Loss:0.909    Policy Loss: 3.211    Value Loss: 4.040    Reward Loss: 0.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 578655     Buffer Size: 18896      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:33:57,233][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 3.093    Value Loss: 4.348    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 581325     Buffer Size: 19481      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:36:57,508][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.152    [weighted Loss:1.152    Policy Loss: 3.696    Value Loss: 4.305    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 584153     Buffer Size: 20092      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:39:54,225][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.473    [weighted Loss:1.473    Policy Loss: 3.279    Value Loss: 4.334    Reward Loss: 0.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 586535     Buffer Size: 20063      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:42:53,072][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.254    [weighted Loss:1.254    Policy Loss: 3.719    Value Loss: 4.279    Reward Loss: 0.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 589042     Buffer Size: 20057      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:45:49,252][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.389    [weighted Loss:1.389    Policy Loss: 3.555    Value Loss: 4.131    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 591076     Buffer Size: 20145      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:48:48,549][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 3.181    Value Loss: 4.296    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 593376     Buffer Size: 19548      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:51:49,715][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.074    [weighted Loss:1.074    Policy Loss: 3.036    Value Loss: 4.201    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 595488     Buffer Size: 18480      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:54:53,637][train][INFO][train.py>_log] ==> #174000     Total Loss: 0.626    [weighted Loss:0.626    Policy Loss: 2.928    Value Loss: 4.054    Reward Loss: 0.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 597792     Buffer Size: 17381      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 23:57:54,772][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.401    [weighted Loss:1.401    Policy Loss: 3.940    Value Loss: 3.936    Reward Loss: 0.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 599979     Buffer Size: 16679      Transition Number: 1000.320k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:00:51,410][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.377    [weighted Loss:1.377    Policy Loss: 3.515    Value Loss: 4.321    Reward Loss: 0.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 601973     Buffer Size: 16193      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:03:51,228][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.161    [weighted Loss:1.161    Policy Loss: 3.435    Value Loss: 4.316    Reward Loss: 0.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 604237     Buffer Size: 15975      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:06:50,545][train][INFO][train.py>_log] ==> #178000     Total Loss: 0.962    [weighted Loss:0.962    Policy Loss: 3.208    Value Loss: 4.167    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 606643     Buffer Size: 15926      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:09:50,179][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.392    [weighted Loss:1.392    Policy Loss: 3.498    Value Loss: 4.304    Reward Loss: 0.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 608883     Buffer Size: 15878      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:12:46,421][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.562    [weighted Loss:1.562    Policy Loss: 3.526    Value Loss: 4.414    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 611016     Buffer Size: 15908      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:15:47,786][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 4.162    Value Loss: 4.347    Reward Loss: 0.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 613245     Buffer Size: 16118      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:18:47,592][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.200    [weighted Loss:1.200    Policy Loss: 3.073    Value Loss: 4.143    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 615725     Buffer Size: 16281      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:21:48,588][train][INFO][train.py>_log] ==> #183000     Total Loss: 1.015    [weighted Loss:1.015    Policy Loss: 3.699    Value Loss: 4.374    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 617952     Buffer Size: 16271      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:24:48,817][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.396    [weighted Loss:1.396    Policy Loss: 3.350    Value Loss: 4.194    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 620066     Buffer Size: 16153      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:27:47,647][train][INFO][train.py>_log] ==> #185000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 3.989    Value Loss: 4.205    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 622020     Buffer Size: 15984      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:30:44,762][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 3.692    Value Loss: 3.932    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 624172     Buffer Size: 15914      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:33:45,042][train][INFO][train.py>_log] ==> #187000     Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 4.167    Value Loss: 4.211    Reward Loss: 0.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 626621     Buffer Size: 16004      Transition Number: 999.939 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:36:45,662][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.437    [weighted Loss:1.437    Policy Loss: 4.283    Value Loss: 4.317    Reward Loss: 0.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 628896     Buffer Size: 16029      Transition Number: 999.927 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:39:45,905][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 4.193    Value Loss: 4.674    Reward Loss: 0.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 631711     Buffer Size: 16340      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:42:49,131][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 3.642    Value Loss: 4.358    Reward Loss: 0.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 634460     Buffer Size: 16848      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:45:49,289][train][INFO][train.py>_log] ==> #191000     Total Loss: 1.036    [weighted Loss:1.036    Policy Loss: 4.329    Value Loss: 4.375    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 637006     Buffer Size: 17288      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:48:46,382][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.492    [weighted Loss:1.492    Policy Loss: 4.424    Value Loss: 4.654    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 639388     Buffer Size: 17813      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:51:48,238][train][INFO][train.py>_log] ==> #193000     Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 4.301    Value Loss: 4.794    Reward Loss: 0.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 642457     Buffer Size: 18635      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:54:45,515][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 4.109    Value Loss: 4.794    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 645437     Buffer Size: 19301      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 00:57:40,911][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.429    [weighted Loss:2.429    Policy Loss: 4.932    Value Loss: 4.685    Reward Loss: 0.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 647583     Buffer Size: 19199      Transition Number: 1000.378k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:00:36,048][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 4.790    Value Loss: 4.775    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 649564     Buffer Size: 18889      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:03:36,896][train][INFO][train.py>_log] ==> #197000     Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 4.506    Value Loss: 4.333    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 652158     Buffer Size: 18608      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:06:34,483][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.074    [weighted Loss:1.074    Policy Loss: 3.717    Value Loss: 4.490    Reward Loss: 0.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 654564     Buffer Size: 18495      Transition Number: 1000.017k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:09:32,465][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 4.119    Value Loss: 4.258    Reward Loss: 0.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 656943     Buffer Size: 18172      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:12:35,724][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.264    [weighted Loss:1.264    Policy Loss: 3.511    Value Loss: 4.362    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 659138     Buffer Size: 17586      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:15:39,321][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 4.126    Value Loss: 4.168    Reward Loss: 0.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 661422     Buffer Size: 16524      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:18:43,044][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.633    [weighted Loss:1.633    Policy Loss: 4.034    Value Loss: 4.044    Reward Loss: 0.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 663455     Buffer Size: 16113      Transition Number: 1000.672k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:21:48,138][train][INFO][train.py>_log] ==> #203000     Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 3.882    Value Loss: 3.838    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 665651     Buffer Size: 15881      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:24:48,882][train][INFO][train.py>_log] ==> #204000     Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 4.421    Value Loss: 3.470    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 667755     Buffer Size: 15326      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:27:51,755][train][INFO][train.py>_log] ==> #205000     Total Loss: 1.450    [weighted Loss:1.450    Policy Loss: 3.779    Value Loss: 3.712    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 670571     Buffer Size: 15482      Transition Number: 1000.458k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:30:54,059][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.220    [weighted Loss:1.220    Policy Loss: 3.984    Value Loss: 4.414    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 673315     Buffer Size: 15879      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:33:53,844][train][INFO][train.py>_log] ==> #207000     Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 3.973    Value Loss: 3.837    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 675492     Buffer Size: 15877      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:36:55,471][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.006    [weighted Loss:1.006    Policy Loss: 3.829    Value Loss: 3.846    Reward Loss: 0.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 677834     Buffer Size: 16075      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:39:56,441][train][INFO][train.py>_log] ==> #209000     Total Loss: 1.358    [weighted Loss:1.358    Policy Loss: 3.584    Value Loss: 4.027    Reward Loss: 0.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 680258     Buffer Size: 16350      Transition Number: 1000.202k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:42:55,612][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.719    Value Loss: 4.129    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 682418     Buffer Size: 16567      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:45:53,704][train][INFO][train.py>_log] ==> #211000     Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 4.182    Value Loss: 4.199    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 684553     Buffer Size: 16721      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:48:53,251][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 3.868    Value Loss: 3.920    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 686729     Buffer Size: 16217      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:51:54,712][train][INFO][train.py>_log] ==> #213000     Total Loss: 1.536    [weighted Loss:1.536    Policy Loss: 3.714    Value Loss: 4.123    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 688668     Buffer Size: 15657      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:54:57,480][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.382    [weighted Loss:1.382    Policy Loss: 3.799    Value Loss: 3.859    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 690750     Buffer Size: 15289      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 01:57:57,870][train][INFO][train.py>_log] ==> #215000     Total Loss: 1.119    [weighted Loss:1.119    Policy Loss: 4.473    Value Loss: 3.752    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 692996     Buffer Size: 15109      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:01:03,960][train][INFO][train.py>_log] ==> #216000     Total Loss: 1.781    [weighted Loss:1.781    Policy Loss: 4.188    Value Loss: 3.943    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 695244     Buffer Size: 14914      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:04:04,879][train][INFO][train.py>_log] ==> #217000     Total Loss: 1.392    [weighted Loss:1.392    Policy Loss: 3.767    Value Loss: 3.840    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 697308     Buffer Size: 14671      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:07:12,561][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.155    [weighted Loss:1.155    Policy Loss: 3.650    Value Loss: 3.567    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 699606     Buffer Size: 14524      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:10:12,329][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.285    [weighted Loss:1.285    Policy Loss: 4.097    Value Loss: 3.728    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 701694     Buffer Size: 14496      Transition Number: 1000.249k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:13:12,401][train][INFO][train.py>_log] ==> #220000     Total Loss: 0.561    [weighted Loss:0.561    Policy Loss: 4.056    Value Loss: 3.427    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 703970     Buffer Size: 14571      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:16:13,713][train][INFO][train.py>_log] ==> #221000     Total Loss: 1.669    [weighted Loss:1.669    Policy Loss: 4.121    Value Loss: 3.630    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 706275     Buffer Size: 14620      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:19:15,697][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.147    [weighted Loss:1.147    Policy Loss: 3.269    Value Loss: 3.539    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 708370     Buffer Size: 14686      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:22:16,360][train][INFO][train.py>_log] ==> #223000     Total Loss: 0.774    [weighted Loss:0.774    Policy Loss: 4.262    Value Loss: 3.568    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 710595     Buffer Size: 14700      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:25:16,027][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.597    [weighted Loss:1.597    Policy Loss: 4.315    Value Loss: 3.960    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 712465     Buffer Size: 14777      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:28:15,242][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.665    [weighted Loss:1.665    Policy Loss: 4.311    Value Loss: 3.754    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 714896     Buffer Size: 14994      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:31:13,950][train][INFO][train.py>_log] ==> #226000     Total Loss: 1.626    [weighted Loss:1.626    Policy Loss: 5.158    Value Loss: 4.051    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 716856     Buffer Size: 15162      Transition Number: 1000.061k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:34:17,485][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 5.834    Value Loss: 3.960    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 721686     Buffer Size: 17565      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:37:16,764][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 5.580    Value Loss: 4.237    Reward Loss: 0.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 725945     Buffer Size: 19942      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:40:12,237][train][INFO][train.py>_log] ==> #229000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 4.953    Value Loss: 4.345    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 728657     Buffer Size: 20575      Transition Number: 1000.242k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:43:09,857][train][INFO][train.py>_log] ==> #230000     Total Loss: 1.356    [weighted Loss:1.356    Policy Loss: 4.384    Value Loss: 4.618    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 731464     Buffer Size: 21273      Transition Number: 1000.424k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:46:05,158][train][INFO][train.py>_log] ==> #231000     Total Loss: 1.274    [weighted Loss:1.274    Policy Loss: 4.057    Value Loss: 4.685    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 734077     Buffer Size: 21827      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:49:01,805][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.597    [weighted Loss:1.597    Policy Loss: 4.010    Value Loss: 4.477    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 736715     Buffer Size: 22275      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:51:56,174][train][INFO][train.py>_log] ==> #233000     Total Loss: 1.714    [weighted Loss:1.714    Policy Loss: 3.842    Value Loss: 4.215    Reward Loss: 0.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 739133     Buffer Size: 22567      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:54:55,570][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 4.395    Value Loss: 4.076    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 741635     Buffer Size: 20696      Transition Number: 1001.283k Batch Size: 256        Lr: 0.10000 
[2022-01-18 02:57:56,161][train][INFO][train.py>_log] ==> #235000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 3.840    Value Loss: 4.388    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 743900     Buffer Size: 18848      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:00:58,255][train][INFO][train.py>_log] ==> #236000     Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 4.423    Value Loss: 4.360    Reward Loss: 0.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 746177     Buffer Size: 17915      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:03:55,823][train][INFO][train.py>_log] ==> #237000     Total Loss: 1.135    [weighted Loss:1.135    Policy Loss: 3.723    Value Loss: 4.158    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 748295     Buffer Size: 17436      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:06:54,548][train][INFO][train.py>_log] ==> #238000     Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 3.915    Value Loss: 4.071    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 750617     Buffer Size: 16929      Transition Number: 1000.061k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:09:53,440][train][INFO][train.py>_log] ==> #239000     Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 4.208    Value Loss: 3.953    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 752813     Buffer Size: 16533      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:12:55,895][train][INFO][train.py>_log] ==> #240000     Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 4.152    Value Loss: 3.969    Reward Loss: 0.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 755239     Buffer Size: 16282      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:15:58,098][train][INFO][train.py>_log] ==> #241000     Total Loss: 0.994    [weighted Loss:0.994    Policy Loss: 4.242    Value Loss: 4.500    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 758239     Buffer Size: 16867      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:18:57,764][train][INFO][train.py>_log] ==> #242000     Total Loss: 1.898    [weighted Loss:1.898    Policy Loss: 3.899    Value Loss: 4.291    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 761172     Buffer Size: 17659      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:21:56,245][train][INFO][train.py>_log] ==> #243000     Total Loss: 1.375    [weighted Loss:1.375    Policy Loss: 3.973    Value Loss: 4.116    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 763197     Buffer Size: 17567      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:25:00,671][train][INFO][train.py>_log] ==> #244000     Total Loss: 1.803    [weighted Loss:1.803    Policy Loss: 4.055    Value Loss: 3.963    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 765549     Buffer Size: 17508      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:27:58,375][train][INFO][train.py>_log] ==> #245000     Total Loss: 1.112    [weighted Loss:1.112    Policy Loss: 3.932    Value Loss: 4.167    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 767828     Buffer Size: 17438      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:30:55,470][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 3.970    Value Loss: 4.547    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 769879     Buffer Size: 17320      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:33:56,641][train][INFO][train.py>_log] ==> #247000     Total Loss: 1.528    [weighted Loss:1.528    Policy Loss: 4.109    Value Loss: 4.215    Reward Loss: 0.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 772187     Buffer Size: 17145      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:37:02,061][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.550    [weighted Loss:1.550    Policy Loss: 5.013    Value Loss: 4.079    Reward Loss: 0.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 774505     Buffer Size: 16254      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:40:03,129][train][INFO][train.py>_log] ==> #249000     Total Loss: 1.395    [weighted Loss:1.395    Policy Loss: 4.386    Value Loss: 4.405    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 776777     Buffer Size: 15527      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:43:05,347][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 4.750    Value Loss: 4.188    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 779135     Buffer Size: 15660      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:46:07,503][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 4.167    Value Loss: 4.210    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 781595     Buffer Size: 15701      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:49:09,175][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.078    [weighted Loss:1.078    Policy Loss: 4.184    Value Loss: 4.127    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 783547     Buffer Size: 15763      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:52:08,155][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 4.685    Value Loss: 3.908    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 785669     Buffer Size: 15742      Transition Number: 1000.187k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:55:09,058][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.914    [weighted Loss:1.914    Policy Loss: 4.313    Value Loss: 4.068    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 787950     Buffer Size: 15773      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 03:58:15,045][train][INFO][train.py>_log] ==> #255000     Total Loss: 1.355    [weighted Loss:1.355    Policy Loss: 4.391    Value Loss: 4.351    Reward Loss: 0.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 793814     Buffer Size: 19120      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:01:15,393][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 4.790    Value Loss: 4.752    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 799381     Buffer Size: 22390      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:04:07,984][train][INFO][train.py>_log] ==> #257000     Total Loss: 1.487    [weighted Loss:1.487    Policy Loss: 4.421    Value Loss: 4.411    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 801453     Buffer Size: 22375      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:07:05,568][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.059    [weighted Loss:1.059    Policy Loss: 4.266    Value Loss: 4.501    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 803776     Buffer Size: 22365      Transition Number: 1001.625k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:10:00,849][train][INFO][train.py>_log] ==> #259000     Total Loss: 1.337    [weighted Loss:1.337    Policy Loss: 4.643    Value Loss: 4.302    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 805813     Buffer Size: 22267      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:13:03,150][train][INFO][train.py>_log] ==> #260000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 4.143    Value Loss: 4.710    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 808157     Buffer Size: 22262      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:15:57,626][train][INFO][train.py>_log] ==> #261000     Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 4.350    Value Loss: 4.450    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 810070     Buffer Size: 22322      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:18:55,829][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.418    [weighted Loss:1.418    Policy Loss: 4.284    Value Loss: 4.863    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 812402     Buffer Size: 19578      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:21:53,974][train][INFO][train.py>_log] ==> #263000     Total Loss: 1.085    [weighted Loss:1.085    Policy Loss: 4.485    Value Loss: 4.515    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 814472     Buffer Size: 16593      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:24:56,716][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.550    [weighted Loss:1.550    Policy Loss: 4.443    Value Loss: 3.907    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 816849     Buffer Size: 15497      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:27:56,741][train][INFO][train.py>_log] ==> #265000     Total Loss: 1.898    [weighted Loss:1.898    Policy Loss: 4.127    Value Loss: 4.454    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 819280     Buffer Size: 15593      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:30:59,587][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.049    [weighted Loss:1.049    Policy Loss: 4.342    Value Loss: 4.189    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 821525     Buffer Size: 15770      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:34:02,985][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 4.781    Value Loss: 4.410    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 823950     Buffer Size: 15893      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:36:59,664][train][INFO][train.py>_log] ==> #268000     Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 4.806    Value Loss: 4.455    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 826009     Buffer Size: 16024      Transition Number: 1000.094k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:40:01,502][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 5.287    Value Loss: 4.469    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 828661     Buffer Size: 16225      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:43:00,230][train][INFO][train.py>_log] ==> #270000     Total Loss: 1.913    [weighted Loss:1.913    Policy Loss: 5.469    Value Loss: 4.722    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 830732     Buffer Size: 16471      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:45:57,191][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 4.709    Value Loss: 4.070    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 833191     Buffer Size: 16589      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:48:53,581][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 4.915    Value Loss: 4.353    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 835533     Buffer Size: 16648      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:51:51,658][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.119    [weighted Loss:2.119    Policy Loss: 4.773    Value Loss: 4.358    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 837674     Buffer Size: 16569      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:54:49,119][train][INFO][train.py>_log] ==> #274000     Total Loss: 1.666    [weighted Loss:1.666    Policy Loss: 4.647    Value Loss: 4.237    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 840022     Buffer Size: 16516      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 04:57:45,954][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 5.536    Value Loss: 4.493    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 842214     Buffer Size: 16443      Transition Number: 1000.401k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:00:45,869][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 4.339    Value Loss: 4.518    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 844529     Buffer Size: 16329      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:03:41,801][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.388    [weighted Loss:1.388    Policy Loss: 4.998    Value Loss: 4.642    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 846204     Buffer Size: 16155      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:06:40,760][train][INFO][train.py>_log] ==> #278000     Total Loss: 1.551    [weighted Loss:1.551    Policy Loss: 4.077    Value Loss: 4.394    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 848555     Buffer Size: 15897      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:09:40,984][train][INFO][train.py>_log] ==> #279000     Total Loss: 1.259    [weighted Loss:1.259    Policy Loss: 4.306    Value Loss: 4.478    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 850647     Buffer Size: 15686      Transition Number: 1001.484k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:12:44,291][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.488    [weighted Loss:1.488    Policy Loss: 4.098    Value Loss: 4.276    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 852825     Buffer Size: 15479      Transition Number: 1000.137k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:15:47,106][train][INFO][train.py>_log] ==> #281000     Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 4.209    Value Loss: 4.323    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 854957     Buffer Size: 15334      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:18:50,364][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.339    [weighted Loss:1.339    Policy Loss: 4.966    Value Loss: 4.142    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 857154     Buffer Size: 15173      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:21:57,454][train][INFO][train.py>_log] ==> #283000     Total Loss: 1.832    [weighted Loss:1.832    Policy Loss: 5.375    Value Loss: 4.177    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 859890     Buffer Size: 15455      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:24:57,586][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 4.927    Value Loss: 4.457    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 862463     Buffer Size: 15820      Transition Number: 1000.101k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:27:56,753][train][INFO][train.py>_log] ==> #285000     Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 4.886    Value Loss: 4.572    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 864725     Buffer Size: 15958      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:30:56,746][train][INFO][train.py>_log] ==> #286000     Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 4.829    Value Loss: 4.751    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 867198     Buffer Size: 16133      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:33:53,291][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 4.574    Value Loss: 4.450    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 869257     Buffer Size: 16260      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:36:54,694][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 4.311    Value Loss: 4.398    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 871640     Buffer Size: 16404      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:39:56,965][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 4.401    Value Loss: 4.880    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 873897     Buffer Size: 16566      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:42:57,644][train][INFO][train.py>_log] ==> #290000     Total Loss: 0.983    [weighted Loss:0.983    Policy Loss: 4.433    Value Loss: 4.467    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 876133     Buffer Size: 16335      Transition Number: 1000.133k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:45:57,114][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 4.091    Value Loss: 4.139    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 878473     Buffer Size: 15956      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:48:55,664][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.715    [weighted Loss:1.715    Policy Loss: 4.200    Value Loss: 4.656    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 880386     Buffer Size: 15926      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:52:00,936][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 4.492    Value Loss: 4.322    Reward Loss: 0.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 883005     Buffer Size: 15930      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:55:02,392][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 4.121    Value Loss: 4.466    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 885301     Buffer Size: 16055      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 05:58:08,098][train][INFO][train.py>_log] ==> #295000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 4.454    Value Loss: 4.451    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 887622     Buffer Size: 16130      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:01:06,876][train][INFO][train.py>_log] ==> #296000     Total Loss: 1.353    [weighted Loss:1.353    Policy Loss: 4.463    Value Loss: 4.624    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 889905     Buffer Size: 16150      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:04:07,582][train][INFO][train.py>_log] ==> #297000     Total Loss: 1.281    [weighted Loss:1.281    Policy Loss: 4.557    Value Loss: 4.558    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 892084     Buffer Size: 16093      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:07:09,842][train][INFO][train.py>_log] ==> #298000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 4.295    Value Loss: 4.383    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 894331     Buffer Size: 16037      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:10:14,300][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.076    [weighted Loss:2.076    Policy Loss: 4.711    Value Loss: 4.422    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 899100     Buffer Size: 18388      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:13:11,678][train][INFO][train.py>_log] ==> #300000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 5.021    Value Loss: 4.785    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 903523     Buffer Size: 20790      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:16:09,089][train][INFO][train.py>_log] ==> #301000     Total Loss: 1.328    [weighted Loss:1.328    Policy Loss: 4.634    Value Loss: 4.630    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 907211     Buffer Size: 21898      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:19:08,084][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 4.981    Value Loss: 4.638    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 910812     Buffer Size: 23111      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:22:02,231][train][INFO][train.py>_log] ==> #303000     Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 4.799    Value Loss: 4.609    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 912717     Buffer Size: 23119      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:24:57,559][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.843    [weighted Loss:1.843    Policy Loss: 4.659    Value Loss: 4.477    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 915072     Buffer Size: 23111      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:27:53,462][train][INFO][train.py>_log] ==> #305000     Total Loss: 1.331    [weighted Loss:1.331    Policy Loss: 4.980    Value Loss: 4.516    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 917332     Buffer Size: 23119      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:30:50,645][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 5.004    Value Loss: 4.894    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 919422     Buffer Size: 21165      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:33:52,095][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 5.781    Value Loss: 4.535    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 921771     Buffer Size: 18484      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:36:53,591][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 5.136    Value Loss: 4.594    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 924080     Buffer Size: 17087      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:39:56,001][train][INFO][train.py>_log] ==> #309000     Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 5.307    Value Loss: 4.437    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 926255     Buffer Size: 15824      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:42:57,041][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.261    [weighted Loss:1.261    Policy Loss: 4.990    Value Loss: 4.300    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 928585     Buffer Size: 15675      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:45:59,554][train][INFO][train.py>_log] ==> #311000     Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 5.200    Value Loss: 4.464    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 930907     Buffer Size: 15613      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:48:56,411][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 5.038    Value Loss: 4.246    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 932914     Buffer Size: 15628      Transition Number: 1000.959k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:51:52,626][train][INFO][train.py>_log] ==> #313000     Total Loss: 1.515    [weighted Loss:1.515    Policy Loss: 4.898    Value Loss: 4.387    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 935114     Buffer Size: 15707      Transition Number: 1001.524k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:54:57,061][train][INFO][train.py>_log] ==> #314000     Total Loss: 1.103    [weighted Loss:1.103    Policy Loss: 4.866    Value Loss: 4.271    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 937461     Buffer Size: 15737      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 06:58:00,890][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 4.992    Value Loss: 4.113    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 939709     Buffer Size: 15671      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:01:05,049][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.674    [weighted Loss:1.674    Policy Loss: 5.362    Value Loss: 4.562    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 941982     Buffer Size: 15629      Transition Number: 1000.251k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:04:09,965][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 5.089    Value Loss: 4.417    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 944454     Buffer Size: 15472      Transition Number: 1000.187k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:07:13,579][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.903    [weighted Loss:1.903    Policy Loss: 5.258    Value Loss: 4.044    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 946646     Buffer Size: 15365      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:10:12,337][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 5.251    Value Loss: 4.113    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 949045     Buffer Size: 15233      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:13:12,297][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.337    [weighted Loss:1.337    Policy Loss: 5.217    Value Loss: 4.012    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 951035     Buffer Size: 15046      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:16:14,034][train][INFO][train.py>_log] ==> #321000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 5.696    Value Loss: 4.110    Reward Loss: 0.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 953440     Buffer Size: 14863      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:19:18,377][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 4.733    Value Loss: 4.003    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 955636     Buffer Size: 14812      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:22:23,307][train][INFO][train.py>_log] ==> #323000     Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 4.662    Value Loss: 4.071    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 958068     Buffer Size: 14713      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:25:29,894][train][INFO][train.py>_log] ==> #324000     Total Loss: 0.964    [weighted Loss:0.964    Policy Loss: 5.454    Value Loss: 4.313    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 960146     Buffer Size: 14724      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:28:29,585][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 5.164    Value Loss: 4.234    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 962507     Buffer Size: 14807      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:31:31,945][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 5.030    Value Loss: 4.117    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 964783     Buffer Size: 14901      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:34:33,983][train][INFO][train.py>_log] ==> #327000     Total Loss: 1.782    [weighted Loss:1.782    Policy Loss: 4.725    Value Loss: 4.341    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 967085     Buffer Size: 14912      Transition Number: 1000.028k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:37:33,195][train][INFO][train.py>_log] ==> #328000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 5.201    Value Loss: 4.249    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 969351     Buffer Size: 14871      Transition Number: 1000.390k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:40:35,252][train][INFO][train.py>_log] ==> #329000     Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 5.270    Value Loss: 4.180    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 971632     Buffer Size: 15146      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:43:35,828][train][INFO][train.py>_log] ==> #330000     Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 5.048    Value Loss: 4.187    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 974100     Buffer Size: 15455      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:46:38,552][train][INFO][train.py>_log] ==> #331000     Total Loss: 1.522    [weighted Loss:1.522    Policy Loss: 4.840    Value Loss: 4.406    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 976878     Buffer Size: 15928      Transition Number: 1000.001k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:49:37,942][train][INFO][train.py>_log] ==> #332000     Total Loss: 1.091    [weighted Loss:1.091    Policy Loss: 4.616    Value Loss: 4.244    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 979449     Buffer Size: 16309      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:52:41,039][train][INFO][train.py>_log] ==> #333000     Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 4.832    Value Loss: 4.321    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 981859     Buffer Size: 16315      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:55:44,037][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 4.733    Value Loss: 4.231    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 983796     Buffer Size: 16349      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-01-18 07:58:42,985][train][INFO][train.py>_log] ==> #335000     Total Loss: 0.529    [weighted Loss:0.529    Policy Loss: 5.045    Value Loss: 4.304    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 986225     Buffer Size: 16373      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:01:42,778][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 5.293    Value Loss: 4.367    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 988372     Buffer Size: 16184      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:04:43,054][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 5.187    Value Loss: 4.188    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 990687     Buffer Size: 15923      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:07:43,826][train][INFO][train.py>_log] ==> #338000     Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 5.631    Value Loss: 4.191    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 992984     Buffer Size: 15574      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:10:47,311][train][INFO][train.py>_log] ==> #339000     Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 5.472    Value Loss: 4.326    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 995380     Buffer Size: 15560      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:13:49,435][train][INFO][train.py>_log] ==> #340000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 5.219    Value Loss: 4.521    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 997907     Buffer Size: 15880      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:16:47,787][train][INFO][train.py>_log] ==> #341000     Total Loss: 1.741    [weighted Loss:1.741    Policy Loss: 5.159    Value Loss: 4.730    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000199    Buffer Size: 16001      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:19:45,075][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 4.839    Value Loss: 5.003    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002289    Buffer Size: 16063      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:22:42,360][train][INFO][train.py>_log] ==> #343000     Total Loss: 1.625    [weighted Loss:1.625    Policy Loss: 4.867    Value Loss: 4.659    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1004493    Buffer Size: 16014      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:25:42,521][train][INFO][train.py>_log] ==> #344000     Total Loss: 0.970    [weighted Loss:0.970    Policy Loss: 4.895    Value Loss: 4.265    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1006808    Buffer Size: 15933      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:28:41,704][train][INFO][train.py>_log] ==> #345000     Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 5.326    Value Loss: 4.529    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1008908    Buffer Size: 15935      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:31:44,258][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.352    [weighted Loss:1.352    Policy Loss: 4.740    Value Loss: 4.618    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1011289    Buffer Size: 15612      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:34:44,210][train][INFO][train.py>_log] ==> #347000     Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 4.259    Value Loss: 4.526    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013563    Buffer Size: 15334      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:37:47,629][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 4.409    Value Loss: 4.190    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1015936    Buffer Size: 15252      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:40:49,208][train][INFO][train.py>_log] ==> #349000     Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 5.093    Value Loss: 4.060    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1018209    Buffer Size: 15144      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:43:47,803][train][INFO][train.py>_log] ==> #350000     Total Loss: 1.172    [weighted Loss:1.172    Policy Loss: 5.591    Value Loss: 4.514    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 1020293    Buffer Size: 15175      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:46:48,459][train][INFO][train.py>_log] ==> #351000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 5.693    Value Loss: 4.349    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1022948    Buffer Size: 15546      Transition Number: 1000.618k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:49:51,941][train][INFO][train.py>_log] ==> #352000     Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 5.883    Value Loss: 4.317    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025559    Buffer Size: 15904      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:52:50,298][train][INFO][train.py>_log] ==> #353000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 5.418    Value Loss: 4.445    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1027994    Buffer Size: 16166      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:55:49,067][train][INFO][train.py>_log] ==> #354000     Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 5.068    Value Loss: 4.502    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030620    Buffer Size: 16430      Transition Number: 1000.537k Batch Size: 256        Lr: 0.10000 
[2022-01-18 08:58:45,363][train][INFO][train.py>_log] ==> #355000     Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 5.138    Value Loss: 4.609    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032766    Buffer Size: 16693      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:01:40,454][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.537    [weighted Loss:1.537    Policy Loss: 4.432    Value Loss: 4.650    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035322    Buffer Size: 17000      Transition Number: 1000.118k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:04:38,646][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 5.255    Value Loss: 4.652    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1037661    Buffer Size: 17199      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
