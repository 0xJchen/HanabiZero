[2022-01-18 09:06:21,962][train][INFO][train.py>_log] ==> #0          Total Loss: 48.994   [weighted Loss:48.994   Policy Loss: 14.523   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1455       Buffer Size: 1455       Transition Number: 17.337  k Batch Size: 256        Lr: 0.00000 
[2022-01-18 09:08:07,977][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.082    [weighted Loss:4.082    Policy Loss: 13.475   Value Loss: 3.526    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 5546       Buffer Size: 5546       Transition Number: 68.508  k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:09:56,331][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.142    [weighted Loss:4.142    Policy Loss: 11.943   Value Loss: 3.055    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 9755       Buffer Size: 9755       Transition Number: 121.473 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:11:40,309][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 11.715   Value Loss: 2.875    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 15151      Buffer Size: 15151      Transition Number: 175.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:13:21,894][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.079    [weighted Loss:6.079    Policy Loss: 12.071   Value Loss: 2.858    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 19893      Buffer Size: 19893      Transition Number: 223.444 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:15:01,604][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.994    [weighted Loss:4.994    Policy Loss: 12.527   Value Loss: 2.819    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 23563      Buffer Size: 23563      Transition Number: 268.642 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:16:41,019][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.208    [weighted Loss:5.208    Policy Loss: 12.134   Value Loss: 2.832    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 27314      Buffer Size: 27314      Transition Number: 314.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:18:21,315][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.856    [weighted Loss:4.856    Policy Loss: 12.299   Value Loss: 2.694    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 29395      Buffer Size: 29395      Transition Number: 359.203 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:19:59,561][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.526    [weighted Loss:5.526    Policy Loss: 12.721   Value Loss: 2.695    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 31336      Buffer Size: 31336      Transition Number: 403.186 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:21:43,967][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.988    [weighted Loss:3.988    Policy Loss: 12.922   Value Loss: 2.642    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 33941      Buffer Size: 33941      Transition Number: 449.477 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:23:31,133][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.965    [weighted Loss:4.965    Policy Loss: 12.330   Value Loss: 2.761    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 36953      Buffer Size: 36953      Transition Number: 501.199 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:25:18,354][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.778    [weighted Loss:4.778    Policy Loss: 12.336   Value Loss: 2.777    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 40207      Buffer Size: 40207      Transition Number: 551.813 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:27:13,452][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 12.216   Value Loss: 2.906    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 43699      Buffer Size: 43699      Transition Number: 606.513 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:29:09,819][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.213    [weighted Loss:3.213    Policy Loss: 11.927   Value Loss: 2.989    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 47284      Buffer Size: 47284      Transition Number: 659.708 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:31:09,477][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.068    [weighted Loss:5.068    Policy Loss: 11.788   Value Loss: 3.024    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 51146      Buffer Size: 51146      Transition Number: 719.501 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:33:11,046][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.387    [weighted Loss:3.387    Policy Loss: 11.479   Value Loss: 3.100    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 53233      Buffer Size: 53233      Transition Number: 770.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:35:19,281][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.708    [weighted Loss:3.708    Policy Loss: 9.117    Value Loss: 3.181    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 55422      Buffer Size: 55422      Transition Number: 828.459 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:37:30,511][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.319    [weighted Loss:3.319    Policy Loss: 8.115    Value Loss: 3.365    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 57115      Buffer Size: 57115      Transition Number: 884.537 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:39:43,992][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.779    [weighted Loss:2.779    Policy Loss: 6.377    Value Loss: 3.428    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 58841      Buffer Size: 58841      Transition Number: 942.825 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:42:01,579][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 6.168    Value Loss: 3.591    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 59862      Buffer Size: 59340      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:44:30,069][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 5.884    Value Loss: 3.387    Reward Loss: 0.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 61066      Buffer Size: 54388      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:47:03,486][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 5.623    Value Loss: 3.336    Reward Loss: 0.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 62316      Buffer Size: 48460      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:49:38,024][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 5.183    Value Loss: 3.196    Reward Loss: 0.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 63590      Buffer Size: 41918      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:52:14,692][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 5.567    Value Loss: 3.524    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 64873      Buffer Size: 37048      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:54:47,987][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 4.474    Value Loss: 3.360    Reward Loss: 0.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 66091      Buffer Size: 34949      Transition Number: 1000.107k Batch Size: 256        Lr: 0.10000 
[2022-01-18 09:57:25,186][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 5.389    Value Loss: 3.608    Reward Loss: 0.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 67271      Buffer Size: 32009      Transition Number: 1000.400k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:00:02,068][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 4.866    Value Loss: 3.430    Reward Loss: 0.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 68571      Buffer Size: 28195      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:02:40,607][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 5.795    Value Loss: 3.749    Reward Loss: 0.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 69904      Buffer Size: 24104      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:05:18,220][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 5.027    Value Loss: 3.603    Reward Loss: 0.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 71168      Buffer Size: 20073      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:07:58,404][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.002    [weighted Loss:3.002    Policy Loss: 5.811    Value Loss: 3.616    Reward Loss: 0.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 72475      Buffer Size: 18263      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:10:36,735][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.544    [weighted Loss:1.544    Policy Loss: 5.372    Value Loss: 3.490    Reward Loss: 0.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 73827      Buffer Size: 16943      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:13:16,002][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 5.417    Value Loss: 3.778    Reward Loss: 0.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 75204      Buffer Size: 16083      Transition Number: 1000.269k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:15:54,542][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 5.372    Value Loss: 4.094    Reward Loss: 0.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 76517      Buffer Size: 16245      Transition Number: 1001.274k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:18:36,318][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.408    [weighted Loss:3.408    Policy Loss: 6.541    Value Loss: 4.021    Reward Loss: 0.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 78066      Buffer Size: 16598      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:21:17,558][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.091    [weighted Loss:3.091    Policy Loss: 6.083    Value Loss: 3.838    Reward Loss: 0.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 79684      Buffer Size: 16982      Transition Number: 1000.065k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:23:59,188][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.885    [weighted Loss:2.885    Policy Loss: 7.396    Value Loss: 4.466    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 81392      Buffer Size: 17424      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:26:40,823][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.440    [weighted Loss:2.440    Policy Loss: 7.005    Value Loss: 4.606    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 83055      Buffer Size: 17806      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:29:20,051][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.173    [weighted Loss:4.173    Policy Loss: 8.064    Value Loss: 4.592    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 84851      Buffer Size: 18389      Transition Number: 999.928 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:31:58,904][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.779    [weighted Loss:2.779    Policy Loss: 7.026    Value Loss: 4.480    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 86721      Buffer Size: 18971      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:34:39,723][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 8.227    Value Loss: 4.545    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 88479      Buffer Size: 19433      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:37:19,782][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 6.424    Value Loss: 4.701    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 90330      Buffer Size: 19994      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:40:00,240][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 6.841    Value Loss: 4.797    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 92001      Buffer Size: 20415      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:42:40,031][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 7.198    Value Loss: 4.807    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 93723      Buffer Size: 20848      Transition Number: 1000.013k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:45:19,165][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 6.833    Value Loss: 4.406    Reward Loss: 0.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 95442      Buffer Size: 21218      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:47:57,040][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 7.042    Value Loss: 4.531    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 97117      Buffer Size: 21523      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:50:37,760][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 6.959    Value Loss: 4.671    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 98607      Buffer Size: 21665      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:53:17,450][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 6.491    Value Loss: 4.863    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 100185     Buffer Size: 21626      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:55:57,966][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.826    [weighted Loss:2.826    Policy Loss: 6.380    Value Loss: 4.512    Reward Loss: 0.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 101694     Buffer Size: 21508      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 10:58:40,504][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 6.548    Value Loss: 4.513    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 103282     Buffer Size: 21374      Transition Number: 1000.254k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:01:23,407][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 6.308    Value Loss: 4.377    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 104775     Buffer Size: 21175      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:04:05,615][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 5.622    Value Loss: 4.479    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 106295     Buffer Size: 20791      Transition Number: 1000.102k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:06:46,890][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 5.122    Value Loss: 4.312    Reward Loss: 0.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 107658     Buffer Size: 20356      Transition Number: 1000.064k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:09:28,650][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 4.363    Value Loss: 4.352    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 109033     Buffer Size: 19964      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:12:09,397][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 4.716    Value Loss: 4.556    Reward Loss: 0.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 110343     Buffer Size: 19526      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:14:50,218][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 4.393    Value Loss: 4.294    Reward Loss: 0.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 111716     Buffer Size: 19124      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:17:35,296][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 4.186    Value Loss: 4.511    Reward Loss: 0.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 113060     Buffer Size: 18731      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:20:20,384][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 3.290    Value Loss: 4.295    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 114468     Buffer Size: 18313      Transition Number: 1000.591k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:23:05,699][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.538    [weighted Loss:1.538    Policy Loss: 3.411    Value Loss: 4.225    Reward Loss: 0.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 115726     Buffer Size: 17866      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:25:47,429][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 3.967    Value Loss: 4.070    Reward Loss: 0.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 116984     Buffer Size: 17508      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:28:32,283][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 3.307    Value Loss: 4.368    Reward Loss: 0.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 118389     Buffer Size: 17277      Transition Number: 1000.317k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:31:18,045][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.161    [weighted Loss:1.161    Policy Loss: 3.363    Value Loss: 4.331    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 119795     Buffer Size: 17058      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:34:04,051][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 3.613    Value Loss: 4.427    Reward Loss: 0.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 121079     Buffer Size: 16817      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:36:51,191][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.583    [weighted Loss:1.583    Policy Loss: 3.728    Value Loss: 4.204    Reward Loss: 0.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 122509     Buffer Size: 16529      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:39:36,504][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 4.762    Value Loss: 4.138    Reward Loss: 0.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 123816     Buffer Size: 16370      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:42:19,855][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 3.851    Value Loss: 4.067    Reward Loss: 0.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 125071     Buffer Size: 16296      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:45:04,644][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 3.816    Value Loss: 4.404    Reward Loss: 0.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 126380     Buffer Size: 16210      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:47:48,790][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.642    [weighted Loss:1.642    Policy Loss: 3.363    Value Loss: 4.222    Reward Loss: 0.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 127660     Buffer Size: 16155      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:50:33,874][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.220    [weighted Loss:1.220    Policy Loss: 4.184    Value Loss: 4.375    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 128969     Buffer Size: 16132      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:53:16,005][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 4.007    Value Loss: 4.365    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 130385     Buffer Size: 16069      Transition Number: 999.925 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:56:01,586][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 4.845    Value Loss: 4.412    Reward Loss: 0.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 131643     Buffer Size: 16149      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 11:58:47,522][train][INFO][train.py>_log] ==> #70000      Total Loss: 0.800    [weighted Loss:0.800    Policy Loss: 3.749    Value Loss: 4.399    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 132979     Buffer Size: 16239      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:01:32,571][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 3.985    Value Loss: 4.343    Reward Loss: 0.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 134349     Buffer Size: 16207      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:04:18,043][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.643    [weighted Loss:1.643    Policy Loss: 3.301    Value Loss: 4.075    Reward Loss: 0.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 135649     Buffer Size: 16183      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:07:05,820][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 4.131    Value Loss: 4.073    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 136976     Buffer Size: 16171      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:09:53,941][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.838    [weighted Loss:1.838    Policy Loss: 4.249    Value Loss: 4.077    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 138443     Buffer Size: 16202      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:12:41,678][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.811    [weighted Loss:1.811    Policy Loss: 3.962    Value Loss: 4.409    Reward Loss: 0.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 139971     Buffer Size: 16378      Transition Number: 1000.023k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:15:27,751][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.190    [weighted Loss:1.190    Policy Loss: 4.304    Value Loss: 4.176    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 141451     Buffer Size: 16565      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:18:13,435][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.967    [weighted Loss:1.967    Policy Loss: 4.753    Value Loss: 4.411    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 142832     Buffer Size: 16729      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:20:58,790][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 4.376    Value Loss: 4.503    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 144238     Buffer Size: 16848      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:23:43,103][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 4.113    Value Loss: 4.425    Reward Loss: 0.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 145707     Buffer Size: 16913      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:26:27,056][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 3.807    Value Loss: 4.313    Reward Loss: 0.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 147073     Buffer Size: 16954      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:29:10,208][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 4.599    Value Loss: 4.286    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 148384     Buffer Size: 16969      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:31:57,237][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.476    [weighted Loss:1.476    Policy Loss: 3.800    Value Loss: 4.170    Reward Loss: 0.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 149818     Buffer Size: 17018      Transition Number: 999.941 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:34:43,466][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.933    [weighted Loss:1.933    Policy Loss: 3.906    Value Loss: 4.416    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 151124     Buffer Size: 17048      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:37:28,933][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.265    [weighted Loss:1.265    Policy Loss: 4.000    Value Loss: 4.234    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 152452     Buffer Size: 17038      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:40:16,936][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.364    [weighted Loss:1.364    Policy Loss: 3.812    Value Loss: 3.982    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 153873     Buffer Size: 17037      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:43:03,016][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 3.902    Value Loss: 4.163    Reward Loss: 0.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 155238     Buffer Size: 17010      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:45:47,151][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.175    Value Loss: 3.919    Reward Loss: 0.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 156618     Buffer Size: 16865      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:48:30,592][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.219    [weighted Loss:1.219    Policy Loss: 3.687    Value Loss: 4.158    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 157905     Buffer Size: 16737      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:51:13,669][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 4.811    Value Loss: 4.365    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 159090     Buffer Size: 16533      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:54:02,780][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 3.812    Value Loss: 4.064    Reward Loss: 0.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 160516     Buffer Size: 16299      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:56:51,756][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 4.213    Value Loss: 4.097    Reward Loss: 0.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 161986     Buffer Size: 16294      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 12:59:36,784][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 3.819    Value Loss: 4.236    Reward Loss: 0.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 163409     Buffer Size: 16341      Transition Number: 1000.263k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:02:21,704][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 4.335    Value Loss: 4.221    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 164688     Buffer Size: 16375      Transition Number: 1000.156k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:05:08,458][train][INFO][train.py>_log] ==> #94000      Total Loss: 0.991    [weighted Loss:0.991    Policy Loss: 4.610    Value Loss: 3.931    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 166143     Buffer Size: 16393      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:07:53,984][train][INFO][train.py>_log] ==> #95000      Total Loss: 1.696    [weighted Loss:1.696    Policy Loss: 4.368    Value Loss: 4.381    Reward Loss: 0.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 167621     Buffer Size: 16505      Transition Number: 1000.018k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:10:40,349][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.010    [weighted Loss:1.010    Policy Loss: 4.368    Value Loss: 4.316    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 169129     Buffer Size: 16661      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:13:26,533][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.236    [weighted Loss:1.236    Policy Loss: 3.560    Value Loss: 4.444    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 170542     Buffer Size: 16786      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:16:13,827][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.626    [weighted Loss:1.626    Policy Loss: 4.087    Value Loss: 4.132    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 171986     Buffer Size: 16917      Transition Number: 1000.036k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:19:00,557][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 3.557    Value Loss: 4.048    Reward Loss: 0.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 173530     Buffer Size: 17093      Transition Number: 1000.110k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:21:45,725][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 3.982    Value Loss: 4.503    Reward Loss: 0.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 175065     Buffer Size: 17282      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:24:31,718][train][INFO][train.py>_log] ==> #101000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 4.634    Value Loss: 4.270    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 176531     Buffer Size: 17490      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:27:17,680][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.287    [weighted Loss:1.287    Policy Loss: 4.693    Value Loss: 4.396    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 178029     Buffer Size: 17741      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:30:05,754][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 4.457    Value Loss: 4.647    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 179437     Buffer Size: 17836      Transition Number: 999.928 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:32:53,052][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 4.407    Value Loss: 4.586    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 180821     Buffer Size: 17857      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:35:43,256][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 5.510    Value Loss: 4.370    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 182270     Buffer Size: 17832      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:38:33,832][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 4.740    Value Loss: 4.762    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 183688     Buffer Size: 17833      Transition Number: 1000.086k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:41:22,418][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 5.133    Value Loss: 4.344    Reward Loss: 0.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 185163     Buffer Size: 17769      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:44:09,559][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 5.165    Value Loss: 4.371    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 186561     Buffer Size: 17707      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:46:58,563][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 5.782    Value Loss: 4.295    Reward Loss: 0.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 188428     Buffer Size: 18073      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:49:42,684][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 5.894    Value Loss: 4.552    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 190243     Buffer Size: 18440      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:52:30,142][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.015    [weighted Loss:3.015    Policy Loss: 5.279    Value Loss: 4.703    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 192010     Buffer Size: 18676      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:55:17,119][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 5.445    Value Loss: 4.820    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 193765     Buffer Size: 18908      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 13:58:03,383][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 5.428    Value Loss: 4.639    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 195345     Buffer Size: 19042      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:00:48,737][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.993    [weighted Loss:2.993    Policy Loss: 5.265    Value Loss: 4.644    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 196962     Buffer Size: 19127      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:03:36,974][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 5.085    Value Loss: 4.864    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 198560     Buffer Size: 19228      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:06:22,769][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.444    [weighted Loss:1.444    Policy Loss: 4.367    Value Loss: 4.804    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 200109     Buffer Size: 19367      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:09:06,477][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 4.196    Value Loss: 4.976    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 201578     Buffer Size: 19524      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:11:52,501][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 4.065    Value Loss: 4.952    Reward Loss: 0.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 203191     Buffer Size: 19759      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:14:35,542][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 4.087    Value Loss: 4.864    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 204571     Buffer Size: 19764      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:17:23,050][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 3.647    Value Loss: 4.862    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 206050     Buffer Size: 19736      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:20:13,976][train][INFO][train.py>_log] ==> #121000     Total Loss: 1.703    [weighted Loss:1.703    Policy Loss: 3.922    Value Loss: 4.529    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 207373     Buffer Size: 19163      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:23:02,205][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 3.627    Value Loss: 4.807    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 208680     Buffer Size: 18586      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:25:49,391][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 3.505    Value Loss: 4.559    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 210180     Buffer Size: 18302      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:28:37,798][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 3.314    Value Loss: 4.796    Reward Loss: 0.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 211715     Buffer Size: 17992      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:31:26,519][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.092    [weighted Loss:1.092    Policy Loss: 3.070    Value Loss: 4.439    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 213208     Buffer Size: 17829      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:34:16,094][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.589    [weighted Loss:1.589    Policy Loss: 3.746    Value Loss: 4.552    Reward Loss: 0.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 214684     Buffer Size: 17734      Transition Number: 1000.087k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:37:04,742][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.373    [weighted Loss:1.373    Policy Loss: 3.072    Value Loss: 4.381    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 216028     Buffer Size: 17347      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:39:53,656][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.365    [weighted Loss:1.365    Policy Loss: 3.471    Value Loss: 4.392    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 217302     Buffer Size: 16916      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:42:44,064][train][INFO][train.py>_log] ==> #129000     Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 3.460    Value Loss: 4.231    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 218867     Buffer Size: 16854      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:45:33,670][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 3.488    Value Loss: 4.094    Reward Loss: 0.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 220365     Buffer Size: 16826      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:48:23,062][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 3.693    Value Loss: 4.379    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 222026     Buffer Size: 16887      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:51:12,286][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 3.735    Value Loss: 4.124    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 223641     Buffer Size: 17058      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:54:04,037][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 3.657    Value Loss: 4.085    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 224843     Buffer Size: 17012      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:56:50,850][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 3.653    Value Loss: 4.100    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 226143     Buffer Size: 16879      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 14:59:40,457][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 3.646    Value Loss: 4.271    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 227417     Buffer Size: 16637      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:02:29,652][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 3.632    Value Loss: 3.919    Reward Loss: 0.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 228746     Buffer Size: 16325      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:05:19,141][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.407    [weighted Loss:2.407    Policy Loss: 4.455    Value Loss: 4.219    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 229960     Buffer Size: 16099      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:08:12,615][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.973    [weighted Loss:1.973    Policy Loss: 3.873    Value Loss: 3.849    Reward Loss: 0.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 231389     Buffer Size: 15940      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:11:01,477][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.210    [weighted Loss:1.210    Policy Loss: 3.572    Value Loss: 3.848    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 232784     Buffer Size: 16014      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:13:49,240][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.522    [weighted Loss:1.522    Policy Loss: 3.622    Value Loss: 3.990    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 234021     Buffer Size: 15937      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:16:37,462][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.278    [weighted Loss:1.278    Policy Loss: 3.699    Value Loss: 3.994    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 235358     Buffer Size: 15721      Transition Number: 1000.107k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:19:27,345][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 3.983    Value Loss: 4.449    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 236797     Buffer Size: 15525      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:22:15,785][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 3.993    Value Loss: 4.218    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 238409     Buffer Size: 15568      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:25:04,682][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 4.283    Value Loss: 4.672    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 239907     Buffer Size: 15737      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:27:57,314][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.058    [weighted Loss:2.058    Policy Loss: 3.509    Value Loss: 4.419    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 241383     Buffer Size: 15926      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:30:47,931][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 3.756    Value Loss: 4.304    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 242887     Buffer Size: 16125      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:33:33,156][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 3.323    Value Loss: 4.455    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 244216     Buffer Size: 16210      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:36:20,796][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 4.216    Value Loss: 4.325    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 245553     Buffer Size: 16295      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:39:06,873][train][INFO][train.py>_log] ==> #149000     Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 3.894    Value Loss: 4.195    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 247026     Buffer Size: 16564      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:41:54,943][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.407    [weighted Loss:2.407    Policy Loss: 4.190    Value Loss: 4.509    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 248673     Buffer Size: 16820      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:44:42,969][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 4.178    Value Loss: 4.358    Reward Loss: 0.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 250319     Buffer Size: 17205      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:47:31,081][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 3.752    Value Loss: 4.374    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 252033     Buffer Size: 17561      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:50:16,878][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 3.937    Value Loss: 4.653    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 253350     Buffer Size: 17622      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:53:05,888][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 3.956    Value Loss: 4.238    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 254739     Buffer Size: 17573      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:55:56,413][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 3.904    Value Loss: 4.198    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 256041     Buffer Size: 17322      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 15:58:45,625][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 4.175    Value Loss: 4.559    Reward Loss: 0.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 257430     Buffer Size: 17042      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:01:34,514][train][INFO][train.py>_log] ==> #157000     Total Loss: 1.319    [weighted Loss:1.319    Policy Loss: 3.714    Value Loss: 4.309    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 258662     Buffer Size: 16932      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:04:24,946][train][INFO][train.py>_log] ==> #158000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 3.925    Value Loss: 4.107    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 260127     Buffer Size: 16834      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:07:16,060][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 4.156    Value Loss: 4.569    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 261431     Buffer Size: 16839      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:10:07,142][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 4.093    Value Loss: 4.498    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 262893     Buffer Size: 16789      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:12:57,857][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 3.634    Value Loss: 4.428    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 264211     Buffer Size: 16578      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:15:45,561][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 3.830    Value Loss: 4.252    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 265549     Buffer Size: 16290      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:18:35,069][train][INFO][train.py>_log] ==> #163000     Total Loss: 1.206    [weighted Loss:1.206    Policy Loss: 4.151    Value Loss: 4.643    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 266908     Buffer Size: 15876      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:21:24,851][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 4.018    Value Loss: 4.265    Reward Loss: 0.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 268275     Buffer Size: 15569      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:24:14,834][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 4.252    Value Loss: 4.365    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 269548     Buffer Size: 15458      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:27:07,859][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.180    [weighted Loss:2.180    Policy Loss: 4.099    Value Loss: 4.535    Reward Loss: 0.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 270869     Buffer Size: 15407      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:30:00,459][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.519    [weighted Loss:1.519    Policy Loss: 4.870    Value Loss: 4.276    Reward Loss: 0.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 272344     Buffer Size: 15448      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:32:51,974][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 4.582    Value Loss: 4.145    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 273700     Buffer Size: 15508      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:35:40,828][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 4.433    Value Loss: 4.196    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 275109     Buffer Size: 15615      Transition Number: 999.939 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:38:31,781][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 4.322    Value Loss: 4.420    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 276598     Buffer Size: 15685      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:41:22,817][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 4.486    Value Loss: 4.326    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 277935     Buffer Size: 15618      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:44:14,544][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 4.546    Value Loss: 4.314    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 279178     Buffer Size: 15567      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:47:06,403][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 4.084    Value Loss: 4.504    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 280541     Buffer Size: 15515      Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:49:55,892][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 5.063    Value Loss: 4.456    Reward Loss: 0.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 281855     Buffer Size: 15512      Transition Number: 1000.189k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:52:46,768][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 4.441    Value Loss: 4.196    Reward Loss: 0.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 283479     Buffer Size: 15798      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:55:35,812][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 4.802    Value Loss: 4.742    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 285082     Buffer Size: 16109      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 16:58:26,352][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.606    [weighted Loss:1.606    Policy Loss: 4.909    Value Loss: 4.801    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 286328     Buffer Size: 16180      Transition Number: 1000.039k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:01:16,971][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 4.566    Value Loss: 4.529    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 287742     Buffer Size: 16235      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:04:08,439][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.683    [weighted Loss:1.683    Policy Loss: 4.393    Value Loss: 4.395    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 289168     Buffer Size: 16239      Transition Number: 999.939 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:06:58,582][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 4.585    Value Loss: 4.727    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 290460     Buffer Size: 16194      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:09:50,083][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 4.797    Value Loss: 4.614    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 291867     Buffer Size: 16183      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:12:41,724][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.641    [weighted Loss:2.641    Policy Loss: 4.639    Value Loss: 4.663    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 293384     Buffer Size: 16223      Transition Number: 1000.012k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:15:32,990][train][INFO][train.py>_log] ==> #183000     Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 5.003    Value Loss: 4.390    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 294759     Buffer Size: 16283      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:18:28,683][train][INFO][train.py>_log] ==> #184000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 4.429    Value Loss: 4.489    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 296179     Buffer Size: 16340      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:21:23,161][train][INFO][train.py>_log] ==> #185000     Total Loss: 1.370    [weighted Loss:1.370    Policy Loss: 4.177    Value Loss: 4.232    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 297616     Buffer Size: 16284      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:24:16,605][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 4.624    Value Loss: 4.679    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 298893     Buffer Size: 16075      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:27:10,627][train][INFO][train.py>_log] ==> #187000     Total Loss: 1.740    [weighted Loss:1.740    Policy Loss: 4.000    Value Loss: 4.509    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 300353     Buffer Size: 15632      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:30:01,969][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.339    [weighted Loss:2.339    Policy Loss: 4.171    Value Loss: 4.768    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 301673     Buffer Size: 15445      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:32:53,912][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.490    [weighted Loss:2.490    Policy Loss: 4.979    Value Loss: 4.399    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 302951     Buffer Size: 15316      Transition Number: 1000.199k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:35:48,837][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 3.924    Value Loss: 4.150    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 304366     Buffer Size: 15177      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:38:42,034][train][INFO][train.py>_log] ==> #191000     Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 4.317    Value Loss: 4.229    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 305730     Buffer Size: 15074      Transition Number: 1000.827k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:41:33,108][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 5.016    Value Loss: 4.021    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 307046     Buffer Size: 14859      Transition Number: 1000.648k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:44:24,918][train][INFO][train.py>_log] ==> #193000     Total Loss: 1.773    [weighted Loss:1.773    Policy Loss: 4.819    Value Loss: 4.631    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 308529     Buffer Size: 14843      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:47:16,909][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 4.569    Value Loss: 4.398    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 309974     Buffer Size: 14927      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:50:09,330][train][INFO][train.py>_log] ==> #195000     Total Loss: 1.066    [weighted Loss:1.066    Policy Loss: 4.474    Value Loss: 4.476    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 311324     Buffer Size: 14926      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:53:01,237][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.438    [weighted Loss:1.438    Policy Loss: 4.373    Value Loss: 4.115    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 312710     Buffer Size: 15001      Transition Number: 1000.252k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:55:55,072][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 4.409    Value Loss: 4.599    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 314110     Buffer Size: 15093      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 17:58:45,858][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 4.064    Value Loss: 4.555    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 315458     Buffer Size: 15216      Transition Number: 1000.168k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:01:36,892][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 4.511    Value Loss: 4.256    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 316839     Buffer Size: 15343      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:04:29,080][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 4.359    Value Loss: 4.454    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 318251     Buffer Size: 15455      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:07:22,888][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 5.120    Value Loss: 4.417    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 319624     Buffer Size: 15562      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:10:17,593][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.900    [weighted Loss:2.900    Policy Loss: 5.375    Value Loss: 4.287    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 321039     Buffer Size: 15676      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:13:07,388][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 5.149    Value Loss: 4.683    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 323243     Buffer Size: 16611      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:15:54,308][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 4.336    Value Loss: 4.638    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 325392     Buffer Size: 17437      Transition Number: 1000.170k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:18:40,978][train][INFO][train.py>_log] ==> #205000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 3.906    Value Loss: 5.040    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 327468     Buffer Size: 18174      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:21:30,085][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 4.080    Value Loss: 5.247    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 329709     Buffer Size: 18973      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:24:18,371][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 4.303    Value Loss: 5.226    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 331003     Buffer Size: 19010      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:27:09,198][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 3.840    Value Loss: 5.035    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 332320     Buffer Size: 19029      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:29:54,054][train][INFO][train.py>_log] ==> #209000     Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 4.276    Value Loss: 5.098    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 333630     Buffer Size: 19068      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:32:42,817][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.265    [weighted Loss:1.265    Policy Loss: 3.760    Value Loss: 4.896    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 334962     Buffer Size: 19098      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:35:32,906][train][INFO][train.py>_log] ==> #211000     Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 4.137    Value Loss: 4.724    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 336233     Buffer Size: 19040      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:38:24,902][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 3.571    Value Loss: 4.977    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 337616     Buffer Size: 18990      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:41:14,267][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 4.141    Value Loss: 4.906    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 338957     Buffer Size: 19016      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:44:06,849][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 3.595    Value Loss: 4.565    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 340349     Buffer Size: 18883      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:47:02,106][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 3.701    Value Loss: 4.536    Reward Loss: 0.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 341737     Buffer Size: 18006      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:49:53,151][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 3.736    Value Loss: 4.385    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 343060     Buffer Size: 17152      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:52:46,781][train][INFO][train.py>_log] ==> #217000     Total Loss: 1.032    [weighted Loss:1.032    Policy Loss: 3.721    Value Loss: 4.580    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 344391     Buffer Size: 16140      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:55:38,669][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 3.528    Value Loss: 4.140    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 345762     Buffer Size: 15513      Transition Number: 1001.588k Batch Size: 256        Lr: 0.10000 
[2022-01-18 18:58:30,096][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.519    [weighted Loss:1.519    Policy Loss: 4.096    Value Loss: 4.027    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 347102     Buffer Size: 15394      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:01:23,093][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.031    [weighted Loss:1.031    Policy Loss: 3.883    Value Loss: 3.956    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 348449     Buffer Size: 15269      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:04:17,327][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 4.424    Value Loss: 4.236    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 349912     Buffer Size: 15194      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:07:12,507][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 4.391    Value Loss: 4.187    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 351224     Buffer Size: 15213      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:10:08,748][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 4.680    Value Loss: 4.407    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 353523     Buffer Size: 16028      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:12:56,999][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.001    [weighted Loss:1.001    Policy Loss: 4.086    Value Loss: 4.663    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 355615     Buffer Size: 16770      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:15:46,543][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.430    [weighted Loss:1.430    Policy Loss: 4.010    Value Loss: 4.585    Reward Loss: 0.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 356882     Buffer Size: 16742      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:18:38,813][train][INFO][train.py>_log] ==> #226000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 4.034    Value Loss: 4.367    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 358315     Buffer Size: 16716      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:21:29,037][train][INFO][train.py>_log] ==> #227000     Total Loss: 1.291    [weighted Loss:1.291    Policy Loss: 3.962    Value Loss: 4.464    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 359746     Buffer Size: 16812      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:24:23,123][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.217    [weighted Loss:1.217    Policy Loss: 3.895    Value Loss: 4.377    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 361168     Buffer Size: 16945      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:27:13,314][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.051    [weighted Loss:2.051    Policy Loss: 3.713    Value Loss: 4.590    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 362545     Buffer Size: 17035      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:30:06,648][train][INFO][train.py>_log] ==> #230000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 3.824    Value Loss: 4.513    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 363930     Buffer Size: 17128      Transition Number: 1000.180k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:32:57,197][train][INFO][train.py>_log] ==> #231000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 4.770    Value Loss: 4.565    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 365260     Buffer Size: 17185      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:35:47,401][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 4.095    Value Loss: 4.780    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 366668     Buffer Size: 17203      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:38:38,513][train][INFO][train.py>_log] ==> #233000     Total Loss: 1.597    [weighted Loss:1.597    Policy Loss: 4.218    Value Loss: 4.589    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 368009     Buffer Size: 17166      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:41:29,717][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 4.076    Value Loss: 4.365    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 369354     Buffer Size: 16611      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:44:25,780][train][INFO][train.py>_log] ==> #235000     Total Loss: 1.703    [weighted Loss:1.703    Policy Loss: 4.123    Value Loss: 4.485    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 370828     Buffer Size: 15743      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:47:16,836][train][INFO][train.py>_log] ==> #236000     Total Loss: 1.535    [weighted Loss:1.535    Policy Loss: 4.043    Value Loss: 4.343    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 372140     Buffer Size: 15556      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:50:07,393][train][INFO][train.py>_log] ==> #237000     Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 4.421    Value Loss: 4.551    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 373438     Buffer Size: 15553      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:52:58,620][train][INFO][train.py>_log] ==> #238000     Total Loss: 1.967    [weighted Loss:1.967    Policy Loss: 4.275    Value Loss: 4.108    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 374867     Buffer Size: 15489      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:55:50,691][train][INFO][train.py>_log] ==> #239000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 5.215    Value Loss: 4.639    Reward Loss: 0.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 376237     Buffer Size: 15499      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 19:58:41,499][train][INFO][train.py>_log] ==> #240000     Total Loss: 0.838    [weighted Loss:0.838    Policy Loss: 3.734    Value Loss: 4.303    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 377704     Buffer Size: 15545      Transition Number: 1000.200k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:01:32,517][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 4.129    Value Loss: 4.425    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 379114     Buffer Size: 15573      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:04:28,031][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 4.319    Value Loss: 4.555    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 380487     Buffer Size: 15640      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:07:20,874][train][INFO][train.py>_log] ==> #243000     Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 4.720    Value Loss: 4.647    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 381915     Buffer Size: 15714      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:10:13,255][train][INFO][train.py>_log] ==> #244000     Total Loss: 1.607    [weighted Loss:1.607    Policy Loss: 4.524    Value Loss: 4.648    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 383333     Buffer Size: 15781      Transition Number: 1000.107k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:13:04,076][train][INFO][train.py>_log] ==> #245000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 3.715    Value Loss: 4.625    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 384752     Buffer Size: 15850      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:15:56,772][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 5.098    Value Loss: 4.563    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 386150     Buffer Size: 15897      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:18:50,725][train][INFO][train.py>_log] ==> #247000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 4.198    Value Loss: 4.693    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 387482     Buffer Size: 15909      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:21:39,208][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.291    [weighted Loss:1.291    Policy Loss: 3.964    Value Loss: 4.560    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 388954     Buffer Size: 15928      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:24:30,645][train][INFO][train.py>_log] ==> #249000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 4.198    Value Loss: 4.576    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 390232     Buffer Size: 15928      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:27:23,550][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.317    [weighted Loss:1.317    Policy Loss: 4.715    Value Loss: 4.413    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 391623     Buffer Size: 15874      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:30:18,215][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 5.493    Value Loss: 4.771    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 393341     Buffer Size: 16006      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:33:09,877][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 5.371    Value Loss: 4.775    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 394892     Buffer Size: 16187      Transition Number: 1000.507k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:36:00,598][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 4.687    Value Loss: 4.427    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 396316     Buffer Size: 16159      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:38:52,051][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 4.859    Value Loss: 4.572    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 397725     Buffer Size: 16171      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:41:46,393][train][INFO][train.py>_log] ==> #255000     Total Loss: 1.202    [weighted Loss:1.202    Policy Loss: 4.550    Value Loss: 4.490    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 399538     Buffer Size: 16596      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:44:35,507][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 5.864    Value Loss: 4.838    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 401384     Buffer Size: 17022      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:47:26,782][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.130    [weighted Loss:2.130    Policy Loss: 5.266    Value Loss: 5.365    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 402949     Buffer Size: 17240      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:50:15,969][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.418    [weighted Loss:1.418    Policy Loss: 5.381    Value Loss: 5.090    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 404489     Buffer Size: 17496      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:53:04,323][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 4.503    Value Loss: 4.958    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 405864     Buffer Size: 17541      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:55:55,480][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 4.126    Value Loss: 5.066    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 407264     Buffer Size: 17567      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 20:58:45,850][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 3.787    Value Loss: 4.686    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 408601     Buffer Size: 17643      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:01:36,686][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 4.531    Value Loss: 4.624    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 410056     Buffer Size: 17626      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:04:28,401][train][INFO][train.py>_log] ==> #263000     Total Loss: 1.480    [weighted Loss:1.480    Policy Loss: 4.194    Value Loss: 4.659    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 411436     Buffer Size: 17478      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:07:19,798][train][INFO][train.py>_log] ==> #264000     Total Loss: 0.905    [weighted Loss:0.905    Policy Loss: 4.251    Value Loss: 4.915    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 412856     Buffer Size: 17370      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:10:11,067][train][INFO][train.py>_log] ==> #265000     Total Loss: 1.967    [weighted Loss:1.967    Policy Loss: 3.598    Value Loss: 4.741    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 414203     Buffer Size: 17309      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:13:02,602][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.461    [weighted Loss:1.461    Policy Loss: 4.247    Value Loss: 4.478    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 415571     Buffer Size: 17088      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:15:57,314][train][INFO][train.py>_log] ==> #267000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 3.883    Value Loss: 4.373    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 416958     Buffer Size: 16605      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:18:51,963][train][INFO][train.py>_log] ==> #268000     Total Loss: 1.224    [weighted Loss:1.224    Policy Loss: 4.454    Value Loss: 4.374    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 418433     Buffer Size: 16245      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:21:43,267][train][INFO][train.py>_log] ==> #269000     Total Loss: 1.366    [weighted Loss:1.366    Policy Loss: 4.510    Value Loss: 4.430    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 419740     Buffer Size: 16011      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:24:37,238][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 5.277    Value Loss: 4.446    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 421207     Buffer Size: 15827      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:27:28,031][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 4.604    Value Loss: 4.191    Reward Loss: 0.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 422563     Buffer Size: 15740      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:30:20,465][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 4.754    Value Loss: 4.474    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 423982     Buffer Size: 15626      Transition Number: 1000.558k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:33:18,031][train][INFO][train.py>_log] ==> #273000     Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 4.922    Value Loss: 4.257    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 425237     Buffer Size: 15531      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:36:14,131][train][INFO][train.py>_log] ==> #274000     Total Loss: 0.857    [weighted Loss:0.857    Policy Loss: 4.142    Value Loss: 4.286    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 426666     Buffer Size: 15414      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:39:08,278][train][INFO][train.py>_log] ==> #275000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 4.608    Value Loss: 4.432    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 428063     Buffer Size: 15290      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:42:04,056][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.856    [weighted Loss:1.856    Policy Loss: 4.416    Value Loss: 4.308    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 429515     Buffer Size: 15257      Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:44:58,391][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 4.334    Value Loss: 4.484    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 430945     Buffer Size: 15238      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:47:51,741][train][INFO][train.py>_log] ==> #278000     Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 4.792    Value Loss: 4.339    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 432399     Buffer Size: 15215      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:50:48,514][train][INFO][train.py>_log] ==> #279000     Total Loss: 1.803    [weighted Loss:1.803    Policy Loss: 4.458    Value Loss: 4.509    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 433775     Buffer Size: 15169      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:53:45,472][train][INFO][train.py>_log] ==> #280000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 4.817    Value Loss: 4.325    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 435229     Buffer Size: 15109      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:56:43,857][train][INFO][train.py>_log] ==> #281000     Total Loss: 1.447    [weighted Loss:1.447    Policy Loss: 4.704    Value Loss: 4.114    Reward Loss: 0.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 436607     Buffer Size: 15084      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 21:59:37,288][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 4.577    Value Loss: 4.419    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 438009     Buffer Size: 15095      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:02:27,715][train][INFO][train.py>_log] ==> #283000     Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 5.384    Value Loss: 4.680    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 439730     Buffer Size: 15505      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:05:17,718][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 6.283    Value Loss: 4.987    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 441426     Buffer Size: 15896      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:08:06,430][train][INFO][train.py>_log] ==> #285000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 4.492    Value Loss: 4.847    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 443000     Buffer Size: 16259      Transition Number: 1000.079k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:10:57,064][train][INFO][train.py>_log] ==> #286000     Total Loss: 1.040    [weighted Loss:1.040    Policy Loss: 4.309    Value Loss: 4.973    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 444636     Buffer Size: 16555      Transition Number: 1000.013k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:13:47,723][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.010    [weighted Loss:2.010    Policy Loss: 4.301    Value Loss: 4.888    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 446083     Buffer Size: 16728      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:16:39,071][train][INFO][train.py>_log] ==> #288000     Total Loss: 0.814    [weighted Loss:0.814    Policy Loss: 4.612    Value Loss: 4.637    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 447521     Buffer Size: 16876      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:19:31,105][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.407    [weighted Loss:1.407    Policy Loss: 4.160    Value Loss: 4.616    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 448834     Buffer Size: 16834      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:22:26,852][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.039    Value Loss: 4.885    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 450274     Buffer Size: 16795      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:25:23,403][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 4.250    Value Loss: 4.572    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 451721     Buffer Size: 16774      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:28:20,017][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 4.889    Value Loss: 4.680    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 453093     Buffer Size: 16770      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:31:13,882][train][INFO][train.py>_log] ==> #293000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 4.201    Value Loss: 4.552    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 454332     Buffer Size: 16783      Transition Number: 1000.368k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:34:04,667][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.601    [weighted Loss:1.601    Policy Loss: 4.097    Value Loss: 4.297    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 455721     Buffer Size: 16502      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:36:57,194][train][INFO][train.py>_log] ==> #295000     Total Loss: 1.224    [weighted Loss:1.224    Policy Loss: 3.731    Value Loss: 4.370    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 457183     Buffer Size: 16178      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:39:53,552][train][INFO][train.py>_log] ==> #296000     Total Loss: 1.015    [weighted Loss:1.015    Policy Loss: 4.272    Value Loss: 4.969    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 458738     Buffer Size: 15902      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:42:51,037][train][INFO][train.py>_log] ==> #297000     Total Loss: 1.612    [weighted Loss:1.612    Policy Loss: 3.885    Value Loss: 4.291    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 460091     Buffer Size: 15536      Transition Number: 1000.420k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:45:49,014][train][INFO][train.py>_log] ==> #298000     Total Loss: 0.881    [weighted Loss:0.881    Policy Loss: 4.137    Value Loss: 4.238    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 461471     Buffer Size: 15318      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:48:44,809][train][INFO][train.py>_log] ==> #299000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 4.487    Value Loss: 4.173    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 462909     Buffer Size: 15197      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:51:39,274][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 4.564    Value Loss: 4.213    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 464331     Buffer Size: 15256      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:54:30,292][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 5.340    Value Loss: 4.494    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 465636     Buffer Size: 15325      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 22:57:23,953][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 5.157    Value Loss: 4.372    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 467033     Buffer Size: 15428      Transition Number: 1000.596k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:00:15,826][train][INFO][train.py>_log] ==> #303000     Total Loss: 1.377    [weighted Loss:1.377    Policy Loss: 4.597    Value Loss: 4.601    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 468518     Buffer Size: 15554      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:03:10,705][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 5.386    Value Loss: 4.743    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 470011     Buffer Size: 15683      Transition Number: 1000.222k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:06:03,350][train][INFO][train.py>_log] ==> #305000     Total Loss: 1.039    [weighted Loss:1.039    Policy Loss: 4.474    Value Loss: 4.496    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 471460     Buffer Size: 15830      Transition Number: 1000.146k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:08:57,954][train][INFO][train.py>_log] ==> #306000     Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 4.538    Value Loss: 4.659    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 472832     Buffer Size: 15864      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:11:51,485][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 5.231    Value Loss: 4.507    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 474287     Buffer Size: 15725      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:14:48,405][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 4.731    Value Loss: 4.468    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 475700     Buffer Size: 15732      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:17:41,771][train][INFO][train.py>_log] ==> #309000     Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 4.770    Value Loss: 4.204    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 477150     Buffer Size: 15800      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:20:35,603][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.642    Value Loss: 4.404    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 478541     Buffer Size: 15820      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:23:26,464][train][INFO][train.py>_log] ==> #311000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 4.327    Value Loss: 4.675    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 479852     Buffer Size: 15788      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:26:17,868][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 4.367    Value Loss: 4.400    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 481217     Buffer Size: 15749      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:29:11,092][train][INFO][train.py>_log] ==> #313000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 4.756    Value Loss: 4.835    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 482566     Buffer Size: 15667      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:32:04,723][train][INFO][train.py>_log] ==> #314000     Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 4.482    Value Loss: 4.326    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 484020     Buffer Size: 15517      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:34:56,511][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.575    [weighted Loss:1.575    Policy Loss: 4.993    Value Loss: 4.011    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 485367     Buffer Size: 15393      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:37:51,616][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.058    [weighted Loss:1.058    Policy Loss: 5.040    Value Loss: 4.270    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 486729     Buffer Size: 15246      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:40:43,167][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 5.230    Value Loss: 4.371    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 488186     Buffer Size: 15211      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:43:36,394][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 4.847    Value Loss: 4.262    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 489545     Buffer Size: 15350      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:46:28,394][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.571    [weighted Loss:2.571    Policy Loss: 5.060    Value Loss: 4.268    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 490965     Buffer Size: 15424      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:49:23,212][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.337    [weighted Loss:1.337    Policy Loss: 5.075    Value Loss: 4.532    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 492430     Buffer Size: 15452      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:52:18,609][train][INFO][train.py>_log] ==> #321000     Total Loss: 1.837    [weighted Loss:1.837    Policy Loss: 4.922    Value Loss: 4.511    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 493840     Buffer Size: 15527      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:55:11,238][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 4.578    Value Loss: 4.512    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 495273     Buffer Size: 15625      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-18 23:58:05,512][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 5.048    Value Loss: 4.819    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 496661     Buffer Size: 15713      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:00:57,356][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.614    [weighted Loss:1.614    Policy Loss: 3.763    Value Loss: 4.714    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 498128     Buffer Size: 15817      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:03:48,564][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 4.939    Value Loss: 4.785    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 499713     Buffer Size: 16107      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:06:44,136][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 4.774    Value Loss: 5.009    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 501259     Buffer Size: 16365      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:09:38,341][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.359    [weighted Loss:2.359    Policy Loss: 5.270    Value Loss: 4.884    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 502671     Buffer Size: 16417      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:12:29,000][train][INFO][train.py>_log] ==> #328000     Total Loss: 1.698    [weighted Loss:1.698    Policy Loss: 4.220    Value Loss: 4.829    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 504005     Buffer Size: 16420      Transition Number: 1000.115k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:15:21,284][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 4.509    Value Loss: 4.522    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 505408     Buffer Size: 16310      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:18:15,296][train][INFO][train.py>_log] ==> #330000     Total Loss: 1.807    [weighted Loss:1.807    Policy Loss: 3.953    Value Loss: 4.317    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 506784     Buffer Size: 16226      Transition Number: 1000.036k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:21:09,079][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 5.308    Value Loss: 4.570    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 508090     Buffer Size: 16147      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:24:03,564][train][INFO][train.py>_log] ==> #332000     Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 4.883    Value Loss: 4.277    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 509564     Buffer Size: 16053      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:26:58,120][train][INFO][train.py>_log] ==> #333000     Total Loss: 2.137    [weighted Loss:2.137    Policy Loss: 4.788    Value Loss: 4.426    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 511017     Buffer Size: 16051      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:29:49,747][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 4.980    Value Loss: 4.773    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 512489     Buffer Size: 16092      Transition Number: 999.941 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:32:42,597][train][INFO][train.py>_log] ==> #335000     Total Loss: 1.671    [weighted Loss:1.671    Policy Loss: 4.944    Value Loss: 4.439    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 513991     Buffer Size: 16178      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:35:38,905][train][INFO][train.py>_log] ==> #336000     Total Loss: 1.728    [weighted Loss:1.728    Policy Loss: 5.633    Value Loss: 4.535    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 515440     Buffer Size: 16134      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:38:33,711][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.601    [weighted Loss:2.601    Policy Loss: 5.469    Value Loss: 4.727    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 516825     Buffer Size: 15901      Transition Number: 1000.056k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:41:28,246][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 4.940    Value Loss: 4.583    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 518126     Buffer Size: 15847      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:44:21,679][train][INFO][train.py>_log] ==> #339000     Total Loss: 1.667    [weighted Loss:1.667    Policy Loss: 5.593    Value Loss: 4.640    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 519513     Buffer Size: 15813      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:47:18,152][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 5.053    Value Loss: 4.326    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 520930     Buffer Size: 15804      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:50:13,759][train][INFO][train.py>_log] ==> #341000     Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 4.733    Value Loss: 4.643    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 522357     Buffer Size: 15901      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:53:11,420][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 6.010    Value Loss: 4.483    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 523870     Buffer Size: 16031      Transition Number: 1000.184k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:56:07,624][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 5.542    Value Loss: 5.017    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 525242     Buffer Size: 16063      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 00:58:59,206][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 4.989    Value Loss: 5.171    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 526672     Buffer Size: 16033      Transition Number: 1000.857k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:01:57,546][train][INFO][train.py>_log] ==> #345000     Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 4.566    Value Loss: 4.395    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 528047     Buffer Size: 15906      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:04:50,447][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 5.126    Value Loss: 4.489    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 529461     Buffer Size: 15743      Transition Number: 1000.684k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:07:47,437][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.248    [weighted Loss:2.248    Policy Loss: 5.117    Value Loss: 4.793    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 530924     Buffer Size: 15712      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:10:44,275][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 5.266    Value Loss: 4.612    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 532437     Buffer Size: 15812      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:13:34,807][train][INFO][train.py>_log] ==> #349000     Total Loss: 1.144    [weighted Loss:1.144    Policy Loss: 5.034    Value Loss: 4.902    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 533878     Buffer Size: 15973      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:16:25,994][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 6.389    Value Loss: 4.750    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 535428     Buffer Size: 16142      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:19:18,739][train][INFO][train.py>_log] ==> #351000     Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 5.586    Value Loss: 5.002    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 536885     Buffer Size: 16316      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:22:12,930][train][INFO][train.py>_log] ==> #352000     Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 5.165    Value Loss: 5.013    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 538436     Buffer Size: 16427      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:25:04,532][train][INFO][train.py>_log] ==> #353000     Total Loss: 1.673    [weighted Loss:1.673    Policy Loss: 4.799    Value Loss: 4.789    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 539838     Buffer Size: 16410      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:27:55,525][train][INFO][train.py>_log] ==> #354000     Total Loss: 1.937    [weighted Loss:1.937    Policy Loss: 4.886    Value Loss: 4.772    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 541205     Buffer Size: 16429      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:30:46,528][train][INFO][train.py>_log] ==> #355000     Total Loss: 1.549    [weighted Loss:1.549    Policy Loss: 4.806    Value Loss: 4.869    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 542584     Buffer Size: 16454      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:33:43,753][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.677    [weighted Loss:1.677    Policy Loss: 4.271    Value Loss: 4.799    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 544076     Buffer Size: 16472      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:36:39,846][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 5.165    Value Loss: 4.903    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 545546     Buffer Size: 16585      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:39:33,653][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.122    [weighted Loss:2.122    Policy Loss: 5.205    Value Loss: 4.784    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 546971     Buffer Size: 16604      Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:42:28,972][train][INFO][train.py>_log] ==> #359000     Total Loss: 1.785    [weighted Loss:1.785    Policy Loss: 5.517    Value Loss: 5.418    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 548660     Buffer Size: 16836      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:45:21,127][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 5.946    Value Loss: 4.817    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 550371     Buffer Size: 17040      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:48:13,306][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 4.988    Value Loss: 4.995    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 552174     Buffer Size: 17376      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:51:04,603][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 5.221    Value Loss: 5.301    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 554098     Buffer Size: 17792      Transition Number: 1000.543k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:53:55,062][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 4.466    Value Loss: 4.897    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 555602     Buffer Size: 17792      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:56:49,938][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 4.790    Value Loss: 5.252    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 557157     Buffer Size: 17856      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 01:59:43,699][train][INFO][train.py>_log] ==> #365000     Total Loss: 1.339    [weighted Loss:1.339    Policy Loss: 4.526    Value Loss: 5.052    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 558412     Buffer Size: 17813      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:02:35,521][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.332    [weighted Loss:1.332    Policy Loss: 4.535    Value Loss: 4.491    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 559887     Buffer Size: 17794      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:05:31,199][train][INFO][train.py>_log] ==> #367000     Total Loss: 1.519    [weighted Loss:1.519    Policy Loss: 4.612    Value Loss: 4.758    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 561254     Buffer Size: 17762      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:08:29,157][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 4.963    Value Loss: 4.860    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 562744     Buffer Size: 17669      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:11:23,343][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 4.941    Value Loss: 4.549    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 564053     Buffer Size: 17626      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:14:15,877][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 5.012    Value Loss: 4.705    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 565470     Buffer Size: 17416      Transition Number: 1000.183k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:17:12,521][train][INFO][train.py>_log] ==> #371000     Total Loss: 1.166    [weighted Loss:1.166    Policy Loss: 4.297    Value Loss: 4.703    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 566903     Buffer Size: 16981      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:20:06,327][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.384    [weighted Loss:1.384    Policy Loss: 5.468    Value Loss: 4.353    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 568172     Buffer Size: 16507      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:23:00,482][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 5.878    Value Loss: 4.310    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 569537     Buffer Size: 16015      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:25:59,754][train][INFO][train.py>_log] ==> #374000     Total Loss: 0.983    [weighted Loss:0.983    Policy Loss: 4.850    Value Loss: 4.600    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 570988     Buffer Size: 15722      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:28:55,704][train][INFO][train.py>_log] ==> #375000     Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 5.662    Value Loss: 4.496    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 572438     Buffer Size: 15578      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:31:48,507][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.506    [weighted Loss:1.506    Policy Loss: 6.227    Value Loss: 4.250    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 573925     Buffer Size: 15600      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:34:42,119][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.380    [weighted Loss:2.380    Policy Loss: 7.183    Value Loss: 4.653    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 575397     Buffer Size: 15817      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:37:36,097][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 7.056    Value Loss: 4.468    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 577027     Buffer Size: 16084      Transition Number: 1000.101k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:40:27,257][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 6.827    Value Loss: 4.699    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 578561     Buffer Size: 16301      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:43:19,978][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.548    [weighted Loss:2.548    Policy Loss: 6.261    Value Loss: 4.589    Reward Loss: 0.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 580168     Buffer Size: 16528      Transition Number: 1000.437k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:46:13,716][train][INFO][train.py>_log] ==> #381000     Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 6.378    Value Loss: 5.002    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 581665     Buffer Size: 16675      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:49:06,240][train][INFO][train.py>_log] ==> #382000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 4.922    Value Loss: 4.987    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 583158     Buffer Size: 16855      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:51:56,362][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 5.670    Value Loss: 5.029    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 584601     Buffer Size: 16963      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:54:47,920][train][INFO][train.py>_log] ==> #384000     Total Loss: 1.544    [weighted Loss:1.544    Policy Loss: 5.575    Value Loss: 5.025    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 586021     Buffer Size: 17019      Transition Number: 1000.023k Batch Size: 256        Lr: 0.10000 
[2022-01-19 02:57:44,399][train][INFO][train.py>_log] ==> #385000     Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 7.234    Value Loss: 4.748    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 587436     Buffer Size: 17130      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:00:36,664][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 5.387    Value Loss: 4.966    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 588937     Buffer Size: 17223      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:03:28,220][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 6.860    Value Loss: 4.722    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 590488     Buffer Size: 17373      Transition Number: 1000.154k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:06:21,558][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 5.690    Value Loss: 5.276    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 591999     Buffer Size: 17468      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:09:15,223][train][INFO][train.py>_log] ==> #389000     Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 5.033    Value Loss: 4.563    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 593413     Buffer Size: 17262      Transition Number: 1000.033k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:12:09,801][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 5.483    Value Loss: 4.828    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 594865     Buffer Size: 17083      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:15:04,026][train][INFO][train.py>_log] ==> #391000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 5.489    Value Loss: 4.779    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 596299     Buffer Size: 16976      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:17:59,692][train][INFO][train.py>_log] ==> #392000     Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 5.202    Value Loss: 4.592    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 597886     Buffer Size: 16885      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:20:54,337][train][INFO][train.py>_log] ==> #393000     Total Loss: 1.895    [weighted Loss:1.895    Policy Loss: 6.213    Value Loss: 4.951    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 599153     Buffer Size: 16762      Transition Number: 1000.005k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:23:47,685][train][INFO][train.py>_log] ==> #394000     Total Loss: 1.651    [weighted Loss:1.651    Policy Loss: 5.581    Value Loss: 4.773    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 600568     Buffer Size: 16646      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:26:39,620][train][INFO][train.py>_log] ==> #395000     Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 6.200    Value Loss: 4.883    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 602134     Buffer Size: 16788      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:29:36,598][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 5.722    Value Loss: 4.595    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 603692     Buffer Size: 16864      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:32:31,687][train][INFO][train.py>_log] ==> #397000     Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 6.716    Value Loss: 4.887    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 605348     Buffer Size: 17015      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:35:22,765][train][INFO][train.py>_log] ==> #398000     Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 6.004    Value Loss: 5.081    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 606906     Buffer Size: 17118      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:38:15,516][train][INFO][train.py>_log] ==> #399000     Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 6.200    Value Loss: 5.214    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 608422     Buffer Size: 17037      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:41:09,257][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.032    Value Loss: 5.116    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 609945     Buffer Size: 17066      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:44:02,148][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.384    [weighted Loss:2.384    Policy Loss: 5.512    Value Loss: 4.601    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 611269     Buffer Size: 17138      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:46:57,137][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.939    [weighted Loss:2.939    Policy Loss: 6.807    Value Loss: 4.944    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 612835     Buffer Size: 17154      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:49:51,767][train][INFO][train.py>_log] ==> #403000     Total Loss: 1.373    [weighted Loss:1.373    Policy Loss: 5.116    Value Loss: 5.179    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 615261     Buffer Size: 17992      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:52:42,918][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 6.869    Value Loss: 5.248    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 617497     Buffer Size: 18837      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:55:32,275][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 6.124    Value Loss: 5.061    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 619017     Buffer Size: 18996      Transition Number: 999.941 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 03:58:22,726][train][INFO][train.py>_log] ==> #406000     Total Loss: 1.436    [weighted Loss:1.436    Policy Loss: 6.159    Value Loss: 5.338    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 620499     Buffer Size: 19052      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:01:14,452][train][INFO][train.py>_log] ==> #407000     Total Loss: 1.398    [weighted Loss:1.398    Policy Loss: 6.221    Value Loss: 5.284    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 622003     Buffer Size: 18999      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:04:08,664][train][INFO][train.py>_log] ==> #408000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 7.173    Value Loss: 5.017    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 623523     Buffer Size: 18912      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:07:03,205][train][INFO][train.py>_log] ==> #409000     Total Loss: 1.562    [weighted Loss:1.562    Policy Loss: 6.683    Value Loss: 5.162    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 625265     Buffer Size: 18993      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:09:55,962][train][INFO][train.py>_log] ==> #410000     Total Loss: 1.881    [weighted Loss:1.881    Policy Loss: 7.365    Value Loss: 5.223    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 627006     Buffer Size: 19218      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:12:48,389][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 6.716    Value Loss: 5.324    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 628539     Buffer Size: 19262      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:15:42,349][train][INFO][train.py>_log] ==> #412000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 7.369    Value Loss: 5.147    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 630109     Buffer Size: 19293      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:18:35,555][train][INFO][train.py>_log] ==> #413000     Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 7.107    Value Loss: 5.141    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 631577     Buffer Size: 19328      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:21:27,949][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.704    [weighted Loss:2.704    Policy Loss: 6.268    Value Loss: 4.714    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 633051     Buffer Size: 18930      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:24:19,615][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 6.193    Value Loss: 4.892    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 634472     Buffer Size: 18046      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:27:12,694][train][INFO][train.py>_log] ==> #416000     Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 6.235    Value Loss: 5.173    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 635927     Buffer Size: 17581      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:30:07,309][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 5.632    Value Loss: 5.225    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 637395     Buffer Size: 17575      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:33:02,221][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 5.774    Value Loss: 5.043    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 638915     Buffer Size: 17571      Transition Number: 1000.484k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:35:58,518][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 6.667    Value Loss: 4.834    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 640729     Buffer Size: 17814      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:38:51,835][train][INFO][train.py>_log] ==> #420000     Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 7.835    Value Loss: 5.477    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 642424     Buffer Size: 17906      Transition Number: 1000.320k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:41:45,713][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 6.572    Value Loss: 5.037    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 644163     Buffer Size: 17910      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:44:39,738][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 7.081    Value Loss: 5.571    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 645996     Buffer Size: 18079      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:47:31,064][train][INFO][train.py>_log] ==> #423000     Total Loss: 3.002    [weighted Loss:3.002    Policy Loss: 6.874    Value Loss: 5.123    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 647712     Buffer Size: 18250      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:50:22,873][train][INFO][train.py>_log] ==> #424000     Total Loss: 3.036    [weighted Loss:3.036    Policy Loss: 7.121    Value Loss: 5.720    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 649362     Buffer Size: 18420      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:53:14,146][train][INFO][train.py>_log] ==> #425000     Total Loss: 3.510    [weighted Loss:3.510    Policy Loss: 6.757    Value Loss: 5.035    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 651004     Buffer Size: 18670      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:56:07,055][train][INFO][train.py>_log] ==> #426000     Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 7.608    Value Loss: 5.715    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 652756     Buffer Size: 18864      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 04:58:58,770][train][INFO][train.py>_log] ==> #427000     Total Loss: 1.856    [weighted Loss:1.856    Policy Loss: 7.700    Value Loss: 5.280    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 654393     Buffer Size: 19110      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:01:50,046][train][INFO][train.py>_log] ==> #428000     Total Loss: 3.259    [weighted Loss:3.259    Policy Loss: 8.978    Value Loss: 5.768    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 656099     Buffer Size: 19351      Transition Number: 1000.160k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:04:41,240][train][INFO][train.py>_log] ==> #429000     Total Loss: 2.333    [weighted Loss:2.333    Policy Loss: 6.393    Value Loss: 5.375    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 657759     Buffer Size: 19488      Transition Number: 999.941 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:07:32,261][train][INFO][train.py>_log] ==> #430000     Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 6.832    Value Loss: 5.384    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 659381     Buffer Size: 19537      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:10:24,191][train][INFO][train.py>_log] ==> #431000     Total Loss: 0.838    [weighted Loss:0.838    Policy Loss: 6.736    Value Loss: 5.381    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 660957     Buffer Size: 19391      Transition Number: 1000.186k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:13:16,490][train][INFO][train.py>_log] ==> #432000     Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 6.763    Value Loss: 5.756    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 662549     Buffer Size: 19175      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:16:11,633][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.318    [weighted Loss:2.318    Policy Loss: 7.319    Value Loss: 5.356    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 664045     Buffer Size: 18960      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:19:07,174][train][INFO][train.py>_log] ==> #434000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 6.669    Value Loss: 5.548    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 665658     Buffer Size: 18734      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:22:00,898][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 6.655    Value Loss: 5.127    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 667107     Buffer Size: 18576      Transition Number: 1000.081k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:24:53,851][train][INFO][train.py>_log] ==> #436000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 6.697    Value Loss: 5.208    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 668727     Buffer Size: 18402      Transition Number: 1000.705k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:27:47,748][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 6.913    Value Loss: 5.219    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 670574     Buffer Size: 18505      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:30:40,175][train][INFO][train.py>_log] ==> #438000     Total Loss: 1.381    [weighted Loss:1.381    Policy Loss: 6.934    Value Loss: 5.279    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 672409     Buffer Size: 18660      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:33:36,740][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 7.092    Value Loss: 5.778    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 675955     Buffer Size: 20280      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:36:27,384][train][INFO][train.py>_log] ==> #440000     Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 7.292    Value Loss: 5.937    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 679363     Buffer Size: 21943      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:39:14,608][train][INFO][train.py>_log] ==> #441000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 7.069    Value Loss: 5.721    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 681735     Buffer Size: 22757      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:42:00,978][train][INFO][train.py>_log] ==> #442000     Total Loss: 0.865    [weighted Loss:0.865    Policy Loss: 6.749    Value Loss: 5.715    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 684166     Buffer Size: 23567      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:44:49,929][train][INFO][train.py>_log] ==> #443000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 6.836    Value Loss: 5.520    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 685547     Buffer Size: 23461      Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:47:42,197][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 6.301    Value Loss: 5.131    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 686882     Buffer Size: 23334      Transition Number: 1000.198k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:50:34,571][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.539    [weighted Loss:3.539    Policy Loss: 7.901    Value Loss: 5.376    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 688290     Buffer Size: 23192      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:53:26,360][train][INFO][train.py>_log] ==> #446000     Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 7.085    Value Loss: 5.208    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 689766     Buffer Size: 23062      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:56:18,800][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 7.771    Value Loss: 5.534    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 691801     Buffer Size: 23617      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 05:59:09,449][train][INFO][train.py>_log] ==> #448000     Total Loss: 3.697    [weighted Loss:3.697    Policy Loss: 8.093    Value Loss: 5.443    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 693840     Buffer Size: 23917      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:01:56,920][train][INFO][train.py>_log] ==> #449000     Total Loss: 3.629    [weighted Loss:3.629    Policy Loss: 7.324    Value Loss: 5.726    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 695642     Buffer Size: 23875      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:04:45,265][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.950    [weighted Loss:2.950    Policy Loss: 7.685    Value Loss: 5.700    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 697386     Buffer Size: 23197      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:07:33,896][train][INFO][train.py>_log] ==> #451000     Total Loss: 3.579    [weighted Loss:3.579    Policy Loss: 7.642    Value Loss: 5.493    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 699558     Buffer Size: 22090      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:10:24,348][train][INFO][train.py>_log] ==> #452000     Total Loss: 2.330    [weighted Loss:2.330    Policy Loss: 7.607    Value Loss: 5.401    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 701697     Buffer Size: 21187      Transition Number: 1000.119k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:13:14,125][train][INFO][train.py>_log] ==> #453000     Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 7.591    Value Loss: 5.652    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 703664     Buffer Size: 20753      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:16:06,939][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 7.737    Value Loss: 5.915    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 705710     Buffer Size: 20848      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:18:57,126][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 6.994    Value Loss: 5.697    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 707783     Buffer Size: 21453      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:21:45,838][train][INFO][train.py>_log] ==> #456000     Total Loss: 3.497    [weighted Loss:3.497    Policy Loss: 7.247    Value Loss: 5.568    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 709684     Buffer Size: 21990      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:24:32,341][train][INFO][train.py>_log] ==> #457000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 6.283    Value Loss: 5.656    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 711361     Buffer Size: 22405      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:27:23,926][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 6.566    Value Loss: 5.626    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 713259     Buffer Size: 22542      Transition Number: 1000.174k Batch Size: 256        Lr: 0.10000 
[2022-01-19 06:30:13,766][train][INFO][train.py>_log] ==> #459000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 6.897    Value Loss: 5.764    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 715017     Buffer Size: 22234      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
