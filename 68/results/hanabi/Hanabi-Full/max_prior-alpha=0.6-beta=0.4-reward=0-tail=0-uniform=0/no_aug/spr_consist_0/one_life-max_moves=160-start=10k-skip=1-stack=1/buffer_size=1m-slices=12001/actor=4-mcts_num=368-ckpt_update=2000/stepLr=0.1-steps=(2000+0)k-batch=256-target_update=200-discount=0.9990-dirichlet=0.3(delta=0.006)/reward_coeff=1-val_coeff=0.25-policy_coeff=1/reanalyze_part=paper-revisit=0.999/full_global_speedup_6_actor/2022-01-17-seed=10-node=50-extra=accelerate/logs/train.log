[2022-01-17 11:09:23,537][train][INFO][train.py>_log] ==> #0          Total Loss: 55.904   [weighted Loss:55.904   Policy Loss: 14.803   Value Loss: 37.125   Reward Loss: 31.820   Consistency Loss: 0.000    ] Replay Episodes Collected: 2040       Buffer Size: 2040       Transition Number: 22.330  k Batch Size: 256        Lr: 0.00000 
[2022-01-17 11:11:23,949][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.079    [weighted Loss:5.079    Policy Loss: 14.153   Value Loss: 4.142    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 11429      Buffer Size: 11429      Transition Number: 141.844 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:13:26,648][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.460    [weighted Loss:5.460    Policy Loss: 13.409   Value Loss: 3.588    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 20589      Buffer Size: 20589      Transition Number: 254.291 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:15:26,908][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 12.405   Value Loss: 3.317    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 31641      Buffer Size: 31641      Transition Number: 365.283 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:17:26,930][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.870    [weighted Loss:5.870    Policy Loss: 13.007   Value Loss: 3.186    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 43598      Buffer Size: 43598      Transition Number: 487.292 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:19:31,812][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.789    [weighted Loss:5.789    Policy Loss: 12.916   Value Loss: 3.262    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 56016      Buffer Size: 56016      Transition Number: 604.009 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:21:47,591][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.229    [weighted Loss:4.229    Policy Loss: 12.823   Value Loss: 3.171    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 70186      Buffer Size: 70186      Transition Number: 738.056 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:23:54,404][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.838    [weighted Loss:4.838    Policy Loss: 13.496   Value Loss: 2.987    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 74265      Buffer Size: 74265      Transition Number: 840.833 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:26:08,362][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.353    [weighted Loss:4.353    Policy Loss: 11.975   Value Loss: 2.397    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 78349      Buffer Size: 78349      Transition Number: 962.860 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:28:34,129][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.383    [weighted Loss:4.383    Policy Loss: 10.833   Value Loss: 3.086    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 82751      Buffer Size: 82751      Transition Number: 1085.357k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:31:12,535][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 10.362   Value Loss: 2.768    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 87865      Buffer Size: 85554      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:34:10,793][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 9.681    Value Loss: 2.938    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 96085      Buffer Size: 80409      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:37:11,532][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 8.596    Value Loss: 2.789    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 104452     Buffer Size: 73794      Transition Number: 1200.075k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:40:10,696][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.950    [weighted Loss:2.950    Policy Loss: 8.655    Value Loss: 3.087    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 110737     Buffer Size: 65286      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:43:13,837][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 8.105    Value Loss: 3.018    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 117254     Buffer Size: 55463      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:46:14,391][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.167    [weighted Loss:3.167    Policy Loss: 8.459    Value Loss: 3.021    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 122914     Buffer Size: 49780      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:49:14,990][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 6.681    Value Loss: 2.890    Reward Loss: 0.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 128484     Buffer Size: 50118      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:52:09,396][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 7.773    Value Loss: 2.987    Reward Loss: 0.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 131372     Buffer Size: 48458      Transition Number: 1200.178k Batch Size: 256        Lr: 0.10000 
[2022-01-17 11:55:04,203][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 6.773    Value Loss: 3.222    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 134262     Buffer Size: 46296      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
