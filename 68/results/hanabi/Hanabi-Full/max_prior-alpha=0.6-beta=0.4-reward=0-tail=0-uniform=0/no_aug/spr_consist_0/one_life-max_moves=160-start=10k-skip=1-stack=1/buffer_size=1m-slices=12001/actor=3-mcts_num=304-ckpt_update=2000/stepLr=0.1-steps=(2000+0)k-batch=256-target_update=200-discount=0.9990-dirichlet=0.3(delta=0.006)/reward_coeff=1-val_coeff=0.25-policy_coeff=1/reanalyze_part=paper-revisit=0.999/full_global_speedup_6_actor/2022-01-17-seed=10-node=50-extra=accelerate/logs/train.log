[2022-01-17 13:02:04,263][train][INFO][train.py>_log] ==> #0          Total Loss: 48.409   [weighted Loss:48.409   Policy Loss: 13.938   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1896       Buffer Size: 1896       Transition Number: 21.083  k Batch Size: 256        Lr: 0.00000 
[2022-01-17 13:03:43,193][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.387    [weighted Loss:6.387    Policy Loss: 12.659   Value Loss: 3.547    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 9561       Buffer Size: 9561       Transition Number: 119.801 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:05:23,897][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.374    [weighted Loss:6.374    Policy Loss: 12.351   Value Loss: 3.197    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 16637      Buffer Size: 16637      Transition Number: 206.735 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:07:04,621][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.290    [weighted Loss:6.290    Policy Loss: 11.500   Value Loss: 2.840    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 25696      Buffer Size: 25696      Transition Number: 298.419 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:08:48,781][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.280    [weighted Loss:4.280    Policy Loss: 12.171   Value Loss: 2.809    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 35430      Buffer Size: 35430      Transition Number: 399.566 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:10:38,331][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.968    [weighted Loss:4.968    Policy Loss: 11.671   Value Loss: 2.680    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 43326      Buffer Size: 43326      Transition Number: 496.005 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:12:36,798][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.136    [weighted Loss:5.136    Policy Loss: 12.937   Value Loss: 2.801    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 52390      Buffer Size: 52390      Transition Number: 610.233 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:14:51,163][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.477    [weighted Loss:3.477    Policy Loss: 12.677   Value Loss: 2.743    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 63650      Buffer Size: 63650      Transition Number: 742.923 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:17:16,620][train][INFO][train.py>_log] ==> #8000       Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 11.251   Value Loss: 2.671    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 76207      Buffer Size: 76207      Transition Number: 892.403 k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:20:09,625][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 11.713   Value Loss: 2.688    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 95007      Buffer Size: 95007      Transition Number: 1074.045k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:23:29,857][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.710    [weighted Loss:3.710    Policy Loss: 11.592   Value Loss: 2.708    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 116731     Buffer Size: 110181     Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:27:21,062][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.101    [weighted Loss:3.101    Policy Loss: 10.053   Value Loss: 2.694    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 144627     Buffer Size: 116392     Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:31:21,284][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 9.192    Value Loss: 2.459    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 174030     Buffer Size: 124162     Transition Number: 1200.222k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:35:13,013][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 8.668    Value Loss: 2.522    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 203290     Buffer Size: 133001     Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:39:10,424][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 9.679    Value Loss: 2.403    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 233296     Buffer Size: 138346     Transition Number: 1200.235k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:43:23,481][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.020    [weighted Loss:4.020    Policy Loss: 10.031   Value Loss: 2.689    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 266570     Buffer Size: 143535     Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:47:38,835][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 9.279    Value Loss: 2.782    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 300947     Buffer Size: 146410     Transition Number: 1200.239k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:51:20,440][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 9.306    Value Loss: 2.924    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 322871     Buffer Size: 141147     Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:54:58,042][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 10.590   Value Loss: 2.756    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 344386     Buffer Size: 135346     Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-17 13:58:41,419][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.079    [weighted Loss:3.079    Policy Loss: 9.597    Value Loss: 3.046    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 365342     Buffer Size: 127808     Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:02:24,988][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.241    [weighted Loss:4.241    Policy Loss: 10.890   Value Loss: 2.919    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 386242     Buffer Size: 118565     Transition Number: 1200.309k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:06:00,974][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.666    [weighted Loss:4.666    Policy Loss: 10.806   Value Loss: 3.215    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 404927     Buffer Size: 108971     Transition Number: 1200.235k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:09:45,393][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.166    [weighted Loss:3.166    Policy Loss: 11.142   Value Loss: 3.134    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 424315     Buffer Size: 105003     Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:12:56,844][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 11.532   Value Loss: 3.196    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 432345     Buffer Size: 96100      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:16:08,147][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 10.655   Value Loss: 3.563    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 439987     Buffer Size: 86812      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:19:07,937][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 10.368   Value Loss: 3.594    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 443248     Buffer Size: 76939      Transition Number: 1200.417k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:22:09,774][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 9.338    Value Loss: 3.612    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 446480     Buffer Size: 66678      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:25:16,532][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 8.628    Value Loss: 3.702    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 449524     Buffer Size: 55620      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:28:20,956][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 6.877    Value Loss: 3.695    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 452275     Buffer Size: 46388      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:31:28,957][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.142    [weighted Loss:3.142    Policy Loss: 6.978    Value Loss: 3.720    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 454448     Buffer Size: 37379      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:34:39,236][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 5.759    Value Loss: 3.598    Reward Loss: 0.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 456906     Buffer Size: 28999      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:37:48,348][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 6.270    Value Loss: 3.126    Reward Loss: 0.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 458815     Buffer Size: 25586      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:41:00,888][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 5.426    Value Loss: 3.514    Reward Loss: 0.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 461140     Buffer Size: 21397      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:44:10,274][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 5.078    Value Loss: 3.150    Reward Loss: 0.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 463260     Buffer Size: 20163      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:47:19,726][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.580    [weighted Loss:1.580    Policy Loss: 5.398    Value Loss: 3.064    Reward Loss: 0.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 465103     Buffer Size: 19421      Transition Number: 1200.037k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:50:34,603][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 4.580    Value Loss: 3.436    Reward Loss: 0.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 468284     Buffer Size: 19090      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:53:46,554][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 6.214    Value Loss: 3.337    Reward Loss: 0.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 471202     Buffer Size: 18981      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-17 14:56:58,034][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.865    [weighted Loss:1.865    Policy Loss: 5.580    Value Loss: 3.497    Reward Loss: 0.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 474401     Buffer Size: 19390      Transition Number: 1200.265k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:00:10,788][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 8.056    Value Loss: 3.514    Reward Loss: 0.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 477608     Buffer Size: 20013      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-17 15:03:26,996][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.143    [weighted Loss:2.143    Policy Loss: 7.223    Value Loss: 3.847    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 482200     Buffer Size: 22222      Transition Number: 1200.347k Batch Size: 256        Lr: 0.10000 
