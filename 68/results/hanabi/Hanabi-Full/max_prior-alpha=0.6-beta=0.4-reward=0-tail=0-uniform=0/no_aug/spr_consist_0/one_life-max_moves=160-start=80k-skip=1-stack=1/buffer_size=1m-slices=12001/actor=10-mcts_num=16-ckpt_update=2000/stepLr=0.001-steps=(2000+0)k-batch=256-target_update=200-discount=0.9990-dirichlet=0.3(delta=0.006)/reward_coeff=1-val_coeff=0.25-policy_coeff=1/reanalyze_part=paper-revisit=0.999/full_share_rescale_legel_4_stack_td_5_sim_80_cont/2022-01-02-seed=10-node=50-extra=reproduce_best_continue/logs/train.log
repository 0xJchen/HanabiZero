[2022-01-02 09:05:37,796][train][INFO][train.py>_log] ==> #0          Total Loss: 30.752   [weighted Loss:30.752   Policy Loss: 17.806   Value Loss: 37.254   Reward Loss: 3.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 6480       Buffer Size: 6480       Transition Number: 80.549  k Batch Size: 256        Lr: 0.00000 
[2022-01-02 09:07:54,078][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.490    [weighted Loss:5.490    Policy Loss: 7.072    Value Loss: 9.027    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 6741       Buffer Size: 6741       Transition Number: 97.185  k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:10:21,742][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.264    [weighted Loss:4.264    Policy Loss: 6.223    Value Loss: 6.833    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 7150       Buffer Size: 7150       Transition Number: 124.442 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:12:46,888][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 5.984    Value Loss: 7.023    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 7494       Buffer Size: 7494       Transition Number: 147.017 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:15:20,272][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.215    [weighted Loss:3.215    Policy Loss: 5.909    Value Loss: 6.465    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 7921       Buffer Size: 7921       Transition Number: 174.815 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:17:52,976][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 5.700    Value Loss: 6.540    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 8264       Buffer Size: 8264       Transition Number: 197.654 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:20:25,348][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.295    [weighted Loss:3.295    Policy Loss: 5.118    Value Loss: 6.034    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 8621       Buffer Size: 8621       Transition Number: 221.462 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:22:53,998][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.317    [weighted Loss:3.317    Policy Loss: 5.755    Value Loss: 6.134    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 8989       Buffer Size: 8989       Transition Number: 245.715 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:25:26,627][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 6.456    Value Loss: 6.645    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 9381       Buffer Size: 9381       Transition Number: 271.557 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:27:56,598][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.327    [weighted Loss:4.327    Policy Loss: 6.670    Value Loss: 6.190    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 9728       Buffer Size: 9728       Transition Number: 294.617 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:30:25,914][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 6.439    Value Loss: 6.441    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 10123      Buffer Size: 10123      Transition Number: 320.755 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:32:53,771][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.813    [weighted Loss:3.813    Policy Loss: 6.701    Value Loss: 5.822    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 10479      Buffer Size: 10479      Transition Number: 344.270 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:35:24,873][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.976    [weighted Loss:3.976    Policy Loss: 6.375    Value Loss: 6.448    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 10835      Buffer Size: 10835      Transition Number: 367.727 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:37:53,796][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 6.145    Value Loss: 6.398    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 11170      Buffer Size: 11170      Transition Number: 389.896 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:40:19,095][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.940    [weighted Loss:2.940    Policy Loss: 7.073    Value Loss: 6.523    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 11561      Buffer Size: 11561      Transition Number: 415.917 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:42:46,767][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.766    [weighted Loss:3.766    Policy Loss: 6.729    Value Loss: 6.927    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 11919      Buffer Size: 11919      Transition Number: 439.626 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:45:16,378][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.342    [weighted Loss:4.342    Policy Loss: 7.112    Value Loss: 6.624    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 12275      Buffer Size: 12275      Transition Number: 462.971 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:47:47,379][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.864    [weighted Loss:4.864    Policy Loss: 7.491    Value Loss: 6.250    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 12637      Buffer Size: 12637      Transition Number: 486.747 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:50:11,934][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 7.192    Value Loss: 6.465    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 12977      Buffer Size: 12977      Transition Number: 509.405 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:52:41,825][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.462    [weighted Loss:4.462    Policy Loss: 7.362    Value Loss: 6.704    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 13342      Buffer Size: 13342      Transition Number: 533.500 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:55:08,789][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 7.501    Value Loss: 6.396    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 13702      Buffer Size: 13702      Transition Number: 556.942 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 09:57:36,857][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 7.586    Value Loss: 6.183    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 14044      Buffer Size: 14044      Transition Number: 578.766 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:00:11,977][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 7.161    Value Loss: 6.002    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 14426      Buffer Size: 14426      Transition Number: 603.134 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:02:37,817][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.907    [weighted Loss:3.907    Policy Loss: 7.712    Value Loss: 6.402    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 14783      Buffer Size: 14783      Transition Number: 625.403 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:05:06,025][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.319    [weighted Loss:4.319    Policy Loss: 8.225    Value Loss: 7.010    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 15165      Buffer Size: 15165      Transition Number: 649.242 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:07:33,483][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.973    [weighted Loss:3.973    Policy Loss: 8.435    Value Loss: 6.639    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 15578      Buffer Size: 15578      Transition Number: 673.395 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:09:59,702][train][INFO][train.py>_log] ==> #26000      Total Loss: 4.763    [weighted Loss:4.763    Policy Loss: 8.322    Value Loss: 6.645    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 15970      Buffer Size: 15970      Transition Number: 695.556 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:12:22,648][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.171    [weighted Loss:3.171    Policy Loss: 8.040    Value Loss: 6.358    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 16347      Buffer Size: 16347      Transition Number: 717.283 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:14:45,770][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.588    [weighted Loss:4.588    Policy Loss: 8.330    Value Loss: 6.767    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 16715      Buffer Size: 16715      Transition Number: 738.501 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:17:11,235][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.406    [weighted Loss:3.406    Policy Loss: 8.072    Value Loss: 6.477    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 17066      Buffer Size: 17066      Transition Number: 759.030 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:19:37,062][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.983    [weighted Loss:3.983    Policy Loss: 8.466    Value Loss: 6.800    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 17428      Buffer Size: 17428      Transition Number: 780.643 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:22:02,594][train][INFO][train.py>_log] ==> #31000      Total Loss: 6.089    [weighted Loss:6.089    Policy Loss: 8.169    Value Loss: 6.842    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 17808      Buffer Size: 17808      Transition Number: 802.959 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:24:28,575][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.697    [weighted Loss:3.697    Policy Loss: 8.831    Value Loss: 7.028    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 18170      Buffer Size: 18170      Transition Number: 824.842 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:27:05,785][train][INFO][train.py>_log] ==> #33000      Total Loss: 5.204    [weighted Loss:5.204    Policy Loss: 8.252    Value Loss: 7.105    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 18583      Buffer Size: 18583      Transition Number: 849.201 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:29:36,836][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 8.291    Value Loss: 7.188    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 18960      Buffer Size: 18960      Transition Number: 871.720 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:32:06,350][train][INFO][train.py>_log] ==> #35000      Total Loss: 4.634    [weighted Loss:4.634    Policy Loss: 7.818    Value Loss: 7.887    Reward Loss: 1.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 19367      Buffer Size: 19367      Transition Number: 894.875 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:34:38,463][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.261    [weighted Loss:3.261    Policy Loss: 8.043    Value Loss: 6.874    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 19800      Buffer Size: 19800      Transition Number: 919.296 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:37:10,497][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.505    [weighted Loss:4.505    Policy Loss: 8.311    Value Loss: 7.235    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 20262      Buffer Size: 20262      Transition Number: 941.952 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:39:41,827][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.751    [weighted Loss:3.751    Policy Loss: 8.370    Value Loss: 7.766    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 20739      Buffer Size: 20739      Transition Number: 964.608 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:42:14,725][train][INFO][train.py>_log] ==> #39000      Total Loss: 4.204    [weighted Loss:4.204    Policy Loss: 8.716    Value Loss: 7.404    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 21289      Buffer Size: 21289      Transition Number: 988.373 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:44:52,834][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.422    [weighted Loss:4.422    Policy Loss: 8.475    Value Loss: 7.603    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 21864      Buffer Size: 20798      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:47:34,393][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.611    [weighted Loss:3.611    Policy Loss: 9.502    Value Loss: 8.139    Reward Loss: 1.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 22456      Buffer Size: 19429      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:50:16,293][train][INFO][train.py>_log] ==> #42000      Total Loss: 5.178    [weighted Loss:5.178    Policy Loss: 10.161   Value Loss: 7.961    Reward Loss: 1.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 23066      Buffer Size: 18002      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:52:56,617][train][INFO][train.py>_log] ==> #43000      Total Loss: 5.527    [weighted Loss:5.527    Policy Loss: 10.075   Value Loss: 8.146    Reward Loss: 1.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 23771      Buffer Size: 17173      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:55:39,575][train][INFO][train.py>_log] ==> #44000      Total Loss: 4.650    [weighted Loss:4.650    Policy Loss: 9.741    Value Loss: 8.477    Reward Loss: 1.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 24496      Buffer Size: 17506      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 10:58:19,366][train][INFO][train.py>_log] ==> #45000      Total Loss: 5.452    [weighted Loss:5.452    Policy Loss: 10.495   Value Loss: 8.854    Reward Loss: 1.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 25142      Buffer Size: 17792      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:00:58,742][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.368    [weighted Loss:4.368    Policy Loss: 9.744    Value Loss: 8.893    Reward Loss: 1.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 25817      Buffer Size: 18087      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:03:38,045][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.317    [weighted Loss:4.317    Policy Loss: 9.927    Value Loss: 8.327    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 26424      Buffer Size: 18331      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:06:18,040][train][INFO][train.py>_log] ==> #48000      Total Loss: 4.659    [weighted Loss:4.659    Policy Loss: 9.099    Value Loss: 8.601    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 27017      Buffer Size: 18555      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:08:58,824][train][INFO][train.py>_log] ==> #49000      Total Loss: 4.846    [weighted Loss:4.846    Policy Loss: 9.727    Value Loss: 9.081    Reward Loss: 1.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 27538      Buffer Size: 18718      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:11:37,062][train][INFO][train.py>_log] ==> #50000      Total Loss: 5.255    [weighted Loss:5.255    Policy Loss: 8.193    Value Loss: 9.162    Reward Loss: 1.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 28029      Buffer Size: 18862      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:14:14,516][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 8.517    Value Loss: 8.828    Reward Loss: 1.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 28520      Buffer Size: 18995      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:16:52,679][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.835    [weighted Loss:3.835    Policy Loss: 8.131    Value Loss: 9.092    Reward Loss: 1.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 28996      Buffer Size: 19124      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:19:30,006][train][INFO][train.py>_log] ==> #53000      Total Loss: 4.430    [weighted Loss:4.430    Policy Loss: 8.948    Value Loss: 9.484    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 29443      Buffer Size: 19217      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:22:06,577][train][INFO][train.py>_log] ==> #54000      Total Loss: 4.775    [weighted Loss:4.775    Policy Loss: 7.146    Value Loss: 9.015    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 29859      Buffer Size: 19300      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:24:42,425][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.975    [weighted Loss:3.975    Policy Loss: 7.591    Value Loss: 9.495    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 30226      Buffer Size: 19328      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:27:19,480][train][INFO][train.py>_log] ==> #56000      Total Loss: 4.341    [weighted Loss:4.341    Policy Loss: 7.468    Value Loss: 9.061    Reward Loss: 1.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 30616      Buffer Size: 19361      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:30:00,949][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 7.644    Value Loss: 9.223    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 31005      Buffer Size: 19385      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:32:39,065][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.651    [weighted Loss:3.651    Policy Loss: 6.853    Value Loss: 8.436    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 31398      Buffer Size: 19402      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 11:35:16,000][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 7.798    Value Loss: 8.859    Reward Loss: 1.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 31761      Buffer Size: 19422      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00100 
