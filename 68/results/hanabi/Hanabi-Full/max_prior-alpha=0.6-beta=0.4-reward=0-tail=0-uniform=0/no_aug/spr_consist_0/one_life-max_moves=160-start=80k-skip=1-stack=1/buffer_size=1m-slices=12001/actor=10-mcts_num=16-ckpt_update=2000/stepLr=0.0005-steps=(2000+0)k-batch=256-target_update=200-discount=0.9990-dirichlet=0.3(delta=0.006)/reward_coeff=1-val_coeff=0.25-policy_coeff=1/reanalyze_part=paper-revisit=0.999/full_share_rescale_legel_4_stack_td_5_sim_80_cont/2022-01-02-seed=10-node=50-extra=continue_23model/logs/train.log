[2022-01-02 11:45:29,712][train][INFO][train.py>_log] ==> #0          Total Loss: 30.320   [weighted Loss:30.320   Policy Loss: 18.185   Value Loss: 35.396   Reward Loss: 3.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 6471       Buffer Size: 6471       Transition Number: 80.390  k Batch Size: 256        Lr: 0.00000 
[2022-01-02 11:47:46,541][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.344    [weighted Loss:4.344    Policy Loss: 6.693    Value Loss: 9.910    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 6732       Buffer Size: 6732       Transition Number: 96.609  k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:49:59,882][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.547    [weighted Loss:4.547    Policy Loss: 6.141    Value Loss: 8.224    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 7076       Buffer Size: 7076       Transition Number: 119.358 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:52:17,662][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.403    [weighted Loss:3.403    Policy Loss: 5.581    Value Loss: 6.506    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 7444       Buffer Size: 7444       Transition Number: 143.826 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:54:34,995][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.976    [weighted Loss:3.976    Policy Loss: 5.692    Value Loss: 6.789    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 7784       Buffer Size: 7784       Transition Number: 166.425 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:56:50,914][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 5.971    Value Loss: 6.755    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 8095       Buffer Size: 8095       Transition Number: 187.393 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:59:10,839][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.362    [weighted Loss:3.362    Policy Loss: 6.094    Value Loss: 6.770    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 8433       Buffer Size: 8433       Transition Number: 210.126 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:01:26,384][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 5.861    Value Loss: 6.600    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 8786       Buffer Size: 8786       Transition Number: 233.867 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:03:43,414][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.457    [weighted Loss:3.457    Policy Loss: 6.110    Value Loss: 6.417    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 9129       Buffer Size: 9129       Transition Number: 257.042 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:06:03,016][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.772    [weighted Loss:3.772    Policy Loss: 6.096    Value Loss: 6.204    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 9457       Buffer Size: 9457       Transition Number: 279.018 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:08:19,184][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.773    [weighted Loss:3.773    Policy Loss: 5.893    Value Loss: 6.573    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 9793       Buffer Size: 9793       Transition Number: 301.355 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:10:35,812][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 6.044    Value Loss: 6.250    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 10129      Buffer Size: 10129      Transition Number: 323.891 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:12:53,569][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.921    [weighted Loss:3.921    Policy Loss: 6.801    Value Loss: 6.082    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 10466      Buffer Size: 10466      Transition Number: 346.584 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:15:10,079][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 6.480    Value Loss: 6.319    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 10788      Buffer Size: 10788      Transition Number: 368.035 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:17:26,852][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 6.642    Value Loss: 6.257    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 11110      Buffer Size: 11110      Transition Number: 389.731 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:19:43,970][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 7.338    Value Loss: 6.155    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 11431      Buffer Size: 11431      Transition Number: 411.410 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:21:59,145][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.519    [weighted Loss:4.519    Policy Loss: 6.869    Value Loss: 6.390    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 11773      Buffer Size: 11773      Transition Number: 434.353 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:24:14,813][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.065    [weighted Loss:4.065    Policy Loss: 6.723    Value Loss: 6.220    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 12109      Buffer Size: 12109      Transition Number: 457.159 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:26:30,640][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.667    [weighted Loss:3.667    Policy Loss: 7.436    Value Loss: 6.432    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 12440      Buffer Size: 12440      Transition Number: 479.566 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:28:45,639][train][INFO][train.py>_log] ==> #19000      Total Loss: 5.200    [weighted Loss:5.200    Policy Loss: 7.597    Value Loss: 5.998    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 12762      Buffer Size: 12762      Transition Number: 501.185 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:31:04,640][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.485    [weighted Loss:4.485    Policy Loss: 7.140    Value Loss: 6.048    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 13085      Buffer Size: 13085      Transition Number: 522.811 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:33:23,656][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 7.261    Value Loss: 6.207    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 13405      Buffer Size: 13405      Transition Number: 544.336 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:35:42,489][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.568    [weighted Loss:4.568    Policy Loss: 7.775    Value Loss: 6.076    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 13729      Buffer Size: 13729      Transition Number: 566.087 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:37:59,068][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.887    [weighted Loss:3.887    Policy Loss: 7.760    Value Loss: 5.991    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 14052      Buffer Size: 14052      Transition Number: 587.797 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:40:15,092][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.475    [weighted Loss:3.475    Policy Loss: 7.673    Value Loss: 6.090    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 14379      Buffer Size: 14379      Transition Number: 609.874 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:42:32,159][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.992    [weighted Loss:2.992    Policy Loss: 7.767    Value Loss: 6.088    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 14698      Buffer Size: 14698      Transition Number: 631.434 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:44:46,793][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 8.025    Value Loss: 6.290    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 15030      Buffer Size: 15030      Transition Number: 653.590 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:47:04,802][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.384    [weighted Loss:3.384    Policy Loss: 7.546    Value Loss: 6.003    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 15382      Buffer Size: 15382      Transition Number: 677.195 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:49:21,026][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.400    [weighted Loss:4.400    Policy Loss: 8.507    Value Loss: 6.348    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 15712      Buffer Size: 15712      Transition Number: 699.240 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:51:38,013][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.469    [weighted Loss:3.469    Policy Loss: 8.412    Value Loss: 5.911    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 16039      Buffer Size: 16039      Transition Number: 720.897 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:53:54,864][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.848    [weighted Loss:4.848    Policy Loss: 8.054    Value Loss: 5.723    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 16363      Buffer Size: 16363      Transition Number: 742.476 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:56:12,621][train][INFO][train.py>_log] ==> #31000      Total Loss: 5.168    [weighted Loss:5.168    Policy Loss: 8.660    Value Loss: 6.025    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 16685      Buffer Size: 16685      Transition Number: 763.838 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:58:29,889][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.890    [weighted Loss:4.890    Policy Loss: 7.563    Value Loss: 6.344    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 17006      Buffer Size: 17006      Transition Number: 785.174 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:00:45,586][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.413    [weighted Loss:4.413    Policy Loss: 8.302    Value Loss: 6.180    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 17326      Buffer Size: 17326      Transition Number: 806.631 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:03:04,017][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 7.689    Value Loss: 5.939    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 17656      Buffer Size: 17656      Transition Number: 828.059 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:05:23,758][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.779    [weighted Loss:3.779    Policy Loss: 9.025    Value Loss: 6.193    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 17975      Buffer Size: 17975      Transition Number: 849.320 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:07:43,976][train][INFO][train.py>_log] ==> #36000      Total Loss: 5.137    [weighted Loss:5.137    Policy Loss: 8.073    Value Loss: 5.927    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 18319      Buffer Size: 18319      Transition Number: 872.089 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:10:08,818][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 8.061    Value Loss: 6.042    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 18686      Buffer Size: 18686      Transition Number: 896.328 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:12:35,961][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 8.163    Value Loss: 6.448    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 19060      Buffer Size: 19060      Transition Number: 921.437 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:15:01,181][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.991    [weighted Loss:2.991    Policy Loss: 7.596    Value Loss: 6.610    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 19398      Buffer Size: 19398      Transition Number: 943.989 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:17:28,213][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 8.276    Value Loss: 6.207    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 19737      Buffer Size: 19737      Transition Number: 966.667 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:19:58,428][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.712    [weighted Loss:4.712    Policy Loss: 8.917    Value Loss: 5.891    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 20088      Buffer Size: 20088      Transition Number: 990.078 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:22:32,468][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.340    [weighted Loss:3.340    Policy Loss: 8.744    Value Loss: 6.513    Reward Loss: 1.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 20479      Buffer Size: 19166      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
