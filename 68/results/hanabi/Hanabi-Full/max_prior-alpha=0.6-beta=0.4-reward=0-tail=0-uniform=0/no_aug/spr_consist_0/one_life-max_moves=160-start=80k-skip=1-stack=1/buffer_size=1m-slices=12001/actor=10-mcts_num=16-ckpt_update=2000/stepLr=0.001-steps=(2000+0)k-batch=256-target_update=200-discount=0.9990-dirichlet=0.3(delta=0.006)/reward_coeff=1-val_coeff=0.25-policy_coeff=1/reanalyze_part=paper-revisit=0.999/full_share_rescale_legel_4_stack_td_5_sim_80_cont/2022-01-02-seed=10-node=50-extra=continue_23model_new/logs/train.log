[2022-01-02 13:33:15,557][train][INFO][train.py>_log] ==> #0          Total Loss: 31.274   [weighted Loss:31.274   Policy Loss: 18.040   Value Loss: 38.112   Reward Loss: 3.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 6413       Buffer Size: 6413       Transition Number: 80.359  k Batch Size: 256        Lr: 0.00000 
[2022-01-02 13:35:35,064][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 6.256    Value Loss: 9.364    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 6710       Buffer Size: 6710       Transition Number: 98.384  k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:37:54,373][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.351    [weighted Loss:4.351    Policy Loss: 5.963    Value Loss: 7.048    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 7076       Buffer Size: 7076       Transition Number: 122.753 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:40:18,690][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 5.725    Value Loss: 6.968    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 7427       Buffer Size: 7427       Transition Number: 146.090 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:42:39,372][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 5.353    Value Loss: 6.527    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 7760       Buffer Size: 7760       Transition Number: 168.268 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:45:08,575][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.915    [weighted Loss:2.915    Policy Loss: 5.669    Value Loss: 6.384    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 8150       Buffer Size: 8150       Transition Number: 194.435 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:47:36,718][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 6.008    Value Loss: 6.282    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 8516       Buffer Size: 8516       Transition Number: 218.966 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:50:05,730][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.997    [weighted Loss:3.997    Policy Loss: 6.394    Value Loss: 6.186    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 8859       Buffer Size: 8859       Transition Number: 241.742 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:52:31,483][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.628    [weighted Loss:4.628    Policy Loss: 6.200    Value Loss: 5.768    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 9210       Buffer Size: 9210       Transition Number: 265.125 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:54:58,416][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.583    [weighted Loss:2.583    Policy Loss: 6.921    Value Loss: 6.194    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 9585       Buffer Size: 9585       Transition Number: 290.161 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 13:57:30,278][train][INFO][train.py>_log] ==> #10000      Total Loss: 1.271    [weighted Loss:1.271    Policy Loss: 7.098    Value Loss: 6.106    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 9929       Buffer Size: 9929       Transition Number: 312.764 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:00:00,376][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.912    [weighted Loss:3.912    Policy Loss: 6.903    Value Loss: 6.372    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 10320      Buffer Size: 10320      Transition Number: 338.440 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:02:30,604][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.135    [weighted Loss:3.135    Policy Loss: 6.784    Value Loss: 6.727    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 10694      Buffer Size: 10694      Transition Number: 363.296 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:04:59,798][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 6.917    Value Loss: 6.003    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 11030      Buffer Size: 11030      Transition Number: 385.569 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:07:27,480][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.660    [weighted Loss:3.660    Policy Loss: 7.044    Value Loss: 6.292    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 11390      Buffer Size: 11390      Transition Number: 409.565 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:09:56,409][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 7.094    Value Loss: 6.371    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 11760      Buffer Size: 11760      Transition Number: 434.049 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:12:23,990][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 6.871    Value Loss: 6.057    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 12126      Buffer Size: 12126      Transition Number: 458.363 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:14:42,845][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.606    [weighted Loss:4.606    Policy Loss: 7.499    Value Loss: 6.590    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 12454      Buffer Size: 12454      Transition Number: 479.803 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:17:00,053][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.394    [weighted Loss:4.394    Policy Loss: 7.550    Value Loss: 5.712    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 12773      Buffer Size: 12773      Transition Number: 500.914 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:19:24,167][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 7.575    Value Loss: 6.030    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 13116      Buffer Size: 13116      Transition Number: 523.452 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:21:45,355][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.913    [weighted Loss:3.913    Policy Loss: 8.149    Value Loss: 6.198    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 13458      Buffer Size: 13458      Transition Number: 546.033 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:24:04,165][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.586    [weighted Loss:3.586    Policy Loss: 7.858    Value Loss: 6.371    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 13782      Buffer Size: 13782      Transition Number: 567.474 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:26:26,360][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.501    [weighted Loss:4.501    Policy Loss: 7.971    Value Loss: 6.403    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 14143      Buffer Size: 14143      Transition Number: 591.210 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:28:42,962][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 7.821    Value Loss: 5.780    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 14469      Buffer Size: 14469      Transition Number: 612.840 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:31:04,810][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 7.843    Value Loss: 6.222    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 14804      Buffer Size: 14804      Transition Number: 634.908 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:33:26,498][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.352    [weighted Loss:2.352    Policy Loss: 7.744    Value Loss: 6.303    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 15134      Buffer Size: 15134      Transition Number: 656.544 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:35:49,379][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 7.984    Value Loss: 6.327    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 15475      Buffer Size: 15475      Transition Number: 678.918 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:38:11,164][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.747    [weighted Loss:2.747    Policy Loss: 8.019    Value Loss: 6.222    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 15815      Buffer Size: 15815      Transition Number: 701.092 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:40:43,668][train][INFO][train.py>_log] ==> #28000      Total Loss: 5.600    [weighted Loss:5.600    Policy Loss: 8.464    Value Loss: 5.769    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 16202      Buffer Size: 16202      Transition Number: 726.427 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:43:05,230][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.991    [weighted Loss:4.991    Policy Loss: 8.522    Value Loss: 6.158    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 16545      Buffer Size: 16545      Transition Number: 748.746 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:45:30,855][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 8.016    Value Loss: 6.005    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 16887      Buffer Size: 16887      Transition Number: 771.064 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:47:59,779][train][INFO][train.py>_log] ==> #31000      Total Loss: 5.042    [weighted Loss:5.042    Policy Loss: 8.914    Value Loss: 6.116    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 17227      Buffer Size: 17227      Transition Number: 792.796 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:50:25,421][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.645    [weighted Loss:2.645    Policy Loss: 8.827    Value Loss: 6.519    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 17612      Buffer Size: 17612      Transition Number: 817.174 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:52:52,534][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 8.725    Value Loss: 6.663    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 17981      Buffer Size: 17981      Transition Number: 840.050 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:55:19,324][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.368    [weighted Loss:2.368    Policy Loss: 8.809    Value Loss: 6.463    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 18335      Buffer Size: 18335      Transition Number: 861.955 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 14:57:46,790][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.449    [weighted Loss:3.449    Policy Loss: 8.280    Value Loss: 6.558    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 18716      Buffer Size: 18716      Transition Number: 884.138 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:00:16,962][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 9.079    Value Loss: 6.582    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 19097      Buffer Size: 19097      Transition Number: 906.209 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:02:47,482][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.972    [weighted Loss:4.972    Policy Loss: 8.989    Value Loss: 7.236    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 19494      Buffer Size: 19494      Transition Number: 928.290 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:05:19,610][train][INFO][train.py>_log] ==> #38000      Total Loss: 4.301    [weighted Loss:4.301    Policy Loss: 9.013    Value Loss: 6.869    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 19911      Buffer Size: 19911      Transition Number: 951.031 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:07:54,464][train][INFO][train.py>_log] ==> #39000      Total Loss: 6.008    [weighted Loss:6.008    Policy Loss: 8.763    Value Loss: 7.407    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 20337      Buffer Size: 20337      Transition Number: 974.624 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:10:29,443][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 9.413    Value Loss: 8.272    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 20787      Buffer Size: 20787      Transition Number: 999.195 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:13:04,107][train][INFO][train.py>_log] ==> #41000      Total Loss: 5.381    [weighted Loss:5.381    Policy Loss: 8.630    Value Loss: 7.829    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 21198      Buffer Size: 19493      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:15:41,924][train][INFO][train.py>_log] ==> #42000      Total Loss: 5.910    [weighted Loss:5.910    Policy Loss: 9.346    Value Loss: 7.517    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 21647      Buffer Size: 18094      Transition Number: 1000.118k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:18:24,021][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.843    [weighted Loss:3.843    Policy Loss: 8.696    Value Loss: 7.685    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 22106      Buffer Size: 16535      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:21:05,324][train][INFO][train.py>_log] ==> #44000      Total Loss: 4.216    [weighted Loss:4.216    Policy Loss: 9.171    Value Loss: 8.064    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 22529      Buffer Size: 15914      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:23:45,024][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.730    [weighted Loss:3.730    Policy Loss: 9.544    Value Loss: 7.709    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 22958      Buffer Size: 15994      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:26:26,721][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.758    [weighted Loss:4.758    Policy Loss: 9.343    Value Loss: 8.329    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 23425      Buffer Size: 16097      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:29:09,319][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.228    [weighted Loss:4.228    Policy Loss: 9.683    Value Loss: 7.933    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 23930      Buffer Size: 16227      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:31:49,961][train][INFO][train.py>_log] ==> #48000      Total Loss: 5.339    [weighted Loss:5.339    Policy Loss: 9.883    Value Loss: 8.629    Reward Loss: 1.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 24425      Buffer Size: 16361      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:34:31,517][train][INFO][train.py>_log] ==> #49000      Total Loss: 4.558    [weighted Loss:4.558    Policy Loss: 10.067   Value Loss: 8.525    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 24912      Buffer Size: 16495      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:37:12,186][train][INFO][train.py>_log] ==> #50000      Total Loss: 5.252    [weighted Loss:5.252    Policy Loss: 9.842    Value Loss: 8.516    Reward Loss: 1.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 25371      Buffer Size: 16603      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:39:53,277][train][INFO][train.py>_log] ==> #51000      Total Loss: 5.901    [weighted Loss:5.901    Policy Loss: 10.309   Value Loss: 9.796    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 25860      Buffer Size: 16726      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:42:32,603][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.668    [weighted Loss:3.668    Policy Loss: 9.439    Value Loss: 9.280    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 26333      Buffer Size: 16857      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:45:10,749][train][INFO][train.py>_log] ==> #53000      Total Loss: 4.989    [weighted Loss:4.989    Policy Loss: 9.909    Value Loss: 9.525    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 26787      Buffer Size: 16977      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:47:50,679][train][INFO][train.py>_log] ==> #54000      Total Loss: 4.905    [weighted Loss:4.905    Policy Loss: 9.532    Value Loss: 8.793    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 27260      Buffer Size: 17094      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:50:30,336][train][INFO][train.py>_log] ==> #55000      Total Loss: 5.555    [weighted Loss:5.555    Policy Loss: 10.402   Value Loss: 9.330    Reward Loss: 2.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 27812      Buffer Size: 17282      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:53:10,187][train][INFO][train.py>_log] ==> #56000      Total Loss: 6.299    [weighted Loss:6.299    Policy Loss: 10.497   Value Loss: 9.079    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 28379      Buffer Size: 17484      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:55:49,765][train][INFO][train.py>_log] ==> #57000      Total Loss: 5.702    [weighted Loss:5.702    Policy Loss: 10.243   Value Loss: 9.824    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 28913      Buffer Size: 17663      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 15:58:27,467][train][INFO][train.py>_log] ==> #58000      Total Loss: 4.578    [weighted Loss:4.578    Policy Loss: 9.171    Value Loss: 9.369    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 29448      Buffer Size: 17840      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:01:07,190][train][INFO][train.py>_log] ==> #59000      Total Loss: 5.429    [weighted Loss:5.429    Policy Loss: 10.443   Value Loss: 9.216    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 29960      Buffer Size: 17993      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:03:45,165][train][INFO][train.py>_log] ==> #60000      Total Loss: 4.351    [weighted Loss:4.351    Policy Loss: 9.421    Value Loss: 9.209    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 30483      Buffer Size: 18159      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:06:21,455][train][INFO][train.py>_log] ==> #61000      Total Loss: 5.597    [weighted Loss:5.597    Policy Loss: 10.210   Value Loss: 8.997    Reward Loss: 1.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 30920      Buffer Size: 18263      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:08:55,382][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.865    [weighted Loss:4.865    Policy Loss: 8.773    Value Loss: 9.117    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 31376      Buffer Size: 18382      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:11:29,809][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.628    [weighted Loss:4.628    Policy Loss: 10.044   Value Loss: 9.707    Reward Loss: 1.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 31833      Buffer Size: 18485      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:14:05,058][train][INFO][train.py>_log] ==> #64000      Total Loss: 4.859    [weighted Loss:4.859    Policy Loss: 9.039    Value Loss: 9.407    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 32267      Buffer Size: 18584      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:16:40,718][train][INFO][train.py>_log] ==> #65000      Total Loss: 4.842    [weighted Loss:4.842    Policy Loss: 9.531    Value Loss: 9.733    Reward Loss: 1.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 32667      Buffer Size: 18655      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:19:16,310][train][INFO][train.py>_log] ==> #66000      Total Loss: 5.222    [weighted Loss:5.222    Policy Loss: 8.872    Value Loss: 9.792    Reward Loss: 1.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 33053      Buffer Size: 18720      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:21:51,726][train][INFO][train.py>_log] ==> #67000      Total Loss: 4.333    [weighted Loss:4.333    Policy Loss: 8.752    Value Loss: 9.134    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 33478      Buffer Size: 18795      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:24:29,353][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.451    [weighted Loss:4.451    Policy Loss: 8.273    Value Loss: 9.634    Reward Loss: 1.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 33894      Buffer Size: 18861      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:27:06,010][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.821    [weighted Loss:3.821    Policy Loss: 8.223    Value Loss: 9.493    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 34276      Buffer Size: 18906      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:29:42,512][train][INFO][train.py>_log] ==> #70000      Total Loss: 4.463    [weighted Loss:4.463    Policy Loss: 8.017    Value Loss: 9.527    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 34656      Buffer Size: 18945      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:32:20,491][train][INFO][train.py>_log] ==> #71000      Total Loss: 4.565    [weighted Loss:4.565    Policy Loss: 7.883    Value Loss: 9.427    Reward Loss: 1.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 35030      Buffer Size: 18974      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:34:58,827][train][INFO][train.py>_log] ==> #72000      Total Loss: 4.669    [weighted Loss:4.669    Policy Loss: 7.435    Value Loss: 9.073    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 35403      Buffer Size: 18991      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:37:38,442][train][INFO][train.py>_log] ==> #73000      Total Loss: 4.131    [weighted Loss:4.131    Policy Loss: 7.575    Value Loss: 9.982    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 35756      Buffer Size: 18989      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:40:19,685][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.232    [weighted Loss:4.232    Policy Loss: 7.412    Value Loss: 9.488    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 36126      Buffer Size: 18979      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:42:58,309][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.615    [weighted Loss:4.615    Policy Loss: 6.631    Value Loss: 9.225    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 36485      Buffer Size: 18955      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:45:39,261][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 6.848    Value Loss: 9.213    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 36901      Buffer Size: 18921      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:48:15,868][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.391    [weighted Loss:3.391    Policy Loss: 6.010    Value Loss: 9.615    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 37237      Buffer Size: 18888      Transition Number: 1000.138k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:50:54,525][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.035    [weighted Loss:5.035    Policy Loss: 6.649    Value Loss: 9.441    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 37588      Buffer Size: 18819      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:53:34,903][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 6.344    Value Loss: 9.593    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 37955      Buffer Size: 18746      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:56:13,627][train][INFO][train.py>_log] ==> #80000      Total Loss: 4.290    [weighted Loss:4.290    Policy Loss: 6.527    Value Loss: 9.105    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 38341      Buffer Size: 18657      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 16:58:53,649][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.322    [weighted Loss:3.322    Policy Loss: 5.640    Value Loss: 9.197    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 38713      Buffer Size: 18557      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:01:31,316][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 5.709    Value Loss: 9.011    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 39060      Buffer Size: 18461      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:04:09,541][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.560    [weighted Loss:3.560    Policy Loss: 6.163    Value Loss: 8.852    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 39428      Buffer Size: 18351      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:06:52,381][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.907    [weighted Loss:4.907    Policy Loss: 5.956    Value Loss: 9.500    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 39810      Buffer Size: 18219      Transition Number: 1000.102k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:09:34,776][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 5.804    Value Loss: 9.055    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 40177      Buffer Size: 18112      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:12:15,918][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 5.864    Value Loss: 9.256    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 40538      Buffer Size: 17994      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:14:57,722][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.703    [weighted Loss:3.703    Policy Loss: 5.940    Value Loss: 8.947    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 40939      Buffer Size: 17862      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:17:40,102][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 5.540    Value Loss: 8.924    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 41317      Buffer Size: 17718      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:20:22,888][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 5.807    Value Loss: 8.576    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 41673      Buffer Size: 17564      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:23:06,597][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 5.606    Value Loss: 8.957    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 42071      Buffer Size: 17366      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:25:47,631][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.879    [weighted Loss:3.879    Policy Loss: 5.451    Value Loss: 8.647    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 42447      Buffer Size: 17216      Transition Number: 1000.131k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:28:31,896][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 5.791    Value Loss: 8.530    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 42832      Buffer Size: 17047      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:31:12,057][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 6.021    Value Loss: 8.850    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 43185      Buffer Size: 16881      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:33:54,077][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.543    [weighted Loss:3.543    Policy Loss: 5.760    Value Loss: 8.329    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 43568      Buffer Size: 16691      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:36:35,299][train][INFO][train.py>_log] ==> #95000      Total Loss: 3.518    [weighted Loss:3.518    Policy Loss: 5.747    Value Loss: 8.670    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 43973      Buffer Size: 16506      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:39:14,772][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.614    [weighted Loss:3.614    Policy Loss: 5.891    Value Loss: 8.806    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 44325      Buffer Size: 16256      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:41:58,177][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.011    [weighted Loss:4.011    Policy Loss: 5.785    Value Loss: 8.403    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 44693      Buffer Size: 16034      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:44:40,681][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.757    [weighted Loss:3.757    Policy Loss: 6.127    Value Loss: 7.820    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 45088      Buffer Size: 15789      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:47:24,761][train][INFO][train.py>_log] ==> #99000      Total Loss: 4.129    [weighted Loss:4.129    Policy Loss: 6.071    Value Loss: 8.243    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 45476      Buffer Size: 15577      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:50:08,357][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.136    [weighted Loss:4.136    Policy Loss: 6.203    Value Loss: 7.691    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 45858      Buffer Size: 15371      Transition Number: 1000.116k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:52:51,463][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.450    [weighted Loss:3.450    Policy Loss: 6.535    Value Loss: 8.146    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 46218      Buffer Size: 15234      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:55:34,162][train][INFO][train.py>_log] ==> #102000     Total Loss: 4.619    [weighted Loss:4.619    Policy Loss: 6.726    Value Loss: 8.240    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 46614      Buffer Size: 15078      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00100 
[2022-01-02 17:58:16,461][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 7.015    Value Loss: 7.547    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 46993      Buffer Size: 14976      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:01:00,447][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 7.259    Value Loss: 8.304    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 47417      Buffer Size: 14884      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:03:45,413][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.499    [weighted Loss:4.499    Policy Loss: 7.473    Value Loss: 8.427    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 47803      Buffer Size: 14864      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:06:33,411][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.704    [weighted Loss:2.704    Policy Loss: 7.738    Value Loss: 7.986    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 48243      Buffer Size: 14856      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:09:19,970][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 8.053    Value Loss: 7.954    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 48722      Buffer Size: 14899      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:12:04,075][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.163    [weighted Loss:4.163    Policy Loss: 8.901    Value Loss: 8.996    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 49223      Buffer Size: 14966      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:14:46,077][train][INFO][train.py>_log] ==> #109000     Total Loss: 5.126    [weighted Loss:5.126    Policy Loss: 8.395    Value Loss: 8.950    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 49696      Buffer Size: 15055      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:17:30,449][train][INFO][train.py>_log] ==> #110000     Total Loss: 4.447    [weighted Loss:4.447    Policy Loss: 8.556    Value Loss: 8.224    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 50187      Buffer Size: 15167      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:20:15,117][train][INFO][train.py>_log] ==> #111000     Total Loss: 5.687    [weighted Loss:5.687    Policy Loss: 8.772    Value Loss: 9.313    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 50755      Buffer Size: 15330      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:22:55,511][train][INFO][train.py>_log] ==> #112000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 8.795    Value Loss: 9.240    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 51286      Buffer Size: 15504      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:25:40,169][train][INFO][train.py>_log] ==> #113000     Total Loss: 3.279    [weighted Loss:3.279    Policy Loss: 8.980    Value Loss: 9.085    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 51878      Buffer Size: 15733      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:28:19,367][train][INFO][train.py>_log] ==> #114000     Total Loss: 5.397    [weighted Loss:5.397    Policy Loss: 8.662    Value Loss: 9.363    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 52485      Buffer Size: 15987      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:30:58,851][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.539    [weighted Loss:4.539    Policy Loss: 8.773    Value Loss: 8.728    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 53061      Buffer Size: 16222      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:33:41,406][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.757    [weighted Loss:4.757    Policy Loss: 8.164    Value Loss: 9.386    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 53661      Buffer Size: 16476      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:36:24,762][train][INFO][train.py>_log] ==> #117000     Total Loss: 5.703    [weighted Loss:5.703    Policy Loss: 8.253    Value Loss: 9.244    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 54242      Buffer Size: 16724      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:39:06,220][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 7.427    Value Loss: 8.462    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 54863      Buffer Size: 16988      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:41:46,194][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 8.118    Value Loss: 8.805    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 55384      Buffer Size: 17173      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:44:25,167][train][INFO][train.py>_log] ==> #120000     Total Loss: 5.837    [weighted Loss:5.837    Policy Loss: 7.905    Value Loss: 9.010    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 55903      Buffer Size: 17355      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:47:03,107][train][INFO][train.py>_log] ==> #121000     Total Loss: 4.043    [weighted Loss:4.043    Policy Loss: 8.340    Value Loss: 9.253    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 56424      Buffer Size: 17548      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:49:45,475][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 7.378    Value Loss: 9.015    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 56967      Buffer Size: 17744      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:52:27,469][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 7.216    Value Loss: 9.145    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 57423      Buffer Size: 17876      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:55:09,595][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.849    [weighted Loss:2.849    Policy Loss: 6.675    Value Loss: 8.963    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 57910      Buffer Size: 18018      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 18:57:50,503][train][INFO][train.py>_log] ==> #125000     Total Loss: 4.066    [weighted Loss:4.066    Policy Loss: 7.649    Value Loss: 8.966    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 58306      Buffer Size: 18100      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:00:31,225][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.673    [weighted Loss:4.673    Policy Loss: 6.753    Value Loss: 8.917    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 58702      Buffer Size: 18181      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:03:12,803][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.446    [weighted Loss:3.446    Policy Loss: 7.165    Value Loss: 9.405    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 59080      Buffer Size: 18252      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:05:54,373][train][INFO][train.py>_log] ==> #128000     Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 6.886    Value Loss: 9.306    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 59466      Buffer Size: 18315      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:08:35,164][train][INFO][train.py>_log] ==> #129000     Total Loss: 5.401    [weighted Loss:5.401    Policy Loss: 6.751    Value Loss: 8.959    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 59804      Buffer Size: 18347      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:11:14,267][train][INFO][train.py>_log] ==> #130000     Total Loss: 5.189    [weighted Loss:5.189    Policy Loss: 6.511    Value Loss: 9.680    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 60175      Buffer Size: 18400      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:13:54,726][train][INFO][train.py>_log] ==> #131000     Total Loss: 4.341    [weighted Loss:4.341    Policy Loss: 6.571    Value Loss: 9.005    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 60570      Buffer Size: 18436      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:16:35,992][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 6.873    Value Loss: 8.886    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 60934      Buffer Size: 18459      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:19:16,181][train][INFO][train.py>_log] ==> #133000     Total Loss: 4.185    [weighted Loss:4.185    Policy Loss: 6.723    Value Loss: 8.798    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 61287      Buffer Size: 18486      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:21:57,403][train][INFO][train.py>_log] ==> #134000     Total Loss: 3.467    [weighted Loss:3.467    Policy Loss: 6.353    Value Loss: 9.695    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 61649      Buffer Size: 18522      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:24:39,527][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 5.933    Value Loss: 8.773    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 62017      Buffer Size: 18556      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:27:21,139][train][INFO][train.py>_log] ==> #136000     Total Loss: 4.448    [weighted Loss:4.448    Policy Loss: 6.051    Value Loss: 8.173    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 62408      Buffer Size: 18587      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:30:00,333][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.746    [weighted Loss:3.746    Policy Loss: 5.872    Value Loss: 9.129    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 62754      Buffer Size: 18612      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:32:43,419][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 6.067    Value Loss: 8.351    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 63100      Buffer Size: 18637      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:35:22,979][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.598    [weighted Loss:3.598    Policy Loss: 6.514    Value Loss: 8.762    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 63459      Buffer Size: 18666      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:38:05,342][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.003    [weighted Loss:3.003    Policy Loss: 5.960    Value Loss: 9.132    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 63855      Buffer Size: 18693      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:40:48,546][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 6.554    Value Loss: 8.926    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 64214      Buffer Size: 18721      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:43:30,120][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.886    [weighted Loss:3.886    Policy Loss: 6.143    Value Loss: 9.226    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 64568      Buffer Size: 18743      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:46:12,134][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 6.132    Value Loss: 9.227    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 64965      Buffer Size: 18759      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:48:53,728][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 6.156    Value Loss: 8.952    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 65345      Buffer Size: 18785      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:51:37,531][train][INFO][train.py>_log] ==> #145000     Total Loss: 4.230    [weighted Loss:4.230    Policy Loss: 6.079    Value Loss: 8.320    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 65690      Buffer Size: 18781      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:54:21,586][train][INFO][train.py>_log] ==> #146000     Total Loss: 4.834    [weighted Loss:4.834    Policy Loss: 6.235    Value Loss: 8.777    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 66047      Buffer Size: 18766      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:57:04,068][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.872    [weighted Loss:2.872    Policy Loss: 6.569    Value Loss: 8.563    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 66437      Buffer Size: 18718      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00100 
[2022-01-02 19:59:47,252][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 6.023    Value Loss: 8.573    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 66815      Buffer Size: 18664      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:02:29,473][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.202    [weighted Loss:3.202    Policy Loss: 6.397    Value Loss: 8.860    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 67178      Buffer Size: 18575      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:05:12,603][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.731    [weighted Loss:3.731    Policy Loss: 6.292    Value Loss: 8.482    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 67537      Buffer Size: 18451      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:07:55,502][train][INFO][train.py>_log] ==> #151000     Total Loss: 3.860    [weighted Loss:3.860    Policy Loss: 6.401    Value Loss: 8.788    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 67927      Buffer Size: 18303      Transition Number: 1000.274k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:10:39,253][train][INFO][train.py>_log] ==> #152000     Total Loss: 4.445    [weighted Loss:4.445    Policy Loss: 6.048    Value Loss: 8.698    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 68272      Buffer Size: 18149      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:13:22,511][train][INFO][train.py>_log] ==> #153000     Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 6.183    Value Loss: 9.159    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 68635      Buffer Size: 17982      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:16:03,929][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 6.351    Value Loss: 8.192    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 69014      Buffer Size: 17783      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:18:44,307][train][INFO][train.py>_log] ==> #155000     Total Loss: 4.016    [weighted Loss:4.016    Policy Loss: 6.736    Value Loss: 9.350    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 69375      Buffer Size: 17542      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:21:27,350][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 6.357    Value Loss: 8.937    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 69749      Buffer Size: 17284      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:24:09,235][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.605    [weighted Loss:3.605    Policy Loss: 6.499    Value Loss: 8.362    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 70087      Buffer Size: 17052      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:26:52,051][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.926    [weighted Loss:3.926    Policy Loss: 6.079    Value Loss: 8.909    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 70442      Buffer Size: 16796      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:29:36,390][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.796    [weighted Loss:3.796    Policy Loss: 6.568    Value Loss: 9.419    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 70824      Buffer Size: 16535      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:32:18,280][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.974    [weighted Loss:2.974    Policy Loss: 6.365    Value Loss: 9.085    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 71209      Buffer Size: 16275      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:34:59,871][train][INFO][train.py>_log] ==> #161000     Total Loss: 4.177    [weighted Loss:4.177    Policy Loss: 6.828    Value Loss: 9.656    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 71559      Buffer Size: 16109      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:37:40,774][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 6.621    Value Loss: 8.694    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 71898      Buffer Size: 15957      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:40:24,476][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.704    [weighted Loss:2.704    Policy Loss: 6.598    Value Loss: 9.141    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 72287      Buffer Size: 15816      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:43:05,900][train][INFO][train.py>_log] ==> #164000     Total Loss: 4.895    [weighted Loss:4.895    Policy Loss: 7.166    Value Loss: 8.958    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 72687      Buffer Size: 15683      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:45:50,645][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.153    [weighted Loss:3.153    Policy Loss: 7.550    Value Loss: 8.989    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 73097      Buffer Size: 15626      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:48:33,189][train][INFO][train.py>_log] ==> #166000     Total Loss: 4.350    [weighted Loss:4.350    Policy Loss: 7.446    Value Loss: 8.492    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 73492      Buffer Size: 15575      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:51:18,204][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 8.237    Value Loss: 8.646    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 73944      Buffer Size: 15605      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:54:06,446][train][INFO][train.py>_log] ==> #168000     Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 7.942    Value Loss: 8.806    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 74400      Buffer Size: 15637      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:56:49,932][train][INFO][train.py>_log] ==> #169000     Total Loss: 3.842    [weighted Loss:3.842    Policy Loss: 8.969    Value Loss: 8.927    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 74852      Buffer Size: 15694      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00100 
[2022-01-02 20:59:31,944][train][INFO][train.py>_log] ==> #170000     Total Loss: 3.738    [weighted Loss:3.738    Policy Loss: 8.732    Value Loss: 8.921    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 75316      Buffer Size: 15788      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:02:16,121][train][INFO][train.py>_log] ==> #171000     Total Loss: 5.205    [weighted Loss:5.205    Policy Loss: 10.726   Value Loss: 9.370    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 75876      Buffer Size: 15974      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:05:00,771][train][INFO][train.py>_log] ==> #172000     Total Loss: 5.323    [weighted Loss:5.323    Policy Loss: 9.686    Value Loss: 8.565    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 76442      Buffer Size: 16148      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:07:44,391][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 9.693    Value Loss: 9.175    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 77030      Buffer Size: 16373      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:10:28,205][train][INFO][train.py>_log] ==> #174000     Total Loss: 4.373    [weighted Loss:4.373    Policy Loss: 10.455   Value Loss: 9.180    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 77652      Buffer Size: 16624      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:13:11,770][train][INFO][train.py>_log] ==> #175000     Total Loss: 4.337    [weighted Loss:4.337    Policy Loss: 9.810    Value Loss: 8.982    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 78360      Buffer Size: 16962      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:15:50,589][train][INFO][train.py>_log] ==> #176000     Total Loss: 4.652    [weighted Loss:4.652    Policy Loss: 10.118   Value Loss: 8.818    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 79071      Buffer Size: 17304      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:18:30,188][train][INFO][train.py>_log] ==> #177000     Total Loss: 4.379    [weighted Loss:4.379    Policy Loss: 10.008   Value Loss: 8.759    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 79786      Buffer Size: 17663      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:21:09,992][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 9.849    Value Loss: 9.393    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 80532      Buffer Size: 18041      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:23:50,768][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 9.503    Value Loss: 9.113    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 81169      Buffer Size: 18328      Transition Number: 999.927 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:26:31,926][train][INFO][train.py>_log] ==> #180000     Total Loss: 4.708    [weighted Loss:4.708    Policy Loss: 8.520    Value Loss: 9.188    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 81833      Buffer Size: 18623      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:29:12,720][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 8.727    Value Loss: 8.917    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 82350      Buffer Size: 18794      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:31:51,573][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 8.507    Value Loss: 8.657    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 82868      Buffer Size: 18963      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:34:31,501][train][INFO][train.py>_log] ==> #183000     Total Loss: 4.252    [weighted Loss:4.252    Policy Loss: 8.131    Value Loss: 9.382    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 83339      Buffer Size: 19084      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:37:13,615][train][INFO][train.py>_log] ==> #184000     Total Loss: 4.908    [weighted Loss:4.908    Policy Loss: 8.444    Value Loss: 8.863    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 83818      Buffer Size: 19211      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:39:56,112][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 8.074    Value Loss: 8.470    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 84265      Buffer Size: 19317      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:42:38,062][train][INFO][train.py>_log] ==> #186000     Total Loss: 4.636    [weighted Loss:4.636    Policy Loss: 8.399    Value Loss: 9.271    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 84721      Buffer Size: 19414      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:45:17,969][train][INFO][train.py>_log] ==> #187000     Total Loss: 4.401    [weighted Loss:4.401    Policy Loss: 8.221    Value Loss: 8.954    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 85152      Buffer Size: 19505      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:48:02,342][train][INFO][train.py>_log] ==> #188000     Total Loss: 4.942    [weighted Loss:4.942    Policy Loss: 8.171    Value Loss: 8.851    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 85594      Buffer Size: 19609      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:50:43,991][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.194    [weighted Loss:3.194    Policy Loss: 7.902    Value Loss: 8.819    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 86047      Buffer Size: 19703      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:53:24,395][train][INFO][train.py>_log] ==> #190000     Total Loss: 4.177    [weighted Loss:4.177    Policy Loss: 7.653    Value Loss: 8.331    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 86454      Buffer Size: 19776      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:56:05,124][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.616    [weighted Loss:3.616    Policy Loss: 8.240    Value Loss: 8.926    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 86857      Buffer Size: 19833      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 21:58:46,456][train][INFO][train.py>_log] ==> #192000     Total Loss: 4.678    [weighted Loss:4.678    Policy Loss: 7.454    Value Loss: 8.359    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 87246      Buffer Size: 19886      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:01:29,226][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.486    [weighted Loss:3.486    Policy Loss: 7.685    Value Loss: 8.455    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 87653      Buffer Size: 19960      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:04:11,815][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.137    [weighted Loss:3.137    Policy Loss: 7.763    Value Loss: 8.470    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 88075      Buffer Size: 20041      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:06:57,215][train][INFO][train.py>_log] ==> #195000     Total Loss: 4.474    [weighted Loss:4.474    Policy Loss: 7.325    Value Loss: 8.375    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 88488      Buffer Size: 20100      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:09:39,295][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.170    [weighted Loss:3.170    Policy Loss: 6.963    Value Loss: 7.932    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 88906      Buffer Size: 20187      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:12:22,056][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.274    [weighted Loss:3.274    Policy Loss: 6.467    Value Loss: 7.602    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 89306      Buffer Size: 20265      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:15:02,786][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.141    [weighted Loss:3.141    Policy Loss: 6.464    Value Loss: 8.145    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 89727      Buffer Size: 20359      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:17:41,161][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 5.867    Value Loss: 7.762    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 90128      Buffer Size: 20426      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:20:22,153][train][INFO][train.py>_log] ==> #200000     Total Loss: 3.978    [weighted Loss:3.978    Policy Loss: 6.634    Value Loss: 8.033    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 90543      Buffer Size: 20495      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:23:03,133][train][INFO][train.py>_log] ==> #201000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 5.867    Value Loss: 7.828    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 90935      Buffer Size: 20558      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:25:44,610][train][INFO][train.py>_log] ==> #202000     Total Loss: 4.507    [weighted Loss:4.507    Policy Loss: 6.164    Value Loss: 8.021    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 91336      Buffer Size: 20620      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:28:27,414][train][INFO][train.py>_log] ==> #203000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 5.937    Value Loss: 7.207    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 91748      Buffer Size: 20677      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:31:09,559][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.416    [weighted Loss:3.416    Policy Loss: 5.381    Value Loss: 7.341    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 92146      Buffer Size: 20721      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:33:50,576][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.210    [weighted Loss:2.210    Policy Loss: 5.444    Value Loss: 7.260    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 92519      Buffer Size: 20769      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:36:31,730][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 5.679    Value Loss: 7.581    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 92929      Buffer Size: 20807      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:39:14,192][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 5.668    Value Loss: 7.650    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 93327      Buffer Size: 20822      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:41:54,313][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 5.546    Value Loss: 7.469    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 93707      Buffer Size: 20821      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:44:37,593][train][INFO][train.py>_log] ==> #209000     Total Loss: 3.226    [weighted Loss:3.226    Policy Loss: 5.328    Value Loss: 7.414    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 94071      Buffer Size: 20810      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:47:20,566][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 5.632    Value Loss: 8.088    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 94477      Buffer Size: 20792      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:50:04,356][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 5.706    Value Loss: 7.753    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 94871      Buffer Size: 20743      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:52:51,177][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.483    [weighted Loss:3.483    Policy Loss: 5.545    Value Loss: 8.288    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 95301      Buffer Size: 20679      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:55:36,488][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 5.687    Value Loss: 8.112    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 95677      Buffer Size: 20613      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 22:58:22,053][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.612    [weighted Loss:1.612    Policy Loss: 5.213    Value Loss: 7.867    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 96060      Buffer Size: 20488      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:01:07,103][train][INFO][train.py>_log] ==> #215000     Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 5.286    Value Loss: 7.953    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 96480      Buffer Size: 20348      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:03:51,084][train][INFO][train.py>_log] ==> #216000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 5.219    Value Loss: 7.964    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 96883      Buffer Size: 20203      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:06:35,320][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 5.557    Value Loss: 7.514    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 97284      Buffer Size: 20031      Transition Number: 1000.192k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:09:18,083][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 5.747    Value Loss: 8.564    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 97668      Buffer Size: 19854      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:12:00,465][train][INFO][train.py>_log] ==> #219000     Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 5.380    Value Loss: 7.743    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 98079      Buffer Size: 19631      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:14:41,932][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.813    [weighted Loss:3.813    Policy Loss: 5.674    Value Loss: 8.027    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 98516      Buffer Size: 19392      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:17:24,274][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.672    [weighted Loss:2.672    Policy Loss: 5.621    Value Loss: 7.834    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 98934      Buffer Size: 19144      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:20:07,849][train][INFO][train.py>_log] ==> #222000     Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 5.995    Value Loss: 7.722    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 99411      Buffer Size: 18863      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:22:48,113][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.668    [weighted Loss:3.668    Policy Loss: 5.798    Value Loss: 7.850    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 99892      Buffer Size: 18737      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:25:29,286][train][INFO][train.py>_log] ==> #224000     Total Loss: 3.186    [weighted Loss:3.186    Policy Loss: 6.084    Value Loss: 8.052    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 100405     Buffer Size: 18647      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:28:11,026][train][INFO][train.py>_log] ==> #225000     Total Loss: 4.381    [weighted Loss:4.381    Policy Loss: 6.084    Value Loss: 8.051    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 100952     Buffer Size: 18690      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:30:54,684][train][INFO][train.py>_log] ==> #226000     Total Loss: 4.116    [weighted Loss:4.116    Policy Loss: 6.452    Value Loss: 7.838    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 101538     Buffer Size: 18769      Transition Number: 1000.149k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:33:37,204][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.844    [weighted Loss:3.844    Policy Loss: 6.311    Value Loss: 7.628    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 102240     Buffer Size: 18954      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:36:17,530][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 6.503    Value Loss: 8.476    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 102940     Buffer Size: 19158      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:39:02,508][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.522    [weighted Loss:2.522    Policy Loss: 6.769    Value Loss: 7.967    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 103690     Buffer Size: 19432      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:41:43,179][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 6.400    Value Loss: 7.845    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 104417     Buffer Size: 19705      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:44:25,392][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 7.305    Value Loss: 8.079    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 105143     Buffer Size: 19962      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:47:05,631][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.844    [weighted Loss:2.844    Policy Loss: 7.323    Value Loss: 7.811    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 105831     Buffer Size: 20206      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:49:47,795][train][INFO][train.py>_log] ==> #233000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 7.918    Value Loss: 7.955    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 106595     Buffer Size: 20530      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:52:29,803][train][INFO][train.py>_log] ==> #234000     Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 7.327    Value Loss: 8.032    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 107390     Buffer Size: 20873      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:55:10,314][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 7.360    Value Loss: 8.182    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 108369     Buffer Size: 21405      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00100 
[2022-01-02 23:57:50,349][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 8.368    Value Loss: 7.939    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 109310     Buffer Size: 21920      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:00:31,319][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 8.615    Value Loss: 8.509    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 110397     Buffer Size: 22552      Transition Number: 999.932 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:03:10,758][train][INFO][train.py>_log] ==> #238000     Total Loss: 5.714    [weighted Loss:5.714    Policy Loss: 8.046    Value Loss: 7.780    Reward Loss: 1.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 111509     Buffer Size: 23231      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:05:50,942][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.085    [weighted Loss:2.085    Policy Loss: 9.047    Value Loss: 7.592    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 112816     Buffer Size: 24084      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:08:33,066][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.896    [weighted Loss:3.896    Policy Loss: 8.348    Value Loss: 7.543    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 114114     Buffer Size: 24923      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:11:12,606][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 9.915    Value Loss: 7.930    Reward Loss: 1.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 115544     Buffer Size: 25894      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:13:50,802][train][INFO][train.py>_log] ==> #242000     Total Loss: 4.271    [weighted Loss:4.271    Policy Loss: 8.674    Value Loss: 7.295    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 117043     Buffer Size: 26941      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:16:28,666][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 9.483    Value Loss: 7.647    Reward Loss: 1.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 118702     Buffer Size: 28161      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:19:05,669][train][INFO][train.py>_log] ==> #244000     Total Loss: 5.083    [weighted Loss:5.083    Policy Loss: 9.607    Value Loss: 7.508    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 120399     Buffer Size: 29424      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:21:42,970][train][INFO][train.py>_log] ==> #245000     Total Loss: 4.592    [weighted Loss:4.592    Policy Loss: 8.985    Value Loss: 7.741    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 121716     Buffer Size: 30335      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:24:18,514][train][INFO][train.py>_log] ==> #246000     Total Loss: 5.329    [weighted Loss:5.329    Policy Loss: 9.389    Value Loss: 7.656    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 123053     Buffer Size: 31252      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:26:55,623][train][INFO][train.py>_log] ==> #247000     Total Loss: 3.360    [weighted Loss:3.360    Policy Loss: 8.996    Value Loss: 7.013    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 124165     Buffer Size: 31962      Transition Number: 1000.130k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:29:30,809][train][INFO][train.py>_log] ==> #248000     Total Loss: 4.525    [weighted Loss:4.525    Policy Loss: 8.087    Value Loss: 7.448    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 125312     Buffer Size: 32677      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:32:05,940][train][INFO][train.py>_log] ==> #249000     Total Loss: 5.664    [weighted Loss:5.664    Policy Loss: 9.185    Value Loss: 7.460    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 126248     Buffer Size: 33218      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:34:42,998][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.911    [weighted Loss:3.911    Policy Loss: 8.878    Value Loss: 7.281    Reward Loss: 1.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 127193     Buffer Size: 33763      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:37:18,406][train][INFO][train.py>_log] ==> #251000     Total Loss: 4.786    [weighted Loss:4.786    Policy Loss: 8.168    Value Loss: 7.353    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 128117     Buffer Size: 34289      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:39:54,571][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.613    [weighted Loss:2.613    Policy Loss: 8.374    Value Loss: 7.070    Reward Loss: 1.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 129072     Buffer Size: 34820      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:42:31,766][train][INFO][train.py>_log] ==> #253000     Total Loss: 4.158    [weighted Loss:4.158    Policy Loss: 8.081    Value Loss: 7.202    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 129885     Buffer Size: 35238      Transition Number: 1000.074k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:45:07,551][train][INFO][train.py>_log] ==> #254000     Total Loss: 3.731    [weighted Loss:3.731    Policy Loss: 8.094    Value Loss: 7.454    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 130722     Buffer Size: 35675      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:47:44,862][train][INFO][train.py>_log] ==> #255000     Total Loss: 4.027    [weighted Loss:4.027    Policy Loss: 7.240    Value Loss: 7.173    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 131393     Buffer Size: 35955      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:50:22,887][train][INFO][train.py>_log] ==> #256000     Total Loss: 4.073    [weighted Loss:4.073    Policy Loss: 7.955    Value Loss: 7.147    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 132117     Buffer Size: 36276      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:52:57,971][train][INFO][train.py>_log] ==> #257000     Total Loss: 3.911    [weighted Loss:3.911    Policy Loss: 8.354    Value Loss: 7.220    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 132747     Buffer Size: 36522      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:55:35,759][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 7.867    Value Loss: 6.875    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 133406     Buffer Size: 36763      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 00:58:14,020][train][INFO][train.py>_log] ==> #259000     Total Loss: 3.950    [weighted Loss:3.950    Policy Loss: 8.673    Value Loss: 7.316    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 134005     Buffer Size: 36964      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:00:48,303][train][INFO][train.py>_log] ==> #260000     Total Loss: 5.001    [weighted Loss:5.001    Policy Loss: 8.508    Value Loss: 6.854    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 134587     Buffer Size: 37146      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:03:23,747][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 9.035    Value Loss: 6.813    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 135065     Buffer Size: 37235      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:06:00,920][train][INFO][train.py>_log] ==> #262000     Total Loss: 3.600    [weighted Loss:3.600    Policy Loss: 8.340    Value Loss: 6.587    Reward Loss: 1.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 135549     Buffer Size: 37298      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:08:39,084][train][INFO][train.py>_log] ==> #263000     Total Loss: 3.883    [weighted Loss:3.883    Policy Loss: 8.166    Value Loss: 6.472    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 136082     Buffer Size: 37365      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:11:16,367][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 8.758    Value Loss: 6.514    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 136593     Buffer Size: 37439      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:13:52,597][train][INFO][train.py>_log] ==> #265000     Total Loss: 4.423    [weighted Loss:4.423    Policy Loss: 8.405    Value Loss: 6.356    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 137064     Buffer Size: 37470      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:16:30,624][train][INFO][train.py>_log] ==> #266000     Total Loss: 4.725    [weighted Loss:4.725    Policy Loss: 8.585    Value Loss: 6.178    Reward Loss: 1.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 137590     Buffer Size: 37488      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:19:07,254][train][INFO][train.py>_log] ==> #267000     Total Loss: 4.387    [weighted Loss:4.387    Policy Loss: 9.100    Value Loss: 6.299    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 138082     Buffer Size: 37445      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:21:44,829][train][INFO][train.py>_log] ==> #268000     Total Loss: 5.034    [weighted Loss:5.034    Policy Loss: 10.133   Value Loss: 5.962    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 138576     Buffer Size: 37348      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:24:22,146][train][INFO][train.py>_log] ==> #269000     Total Loss: 4.965    [weighted Loss:4.965    Policy Loss: 9.802    Value Loss: 5.803    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 139069     Buffer Size: 37244      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:27:05,214][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 10.001   Value Loss: 5.679    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 139590     Buffer Size: 37077      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:29:41,093][train][INFO][train.py>_log] ==> #271000     Total Loss: 4.789    [weighted Loss:4.789    Policy Loss: 11.050   Value Loss: 5.947    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 140085     Buffer Size: 36895      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:32:17,670][train][INFO][train.py>_log] ==> #272000     Total Loss: 4.827    [weighted Loss:4.827    Policy Loss: 11.357   Value Loss: 5.446    Reward Loss: 1.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 140597     Buffer Size: 36679      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:34:56,827][train][INFO][train.py>_log] ==> #273000     Total Loss: 5.503    [weighted Loss:5.503    Policy Loss: 10.296   Value Loss: 5.662    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 141067     Buffer Size: 36484      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:37:32,815][train][INFO][train.py>_log] ==> #274000     Total Loss: 4.353    [weighted Loss:4.353    Policy Loss: 10.748   Value Loss: 5.472    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 141557     Buffer Size: 36301      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:40:10,012][train][INFO][train.py>_log] ==> #275000     Total Loss: 3.651    [weighted Loss:3.651    Policy Loss: 10.869   Value Loss: 5.701    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 142071     Buffer Size: 36141      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:42:49,156][train][INFO][train.py>_log] ==> #276000     Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 11.029   Value Loss: 5.430    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 142562     Buffer Size: 35902      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:45:28,898][train][INFO][train.py>_log] ==> #277000     Total Loss: 6.047    [weighted Loss:6.047    Policy Loss: 9.675    Value Loss: 5.746    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 143079     Buffer Size: 35670      Transition Number: 1000.150k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:48:06,163][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 9.909    Value Loss: 5.557    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 143551     Buffer Size: 35271      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:50:44,387][train][INFO][train.py>_log] ==> #279000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 10.498   Value Loss: 5.673    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 144088     Buffer Size: 34907      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:53:23,655][train][INFO][train.py>_log] ==> #280000     Total Loss: 5.499    [weighted Loss:5.499    Policy Loss: 9.715    Value Loss: 6.118    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 144610     Buffer Size: 34475      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:55:59,951][train][INFO][train.py>_log] ==> #281000     Total Loss: 4.677    [weighted Loss:4.677    Policy Loss: 10.214   Value Loss: 5.853    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 145143     Buffer Size: 33993      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00100 
[2022-01-03 01:58:38,023][train][INFO][train.py>_log] ==> #282000     Total Loss: 4.969    [weighted Loss:4.969    Policy Loss: 9.921    Value Loss: 5.975    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 145691     Buffer Size: 33417      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:01:14,253][train][INFO][train.py>_log] ==> #283000     Total Loss: 4.465    [weighted Loss:4.465    Policy Loss: 9.658    Value Loss: 6.274    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 146282     Buffer Size: 32836      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:03:50,733][train][INFO][train.py>_log] ==> #284000     Total Loss: 1.301    [weighted Loss:1.301    Policy Loss: 10.171   Value Loss: 6.204    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 146870     Buffer Size: 32207      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:06:31,306][train][INFO][train.py>_log] ==> #285000     Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 9.534    Value Loss: 6.214    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 147440     Buffer Size: 31490      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:09:09,209][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.364    [weighted Loss:3.364    Policy Loss: 10.352   Value Loss: 6.287    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 148028     Buffer Size: 30707      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:11:51,239][train][INFO][train.py>_log] ==> #287000     Total Loss: 4.660    [weighted Loss:4.660    Policy Loss: 10.267   Value Loss: 6.614    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 148570     Buffer Size: 29730      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:14:28,278][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 10.037   Value Loss: 6.116    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 149099     Buffer Size: 28709      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:17:07,898][train][INFO][train.py>_log] ==> #289000     Total Loss: 3.831    [weighted Loss:3.831    Policy Loss: 9.558    Value Loss: 6.368    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 149573     Buffer Size: 27949      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:19:48,673][train][INFO][train.py>_log] ==> #290000     Total Loss: 4.390    [weighted Loss:4.390    Policy Loss: 9.200    Value Loss: 6.311    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 150080     Buffer Size: 27232      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:22:30,434][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.861    [weighted Loss:2.861    Policy Loss: 9.198    Value Loss: 5.812    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 150599     Buffer Size: 26610      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:25:08,783][train][INFO][train.py>_log] ==> #292000     Total Loss: 4.977    [weighted Loss:4.977    Policy Loss: 9.715    Value Loss: 6.499    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 151086     Buffer Size: 26031      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:27:46,967][train][INFO][train.py>_log] ==> #293000     Total Loss: 4.300    [weighted Loss:4.300    Policy Loss: 9.434    Value Loss: 6.537    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 151536     Buffer Size: 25595      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:30:27,493][train][INFO][train.py>_log] ==> #294000     Total Loss: 3.861    [weighted Loss:3.861    Policy Loss: 8.947    Value Loss: 6.321    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 152006     Buffer Size: 25148      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:33:10,960][train][INFO][train.py>_log] ==> #295000     Total Loss: 4.394    [weighted Loss:4.394    Policy Loss: 9.215    Value Loss: 6.254    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 152475     Buffer Size: 24741      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:35:50,678][train][INFO][train.py>_log] ==> #296000     Total Loss: 4.466    [weighted Loss:4.466    Policy Loss: 9.173    Value Loss: 6.802    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 152950     Buffer Size: 24329      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:38:31,845][train][INFO][train.py>_log] ==> #297000     Total Loss: 4.251    [weighted Loss:4.251    Policy Loss: 8.020    Value Loss: 6.925    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 153397     Buffer Size: 23956      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:41:16,408][train][INFO][train.py>_log] ==> #298000     Total Loss: 4.216    [weighted Loss:4.216    Policy Loss: 8.624    Value Loss: 6.471    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 153863     Buffer Size: 23604      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:43:59,134][train][INFO][train.py>_log] ==> #299000     Total Loss: 3.197    [weighted Loss:3.197    Policy Loss: 8.133    Value Loss: 6.654    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 154341     Buffer Size: 23312      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:46:45,498][train][INFO][train.py>_log] ==> #300000     Total Loss: 3.615    [weighted Loss:3.615    Policy Loss: 8.249    Value Loss: 6.527    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 154851     Buffer Size: 23118      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:49:26,388][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 7.473    Value Loss: 6.960    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 155289     Buffer Size: 22931      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:52:07,681][train][INFO][train.py>_log] ==> #302000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 7.285    Value Loss: 6.737    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 155766     Buffer Size: 22773      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:54:50,467][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 7.295    Value Loss: 6.850    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 156206     Buffer Size: 22586      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00100 
[2022-01-03 02:57:33,324][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.370    [weighted Loss:1.370    Policy Loss: 6.425    Value Loss: 6.841    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 156632     Buffer Size: 22466      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:00:18,054][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 7.258    Value Loss: 6.875    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 157067     Buffer Size: 22357      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:03:02,802][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.999    [weighted Loss:1.999    Policy Loss: 6.616    Value Loss: 6.841    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 157515     Buffer Size: 22298      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:05:46,981][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 7.563    Value Loss: 7.156    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 157982     Buffer Size: 22258      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:08:29,891][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 7.002    Value Loss: 7.161    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 158421     Buffer Size: 22189      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:11:14,716][train][INFO][train.py>_log] ==> #309000     Total Loss: 3.286    [weighted Loss:3.286    Policy Loss: 6.495    Value Loss: 6.914    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 158902     Buffer Size: 22157      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:13:58,563][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.513    [weighted Loss:3.513    Policy Loss: 7.106    Value Loss: 7.330    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 159375     Buffer Size: 22148      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:16:40,526][train][INFO][train.py>_log] ==> #311000     Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 7.134    Value Loss: 7.156    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 159838     Buffer Size: 22098      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:19:23,794][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 7.119    Value Loss: 7.259    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 160296     Buffer Size: 22054      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:22:03,659][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.947    [weighted Loss:3.947    Policy Loss: 7.358    Value Loss: 7.495    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 160714     Buffer Size: 22023      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:24:49,244][train][INFO][train.py>_log] ==> #314000     Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 7.348    Value Loss: 7.385    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 161194     Buffer Size: 21986      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:27:30,657][train][INFO][train.py>_log] ==> #315000     Total Loss: 3.449    [weighted Loss:3.449    Policy Loss: 6.863    Value Loss: 7.485    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 161658     Buffer Size: 21950      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:30:14,302][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 7.336    Value Loss: 7.541    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 162143     Buffer Size: 21918      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:32:58,807][train][INFO][train.py>_log] ==> #317000     Total Loss: 3.853    [weighted Loss:3.853    Policy Loss: 7.583    Value Loss: 7.498    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 162577     Buffer Size: 21857      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:35:44,447][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.324    [weighted Loss:2.324    Policy Loss: 7.091    Value Loss: 7.686    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 163047     Buffer Size: 21820      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:38:28,021][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 7.131    Value Loss: 7.320    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 163517     Buffer Size: 21789      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:41:12,826][train][INFO][train.py>_log] ==> #320000     Total Loss: 4.021    [weighted Loss:4.021    Policy Loss: 7.005    Value Loss: 7.586    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 163990     Buffer Size: 21754      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:43:59,506][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 7.384    Value Loss: 8.009    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 164446     Buffer Size: 21687      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:46:48,233][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 6.574    Value Loss: 7.306    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 164938     Buffer Size: 21663      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:49:29,315][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.894    [weighted Loss:2.894    Policy Loss: 7.087    Value Loss: 8.054    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 165406     Buffer Size: 21633      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:52:17,088][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 6.504    Value Loss: 7.751    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 165920     Buffer Size: 21580      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:55:02,286][train][INFO][train.py>_log] ==> #325000     Total Loss: 3.590    [weighted Loss:3.590    Policy Loss: 7.453    Value Loss: 7.769    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 166372     Buffer Size: 21513      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 03:57:45,256][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 7.447    Value Loss: 7.692    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 166865     Buffer Size: 21442      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:00:30,139][train][INFO][train.py>_log] ==> #327000     Total Loss: 3.723    [weighted Loss:3.723    Policy Loss: 7.069    Value Loss: 7.837    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 167349     Buffer Size: 21340      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:03:15,742][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 6.772    Value Loss: 7.902    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 167817     Buffer Size: 21211      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:06:04,325][train][INFO][train.py>_log] ==> #329000     Total Loss: 3.895    [weighted Loss:3.895    Policy Loss: 7.328    Value Loss: 7.540    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 168313     Buffer Size: 21093      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:08:51,605][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 6.894    Value Loss: 7.907    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 168786     Buffer Size: 20957      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:11:38,557][train][INFO][train.py>_log] ==> #331000     Total Loss: 3.974    [weighted Loss:3.974    Policy Loss: 7.477    Value Loss: 7.743    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 169269     Buffer Size: 20871      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:14:26,365][train][INFO][train.py>_log] ==> #332000     Total Loss: 3.127    [weighted Loss:3.127    Policy Loss: 6.854    Value Loss: 7.802    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 169746     Buffer Size: 20789      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:17:14,980][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.822    [weighted Loss:3.822    Policy Loss: 6.927    Value Loss: 7.903    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 170197     Buffer Size: 20729      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:19:59,521][train][INFO][train.py>_log] ==> #334000     Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 6.853    Value Loss: 7.978    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 170634     Buffer Size: 20660      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:22:48,365][train][INFO][train.py>_log] ==> #335000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 6.359    Value Loss: 8.022    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 171090     Buffer Size: 20565      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:25:37,552][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 6.518    Value Loss: 7.720    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 171540     Buffer Size: 20523      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:28:27,183][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.702    [weighted Loss:3.702    Policy Loss: 6.487    Value Loss: 7.670    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 171974     Buffer Size: 20473      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:31:14,474][train][INFO][train.py>_log] ==> #338000     Total Loss: 3.758    [weighted Loss:3.758    Policy Loss: 6.792    Value Loss: 7.838    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 172450     Buffer Size: 20439      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:34:00,440][train][INFO][train.py>_log] ==> #339000     Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 6.109    Value Loss: 7.528    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 172892     Buffer Size: 20387      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:36:46,788][train][INFO][train.py>_log] ==> #340000     Total Loss: 3.305    [weighted Loss:3.305    Policy Loss: 6.371    Value Loss: 7.861    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 173329     Buffer Size: 20355      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:39:31,548][train][INFO][train.py>_log] ==> #341000     Total Loss: 3.682    [weighted Loss:3.682    Policy Loss: 6.610    Value Loss: 7.715    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 173757     Buffer Size: 20330      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:42:20,233][train][INFO][train.py>_log] ==> #342000     Total Loss: 4.438    [weighted Loss:4.438    Policy Loss: 6.913    Value Loss: 7.967    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 174215     Buffer Size: 20317      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:45:07,663][train][INFO][train.py>_log] ==> #343000     Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 6.883    Value Loss: 7.976    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 174684     Buffer Size: 20275      Transition Number: 999.927 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:47:55,573][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 7.032    Value Loss: 8.120    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 175110     Buffer Size: 20218      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:50:45,025][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 6.329    Value Loss: 7.724    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 175563     Buffer Size: 20180      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:53:33,019][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.549    [weighted Loss:2.549    Policy Loss: 7.103    Value Loss: 8.269    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 176018     Buffer Size: 20155      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:56:26,505][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 6.686    Value Loss: 7.571    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 176483     Buffer Size: 20153      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-01-03 04:59:15,197][train][INFO][train.py>_log] ==> #348000     Total Loss: 3.114    [weighted Loss:3.114    Policy Loss: 6.895    Value Loss: 8.059    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 176947     Buffer Size: 20157      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:02:03,760][train][INFO][train.py>_log] ==> #349000     Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 6.672    Value Loss: 7.738    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 177386     Buffer Size: 20157      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:04:54,494][train][INFO][train.py>_log] ==> #350000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 6.916    Value Loss: 8.068    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 177875     Buffer Size: 20166      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:07:41,766][train][INFO][train.py>_log] ==> #351000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 7.211    Value Loss: 8.594    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 178338     Buffer Size: 20161      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:10:32,041][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 6.483    Value Loss: 8.250    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 178817     Buffer Size: 20152      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:13:20,122][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 7.020    Value Loss: 8.068    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 179254     Buffer Size: 20115      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:16:08,897][train][INFO][train.py>_log] ==> #354000     Total Loss: 3.250    [weighted Loss:3.250    Policy Loss: 7.018    Value Loss: 8.446    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 179730     Buffer Size: 20091      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:18:55,597][train][INFO][train.py>_log] ==> #355000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 6.886    Value Loss: 8.338    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 180163     Buffer Size: 20054      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:21:40,372][train][INFO][train.py>_log] ==> #356000     Total Loss: 3.379    [weighted Loss:3.379    Policy Loss: 6.747    Value Loss: 8.356    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 180589     Buffer Size: 20029      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:24:28,244][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.428    [weighted Loss:3.428    Policy Loss: 6.783    Value Loss: 8.201    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 181009     Buffer Size: 19996      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:27:15,500][train][INFO][train.py>_log] ==> #358000     Total Loss: 3.614    [weighted Loss:3.614    Policy Loss: 6.916    Value Loss: 8.171    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 181451     Buffer Size: 19945      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:30:03,707][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 6.573    Value Loss: 8.230    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 181904     Buffer Size: 19905      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:32:52,363][train][INFO][train.py>_log] ==> #360000     Total Loss: 3.576    [weighted Loss:3.576    Policy Loss: 6.602    Value Loss: 8.418    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 182343     Buffer Size: 19890      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:35:40,906][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 6.417    Value Loss: 8.316    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 182776     Buffer Size: 19864      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:38:26,095][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.527    [weighted Loss:2.527    Policy Loss: 6.795    Value Loss: 8.337    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 183215     Buffer Size: 19835      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:41:12,765][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.992    [weighted Loss:2.992    Policy Loss: 6.772    Value Loss: 8.164    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 183678     Buffer Size: 19796      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00100 
[2022-01-03 05:43:58,263][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 6.535    Value Loss: 7.977    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 184149     Buffer Size: 19801      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00100 
