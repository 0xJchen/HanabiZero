[2022-01-19 10:03:59,799][train][INFO][train.py>_log] ==> #0          Total Loss: 49.252   [weighted Loss:49.252   Policy Loss: 14.780   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 886        Buffer Size: 886        Transition Number: 10.898  k Batch Size: 256        Lr: 0.00000 
[2022-01-19 10:06:09,497][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.611    [weighted Loss:4.611    Policy Loss: 14.196   Value Loss: 3.645    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 2606       Buffer Size: 2606       Transition Number: 32.536  k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:08:09,441][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 13.421   Value Loss: 3.191    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 4275       Buffer Size: 4275       Transition Number: 53.728  k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:10:11,188][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.003    [weighted Loss:6.003    Policy Loss: 13.358   Value Loss: 2.955    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 6017       Buffer Size: 6017       Transition Number: 74.565  k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:12:16,018][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 12.707   Value Loss: 2.731    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 7805       Buffer Size: 7805       Transition Number: 95.536  k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:14:24,929][train][INFO][train.py>_log] ==> #5000       Total Loss: 6.130    [weighted Loss:6.130    Policy Loss: 13.021   Value Loss: 3.170    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 9690       Buffer Size: 9690       Transition Number: 116.277 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:16:26,333][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.797    [weighted Loss:4.797    Policy Loss: 12.684   Value Loss: 2.918    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 11682      Buffer Size: 11682      Transition Number: 138.078 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:18:28,376][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.784    [weighted Loss:4.784    Policy Loss: 13.281   Value Loss: 2.724    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 13300      Buffer Size: 13300      Transition Number: 158.326 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:20:30,904][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.858    [weighted Loss:5.858    Policy Loss: 13.330   Value Loss: 2.900    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 14975      Buffer Size: 14975      Transition Number: 179.114 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:22:35,376][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.851    [weighted Loss:4.851    Policy Loss: 13.208   Value Loss: 2.860    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 16591      Buffer Size: 16591      Transition Number: 200.721 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:24:36,153][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.284    [weighted Loss:5.284    Policy Loss: 11.939   Value Loss: 2.403    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 18079      Buffer Size: 18079      Transition Number: 221.140 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:26:37,206][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 11.326   Value Loss: 2.589    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 19986      Buffer Size: 19986      Transition Number: 242.238 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:28:36,271][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 12.049   Value Loss: 2.658    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 21997      Buffer Size: 21997      Transition Number: 263.918 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:30:38,489][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.743    [weighted Loss:4.743    Policy Loss: 11.469   Value Loss: 2.647    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 24097      Buffer Size: 24097      Transition Number: 284.911 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:32:36,663][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.820    [weighted Loss:4.820    Policy Loss: 11.696   Value Loss: 2.466    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 26249      Buffer Size: 26249      Transition Number: 306.058 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:34:35,111][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.395    [weighted Loss:4.395    Policy Loss: 12.211   Value Loss: 2.917    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 28374      Buffer Size: 28374      Transition Number: 327.612 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:36:33,674][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.216    [weighted Loss:4.216    Policy Loss: 12.382   Value Loss: 2.747    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 30524      Buffer Size: 30524      Transition Number: 349.145 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:38:32,816][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.486    [weighted Loss:4.486    Policy Loss: 12.580   Value Loss: 2.723    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 32753      Buffer Size: 32753      Transition Number: 370.399 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:40:28,975][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.037    [weighted Loss:4.037    Policy Loss: 12.094   Value Loss: 2.476    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 34887      Buffer Size: 34887      Transition Number: 390.783 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:42:25,540][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 12.280   Value Loss: 2.759    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 36819      Buffer Size: 36819      Transition Number: 411.288 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:44:21,761][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.754    [weighted Loss:4.754    Policy Loss: 12.241   Value Loss: 2.584    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 38837      Buffer Size: 38837      Transition Number: 432.543 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:46:23,488][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.250    [weighted Loss:4.250    Policy Loss: 12.161   Value Loss: 2.630    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 40534      Buffer Size: 40534      Transition Number: 453.503 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:48:20,811][train][INFO][train.py>_log] ==> #22000      Total Loss: 5.012    [weighted Loss:5.012    Policy Loss: 12.143   Value Loss: 2.771    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 42232      Buffer Size: 42232      Transition Number: 474.428 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:50:19,456][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 12.648   Value Loss: 3.124    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 43773      Buffer Size: 43773      Transition Number: 495.478 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:52:16,529][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.397    [weighted Loss:4.397    Policy Loss: 11.218   Value Loss: 2.836    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 45264      Buffer Size: 45264      Transition Number: 516.307 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:54:14,676][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 12.770   Value Loss: 3.011    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 46084      Buffer Size: 46084      Transition Number: 535.031 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:56:16,847][train][INFO][train.py>_log] ==> #26000      Total Loss: 4.248    [weighted Loss:4.248    Policy Loss: 12.270   Value Loss: 2.999    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 46888      Buffer Size: 46888      Transition Number: 554.424 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 10:58:17,176][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.933    [weighted Loss:2.933    Policy Loss: 11.159   Value Loss: 2.970    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 47348      Buffer Size: 47348      Transition Number: 572.807 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:00:16,479][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 8.389    Value Loss: 3.142    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 47814      Buffer Size: 47814      Transition Number: 591.635 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:02:21,202][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.432    [weighted Loss:3.432    Policy Loss: 7.874    Value Loss: 3.104    Reward Loss: 0.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 48067      Buffer Size: 48067      Transition Number: 608.331 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:04:19,993][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.302    [weighted Loss:1.302    Policy Loss: 6.584    Value Loss: 3.164    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 48357      Buffer Size: 48357      Transition Number: 628.424 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:06:20,733][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.220    [weighted Loss:1.220    Policy Loss: 6.318    Value Loss: 3.145    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 48656      Buffer Size: 48656      Transition Number: 648.869 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:08:20,921][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.149    [weighted Loss:2.149    Policy Loss: 5.329    Value Loss: 3.197    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 48934      Buffer Size: 48934      Transition Number: 668.478 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:10:22,284][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.323    [weighted Loss:1.323    Policy Loss: 5.734    Value Loss: 3.253    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 49241      Buffer Size: 49241      Transition Number: 689.198 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:12:28,146][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 4.520    Value Loss: 3.113    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 49507      Buffer Size: 49507      Transition Number: 706.322 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:14:29,208][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.365    [weighted Loss:1.365    Policy Loss: 4.724    Value Loss: 3.490    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 49816      Buffer Size: 49816      Transition Number: 729.144 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:16:31,388][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.299    [weighted Loss:1.299    Policy Loss: 3.471    Value Loss: 3.401    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 50103      Buffer Size: 50103      Transition Number: 750.086 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:18:35,333][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 3.756    Value Loss: 3.298    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 50360      Buffer Size: 50360      Transition Number: 768.819 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:20:39,428][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.247    [weighted Loss:2.247    Policy Loss: 3.667    Value Loss: 3.522    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 50703      Buffer Size: 50703      Transition Number: 793.782 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:22:43,303][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 3.571    Value Loss: 3.662    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 50979      Buffer Size: 50979      Transition Number: 813.592 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:24:47,542][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.430    [weighted Loss:1.430    Policy Loss: 3.502    Value Loss: 3.360    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 51283      Buffer Size: 51283      Transition Number: 835.409 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:26:54,660][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.607    [weighted Loss:1.607    Policy Loss: 3.096    Value Loss: 3.520    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 51614      Buffer Size: 51614      Transition Number: 858.376 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:29:03,729][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 3.530    Value Loss: 3.582    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 51939      Buffer Size: 51939      Transition Number: 879.621 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:31:12,467][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.728    [weighted Loss:1.728    Policy Loss: 3.199    Value Loss: 3.659    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 52316      Buffer Size: 52316      Transition Number: 901.829 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:33:19,809][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 3.248    Value Loss: 3.651    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 52671      Buffer Size: 52671      Transition Number: 923.376 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:35:32,776][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 3.380    Value Loss: 3.667    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 52970      Buffer Size: 52970      Transition Number: 942.851 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:37:47,973][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 2.932    Value Loss: 3.718    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 53331      Buffer Size: 53331      Transition Number: 965.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:40:08,297][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 3.307    Value Loss: 3.961    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 53749      Buffer Size: 53749      Transition Number: 991.930 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:42:27,515][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.123    [weighted Loss:1.123    Policy Loss: 3.330    Value Loss: 3.961    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 54140      Buffer Size: 52889      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:44:54,827][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 3.490    Value Loss: 3.949    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 54511      Buffer Size: 51146      Transition Number: 1000.294k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:47:13,520][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.316    [weighted Loss:1.316    Policy Loss: 3.184    Value Loss: 3.835    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 54877      Buffer Size: 49355      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:49:32,640][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 3.168    Value Loss: 4.036    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 55271      Buffer Size: 47303      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:51:54,308][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.318    [weighted Loss:1.318    Policy Loss: 3.074    Value Loss: 3.969    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 55637      Buffer Size: 45262      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:54:18,509][train][INFO][train.py>_log] ==> #53000      Total Loss: 0.977    [weighted Loss:0.977    Policy Loss: 3.248    Value Loss: 3.842    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 56099      Buffer Size: 43361      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:56:41,593][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.534    [weighted Loss:1.534    Policy Loss: 3.363    Value Loss: 4.064    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 56558      Buffer Size: 41677      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 11:59:01,746][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 3.258    Value Loss: 3.919    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 56940      Buffer Size: 40050      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:01:24,627][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 3.561    Value Loss: 4.026    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 57308      Buffer Size: 38333      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:03:45,688][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.129    [weighted Loss:1.129    Policy Loss: 3.369    Value Loss: 4.118    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 57696      Buffer Size: 36359      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:06:07,238][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 3.271    Value Loss: 3.892    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 58068      Buffer Size: 34322      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:08:33,124][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 3.490    Value Loss: 4.018    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 58506      Buffer Size: 31681      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:10:57,774][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.682    [weighted Loss:1.682    Policy Loss: 3.459    Value Loss: 4.378    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 58899      Buffer Size: 29342      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:13:24,130][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 3.452    Value Loss: 3.966    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 59265      Buffer Size: 27015      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:15:53,034][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 3.298    Value Loss: 4.194    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 59670      Buffer Size: 24512      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:18:15,101][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 3.260    Value Loss: 4.304    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 60076      Buffer Size: 22242      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:20:44,063][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.807    [weighted Loss:1.807    Policy Loss: 3.650    Value Loss: 4.017    Reward Loss: 0.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 60468      Buffer Size: 20300      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:23:08,404][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 3.441    Value Loss: 4.198    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 61056      Buffer Size: 18421      Transition Number: 1000.210k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:25:36,311][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 3.569    Value Loss: 4.420    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 61538      Buffer Size: 17014      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:28:03,204][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 3.647    Value Loss: 4.326    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 61980      Buffer Size: 15966      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:30:30,237][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 3.772    Value Loss: 4.158    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 62402      Buffer Size: 15369      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:32:54,654][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 3.625    Value Loss: 4.498    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 62811      Buffer Size: 15105      Transition Number: 1000.291k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:35:22,149][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.547    [weighted Loss:1.547    Policy Loss: 3.462    Value Loss: 4.447    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 63215      Buffer Size: 15052      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:37:41,593][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.294    [weighted Loss:1.294    Policy Loss: 3.414    Value Loss: 4.350    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 63601      Buffer Size: 15049      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:40:04,083][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 3.696    Value Loss: 4.111    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 63978      Buffer Size: 15060      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:42:31,470][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 3.576    Value Loss: 4.250    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 64353      Buffer Size: 15059      Transition Number: 1000.582k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:44:52,487][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 3.572    Value Loss: 4.299    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 64778      Buffer Size: 15051      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:47:14,490][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 3.469    Value Loss: 4.526    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 65154      Buffer Size: 15076      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:49:40,200][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.616    [weighted Loss:1.616    Policy Loss: 3.812    Value Loss: 4.333    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 65586      Buffer Size: 15099      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:52:04,966][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 3.841    Value Loss: 4.099    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 65956      Buffer Size: 15124      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:54:29,053][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 4.046    Value Loss: 4.331    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 66361      Buffer Size: 15143      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:56:57,003][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 3.732    Value Loss: 4.312    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 66774      Buffer Size: 15165      Transition Number: 1000.624k Batch Size: 256        Lr: 0.10000 
[2022-01-19 12:59:22,269][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.232    [weighted Loss:1.232    Policy Loss: 3.898    Value Loss: 4.077    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 67221      Buffer Size: 15114      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:01:49,384][train][INFO][train.py>_log] ==> #81000      Total Loss: 1.987    [weighted Loss:1.987    Policy Loss: 3.863    Value Loss: 4.399    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 67587      Buffer Size: 15047      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:04:13,399][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 3.661    Value Loss: 4.434    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 68001      Buffer Size: 15010      Transition Number: 999.930 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:06:37,590][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.247    [weighted Loss:2.247    Policy Loss: 4.263    Value Loss: 4.245    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 68395      Buffer Size: 14974      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:09:05,929][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 4.086    Value Loss: 4.052    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 68838      Buffer Size: 14908      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:11:30,265][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 3.957    Value Loss: 4.000    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 69238      Buffer Size: 14889      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:13:53,827][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 3.897    Value Loss: 3.901    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 69609      Buffer Size: 14911      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:16:15,284][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 3.953    Value Loss: 4.320    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 70020      Buffer Size: 14929      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:18:43,008][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 3.748    Value Loss: 4.403    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 70443      Buffer Size: 14953      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:21:08,009][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 4.140    Value Loss: 4.097    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 70834      Buffer Size: 14908      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:23:37,370][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 4.012    Value Loss: 3.998    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 71248      Buffer Size: 14845      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:26:05,620][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 4.436    Value Loss: 4.210    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 71680      Buffer Size: 14802      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:28:36,718][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 3.807    Value Loss: 4.264    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 72119      Buffer Size: 14815      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:31:04,214][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 3.648    Value Loss: 4.003    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 72541      Buffer Size: 14783      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:33:31,640][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 4.222    Value Loss: 4.084    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 72947      Buffer Size: 14768      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:36:02,863][train][INFO][train.py>_log] ==> #95000      Total Loss: 1.536    [weighted Loss:1.536    Policy Loss: 3.848    Value Loss: 4.043    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 73432      Buffer Size: 14818      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:38:31,116][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 3.729    Value Loss: 3.994    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 73907      Buffer Size: 14879      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:41:01,037][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 4.264    Value Loss: 4.322    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 74274      Buffer Size: 14877      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:43:22,343][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 3.747    Value Loss: 4.180    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 74676      Buffer Size: 14860      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:45:53,315][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 3.992    Value Loss: 4.428    Reward Loss: 0.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 75152      Buffer Size: 14848      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:48:19,385][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 4.056    Value Loss: 4.381    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 75518      Buffer Size: 14776      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:50:50,563][train][INFO][train.py>_log] ==> #101000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.738    Value Loss: 4.164    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 75991      Buffer Size: 14669      Transition Number: 1000.215k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:53:16,882][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 3.926    Value Loss: 4.107    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 76432      Buffer Size: 14635      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:55:48,109][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.683    [weighted Loss:1.683    Policy Loss: 3.707    Value Loss: 4.634    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 76875      Buffer Size: 14629      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 13:58:21,490][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 4.152    Value Loss: 4.515    Reward Loss: 0.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 77345      Buffer Size: 14644      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:00:52,957][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 3.923    Value Loss: 4.385    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 77803      Buffer Size: 14672      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:03:20,229][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.323    [weighted Loss:1.323    Policy Loss: 3.502    Value Loss: 4.347    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 78203      Buffer Size: 14698      Transition Number: 999.930 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:05:47,574][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 3.768    Value Loss: 4.103    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 78645      Buffer Size: 14697      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:08:11,983][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 3.378    Value Loss: 4.823    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 79029      Buffer Size: 14693      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:10:42,971][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 3.950    Value Loss: 4.226    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 79456      Buffer Size: 14684      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:13:11,459][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 3.601    Value Loss: 4.477    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 79900      Buffer Size: 14668      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:15:41,813][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.194    [weighted Loss:1.194    Policy Loss: 3.705    Value Loss: 4.638    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 80372      Buffer Size: 14694      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:18:12,267][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 3.595    Value Loss: 4.648    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 80797      Buffer Size: 14743      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:20:39,480][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.617    [weighted Loss:1.617    Policy Loss: 3.552    Value Loss: 4.935    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 81237      Buffer Size: 14757      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:23:08,624][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 4.024    Value Loss: 4.452    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 81654      Buffer Size: 14769      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:25:37,018][train][INFO][train.py>_log] ==> #115000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 3.332    Value Loss: 4.383    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 82077      Buffer Size: 14770      Transition Number: 1000.022k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:28:09,692][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 3.544    Value Loss: 4.526    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 82529      Buffer Size: 14784      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:30:37,948][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.085    [weighted Loss:2.085    Policy Loss: 3.840    Value Loss: 4.634    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 82929      Buffer Size: 14788      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:33:07,998][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 3.412    Value Loss: 4.247    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 83350      Buffer Size: 14797      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:35:39,766][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.942    [weighted Loss:1.942    Policy Loss: 3.877    Value Loss: 4.545    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 83788      Buffer Size: 14801      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:38:08,590][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.069    [weighted Loss:1.069    Policy Loss: 3.534    Value Loss: 4.552    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 84227      Buffer Size: 14792      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:40:36,394][train][INFO][train.py>_log] ==> #121000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 3.219    Value Loss: 4.508    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 84689      Buffer Size: 14851      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:43:04,659][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.628    [weighted Loss:1.628    Policy Loss: 3.468    Value Loss: 4.773    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 85159      Buffer Size: 14921      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:45:31,868][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 3.420    Value Loss: 4.644    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 85583      Buffer Size: 14931      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:48:02,159][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 3.433    Value Loss: 4.416    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 86053      Buffer Size: 14945      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:50:31,075][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 3.588    Value Loss: 4.773    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 86439      Buffer Size: 14970      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:53:00,964][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 3.335    Value Loss: 4.251    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 86863      Buffer Size: 14983      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:55:36,217][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.513    [weighted Loss:1.513    Policy Loss: 3.571    Value Loss: 4.300    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 87334      Buffer Size: 14984      Transition Number: 1000.017k Batch Size: 256        Lr: 0.10000 
[2022-01-19 14:58:07,369][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 3.538    Value Loss: 4.517    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 87741      Buffer Size: 14989      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:00:30,786][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.071    [weighted Loss:2.071    Policy Loss: 3.733    Value Loss: 4.660    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 88143      Buffer Size: 14964      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:02:58,284][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 3.544    Value Loss: 4.473    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 88552      Buffer Size: 14914      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:05:28,319][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.444    [weighted Loss:1.444    Policy Loss: 3.493    Value Loss: 4.503    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 88992      Buffer Size: 14885      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:07:56,412][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 3.674    Value Loss: 4.347    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 89441      Buffer Size: 14904      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:10:24,801][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.467    [weighted Loss:1.467    Policy Loss: 3.348    Value Loss: 4.515    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 89825      Buffer Size: 14938      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:12:55,475][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 3.445    Value Loss: 4.551    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 90265      Buffer Size: 14970      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:15:25,108][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 3.632    Value Loss: 4.436    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 90728      Buffer Size: 14960      Transition Number: 999.941 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:17:54,513][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.807    [weighted Loss:1.807    Policy Loss: 3.537    Value Loss: 4.157    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 91141      Buffer Size: 14911      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:20:24,042][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.330    [weighted Loss:1.330    Policy Loss: 3.662    Value Loss: 4.259    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 91543      Buffer Size: 14906      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:22:48,376][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 3.747    Value Loss: 4.598    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 92007      Buffer Size: 14910      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:25:13,315][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.082    [weighted Loss:2.082    Policy Loss: 3.652    Value Loss: 4.651    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 92486      Buffer Size: 14964      Transition Number: 1000.064k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:27:46,054][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 3.644    Value Loss: 4.728    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 92949      Buffer Size: 15000      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:30:18,685][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.208    [weighted Loss:1.208    Policy Loss: 3.542    Value Loss: 4.510    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 93364      Buffer Size: 14981      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:32:48,211][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 4.041    Value Loss: 4.424    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 93803      Buffer Size: 14973      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:35:24,928][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 3.857    Value Loss: 4.330    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 94252      Buffer Size: 14977      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:37:54,522][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 3.760    Value Loss: 4.564    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 94692      Buffer Size: 14984      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:40:22,197][train][INFO][train.py>_log] ==> #145000     Total Loss: 1.258    [weighted Loss:1.258    Policy Loss: 3.438    Value Loss: 4.451    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 95062      Buffer Size: 14970      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:42:59,435][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 3.477    Value Loss: 4.566    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 95532      Buffer Size: 14920      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:45:30,690][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 3.593    Value Loss: 4.552    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 95953      Buffer Size: 14901      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:48:00,169][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 3.598    Value Loss: 4.631    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 96401      Buffer Size: 14890      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:50:26,272][train][INFO][train.py>_log] ==> #149000     Total Loss: 1.686    [weighted Loss:1.686    Policy Loss: 3.828    Value Loss: 4.741    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 96805      Buffer Size: 14879      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:52:56,487][train][INFO][train.py>_log] ==> #150000     Total Loss: 1.711    [weighted Loss:1.711    Policy Loss: 3.564    Value Loss: 4.160    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 97259      Buffer Size: 14870      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:55:27,960][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 4.072    Value Loss: 4.234    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 97735      Buffer Size: 14918      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 15:57:57,454][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 3.751    Value Loss: 4.601    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 98215      Buffer Size: 14976      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:00:20,714][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.740    [weighted Loss:1.740    Policy Loss: 3.455    Value Loss: 4.661    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 98555      Buffer Size: 14982      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:02:47,661][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 4.273    Value Loss: 4.425    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 99026      Buffer Size: 14993      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:05:14,136][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 4.106    Value Loss: 4.854    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 99466      Buffer Size: 15062      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:07:45,438][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 4.023    Value Loss: 4.566    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 99933      Buffer Size: 15070      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:10:20,957][train][INFO][train.py>_log] ==> #157000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 3.997    Value Loss: 4.773    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 100421     Buffer Size: 15078      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:12:54,218][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 3.650    Value Loss: 4.521    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 100921     Buffer Size: 15161      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:15:24,706][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.130    [weighted Loss:2.130    Policy Loss: 3.818    Value Loss: 4.436    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 101351     Buffer Size: 15176      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:18:04,577][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 3.777    Value Loss: 4.568    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 101854     Buffer Size: 15178      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:20:36,654][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.111    [weighted Loss:1.111    Policy Loss: 3.717    Value Loss: 4.538    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 102240     Buffer Size: 15197      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:23:07,403][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.348    [weighted Loss:1.348    Policy Loss: 3.805    Value Loss: 4.474    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 102670     Buffer Size: 15228      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:25:39,679][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 3.529    Value Loss: 4.641    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 103148     Buffer Size: 15253      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:28:10,429][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 3.547    Value Loss: 4.464    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 103578     Buffer Size: 15286      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:30:38,692][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 3.768    Value Loss: 4.701    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 103990     Buffer Size: 15301      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:33:10,215][train][INFO][train.py>_log] ==> #166000     Total Loss: 1.933    [weighted Loss:1.933    Policy Loss: 3.906    Value Loss: 4.531    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 104446     Buffer Size: 15323      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:35:46,458][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.201    [weighted Loss:1.201    Policy Loss: 3.645    Value Loss: 4.516    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 104906     Buffer Size: 15344      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:38:22,712][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 3.951    Value Loss: 4.530    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 105359     Buffer Size: 15344      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:40:52,826][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.519    [weighted Loss:2.519    Policy Loss: 4.015    Value Loss: 4.856    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 105814     Buffer Size: 15368      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:43:21,783][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 3.656    Value Loss: 4.915    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 106251     Buffer Size: 15407      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:45:45,689][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.249    [weighted Loss:1.249    Policy Loss: 3.621    Value Loss: 4.593    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 106621     Buffer Size: 15425      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:48:08,673][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 4.013    Value Loss: 4.527    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 107094     Buffer Size: 15397      Transition Number: 1000.035k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:50:31,480][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 3.522    Value Loss: 4.441    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 107428     Buffer Size: 15364      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:52:47,838][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 4.072    Value Loss: 4.526    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 107828     Buffer Size: 15292      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:55:03,182][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 3.637    Value Loss: 4.518    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 108368     Buffer Size: 15466      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:57:20,504][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 4.094    Value Loss: 4.865    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 108984     Buffer Size: 15694      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-01-19 16:59:36,299][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 4.109    Value Loss: 4.650    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 109493     Buffer Size: 15884      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:01:49,934][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 3.770    Value Loss: 5.121    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 110048     Buffer Size: 16111      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:04:00,664][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 3.918    Value Loss: 4.768    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 110425     Buffer Size: 16162      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:06:12,139][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.222    [weighted Loss:1.222    Policy Loss: 4.036    Value Loss: 4.893    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 110794     Buffer Size: 16211      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:08:20,042][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 3.952    Value Loss: 5.083    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 111121     Buffer Size: 16248      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:10:25,986][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.838    [weighted Loss:1.838    Policy Loss: 3.990    Value Loss: 4.779    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 111463     Buffer Size: 16295      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:12:35,143][train][INFO][train.py>_log] ==> #183000     Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 4.008    Value Loss: 5.025    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 111791     Buffer Size: 16340      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:14:44,360][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.179    [weighted Loss:1.179    Policy Loss: 4.380    Value Loss: 4.996    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 112186     Buffer Size: 16375      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:16:53,927][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 4.635    Value Loss: 4.838    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 112506     Buffer Size: 16397      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:19:03,030][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.661    [weighted Loss:1.661    Policy Loss: 4.121    Value Loss: 4.661    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 112826     Buffer Size: 16416      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:21:12,127][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.312    [weighted Loss:2.312    Policy Loss: 4.409    Value Loss: 4.695    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 113173     Buffer Size: 16435      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:23:20,287][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.682    [weighted Loss:1.682    Policy Loss: 4.282    Value Loss: 5.013    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 113544     Buffer Size: 16454      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:25:28,877][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.854    [weighted Loss:1.854    Policy Loss: 4.229    Value Loss: 4.864    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 113837     Buffer Size: 16474      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:27:37,590][train][INFO][train.py>_log] ==> #190000     Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 4.429    Value Loss: 4.765    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 114203     Buffer Size: 16441      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:29:45,689][train][INFO][train.py>_log] ==> #191000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 5.012    Value Loss: 4.972    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 114542     Buffer Size: 16440      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:31:52,290][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.350    [weighted Loss:2.350    Policy Loss: 4.475    Value Loss: 5.052    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 114890     Buffer Size: 16450      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:34:00,112][train][INFO][train.py>_log] ==> #193000     Total Loss: 2.735    [weighted Loss:2.735    Policy Loss: 4.936    Value Loss: 4.998    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 115302     Buffer Size: 16575      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:36:09,417][train][INFO][train.py>_log] ==> #194000     Total Loss: 0.877    [weighted Loss:0.877    Policy Loss: 4.048    Value Loss: 5.008    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 115737     Buffer Size: 16717      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:38:19,224][train][INFO][train.py>_log] ==> #195000     Total Loss: 1.887    [weighted Loss:1.887    Policy Loss: 4.905    Value Loss: 5.142    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 116295     Buffer Size: 16842      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:40:28,301][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 4.578    Value Loss: 5.211    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 116785     Buffer Size: 16980      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:42:37,853][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.490    [weighted Loss:2.490    Policy Loss: 4.344    Value Loss: 5.117    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 117204     Buffer Size: 17052      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:44:44,603][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 4.317    Value Loss: 5.111    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 117627     Buffer Size: 17092      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:46:53,104][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 4.437    Value Loss: 5.105    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 117980     Buffer Size: 17095      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:49:03,302][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 4.271    Value Loss: 4.927    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 118378     Buffer Size: 17143      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:51:11,869][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 4.061    Value Loss: 5.011    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 118704     Buffer Size: 17197      Transition Number: 1000.092k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:53:22,468][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 3.721    Value Loss: 5.073    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 119108     Buffer Size: 17249      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:55:33,491][train][INFO][train.py>_log] ==> #203000     Total Loss: 1.606    [weighted Loss:1.606    Policy Loss: 4.697    Value Loss: 4.988    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 119492     Buffer Size: 17309      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:57:42,739][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 4.122    Value Loss: 5.318    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 119892     Buffer Size: 17373      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-01-19 17:59:52,510][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 4.433    Value Loss: 5.102    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 120263     Buffer Size: 17445      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:02:02,816][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 4.275    Value Loss: 5.163    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 120720     Buffer Size: 17544      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:04:13,432][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 4.674    Value Loss: 5.101    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 121095     Buffer Size: 17609      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:06:20,902][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 4.218    Value Loss: 5.509    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 121464     Buffer Size: 17660      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:08:28,871][train][INFO][train.py>_log] ==> #209000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 4.015    Value Loss: 5.218    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 121815     Buffer Size: 17717      Transition Number: 1000.002k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:10:38,902][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 4.538    Value Loss: 5.132    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 122219     Buffer Size: 17788      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:12:47,854][train][INFO][train.py>_log] ==> #211000     Total Loss: 0.982    [weighted Loss:0.982    Policy Loss: 4.156    Value Loss: 5.203    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 122693     Buffer Size: 17899      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:14:56,464][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 4.838    Value Loss: 5.227    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 123091     Buffer Size: 18027      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:17:05,305][train][INFO][train.py>_log] ==> #213000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 5.067    Value Loss: 5.370    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 123511     Buffer Size: 18101      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:19:13,427][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 4.578    Value Loss: 5.126    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 123902     Buffer Size: 18166      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:21:22,840][train][INFO][train.py>_log] ==> #215000     Total Loss: 1.693    [weighted Loss:1.693    Policy Loss: 4.614    Value Loss: 5.349    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 124412     Buffer Size: 18332      Transition Number: 1000.144k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:23:32,727][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 4.858    Value Loss: 4.929    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 124912     Buffer Size: 18491      Transition Number: 1000.017k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:25:42,279][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 4.646    Value Loss: 5.410    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 125400     Buffer Size: 18641      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:27:52,468][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 4.542    Value Loss: 5.515    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 125829     Buffer Size: 18768      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:30:00,952][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.409    [weighted Loss:1.409    Policy Loss: 4.295    Value Loss: 5.292    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 126288     Buffer Size: 18918      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:32:11,729][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 4.101    Value Loss: 5.385    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 126761     Buffer Size: 19060      Transition Number: 1000.012k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:34:19,029][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 3.944    Value Loss: 5.224    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 127176     Buffer Size: 19076      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:36:26,559][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 4.199    Value Loss: 5.457    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 127564     Buffer Size: 19008      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:38:37,229][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 4.479    Value Loss: 5.395    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 128079     Buffer Size: 18940      Transition Number: 1000.027k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:40:46,122][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 4.033    Value Loss: 5.814    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 128586     Buffer Size: 18959      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:42:51,942][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 4.525    Value Loss: 5.299    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 128989     Buffer Size: 18895      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:45:02,333][train][INFO][train.py>_log] ==> #226000     Total Loss: 1.753    [weighted Loss:1.753    Policy Loss: 4.134    Value Loss: 5.256    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 129422     Buffer Size: 18980      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:47:10,886][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.105    [weighted Loss:2.105    Policy Loss: 3.967    Value Loss: 5.287    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 129839     Buffer Size: 19027      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:49:20,305][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 4.453    Value Loss: 5.326    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 130212     Buffer Size: 19084      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:51:29,682][train][INFO][train.py>_log] ==> #229000     Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 4.183    Value Loss: 5.629    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 130631     Buffer Size: 19139      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:53:37,602][train][INFO][train.py>_log] ==> #230000     Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 3.636    Value Loss: 5.591    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 131029     Buffer Size: 19193      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:55:47,202][train][INFO][train.py>_log] ==> #231000     Total Loss: 1.001    [weighted Loss:1.001    Policy Loss: 3.829    Value Loss: 5.368    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 131472     Buffer Size: 19280      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 18:57:58,756][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.977    [weighted Loss:1.977    Policy Loss: 4.129    Value Loss: 5.511    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 131899     Buffer Size: 19379      Transition Number: 1000.397k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:00:07,342][train][INFO][train.py>_log] ==> #233000     Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 4.599    Value Loss: 5.442    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 132366     Buffer Size: 19518      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:02:15,822][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.569    [weighted Loss:1.569    Policy Loss: 4.289    Value Loss: 5.717    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 132860     Buffer Size: 19669      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:04:21,415][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 4.384    Value Loss: 5.416    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 133277     Buffer Size: 19795      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:06:30,465][train][INFO][train.py>_log] ==> #236000     Total Loss: 0.500    [weighted Loss:0.500    Policy Loss: 3.685    Value Loss: 5.389    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 133702     Buffer Size: 19899      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:08:40,130][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 4.319    Value Loss: 5.503    Reward Loss: 0.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 134362     Buffer Size: 20200      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:10:49,060][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 3.854    Value Loss: 5.502    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 135035     Buffer Size: 20545      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:12:57,282][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 4.183    Value Loss: 5.242    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 135535     Buffer Size: 20707      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:15:06,258][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 3.921    Value Loss: 5.405    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 136057     Buffer Size: 20793      Transition Number: 1000.113k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:17:13,994][train][INFO][train.py>_log] ==> #241000     Total Loss: 1.534    [weighted Loss:1.534    Policy Loss: 4.207    Value Loss: 5.614    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 136548     Buffer Size: 20833      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:19:24,386][train][INFO][train.py>_log] ==> #242000     Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 4.189    Value Loss: 5.262    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 137039     Buffer Size: 20843      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:21:30,981][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 4.282    Value Loss: 5.603    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 137670     Buffer Size: 20982      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:23:40,522][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 4.021    Value Loss: 5.737    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 138386     Buffer Size: 21216      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:25:50,872][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 4.355    Value Loss: 5.774    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 139061     Buffer Size: 21496      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:28:00,457][train][INFO][train.py>_log] ==> #246000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 4.150    Value Loss: 5.641    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 139765     Buffer Size: 21807      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:30:13,047][train][INFO][train.py>_log] ==> #247000     Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 3.679    Value Loss: 5.740    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 140351     Buffer Size: 22020      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:32:22,525][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 3.683    Value Loss: 5.749    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 140965     Buffer Size: 22218      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:34:32,817][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 3.951    Value Loss: 5.526    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 141369     Buffer Size: 22296      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:36:42,127][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.316    [weighted Loss:2.316    Policy Loss: 4.072    Value Loss: 5.722    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 141828     Buffer Size: 22352      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:38:51,802][train][INFO][train.py>_log] ==> #251000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 4.416    Value Loss: 5.668    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 142219     Buffer Size: 22368      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:41:00,683][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 3.841    Value Loss: 5.669    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 142623     Buffer Size: 22343      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:43:11,000][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.324    [weighted Loss:2.324    Policy Loss: 4.380    Value Loss: 5.525    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 143003     Buffer Size: 22291      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:45:20,334][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 3.913    Value Loss: 5.387    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 143354     Buffer Size: 22280      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:47:29,600][train][INFO][train.py>_log] ==> #255000     Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 4.150    Value Loss: 5.383    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 143756     Buffer Size: 22284      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:49:39,950][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 3.857    Value Loss: 5.510    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 144144     Buffer Size: 22306      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:51:50,307][train][INFO][train.py>_log] ==> #257000     Total Loss: 1.540    [weighted Loss:1.540    Policy Loss: 3.836    Value Loss: 5.624    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 144612     Buffer Size: 22397      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:53:59,416][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 3.714    Value Loss: 5.615    Reward Loss: 0.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 145103     Buffer Size: 22464      Transition Number: 1000.065k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:56:08,910][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 4.145    Value Loss: 5.981    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 145605     Buffer Size: 22496      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 19:58:18,966][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 3.676    Value Loss: 5.768    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 146139     Buffer Size: 22595      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:00:30,214][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.153    [weighted Loss:2.153    Policy Loss: 3.772    Value Loss: 5.974    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 146622     Buffer Size: 22690      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:02:38,007][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 4.237    Value Loss: 5.625    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 147131     Buffer Size: 22704      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:04:46,963][train][INFO][train.py>_log] ==> #263000     Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 4.291    Value Loss: 5.814    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 147583     Buffer Size: 22690      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:06:58,699][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 4.252    Value Loss: 5.619    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 148067     Buffer Size: 22649      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:09:10,882][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 3.862    Value Loss: 5.391    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 148486     Buffer Size: 22672      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:11:20,350][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 4.106    Value Loss: 5.799    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 148942     Buffer Size: 22629      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:13:30,891][train][INFO][train.py>_log] ==> #267000     Total Loss: 1.359    [weighted Loss:1.359    Policy Loss: 4.356    Value Loss: 5.962    Reward Loss: 0.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 149465     Buffer Size: 22664      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:15:41,853][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.676    [weighted Loss:2.676    Policy Loss: 4.277    Value Loss: 5.690    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 149970     Buffer Size: 22732      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:17:51,817][train][INFO][train.py>_log] ==> #269000     Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 4.421    Value Loss: 5.750    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 150433     Buffer Size: 22749      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:20:00,812][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 4.098    Value Loss: 5.760    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 150882     Buffer Size: 22694      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:22:09,428][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 4.416    Value Loss: 5.671    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 151269     Buffer Size: 22620      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:24:19,513][train][INFO][train.py>_log] ==> #272000     Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 4.052    Value Loss: 5.570    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 151674     Buffer Size: 22604      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:26:31,835][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.200    [weighted Loss:2.200    Policy Loss: 4.944    Value Loss: 5.657    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 152212     Buffer Size: 22664      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:28:40,232][train][INFO][train.py>_log] ==> #274000     Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 5.389    Value Loss: 5.673    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 152682     Buffer Size: 22754      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:30:50,724][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 4.269    Value Loss: 5.473    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 153257     Buffer Size: 22921      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:32:58,330][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 4.638    Value Loss: 5.332    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 153803     Buffer Size: 23052      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:35:11,468][train][INFO][train.py>_log] ==> #277000     Total Loss: 2.324    [weighted Loss:2.324    Policy Loss: 3.930    Value Loss: 5.536    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 154471     Buffer Size: 23266      Transition Number: 1000.112k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:37:19,185][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 4.980    Value Loss: 5.573    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 155118     Buffer Size: 23493      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:39:27,118][train][INFO][train.py>_log] ==> #279000     Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 4.366    Value Loss: 5.542    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 155954     Buffer Size: 23860      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:41:34,998][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.932    [weighted Loss:1.932    Policy Loss: 5.520    Value Loss: 5.918    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 156767     Buffer Size: 24128      Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:43:43,066][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 4.436    Value Loss: 5.612    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 157607     Buffer Size: 24511      Transition Number: 1000.022k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:45:51,028][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 4.763    Value Loss: 5.888    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 158539     Buffer Size: 24975      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:47:59,078][train][INFO][train.py>_log] ==> #283000     Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 4.223    Value Loss: 5.426    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 158940     Buffer Size: 24836      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:50:08,946][train][INFO][train.py>_log] ==> #284000     Total Loss: 0.971    [weighted Loss:0.971    Policy Loss: 4.299    Value Loss: 5.610    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 159371     Buffer Size: 24578      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:52:19,958][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.566    [weighted Loss:2.566    Policy Loss: 4.330    Value Loss: 5.813    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 159758     Buffer Size: 24436      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:54:27,118][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 4.265    Value Loss: 5.616    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 160187     Buffer Size: 24356      Transition Number: 1000.018k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:56:37,102][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.143    [weighted Loss:2.143    Policy Loss: 4.946    Value Loss: 5.863    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 160676     Buffer Size: 24251      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 20:58:47,274][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 4.297    Value Loss: 5.922    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 161089     Buffer Size: 24235      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:00:56,113][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.661    [weighted Loss:1.661    Policy Loss: 4.249    Value Loss: 5.719    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 161493     Buffer Size: 24103      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:03:08,100][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.462    [weighted Loss:2.462    Policy Loss: 4.280    Value Loss: 5.973    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 161919     Buffer Size: 23808      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:05:16,720][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 4.492    Value Loss: 5.786    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 162342     Buffer Size: 23558      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:07:28,272][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 4.521    Value Loss: 5.903    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 162780     Buffer Size: 23245      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:09:39,402][train][INFO][train.py>_log] ==> #293000     Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 4.131    Value Loss: 5.590    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 163239     Buffer Size: 23137      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:11:52,686][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 4.910    Value Loss: 5.653    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 163747     Buffer Size: 23046      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:14:06,054][train][INFO][train.py>_log] ==> #295000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 4.357    Value Loss: 5.729    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 165115     Buffer Size: 23837      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:16:16,048][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 5.756    Value Loss: 5.682    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 166335     Buffer Size: 24540      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:18:25,661][train][INFO][train.py>_log] ==> #297000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 4.432    Value Loss: 5.726    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 167191     Buffer Size: 24994      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:20:36,798][train][INFO][train.py>_log] ==> #298000     Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 4.641    Value Loss: 5.922    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 168058     Buffer Size: 25455      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:22:48,083][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 5.194    Value Loss: 5.808    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 169030     Buffer Size: 26023      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:24:57,721][train][INFO][train.py>_log] ==> #300000     Total Loss: 1.187    [weighted Loss:1.187    Policy Loss: 3.842    Value Loss: 5.646    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 170000     Buffer Size: 26563      Transition Number: 999.946 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:27:06,178][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 4.071    Value Loss: 5.629    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 170731     Buffer Size: 26941      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:29:19,785][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 4.794    Value Loss: 5.741    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 171535     Buffer Size: 27276      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:31:28,862][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.180    [weighted Loss:2.180    Policy Loss: 4.079    Value Loss: 5.978    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 172243     Buffer Size: 27453      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:33:38,146][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 4.521    Value Loss: 5.745    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 172923     Buffer Size: 27646      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:35:51,853][train][INFO][train.py>_log] ==> #305000     Total Loss: 1.574    [weighted Loss:1.574    Policy Loss: 4.140    Value Loss: 5.945    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 173529     Buffer Size: 27690      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:38:00,392][train][INFO][train.py>_log] ==> #306000     Total Loss: 3.108    [weighted Loss:3.108    Policy Loss: 4.529    Value Loss: 5.804    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 174106     Buffer Size: 27740      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:40:11,683][train][INFO][train.py>_log] ==> #307000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 4.295    Value Loss: 5.872    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 174738     Buffer Size: 27844      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:42:22,261][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.789    [weighted Loss:2.789    Policy Loss: 4.526    Value Loss: 5.795    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 175369     Buffer Size: 27977      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:44:34,566][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 4.490    Value Loss: 5.932    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 176024     Buffer Size: 28145      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:46:43,312][train][INFO][train.py>_log] ==> #310000     Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 4.403    Value Loss: 5.465    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 176591     Buffer Size: 28291      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:48:54,793][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 4.246    Value Loss: 5.866    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 177019     Buffer Size: 28248      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:51:05,839][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 4.367    Value Loss: 5.765    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 177416     Buffer Size: 28177      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:53:17,073][train][INFO][train.py>_log] ==> #313000     Total Loss: 1.331    [weighted Loss:1.331    Policy Loss: 4.562    Value Loss: 5.725    Reward Loss: 1.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 177867     Buffer Size: 28112      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:55:31,678][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 4.538    Value Loss: 5.794    Reward Loss: 1.093    Consistency Loss: 0.000    ] Replay Episodes Collected: 178306     Buffer Size: 28081      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:57:43,177][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 4.323    Value Loss: 5.800    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 178732     Buffer Size: 28026      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 21:59:51,714][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.019    [weighted Loss:3.019    Policy Loss: 4.432    Value Loss: 5.837    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 179148     Buffer Size: 28014      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:02:02,723][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 4.479    Value Loss: 6.023    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 179516     Buffer Size: 28000      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:04:15,076][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.615    [weighted Loss:1.615    Policy Loss: 4.835    Value Loss: 5.782    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 179915     Buffer Size: 27897      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:06:26,290][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 5.532    Value Loss: 5.917    Reward Loss: 1.064    Consistency Loss: 0.000    ] Replay Episodes Collected: 180395     Buffer Size: 27838      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:08:35,611][train][INFO][train.py>_log] ==> #320000     Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 4.382    Value Loss: 5.746    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 180824     Buffer Size: 27737      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:10:46,340][train][INFO][train.py>_log] ==> #321000     Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 4.489    Value Loss: 5.963    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 181306     Buffer Size: 27668      Transition Number: 1000.001k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:12:57,669][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 4.838    Value Loss: 5.532    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 181846     Buffer Size: 27549      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:15:06,748][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 4.502    Value Loss: 5.679    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 182359     Buffer Size: 27409      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:17:17,380][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.674    [weighted Loss:1.674    Policy Loss: 4.101    Value Loss: 5.840    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 182859     Buffer Size: 27105      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:19:29,539][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 4.757    Value Loss: 5.949    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 183278     Buffer Size: 26748      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:21:42,065][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.539    [weighted Loss:2.539    Policy Loss: 4.612    Value Loss: 5.816    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 183740     Buffer Size: 26363      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:23:54,424][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 4.608    Value Loss: 6.017    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 184140     Buffer Size: 25940      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:26:03,693][train][INFO][train.py>_log] ==> #328000     Total Loss: 1.580    [weighted Loss:1.580    Policy Loss: 4.027    Value Loss: 5.851    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 184575     Buffer Size: 25739      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:28:12,821][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 4.343    Value Loss: 6.086    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 185023     Buffer Size: 25808      Transition Number: 1000.266k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:30:23,789][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 4.253    Value Loss: 5.855    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 185494     Buffer Size: 25857      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:32:36,054][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.582    [weighted Loss:2.582    Policy Loss: 4.666    Value Loss: 5.811    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 186020     Buffer Size: 25916      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:34:49,468][train][INFO][train.py>_log] ==> #332000     Total Loss: 1.635    [weighted Loss:1.635    Policy Loss: 4.521    Value Loss: 6.144    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 186579     Buffer Size: 25970      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:37:00,916][train][INFO][train.py>_log] ==> #333000     Total Loss: 1.734    [weighted Loss:1.734    Policy Loss: 3.896    Value Loss: 5.565    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 186970     Buffer Size: 25978      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:39:11,825][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 3.642    Value Loss: 5.703    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 187433     Buffer Size: 25969      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:41:22,559][train][INFO][train.py>_log] ==> #335000     Total Loss: 0.980    [weighted Loss:0.980    Policy Loss: 3.855    Value Loss: 5.737    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 187839     Buffer Size: 25962      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:43:35,247][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 3.780    Value Loss: 6.029    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 188270     Buffer Size: 25977      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:45:48,843][train][INFO][train.py>_log] ==> #337000     Total Loss: 1.402    [weighted Loss:1.402    Policy Loss: 3.754    Value Loss: 6.135    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 188761     Buffer Size: 26011      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:48:00,024][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 3.805    Value Loss: 5.823    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 189273     Buffer Size: 26010      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:50:09,900][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 3.989    Value Loss: 5.587    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 189655     Buffer Size: 25955      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:52:22,363][train][INFO][train.py>_log] ==> #340000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 3.956    Value Loss: 5.852    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 190109     Buffer Size: 25116      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:54:34,823][train][INFO][train.py>_log] ==> #341000     Total Loss: 1.575    [weighted Loss:1.575    Policy Loss: 4.518    Value Loss: 5.858    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 190582     Buffer Size: 24497      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:56:46,101][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 4.261    Value Loss: 6.002    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 191073     Buffer Size: 24103      Transition Number: 1000.071k Batch Size: 256        Lr: 0.10000 
[2022-01-19 22:58:58,529][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 4.559    Value Loss: 5.655    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 191651     Buffer Size: 23754      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:01:12,317][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.416    [weighted Loss:2.416    Policy Loss: 4.457    Value Loss: 5.900    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 192213     Buffer Size: 23339      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:03:23,029][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.138    [weighted Loss:3.138    Policy Loss: 5.135    Value Loss: 6.210    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 192702     Buffer Size: 22987      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:05:38,342][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.736    [weighted Loss:2.736    Policy Loss: 4.344    Value Loss: 5.911    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 193268     Buffer Size: 22696      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:07:53,064][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 4.524    Value Loss: 5.692    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 193721     Buffer Size: 22328      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:10:08,804][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 4.670    Value Loss: 5.832    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 194190     Buffer Size: 22125      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:12:19,604][train][INFO][train.py>_log] ==> #349000     Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 5.222    Value Loss: 5.770    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 194606     Buffer Size: 21895      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:14:32,332][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 5.898    Value Loss: 5.713    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 195081     Buffer Size: 21691      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:16:44,824][train][INFO][train.py>_log] ==> #351000     Total Loss: 1.375    [weighted Loss:1.375    Policy Loss: 5.548    Value Loss: 5.697    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 196589     Buffer Size: 22546      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:19:00,407][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 5.544    Value Loss: 5.693    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 198224     Buffer Size: 23427      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:21:14,783][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.966    [weighted Loss:2.966    Policy Loss: 5.582    Value Loss: 5.874    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 199196     Buffer Size: 23774      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:23:27,230][train][INFO][train.py>_log] ==> #354000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 5.498    Value Loss: 5.913    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 200197     Buffer Size: 24050      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:25:38,507][train][INFO][train.py>_log] ==> #355000     Total Loss: 1.967    [weighted Loss:1.967    Policy Loss: 5.489    Value Loss: 5.838    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 200945     Buffer Size: 24205      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:27:49,949][train][INFO][train.py>_log] ==> #356000     Total Loss: 3.083    [weighted Loss:3.083    Policy Loss: 5.331    Value Loss: 6.176    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 201697     Buffer Size: 24521      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:29:59,998][train][INFO][train.py>_log] ==> #357000     Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 5.828    Value Loss: 6.048    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 202360     Buffer Size: 24778      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:32:08,974][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 5.090    Value Loss: 5.871    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 203060     Buffer Size: 24994      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:34:17,397][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.180    [weighted Loss:2.180    Policy Loss: 4.668    Value Loss: 6.074    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 203762     Buffer Size: 25258      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:36:25,294][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 4.643    Value Loss: 5.934    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 204488     Buffer Size: 25553      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:38:35,470][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.429    [weighted Loss:2.429    Policy Loss: 4.789    Value Loss: 5.849    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 205151     Buffer Size: 25788      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:40:46,690][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.123    [weighted Loss:2.123    Policy Loss: 5.004    Value Loss: 5.952    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 205821     Buffer Size: 26068      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:42:58,333][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.455    [weighted Loss:3.455    Policy Loss: 5.722    Value Loss: 5.898    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 206637     Buffer Size: 26396      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:45:08,751][train][INFO][train.py>_log] ==> #364000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 5.298    Value Loss: 6.209    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 207401     Buffer Size: 26709      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:47:20,074][train][INFO][train.py>_log] ==> #365000     Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 5.570    Value Loss: 6.047    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 208230     Buffer Size: 27044      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:49:29,733][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 4.412    Value Loss: 5.724    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 209034     Buffer Size: 27321      Transition Number: 1000.124k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:51:39,782][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 4.324    Value Loss: 5.643    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 209454     Buffer Size: 27284      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:53:51,670][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 4.275    Value Loss: 5.390    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 209900     Buffer Size: 27201      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:56:04,876][train][INFO][train.py>_log] ==> #369000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 4.562    Value Loss: 5.484    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 210334     Buffer Size: 27154      Transition Number: 999.941 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 23:58:17,838][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 4.378    Value Loss: 5.813    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 210722     Buffer Size: 27145      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:00:29,615][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.105    [weighted Loss:2.105    Policy Loss: 4.336    Value Loss: 5.949    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 211315     Buffer Size: 27263      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:02:43,594][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 4.556    Value Loss: 5.937    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 211917     Buffer Size: 27413      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:04:54,998][train][INFO][train.py>_log] ==> #373000     Total Loss: 1.332    [weighted Loss:1.332    Policy Loss: 4.508    Value Loss: 5.532    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 212379     Buffer Size: 27423      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:07:09,298][train][INFO][train.py>_log] ==> #374000     Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 4.479    Value Loss: 5.797    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 212832     Buffer Size: 27398      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:09:21,609][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 4.129    Value Loss: 5.553    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 213275     Buffer Size: 27302      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:11:32,897][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 4.205    Value Loss: 5.732    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 213683     Buffer Size: 27237      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:13:45,306][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.058    [weighted Loss:2.058    Policy Loss: 4.226    Value Loss: 5.653    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 214194     Buffer Size: 27241      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:15:55,203][train][INFO][train.py>_log] ==> #378000     Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 4.648    Value Loss: 5.923    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 214631     Buffer Size: 27266      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:18:07,668][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 5.189    Value Loss: 5.675    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 215214     Buffer Size: 27412      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:20:20,729][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 4.582    Value Loss: 5.855    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 215809     Buffer Size: 27541      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:22:32,690][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 4.307    Value Loss: 5.782    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 216239     Buffer Size: 27512      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:24:43,171][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 4.612    Value Loss: 5.747    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 216645     Buffer Size: 27454      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:26:56,777][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 4.566    Value Loss: 5.870    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 217268     Buffer Size: 27570      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:29:09,434][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 4.345    Value Loss: 5.686    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 217831     Buffer Size: 27725      Transition Number: 1000.018k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:31:23,607][train][INFO][train.py>_log] ==> #385000     Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 4.673    Value Loss: 5.801    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 218617     Buffer Size: 27942      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:33:35,188][train][INFO][train.py>_log] ==> #386000     Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 4.869    Value Loss: 6.008    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 219347     Buffer Size: 28154      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:35:46,605][train][INFO][train.py>_log] ==> #387000     Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 4.677    Value Loss: 5.702    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 219777     Buffer Size: 28084      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:38:01,044][train][INFO][train.py>_log] ==> #388000     Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 4.293    Value Loss: 5.500    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 220283     Buffer Size: 27988      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:40:15,214][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 5.058    Value Loss: 5.943    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 220767     Buffer Size: 27905      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:42:28,714][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 4.781    Value Loss: 5.877    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 221217     Buffer Size: 27861      Transition Number: 1000.035k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:44:42,501][train][INFO][train.py>_log] ==> #391000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 4.489    Value Loss: 5.661    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 221757     Buffer Size: 27891      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:46:55,872][train][INFO][train.py>_log] ==> #392000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 5.582    Value Loss: 5.801    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 222250     Buffer Size: 27950      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:49:09,796][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 5.070    Value Loss: 5.524    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 222735     Buffer Size: 27976      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:51:26,424][train][INFO][train.py>_log] ==> #394000     Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 4.439    Value Loss: 5.660    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 223217     Buffer Size: 27782      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:53:39,228][train][INFO][train.py>_log] ==> #395000     Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 4.846    Value Loss: 5.806    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 223715     Buffer Size: 26924      Transition Number: 1000.230k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:55:51,178][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 4.410    Value Loss: 5.691    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 224218     Buffer Size: 26001      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 00:58:02,086][train][INFO][train.py>_log] ==> #397000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 4.404    Value Loss: 5.863    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 224841     Buffer Size: 25633      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-01-20 01:00:13,480][train][INFO][train.py>_log] ==> #398000     Total Loss: 2.333    [weighted Loss:2.333    Policy Loss: 4.834    Value Loss: 5.751    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 225445     Buffer Size: 25397      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
