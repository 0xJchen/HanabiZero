[2022-01-19 09:48:46,304][train][INFO][train.py>_log] ==> #0          Total Loss: 48.573   [weighted Loss:48.573   Policy Loss: 14.101   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1031       Buffer Size: 1031       Transition Number: 12.150  k Batch Size: 256        Lr: 0.00000 
[2022-01-19 09:51:04,725][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.053    [weighted Loss:4.053    Policy Loss: 13.829   Value Loss: 3.687    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 4761       Buffer Size: 4761       Transition Number: 57.803  k Batch Size: 256        Lr: 0.10000 
[2022-01-19 09:53:16,672][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.816    [weighted Loss:4.816    Policy Loss: 12.417   Value Loss: 2.939    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 8300       Buffer Size: 8300       Transition Number: 101.813 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 09:55:30,028][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.676    [weighted Loss:5.676    Policy Loss: 13.165   Value Loss: 3.056    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 12108      Buffer Size: 12108      Transition Number: 145.826 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 09:57:39,306][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.699    [weighted Loss:5.699    Policy Loss: 12.679   Value Loss: 2.856    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 15943      Buffer Size: 15943      Transition Number: 190.886 k Batch Size: 256        Lr: 0.10000 
[2022-01-19 09:59:50,498][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.938    [weighted Loss:5.938    Policy Loss: 12.445   Value Loss: 2.998    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 20371      Buffer Size: 20371      Transition Number: 233.998 k Batch Size: 256        Lr: 0.10000 
