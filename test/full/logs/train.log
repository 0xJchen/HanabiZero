[2021-10-13 13:27:22,906][train][INFO][train.py>_log] ==> #0          Total Loss: 33.098   [weighted Loss:33.098   Policy Loss: 7.541    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 1164       Buffer Size: 1164       Transition Number: 4.643   k Batch Size: 256        Lr: 0.000   
[2021-10-13 13:32:44,355][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.999    [weighted Loss:4.999    Policy Loss: 8.027    Value Loss: 3.414    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 10771      Buffer Size: 10771      Transition Number: 41.070  k Batch Size: 256        Lr: 0.020   
[2021-10-13 13:42:46,330][train][INFO][train.py>_log] ==> #2000       Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 8.955    Value Loss: 3.146    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 29607      Buffer Size: 20786      Transition Number: 80.025  k Batch Size: 256        Lr: 0.040   
[2021-10-13 14:05:08,977][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.257    [weighted Loss:4.257    Policy Loss: 10.514   Value Loss: 2.677    Reward Loss: 0.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 49937      Buffer Size: 12257      Transition Number: 80.104  k Batch Size: 256        Lr: 0.060   
[2021-10-13 14:30:40,887][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 9.855    Value Loss: 2.312    Reward Loss: 0.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 71830      Buffer Size: 11519      Transition Number: 80.079  k Batch Size: 256        Lr: 0.080   
[2021-10-13 15:06:45,169][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.356    [weighted Loss:3.356    Policy Loss: 9.801    Value Loss: 2.957    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 99619      Buffer Size: 10800      Transition Number: 80.261  k Batch Size: 256        Lr: 0.100   
[2021-10-13 15:34:48,755][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.007    [weighted Loss:4.007    Policy Loss: 9.283    Value Loss: 2.965    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 126051     Buffer Size: 12498      Transition Number: 80.183  k Batch Size: 256        Lr: 0.100   
[2021-10-13 16:08:28,936][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 9.203    Value Loss: 3.015    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 149460     Buffer Size: 9578       Transition Number: 80.224  k Batch Size: 256        Lr: 0.100   
[2021-10-13 16:48:02,605][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 9.215    Value Loss: 3.072    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 174847     Buffer Size: 8836       Transition Number: 80.283  k Batch Size: 256        Lr: 0.100   
[2021-10-13 17:24:30,691][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.941    [weighted Loss:3.941    Policy Loss: 9.167    Value Loss: 3.111    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 199611     Buffer Size: 9317       Transition Number: 80.131  k Batch Size: 256        Lr: 0.100   
[2021-10-13 18:08:18,271][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.091    [weighted Loss:4.091    Policy Loss: 9.351    Value Loss: 3.179    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 222842     Buffer Size: 7427       Transition Number: 80.237  k Batch Size: 256        Lr: 0.100   
[2021-10-13 18:59:20,081][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.708    [weighted Loss:3.708    Policy Loss: 9.651    Value Loss: 3.071    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 244788     Buffer Size: 5758       Transition Number: 80.186  k Batch Size: 256        Lr: 0.100   
[2021-10-13 19:51:20,730][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.257    [weighted Loss:3.257    Policy Loss: 8.823    Value Loss: 3.307    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 268397     Buffer Size: 6005       Transition Number: 80.364  k Batch Size: 256        Lr: 0.100   
[2021-10-13 20:45:36,795][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.815    [weighted Loss:3.815    Policy Loss: 9.220    Value Loss: 3.278    Reward Loss: 0.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 289578     Buffer Size: 5147       Transition Number: 80.297  k Batch Size: 256        Lr: 0.100   
[2021-10-13 21:42:11,620][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.340    [weighted Loss:2.340    Policy Loss: 9.514    Value Loss: 3.412    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 307835     Buffer Size: 4251       Transition Number: 80.416  k Batch Size: 256        Lr: 0.100   
[2021-10-13 22:39:31,529][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 8.217    Value Loss: 3.288    Reward Loss: 0.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 324657     Buffer Size: 3909       Transition Number: 80.465  k Batch Size: 256        Lr: 0.100   
[2021-10-13 23:36:30,695][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.575    [weighted Loss:3.575    Policy Loss: 8.105    Value Loss: 4.000    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 340980     Buffer Size: 3917       Transition Number: 80.481  k Batch Size: 256        Lr: 0.100   
[2021-10-14 00:32:03,522][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 7.671    Value Loss: 3.416    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 356231     Buffer Size: 3739       Transition Number: 80.439  k Batch Size: 256        Lr: 0.100   
[2021-10-14 01:27:57,701][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 5.873    Value Loss: 3.780    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 370791     Buffer Size: 3600       Transition Number: 80.472  k Batch Size: 256        Lr: 0.100   
[2021-10-14 02:23:31,561][train][INFO][train.py>_log] ==> #19000      Total Loss: 1.725    [weighted Loss:1.725    Policy Loss: 5.459    Value Loss: 3.562    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 385694     Buffer Size: 3718       Transition Number: 80.045  k Batch Size: 256        Lr: 0.100   
[2021-10-14 03:16:51,480][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.530    [weighted Loss:2.530    Policy Loss: 5.282    Value Loss: 4.391    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 404343     Buffer Size: 4799       Transition Number: 80.515  k Batch Size: 256        Lr: 0.100   
[2021-10-14 04:10:31,474][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 4.676    Value Loss: 4.029    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 418743     Buffer Size: 3773       Transition Number: 80.739  k Batch Size: 256        Lr: 0.100   
[2021-10-14 05:04:06,761][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.800    [weighted Loss:2.800    Policy Loss: 4.588    Value Loss: 4.045    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 433911     Buffer Size: 3919       Transition Number: 80.749  k Batch Size: 256        Lr: 0.100   
[2021-10-14 05:57:12,692][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 4.314    Value Loss: 4.176    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 448936     Buffer Size: 3902       Transition Number: 80.102  k Batch Size: 256        Lr: 0.100   
[2021-10-14 06:50:25,069][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.857    [weighted Loss:1.857    Policy Loss: 4.325    Value Loss: 4.455    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 463962     Buffer Size: 3918       Transition Number: 80.275  k Batch Size: 256        Lr: 0.100   
[2021-10-14 07:42:56,580][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 4.140    Value Loss: 4.508    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 479204     Buffer Size: 4060       Transition Number: 80.340  k Batch Size: 256        Lr: 0.100   
[2021-10-14 08:36:17,577][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.745    [weighted Loss:1.745    Policy Loss: 4.198    Value Loss: 4.275    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 494173     Buffer Size: 3897       Transition Number: 80.753  k Batch Size: 256        Lr: 0.100   
[2021-10-14 09:28:41,983][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 4.085    Value Loss: 4.931    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 508808     Buffer Size: 3876       Transition Number: 80.085  k Batch Size: 256        Lr: 0.100   
[2021-10-14 10:21:07,988][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.305    [weighted Loss:2.305    Policy Loss: 4.005    Value Loss: 4.630    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 523661     Buffer Size: 3960       Transition Number: 80.061  k Batch Size: 256        Lr: 0.100   
[2021-10-14 11:13:29,059][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 4.397    Value Loss: 4.605    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 538404     Buffer Size: 3950       Transition Number: 80.093  k Batch Size: 256        Lr: 0.100   
[2021-10-14 12:04:24,230][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 4.336    Value Loss: 4.632    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 553617     Buffer Size: 4179       Transition Number: 80.114  k Batch Size: 256        Lr: 0.100   
[2021-10-14 12:55:27,141][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 4.384    Value Loss: 5.024    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 568704     Buffer Size: 4167       Transition Number: 80.352  k Batch Size: 256        Lr: 0.100   
[2021-10-14 13:46:05,829][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 3.985    Value Loss: 4.610    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 584002     Buffer Size: 4266       Transition Number: 80.329  k Batch Size: 256        Lr: 0.100   
[2021-10-14 14:35:23,917][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 4.476    Value Loss: 4.849    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 599885     Buffer Size: 4499       Transition Number: 80.202  k Batch Size: 256        Lr: 0.100   
[2021-10-14 15:25:14,057][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.059    [weighted Loss:1.059    Policy Loss: 4.539    Value Loss: 4.614    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 615599     Buffer Size: 4394       Transition Number: 80.161  k Batch Size: 256        Lr: 0.100   
[2021-10-14 16:13:55,678][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 4.535    Value Loss: 5.017    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 631272     Buffer Size: 4545       Transition Number: 80.406  k Batch Size: 256        Lr: 0.100   
[2021-10-14 17:01:24,270][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 4.147    Value Loss: 4.666    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 646235     Buffer Size: 4364       Transition Number: 80.088  k Batch Size: 256        Lr: 0.100   
[2021-10-14 17:50:09,027][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.527    [weighted Loss:2.527    Policy Loss: 4.485    Value Loss: 4.755    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 661109     Buffer Size: 4380       Transition Number: 80.099  k Batch Size: 256        Lr: 0.100   
[2021-10-14 18:37:11,055][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.441    [weighted Loss:1.441    Policy Loss: 4.452    Value Loss: 5.172    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 676701     Buffer Size: 4654       Transition Number: 80.645  k Batch Size: 256        Lr: 0.100   
[2021-10-14 19:24:55,027][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.767    [weighted Loss:2.767    Policy Loss: 4.643    Value Loss: 4.828    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 691997     Buffer Size: 4507       Transition Number: 80.126  k Batch Size: 256        Lr: 0.100   
[2021-10-14 20:11:57,065][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 4.372    Value Loss: 4.972    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 707391     Buffer Size: 4625       Transition Number: 80.242  k Batch Size: 256        Lr: 0.100   
[2021-10-14 20:57:35,475][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.700    [weighted Loss:2.700    Policy Loss: 4.223    Value Loss: 4.854    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 725682     Buffer Size: 5640       Transition Number: 80.282  k Batch Size: 256        Lr: 0.100   
[2021-10-14 21:45:26,029][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 4.892    Value Loss: 4.797    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 740611     Buffer Size: 4432       Transition Number: 80.191  k Batch Size: 256        Lr: 0.100   
[2021-10-14 22:30:50,057][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.698    [weighted Loss:1.698    Policy Loss: 4.665    Value Loss: 5.075    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 757893     Buffer Size: 5280       Transition Number: 80.133  k Batch Size: 256        Lr: 0.100   
[2021-10-14 23:19:08,369][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 4.361    Value Loss: 4.754    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 773571     Buffer Size: 4600       Transition Number: 80.281  k Batch Size: 256        Lr: 0.100   
[2021-10-15 00:07:35,579][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 4.689    Value Loss: 4.619    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 788832     Buffer Size: 4440       Transition Number: 80.267  k Batch Size: 256        Lr: 0.100   
[2021-10-15 00:56:18,719][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.753    [weighted Loss:1.753    Policy Loss: 4.293    Value Loss: 4.713    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 804611     Buffer Size: 4526       Transition Number: 80.079  k Batch Size: 256        Lr: 0.100   
[2021-10-15 01:44:54,046][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 4.433    Value Loss: 4.732    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 821302     Buffer Size: 4824       Transition Number: 80.369  k Batch Size: 256        Lr: 0.100   
[2021-10-15 02:35:08,650][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.886    [weighted Loss:2.886    Policy Loss: 4.755    Value Loss: 4.761    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 836924     Buffer Size: 4356       Transition Number: 80.719  k Batch Size: 256        Lr: 0.100   
[2021-10-15 03:26:06,859][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.619    [weighted Loss:1.619    Policy Loss: 4.860    Value Loss: 4.383    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 852391     Buffer Size: 4289       Transition Number: 80.066  k Batch Size: 256        Lr: 0.100   
[2021-10-15 04:17:03,125][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 4.585    Value Loss: 4.290    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 867687     Buffer Size: 4222       Transition Number: 80.182  k Batch Size: 256        Lr: 0.100   
[2021-10-15 05:07:21,188][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 4.477    Value Loss: 4.633    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 883314     Buffer Size: 4351       Transition Number: 80.421  k Batch Size: 256        Lr: 0.100   
[2021-10-15 05:58:09,561][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 4.154    Value Loss: 4.931    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 898700     Buffer Size: 4229       Transition Number: 80.112  k Batch Size: 256        Lr: 0.100   
[2021-10-15 06:49:58,825][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.632    [weighted Loss:2.632    Policy Loss: 4.387    Value Loss: 4.792    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 914126     Buffer Size: 4195       Transition Number: 80.556  k Batch Size: 256        Lr: 0.100   
[2021-10-15 07:41:39,013][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 4.412    Value Loss: 4.498    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 929642     Buffer Size: 4200       Transition Number: 80.438  k Batch Size: 256        Lr: 0.100   
[2021-10-15 08:33:05,323][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 4.566    Value Loss: 4.597    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 944838     Buffer Size: 4107       Transition Number: 80.338  k Batch Size: 256        Lr: 0.100   
[2021-10-15 09:23:26,703][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 4.281    Value Loss: 4.342    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 960893     Buffer Size: 4453       Transition Number: 80.068  k Batch Size: 256        Lr: 0.100   
[2021-10-15 10:13:35,125][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 4.596    Value Loss: 5.107    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 976963     Buffer Size: 4506       Transition Number: 80.039  k Batch Size: 256        Lr: 0.100   
[2021-10-15 11:03:46,249][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 4.769    Value Loss: 4.721    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 993312     Buffer Size: 4540       Transition Number: 80.060  k Batch Size: 256        Lr: 0.100   
[2021-10-15 11:55:42,701][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 4.502    Value Loss: 4.666    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 1008411    Buffer Size: 4075       Transition Number: 80.632  k Batch Size: 256        Lr: 0.100   
[2021-10-15 12:45:35,097][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.807    [weighted Loss:1.807    Policy Loss: 4.433    Value Loss: 4.738    Reward Loss: 0.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025813    Buffer Size: 4767       Transition Number: 80.372  k Batch Size: 256        Lr: 0.100   
[2021-10-15 13:35:52,208][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 4.250    Value Loss: 4.686    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 1041499    Buffer Size: 4396       Transition Number: 80.267  k Batch Size: 256        Lr: 0.100   
[2021-10-15 14:24:44,274][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 4.139    Value Loss: 5.079    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 1058858    Buffer Size: 4894       Transition Number: 80.159  k Batch Size: 256        Lr: 0.100   
[2021-10-15 15:14:00,073][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 4.207    Value Loss: 4.516    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076472    Buffer Size: 4933       Transition Number: 80.480  k Batch Size: 256        Lr: 0.100   
[2021-10-15 15:58:18,855][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.407    [weighted Loss:2.407    Policy Loss: 4.154    Value Loss: 5.009    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100868    Buffer Size: 7443       Transition Number: 80.356  k Batch Size: 256        Lr: 0.100   
[2021-10-15 16:46:27,319][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 4.128    Value Loss: 4.487    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117592    Buffer Size: 4804       Transition Number: 80.360  k Batch Size: 256        Lr: 0.100   
[2021-10-15 17:36:49,983][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.180    [weighted Loss:2.180    Policy Loss: 4.079    Value Loss: 4.616    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 1134501    Buffer Size: 4721       Transition Number: 80.321  k Batch Size: 256        Lr: 0.100   
[2021-10-15 18:26:53,751][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.670    [weighted Loss:2.670    Policy Loss: 4.376    Value Loss: 4.651    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152606    Buffer Size: 5070       Transition Number: 80.265  k Batch Size: 256        Lr: 0.100   
[2021-10-15 19:10:33,932][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 4.021    Value Loss: 4.708    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 1179682    Buffer Size: 8221       Transition Number: 80.319  k Batch Size: 256        Lr: 0.100   
[2021-10-15 19:58:44,927][train][INFO][train.py>_log] ==> #69000      Total Loss: 0.896    [weighted Loss:0.896    Policy Loss: 4.545    Value Loss: 4.696    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 1197447    Buffer Size: 5132       Transition Number: 80.152  k Batch Size: 256        Lr: 0.100   
[2021-10-15 20:46:41,911][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 4.044    Value Loss: 4.542    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 1217903    Buffer Size: 5791       Transition Number: 80.237  k Batch Size: 256        Lr: 0.100   
[2021-10-15 21:35:17,384][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.177    [weighted Loss:3.177    Policy Loss: 4.278    Value Loss: 4.990    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236499    Buffer Size: 5362       Transition Number: 80.634  k Batch Size: 256        Lr: 0.100   
[2021-10-15 22:26:07,691][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.304    [weighted Loss:1.304    Policy Loss: 4.245    Value Loss: 4.524    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252687    Buffer Size: 4453       Transition Number: 80.165  k Batch Size: 256        Lr: 0.100   
[2021-10-15 23:15:23,466][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 4.630    Value Loss: 4.835    Reward Loss: 0.952    Consistency Loss: 0.000    ] Replay Episodes Collected: 1270452    Buffer Size: 5045       Transition Number: 80.418  k Batch Size: 256        Lr: 0.100   
[2021-10-16 00:05:19,515][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 4.349    Value Loss: 5.083    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 1287570    Buffer Size: 4779       Transition Number: 80.056  k Batch Size: 256        Lr: 0.100   
[2021-10-16 00:53:56,943][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.924    [weighted Loss:2.924    Policy Loss: 4.689    Value Loss: 5.302    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304855    Buffer Size: 4870       Transition Number: 80.358  k Batch Size: 256        Lr: 0.100   
[2021-10-16 01:44:46,614][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 4.270    Value Loss: 4.564    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 1321127    Buffer Size: 4495       Transition Number: 80.159  k Batch Size: 256        Lr: 0.100   
[2021-10-16 02:34:43,241][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 4.345    Value Loss: 5.240    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 1336750    Buffer Size: 4492       Transition Number: 80.291  k Batch Size: 256        Lr: 0.100   
[2021-10-16 03:24:15,512][train][INFO][train.py>_log] ==> #78000      Total Loss: 0.721    [weighted Loss:0.721    Policy Loss: 4.220    Value Loss: 4.830    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 1354041    Buffer Size: 4792       Transition Number: 80.352  k Batch Size: 256        Lr: 0.100   
[2021-10-16 04:09:43,790][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.006    [weighted Loss:2.006    Policy Loss: 4.595    Value Loss: 5.171    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370959    Buffer Size: 5172       Transition Number: 80.287  k Batch Size: 256        Lr: 0.100   
[2021-10-16 04:59:14,423][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.416    [weighted Loss:2.416    Policy Loss: 4.613    Value Loss: 4.877    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 1386546    Buffer Size: 4439       Transition Number: 80.040  k Batch Size: 256        Lr: 0.100   
[2021-10-16 05:49:20,588][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.478    [weighted Loss:2.478    Policy Loss: 4.511    Value Loss: 5.010    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 1403416    Buffer Size: 4774       Transition Number: 80.272  k Batch Size: 256        Lr: 0.100   
[2021-10-16 06:39:39,683][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 4.299    Value Loss: 4.849    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 1418926    Buffer Size: 4351       Transition Number: 80.093  k Batch Size: 256        Lr: 0.100   
[2021-10-16 07:31:56,565][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 5.048    Value Loss: 4.827    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 1434379    Buffer Size: 4233       Transition Number: 80.383  k Batch Size: 256        Lr: 0.100   
[2021-10-16 08:23:51,314][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 5.091    Value Loss: 5.079    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 1450534    Buffer Size: 4391       Transition Number: 80.380  k Batch Size: 256        Lr: 0.100   
[2021-10-16 09:16:07,163][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.896    [weighted Loss:2.896    Policy Loss: 5.423    Value Loss: 4.949    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 1466524    Buffer Size: 4316       Transition Number: 80.251  k Batch Size: 256        Lr: 0.100   
[2021-10-16 10:07:48,898][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 5.202    Value Loss: 4.731    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 1482535    Buffer Size: 4405       Transition Number: 80.119  k Batch Size: 256        Lr: 0.100   
[2021-10-16 10:58:52,770][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 4.688    Value Loss: 4.910    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 1498684    Buffer Size: 4452       Transition Number: 80.295  k Batch Size: 256        Lr: 0.100   
[2021-10-16 11:50:41,147][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.943    [weighted Loss:1.943    Policy Loss: 4.738    Value Loss: 4.709    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 1515101    Buffer Size: 4407       Transition Number: 80.063  k Batch Size: 256        Lr: 0.100   
[2021-10-16 12:42:47,667][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 4.746    Value Loss: 4.823    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 1530817    Buffer Size: 4188       Transition Number: 80.261  k Batch Size: 256        Lr: 0.100   
[2021-10-16 13:34:47,490][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 4.896    Value Loss: 4.524    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 1546883    Buffer Size: 4332       Transition Number: 80.145  k Batch Size: 256        Lr: 0.100   
[2021-10-16 14:26:49,325][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.252    [weighted Loss:1.252    Policy Loss: 4.895    Value Loss: 4.792    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 1562930    Buffer Size: 4304       Transition Number: 80.323  k Batch Size: 256        Lr: 0.100   
[2021-10-16 15:19:16,566][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.996    [weighted Loss:2.996    Policy Loss: 4.590    Value Loss: 4.879    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 1578732    Buffer Size: 4245       Transition Number: 80.498  k Batch Size: 256        Lr: 0.100   
[2021-10-16 16:11:36,322][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.191    [weighted Loss:1.191    Policy Loss: 4.645    Value Loss: 4.398    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 1594386    Buffer Size: 4255       Transition Number: 80.298  k Batch Size: 256        Lr: 0.100   
[2021-10-16 17:04:16,578][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.006    [weighted Loss:3.006    Policy Loss: 4.864    Value Loss: 4.794    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 1609992    Buffer Size: 4122       Transition Number: 80.226  k Batch Size: 256        Lr: 0.100   
[2021-10-16 17:56:16,570][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 4.749    Value Loss: 4.820    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 1626263    Buffer Size: 4366       Transition Number: 80.526  k Batch Size: 256        Lr: 0.100   
[2021-10-16 18:49:00,263][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 4.994    Value Loss: 4.679    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 1641885    Buffer Size: 4202       Transition Number: 80.186  k Batch Size: 256        Lr: 0.100   
[2021-10-16 19:41:37,790][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 4.669    Value Loss: 4.713    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 1658533    Buffer Size: 4511       Transition Number: 80.260  k Batch Size: 256        Lr: 0.100   
[2021-10-16 20:32:48,072][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 4.691    Value Loss: 5.113    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 1674847    Buffer Size: 4496       Transition Number: 80.259  k Batch Size: 256        Lr: 0.100   
[2021-10-16 21:23:47,006][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.636    [weighted Loss:1.636    Policy Loss: 4.407    Value Loss: 4.862    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 1692089    Buffer Size: 4657       Transition Number: 80.610  k Batch Size: 256        Lr: 0.100   
[2021-10-16 22:15:19,061][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.677    [weighted Loss:1.677    Policy Loss: 4.329    Value Loss: 5.060    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 1709425    Buffer Size: 4738       Transition Number: 80.211  k Batch Size: 256        Lr: 0.100   
[2021-10-16 23:06:53,328][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 4.387    Value Loss: 4.668    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 1726186    Buffer Size: 4463       Transition Number: 80.703  k Batch Size: 256        Lr: 0.100   
[2021-10-16 23:58:36,187][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.035    [weighted Loss:2.035    Policy Loss: 4.279    Value Loss: 4.962    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 1742778    Buffer Size: 4575       Transition Number: 80.368  k Batch Size: 256        Lr: 0.100   
[2021-10-17 00:48:36,609][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.418    [weighted Loss:1.418    Policy Loss: 4.421    Value Loss: 5.202    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 1760124    Buffer Size: 4867       Transition Number: 80.425  k Batch Size: 256        Lr: 0.100   
[2021-10-17 01:35:50,664][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 4.220    Value Loss: 5.388    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 1778932    Buffer Size: 5490       Transition Number: 80.056  k Batch Size: 256        Lr: 0.100   
[2021-10-17 02:25:37,290][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 4.406    Value Loss: 4.638    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 1795512    Buffer Size: 4605       Transition Number: 80.587  k Batch Size: 256        Lr: 0.100   
[2021-10-17 03:16:22,871][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 4.413    Value Loss: 5.207    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 1812399    Buffer Size: 4648       Transition Number: 80.072  k Batch Size: 256        Lr: 0.100   
[2021-10-17 04:06:36,775][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 4.078    Value Loss: 5.177    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 1829428    Buffer Size: 4737       Transition Number: 80.432  k Batch Size: 256        Lr: 0.100   
[2021-10-17 04:58:27,161][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 4.234    Value Loss: 4.885    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 1845557    Buffer Size: 4395       Transition Number: 80.111  k Batch Size: 256        Lr: 0.100   
[2021-10-17 05:50:56,200][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 4.116    Value Loss: 5.229    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 1861308    Buffer Size: 4242       Transition Number: 80.523  k Batch Size: 256        Lr: 0.100   
[2021-10-17 06:41:21,055][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 3.832    Value Loss: 5.025    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 1878266    Buffer Size: 4672       Transition Number: 80.337  k Batch Size: 256        Lr: 0.100   
[2021-10-17 07:30:38,659][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.046    [weighted Loss:2.046    Policy Loss: 4.161    Value Loss: 4.893    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 1896148    Buffer Size: 5044       Transition Number: 80.388  k Batch Size: 256        Lr: 0.100   
[2021-10-17 08:21:58,895][train][INFO][train.py>_log] ==> #112000     Total Loss: 1.875    [weighted Loss:1.875    Policy Loss: 4.439    Value Loss: 5.095    Reward Loss: 1.093    Consistency Loss: 0.000    ] Replay Episodes Collected: 1912155    Buffer Size: 4458       Transition Number: 80.442  k Batch Size: 256        Lr: 0.100   
[2021-10-17 09:11:59,545][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.358    [weighted Loss:2.358    Policy Loss: 4.729    Value Loss: 5.075    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 1929993    Buffer Size: 4944       Transition Number: 80.426  k Batch Size: 256        Lr: 0.100   
[2021-10-17 10:02:14,234][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 4.384    Value Loss: 4.814    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 1946407    Buffer Size: 4600       Transition Number: 80.278  k Batch Size: 256        Lr: 0.100   
[2021-10-17 10:53:38,508][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.312    [weighted Loss:2.312    Policy Loss: 4.271    Value Loss: 4.656    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 1962487    Buffer Size: 4417       Transition Number: 80.208  k Batch Size: 256        Lr: 0.100   
[2021-10-17 11:45:21,067][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 4.672    Value Loss: 5.141    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 1978841    Buffer Size: 4467       Transition Number: 80.341  k Batch Size: 256        Lr: 0.100   
[2021-10-17 12:36:11,930][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.800    [weighted Loss:1.800    Policy Loss: 4.394    Value Loss: 5.091    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 1995791    Buffer Size: 4661       Transition Number: 80.672  k Batch Size: 256        Lr: 0.100   
[2021-10-17 13:26:43,811][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.366    [weighted Loss:1.366    Policy Loss: 4.323    Value Loss: 5.180    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 2012784    Buffer Size: 4676       Transition Number: 80.545  k Batch Size: 256        Lr: 0.100   
[2021-10-17 14:16:36,651][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 3.636    Value Loss: 5.166    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 2030554    Buffer Size: 5009       Transition Number: 80.223  k Batch Size: 256        Lr: 0.100   
[2021-10-17 15:07:16,623][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 4.204    Value Loss: 5.329    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 2047186    Buffer Size: 4639       Transition Number: 80.350  k Batch Size: 256        Lr: 0.100   
[2021-10-17 15:58:28,934][train][INFO][train.py>_log] ==> #121000     Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 4.210    Value Loss: 4.813    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 2063552    Buffer Size: 4565       Transition Number: 80.112  k Batch Size: 256        Lr: 0.100   
[2021-10-17 16:50:40,059][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.418    [weighted Loss:1.418    Policy Loss: 4.052    Value Loss: 4.860    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 2080217    Buffer Size: 4515       Transition Number: 80.277  k Batch Size: 256        Lr: 0.100   
[2021-10-17 17:39:40,950][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.348    [weighted Loss:1.348    Policy Loss: 4.426    Value Loss: 5.071    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 2098532    Buffer Size: 5138       Transition Number: 80.234  k Batch Size: 256        Lr: 0.100   
[2021-10-17 18:30:28,514][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.405    [weighted Loss:2.405    Policy Loss: 4.512    Value Loss: 4.787    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 2115472    Buffer Size: 4690       Transition Number: 80.371  k Batch Size: 256        Lr: 0.100   
[2021-10-17 19:19:52,970][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 4.257    Value Loss: 5.175    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 2134035    Buffer Size: 5164       Transition Number: 80.075  k Batch Size: 256        Lr: 0.100   
[2021-10-17 20:09:06,607][train][INFO][train.py>_log] ==> #126000     Total Loss: 0.995    [weighted Loss:0.995    Policy Loss: 4.085    Value Loss: 5.101    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 2151530    Buffer Size: 4939       Transition Number: 80.328  k Batch Size: 256        Lr: 0.100   
[2021-10-17 20:57:32,936][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.819    [weighted Loss:1.819    Policy Loss: 3.932    Value Loss: 5.439    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 2170123    Buffer Size: 5238       Transition Number: 80.082  k Batch Size: 256        Lr: 0.100   
[2021-10-17 21:46:27,479][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 4.045    Value Loss: 5.217    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 2189083    Buffer Size: 5322       Transition Number: 80.155  k Batch Size: 256        Lr: 0.100   
[2021-10-17 22:37:12,403][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.368    [weighted Loss:2.368    Policy Loss: 4.168    Value Loss: 4.986    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 2205308    Buffer Size: 4511       Transition Number: 80.233  k Batch Size: 256        Lr: 0.100   
[2021-10-17 23:23:13,244][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 4.007    Value Loss: 5.238    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 2225869    Buffer Size: 6014       Transition Number: 80.207  k Batch Size: 256        Lr: 0.100   
[2021-10-18 00:03:00,907][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.475    [weighted Loss:1.475    Policy Loss: 3.347    Value Loss: 5.141    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 2248991    Buffer Size: 7722       Transition Number: 80.324  k Batch Size: 256        Lr: 0.100   
[2021-10-18 00:44:25,196][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 3.580    Value Loss: 4.913    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 2274909    Buffer Size: 8402       Transition Number: 80.157  k Batch Size: 256        Lr: 0.100   
[2021-10-18 01:28:25,514][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.339    [weighted Loss:2.339    Policy Loss: 4.504    Value Loss: 5.197    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 2295096    Buffer Size: 6216       Transition Number: 80.078  k Batch Size: 256        Lr: 0.100   
[2021-10-18 02:11:49,159][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 4.081    Value Loss: 5.298    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 2316578    Buffer Size: 6656       Transition Number: 80.320  k Batch Size: 256        Lr: 0.100   
[2021-10-18 02:58:55,144][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 4.306    Value Loss: 5.001    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 2337773    Buffer Size: 6195       Transition Number: 80.147  k Batch Size: 256        Lr: 0.100   
[2021-10-18 03:49:25,217][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 4.538    Value Loss: 4.683    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 2355279    Buffer Size: 4908       Transition Number: 80.274  k Batch Size: 256        Lr: 0.100   
[2021-10-18 04:40:23,904][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.140    [weighted Loss:2.140    Policy Loss: 4.297    Value Loss: 4.956    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 2373268    Buffer Size: 4905       Transition Number: 80.124  k Batch Size: 256        Lr: 0.100   
[2021-10-18 05:32:43,124][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 4.270    Value Loss: 5.100    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 2390879    Buffer Size: 4792       Transition Number: 80.463  k Batch Size: 256        Lr: 0.100   
[2021-10-18 06:23:07,941][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 4.170    Value Loss: 4.823    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 2410683    Buffer Size: 5449       Transition Number: 80.184  k Batch Size: 256        Lr: 0.100   
[2021-10-18 07:14:13,687][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 4.032    Value Loss: 5.142    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 2427749    Buffer Size: 4669       Transition Number: 80.354  k Batch Size: 256        Lr: 0.100   
[2021-10-18 08:03:32,684][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 3.923    Value Loss: 5.237    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 2446227    Buffer Size: 5189       Transition Number: 80.367  k Batch Size: 256        Lr: 0.100   
[2021-10-18 08:54:29,970][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 4.100    Value Loss: 5.331    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 2462781    Buffer Size: 4558       Transition Number: 80.116  k Batch Size: 256        Lr: 0.100   
[2021-10-18 09:45:25,836][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 3.943    Value Loss: 5.202    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 2480219    Buffer Size: 4799       Transition Number: 80.474  k Batch Size: 256        Lr: 0.100   
[2021-10-18 10:25:41,231][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 3.587    Value Loss: 5.129    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 2510832    Buffer Size: 10046      Transition Number: 80.285  k Batch Size: 256        Lr: 0.100   
[2021-10-18 11:10:52,341][train][INFO][train.py>_log] ==> #145000     Total Loss: 1.533    [weighted Loss:1.533    Policy Loss: 3.876    Value Loss: 5.614    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 2527868    Buffer Size: 5203       Transition Number: 80.334  k Batch Size: 256        Lr: 0.100   
[2021-10-18 11:55:33,402][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 3.737    Value Loss: 5.189    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 2552374    Buffer Size: 7696       Transition Number: 80.375  k Batch Size: 256        Lr: 0.100   
[2021-10-18 12:42:58,451][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 4.162    Value Loss: 4.886    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 2571295    Buffer Size: 5533       Transition Number: 80.329  k Batch Size: 256        Lr: 0.100   
[2021-10-18 13:29:45,317][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 4.233    Value Loss: 4.865    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 2594268    Buffer Size: 6627       Transition Number: 80.115  k Batch Size: 256        Lr: 0.100   
[2021-10-18 14:14:05,203][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 4.106    Value Loss: 5.235    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 2618015    Buffer Size: 7262       Transition Number: 80.476  k Batch Size: 256        Lr: 0.100   
[2021-10-18 15:01:38,894][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 4.433    Value Loss: 5.533    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 2636582    Buffer Size: 5423       Transition Number: 80.493  k Batch Size: 256        Lr: 0.100   
[2021-10-18 15:51:23,117][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 4.346    Value Loss: 4.816    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 2655809    Buffer Size: 5326       Transition Number: 80.646  k Batch Size: 256        Lr: 0.100   
[2021-10-18 16:40:33,466][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 3.606    Value Loss: 4.967    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 2674501    Buffer Size: 5228       Transition Number: 80.218  k Batch Size: 256        Lr: 0.100   
[2021-10-18 17:31:51,672][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.137    [weighted Loss:1.137    Policy Loss: 4.370    Value Loss: 5.206    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 2691924    Buffer Size: 4732       Transition Number: 80.128  k Batch Size: 256        Lr: 0.100   
[2021-10-18 18:23:42,696][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 4.840    Value Loss: 5.278    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 2710271    Buffer Size: 4972       Transition Number: 80.622  k Batch Size: 256        Lr: 0.100   
[2021-10-18 19:13:51,350][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 4.092    Value Loss: 5.228    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 2728251    Buffer Size: 4979       Transition Number: 80.438  k Batch Size: 256        Lr: 0.100   
[2021-10-18 20:05:33,031][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 4.231    Value Loss: 5.121    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 2745678    Buffer Size: 4714       Transition Number: 80.093  k Batch Size: 256        Lr: 0.100   
[2021-10-18 20:57:03,874][train][INFO][train.py>_log] ==> #157000     Total Loss: 1.298    [weighted Loss:1.298    Policy Loss: 4.892    Value Loss: 4.876    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 2763282    Buffer Size: 4766       Transition Number: 80.382  k Batch Size: 256        Lr: 0.100   
[2021-10-18 21:46:34,210][train][INFO][train.py>_log] ==> #158000     Total Loss: 1.323    [weighted Loss:1.323    Policy Loss: 4.561    Value Loss: 5.046    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 2782920    Buffer Size: 5499       Transition Number: 80.216  k Batch Size: 256        Lr: 0.100   
[2021-10-18 22:37:59,831][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 4.359    Value Loss: 4.865    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 2801044    Buffer Size: 4924       Transition Number: 80.056  k Batch Size: 256        Lr: 0.100   
[2021-10-18 23:26:58,717][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 4.209    Value Loss: 4.942    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 2820983    Buffer Size: 5572       Transition Number: 80.106  k Batch Size: 256        Lr: 0.100   
[2021-10-19 00:13:25,549][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 4.305    Value Loss: 5.477    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 2840699    Buffer Size: 5765       Transition Number: 80.374  k Batch Size: 256        Lr: 0.100   
[2021-10-19 01:02:02,733][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.421    [weighted Loss:1.421    Policy Loss: 4.203    Value Loss: 4.744    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 2861924    Buffer Size: 6035       Transition Number: 80.189  k Batch Size: 256        Lr: 0.100   
[2021-10-19 01:46:55,034][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 4.551    Value Loss: 4.896    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 2892308    Buffer Size: 9187       Transition Number: 80.102  k Batch Size: 256        Lr: 0.100   
[2021-10-19 02:36:02,808][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 4.470    Value Loss: 5.294    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 2909296    Buffer Size: 4821       Transition Number: 80.124  k Batch Size: 256        Lr: 0.100   
[2021-10-19 03:26:45,546][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 4.435    Value Loss: 5.017    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 2927993    Buffer Size: 5152       Transition Number: 80.291  k Batch Size: 256        Lr: 0.100   
[2021-10-19 04:14:04,934][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 4.099    Value Loss: 5.243    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 2951273    Buffer Size: 6757       Transition Number: 80.111  k Batch Size: 256        Lr: 0.100   
[2021-10-19 05:04:28,292][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.493    [weighted Loss:1.493    Policy Loss: 4.278    Value Loss: 4.855    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 2969409    Buffer Size: 5011       Transition Number: 80.099  k Batch Size: 256        Lr: 0.100   
[2021-10-19 05:55:34,700][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.542    [weighted Loss:1.542    Policy Loss: 3.840    Value Loss: 4.942    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 2988654    Buffer Size: 5215       Transition Number: 80.394  k Batch Size: 256        Lr: 0.100   
[2021-10-19 06:45:23,949][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.447    [weighted Loss:1.447    Policy Loss: 4.140    Value Loss: 5.035    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 3008481    Buffer Size: 5458       Transition Number: 80.670  k Batch Size: 256        Lr: 0.100   
[2021-10-19 07:34:28,058][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 4.093    Value Loss: 5.224    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 3028675    Buffer Size: 5590       Transition Number: 80.421  k Batch Size: 256        Lr: 0.100   
[2021-10-19 08:26:21,782][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.383    [weighted Loss:1.383    Policy Loss: 4.083    Value Loss: 5.135    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 3046991    Buffer Size: 4954       Transition Number: 80.359  k Batch Size: 256        Lr: 0.100   
[2021-10-19 09:18:46,878][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.522    [weighted Loss:2.522    Policy Loss: 4.219    Value Loss: 5.197    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 3064763    Buffer Size: 4698       Transition Number: 80.131  k Batch Size: 256        Lr: 0.100   
[2021-10-19 10:07:56,646][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 3.880    Value Loss: 5.048    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 3084841    Buffer Size: 5623       Transition Number: 80.398  k Batch Size: 256        Lr: 0.100   
[2021-10-19 10:59:00,973][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 4.499    Value Loss: 5.147    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 3102581    Buffer Size: 4797       Transition Number: 80.261  k Batch Size: 256        Lr: 0.100   
[2021-10-19 11:50:51,203][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 4.502    Value Loss: 5.049    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 3120816    Buffer Size: 4938       Transition Number: 80.315  k Batch Size: 256        Lr: 0.100   
[2021-10-19 12:39:32,401][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 4.253    Value Loss: 5.391    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 3139536    Buffer Size: 5250       Transition Number: 80.084  k Batch Size: 256        Lr: 0.100   
[2021-10-19 13:30:02,298][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.746    [weighted Loss:1.746    Policy Loss: 3.897    Value Loss: 5.485    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 3158233    Buffer Size: 5077       Transition Number: 80.388  k Batch Size: 256        Lr: 0.100   
[2021-10-19 14:14:26,383][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 3.583    Value Loss: 5.209    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 3181611    Buffer Size: 7036       Transition Number: 80.375  k Batch Size: 256        Lr: 0.100   
[2021-10-19 15:05:02,051][train][INFO][train.py>_log] ==> #179000     Total Loss: 0.748    [weighted Loss:0.748    Policy Loss: 4.182    Value Loss: 5.130    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 3198905    Buffer Size: 4751       Transition Number: 80.118  k Batch Size: 256        Lr: 0.100   
[2021-10-19 15:57:42,967][train][INFO][train.py>_log] ==> #180000     Total Loss: 0.969    [weighted Loss:0.969    Policy Loss: 4.299    Value Loss: 5.058    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 3216322    Buffer Size: 4714       Transition Number: 80.316  k Batch Size: 256        Lr: 0.100   
[2021-10-19 16:47:33,869][train][INFO][train.py>_log] ==> #181000     Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 4.068    Value Loss: 4.874    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 3235435    Buffer Size: 5213       Transition Number: 80.209  k Batch Size: 256        Lr: 0.100   
[2021-10-19 17:37:48,471][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.193    [weighted Loss:1.193    Policy Loss: 4.407    Value Loss: 4.948    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 3254520    Buffer Size: 5271       Transition Number: 80.501  k Batch Size: 256        Lr: 0.100   
[2021-10-19 18:27:25,970][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.513    [weighted Loss:2.513    Policy Loss: 4.392    Value Loss: 4.910    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 3273709    Buffer Size: 5253       Transition Number: 80.307  k Batch Size: 256        Lr: 0.100   
[2021-10-19 19:19:13,506][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 4.149    Value Loss: 5.240    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 3291005    Buffer Size: 4692       Transition Number: 80.135  k Batch Size: 256        Lr: 0.100   
[2021-10-19 20:08:05,095][train][INFO][train.py>_log] ==> #185000     Total Loss: 1.571    [weighted Loss:1.571    Policy Loss: 3.949    Value Loss: 5.343    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 3310597    Buffer Size: 5517       Transition Number: 80.203  k Batch Size: 256        Lr: 0.100   
[2021-10-19 20:52:23,981][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 3.754    Value Loss: 5.247    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 3334387    Buffer Size: 7164       Transition Number: 80.534  k Batch Size: 256        Lr: 0.100   
[2021-10-19 21:41:39,489][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 4.315    Value Loss: 5.211    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 3352401    Buffer Size: 5019       Transition Number: 80.170  k Batch Size: 256        Lr: 0.100   
[2021-10-19 22:30:44,642][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 3.903    Value Loss: 5.249    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 3372077    Buffer Size: 5515       Transition Number: 80.333  k Batch Size: 256        Lr: 0.100   
[2021-10-19 23:14:36,959][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 3.923    Value Loss: 4.952    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 3396838    Buffer Size: 7487       Transition Number: 80.219  k Batch Size: 256        Lr: 0.100   
[2021-10-20 00:04:13,248][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.671    [weighted Loss:1.671    Policy Loss: 3.848    Value Loss: 5.175    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 3414726    Buffer Size: 5008       Transition Number: 80.357  k Batch Size: 256        Lr: 0.100   
[2021-10-20 00:53:45,413][train][INFO][train.py>_log] ==> #191000     Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 4.015    Value Loss: 5.022    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 3434092    Buffer Size: 5458       Transition Number: 80.192  k Batch Size: 256        Lr: 0.100   
[2021-10-20 01:40:53,313][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 4.083    Value Loss: 5.120    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 3455269    Buffer Size: 5966       Transition Number: 80.094  k Batch Size: 256        Lr: 0.100   
[2021-10-20 02:31:54,260][train][INFO][train.py>_log] ==> #193000     Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 4.263    Value Loss: 5.221    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 3473274    Buffer Size: 4936       Transition Number: 80.116  k Batch Size: 256        Lr: 0.100   
[2021-10-20 03:20:54,762][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.120    [weighted Loss:1.120    Policy Loss: 3.877    Value Loss: 5.242    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 3493931    Buffer Size: 5747       Transition Number: 80.125  k Batch Size: 256        Lr: 0.100   
[2021-10-20 04:07:25,536][train][INFO][train.py>_log] ==> #195000     Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 3.934    Value Loss: 5.415    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 3515096    Buffer Size: 6223       Transition Number: 80.278  k Batch Size: 256        Lr: 0.100   
[2021-10-20 04:57:02,992][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.239    [weighted Loss:1.239    Policy Loss: 3.877    Value Loss: 5.238    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 3534025    Buffer Size: 5272       Transition Number: 80.378  k Batch Size: 256        Lr: 0.100   
[2021-10-20 05:45:01,477][train][INFO][train.py>_log] ==> #197000     Total Loss: 1.449    [weighted Loss:1.449    Policy Loss: 4.202    Value Loss: 5.519    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 3554376    Buffer Size: 5752       Transition Number: 80.258  k Batch Size: 256        Lr: 0.100   
[2021-10-20 06:34:53,671][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 4.384    Value Loss: 5.270    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 3572862    Buffer Size: 5228       Transition Number: 80.109  k Batch Size: 256        Lr: 0.100   
[2021-10-20 07:25:58,361][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 4.085    Value Loss: 5.289    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 3591353    Buffer Size: 4978       Transition Number: 80.386  k Batch Size: 256        Lr: 0.100   
[2021-10-20 08:16:06,312][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 3.881    Value Loss: 5.178    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 3610219    Buffer Size: 5222       Transition Number: 80.519  k Batch Size: 256        Lr: 0.100   
[2021-10-20 09:05:49,472][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.428    [weighted Loss:1.428    Policy Loss: 4.149    Value Loss: 5.255    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 3629213    Buffer Size: 5283       Transition Number: 80.506  k Batch Size: 256        Lr: 0.100   
