[2021-11-04 14:40:29,701][train][INFO][train.py>_log] ==> #0          Total Loss: 15.235   [weighted Loss:15.235   Policy Loss: 13.401   Value Loss: 3.390    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 50         Buffer Size: 50         Transition Number: 0.594   k Batch Size: 128        Lr: 0.000   
[2021-11-04 14:45:11,673][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.785    [weighted Loss:4.785    Policy Loss: 7.563    Value Loss: 2.639    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 498        Buffer Size: 498        Transition Number: 3.919   k Batch Size: 128        Lr: 0.010   
[2021-11-04 14:49:59,728][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.648    [weighted Loss:3.648    Policy Loss: 6.830    Value Loss: 2.644    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 842        Buffer Size: 842        Transition Number: 7.089   k Batch Size: 128        Lr: 0.020   
[2021-11-04 14:55:00,050][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.274    [weighted Loss:3.274    Policy Loss: 6.695    Value Loss: 2.818    Reward Loss: 1.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 1204       Buffer Size: 1204       Transition Number: 10.504  k Batch Size: 128        Lr: 0.030   
[2021-11-04 15:00:25,180][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 5.698    Value Loss: 2.953    Reward Loss: 1.274    Consistency Loss: 0.000    ] Replay Episodes Collected: 1613       Buffer Size: 1613       Transition Number: 14.120  k Batch Size: 128        Lr: 0.040   
[2021-11-04 15:05:53,848][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 5.967    Value Loss: 2.511    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 2148       Buffer Size: 2148       Transition Number: 17.975  k Batch Size: 128        Lr: 0.050   
[2021-11-04 15:11:14,872][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 5.898    Value Loss: 3.020    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 2803       Buffer Size: 2803       Transition Number: 21.976  k Batch Size: 128        Lr: 0.060   
[2021-11-04 15:16:26,029][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 6.750    Value Loss: 3.056    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 3380       Buffer Size: 3380       Transition Number: 25.565  k Batch Size: 128        Lr: 0.070   
[2021-11-04 15:21:37,788][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 7.087    Value Loss: 2.752    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 4139       Buffer Size: 4139       Transition Number: 29.396  k Batch Size: 128        Lr: 0.080   
[2021-11-04 15:26:47,696][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 4.795    Value Loss: 2.878    Reward Loss: 1.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 4637       Buffer Size: 4637       Transition Number: 32.979  k Batch Size: 128        Lr: 0.090   
[2021-11-04 15:32:00,439][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 4.937    Value Loss: 2.576    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 5280       Buffer Size: 5280       Transition Number: 36.792  k Batch Size: 128        Lr: 0.100   
[2021-11-04 15:37:16,113][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.448    [weighted Loss:3.448    Policy Loss: 6.478    Value Loss: 2.839    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 5899       Buffer Size: 5899       Transition Number: 40.496  k Batch Size: 128        Lr: 0.100   
[2021-11-04 15:42:35,175][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 6.681    Value Loss: 2.698    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 6495       Buffer Size: 6495       Transition Number: 44.240  k Batch Size: 128        Lr: 0.100   
[2021-11-04 15:47:51,500][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.769    [weighted Loss:3.769    Policy Loss: 7.070    Value Loss: 2.804    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 6959       Buffer Size: 6959       Transition Number: 47.862  k Batch Size: 128        Lr: 0.100   
[2021-11-04 15:52:50,548][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 7.093    Value Loss: 3.070    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 7431       Buffer Size: 7431       Transition Number: 51.291  k Batch Size: 128        Lr: 0.100   
[2021-11-04 15:58:05,586][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.609    [weighted Loss:5.609    Policy Loss: 10.562   Value Loss: 2.918    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 7993       Buffer Size: 7993       Transition Number: 55.048  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:03:21,843][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.131    [weighted Loss:5.131    Policy Loss: 8.472    Value Loss: 2.851    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 8375       Buffer Size: 8375       Transition Number: 58.637  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:08:55,675][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.299    [weighted Loss:4.299    Policy Loss: 7.483    Value Loss: 3.097    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 8898       Buffer Size: 8898       Transition Number: 62.733  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:13:58,722][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.109    [weighted Loss:5.109    Policy Loss: 8.080    Value Loss: 2.864    Reward Loss: 1.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 9474       Buffer Size: 9474       Transition Number: 66.246  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:19:04,155][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.944    [weighted Loss:4.944    Policy Loss: 8.264    Value Loss: 2.997    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 9854       Buffer Size: 9854       Transition Number: 69.532  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:24:38,551][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.002    [weighted Loss:3.002    Policy Loss: 8.300    Value Loss: 2.884    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 10363      Buffer Size: 10363      Transition Number: 73.457  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:30:01,453][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 5.998    Value Loss: 2.799    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 10879      Buffer Size: 10879      Transition Number: 77.349  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:35:15,007][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.371    [weighted Loss:3.371    Policy Loss: 7.205    Value Loss: 3.064    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 11378      Buffer Size: 11378      Transition Number: 80.950  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:40:30,857][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.225    [weighted Loss:4.225    Policy Loss: 8.535    Value Loss: 2.724    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 11851      Buffer Size: 11851      Transition Number: 84.420  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:45:59,483][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 5.728    Value Loss: 2.946    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 12439      Buffer Size: 12439      Transition Number: 88.257  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:51:33,689][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 7.465    Value Loss: 2.953    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 13092      Buffer Size: 13092      Transition Number: 92.124  k Batch Size: 128        Lr: 0.100   
[2021-11-04 16:57:14,268][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.966    [weighted Loss:2.966    Policy Loss: 7.460    Value Loss: 2.827    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 13775      Buffer Size: 13775      Transition Number: 96.125  k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:02:34,926][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 5.790    Value Loss: 2.933    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 14256      Buffer Size: 14256      Transition Number: 99.732  k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:08:03,913][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.527    [weighted Loss:3.527    Policy Loss: 6.768    Value Loss: 2.982    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 14852      Buffer Size: 14852      Transition Number: 103.555 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:13:13,945][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.854    [weighted Loss:2.854    Policy Loss: 6.182    Value Loss: 2.777    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 15502      Buffer Size: 15502      Transition Number: 107.459 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:18:47,328][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.076    [weighted Loss:2.076    Policy Loss: 6.886    Value Loss: 2.938    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 15992      Buffer Size: 15992      Transition Number: 111.492 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:24:06,829][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 6.210    Value Loss: 3.033    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 16574      Buffer Size: 16574      Transition Number: 115.535 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:29:27,159][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.803    [weighted Loss:4.803    Policy Loss: 8.326    Value Loss: 3.099    Reward Loss: 1.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 17123      Buffer Size: 17123      Transition Number: 119.666 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:34:33,519][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.947    [weighted Loss:3.947    Policy Loss: 5.043    Value Loss: 2.824    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 17711      Buffer Size: 17711      Transition Number: 123.438 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:39:53,078][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 6.383    Value Loss: 3.001    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 18300      Buffer Size: 18300      Transition Number: 127.354 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:45:04,776][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.353    [weighted Loss:1.353    Policy Loss: 5.888    Value Loss: 3.089    Reward Loss: 1.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 18865      Buffer Size: 18865      Transition Number: 131.197 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:50:36,233][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.402    [weighted Loss:3.402    Policy Loss: 6.764    Value Loss: 3.239    Reward Loss: 1.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 19431      Buffer Size: 19431      Transition Number: 135.190 k Batch Size: 128        Lr: 0.100   
[2021-11-04 17:55:52,597][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.600    [weighted Loss:3.600    Policy Loss: 7.141    Value Loss: 3.110    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 19949      Buffer Size: 19949      Transition Number: 138.895 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:01:27,566][train][INFO][train.py>_log] ==> #38000      Total Loss: 4.571    [weighted Loss:4.571    Policy Loss: 7.669    Value Loss: 3.349    Reward Loss: 1.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 20358      Buffer Size: 20358      Transition Number: 143.049 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:06:38,116][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.971    [weighted Loss:2.971    Policy Loss: 7.639    Value Loss: 3.036    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 20916      Buffer Size: 20916      Transition Number: 146.762 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:11:39,291][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.452    [weighted Loss:3.452    Policy Loss: 8.367    Value Loss: 3.174    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 21331      Buffer Size: 21309      Transition Number: 150.005 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:16:59,606][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.858    [weighted Loss:3.858    Policy Loss: 6.367    Value Loss: 2.860    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 21654      Buffer Size: 21158      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:22:24,261][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 8.335    Value Loss: 3.110    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 21977      Buffer Size: 21097      Transition Number: 149.960 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:27:56,229][train][INFO][train.py>_log] ==> #43000      Total Loss: 4.118    [weighted Loss:4.118    Policy Loss: 7.221    Value Loss: 3.370    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 22518      Buffer Size: 21240      Transition Number: 150.034 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:33:00,127][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.985    [weighted Loss:3.985    Policy Loss: 9.187    Value Loss: 3.047    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 22942      Buffer Size: 21247      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:38:28,925][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 7.942    Value Loss: 3.364    Reward Loss: 1.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 23212      Buffer Size: 21028      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:44:01,544][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.168    [weighted Loss:3.168    Policy Loss: 7.695    Value Loss: 3.469    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 23441      Buffer Size: 20678      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:49:38,849][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 7.624    Value Loss: 3.115    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 23945      Buffer Size: 20540      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-04 18:55:29,320][train][INFO][train.py>_log] ==> #48000      Total Loss: 4.433    [weighted Loss:4.433    Policy Loss: 8.236    Value Loss: 3.243    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 24463      Buffer Size: 20276      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-04 19:01:05,589][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.458    [weighted Loss:3.458    Policy Loss: 7.985    Value Loss: 3.342    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 24767      Buffer Size: 20147      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-04 19:15:17,629][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.248    [weighted Loss:3.248    Policy Loss: 8.651    Value Loss: 3.161    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 25111      Buffer Size: 19945      Transition Number: 150.092 k Batch Size: 128        Lr: 0.100   
[2021-11-04 19:22:11,498][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.938    [weighted Loss:3.938    Policy Loss: 10.221   Value Loss: 3.559    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 26079      Buffer Size: 19130      Transition Number: 150.012 k Batch Size: 128        Lr: 0.100   
[2021-11-04 19:29:10,621][train][INFO][train.py>_log] ==> #52000      Total Loss: 4.378    [weighted Loss:4.378    Policy Loss: 10.062   Value Loss: 3.345    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 26390      Buffer Size: 18857      Transition Number: 150.009 k Batch Size: 128        Lr: 0.100   
[2021-11-04 19:36:58,865][train][INFO][train.py>_log] ==> #53000      Total Loss: 6.836    [weighted Loss:6.836    Policy Loss: 11.153   Value Loss: 3.672    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 26715      Buffer Size: 18586      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-04 19:45:08,959][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 8.966    Value Loss: 3.650    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 26989      Buffer Size: 18321      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-04 19:53:27,538][train][INFO][train.py>_log] ==> #55000      Total Loss: 4.514    [weighted Loss:4.514    Policy Loss: 10.196   Value Loss: 3.406    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 27517      Buffer Size: 18040      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-04 20:02:50,960][train][INFO][train.py>_log] ==> #56000      Total Loss: 5.276    [weighted Loss:5.276    Policy Loss: 9.757    Value Loss: 3.792    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 27943      Buffer Size: 17717      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-04 20:11:47,763][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.248    [weighted Loss:4.248    Policy Loss: 8.443    Value Loss: 3.665    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 28584      Buffer Size: 17621      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-04 20:21:49,626][train][INFO][train.py>_log] ==> #58000      Total Loss: 5.523    [weighted Loss:5.523    Policy Loss: 10.329   Value Loss: 3.510    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 29056      Buffer Size: 17183      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-04 20:32:45,922][train][INFO][train.py>_log] ==> #59000      Total Loss: 4.677    [weighted Loss:4.677    Policy Loss: 10.764   Value Loss: 3.646    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 29565      Buffer Size: 16580      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-04 20:45:06,477][train][INFO][train.py>_log] ==> #60000      Total Loss: 5.202    [weighted Loss:5.202    Policy Loss: 9.977    Value Loss: 3.601    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 30293      Buffer Size: 15963      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-04 20:59:13,994][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.233    [weighted Loss:4.233    Policy Loss: 11.011   Value Loss: 3.585    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 31060      Buffer Size: 15296      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-04 21:14:31,414][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.985    [weighted Loss:3.985    Policy Loss: 12.482   Value Loss: 3.725    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 31926      Buffer Size: 14726      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-04 21:40:50,345][train][INFO][train.py>_log] ==> #63000      Total Loss: 5.398    [weighted Loss:5.398    Policy Loss: 12.281   Value Loss: 3.479    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 33113      Buffer Size: 13360      Transition Number: 150.002 k Batch Size: 128        Lr: 0.100   
[2021-11-04 22:34:36,649][train][INFO][train.py>_log] ==> #64000      Total Loss: 5.341    [weighted Loss:5.341    Policy Loss: 12.859   Value Loss: 4.022    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 35185      Buffer Size: 11589      Transition Number: 150.015 k Batch Size: 128        Lr: 0.100   
[2021-11-04 23:36:41,648][train][INFO][train.py>_log] ==> #65000      Total Loss: 5.919    [weighted Loss:5.919    Policy Loss: 13.289   Value Loss: 3.650    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 39345      Buffer Size: 11876      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
