[2021-11-08 15:58:03,320][train][INFO][train.py>_log] ==> #0          Total Loss: 44.439   [weighted Loss:44.439   Policy Loss: 14.441   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 43         Buffer Size: 43         Transition Number: 0.569   k Batch Size: 128        Lr: 0.000   
[2021-11-08 16:00:28,991][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.719    [weighted Loss:7.719    Policy Loss: 13.411   Value Loss: 4.472    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 465        Buffer Size: 465        Transition Number: 5.848   k Batch Size: 128        Lr: 0.010   
[2021-11-08 16:03:44,540][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.598    [weighted Loss:6.598    Policy Loss: 14.529   Value Loss: 3.418    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069       Buffer Size: 1069       Transition Number: 13.086  k Batch Size: 128        Lr: 0.020   
[2021-11-08 16:07:11,997][train][INFO][train.py>_log] ==> #3000       Total Loss: 7.579    [weighted Loss:7.579    Policy Loss: 14.220   Value Loss: 3.371    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 1710       Buffer Size: 1710       Transition Number: 19.981  k Batch Size: 128        Lr: 0.030   
[2021-11-08 16:10:39,657][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.317    [weighted Loss:6.317    Policy Loss: 13.207   Value Loss: 2.767    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2344       Buffer Size: 2344       Transition Number: 26.615  k Batch Size: 128        Lr: 0.040   
[2021-11-08 16:14:09,997][train][INFO][train.py>_log] ==> #5000       Total Loss: 6.654    [weighted Loss:6.654    Policy Loss: 12.892   Value Loss: 3.481    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 3070       Buffer Size: 3070       Transition Number: 33.339  k Batch Size: 128        Lr: 0.050   
[2021-11-08 16:17:42,785][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.763    [weighted Loss:5.763    Policy Loss: 12.971   Value Loss: 2.725    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 3674       Buffer Size: 3674       Transition Number: 40.085  k Batch Size: 128        Lr: 0.060   
[2021-11-08 16:21:21,164][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.824    [weighted Loss:5.824    Policy Loss: 13.323   Value Loss: 2.745    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 4298       Buffer Size: 4298       Transition Number: 47.071  k Batch Size: 128        Lr: 0.070   
[2021-11-08 16:24:55,868][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.517    [weighted Loss:5.517    Policy Loss: 14.047   Value Loss: 2.884    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 5026       Buffer Size: 5026       Transition Number: 54.006  k Batch Size: 128        Lr: 0.080   
[2021-11-08 16:28:42,958][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.618    [weighted Loss:4.618    Policy Loss: 12.944   Value Loss: 2.531    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 5557       Buffer Size: 5557       Transition Number: 60.944  k Batch Size: 128        Lr: 0.090   
[2021-11-08 16:32:26,741][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.115    [weighted Loss:5.115    Policy Loss: 12.601   Value Loss: 2.742    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 6153       Buffer Size: 6153       Transition Number: 67.991  k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:36:19,929][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.902    [weighted Loss:5.902    Policy Loss: 13.430   Value Loss: 2.688    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 6753       Buffer Size: 6753       Transition Number: 75.552  k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:40:13,777][train][INFO][train.py>_log] ==> #12000      Total Loss: 7.043    [weighted Loss:7.043    Policy Loss: 13.573   Value Loss: 2.771    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 7325       Buffer Size: 7325       Transition Number: 83.065  k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:43:59,725][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.965    [weighted Loss:5.965    Policy Loss: 14.866   Value Loss: 3.020    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 8071       Buffer Size: 8071       Transition Number: 90.421  k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:47:42,194][train][INFO][train.py>_log] ==> #14000      Total Loss: 6.740    [weighted Loss:6.740    Policy Loss: 14.174   Value Loss: 2.868    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 8805       Buffer Size: 8805       Transition Number: 97.678  k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:51:22,240][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.722    [weighted Loss:5.722    Policy Loss: 12.870   Value Loss: 2.494    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 9556       Buffer Size: 9556       Transition Number: 104.991 k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:55:02,677][train][INFO][train.py>_log] ==> #16000      Total Loss: 6.037    [weighted Loss:6.037    Policy Loss: 13.104   Value Loss: 2.804    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 10269      Buffer Size: 10269      Transition Number: 112.213 k Batch Size: 128        Lr: 0.100   
[2021-11-08 16:58:45,544][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.960    [weighted Loss:4.960    Policy Loss: 12.931   Value Loss: 2.688    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 10944      Buffer Size: 10944      Transition Number: 119.324 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:02:33,124][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.957    [weighted Loss:5.957    Policy Loss: 12.710   Value Loss: 2.878    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 11629      Buffer Size: 11629      Transition Number: 126.748 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:06:19,594][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.817    [weighted Loss:4.817    Policy Loss: 12.730   Value Loss: 2.728    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 12286      Buffer Size: 12286      Transition Number: 134.033 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:10:09,200][train][INFO][train.py>_log] ==> #20000      Total Loss: 7.328    [weighted Loss:7.328    Policy Loss: 13.835   Value Loss: 2.814    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 12782      Buffer Size: 12782      Transition Number: 141.066 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:14:10,663][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.849    [weighted Loss:5.849    Policy Loss: 12.775   Value Loss: 2.643    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 13283      Buffer Size: 13283      Transition Number: 148.071 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:18:35,860][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.440    [weighted Loss:4.440    Policy Loss: 13.722   Value Loss: 2.954    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 13715      Buffer Size: 13715      Transition Number: 155.721 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:23:07,403][train][INFO][train.py>_log] ==> #23000      Total Loss: 5.241    [weighted Loss:5.241    Policy Loss: 13.312   Value Loss: 3.436    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 14140      Buffer Size: 14140      Transition Number: 162.737 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:27:54,306][train][INFO][train.py>_log] ==> #24000      Total Loss: 7.383    [weighted Loss:7.383    Policy Loss: 14.846   Value Loss: 2.841    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 14424      Buffer Size: 14424      Transition Number: 169.381 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:33:22,950][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.427    [weighted Loss:4.427    Policy Loss: 12.065   Value Loss: 2.819    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 14730      Buffer Size: 14730      Transition Number: 176.797 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:39:04,598][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.307    [weighted Loss:5.307    Policy Loss: 11.221   Value Loss: 2.954    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 15042      Buffer Size: 15042      Transition Number: 184.391 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:45:06,574][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 10.435   Value Loss: 3.158    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 15578      Buffer Size: 15578      Transition Number: 192.465 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:51:03,996][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.866    [weighted Loss:4.866    Policy Loss: 10.781   Value Loss: 3.257    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 15972      Buffer Size: 15972      Transition Number: 199.585 k Batch Size: 128        Lr: 0.100   
[2021-11-08 17:57:13,811][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.970    [weighted Loss:4.970    Policy Loss: 10.110   Value Loss: 3.573    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 16348      Buffer Size: 16348      Transition Number: 206.962 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:04:03,128][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.846    [weighted Loss:2.846    Policy Loss: 8.779    Value Loss: 3.425    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 16618      Buffer Size: 16618      Transition Number: 216.729 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:11:13,257][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.473    [weighted Loss:3.473    Policy Loss: 9.403    Value Loss: 3.601    Reward Loss: 0.952    Consistency Loss: 0.000    ] Replay Episodes Collected: 16943      Buffer Size: 16943      Transition Number: 227.188 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:18:21,969][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 9.127    Value Loss: 3.677    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 17457      Buffer Size: 17457      Transition Number: 237.090 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:25:45,051][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 9.405    Value Loss: 3.843    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 17973      Buffer Size: 17973      Transition Number: 247.145 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:32:56,765][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 8.804    Value Loss: 3.740    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 18530      Buffer Size: 18530      Transition Number: 258.148 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:40:27,580][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 8.195    Value Loss: 3.596    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 18909      Buffer Size: 18909      Transition Number: 269.324 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:48:12,478][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.384    [weighted Loss:2.384    Policy Loss: 7.482    Value Loss: 3.971    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 19512      Buffer Size: 19512      Transition Number: 280.871 k Batch Size: 128        Lr: 0.100   
[2021-11-08 18:55:39,170][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 8.323    Value Loss: 4.199    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 20284      Buffer Size: 20284      Transition Number: 290.605 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:03:08,341][train][INFO][train.py>_log] ==> #38000      Total Loss: 4.344    [weighted Loss:4.344    Policy Loss: 6.564    Value Loss: 4.242    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 20973      Buffer Size: 20973      Transition Number: 301.278 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:11:12,608][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 6.366    Value Loss: 3.885    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 21568      Buffer Size: 21568      Transition Number: 313.254 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:19:15,377][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.384    [weighted Loss:3.384    Policy Loss: 6.216    Value Loss: 3.952    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 22192      Buffer Size: 22192      Transition Number: 326.020 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:26:58,191][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.511    [weighted Loss:2.511    Policy Loss: 5.105    Value Loss: 3.840    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 22776      Buffer Size: 22776      Transition Number: 338.381 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:34:47,172][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 4.510    Value Loss: 3.837    Reward Loss: 0.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 23261      Buffer Size: 23261      Transition Number: 350.570 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:43:29,435][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 3.920    Value Loss: 4.136    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 23831      Buffer Size: 23831      Transition Number: 363.321 k Batch Size: 128        Lr: 0.100   
[2021-11-08 19:52:15,131][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.857    [weighted Loss:1.857    Policy Loss: 3.662    Value Loss: 4.233    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 24372      Buffer Size: 24372      Transition Number: 376.694 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:01:03,854][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 3.385    Value Loss: 4.000    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 25363      Buffer Size: 25363      Transition Number: 389.973 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:09:45,382][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.906    [weighted Loss:1.906    Policy Loss: 3.065    Value Loss: 3.739    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 25917      Buffer Size: 25794      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:18:19,907][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 3.272    Value Loss: 4.470    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 28463      Buffer Size: 26953      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:26:26,293][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 2.550    Value Loss: 4.006    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 30130      Buffer Size: 27323      Transition Number: 400.002 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:35:04,249][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 2.975    Value Loss: 3.918    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 31274      Buffer Size: 27395      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:43:35,132][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 1.776    Value Loss: 3.841    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 32509      Buffer Size: 27457      Transition Number: 400.002 k Batch Size: 128        Lr: 0.100   
[2021-11-08 20:52:14,256][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.390    [weighted Loss:1.390    Policy Loss: 1.880    Value Loss: 4.287    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 33237      Buffer Size: 27247      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:01:01,550][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.375    [weighted Loss:1.375    Policy Loss: 1.912    Value Loss: 4.074    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 33602      Buffer Size: 26611      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:10:09,904][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.550    [weighted Loss:1.550    Policy Loss: 1.852    Value Loss: 4.308    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 34343      Buffer Size: 26092      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:19:02,747][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.547    [weighted Loss:1.547    Policy Loss: 2.816    Value Loss: 3.787    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 34970      Buffer Size: 25410      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:28:08,199][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.953    [weighted Loss:1.953    Policy Loss: 1.952    Value Loss: 4.150    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 35492      Buffer Size: 24676      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:37:33,043][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.312    [weighted Loss:1.312    Policy Loss: 1.343    Value Loss: 4.040    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 35928      Buffer Size: 23872      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:47:13,830][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.740    [weighted Loss:1.740    Policy Loss: 1.372    Value Loss: 3.896    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 36389      Buffer Size: 23294      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-08 21:56:49,648][train][INFO][train.py>_log] ==> #58000      Total Loss: 0.888    [weighted Loss:0.888    Policy Loss: 1.598    Value Loss: 4.024    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 37076      Buffer Size: 23133      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:06:53,170][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.075    [weighted Loss:1.075    Policy Loss: 1.313    Value Loss: 3.928    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 37675      Buffer Size: 23049      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:16:24,801][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 1.455    Value Loss: 3.992    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 39660      Buffer Size: 24193      Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:25:27,954][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.106    [weighted Loss:1.106    Policy Loss: 2.197    Value Loss: 4.024    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 42825      Buffer Size: 26441      Transition Number: 399.935 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:34:11,856][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 1.850    Value Loss: 3.957    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 44219      Buffer Size: 27450      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:42:58,144][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.301    [weighted Loss:1.301    Policy Loss: 1.713    Value Loss: 3.921    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 45098      Buffer Size: 27788      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-08 22:52:05,877][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 2.201    Value Loss: 4.151    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 46238      Buffer Size: 28188      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:01:32,771][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 2.281    Value Loss: 4.201    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 46775      Buffer Size: 28074      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:10:37,044][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 4.525    Value Loss: 4.021    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 47468      Buffer Size: 28163      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:19:28,830][train][INFO][train.py>_log] ==> #67000      Total Loss: 4.537    [weighted Loss:4.537    Policy Loss: 6.445    Value Loss: 4.153    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 47838      Buffer Size: 27575      Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:28:24,829][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.467    [weighted Loss:1.467    Policy Loss: 3.431    Value Loss: 3.887    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 48409      Buffer Size: 27319      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:37:47,892][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 3.030    Value Loss: 3.973    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 48847      Buffer Size: 27099      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:48:19,220][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 2.494    Value Loss: 3.889    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 49271      Buffer Size: 26729      Transition Number: 400.018 k Batch Size: 128        Lr: 0.100   
[2021-11-08 23:58:16,398][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 2.716    Value Loss: 4.188    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 50563      Buffer Size: 27321      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:07:01,688][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 3.819    Value Loss: 3.673    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 53822      Buffer Size: 29780      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:15:45,122][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 6.825    Value Loss: 3.719    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 55467      Buffer Size: 30605      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:24:29,095][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.234    [weighted Loss:3.234    Policy Loss: 6.729    Value Loss: 3.732    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 56407      Buffer Size: 30699      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:33:38,312][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 7.641    Value Loss: 4.046    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 56760      Buffer Size: 29449      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:43:48,705][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.452    [weighted Loss:4.452    Policy Loss: 6.981    Value Loss: 4.559    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 57140      Buffer Size: 27556      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 00:54:02,128][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.023    [weighted Loss:4.023    Policy Loss: 6.693    Value Loss: 4.379    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 57428      Buffer Size: 26070      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:04:18,815][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 6.045    Value Loss: 4.333    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 57710      Buffer Size: 24723      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:14:37,524][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 5.678    Value Loss: 4.296    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 58108      Buffer Size: 24526      Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:24:45,018][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 5.259    Value Loss: 4.016    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 58422      Buffer Size: 23953      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:35:30,073][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.238    [weighted Loss:3.238    Policy Loss: 5.695    Value Loss: 4.272    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 58750      Buffer Size: 23493      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:46:25,041][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 5.619    Value Loss: 4.074    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 59095      Buffer Size: 23220      Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-09 01:57:16,943][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 5.575    Value Loss: 4.292    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 59506      Buffer Size: 23050      Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:07:56,462][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.677    [weighted Loss:2.677    Policy Loss: 4.682    Value Loss: 4.324    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 59849      Buffer Size: 22599      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:18:25,639][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 5.967    Value Loss: 4.556    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 60180      Buffer Size: 21719      Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:28:57,921][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 4.367    Value Loss: 4.517    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 60658      Buffer Size: 19654      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:39:42,447][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 4.637    Value Loss: 4.452    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 61003      Buffer Size: 17393      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-09 02:50:44,062][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.129    [weighted Loss:2.129    Policy Loss: 3.902    Value Loss: 4.402    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 61328      Buffer Size: 16242      Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:02:10,673][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.577    [weighted Loss:2.577    Policy Loss: 4.005    Value Loss: 4.586    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 61659      Buffer Size: 15250      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:13:45,558][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 3.791    Value Loss: 4.828    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 61996      Buffer Size: 14764      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:25:32,741][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 3.089    Value Loss: 4.282    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 62330      Buffer Size: 14353      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:37:38,015][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 3.003    Value Loss: 4.691    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 62655      Buffer Size: 13882      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 03:50:16,113][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 3.460    Value Loss: 4.551    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 62996      Buffer Size: 13534      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:03:16,177][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 2.802    Value Loss: 5.297    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 63370      Buffer Size: 11289      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:16:24,363][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 4.026    Value Loss: 4.741    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 63737      Buffer Size: 8399       Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:29:51,980][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.692    [weighted Loss:1.692    Policy Loss: 3.647    Value Loss: 4.864    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 64124      Buffer Size: 7491       Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:43:26,689][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 3.300    Value Loss: 4.707    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 64488      Buffer Size: 7298       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 04:57:09,561][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 3.523    Value Loss: 4.599    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 64871      Buffer Size: 7282       Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:10:54,854][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 3.059    Value Loss: 4.956    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 65258      Buffer Size: 7159       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:24:35,454][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 5.185    Value Loss: 4.735    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 65651      Buffer Size: 7103       Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:38:20,269][train][INFO][train.py>_log] ==> #101000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 4.080    Value Loss: 4.929    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 66036      Buffer Size: 7008       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-09 05:52:10,053][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 3.586    Value Loss: 4.321    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 66409      Buffer Size: 6815       Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:06:09,714][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 3.243    Value Loss: 4.610    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 66793      Buffer Size: 6682       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:20:22,038][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.307    [weighted Loss:1.307    Policy Loss: 3.935    Value Loss: 5.013    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 67185      Buffer Size: 6383       Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:34:45,588][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 3.404    Value Loss: 4.696    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 67574      Buffer Size: 6301       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-09 06:49:09,356][train][INFO][train.py>_log] ==> #106000     Total Loss: 0.650    [weighted Loss:0.650    Policy Loss: 3.304    Value Loss: 4.476    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 67979      Buffer Size: 6221       Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:03:36,109][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 4.328    Value Loss: 4.176    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 68378      Buffer Size: 6157       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:18:06,575][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 3.902    Value Loss: 4.323    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 68780      Buffer Size: 6135       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:32:35,386][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 3.748    Value Loss: 4.390    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 69186      Buffer Size: 6126       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-09 07:47:01,753][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 3.442    Value Loss: 4.562    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 69588      Buffer Size: 6091       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:01:35,113][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 3.483    Value Loss: 4.268    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 69991      Buffer Size: 6054       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:16:22,803][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.320    [weighted Loss:2.320    Policy Loss: 3.558    Value Loss: 4.618    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 70401      Buffer Size: 6012       Transition Number: 399.932 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:31:05,399][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.362    [weighted Loss:1.362    Policy Loss: 3.506    Value Loss: 4.368    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 70801      Buffer Size: 5978       Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-09 08:45:55,160][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.281    [weighted Loss:1.281    Policy Loss: 3.177    Value Loss: 4.445    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 71226      Buffer Size: 5933       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:00:53,105][train][INFO][train.py>_log] ==> #115000     Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 3.548    Value Loss: 4.397    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 71648      Buffer Size: 5884       Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:15:36,404][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 3.164    Value Loss: 4.134    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 72084      Buffer Size: 5907       Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:30:13,582][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.318    [weighted Loss:2.318    Policy Loss: 4.129    Value Loss: 4.223    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 72503      Buffer Size: 5952       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-09 09:45:21,890][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 4.966    Value Loss: 4.521    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 72941      Buffer Size: 6001       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:00:07,005][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 4.059    Value Loss: 4.389    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 73365      Buffer Size: 6026       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:15:07,633][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.682    [weighted Loss:2.682    Policy Loss: 4.041    Value Loss: 4.965    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 73829      Buffer Size: 6107       Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:30:38,026][train][INFO][train.py>_log] ==> #121000     Total Loss: 1.942    [weighted Loss:1.942    Policy Loss: 4.262    Value Loss: 4.748    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 74262      Buffer Size: 6108       Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-09 10:46:06,020][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 4.006    Value Loss: 4.440    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 74692      Buffer Size: 6090       Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:01:13,944][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 4.376    Value Loss: 5.013    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 75123      Buffer Size: 6069       Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:16:41,811][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 3.783    Value Loss: 4.438    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 75565      Buffer Size: 6061       Transition Number: 399.948 k Batch Size: 128        Lr: 0.100   
[2021-11-09 11:32:28,343][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.614    [weighted Loss:1.614    Policy Loss: 3.592    Value Loss: 4.294    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 76003      Buffer Size: 6065       Transition Number: 399.937 k Batch Size: 128        Lr: 0.100   
