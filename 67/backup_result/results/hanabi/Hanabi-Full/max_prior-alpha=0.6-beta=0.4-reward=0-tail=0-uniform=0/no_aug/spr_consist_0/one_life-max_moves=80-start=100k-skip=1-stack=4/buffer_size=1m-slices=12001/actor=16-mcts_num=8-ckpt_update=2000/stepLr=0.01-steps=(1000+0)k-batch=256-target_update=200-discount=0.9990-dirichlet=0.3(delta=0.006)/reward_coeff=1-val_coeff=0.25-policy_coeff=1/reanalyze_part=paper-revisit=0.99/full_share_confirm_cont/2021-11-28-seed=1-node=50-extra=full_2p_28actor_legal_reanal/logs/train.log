[2021-11-28 22:25:33,120][train][INFO][train.py>_log] ==> #0          Total Loss: 18.966   [weighted Loss:18.966   Policy Loss: 13.761   Value Loss: 13.418   Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 8323       Buffer Size: 8323       Transition Number: 100.333 k Batch Size: 256        Lr: 0.000   
[2021-11-28 22:30:21,816][train][INFO][train.py>_log] ==> #2000       Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 6.838    Value Loss: 4.659    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 8697       Buffer Size: 8697       Transition Number: 125.406 k Batch Size: 256        Lr: 0.002   
[2021-11-28 22:35:41,424][train][INFO][train.py>_log] ==> #4000       Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 4.088    Value Loss: 3.972    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 9139       Buffer Size: 9139       Transition Number: 156.382 k Batch Size: 256        Lr: 0.004   
[2021-11-28 22:41:04,739][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 4.656    Value Loss: 3.880    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 9566       Buffer Size: 9566       Transition Number: 187.036 k Batch Size: 256        Lr: 0.006   
[2021-11-28 22:46:35,312][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 6.027    Value Loss: 3.994    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 10039      Buffer Size: 10039      Transition Number: 218.198 k Batch Size: 256        Lr: 0.008   
[2021-11-28 22:51:58,826][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 6.998    Value Loss: 4.340    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 10506      Buffer Size: 10506      Transition Number: 247.096 k Batch Size: 256        Lr: 0.010   
[2021-11-28 22:57:20,598][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.594    [weighted Loss:3.594    Policy Loss: 7.694    Value Loss: 4.251    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 10947      Buffer Size: 10947      Transition Number: 275.923 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:02:48,054][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.908    [weighted Loss:3.908    Policy Loss: 7.818    Value Loss: 4.418    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 11413      Buffer Size: 11413      Transition Number: 304.121 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:08:19,109][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 8.131    Value Loss: 4.619    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 11880      Buffer Size: 11880      Transition Number: 332.476 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:13:54,518][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.648    [weighted Loss:2.648    Policy Loss: 8.073    Value Loss: 4.752    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 12334      Buffer Size: 12334      Transition Number: 360.576 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:19:48,466][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.082    [weighted Loss:3.082    Policy Loss: 8.641    Value Loss: 4.805    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 12820      Buffer Size: 12820      Transition Number: 392.145 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:25:09,432][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 8.235    Value Loss: 5.191    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 13256      Buffer Size: 13256      Transition Number: 420.422 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:30:27,818][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 8.466    Value Loss: 5.030    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 13695      Buffer Size: 13695      Transition Number: 449.265 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:35:55,368][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.609    [weighted Loss:3.609    Policy Loss: 8.320    Value Loss: 4.705    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 14140      Buffer Size: 14140      Transition Number: 478.509 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:41:12,119][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.826    [weighted Loss:3.826    Policy Loss: 8.591    Value Loss: 4.804    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 14549      Buffer Size: 14549      Transition Number: 506.098 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:46:44,878][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.676    [weighted Loss:3.676    Policy Loss: 8.766    Value Loss: 4.735    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 14988      Buffer Size: 14988      Transition Number: 536.069 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:52:27,069][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.502    [weighted Loss:3.502    Policy Loss: 8.483    Value Loss: 4.917    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 15452      Buffer Size: 15452      Transition Number: 568.765 k Batch Size: 256        Lr: 0.010   
[2021-11-28 23:57:58,116][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 8.279    Value Loss: 4.474    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 15896      Buffer Size: 15896      Transition Number: 599.093 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:03:32,208][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 8.458    Value Loss: 4.756    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 16354      Buffer Size: 16354      Transition Number: 629.715 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:09:01,415][train][INFO][train.py>_log] ==> #38000      Total Loss: 4.208    [weighted Loss:4.208    Policy Loss: 7.844    Value Loss: 4.878    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 16797      Buffer Size: 16797      Transition Number: 659.089 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:14:38,823][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.041    [weighted Loss:4.041    Policy Loss: 8.064    Value Loss: 4.542    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 17255      Buffer Size: 17255      Transition Number: 690.511 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:20:14,278][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.403    [weighted Loss:1.403    Policy Loss: 8.545    Value Loss: 4.623    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 17704      Buffer Size: 17704      Transition Number: 720.818 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:25:35,629][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.655    [weighted Loss:3.655    Policy Loss: 8.177    Value Loss: 4.750    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 18149      Buffer Size: 18149      Transition Number: 750.398 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:31:07,407][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.608    [weighted Loss:3.608    Policy Loss: 8.746    Value Loss: 4.575    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 18600      Buffer Size: 18600      Transition Number: 780.970 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:36:45,481][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 8.430    Value Loss: 4.952    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 19053      Buffer Size: 19053      Transition Number: 811.268 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:42:12,504][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 8.687    Value Loss: 4.672    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 19492      Buffer Size: 19492      Transition Number: 839.250 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:47:47,937][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 8.544    Value Loss: 4.947    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 19936      Buffer Size: 19936      Transition Number: 867.749 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:53:28,391][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 8.458    Value Loss: 4.913    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 20424      Buffer Size: 20424      Transition Number: 900.495 k Batch Size: 256        Lr: 0.010   
[2021-11-29 00:59:06,269][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 8.674    Value Loss: 4.720    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 20880      Buffer Size: 20880      Transition Number: 930.792 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:04:37,974][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 9.039    Value Loss: 4.565    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 21338      Buffer Size: 21338      Transition Number: 960.789 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:10:09,891][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.339    [weighted Loss:2.339    Policy Loss: 8.824    Value Loss: 4.485    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 21790      Buffer Size: 21790      Transition Number: 989.979 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:15:46,801][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.996    [weighted Loss:3.996    Policy Loss: 9.045    Value Loss: 4.621    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 22255      Buffer Size: 20576      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:21:27,560][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.872    [weighted Loss:1.872    Policy Loss: 8.873    Value Loss: 4.528    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 22725      Buffer Size: 18502      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:27:07,432][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 9.350    Value Loss: 5.154    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 23204      Buffer Size: 16572      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:32:48,479][train][INFO][train.py>_log] ==> #68000      Total Loss: 5.719    [weighted Loss:5.719    Policy Loss: 9.863    Value Loss: 4.933    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 23663      Buffer Size: 15201      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:38:25,272][train][INFO][train.py>_log] ==> #70000      Total Loss: 4.866    [weighted Loss:4.866    Policy Loss: 9.791    Value Loss: 4.365    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 24113      Buffer Size: 15235      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:44:10,609][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 9.963    Value Loss: 4.593    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 24588      Buffer Size: 15278      Transition Number: 1000.050k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:49:45,901][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.328    [weighted Loss:3.328    Policy Loss: 9.708    Value Loss: 4.949    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 25041      Buffer Size: 15319      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-29 01:55:30,476][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 9.828    Value Loss: 4.557    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 25518      Buffer Size: 15332      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:01:03,665][train][INFO][train.py>_log] ==> #78000      Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 9.881    Value Loss: 4.766    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 25982      Buffer Size: 15315      Transition Number: 999.947 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:06:35,837][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 10.004   Value Loss: 4.915    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 26446      Buffer Size: 15324      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:12:11,075][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.928    [weighted Loss:3.928    Policy Loss: 10.104   Value Loss: 4.640    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 26900      Buffer Size: 15299      Transition Number: 999.983 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:17:50,173][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.149    [weighted Loss:4.149    Policy Loss: 10.240   Value Loss: 4.877    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 27367      Buffer Size: 15270      Transition Number: 1000.053k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:23:34,705][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.120    [weighted Loss:4.120    Policy Loss: 10.280   Value Loss: 5.163    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 27870      Buffer Size: 15279      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:29:19,857][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.611    [weighted Loss:4.611    Policy Loss: 9.936    Value Loss: 4.880    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 28360      Buffer Size: 15299      Transition Number: 999.983 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:35:00,338][train][INFO][train.py>_log] ==> #90000      Total Loss: 5.400    [weighted Loss:5.400    Policy Loss: 10.340   Value Loss: 5.251    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 28827      Buffer Size: 15326      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:40:43,369][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 10.277   Value Loss: 4.779    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 29296      Buffer Size: 15345      Transition Number: 999.969 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:46:25,000][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.092    [weighted Loss:4.092    Policy Loss: 10.252   Value Loss: 4.719    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 29779      Buffer Size: 15388      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:52:02,170][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 10.391   Value Loss: 4.796    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 30254      Buffer Size: 15428      Transition Number: 1000.017k Batch Size: 256        Lr: 0.010   
[2021-11-29 02:57:43,148][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 10.153   Value Loss: 4.918    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 30737      Buffer Size: 15478      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:03:32,000][train][INFO][train.py>_log] ==> #100000     Total Loss: 5.260    [weighted Loss:5.260    Policy Loss: 10.698   Value Loss: 4.892    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 31222      Buffer Size: 15511      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:09:07,547][train][INFO][train.py>_log] ==> #102000     Total Loss: 4.713    [weighted Loss:4.713    Policy Loss: 10.356   Value Loss: 4.692    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 31679      Buffer Size: 15528      Transition Number: 999.971 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:14:50,938][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 10.228   Value Loss: 4.889    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 32150      Buffer Size: 15559      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:20:40,200][train][INFO][train.py>_log] ==> #106000     Total Loss: 4.912    [weighted Loss:4.912    Policy Loss: 10.135   Value Loss: 4.421    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 32641      Buffer Size: 15598      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:26:28,234][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.165    [weighted Loss:4.165    Policy Loss: 10.551   Value Loss: 4.674    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 33140      Buffer Size: 15636      Transition Number: 1000.053k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:32:07,593][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.341    [weighted Loss:3.341    Policy Loss: 10.790   Value Loss: 5.101    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 33610      Buffer Size: 15670      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:37:51,441][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 10.577   Value Loss: 5.480    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 34093      Buffer Size: 15720      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:43:27,494][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 10.667   Value Loss: 4.932    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 34569      Buffer Size: 15770      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:49:01,206][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.301    [weighted Loss:4.301    Policy Loss: 10.712   Value Loss: 4.822    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 35036      Buffer Size: 15793      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-11-29 03:54:48,137][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.689    [weighted Loss:3.689    Policy Loss: 10.416   Value Loss: 4.798    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 35532      Buffer Size: 15822      Transition Number: 1000.038k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:00:26,069][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.907    [weighted Loss:3.907    Policy Loss: 10.612   Value Loss: 4.712    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 36535      Buffer Size: 16404      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:06:06,031][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.951    [weighted Loss:3.951    Policy Loss: 10.249   Value Loss: 5.141    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 37372      Buffer Size: 16824      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:11:53,312][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 10.344   Value Loss: 5.125    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 37858      Buffer Size: 16883      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:17:37,087][train][INFO][train.py>_log] ==> #126000     Total Loss: 3.937    [weighted Loss:3.937    Policy Loss: 10.481   Value Loss: 5.653    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 38347      Buffer Size: 16911      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:23:05,839][train][INFO][train.py>_log] ==> #128000     Total Loss: 3.815    [weighted Loss:3.815    Policy Loss: 10.414   Value Loss: 5.228    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 38806      Buffer Size: 16933      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:28:44,729][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 9.846    Value Loss: 4.609    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 39278      Buffer Size: 16946      Transition Number: 999.974 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:34:21,791][train][INFO][train.py>_log] ==> #132000     Total Loss: 4.133    [weighted Loss:4.133    Policy Loss: 9.926    Value Loss: 5.009    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 39748      Buffer Size: 16969      Transition Number: 999.985 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:40:03,057][train][INFO][train.py>_log] ==> #134000     Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 10.176   Value Loss: 5.235    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 40241      Buffer Size: 17001      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:45:40,131][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.962    [weighted Loss:2.962    Policy Loss: 9.578    Value Loss: 4.737    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 40711      Buffer Size: 17036      Transition Number: 1000.070k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:51:24,503][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 10.373   Value Loss: 5.264    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 41203      Buffer Size: 17081      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-29 04:57:03,680][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 10.124   Value Loss: 4.977    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 41695      Buffer Size: 17137      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:02:34,843][train][INFO][train.py>_log] ==> #142000     Total Loss: 5.425    [weighted Loss:5.425    Policy Loss: 10.238   Value Loss: 5.147    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 42150      Buffer Size: 17156      Transition Number: 1000.012k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:08:07,778][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 9.844    Value Loss: 4.783    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 42613      Buffer Size: 17176      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:13:40,577][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 9.681    Value Loss: 4.917    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 43088      Buffer Size: 17224      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:19:15,017][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 9.797    Value Loss: 4.862    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 43563      Buffer Size: 17252      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:24:51,449][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.660    [weighted Loss:3.660    Policy Loss: 10.487   Value Loss: 5.422    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 44044      Buffer Size: 17260      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:30:32,434][train][INFO][train.py>_log] ==> #152000     Total Loss: 4.716    [weighted Loss:4.716    Policy Loss: 10.567   Value Loss: 5.071    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 44546      Buffer Size: 17308      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:36:15,741][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.662    [weighted Loss:3.662    Policy Loss: 9.908    Value Loss: 5.188    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 45020      Buffer Size: 17340      Transition Number: 1000.100k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:41:52,326][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.674    [weighted Loss:2.674    Policy Loss: 9.807    Value Loss: 5.145    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 45495      Buffer Size: 17342      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:47:31,246][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 10.245   Value Loss: 5.308    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 45957      Buffer Size: 17345      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:53:04,629][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 10.227   Value Loss: 4.937    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 46420      Buffer Size: 17357      Transition Number: 999.943 k Batch Size: 256        Lr: 0.010   
[2021-11-29 05:58:43,049][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 10.040   Value Loss: 5.416    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 46902      Buffer Size: 17378      Transition Number: 999.933 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:04:20,766][train][INFO][train.py>_log] ==> #164000     Total Loss: 4.414    [weighted Loss:4.414    Policy Loss: 10.549   Value Loss: 5.241    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 47372      Buffer Size: 17382      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:09:56,617][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 9.826    Value Loss: 5.325    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 47851      Buffer Size: 17414      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:15:33,258][train][INFO][train.py>_log] ==> #168000     Total Loss: 4.399    [weighted Loss:4.399    Policy Loss: 10.313   Value Loss: 5.200    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 48313      Buffer Size: 17433      Transition Number: 1000.005k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:21:03,473][train][INFO][train.py>_log] ==> #170000     Total Loss: 4.164    [weighted Loss:4.164    Policy Loss: 10.398   Value Loss: 5.000    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 48788      Buffer Size: 17474      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:26:32,800][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.583    [weighted Loss:2.583    Policy Loss: 9.825    Value Loss: 5.179    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 49247      Buffer Size: 17497      Transition Number: 999.982 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:32:02,548][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.566    [weighted Loss:3.566    Policy Loss: 10.253   Value Loss: 5.310    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 49708      Buffer Size: 17493      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:37:30,782][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.805    [weighted Loss:3.805    Policy Loss: 10.635   Value Loss: 5.716    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 50184      Buffer Size: 17551      Transition Number: 999.948 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:42:57,403][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 10.851   Value Loss: 5.377    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 50645      Buffer Size: 17575      Transition Number: 999.949 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:48:36,808][train][INFO][train.py>_log] ==> #180000     Total Loss: 3.904    [weighted Loss:3.904    Policy Loss: 10.726   Value Loss: 5.681    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 51140      Buffer Size: 17615      Transition Number: 999.947 k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:54:10,237][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.950    [weighted Loss:1.950    Policy Loss: 10.467   Value Loss: 5.392    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 51601      Buffer Size: 17627      Transition Number: 1000.063k Batch Size: 256        Lr: 0.010   
[2021-11-29 06:59:43,578][train][INFO][train.py>_log] ==> #184000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 10.216   Value Loss: 5.366    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 52077      Buffer Size: 17621      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:05:16,488][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 10.197   Value Loss: 4.987    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 52543      Buffer Size: 17639      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:10:49,189][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.959    [weighted Loss:3.959    Policy Loss: 10.976   Value Loss: 5.287    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 53014      Buffer Size: 17656      Transition Number: 999.980 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:16:26,182][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 10.850   Value Loss: 5.634    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 53490      Buffer Size: 17328      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:22:09,903][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 11.118   Value Loss: 5.239    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 53976      Buffer Size: 16899      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:27:41,865][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.973    [weighted Loss:3.973    Policy Loss: 10.697   Value Loss: 5.229    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 54470      Buffer Size: 16795      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:33:22,702][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.339    [weighted Loss:2.339    Policy Loss: 10.810   Value Loss: 5.199    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 54977      Buffer Size: 16854      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:39:00,289][train][INFO][train.py>_log] ==> #198000     Total Loss: 5.061    [weighted Loss:5.061    Policy Loss: 10.859   Value Loss: 5.068    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 55464      Buffer Size: 16911      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:44:45,604][train][INFO][train.py>_log] ==> #200000     Total Loss: 3.293    [weighted Loss:3.293    Policy Loss: 11.012   Value Loss: 5.198    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 55960      Buffer Size: 16941      Transition Number: 999.942 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:50:10,927][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 11.163   Value Loss: 5.254    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 56429      Buffer Size: 16974      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-29 07:55:34,436][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.470    [weighted Loss:3.470    Policy Loss: 12.079   Value Loss: 5.489    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 56911      Buffer Size: 17001      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:01:04,751][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.245    [weighted Loss:3.245    Policy Loss: 11.270   Value Loss: 5.385    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 57381      Buffer Size: 16989      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:06:39,864][train][INFO][train.py>_log] ==> #208000     Total Loss: 5.064    [weighted Loss:5.064    Policy Loss: 11.451   Value Loss: 5.546    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 57865      Buffer Size: 16990      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:12:20,539][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.443    [weighted Loss:1.443    Policy Loss: 11.191   Value Loss: 5.375    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 58356      Buffer Size: 16980      Transition Number: 999.961 k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:18:06,788][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 10.871   Value Loss: 5.196    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 58840      Buffer Size: 16976      Transition Number: 999.949 k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:23:54,455][train][INFO][train.py>_log] ==> #214000     Total Loss: 4.326    [weighted Loss:4.326    Policy Loss: 11.012   Value Loss: 5.548    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 59335      Buffer Size: 17002      Transition Number: 1000.020k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:29:35,030][train][INFO][train.py>_log] ==> #216000     Total Loss: 3.959    [weighted Loss:3.959    Policy Loss: 11.126   Value Loss: 4.976    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 59831      Buffer Size: 17020      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:35:15,084][train][INFO][train.py>_log] ==> #218000     Total Loss: 3.334    [weighted Loss:3.334    Policy Loss: 11.651   Value Loss: 5.549    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 60322      Buffer Size: 17029      Transition Number: 1000.008k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:40:54,702][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 11.242   Value Loss: 5.181    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 60817      Buffer Size: 17055      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:46:39,750][train][INFO][train.py>_log] ==> #222000     Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 11.147   Value Loss: 5.214    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 61303      Buffer Size: 17087      Transition Number: 999.942 k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:52:17,703][train][INFO][train.py>_log] ==> #224000     Total Loss: 3.822    [weighted Loss:3.822    Policy Loss: 11.109   Value Loss: 5.141    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 61813      Buffer Size: 17140      Transition Number: 1000.027k Batch Size: 256        Lr: 0.010   
[2021-11-29 08:57:56,766][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.142    [weighted Loss:3.142    Policy Loss: 11.091   Value Loss: 5.361    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 62294      Buffer Size: 17153      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-29 09:03:35,840][train][INFO][train.py>_log] ==> #228000     Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 11.167   Value Loss: 5.221    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 62779      Buffer Size: 17159      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-11-29 09:09:15,376][train][INFO][train.py>_log] ==> #230000     Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 11.010   Value Loss: 5.386    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 63249      Buffer Size: 17178      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-29 09:14:58,173][train][INFO][train.py>_log] ==> #232000     Total Loss: 3.819    [weighted Loss:3.819    Policy Loss: 10.841   Value Loss: 5.173    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 63740      Buffer Size: 17187      Transition Number: 1000.050k Batch Size: 256        Lr: 0.010   
