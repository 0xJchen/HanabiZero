[2021-11-10 11:03:57,170][train][INFO][train.py>_log] ==> #0          Total Loss: 44.977   [weighted Loss:44.977   Policy Loss: 14.979   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 55         Buffer Size: 55         Transition Number: 0.767   k Batch Size: 128        Lr: 0.000   
[2021-11-10 11:06:29,344][train][INFO][train.py>_log] ==> #1000       Total Loss: 8.474    [weighted Loss:8.474    Policy Loss: 14.066   Value Loss: 4.657    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 365        Buffer Size: 365        Transition Number: 4.664   k Batch Size: 128        Lr: 0.010   
[2021-11-10 11:09:55,227][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.396    [weighted Loss:7.396    Policy Loss: 13.493   Value Loss: 3.468    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 912        Buffer Size: 912        Transition Number: 9.981   k Batch Size: 128        Lr: 0.020   
[2021-11-10 11:13:18,578][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.836    [weighted Loss:6.836    Policy Loss: 14.034   Value Loss: 3.064    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1380       Buffer Size: 1380       Transition Number: 14.884  k Batch Size: 128        Lr: 0.030   
[2021-11-10 11:16:50,644][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.742    [weighted Loss:2.742    Policy Loss: 12.839   Value Loss: 2.895    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 1926       Buffer Size: 1926       Transition Number: 20.238  k Batch Size: 128        Lr: 0.040   
[2021-11-10 11:20:22,651][train][INFO][train.py>_log] ==> #5000       Total Loss: 6.666    [weighted Loss:6.666    Policy Loss: 13.001   Value Loss: 3.064    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 2549       Buffer Size: 2549       Transition Number: 25.512  k Batch Size: 128        Lr: 0.050   
[2021-11-10 11:23:55,685][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.198    [weighted Loss:5.198    Policy Loss: 12.322   Value Loss: 2.675    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 3302       Buffer Size: 3302       Transition Number: 30.895  k Batch Size: 128        Lr: 0.060   
[2021-11-10 11:27:26,120][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.051    [weighted Loss:4.051    Policy Loss: 13.182   Value Loss: 3.131    Reward Loss: 0.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 3817       Buffer Size: 3817       Transition Number: 36.056  k Batch Size: 128        Lr: 0.070   
[2021-11-10 11:30:59,051][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.834    [weighted Loss:4.834    Policy Loss: 13.632   Value Loss: 2.873    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 4415       Buffer Size: 4415       Transition Number: 41.465  k Batch Size: 128        Lr: 0.080   
[2021-11-10 11:34:28,722][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.199    [weighted Loss:5.199    Policy Loss: 13.297   Value Loss: 2.725    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 4933       Buffer Size: 4933       Transition Number: 46.599  k Batch Size: 128        Lr: 0.090   
[2021-11-10 11:38:05,881][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.493    [weighted Loss:5.493    Policy Loss: 13.252   Value Loss: 3.196    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 5560       Buffer Size: 5560       Transition Number: 52.131  k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:41:54,834][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.328    [weighted Loss:4.328    Policy Loss: 12.059   Value Loss: 2.660    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 6283       Buffer Size: 6283       Transition Number: 58.061  k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:45:33,559][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.727    [weighted Loss:4.727    Policy Loss: 11.837   Value Loss: 2.582    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 6929       Buffer Size: 6929       Transition Number: 63.668  k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:49:18,589][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.940    [weighted Loss:4.940    Policy Loss: 11.562   Value Loss: 2.442    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 7635       Buffer Size: 7635       Transition Number: 69.543  k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:52:57,957][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.124    [weighted Loss:5.124    Policy Loss: 12.270   Value Loss: 2.535    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 8244       Buffer Size: 8244       Transition Number: 75.138  k Batch Size: 128        Lr: 0.100   
[2021-11-10 11:56:38,190][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.474    [weighted Loss:5.474    Policy Loss: 13.018   Value Loss: 2.804    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 8898       Buffer Size: 8898       Transition Number: 80.825  k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:00:14,667][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.014    [weighted Loss:5.014    Policy Loss: 12.244   Value Loss: 2.923    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 9530       Buffer Size: 9530       Transition Number: 86.404  k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:03:52,634][train][INFO][train.py>_log] ==> #17000      Total Loss: 5.539    [weighted Loss:5.539    Policy Loss: 12.472   Value Loss: 2.815    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 10174      Buffer Size: 10174      Transition Number: 91.874  k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:07:41,057][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.722    [weighted Loss:5.722    Policy Loss: 13.519   Value Loss: 3.067    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 10781      Buffer Size: 10781      Transition Number: 97.921  k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:11:19,988][train][INFO][train.py>_log] ==> #19000      Total Loss: 5.338    [weighted Loss:5.338    Policy Loss: 12.656   Value Loss: 2.737    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 11344      Buffer Size: 11344      Transition Number: 103.329 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:15:04,626][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 12.423   Value Loss: 3.134    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 11933      Buffer Size: 11933      Transition Number: 109.090 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:18:44,599][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 11.438   Value Loss: 2.530    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 12505      Buffer Size: 12505      Transition Number: 114.506 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:22:23,345][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.013    [weighted Loss:4.013    Policy Loss: 11.748   Value Loss: 2.434    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 13102      Buffer Size: 13102      Transition Number: 120.054 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:25:59,063][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.997    [weighted Loss:2.997    Policy Loss: 12.167   Value Loss: 2.605    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 13610      Buffer Size: 13610      Transition Number: 125.389 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:29:50,616][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.592    [weighted Loss:5.592    Policy Loss: 13.769   Value Loss: 2.992    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 14124      Buffer Size: 14124      Transition Number: 131.222 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:33:40,768][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.908    [weighted Loss:4.908    Policy Loss: 12.100   Value Loss: 2.794    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 14547      Buffer Size: 14547      Transition Number: 136.981 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:37:27,895][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 12.658   Value Loss: 2.694    Reward Loss: 0.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 14975      Buffer Size: 14975      Transition Number: 142.734 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:41:34,510][train][INFO][train.py>_log] ==> #27000      Total Loss: 5.589    [weighted Loss:5.589    Policy Loss: 12.401   Value Loss: 2.887    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 15494      Buffer Size: 15494      Transition Number: 149.182 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:45:27,790][train][INFO][train.py>_log] ==> #28000      Total Loss: 7.415    [weighted Loss:7.415    Policy Loss: 13.196   Value Loss: 2.835    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 15930      Buffer Size: 15930      Transition Number: 155.136 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:49:33,731][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.776    [weighted Loss:4.776    Policy Loss: 13.356   Value Loss: 3.158    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 16308      Buffer Size: 16308      Transition Number: 160.971 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:53:42,936][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.914    [weighted Loss:4.914    Policy Loss: 13.351   Value Loss: 2.745    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 16702      Buffer Size: 16702      Transition Number: 167.406 k Batch Size: 128        Lr: 0.100   
[2021-11-10 12:58:03,332][train][INFO][train.py>_log] ==> #31000      Total Loss: 6.774    [weighted Loss:6.774    Policy Loss: 13.300   Value Loss: 3.074    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 17058      Buffer Size: 17058      Transition Number: 173.953 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:02:24,871][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.109    [weighted Loss:4.109    Policy Loss: 13.730   Value Loss: 3.073    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 17344      Buffer Size: 17344      Transition Number: 180.162 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:06:45,653][train][INFO][train.py>_log] ==> #33000      Total Loss: 5.474    [weighted Loss:5.474    Policy Loss: 13.990   Value Loss: 3.170    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 17554      Buffer Size: 17554      Transition Number: 185.395 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:11:29,009][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.970    [weighted Loss:3.970    Policy Loss: 13.004   Value Loss: 3.277    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 17726      Buffer Size: 17726      Transition Number: 191.146 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:16:35,384][train][INFO][train.py>_log] ==> #35000      Total Loss: 7.093    [weighted Loss:7.093    Policy Loss: 12.950   Value Loss: 3.038    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 17906      Buffer Size: 17906      Transition Number: 197.329 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:21:40,197][train][INFO][train.py>_log] ==> #36000      Total Loss: 6.531    [weighted Loss:6.531    Policy Loss: 11.541   Value Loss: 2.909    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 18040      Buffer Size: 17921      Transition Number: 199.993 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:26:54,662][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.441    [weighted Loss:4.441    Policy Loss: 11.521   Value Loss: 3.276    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 18146      Buffer Size: 17733      Transition Number: 199.994 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:32:36,485][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 10.677   Value Loss: 3.295    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 18263      Buffer Size: 17466      Transition Number: 199.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:38:44,672][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.859    [weighted Loss:3.859    Policy Loss: 9.898    Value Loss: 3.645    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 18411      Buffer Size: 16774      Transition Number: 199.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:45:17,289][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.896    [weighted Loss:4.896    Policy Loss: 9.080    Value Loss: 3.842    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 18570      Buffer Size: 15746      Transition Number: 199.998 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:52:15,483][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.635    [weighted Loss:4.635    Policy Loss: 8.401    Value Loss: 3.526    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 18737      Buffer Size: 14757      Transition Number: 200.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 13:59:34,482][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 6.962    Value Loss: 3.438    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 18960      Buffer Size: 13655      Transition Number: 199.996 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:07:24,613][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 5.866    Value Loss: 3.730    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 19228      Buffer Size: 12421      Transition Number: 199.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:15:28,023][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 4.718    Value Loss: 3.902    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 19530      Buffer Size: 11298      Transition Number: 199.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:23:56,254][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 4.814    Value Loss: 3.792    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 19888      Buffer Size: 10157      Transition Number: 199.989 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:32:48,044][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 4.748    Value Loss: 4.180    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 20334      Buffer Size: 9167       Transition Number: 199.993 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:42:15,394][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 4.527    Value Loss: 3.802    Reward Loss: 0.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 20690      Buffer Size: 7987       Transition Number: 199.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 14:52:08,886][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 4.195    Value Loss: 4.076    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 21052      Buffer Size: 6871       Transition Number: 199.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:03:01,705][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 2.941    Value Loss: 3.940    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 21408      Buffer Size: 5816       Transition Number: 199.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:14:33,129][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 5.203    Value Loss: 3.905    Reward Loss: 0.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 21772      Buffer Size: 4850       Transition Number: 199.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:26:39,381][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.010    [weighted Loss:2.010    Policy Loss: 2.821    Value Loss: 4.346    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 22162      Buffer Size: 4404       Transition Number: 199.938 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:38:54,202][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 3.721    Value Loss: 3.891    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 22622      Buffer Size: 4288       Transition Number: 199.923 k Batch Size: 128        Lr: 0.100   
[2021-11-10 15:51:09,190][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 3.156    Value Loss: 4.188    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 23076      Buffer Size: 4415       Transition Number: 199.997 k Batch Size: 128        Lr: 0.100   
