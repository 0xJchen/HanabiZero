[2021-11-10 10:17:29,924][train][INFO][train.py>_log] ==> #0          Total Loss: 45.164   [weighted Loss:45.164   Policy Loss: 15.166   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 61         Buffer Size: 61         Transition Number: 0.812   k Batch Size: 128        Lr: 0.000   
[2021-11-10 10:20:05,478][train][INFO][train.py>_log] ==> #1000       Total Loss: 8.983    [weighted Loss:8.983    Policy Loss: 13.762   Value Loss: 4.253    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 416        Buffer Size: 416        Transition Number: 4.969   k Batch Size: 128        Lr: 0.010   
[2021-11-10 10:23:05,524][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.955    [weighted Loss:4.955    Policy Loss: 14.585   Value Loss: 3.593    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 838        Buffer Size: 838        Transition Number: 9.643   k Batch Size: 128        Lr: 0.020   
[2021-11-10 10:26:13,161][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.687    [weighted Loss:6.687    Policy Loss: 14.073   Value Loss: 3.339    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1316       Buffer Size: 1316       Transition Number: 14.241  k Batch Size: 128        Lr: 0.030   
[2021-11-10 10:29:28,882][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.835    [weighted Loss:5.835    Policy Loss: 13.196   Value Loss: 2.786    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1810       Buffer Size: 1810       Transition Number: 19.209  k Batch Size: 128        Lr: 0.040   
[2021-11-10 10:32:41,692][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.662    [weighted Loss:5.662    Policy Loss: 11.815   Value Loss: 2.568    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 2419       Buffer Size: 2419       Transition Number: 24.016  k Batch Size: 128        Lr: 0.050   
[2021-11-10 10:35:51,967][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.634    [weighted Loss:4.634    Policy Loss: 13.640   Value Loss: 2.715    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 2902       Buffer Size: 2902       Transition Number: 28.763  k Batch Size: 128        Lr: 0.060   
[2021-11-10 10:39:08,549][train][INFO][train.py>_log] ==> #7000       Total Loss: 6.693    [weighted Loss:6.693    Policy Loss: 13.080   Value Loss: 2.669    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 3387       Buffer Size: 3387       Transition Number: 33.644  k Batch Size: 128        Lr: 0.070   
[2021-11-10 10:42:32,713][train][INFO][train.py>_log] ==> #8000       Total Loss: 6.448    [weighted Loss:6.448    Policy Loss: 13.556   Value Loss: 2.665    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 3825       Buffer Size: 3825       Transition Number: 38.711  k Batch Size: 128        Lr: 0.080   
[2021-11-10 10:45:59,361][train][INFO][train.py>_log] ==> #9000       Total Loss: 6.438    [weighted Loss:6.438    Policy Loss: 12.603   Value Loss: 2.899    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 4362       Buffer Size: 4362       Transition Number: 43.945  k Batch Size: 128        Lr: 0.090   
[2021-11-10 10:49:34,675][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 13.625   Value Loss: 3.089    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 4916       Buffer Size: 4916       Transition Number: 49.411  k Batch Size: 128        Lr: 0.100   
[2021-11-10 10:53:11,676][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.786    [weighted Loss:5.786    Policy Loss: 12.771   Value Loss: 2.907    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 5510       Buffer Size: 5510       Transition Number: 55.169  k Batch Size: 128        Lr: 0.100   
