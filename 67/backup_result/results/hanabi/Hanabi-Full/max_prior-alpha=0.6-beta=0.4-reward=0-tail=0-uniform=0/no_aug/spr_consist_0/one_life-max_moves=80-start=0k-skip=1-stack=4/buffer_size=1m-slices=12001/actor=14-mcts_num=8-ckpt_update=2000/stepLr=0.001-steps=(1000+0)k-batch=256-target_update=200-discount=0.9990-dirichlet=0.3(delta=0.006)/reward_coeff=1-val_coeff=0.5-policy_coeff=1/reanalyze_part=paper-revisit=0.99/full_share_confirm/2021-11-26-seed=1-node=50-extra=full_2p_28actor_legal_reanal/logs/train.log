[2021-11-26 19:35:25,925][train][INFO][train.py>_log] ==> #0          Total Loss: 54.750   [weighted Loss:54.750   Policy Loss: 12.323   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 132        Buffer Size: 132        Transition Number: 1.354   k Batch Size: 256        Lr: 0.000   
[2021-11-26 19:40:10,492][train][INFO][train.py>_log] ==> #2000       Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 13.446   Value Loss: 12.224   Reward Loss: 4.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2545       Buffer Size: 2545       Transition Number: 31.001  k Batch Size: 256        Lr: 0.000   
[2021-11-26 19:44:41,064][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.467    [weighted Loss:5.467    Policy Loss: 12.102   Value Loss: 6.772    Reward Loss: 3.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 4695       Buffer Size: 4695       Transition Number: 54.321  k Batch Size: 256        Lr: 0.000   
[2021-11-26 19:49:22,402][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 6.171    Value Loss: 5.326    Reward Loss: 2.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 7441       Buffer Size: 7441       Transition Number: 78.611  k Batch Size: 256        Lr: 0.001   
[2021-11-26 19:54:07,513][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.550    [weighted Loss:5.550    Policy Loss: 6.996    Value Loss: 4.601    Reward Loss: 2.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 11245      Buffer Size: 11245      Transition Number: 104.405 k Batch Size: 256        Lr: 0.001   
[2021-11-26 19:58:48,468][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.429    [weighted Loss:2.429    Policy Loss: 9.647    Value Loss: 4.206    Reward Loss: 2.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 15302      Buffer Size: 15302      Transition Number: 129.665 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:03:24,781][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.378    [weighted Loss:5.378    Policy Loss: 10.889   Value Loss: 4.435    Reward Loss: 2.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 19316      Buffer Size: 19316      Transition Number: 154.180 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:07:58,085][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.802    [weighted Loss:4.802    Policy Loss: 7.464    Value Loss: 4.047    Reward Loss: 2.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 22779      Buffer Size: 22779      Transition Number: 177.976 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:12:39,043][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.295    [weighted Loss:4.295    Policy Loss: 7.120    Value Loss: 3.800    Reward Loss: 1.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 27117      Buffer Size: 27117      Transition Number: 203.124 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:17:11,381][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.655    [weighted Loss:5.655    Policy Loss: 8.013    Value Loss: 3.701    Reward Loss: 1.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 30776      Buffer Size: 30776      Transition Number: 226.763 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:21:43,915][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 7.444    Value Loss: 3.395    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 33189      Buffer Size: 33189      Transition Number: 248.386 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:26:20,660][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.085    [weighted Loss:2.085    Policy Loss: 8.061    Value Loss: 3.684    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 34409      Buffer Size: 34409      Transition Number: 266.783 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:30:52,780][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.930    [weighted Loss:5.930    Policy Loss: 9.541    Value Loss: 3.830    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 36152      Buffer Size: 36152      Transition Number: 286.618 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:35:25,001][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.421    [weighted Loss:5.421    Policy Loss: 9.380    Value Loss: 3.329    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 38056      Buffer Size: 38056      Transition Number: 306.730 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:39:58,248][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.329    [weighted Loss:4.329    Policy Loss: 8.273    Value Loss: 3.614    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 40298      Buffer Size: 40298      Transition Number: 327.938 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:44:33,306][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 6.966    Value Loss: 3.380    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 43451      Buffer Size: 43451      Transition Number: 349.899 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:49:07,450][train][INFO][train.py>_log] ==> #32000      Total Loss: 0.935    [weighted Loss:0.935    Policy Loss: 8.490    Value Loss: 3.473    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 46762      Buffer Size: 46762      Transition Number: 372.697 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:53:45,118][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.651    [weighted Loss:3.651    Policy Loss: 8.121    Value Loss: 3.262    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 50206      Buffer Size: 50206      Transition Number: 395.994 k Batch Size: 256        Lr: 0.001   
[2021-11-26 20:58:21,656][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.942    [weighted Loss:2.942    Policy Loss: 9.245    Value Loss: 3.241    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 53899      Buffer Size: 53899      Transition Number: 420.052 k Batch Size: 256        Lr: 0.001   
[2021-11-26 21:02:57,770][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.456    [weighted Loss:3.456    Policy Loss: 9.513    Value Loss: 3.225    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 57470      Buffer Size: 57470      Transition Number: 443.577 k Batch Size: 256        Lr: 0.001   
[2021-11-26 21:07:35,551][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.784    [weighted Loss:3.784    Policy Loss: 9.825    Value Loss: 3.285    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 60928      Buffer Size: 60928      Transition Number: 467.648 k Batch Size: 256        Lr: 0.001   
[2021-11-26 21:12:10,052][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.732    [weighted Loss:3.732    Policy Loss: 9.706    Value Loss: 3.273    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 64027      Buffer Size: 64027      Transition Number: 490.608 k Batch Size: 256        Lr: 0.001   
