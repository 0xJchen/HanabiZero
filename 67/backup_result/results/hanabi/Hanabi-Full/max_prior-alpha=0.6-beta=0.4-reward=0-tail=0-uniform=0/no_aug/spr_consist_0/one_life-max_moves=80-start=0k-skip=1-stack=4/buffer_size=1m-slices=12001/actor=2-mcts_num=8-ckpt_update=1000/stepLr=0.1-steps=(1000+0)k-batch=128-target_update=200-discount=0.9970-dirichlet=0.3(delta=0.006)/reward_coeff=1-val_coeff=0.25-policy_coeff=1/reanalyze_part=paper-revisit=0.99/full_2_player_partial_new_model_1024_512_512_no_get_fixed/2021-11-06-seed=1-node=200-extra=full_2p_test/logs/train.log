[2021-11-06 05:12:43,402][train][INFO][train.py>_log] ==> #0          Total Loss: 44.790   [weighted Loss:44.790   Policy Loss: 14.792   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 42         Buffer Size: 42         Transition Number: 0.580   k Batch Size: 128        Lr: 0.000   
[2021-11-06 05:16:50,707][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.326    [weighted Loss:7.326    Policy Loss: 13.728   Value Loss: 4.441    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 326        Buffer Size: 326        Transition Number: 4.283   k Batch Size: 128        Lr: 0.010   
[2021-11-06 05:21:15,473][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.455    [weighted Loss:6.455    Policy Loss: 13.246   Value Loss: 3.424    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 653        Buffer Size: 653        Transition Number: 8.147   k Batch Size: 128        Lr: 0.020   
[2021-11-06 05:25:40,450][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.802    [weighted Loss:6.802    Policy Loss: 12.141   Value Loss: 3.129    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1059       Buffer Size: 1059       Transition Number: 11.611  k Batch Size: 128        Lr: 0.030   
[2021-11-06 05:30:06,991][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.056    [weighted Loss:6.056    Policy Loss: 12.534   Value Loss: 2.916    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1503       Buffer Size: 1503       Transition Number: 15.132  k Batch Size: 128        Lr: 0.040   
[2021-11-06 05:34:35,805][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.804    [weighted Loss:4.804    Policy Loss: 10.386   Value Loss: 2.926    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1967       Buffer Size: 1967       Transition Number: 18.500  k Batch Size: 128        Lr: 0.050   
[2021-11-06 05:39:04,974][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 10.001   Value Loss: 2.813    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 2284       Buffer Size: 2284       Transition Number: 21.915  k Batch Size: 128        Lr: 0.060   
[2021-11-06 05:43:36,884][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.720    [weighted Loss:5.720    Policy Loss: 12.019   Value Loss: 2.527    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 2624       Buffer Size: 2624       Transition Number: 25.243  k Batch Size: 128        Lr: 0.070   
[2021-11-06 05:48:08,928][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.091    [weighted Loss:4.091    Policy Loss: 11.729   Value Loss: 2.611    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 3088       Buffer Size: 3088       Transition Number: 28.870  k Batch Size: 128        Lr: 0.080   
[2021-11-06 05:52:39,246][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 12.314   Value Loss: 2.704    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 3464       Buffer Size: 3464       Transition Number: 32.280  k Batch Size: 128        Lr: 0.090   
[2021-11-06 05:57:12,992][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.039    [weighted Loss:4.039    Policy Loss: 11.789   Value Loss: 2.561    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 3848       Buffer Size: 3848       Transition Number: 35.972  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:01:41,693][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.054    [weighted Loss:4.054    Policy Loss: 12.694   Value Loss: 2.984    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 4207       Buffer Size: 4207       Transition Number: 39.401  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:06:09,846][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.651    [weighted Loss:5.651    Policy Loss: 12.269   Value Loss: 2.431    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 4856       Buffer Size: 4856       Transition Number: 43.046  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:10:40,229][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.430    [weighted Loss:5.430    Policy Loss: 13.199   Value Loss: 2.809    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 5041       Buffer Size: 5041       Transition Number: 45.957  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:15:11,144][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.350    [weighted Loss:3.350    Policy Loss: 11.868   Value Loss: 2.838    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 5404       Buffer Size: 5404       Transition Number: 49.495  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:19:42,878][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.547    [weighted Loss:4.547    Policy Loss: 12.344   Value Loss: 2.669    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 5830       Buffer Size: 5830       Transition Number: 52.970  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:24:14,459][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 9.354    Value Loss: 2.656    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 6411       Buffer Size: 6411       Transition Number: 56.616  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:28:44,534][train][INFO][train.py>_log] ==> #17000      Total Loss: 5.455    [weighted Loss:5.455    Policy Loss: 10.359   Value Loss: 2.923    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 6878       Buffer Size: 6878       Transition Number: 60.062  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:33:16,406][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.632    [weighted Loss:5.632    Policy Loss: 11.092   Value Loss: 2.404    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 7289       Buffer Size: 7289       Transition Number: 63.461  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:37:48,723][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.299    [weighted Loss:4.299    Policy Loss: 10.202   Value Loss: 2.384    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 7652       Buffer Size: 7652       Transition Number: 66.792  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:42:21,151][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.911    [weighted Loss:4.911    Policy Loss: 10.735   Value Loss: 2.729    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 8003       Buffer Size: 8003       Transition Number: 70.254  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:46:51,803][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 11.557   Value Loss: 2.691    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 8511       Buffer Size: 8511       Transition Number: 73.707  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:51:23,319][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.400    [weighted Loss:4.400    Policy Loss: 10.704   Value Loss: 2.487    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 9148       Buffer Size: 9148       Transition Number: 77.297  k Batch Size: 128        Lr: 0.100   
[2021-11-06 06:55:57,822][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.775    [weighted Loss:3.775    Policy Loss: 11.639   Value Loss: 2.774    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 9490       Buffer Size: 9490       Transition Number: 80.630  k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:00:32,700][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.524    [weighted Loss:4.524    Policy Loss: 11.825   Value Loss: 2.732    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 9860       Buffer Size: 9860       Transition Number: 84.243  k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:05:03,515][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.672    [weighted Loss:5.672    Policy Loss: 12.661   Value Loss: 2.888    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 10226      Buffer Size: 10226      Transition Number: 87.571  k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:09:35,060][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 10.163   Value Loss: 2.825    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 10522      Buffer Size: 10522      Transition Number: 90.865  k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:14:07,364][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 11.779   Value Loss: 2.656    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 10930      Buffer Size: 10930      Transition Number: 94.302  k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:18:39,982][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 9.939    Value Loss: 2.842    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 11476      Buffer Size: 11476      Transition Number: 97.875  k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:23:13,168][train][INFO][train.py>_log] ==> #29000      Total Loss: 5.210    [weighted Loss:5.210    Policy Loss: 11.757   Value Loss: 3.038    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 11931      Buffer Size: 11931      Transition Number: 101.193 k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:27:45,673][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.211    [weighted Loss:4.211    Policy Loss: 9.997    Value Loss: 2.963    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 12212      Buffer Size: 12212      Transition Number: 104.448 k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:32:19,650][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.629    [weighted Loss:4.629    Policy Loss: 9.985    Value Loss: 3.239    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 12455      Buffer Size: 12455      Transition Number: 107.909 k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:36:49,476][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.597    [weighted Loss:4.597    Policy Loss: 9.379    Value Loss: 2.728    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 12955      Buffer Size: 12955      Transition Number: 111.507 k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:41:25,926][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.019    [weighted Loss:4.019    Policy Loss: 10.729   Value Loss: 3.044    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 13364      Buffer Size: 13364      Transition Number: 114.953 k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:45:58,409][train][INFO][train.py>_log] ==> #34000      Total Loss: 5.037    [weighted Loss:5.037    Policy Loss: 11.427   Value Loss: 2.936    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 13632      Buffer Size: 13632      Transition Number: 118.454 k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:50:27,370][train][INFO][train.py>_log] ==> #35000      Total Loss: 5.542    [weighted Loss:5.542    Policy Loss: 10.389   Value Loss: 2.984    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 13845      Buffer Size: 13845      Transition Number: 121.493 k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:54:59,162][train][INFO][train.py>_log] ==> #36000      Total Loss: 6.356    [weighted Loss:6.356    Policy Loss: 11.636   Value Loss: 3.033    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 14032      Buffer Size: 14032      Transition Number: 124.626 k Batch Size: 128        Lr: 0.100   
[2021-11-06 07:59:28,502][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.205    [weighted Loss:4.205    Policy Loss: 11.286   Value Loss: 3.006    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 14186      Buffer Size: 14186      Transition Number: 127.718 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:03:57,474][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.629    [weighted Loss:3.629    Policy Loss: 10.932   Value Loss: 2.820    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 14333      Buffer Size: 14333      Transition Number: 130.615 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:08:30,827][train][INFO][train.py>_log] ==> #39000      Total Loss: 5.686    [weighted Loss:5.686    Policy Loss: 11.845   Value Loss: 3.006    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 14479      Buffer Size: 14479      Transition Number: 133.461 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:13:04,220][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.497    [weighted Loss:3.497    Policy Loss: 9.809    Value Loss: 3.102    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 14630      Buffer Size: 14630      Transition Number: 136.654 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:17:38,560][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.820    [weighted Loss:4.820    Policy Loss: 10.336   Value Loss: 3.515    Reward Loss: 1.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 14829      Buffer Size: 14829      Transition Number: 139.775 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:22:15,133][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.493    [weighted Loss:3.493    Policy Loss: 10.709   Value Loss: 3.121    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 15029      Buffer Size: 15029      Transition Number: 142.584 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:26:53,476][train][INFO][train.py>_log] ==> #43000      Total Loss: 5.267    [weighted Loss:5.267    Policy Loss: 10.243   Value Loss: 3.519    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 15193      Buffer Size: 15193      Transition Number: 145.224 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:31:34,403][train][INFO][train.py>_log] ==> #44000      Total Loss: 5.446    [weighted Loss:5.446    Policy Loss: 10.028   Value Loss: 3.418    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 15312      Buffer Size: 15312      Transition Number: 148.063 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:36:20,116][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.228    [weighted Loss:4.228    Policy Loss: 9.094    Value Loss: 2.740    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 15455      Buffer Size: 15455      Transition Number: 150.899 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:41:16,798][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.857    [weighted Loss:4.857    Policy Loss: 11.193   Value Loss: 3.313    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 15698      Buffer Size: 15698      Transition Number: 154.838 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:46:13,733][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 8.845    Value Loss: 2.977    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 15905      Buffer Size: 15905      Transition Number: 158.159 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:51:10,490][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.189    [weighted Loss:3.189    Policy Loss: 9.941    Value Loss: 3.346    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 16161      Buffer Size: 16161      Transition Number: 161.209 k Batch Size: 128        Lr: 0.100   
[2021-11-06 08:56:08,304][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.469    [weighted Loss:2.469    Policy Loss: 9.661    Value Loss: 3.127    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 16359      Buffer Size: 16359      Transition Number: 163.830 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:01:12,313][train][INFO][train.py>_log] ==> #50000      Total Loss: 5.731    [weighted Loss:5.731    Policy Loss: 9.655    Value Loss: 3.364    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 16636      Buffer Size: 16636      Transition Number: 167.026 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:06:12,424][train][INFO][train.py>_log] ==> #51000      Total Loss: 4.939    [weighted Loss:4.939    Policy Loss: 10.680   Value Loss: 3.613    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 16765      Buffer Size: 16765      Transition Number: 169.994 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:11:26,366][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 10.234   Value Loss: 3.592    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 16850      Buffer Size: 16850      Transition Number: 172.714 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:16:53,806][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 7.842    Value Loss: 3.322    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 16924      Buffer Size: 16924      Transition Number: 175.694 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:22:36,889][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.083    [weighted Loss:3.083    Policy Loss: 9.106    Value Loss: 3.222    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 17061      Buffer Size: 17061      Transition Number: 179.253 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:28:59,846][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 7.849    Value Loss: 3.434    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 17173      Buffer Size: 17173      Transition Number: 183.355 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:35:32,565][train][INFO][train.py>_log] ==> #56000      Total Loss: 4.497    [weighted Loss:4.497    Policy Loss: 8.690    Value Loss: 3.326    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 17282      Buffer Size: 17282      Transition Number: 187.566 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:42:26,187][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.079    [weighted Loss:4.079    Policy Loss: 8.563    Value Loss: 3.679    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 17412      Buffer Size: 17412      Transition Number: 192.006 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:49:37,687][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 7.144    Value Loss: 3.780    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 17517      Buffer Size: 17517      Transition Number: 196.798 k Batch Size: 128        Lr: 0.100   
[2021-11-06 09:57:18,467][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 6.527    Value Loss: 3.653    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 17612      Buffer Size: 17612      Transition Number: 201.474 k Batch Size: 128        Lr: 0.100   
[2021-11-06 10:04:55,116][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 6.186    Value Loss: 3.496    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 17713      Buffer Size: 17713      Transition Number: 206.969 k Batch Size: 128        Lr: 0.100   
[2021-11-06 10:12:55,951][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 5.898    Value Loss: 4.113    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 17814      Buffer Size: 17814      Transition Number: 212.144 k Batch Size: 128        Lr: 0.100   
[2021-11-06 10:21:14,857][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 6.252    Value Loss: 3.712    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 17942      Buffer Size: 17942      Transition Number: 218.608 k Batch Size: 128        Lr: 0.100   
[2021-11-06 10:29:28,818][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 4.791    Value Loss: 3.774    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 18079      Buffer Size: 18079      Transition Number: 223.739 k Batch Size: 128        Lr: 0.100   
[2021-11-06 10:38:03,006][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 3.808    Value Loss: 3.526    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 18232      Buffer Size: 18232      Transition Number: 229.602 k Batch Size: 128        Lr: 0.100   
[2021-11-06 10:46:26,222][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 4.273    Value Loss: 3.660    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 18336      Buffer Size: 18336      Transition Number: 235.423 k Batch Size: 128        Lr: 0.100   
[2021-11-06 10:55:30,950][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 4.144    Value Loss: 3.707    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 18443      Buffer Size: 18443      Transition Number: 242.924 k Batch Size: 128        Lr: 0.100   
[2021-11-06 11:04:34,563][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 4.127    Value Loss: 3.866    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 18570      Buffer Size: 18570      Transition Number: 248.856 k Batch Size: 128        Lr: 0.100   
[2021-11-06 11:13:38,731][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 4.417    Value Loss: 3.530    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 18737      Buffer Size: 18737      Transition Number: 255.272 k Batch Size: 128        Lr: 0.100   
[2021-11-06 11:22:56,952][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 4.944    Value Loss: 3.780    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 18869      Buffer Size: 18869      Transition Number: 261.718 k Batch Size: 128        Lr: 0.100   
[2021-11-06 11:32:52,674][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.187    [weighted Loss:1.187    Policy Loss: 4.867    Value Loss: 3.856    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 19044      Buffer Size: 19044      Transition Number: 268.433 k Batch Size: 128        Lr: 0.100   
[2021-11-06 11:42:57,483][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 5.212    Value Loss: 3.977    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 19177      Buffer Size: 19177      Transition Number: 276.428 k Batch Size: 128        Lr: 0.100   
[2021-11-06 11:53:07,137][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 3.843    Value Loss: 3.908    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 19304      Buffer Size: 19304      Transition Number: 284.021 k Batch Size: 128        Lr: 0.100   
[2021-11-06 12:03:39,657][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 4.153    Value Loss: 3.859    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 19440      Buffer Size: 19440      Transition Number: 292.125 k Batch Size: 128        Lr: 0.100   
