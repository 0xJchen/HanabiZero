[2021-11-06 19:14:54,125][train][INFO][train.py>_log] ==> #0          Total Loss: 43.924   [weighted Loss:43.924   Policy Loss: 13.926   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 58         Buffer Size: 58         Transition Number: 0.653   k Batch Size: 256        Lr: 0.000   
[2021-11-06 19:18:37,196][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.601    [weighted Loss:5.601    Policy Loss: 14.124   Value Loss: 4.860    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 606        Buffer Size: 606        Transition Number: 7.485   k Batch Size: 256        Lr: 0.010   
[2021-11-06 19:24:52,834][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.472    [weighted Loss:5.472    Policy Loss: 14.783   Value Loss: 3.861    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 1654       Buffer Size: 1654       Transition Number: 19.961  k Batch Size: 256        Lr: 0.020   
[2021-11-06 19:31:52,281][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.370    [weighted Loss:3.370    Policy Loss: 13.462   Value Loss: 3.153    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 2991       Buffer Size: 2991       Transition Number: 32.578  k Batch Size: 256        Lr: 0.030   
[2021-11-06 19:38:53,603][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.367    [weighted Loss:6.367    Policy Loss: 13.860   Value Loss: 3.202    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 4318       Buffer Size: 4318       Transition Number: 45.129  k Batch Size: 256        Lr: 0.040   
[2021-11-06 19:45:46,227][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.044    [weighted Loss:5.044    Policy Loss: 13.581   Value Loss: 2.853    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 5605       Buffer Size: 5605       Transition Number: 57.485  k Batch Size: 256        Lr: 0.050   
[2021-11-06 19:52:43,401][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.749    [weighted Loss:5.749    Policy Loss: 13.822   Value Loss: 3.070    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 6844       Buffer Size: 6844       Transition Number: 69.951  k Batch Size: 256        Lr: 0.060   
[2021-11-06 19:59:47,303][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.088    [weighted Loss:4.088    Policy Loss: 14.167   Value Loss: 2.912    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 7953       Buffer Size: 7953       Transition Number: 82.206  k Batch Size: 256        Lr: 0.070   
[2021-11-06 20:07:14,629][train][INFO][train.py>_log] ==> #8000       Total Loss: 6.641    [weighted Loss:6.641    Policy Loss: 13.546   Value Loss: 2.692    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 8944       Buffer Size: 8944       Transition Number: 94.942  k Batch Size: 256        Lr: 0.080   
[2021-11-06 20:15:09,478][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.683    [weighted Loss:5.683    Policy Loss: 13.331   Value Loss: 2.802    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 10112      Buffer Size: 10112      Transition Number: 108.952 k Batch Size: 256        Lr: 0.090   
[2021-11-06 20:22:52,116][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.010    [weighted Loss:4.010    Policy Loss: 11.313   Value Loss: 2.726    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 11332      Buffer Size: 11332      Transition Number: 122.676 k Batch Size: 256        Lr: 0.100   
[2021-11-06 20:30:31,581][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.968    [weighted Loss:3.968    Policy Loss: 12.222   Value Loss: 2.747    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 12569      Buffer Size: 12569      Transition Number: 136.469 k Batch Size: 256        Lr: 0.100   
[2021-11-06 20:38:24,958][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.133    [weighted Loss:4.133    Policy Loss: 12.709   Value Loss: 2.696    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 13788      Buffer Size: 13788      Transition Number: 150.565 k Batch Size: 256        Lr: 0.100   
[2021-11-06 20:46:32,953][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.875    [weighted Loss:5.875    Policy Loss: 11.991   Value Loss: 2.589    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 15194      Buffer Size: 15194      Transition Number: 165.140 k Batch Size: 256        Lr: 0.100   
[2021-11-06 20:54:32,807][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.651    [weighted Loss:3.651    Policy Loss: 12.717   Value Loss: 2.651    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 16699      Buffer Size: 16699      Transition Number: 179.859 k Batch Size: 256        Lr: 0.100   
[2021-11-06 21:02:14,763][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.638    [weighted Loss:4.638    Policy Loss: 12.754   Value Loss: 2.534    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 18725      Buffer Size: 18725      Transition Number: 193.762 k Batch Size: 256        Lr: 0.100   
[2021-11-06 21:09:56,744][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.995    [weighted Loss:4.995    Policy Loss: 12.644   Value Loss: 2.564    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 20606      Buffer Size: 20606      Transition Number: 207.780 k Batch Size: 256        Lr: 0.100   
[2021-11-06 21:17:43,752][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.000    [weighted Loss:4.000    Policy Loss: 12.864   Value Loss: 2.497    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 22442      Buffer Size: 22442      Transition Number: 221.748 k Batch Size: 256        Lr: 0.100   
[2021-11-06 21:25:27,265][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.351    [weighted Loss:4.351    Policy Loss: 12.593   Value Loss: 2.453    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 24282      Buffer Size: 24282      Transition Number: 235.828 k Batch Size: 256        Lr: 0.100   
[2021-11-06 21:33:31,038][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.986    [weighted Loss:3.986    Policy Loss: 12.966   Value Loss: 2.397    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 25885      Buffer Size: 25885      Transition Number: 250.049 k Batch Size: 256        Lr: 0.100   
[2021-11-06 21:41:36,571][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.455    [weighted Loss:4.455    Policy Loss: 12.318   Value Loss: 2.539    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 27363      Buffer Size: 27363      Transition Number: 264.486 k Batch Size: 256        Lr: 0.100   
[2021-11-06 21:49:46,625][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.068    [weighted Loss:5.068    Policy Loss: 12.220   Value Loss: 2.780    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 28811      Buffer Size: 28811      Transition Number: 279.054 k Batch Size: 256        Lr: 0.100   
[2021-11-06 21:58:23,161][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.854    [weighted Loss:4.854    Policy Loss: 12.711   Value Loss: 2.784    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 30323      Buffer Size: 30323      Transition Number: 294.897 k Batch Size: 256        Lr: 0.100   
[2021-11-06 22:06:30,859][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.211    [weighted Loss:4.211    Policy Loss: 12.417   Value Loss: 2.729    Reward Loss: 1.180    Consistency Loss: 0.000    ] Replay Episodes Collected: 31727      Buffer Size: 31727      Transition Number: 309.757 k Batch Size: 256        Lr: 0.100   
[2021-11-06 22:14:33,599][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 12.934   Value Loss: 2.488    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 33142      Buffer Size: 33142      Transition Number: 324.271 k Batch Size: 256        Lr: 0.100   
[2021-11-06 22:22:46,411][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.862    [weighted Loss:5.862    Policy Loss: 13.117   Value Loss: 2.497    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 34343      Buffer Size: 34343      Transition Number: 338.761 k Batch Size: 256        Lr: 0.100   
[2021-11-06 22:30:46,077][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.488    [weighted Loss:3.488    Policy Loss: 12.876   Value Loss: 2.553    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 35308      Buffer Size: 35308      Transition Number: 352.665 k Batch Size: 256        Lr: 0.100   
[2021-11-06 22:39:07,564][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.880    [weighted Loss:3.880    Policy Loss: 12.830   Value Loss: 2.552    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 36295      Buffer Size: 36295      Transition Number: 366.798 k Batch Size: 256        Lr: 0.100   
[2021-11-06 22:47:46,039][train][INFO][train.py>_log] ==> #28000      Total Loss: 5.605    [weighted Loss:5.605    Policy Loss: 13.241   Value Loss: 2.842    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 37259      Buffer Size: 37259      Transition Number: 382.201 k Batch Size: 256        Lr: 0.100   
[2021-11-06 22:56:26,158][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 12.724   Value Loss: 2.865    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 38261      Buffer Size: 38261      Transition Number: 397.394 k Batch Size: 256        Lr: 0.100   
[2021-11-06 23:04:51,536][train][INFO][train.py>_log] ==> #30000      Total Loss: 5.678    [weighted Loss:5.678    Policy Loss: 13.039   Value Loss: 2.898    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 39121      Buffer Size: 39121      Transition Number: 411.648 k Batch Size: 256        Lr: 0.100   
[2021-11-06 23:13:41,450][train][INFO][train.py>_log] ==> #31000      Total Loss: 5.952    [weighted Loss:5.952    Policy Loss: 12.802   Value Loss: 2.847    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 39786      Buffer Size: 39786      Transition Number: 425.380 k Batch Size: 256        Lr: 0.100   
[2021-11-06 23:23:07,875][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.827    [weighted Loss:3.827    Policy Loss: 12.972   Value Loss: 3.073    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 40270      Buffer Size: 40270      Transition Number: 438.570 k Batch Size: 256        Lr: 0.100   
[2021-11-06 23:33:08,298][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.650    [weighted Loss:3.650    Policy Loss: 12.468   Value Loss: 2.817    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 40699      Buffer Size: 40699      Transition Number: 452.482 k Batch Size: 256        Lr: 0.100   
[2021-11-06 23:44:15,691][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.950    [weighted Loss:3.950    Policy Loss: 11.604   Value Loss: 2.812    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 40993      Buffer Size: 40993      Transition Number: 465.237 k Batch Size: 256        Lr: 0.100   
[2021-11-06 23:57:34,926][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 10.321   Value Loss: 3.311    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 41321      Buffer Size: 41321      Transition Number: 485.625 k Batch Size: 256        Lr: 0.100   
[2021-11-07 00:12:21,900][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 8.311    Value Loss: 3.217    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 41753      Buffer Size: 40930      Transition Number: 499.981 k Batch Size: 256        Lr: 0.100   
[2021-11-07 00:28:10,464][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 7.023    Value Loss: 3.308    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 42218      Buffer Size: 38924      Transition Number: 499.994 k Batch Size: 256        Lr: 0.100   
[2021-11-07 00:45:02,619][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 5.989    Value Loss: 3.483    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 42984      Buffer Size: 36933      Transition Number: 499.999 k Batch Size: 256        Lr: 0.100   
[2021-11-07 01:02:44,826][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.543    [weighted Loss:1.543    Policy Loss: 5.608    Value Loss: 3.346    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 43705      Buffer Size: 35219      Transition Number: 499.993 k Batch Size: 256        Lr: 0.100   
[2021-11-07 01:20:49,885][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 4.506    Value Loss: 3.495    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 44395      Buffer Size: 33651      Transition Number: 500.000 k Batch Size: 256        Lr: 0.100   
[2021-11-07 01:39:59,005][train][INFO][train.py>_log] ==> #41000      Total Loss: 0.940    [weighted Loss:0.940    Policy Loss: 3.664    Value Loss: 3.976    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 45331      Buffer Size: 32055      Transition Number: 499.988 k Batch Size: 256        Lr: 0.100   
[2021-11-07 01:58:13,649][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.068    [weighted Loss:1.068    Policy Loss: 3.529    Value Loss: 3.994    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 46241      Buffer Size: 30345      Transition Number: 499.991 k Batch Size: 256        Lr: 0.100   
[2021-11-07 02:16:07,541][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 3.114    Value Loss: 4.081    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 48754      Buffer Size: 29243      Transition Number: 500.009 k Batch Size: 256        Lr: 0.100   
[2021-11-07 02:33:47,644][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.329    [weighted Loss:1.329    Policy Loss: 2.692    Value Loss: 4.178    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 50825      Buffer Size: 27654      Transition Number: 499.997 k Batch Size: 256        Lr: 0.100   
[2021-11-07 02:51:32,967][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.249    [weighted Loss:1.249    Policy Loss: 2.325    Value Loss: 4.344    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 52884      Buffer Size: 26413      Transition Number: 499.999 k Batch Size: 256        Lr: 0.100   
[2021-11-07 03:10:00,630][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 1.968    Value Loss: 4.116    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 54109      Buffer Size: 24858      Transition Number: 499.996 k Batch Size: 256        Lr: 0.100   
[2021-11-07 03:29:06,058][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.084    [weighted Loss:1.084    Policy Loss: 1.910    Value Loss: 4.062    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 55530      Buffer Size: 23671      Transition Number: 499.989 k Batch Size: 256        Lr: 0.100   
[2021-11-07 03:48:46,345][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 1.512    Value Loss: 4.126    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 56758      Buffer Size: 22220      Transition Number: 499.994 k Batch Size: 256        Lr: 0.100   
