[2021-11-26 21:27:48,953][train][INFO][train.py>_log] ==> #0          Total Loss: 47.883   [weighted Loss:47.883   Policy Loss: 13.411   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 112        Buffer Size: 112        Transition Number: 1.080   k Batch Size: 256        Lr: 0.000   
[2021-11-26 21:32:20,221][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.380    [weighted Loss:5.380    Policy Loss: 12.673   Value Loss: 6.072    Reward Loss: 2.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 2414       Buffer Size: 2414       Transition Number: 28.743  k Batch Size: 256        Lr: 0.002   
[2021-11-26 21:36:50,101][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.171    [weighted Loss:4.171    Policy Loss: 9.388    Value Loss: 4.752    Reward Loss: 2.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 5351       Buffer Size: 5351       Transition Number: 53.518  k Batch Size: 256        Lr: 0.004   
[2021-11-26 21:41:26,275][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 7.071    Value Loss: 4.183    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 9567       Buffer Size: 9567       Transition Number: 78.230  k Batch Size: 256        Lr: 0.006   
[2021-11-26 21:46:04,783][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 7.388    Value Loss: 3.471    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 11253      Buffer Size: 11253      Transition Number: 95.163  k Batch Size: 256        Lr: 0.008   
[2021-11-26 21:50:38,791][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.646    [weighted Loss:4.646    Policy Loss: 8.670    Value Loss: 3.235    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 13533      Buffer Size: 13533      Transition Number: 116.302 k Batch Size: 256        Lr: 0.010   
[2021-11-26 21:55:10,923][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.243    [weighted Loss:3.243    Policy Loss: 8.409    Value Loss: 2.968    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 15453      Buffer Size: 15453      Transition Number: 136.521 k Batch Size: 256        Lr: 0.010   
[2021-11-26 21:59:43,789][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 8.006    Value Loss: 2.890    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 16726      Buffer Size: 16726      Transition Number: 155.223 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:04:23,988][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.478    [weighted Loss:3.478    Policy Loss: 7.523    Value Loss: 2.855    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 17884      Buffer Size: 17884      Transition Number: 174.675 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:08:55,705][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.931    [weighted Loss:2.931    Policy Loss: 7.526    Value Loss: 2.798    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 18729      Buffer Size: 18729      Transition Number: 191.189 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:13:28,352][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.480    [weighted Loss:3.480    Policy Loss: 7.513    Value Loss: 2.820    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 19540      Buffer Size: 19540      Transition Number: 208.960 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:18:04,359][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 8.734    Value Loss: 2.942    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 20389      Buffer Size: 20389      Transition Number: 226.630 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:22:42,914][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.326    [weighted Loss:3.326    Policy Loss: 7.562    Value Loss: 2.976    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 21334      Buffer Size: 21334      Transition Number: 243.910 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:27:14,852][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.300    [weighted Loss:3.300    Policy Loss: 8.791    Value Loss: 2.888    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 22315      Buffer Size: 22315      Transition Number: 260.323 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:31:49,303][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.981    [weighted Loss:2.981    Policy Loss: 7.825    Value Loss: 3.027    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 23185      Buffer Size: 23185      Transition Number: 276.959 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:36:24,232][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.259    [weighted Loss:3.259    Policy Loss: 8.125    Value Loss: 2.968    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 24024      Buffer Size: 24024      Transition Number: 294.593 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:41:12,947][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.658    [weighted Loss:3.658    Policy Loss: 7.895    Value Loss: 2.935    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 24887      Buffer Size: 24887      Transition Number: 313.621 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:45:51,078][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 8.058    Value Loss: 3.050    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 25885      Buffer Size: 25885      Transition Number: 331.033 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:50:23,645][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 8.247    Value Loss: 3.019    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 27112      Buffer Size: 27112      Transition Number: 348.276 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:54:55,489][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.826    [weighted Loss:2.826    Policy Loss: 8.338    Value Loss: 2.763    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 28554      Buffer Size: 28554      Transition Number: 366.601 k Batch Size: 256        Lr: 0.010   
[2021-11-26 22:59:25,290][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 7.481    Value Loss: 2.962    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 30209      Buffer Size: 30209      Transition Number: 384.818 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:04:03,097][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 7.754    Value Loss: 2.987    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 31998      Buffer Size: 31998      Transition Number: 403.061 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:08:35,129][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 8.075    Value Loss: 2.895    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 33698      Buffer Size: 33698      Transition Number: 420.758 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:13:08,227][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 7.704    Value Loss: 2.849    Reward Loss: 0.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 35427      Buffer Size: 35427      Transition Number: 437.806 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:17:41,783][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 7.459    Value Loss: 2.781    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 36990      Buffer Size: 36990      Transition Number: 455.393 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:22:20,454][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 8.082    Value Loss: 2.837    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 39430      Buffer Size: 39430      Transition Number: 473.561 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:26:56,052][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.400    [weighted Loss:2.400    Policy Loss: 7.747    Value Loss: 2.820    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 41636      Buffer Size: 41636      Transition Number: 490.813 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:31:27,562][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 7.834    Value Loss: 2.686    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 43959      Buffer Size: 43959      Transition Number: 508.477 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:36:02,904][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 8.148    Value Loss: 2.738    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 46159      Buffer Size: 46159      Transition Number: 525.879 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:40:38,082][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.158    [weighted Loss:2.158    Policy Loss: 8.134    Value Loss: 2.677    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 47497      Buffer Size: 47497      Transition Number: 540.984 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:45:17,577][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.933    [weighted Loss:2.933    Policy Loss: 7.918    Value Loss: 2.762    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 48837      Buffer Size: 48837      Transition Number: 556.293 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:49:56,675][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 8.082    Value Loss: 2.802    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 50203      Buffer Size: 50203      Transition Number: 571.670 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:54:34,221][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.657    [weighted Loss:3.657    Policy Loss: 7.504    Value Loss: 2.687    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 51273      Buffer Size: 51273      Transition Number: 586.942 k Batch Size: 256        Lr: 0.010   
[2021-11-26 23:59:06,246][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 7.530    Value Loss: 2.938    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 52383      Buffer Size: 52383      Transition Number: 601.461 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:03:46,117][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.872    [weighted Loss:2.872    Policy Loss: 7.596    Value Loss: 2.698    Reward Loss: 0.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 53394      Buffer Size: 53394      Transition Number: 617.165 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:08:22,672][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.871    [weighted Loss:2.871    Policy Loss: 6.671    Value Loss: 2.897    Reward Loss: 0.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 54001      Buffer Size: 54001      Transition Number: 631.785 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:13:00,883][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 6.671    Value Loss: 3.088    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 54463      Buffer Size: 54463      Transition Number: 648.706 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:17:38,839][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.919    [weighted Loss:1.919    Policy Loss: 5.858    Value Loss: 3.213    Reward Loss: 0.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 54874      Buffer Size: 54874      Transition Number: 666.900 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:22:16,038][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.548    [weighted Loss:1.548    Policy Loss: 5.668    Value Loss: 3.442    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 55230      Buffer Size: 55230      Transition Number: 687.719 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:26:53,621][train][INFO][train.py>_log] ==> #78000      Total Loss: 0.810    [weighted Loss:0.810    Policy Loss: 6.264    Value Loss: 3.429    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 55619      Buffer Size: 55619      Transition Number: 711.005 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:31:34,254][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 5.010    Value Loss: 3.583    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 55971      Buffer Size: 55971      Transition Number: 734.039 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:36:16,447][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 5.873    Value Loss: 3.255    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 56315      Buffer Size: 56315      Transition Number: 757.351 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:40:54,161][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.563    [weighted Loss:1.563    Policy Loss: 5.309    Value Loss: 3.395    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 56682      Buffer Size: 56682      Transition Number: 781.435 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:45:34,937][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 5.584    Value Loss: 3.218    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 57063      Buffer Size: 57063      Transition Number: 804.226 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:50:20,022][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 5.266    Value Loss: 3.435    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 57429      Buffer Size: 57429      Transition Number: 826.295 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:55:02,826][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 4.868    Value Loss: 3.568    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 57797      Buffer Size: 57797      Transition Number: 849.564 k Batch Size: 256        Lr: 0.010   
[2021-11-27 00:59:44,819][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.280    [weighted Loss:1.280    Policy Loss: 4.510    Value Loss: 3.330    Reward Loss: 0.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 58136      Buffer Size: 58136      Transition Number: 871.594 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:04:28,183][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 4.392    Value Loss: 3.420    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 58505      Buffer Size: 58505      Transition Number: 895.729 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:09:19,385][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.371    [weighted Loss:1.371    Policy Loss: 4.388    Value Loss: 3.432    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 58844      Buffer Size: 58844      Transition Number: 918.936 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:14:01,188][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.469    [weighted Loss:1.469    Policy Loss: 4.042    Value Loss: 3.381    Reward Loss: 0.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 59202      Buffer Size: 59202      Transition Number: 943.754 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:18:51,369][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 4.303    Value Loss: 3.347    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 59534      Buffer Size: 59534      Transition Number: 966.553 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:23:39,019][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.114    [weighted Loss:1.114    Policy Loss: 3.811    Value Loss: 3.249    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 59897      Buffer Size: 59897      Transition Number: 991.021 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:28:34,064][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 4.347    Value Loss: 3.330    Reward Loss: 0.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 60253      Buffer Size: 59115      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:33:32,765][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 4.567    Value Loss: 3.385    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 60626      Buffer Size: 57106      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:38:34,311][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.165    [weighted Loss:2.165    Policy Loss: 4.420    Value Loss: 3.350    Reward Loss: 0.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 61000      Buffer Size: 54135      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:43:40,253][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 3.964    Value Loss: 3.399    Reward Loss: 0.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 61364      Buffer Size: 50801      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:48:44,826][train][INFO][train.py>_log] ==> #112000     Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 3.713    Value Loss: 3.445    Reward Loss: 0.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 61738      Buffer Size: 48574      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:53:49,371][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.266    [weighted Loss:1.266    Policy Loss: 3.866    Value Loss: 3.550    Reward Loss: 0.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 62095      Buffer Size: 46563      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-27 01:58:55,934][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.127    [weighted Loss:1.127    Policy Loss: 3.866    Value Loss: 3.347    Reward Loss: 0.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 62477      Buffer Size: 45272      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:04:06,670][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 4.160    Value Loss: 3.577    Reward Loss: 0.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 62830      Buffer Size: 44300      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:09:16,281][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 4.180    Value Loss: 3.501    Reward Loss: 0.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 63213      Buffer Size: 43557      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:14:27,219][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.011    [weighted Loss:1.011    Policy Loss: 4.071    Value Loss: 3.439    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 63586      Buffer Size: 42697      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:19:41,447][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 3.970    Value Loss: 3.650    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 63976      Buffer Size: 41593      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:24:52,995][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.518    [weighted Loss:1.518    Policy Loss: 3.994    Value Loss: 3.450    Reward Loss: 0.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 64333      Buffer Size: 40777      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:30:08,335][train][INFO][train.py>_log] ==> #128000     Total Loss: 0.904    [weighted Loss:0.904    Policy Loss: 3.903    Value Loss: 3.556    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 64719      Buffer Size: 39978      Transition Number: 999.948 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:35:21,504][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.403    [weighted Loss:1.403    Policy Loss: 3.908    Value Loss: 3.652    Reward Loss: 0.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 65075      Buffer Size: 38923      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:40:33,051][train][INFO][train.py>_log] ==> #132000     Total Loss: 0.822    [weighted Loss:0.822    Policy Loss: 3.893    Value Loss: 3.608    Reward Loss: 0.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 65435      Buffer Size: 37407      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:45:50,642][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.135    [weighted Loss:1.135    Policy Loss: 3.838    Value Loss: 3.924    Reward Loss: 0.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 65829      Buffer Size: 35424      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:51:08,428][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 4.212    Value Loss: 3.453    Reward Loss: 0.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 66221      Buffer Size: 33355      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 02:56:24,330][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 4.015    Value Loss: 3.650    Reward Loss: 0.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 66581      Buffer Size: 31385      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:01:43,810][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 4.151    Value Loss: 3.607    Reward Loss: 0.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 66952      Buffer Size: 29385      Transition Number: 999.968 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:07:02,100][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.259    [weighted Loss:1.259    Policy Loss: 4.138    Value Loss: 3.700    Reward Loss: 0.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 67347      Buffer Size: 26340      Transition Number: 1000.265k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:12:26,574][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 4.523    Value Loss: 3.714    Reward Loss: 0.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 67736      Buffer Size: 23331      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:17:50,000][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.845    [weighted Loss:1.845    Policy Loss: 4.560    Value Loss: 3.819    Reward Loss: 0.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 68089      Buffer Size: 21181      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:23:18,612][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 4.232    Value Loss: 3.914    Reward Loss: 0.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 68457      Buffer Size: 19406      Transition Number: 999.946 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:28:49,094][train][INFO][train.py>_log] ==> #150000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 4.435    Value Loss: 3.767    Reward Loss: 0.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 68849      Buffer Size: 17684      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:34:18,909][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 3.933    Value Loss: 3.897    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 69242      Buffer Size: 16165      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:39:46,507][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 4.277    Value Loss: 3.757    Reward Loss: 0.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 69628      Buffer Size: 15433      Transition Number: 999.974 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:45:17,072][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 4.256    Value Loss: 3.989    Reward Loss: 0.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 70017      Buffer Size: 15206      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:50:44,211][train][INFO][train.py>_log] ==> #158000     Total Loss: 0.926    [weighted Loss:0.926    Policy Loss: 4.371    Value Loss: 3.883    Reward Loss: 0.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 70379      Buffer Size: 15140      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-11-27 03:56:13,367][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 4.435    Value Loss: 3.955    Reward Loss: 0.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 70753      Buffer Size: 15098      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:01:39,715][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 4.493    Value Loss: 4.072    Reward Loss: 0.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 71132      Buffer Size: 15101      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:07:07,756][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 4.724    Value Loss: 3.981    Reward Loss: 0.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 71516      Buffer Size: 15108      Transition Number: 999.929 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:12:38,999][train][INFO][train.py>_log] ==> #166000     Total Loss: 1.800    [weighted Loss:1.800    Policy Loss: 4.942    Value Loss: 4.031    Reward Loss: 0.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 71897      Buffer Size: 15104      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:18:14,752][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 4.598    Value Loss: 4.170    Reward Loss: 0.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 72284      Buffer Size: 15071      Transition Number: 999.968 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:23:48,306][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 4.683    Value Loss: 4.250    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 72672      Buffer Size: 15041      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:29:18,115][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 4.540    Value Loss: 4.089    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 73073      Buffer Size: 15062      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:34:49,883][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 4.555    Value Loss: 4.087    Reward Loss: 0.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 73466      Buffer Size: 15086      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:40:17,634][train][INFO][train.py>_log] ==> #176000     Total Loss: 0.884    [weighted Loss:0.884    Policy Loss: 5.085    Value Loss: 4.289    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 73877      Buffer Size: 15137      Transition Number: 1000.027k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:45:49,264][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 4.872    Value Loss: 4.330    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 74270      Buffer Size: 15185      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:51:20,228][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 5.092    Value Loss: 4.311    Reward Loss: 0.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 74670      Buffer Size: 15242      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-27 04:56:53,961][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 5.304    Value Loss: 4.252    Reward Loss: 0.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 75096      Buffer Size: 15305      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:02:27,131][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.357    [weighted Loss:1.357    Policy Loss: 4.862    Value Loss: 4.314    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 75497      Buffer Size: 15330      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:08:00,074][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 4.873    Value Loss: 4.264    Reward Loss: 0.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 75900      Buffer Size: 15371      Transition Number: 1000.059k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:13:28,361][train][INFO][train.py>_log] ==> #188000     Total Loss: 0.974    [weighted Loss:0.974    Policy Loss: 4.663    Value Loss: 4.471    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 76283      Buffer Size: 15377      Transition Number: 999.985 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:19:01,141][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 4.604    Value Loss: 4.339    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 76677      Buffer Size: 15410      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:24:33,764][train][INFO][train.py>_log] ==> #192000     Total Loss: 0.986    [weighted Loss:0.986    Policy Loss: 4.661    Value Loss: 4.453    Reward Loss: 0.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 77066      Buffer Size: 15432      Transition Number: 999.980 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:30:02,050][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 4.743    Value Loss: 4.377    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 77441      Buffer Size: 15453      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:35:35,710][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 4.854    Value Loss: 4.391    Reward Loss: 0.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 77833      Buffer Size: 15459      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:41:07,032][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 4.567    Value Loss: 4.657    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 78208      Buffer Size: 15464      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:46:38,240][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 4.999    Value Loss: 4.534    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 78599      Buffer Size: 15470      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:52:17,759][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 4.914    Value Loss: 4.618    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 79000      Buffer Size: 15478      Transition Number: 999.930 k Batch Size: 256        Lr: 0.010   
[2021-11-27 05:57:48,961][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 4.479    Value Loss: 4.373    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 79390      Buffer Size: 15481      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:03:23,332][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.441    [weighted Loss:1.441    Policy Loss: 4.463    Value Loss: 4.387    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 79781      Buffer Size: 15477      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:08:58,317][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 4.753    Value Loss: 4.675    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 80176      Buffer Size: 15473      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:14:35,509][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.433    [weighted Loss:1.433    Policy Loss: 4.403    Value Loss: 4.597    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 80570      Buffer Size: 15482      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:20:07,057][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.490    [weighted Loss:2.490    Policy Loss: 4.747    Value Loss: 4.531    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 80961      Buffer Size: 15490      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:25:38,021][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 4.294    Value Loss: 4.598    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 81342      Buffer Size: 15474      Transition Number: 999.925 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:31:11,377][train][INFO][train.py>_log] ==> #216000     Total Loss: 1.254    [weighted Loss:1.254    Policy Loss: 4.239    Value Loss: 4.691    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 81729      Buffer Size: 15444      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:36:47,935][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.643    [weighted Loss:1.643    Policy Loss: 4.462    Value Loss: 4.488    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 82114      Buffer Size: 15408      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:42:22,202][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 4.168    Value Loss: 4.597    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 82515      Buffer Size: 15395      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:47:58,506][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 4.465    Value Loss: 4.428    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 82911      Buffer Size: 15357      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:53:35,714][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 4.346    Value Loss: 4.518    Reward Loss: 0.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 83329      Buffer Size: 15319      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-27 06:59:12,599][train][INFO][train.py>_log] ==> #226000     Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 4.584    Value Loss: 4.680    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 83718      Buffer Size: 15287      Transition Number: 1000.038k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:04:50,681][train][INFO][train.py>_log] ==> #228000     Total Loss: 0.880    [weighted Loss:0.880    Policy Loss: 4.450    Value Loss: 4.553    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 84124      Buffer Size: 15252      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:10:26,222][train][INFO][train.py>_log] ==> #230000     Total Loss: 1.210    [weighted Loss:1.210    Policy Loss: 5.283    Value Loss: 4.425    Reward Loss: 0.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 84520      Buffer Size: 15222      Transition Number: 1000.021k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:15:59,278][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 5.324    Value Loss: 4.528    Reward Loss: 0.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 84918      Buffer Size: 15199      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:21:36,186][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 5.178    Value Loss: 4.419    Reward Loss: 0.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 85319      Buffer Size: 15171      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:27:19,407][train][INFO][train.py>_log] ==> #236000     Total Loss: 1.932    [weighted Loss:1.932    Policy Loss: 5.060    Value Loss: 4.835    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 85735      Buffer Size: 15149      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:33:02,028][train][INFO][train.py>_log] ==> #238000     Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 4.969    Value Loss: 4.418    Reward Loss: 0.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 86148      Buffer Size: 15143      Transition Number: 1000.017k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:38:43,900][train][INFO][train.py>_log] ==> #240000     Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 4.888    Value Loss: 4.317    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 86558      Buffer Size: 15116      Transition Number: 999.983 k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:44:22,906][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 5.028    Value Loss: 4.068    Reward Loss: 0.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 86967      Buffer Size: 15093      Transition Number: 1000.121k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:50:01,325][train][INFO][train.py>_log] ==> #244000     Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 5.400    Value Loss: 4.382    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 87395      Buffer Size: 15066      Transition Number: 1000.098k Batch Size: 256        Lr: 0.010   
[2021-11-27 07:55:40,701][train][INFO][train.py>_log] ==> #246000     Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 5.356    Value Loss: 4.341    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 87798      Buffer Size: 15030      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:01:15,744][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.149    [weighted Loss:1.149    Policy Loss: 4.516    Value Loss: 4.315    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 88193      Buffer Size: 14981      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:06:55,840][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 5.076    Value Loss: 4.428    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 88593      Buffer Size: 14930      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:12:34,651][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 4.889    Value Loss: 4.183    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 89006      Buffer Size: 14860      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:18:15,494][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 5.650    Value Loss: 4.330    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 89441      Buffer Size: 14813      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:23:53,399][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 5.161    Value Loss: 4.166    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 89853      Buffer Size: 14740      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:29:27,715][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 5.052    Value Loss: 4.264    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 90254      Buffer Size: 14697      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:35:10,012][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.674    [weighted Loss:1.674    Policy Loss: 5.626    Value Loss: 4.565    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 90671      Buffer Size: 14645      Transition Number: 999.978 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:40:47,962][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 5.645    Value Loss: 4.135    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 91081      Buffer Size: 14626      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:46:31,065][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.781    [weighted Loss:1.781    Policy Loss: 5.904    Value Loss: 4.356    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 91500      Buffer Size: 14582      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:52:08,008][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 5.590    Value Loss: 4.162    Reward Loss: 0.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 91919      Buffer Size: 14582      Transition Number: 999.947 k Batch Size: 256        Lr: 0.010   
[2021-11-27 08:57:46,647][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 5.947    Value Loss: 4.296    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 92317      Buffer Size: 14576      Transition Number: 999.947 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:03:26,130][train][INFO][train.py>_log] ==> #270000     Total Loss: 1.248    [weighted Loss:1.248    Policy Loss: 5.337    Value Loss: 4.421    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 92730      Buffer Size: 14566      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:09:08,400][train][INFO][train.py>_log] ==> #272000     Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 6.382    Value Loss: 4.499    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 93148      Buffer Size: 14546      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:14:49,836][train][INFO][train.py>_log] ==> #274000     Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 5.958    Value Loss: 4.382    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 93566      Buffer Size: 14505      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:20:29,045][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 5.891    Value Loss: 4.704    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 93981      Buffer Size: 14500      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:26:12,836][train][INFO][train.py>_log] ==> #278000     Total Loss: 0.980    [weighted Loss:0.980    Policy Loss: 5.702    Value Loss: 4.339    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 94406      Buffer Size: 14490      Transition Number: 999.943 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:31:53,376][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 5.350    Value Loss: 4.461    Reward Loss: 0.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 94808      Buffer Size: 14466      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:37:34,173][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.753    [weighted Loss:1.753    Policy Loss: 5.049    Value Loss: 4.255    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 95222      Buffer Size: 14459      Transition Number: 999.951 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:43:15,715][train][INFO][train.py>_log] ==> #284000     Total Loss: 1.549    [weighted Loss:1.549    Policy Loss: 5.228    Value Loss: 4.415    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 95651      Buffer Size: 14458      Transition Number: 999.943 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:48:58,068][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 5.524    Value Loss: 4.636    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 96071      Buffer Size: 14490      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-11-27 09:54:38,998][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 5.671    Value Loss: 4.586    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 96485      Buffer Size: 14526      Transition Number: 999.927 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:00:18,849][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 5.309    Value Loss: 4.566    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 96900      Buffer Size: 14538      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:06:00,527][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 4.738    Value Loss: 4.640    Reward Loss: 0.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 97313      Buffer Size: 14531      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:11:41,123][train][INFO][train.py>_log] ==> #294000     Total Loss: 0.583    [weighted Loss:0.583    Policy Loss: 5.458    Value Loss: 4.525    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 97721      Buffer Size: 14524      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:17:24,438][train][INFO][train.py>_log] ==> #296000     Total Loss: 1.313    [weighted Loss:1.313    Policy Loss: 4.693    Value Loss: 4.853    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 98148      Buffer Size: 14530      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:23:05,819][train][INFO][train.py>_log] ==> #298000     Total Loss: 0.885    [weighted Loss:0.885    Policy Loss: 4.452    Value Loss: 4.596    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 98556      Buffer Size: 14526      Transition Number: 999.927 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:28:50,073][train][INFO][train.py>_log] ==> #300000     Total Loss: 1.612    [weighted Loss:1.612    Policy Loss: 4.768    Value Loss: 4.542    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 98972      Buffer Size: 14539      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:34:33,242][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.379    [weighted Loss:1.379    Policy Loss: 4.657    Value Loss: 4.673    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 99386      Buffer Size: 14537      Transition Number: 999.929 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:40:11,439][train][INFO][train.py>_log] ==> #304000     Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 5.275    Value Loss: 4.524    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 99817      Buffer Size: 14517      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:45:51,110][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.437    [weighted Loss:1.437    Policy Loss: 5.493    Value Loss: 4.625    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 100250     Buffer Size: 14569      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:51:30,796][train][INFO][train.py>_log] ==> #308000     Total Loss: 0.948    [weighted Loss:0.948    Policy Loss: 5.832    Value Loss: 4.641    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 100666     Buffer Size: 14550      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-27 10:57:10,630][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.095    [weighted Loss:1.095    Policy Loss: 4.945    Value Loss: 4.398    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 101092     Buffer Size: 14547      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:02:51,886][train][INFO][train.py>_log] ==> #312000     Total Loss: 1.781    [weighted Loss:1.781    Policy Loss: 5.410    Value Loss: 4.777    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 101501     Buffer Size: 14534      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:08:40,212][train][INFO][train.py>_log] ==> #314000     Total Loss: 0.971    [weighted Loss:0.971    Policy Loss: 5.062    Value Loss: 4.515    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 101916     Buffer Size: 14520      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:14:26,304][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 5.499    Value Loss: 4.695    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 102340     Buffer Size: 14491      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:20:09,206][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.468    [weighted Loss:1.468    Policy Loss: 5.835    Value Loss: 4.665    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 102770     Buffer Size: 14478      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:25:55,541][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.154    [weighted Loss:1.154    Policy Loss: 5.687    Value Loss: 4.521    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 103197     Buffer Size: 14453      Transition Number: 1000.085k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:31:41,214][train][INFO][train.py>_log] ==> #322000     Total Loss: 0.964    [weighted Loss:0.964    Policy Loss: 5.297    Value Loss: 4.816    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 103627     Buffer Size: 14427      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:37:23,791][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.118    [weighted Loss:1.118    Policy Loss: 5.418    Value Loss: 4.621    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 104044     Buffer Size: 14389      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:43:09,945][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 5.263    Value Loss: 4.940    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 104473     Buffer Size: 14359      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:48:56,238][train][INFO][train.py>_log] ==> #328000     Total Loss: 0.518    [weighted Loss:0.518    Policy Loss: 5.187    Value Loss: 4.605    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 104913     Buffer Size: 14341      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-11-27 11:54:44,133][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.286    [weighted Loss:2.286    Policy Loss: 6.030    Value Loss: 4.483    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 105342     Buffer Size: 14330      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:00:32,815][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 6.111    Value Loss: 4.713    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 105773     Buffer Size: 14314      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:06:20,023][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 6.021    Value Loss: 4.525    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 106203     Buffer Size: 14274      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:12:05,937][train][INFO][train.py>_log] ==> #336000     Total Loss: 1.417    [weighted Loss:1.417    Policy Loss: 5.559    Value Loss: 4.650    Reward Loss: 0.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 106643     Buffer Size: 14245      Transition Number: 1000.032k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:17:54,341][train][INFO][train.py>_log] ==> #338000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 5.515    Value Loss: 4.997    Reward Loss: 0.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 107067     Buffer Size: 14210      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:23:42,301][train][INFO][train.py>_log] ==> #340000     Total Loss: 1.152    [weighted Loss:1.152    Policy Loss: 6.008    Value Loss: 4.849    Reward Loss: 0.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 107512     Buffer Size: 14194      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:29:31,795][train][INFO][train.py>_log] ==> #342000     Total Loss: 1.104    [weighted Loss:1.104    Policy Loss: 5.573    Value Loss: 4.730    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 107958     Buffer Size: 14163      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:35:19,934][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.292    [weighted Loss:2.292    Policy Loss: 5.446    Value Loss: 4.787    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 108390     Buffer Size: 14150      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:41:06,422][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.678    [weighted Loss:1.678    Policy Loss: 5.512    Value Loss: 4.741    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 108828     Buffer Size: 14137      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:46:50,730][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 5.953    Value Loss: 4.788    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 109271     Buffer Size: 14131      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:52:32,997][train][INFO][train.py>_log] ==> #350000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 5.883    Value Loss: 4.801    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 109696     Buffer Size: 14117      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-27 12:58:17,361][train][INFO][train.py>_log] ==> #352000     Total Loss: 1.568    [weighted Loss:1.568    Policy Loss: 5.838    Value Loss: 4.810    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 110138     Buffer Size: 14094      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:04:05,863][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 5.682    Value Loss: 4.804    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 110572     Buffer Size: 14051      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:09:53,464][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 5.103    Value Loss: 4.394    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 111023     Buffer Size: 14021      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:15:36,633][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.240    [weighted Loss:2.240    Policy Loss: 5.534    Value Loss: 4.949    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 111434     Buffer Size: 14029      Transition Number: 999.937 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:21:24,538][train][INFO][train.py>_log] ==> #360000     Total Loss: 0.895    [weighted Loss:0.895    Policy Loss: 5.611    Value Loss: 5.020    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 111900     Buffer Size: 14044      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:27:14,387][train][INFO][train.py>_log] ==> #362000     Total Loss: 0.756    [weighted Loss:0.756    Policy Loss: 5.586    Value Loss: 4.723    Reward Loss: 0.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 112346     Buffer Size: 14051      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:32:58,790][train][INFO][train.py>_log] ==> #364000     Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 5.789    Value Loss: 4.542    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 112785     Buffer Size: 14067      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:38:44,047][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.882    [weighted Loss:2.882    Policy Loss: 6.294    Value Loss: 4.902    Reward Loss: 0.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 113309     Buffer Size: 14191      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:44:31,225][train][INFO][train.py>_log] ==> #368000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 5.819    Value Loss: 4.681    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 113770     Buffer Size: 14256      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:50:18,388][train][INFO][train.py>_log] ==> #370000     Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 5.843    Value Loss: 4.722    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 114205     Buffer Size: 14276      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-27 13:56:06,127][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.188    [weighted Loss:1.188    Policy Loss: 5.644    Value Loss: 5.010    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 114655     Buffer Size: 14245      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:01:47,782][train][INFO][train.py>_log] ==> #374000     Total Loss: 0.811    [weighted Loss:0.811    Policy Loss: 6.096    Value Loss: 5.036    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 115078     Buffer Size: 14292      Transition Number: 1000.051k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:07:36,303][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 5.669    Value Loss: 4.544    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 115528     Buffer Size: 14321      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:13:23,695][train][INFO][train.py>_log] ==> #378000     Total Loss: 1.677    [weighted Loss:1.677    Policy Loss: 6.543    Value Loss: 5.229    Reward Loss: 0.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 115974     Buffer Size: 14362      Transition Number: 999.971 k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:19:09,085][train][INFO][train.py>_log] ==> #380000     Total Loss: 1.232    [weighted Loss:1.232    Policy Loss: 6.008    Value Loss: 4.727    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 116420     Buffer Size: 14403      Transition Number: 1000.051k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:24:52,341][train][INFO][train.py>_log] ==> #382000     Total Loss: 1.307    [weighted Loss:1.307    Policy Loss: 5.838    Value Loss: 4.842    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 116848     Buffer Size: 14434      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:30:33,463][train][INFO][train.py>_log] ==> #384000     Total Loss: 0.630    [weighted Loss:0.630    Policy Loss: 5.806    Value Loss: 4.622    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 117312     Buffer Size: 14471      Transition Number: 1000.065k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:36:14,850][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.939    [weighted Loss:1.939    Policy Loss: 6.382    Value Loss: 4.635    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 117738     Buffer Size: 14509      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:41:57,265][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 5.883    Value Loss: 4.761    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 118186     Buffer Size: 14540      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:47:40,595][train][INFO][train.py>_log] ==> #390000     Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 5.876    Value Loss: 4.756    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 118630     Buffer Size: 14587      Transition Number: 1000.041k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:53:27,497][train][INFO][train.py>_log] ==> #392000     Total Loss: 0.957    [weighted Loss:0.957    Policy Loss: 5.557    Value Loss: 4.662    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 119068     Buffer Size: 14621      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-27 14:59:07,535][train][INFO][train.py>_log] ==> #394000     Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 5.304    Value Loss: 4.634    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 119507     Buffer Size: 14650      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:04:45,508][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 6.087    Value Loss: 4.658    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 119941     Buffer Size: 14663      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:10:31,146][train][INFO][train.py>_log] ==> #398000     Total Loss: 0.833    [weighted Loss:0.833    Policy Loss: 5.524    Value Loss: 4.644    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 120386     Buffer Size: 14682      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:16:15,664][train][INFO][train.py>_log] ==> #400000     Total Loss: 1.154    [weighted Loss:1.154    Policy Loss: 5.941    Value Loss: 4.620    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 120846     Buffer Size: 14708      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:22:01,354][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 5.985    Value Loss: 4.619    Reward Loss: 0.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 121275     Buffer Size: 14735      Transition Number: 1000.031k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:27:46,283][train][INFO][train.py>_log] ==> #404000     Total Loss: 1.781    [weighted Loss:1.781    Policy Loss: 5.568    Value Loss: 4.588    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 121726     Buffer Size: 14768      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:33:31,365][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.359    [weighted Loss:2.359    Policy Loss: 5.471    Value Loss: 4.709    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 122187     Buffer Size: 14799      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:39:18,624][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.360    [weighted Loss:1.360    Policy Loss: 5.951    Value Loss: 4.595    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 122636     Buffer Size: 14837      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:45:04,424][train][INFO][train.py>_log] ==> #410000     Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 5.620    Value Loss: 4.870    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 123084     Buffer Size: 14881      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:50:49,267][train][INFO][train.py>_log] ==> #412000     Total Loss: 1.439    [weighted Loss:1.439    Policy Loss: 5.397    Value Loss: 4.762    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 123532     Buffer Size: 14921      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-11-27 15:56:35,673][train][INFO][train.py>_log] ==> #414000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 5.697    Value Loss: 4.797    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 123982     Buffer Size: 14958      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:02:21,599][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.774    [weighted Loss:1.774    Policy Loss: 5.618    Value Loss: 4.760    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 124436     Buffer Size: 14988      Transition Number: 1000.010k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:08:04,807][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 5.390    Value Loss: 4.288    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 124870     Buffer Size: 15018      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:13:48,254][train][INFO][train.py>_log] ==> #420000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 5.385    Value Loss: 4.367    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 125328     Buffer Size: 15052      Transition Number: 999.969 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:19:34,034][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.569    [weighted Loss:1.569    Policy Loss: 5.494    Value Loss: 4.661    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 125774     Buffer Size: 15085      Transition Number: 999.933 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:25:17,332][train][INFO][train.py>_log] ==> #424000     Total Loss: 0.519    [weighted Loss:0.519    Policy Loss: 5.882    Value Loss: 4.561    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 126226     Buffer Size: 15135      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:30:59,445][train][INFO][train.py>_log] ==> #426000     Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 6.020    Value Loss: 4.526    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 126668     Buffer Size: 15183      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:36:42,137][train][INFO][train.py>_log] ==> #428000     Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 6.553    Value Loss: 4.972    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 127129     Buffer Size: 15230      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:42:24,820][train][INFO][train.py>_log] ==> #430000     Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 6.136    Value Loss: 4.648    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 127583     Buffer Size: 15273      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:48:02,600][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.450    [weighted Loss:1.450    Policy Loss: 5.938    Value Loss: 4.575    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 128015     Buffer Size: 15306      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:53:48,891][train][INFO][train.py>_log] ==> #434000     Total Loss: 0.882    [weighted Loss:0.882    Policy Loss: 6.144    Value Loss: 4.669    Reward Loss: 0.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 128486     Buffer Size: 15253      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-27 16:59:27,179][train][INFO][train.py>_log] ==> #436000     Total Loss: 1.623    [weighted Loss:1.623    Policy Loss: 6.365    Value Loss: 4.443    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 128919     Buffer Size: 15237      Transition Number: 999.937 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:05:06,200][train][INFO][train.py>_log] ==> #438000     Total Loss: 0.906    [weighted Loss:0.906    Policy Loss: 7.147    Value Loss: 4.896    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 129396     Buffer Size: 15282      Transition Number: 999.929 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:10:50,570][train][INFO][train.py>_log] ==> #440000     Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 6.631    Value Loss: 4.844    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 129855     Buffer Size: 15328      Transition Number: 999.983 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:16:37,352][train][INFO][train.py>_log] ==> #442000     Total Loss: 1.672    [weighted Loss:1.672    Policy Loss: 6.872    Value Loss: 4.891    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 130300     Buffer Size: 15338      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:22:19,303][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 6.873    Value Loss: 4.511    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 130762     Buffer Size: 15341      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:28:01,185][train][INFO][train.py>_log] ==> #446000     Total Loss: 1.300    [weighted Loss:1.300    Policy Loss: 6.514    Value Loss: 4.598    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 131214     Buffer Size: 15359      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:33:42,993][train][INFO][train.py>_log] ==> #448000     Total Loss: 1.990    [weighted Loss:1.990    Policy Loss: 6.513    Value Loss: 4.706    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 131676     Buffer Size: 15383      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:39:23,970][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.152    [weighted Loss:2.152    Policy Loss: 6.712    Value Loss: 5.051    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 132127     Buffer Size: 15408      Transition Number: 1000.011k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:45:05,548][train][INFO][train.py>_log] ==> #452000     Total Loss: 2.058    [weighted Loss:2.058    Policy Loss: 6.623    Value Loss: 4.497    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 132574     Buffer Size: 15420      Transition Number: 999.982 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:50:49,330][train][INFO][train.py>_log] ==> #454000     Total Loss: 1.149    [weighted Loss:1.149    Policy Loss: 7.131    Value Loss: 4.676    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 133025     Buffer Size: 15430      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-11-27 17:56:32,311][train][INFO][train.py>_log] ==> #456000     Total Loss: 1.280    [weighted Loss:1.280    Policy Loss: 6.289    Value Loss: 4.594    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 133476     Buffer Size: 15447      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:02:13,671][train][INFO][train.py>_log] ==> #458000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 7.756    Value Loss: 4.833    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 133928     Buffer Size: 15479      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:07:52,870][train][INFO][train.py>_log] ==> #460000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 7.964    Value Loss: 4.681    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 134385     Buffer Size: 15503      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:13:35,455][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 7.336    Value Loss: 4.723    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 134829     Buffer Size: 15535      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:19:16,022][train][INFO][train.py>_log] ==> #464000     Total Loss: 1.959    [weighted Loss:1.959    Policy Loss: 7.623    Value Loss: 4.845    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 135289     Buffer Size: 15554      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:24:54,490][train][INFO][train.py>_log] ==> #466000     Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 7.554    Value Loss: 4.770    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 135718     Buffer Size: 15576      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:30:34,501][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 6.694    Value Loss: 4.757    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 136174     Buffer Size: 15601      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:36:20,262][train][INFO][train.py>_log] ==> #470000     Total Loss: 1.208    [weighted Loss:1.208    Policy Loss: 7.194    Value Loss: 4.725    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 136612     Buffer Size: 15639      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:42:01,119][train][INFO][train.py>_log] ==> #472000     Total Loss: 1.435    [weighted Loss:1.435    Policy Loss: 7.576    Value Loss: 4.810    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 137069     Buffer Size: 15679      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:47:47,248][train][INFO][train.py>_log] ==> #474000     Total Loss: 1.007    [weighted Loss:1.007    Policy Loss: 6.960    Value Loss: 4.969    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 137521     Buffer Size: 15721      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:53:26,088][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.136    [weighted Loss:1.136    Policy Loss: 7.227    Value Loss: 4.858    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 137972     Buffer Size: 15747      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-11-27 18:59:04,198][train][INFO][train.py>_log] ==> #478000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 6.836    Value Loss: 5.070    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 138409     Buffer Size: 15768      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:04:47,356][train][INFO][train.py>_log] ==> #480000     Total Loss: 1.922    [weighted Loss:1.922    Policy Loss: 7.435    Value Loss: 4.894    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 138871     Buffer Size: 15791      Transition Number: 999.948 k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:10:28,424][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 7.644    Value Loss: 5.180    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 139316     Buffer Size: 15823      Transition Number: 999.974 k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:16:12,057][train][INFO][train.py>_log] ==> #484000     Total Loss: 1.166    [weighted Loss:1.166    Policy Loss: 7.478    Value Loss: 4.677    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 139772     Buffer Size: 15841      Transition Number: 1000.030k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:21:53,381][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.017    [weighted Loss:2.017    Policy Loss: 7.299    Value Loss: 4.951    Reward Loss: 0.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 140217     Buffer Size: 15870      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:27:35,890][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 7.306    Value Loss: 4.816    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 140689     Buffer Size: 15903      Transition Number: 1000.008k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:33:11,885][train][INFO][train.py>_log] ==> #490000     Total Loss: 0.813    [weighted Loss:0.813    Policy Loss: 6.785    Value Loss: 4.833    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 141125     Buffer Size: 15937      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:38:49,784][train][INFO][train.py>_log] ==> #492000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 7.664    Value Loss: 4.769    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 141590     Buffer Size: 15979      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:44:30,184][train][INFO][train.py>_log] ==> #494000     Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 7.395    Value Loss: 5.423    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 142048     Buffer Size: 16022      Transition Number: 1000.107k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:50:11,698][train][INFO][train.py>_log] ==> #496000     Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 7.506    Value Loss: 5.047    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 142502     Buffer Size: 16050      Transition Number: 999.943 k Batch Size: 256        Lr: 0.010   
[2021-11-27 19:55:55,646][train][INFO][train.py>_log] ==> #498000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 8.027    Value Loss: 4.867    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 142964     Buffer Size: 16050      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:01:33,461][train][INFO][train.py>_log] ==> #500000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 7.162    Value Loss: 5.249    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 143393     Buffer Size: 16052      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:07:07,938][train][INFO][train.py>_log] ==> #502000     Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 7.235    Value Loss: 5.151    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 143843     Buffer Size: 16056      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:12:50,389][train][INFO][train.py>_log] ==> #504000     Total Loss: 1.465    [weighted Loss:1.465    Policy Loss: 7.371    Value Loss: 5.276    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 144421     Buffer Size: 16225      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:18:34,113][train][INFO][train.py>_log] ==> #506000     Total Loss: 2.122    [weighted Loss:2.122    Policy Loss: 7.458    Value Loss: 5.040    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 144878     Buffer Size: 16233      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:24:19,131][train][INFO][train.py>_log] ==> #508000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 7.708    Value Loss: 5.056    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 145330     Buffer Size: 16207      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:30:00,573][train][INFO][train.py>_log] ==> #510000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 7.621    Value Loss: 4.978    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 145783     Buffer Size: 16223      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:35:34,810][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.039    [weighted Loss:1.039    Policy Loss: 7.072    Value Loss: 4.984    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 146247     Buffer Size: 16261      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:41:12,253][train][INFO][train.py>_log] ==> #514000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 7.345    Value Loss: 5.190    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 146695     Buffer Size: 16270      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:46:50,774][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 7.741    Value Loss: 5.198    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 147127     Buffer Size: 16269      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:52:31,177][train][INFO][train.py>_log] ==> #518000     Total Loss: 1.795    [weighted Loss:1.795    Policy Loss: 7.414    Value Loss: 4.754    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 147581     Buffer Size: 16279      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-27 20:58:09,451][train][INFO][train.py>_log] ==> #520000     Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 8.072    Value Loss: 5.188    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 148024     Buffer Size: 16265      Transition Number: 1000.045k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:03:50,165][train][INFO][train.py>_log] ==> #522000     Total Loss: 1.312    [weighted Loss:1.312    Policy Loss: 6.865    Value Loss: 4.794    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 148475     Buffer Size: 16267      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:09:31,703][train][INFO][train.py>_log] ==> #524000     Total Loss: 1.006    [weighted Loss:1.006    Policy Loss: 7.573    Value Loss: 4.801    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 148928     Buffer Size: 16275      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:15:11,951][train][INFO][train.py>_log] ==> #526000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 7.241    Value Loss: 5.157    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 149376     Buffer Size: 16273      Transition Number: 1000.210k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:20:46,687][train][INFO][train.py>_log] ==> #528000     Total Loss: 0.522    [weighted Loss:0.522    Policy Loss: 7.251    Value Loss: 4.888    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 149813     Buffer Size: 16258      Transition Number: 999.974 k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:26:24,568][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 6.798    Value Loss: 4.713    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 150259     Buffer Size: 16208      Transition Number: 1000.034k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:32:04,113][train][INFO][train.py>_log] ==> #532000     Total Loss: 1.160    [weighted Loss:1.160    Policy Loss: 7.219    Value Loss: 5.208    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 150727     Buffer Size: 16167      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:37:44,875][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.886    [weighted Loss:2.886    Policy Loss: 6.783    Value Loss: 5.166    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 151161     Buffer Size: 16138      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:43:24,740][train][INFO][train.py>_log] ==> #536000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 7.523    Value Loss: 4.991    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 151647     Buffer Size: 16148      Transition Number: 1000.040k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:49:06,447][train][INFO][train.py>_log] ==> #538000     Total Loss: 1.171    [weighted Loss:1.171    Policy Loss: 7.242    Value Loss: 4.978    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 152116     Buffer Size: 16144      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-11-27 21:54:52,658][train][INFO][train.py>_log] ==> #540000     Total Loss: 0.500    [weighted Loss:0.500    Policy Loss: 8.228    Value Loss: 4.881    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 152582     Buffer Size: 16144      Transition Number: 1000.141k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:00:30,087][train][INFO][train.py>_log] ==> #542000     Total Loss: 1.215    [weighted Loss:1.215    Policy Loss: 7.954    Value Loss: 5.153    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 153026     Buffer Size: 16125      Transition Number: 999.949 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:06:08,511][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.333    [weighted Loss:1.333    Policy Loss: 7.518    Value Loss: 5.325    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 153519     Buffer Size: 16119      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:11:50,806][train][INFO][train.py>_log] ==> #546000     Total Loss: 0.933    [weighted Loss:0.933    Policy Loss: 6.932    Value Loss: 5.185    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 153988     Buffer Size: 16152      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:17:29,137][train][INFO][train.py>_log] ==> #548000     Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 7.528    Value Loss: 5.093    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 154443     Buffer Size: 16125      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:23:08,665][train][INFO][train.py>_log] ==> #550000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 7.407    Value Loss: 4.798    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 154893     Buffer Size: 16091      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:28:51,377][train][INFO][train.py>_log] ==> #552000     Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 7.228    Value Loss: 5.608    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 155363     Buffer Size: 16030      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:34:36,968][train][INFO][train.py>_log] ==> #554000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 8.028    Value Loss: 5.502    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 155814     Buffer Size: 15992      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:40:19,553][train][INFO][train.py>_log] ==> #556000     Total Loss: 1.441    [weighted Loss:1.441    Policy Loss: 7.723    Value Loss: 4.965    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 156262     Buffer Size: 15960      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:46:05,272][train][INFO][train.py>_log] ==> #558000     Total Loss: 1.618    [weighted Loss:1.618    Policy Loss: 7.500    Value Loss: 5.051    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 156726     Buffer Size: 15918      Transition Number: 1000.035k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:51:45,480][train][INFO][train.py>_log] ==> #560000     Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 8.263    Value Loss: 5.174    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 157189     Buffer Size: 15882      Transition Number: 999.968 k Batch Size: 256        Lr: 0.010   
[2021-11-27 22:57:30,012][train][INFO][train.py>_log] ==> #562000     Total Loss: 0.758    [weighted Loss:0.758    Policy Loss: 7.314    Value Loss: 5.310    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 157639     Buffer Size: 15847      Transition Number: 999.948 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:03:14,787][train][INFO][train.py>_log] ==> #564000     Total Loss: 1.423    [weighted Loss:1.423    Policy Loss: 8.500    Value Loss: 4.647    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 158087     Buffer Size: 15773      Transition Number: 1000.093k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:08:58,234][train][INFO][train.py>_log] ==> #566000     Total Loss: 1.904    [weighted Loss:1.904    Policy Loss: 8.410    Value Loss: 5.123    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 158619     Buffer Size: 15843      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:14:43,482][train][INFO][train.py>_log] ==> #568000     Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 7.884    Value Loss: 5.205    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 159118     Buffer Size: 15885      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:20:30,515][train][INFO][train.py>_log] ==> #570000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 8.503    Value Loss: 5.309    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 159598     Buffer Size: 15911      Transition Number: 999.983 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:26:18,700][train][INFO][train.py>_log] ==> #572000     Total Loss: 1.571    [weighted Loss:1.571    Policy Loss: 8.537    Value Loss: 5.689    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 160083     Buffer Size: 15814      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:32:04,440][train][INFO][train.py>_log] ==> #574000     Total Loss: 1.200    [weighted Loss:1.200    Policy Loss: 8.801    Value Loss: 5.081    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 160530     Buffer Size: 15711      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:37:52,446][train][INFO][train.py>_log] ==> #576000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 8.257    Value Loss: 4.901    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 160986     Buffer Size: 15700      Transition Number: 999.946 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:43:32,201][train][INFO][train.py>_log] ==> #578000     Total Loss: 1.919    [weighted Loss:1.919    Policy Loss: 8.521    Value Loss: 4.903    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 161434     Buffer Size: 15626      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:49:20,344][train][INFO][train.py>_log] ==> #580000     Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 8.555    Value Loss: 5.146    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 161911     Buffer Size: 15566      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-27 23:55:06,187][train][INFO][train.py>_log] ==> #582000     Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 8.402    Value Loss: 5.109    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 162363     Buffer Size: 15540      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:00:47,551][train][INFO][train.py>_log] ==> #584000     Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 8.168    Value Loss: 5.218    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 162822     Buffer Size: 15507      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:06:36,000][train][INFO][train.py>_log] ==> #586000     Total Loss: 1.274    [weighted Loss:1.274    Policy Loss: 8.172    Value Loss: 5.199    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 163270     Buffer Size: 15466      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:12:19,913][train][INFO][train.py>_log] ==> #588000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 8.584    Value Loss: 5.281    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 163735     Buffer Size: 15439      Transition Number: 999.980 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:18:04,772][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 9.043    Value Loss: 5.253    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 164181     Buffer Size: 15408      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:23:51,811][train][INFO][train.py>_log] ==> #592000     Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 8.341    Value Loss: 5.037    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 164641     Buffer Size: 15386      Transition Number: 999.961 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:29:37,581][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 8.668    Value Loss: 5.133    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 165109     Buffer Size: 15368      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:35:27,240][train][INFO][train.py>_log] ==> #596000     Total Loss: 0.862    [weighted Loss:0.862    Policy Loss: 8.941    Value Loss: 5.503    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 165573     Buffer Size: 15359      Transition Number: 999.969 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:41:15,296][train][INFO][train.py>_log] ==> #598000     Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 8.591    Value Loss: 5.241    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 166015     Buffer Size: 15346      Transition Number: 1000.013k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:46:57,233][train][INFO][train.py>_log] ==> #600000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 8.140    Value Loss: 5.707    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 166463     Buffer Size: 15328      Transition Number: 1000.018k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:52:43,458][train][INFO][train.py>_log] ==> #602000     Total Loss: 2.350    [weighted Loss:2.350    Policy Loss: 8.800    Value Loss: 4.623    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 166930     Buffer Size: 15274      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-28 00:58:29,029][train][INFO][train.py>_log] ==> #604000     Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 7.809    Value Loss: 4.846    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 167390     Buffer Size: 15220      Transition Number: 999.951 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:04:15,632][train][INFO][train.py>_log] ==> #606000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 8.147    Value Loss: 5.513    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 167828     Buffer Size: 15192      Transition Number: 999.985 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:10:07,546][train][INFO][train.py>_log] ==> #608000     Total Loss: 1.757    [weighted Loss:1.757    Policy Loss: 8.175    Value Loss: 4.928    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 168299     Buffer Size: 15158      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:15:51,008][train][INFO][train.py>_log] ==> #610000     Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 7.903    Value Loss: 4.896    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 168765     Buffer Size: 15095      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:21:44,337][train][INFO][train.py>_log] ==> #612000     Total Loss: 1.429    [weighted Loss:1.429    Policy Loss: 7.758    Value Loss: 5.207    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 169225     Buffer Size: 15031      Transition Number: 999.922 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:27:35,135][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 8.329    Value Loss: 4.920    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 169684     Buffer Size: 15016      Transition Number: 1000.044k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:33:27,233][train][INFO][train.py>_log] ==> #616000     Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 8.003    Value Loss: 5.127    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 170164     Buffer Size: 15029      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:39:12,614][train][INFO][train.py>_log] ==> #618000     Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 7.587    Value Loss: 5.419    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 170626     Buffer Size: 15039      Transition Number: 999.925 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:44:56,432][train][INFO][train.py>_log] ==> #620000     Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 7.666    Value Loss: 4.860    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 171073     Buffer Size: 15025      Transition Number: 999.942 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:50:49,713][train][INFO][train.py>_log] ==> #622000     Total Loss: 1.073    [weighted Loss:1.073    Policy Loss: 7.902    Value Loss: 5.197    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 171533     Buffer Size: 15017      Transition Number: 999.946 k Batch Size: 256        Lr: 0.010   
[2021-11-28 01:56:40,248][train][INFO][train.py>_log] ==> #624000     Total Loss: 1.768    [weighted Loss:1.768    Policy Loss: 7.524    Value Loss: 5.315    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 172012     Buffer Size: 14978      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:02:32,599][train][INFO][train.py>_log] ==> #626000     Total Loss: 1.385    [weighted Loss:1.385    Policy Loss: 7.419    Value Loss: 4.714    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 172471     Buffer Size: 14967      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:08:26,794][train][INFO][train.py>_log] ==> #628000     Total Loss: 1.319    [weighted Loss:1.319    Policy Loss: 8.424    Value Loss: 5.204    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 172947     Buffer Size: 14973      Transition Number: 999.980 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:14:21,540][train][INFO][train.py>_log] ==> #630000     Total Loss: 2.053    [weighted Loss:2.053    Policy Loss: 6.703    Value Loss: 4.740    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 173419     Buffer Size: 14893      Transition Number: 999.943 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:20:13,676][train][INFO][train.py>_log] ==> #632000     Total Loss: 1.142    [weighted Loss:1.142    Policy Loss: 7.750    Value Loss: 4.975    Reward Loss: 0.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 173889     Buffer Size: 14781      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:26:02,893][train][INFO][train.py>_log] ==> #634000     Total Loss: 0.979    [weighted Loss:0.979    Policy Loss: 7.294    Value Loss: 4.902    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 174346     Buffer Size: 14711      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:31:54,720][train][INFO][train.py>_log] ==> #636000     Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 7.227    Value Loss: 4.929    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 174816     Buffer Size: 14667      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:37:47,208][train][INFO][train.py>_log] ==> #638000     Total Loss: 1.745    [weighted Loss:1.745    Policy Loss: 7.997    Value Loss: 4.912    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 175290     Buffer Size: 14696      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:43:37,248][train][INFO][train.py>_log] ==> #640000     Total Loss: 0.692    [weighted Loss:0.692    Policy Loss: 8.302    Value Loss: 4.939    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 175776     Buffer Size: 14735      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:49:26,093][train][INFO][train.py>_log] ==> #642000     Total Loss: 1.527    [weighted Loss:1.527    Policy Loss: 7.522    Value Loss: 4.610    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 176248     Buffer Size: 14775      Transition Number: 999.933 k Batch Size: 256        Lr: 0.010   
[2021-11-28 02:55:17,660][train][INFO][train.py>_log] ==> #644000     Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 7.314    Value Loss: 5.128    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 176716     Buffer Size: 14782      Transition Number: 999.948 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:01:08,817][train][INFO][train.py>_log] ==> #646000     Total Loss: 1.450    [weighted Loss:1.450    Policy Loss: 7.228    Value Loss: 4.676    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 177183     Buffer Size: 14782      Transition Number: 999.985 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:06:59,068][train][INFO][train.py>_log] ==> #648000     Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 7.845    Value Loss: 5.365    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 177647     Buffer Size: 14766      Transition Number: 999.968 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:12:52,728][train][INFO][train.py>_log] ==> #650000     Total Loss: 1.836    [weighted Loss:1.836    Policy Loss: 7.646    Value Loss: 5.000    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 178111     Buffer Size: 14766      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:18:46,675][train][INFO][train.py>_log] ==> #652000     Total Loss: 0.847    [weighted Loss:0.847    Policy Loss: 7.469    Value Loss: 4.641    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 178590     Buffer Size: 14767      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:24:37,218][train][INFO][train.py>_log] ==> #654000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 6.767    Value Loss: 4.896    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 179055     Buffer Size: 14769      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:30:27,368][train][INFO][train.py>_log] ==> #656000     Total Loss: 1.492    [weighted Loss:1.492    Policy Loss: 6.603    Value Loss: 4.982    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 179528     Buffer Size: 14756      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:36:20,820][train][INFO][train.py>_log] ==> #658000     Total Loss: 0.784    [weighted Loss:0.784    Policy Loss: 6.736    Value Loss: 4.765    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 179998     Buffer Size: 14768      Transition Number: 1000.241k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:42:13,944][train][INFO][train.py>_log] ==> #660000     Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 7.287    Value Loss: 5.068    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 180470     Buffer Size: 14783      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:47:58,937][train][INFO][train.py>_log] ==> #662000     Total Loss: 1.385    [weighted Loss:1.385    Policy Loss: 6.928    Value Loss: 4.747    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 180932     Buffer Size: 14796      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:53:46,937][train][INFO][train.py>_log] ==> #664000     Total Loss: 0.913    [weighted Loss:0.913    Policy Loss: 6.330    Value Loss: 4.758    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 181413     Buffer Size: 14818      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-11-28 03:59:34,995][train][INFO][train.py>_log] ==> #666000     Total Loss: 1.602    [weighted Loss:1.602    Policy Loss: 6.959    Value Loss: 4.765    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 181876     Buffer Size: 14838      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:05:21,009][train][INFO][train.py>_log] ==> #668000     Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 7.366    Value Loss: 4.922    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 182335     Buffer Size: 14845      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:11:11,839][train][INFO][train.py>_log] ==> #670000     Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 7.282    Value Loss: 4.784    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 182794     Buffer Size: 14853      Transition Number: 999.968 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:16:56,307][train][INFO][train.py>_log] ==> #672000     Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 7.373    Value Loss: 4.912    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 183273     Buffer Size: 14860      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:22:46,081][train][INFO][train.py>_log] ==> #674000     Total Loss: 0.654    [weighted Loss:0.654    Policy Loss: 7.126    Value Loss: 4.569    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 183728     Buffer Size: 14865      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:28:29,399][train][INFO][train.py>_log] ==> #676000     Total Loss: 1.263    [weighted Loss:1.263    Policy Loss: 6.862    Value Loss: 4.866    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 184197     Buffer Size: 14875      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:34:21,683][train][INFO][train.py>_log] ==> #678000     Total Loss: 0.840    [weighted Loss:0.840    Policy Loss: 6.959    Value Loss: 4.592    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 184663     Buffer Size: 14892      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:40:11,707][train][INFO][train.py>_log] ==> #680000     Total Loss: 1.137    [weighted Loss:1.137    Policy Loss: 6.886    Value Loss: 4.922    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 185146     Buffer Size: 14904      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:45:57,893][train][INFO][train.py>_log] ==> #682000     Total Loss: 0.769    [weighted Loss:0.769    Policy Loss: 7.875    Value Loss: 4.809    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 185626     Buffer Size: 14916      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:51:46,112][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 8.475    Value Loss: 4.757    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 186094     Buffer Size: 14939      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-11-28 04:57:37,892][train][INFO][train.py>_log] ==> #686000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 7.804    Value Loss: 4.650    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 186557     Buffer Size: 14961      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:03:27,669][train][INFO][train.py>_log] ==> #688000     Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 7.225    Value Loss: 4.689    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 187030     Buffer Size: 14981      Transition Number: 999.937 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:09:18,646][train][INFO][train.py>_log] ==> #690000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 6.479    Value Loss: 4.966    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 187496     Buffer Size: 14984      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:15:04,264][train][INFO][train.py>_log] ==> #692000     Total Loss: 1.117    [weighted Loss:1.117    Policy Loss: 7.021    Value Loss: 4.701    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 187975     Buffer Size: 14995      Transition Number: 999.971 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:20:52,679][train][INFO][train.py>_log] ==> #694000     Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 7.282    Value Loss: 4.474    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 188452     Buffer Size: 14994      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:26:41,078][train][INFO][train.py>_log] ==> #696000     Total Loss: 1.418    [weighted Loss:1.418    Policy Loss: 7.973    Value Loss: 4.848    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 188915     Buffer Size: 15032      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:32:27,475][train][INFO][train.py>_log] ==> #698000     Total Loss: 0.957    [weighted Loss:0.957    Policy Loss: 8.234    Value Loss: 4.738    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 189366     Buffer Size: 15057      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:38:11,597][train][INFO][train.py>_log] ==> #700000     Total Loss: 1.555    [weighted Loss:1.555    Policy Loss: 7.718    Value Loss: 4.670    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 189835     Buffer Size: 15088      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:43:58,419][train][INFO][train.py>_log] ==> #702000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 8.252    Value Loss: 4.883    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 190292     Buffer Size: 15073      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:49:44,625][train][INFO][train.py>_log] ==> #704000     Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 8.403    Value Loss: 4.997    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 190931     Buffer Size: 15275      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-11-28 05:55:29,873][train][INFO][train.py>_log] ==> #706000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 8.319    Value Loss: 4.713    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 191458     Buffer Size: 15355      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:01:14,244][train][INFO][train.py>_log] ==> #708000     Total Loss: 1.149    [weighted Loss:1.149    Policy Loss: 7.854    Value Loss: 5.091    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 191912     Buffer Size: 15362      Transition Number: 1000.009k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:07:01,970][train][INFO][train.py>_log] ==> #710000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 7.417    Value Loss: 5.182    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 192374     Buffer Size: 15359      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:12:46,701][train][INFO][train.py>_log] ==> #712000     Total Loss: 0.816    [weighted Loss:0.816    Policy Loss: 7.114    Value Loss: 4.448    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 192852     Buffer Size: 15375      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:18:29,894][train][INFO][train.py>_log] ==> #714000     Total Loss: 0.798    [weighted Loss:0.798    Policy Loss: 7.495    Value Loss: 4.663    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 193302     Buffer Size: 15384      Transition Number: 999.948 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:24:19,918][train][INFO][train.py>_log] ==> #716000     Total Loss: 1.623    [weighted Loss:1.623    Policy Loss: 7.325    Value Loss: 4.810    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 193780     Buffer Size: 15397      Transition Number: 999.974 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:30:08,213][train][INFO][train.py>_log] ==> #718000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 7.715    Value Loss: 4.968    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 194251     Buffer Size: 15411      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:35:53,165][train][INFO][train.py>_log] ==> #720000     Total Loss: 0.834    [weighted Loss:0.834    Policy Loss: 7.561    Value Loss: 4.846    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 194706     Buffer Size: 15423      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:41:37,742][train][INFO][train.py>_log] ==> #722000     Total Loss: 0.857    [weighted Loss:0.857    Policy Loss: 7.868    Value Loss: 4.726    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 195164     Buffer Size: 15429      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:47:27,247][train][INFO][train.py>_log] ==> #724000     Total Loss: 0.685    [weighted Loss:0.685    Policy Loss: 7.478    Value Loss: 5.047    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 195649     Buffer Size: 15435      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:53:17,614][train][INFO][train.py>_log] ==> #726000     Total Loss: 0.938    [weighted Loss:0.938    Policy Loss: 7.313    Value Loss: 4.648    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 196118     Buffer Size: 15442      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-11-28 06:59:07,686][train][INFO][train.py>_log] ==> #728000     Total Loss: 0.593    [weighted Loss:0.593    Policy Loss: 7.670    Value Loss: 4.525    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 196591     Buffer Size: 15457      Transition Number: 999.982 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:04:56,812][train][INFO][train.py>_log] ==> #730000     Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 7.767    Value Loss: 4.828    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 197054     Buffer Size: 15461      Transition Number: 1000.137k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:10:36,745][train][INFO][train.py>_log] ==> #732000     Total Loss: 1.217    [weighted Loss:1.217    Policy Loss: 7.336    Value Loss: 5.014    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 197509     Buffer Size: 15468      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:16:16,753][train][INFO][train.py>_log] ==> #734000     Total Loss: 1.360    [weighted Loss:1.360    Policy Loss: 7.733    Value Loss: 5.003    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 197972     Buffer Size: 15472      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:22:01,000][train][INFO][train.py>_log] ==> #736000     Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 8.003    Value Loss: 5.030    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 198435     Buffer Size: 15484      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:27:49,649][train][INFO][train.py>_log] ==> #738000     Total Loss: 1.010    [weighted Loss:1.010    Policy Loss: 7.249    Value Loss: 4.664    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 198902     Buffer Size: 15500      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:33:36,438][train][INFO][train.py>_log] ==> #740000     Total Loss: 0.969    [weighted Loss:0.969    Policy Loss: 6.609    Value Loss: 4.630    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 199369     Buffer Size: 15499      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:39:28,310][train][INFO][train.py>_log] ==> #742000     Total Loss: 1.536    [weighted Loss:1.536    Policy Loss: 7.134    Value Loss: 4.793    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 199849     Buffer Size: 15476      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:45:12,769][train][INFO][train.py>_log] ==> #744000     Total Loss: 0.576    [weighted Loss:0.576    Policy Loss: 7.740    Value Loss: 4.744    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 200312     Buffer Size: 15443      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:50:57,039][train][INFO][train.py>_log] ==> #746000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 7.284    Value Loss: 5.202    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 200773     Buffer Size: 15415      Transition Number: 999.985 k Batch Size: 256        Lr: 0.010   
[2021-11-28 07:56:48,426][train][INFO][train.py>_log] ==> #748000     Total Loss: 1.671    [weighted Loss:1.671    Policy Loss: 6.982    Value Loss: 4.823    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 201245     Buffer Size: 15394      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:02:37,597][train][INFO][train.py>_log] ==> #750000     Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 7.279    Value Loss: 4.945    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 201717     Buffer Size: 15374      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:08:24,525][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.130    [weighted Loss:1.130    Policy Loss: 7.984    Value Loss: 4.900    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 202194     Buffer Size: 15341      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:14:13,803][train][INFO][train.py>_log] ==> #754000     Total Loss: 1.230    [weighted Loss:1.230    Policy Loss: 7.403    Value Loss: 4.756    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 202665     Buffer Size: 15324      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:20:01,553][train][INFO][train.py>_log] ==> #756000     Total Loss: 1.011    [weighted Loss:1.011    Policy Loss: 7.126    Value Loss: 4.579    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 203119     Buffer Size: 15292      Transition Number: 1000.034k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:25:48,796][train][INFO][train.py>_log] ==> #758000     Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 7.430    Value Loss: 5.207    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 203586     Buffer Size: 15270      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:31:34,091][train][INFO][train.py>_log] ==> #760000     Total Loss: 1.363    [weighted Loss:1.363    Policy Loss: 7.305    Value Loss: 4.938    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 204053     Buffer Size: 15226      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:37:22,842][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 7.186    Value Loss: 4.634    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 204532     Buffer Size: 15188      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:43:13,779][train][INFO][train.py>_log] ==> #764000     Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 7.187    Value Loss: 5.164    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 205010     Buffer Size: 15155      Transition Number: 1000.082k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:49:06,324][train][INFO][train.py>_log] ==> #766000     Total Loss: 1.384    [weighted Loss:1.384    Policy Loss: 7.064    Value Loss: 4.619    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 205489     Buffer Size: 15115      Transition Number: 1000.051k Batch Size: 256        Lr: 0.010   
[2021-11-28 08:54:56,296][train][INFO][train.py>_log] ==> #768000     Total Loss: 1.396    [weighted Loss:1.396    Policy Loss: 7.233    Value Loss: 4.771    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 205959     Buffer Size: 14869      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:00:44,647][train][INFO][train.py>_log] ==> #770000     Total Loss: 0.599    [weighted Loss:0.599    Policy Loss: 6.756    Value Loss: 4.766    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 206415     Buffer Size: 14769      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:06:37,576][train][INFO][train.py>_log] ==> #772000     Total Loss: 1.053    [weighted Loss:1.053    Policy Loss: 6.717    Value Loss: 4.957    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 206885     Buffer Size: 14733      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:12:29,595][train][INFO][train.py>_log] ==> #774000     Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 6.985    Value Loss: 5.150    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 207365     Buffer Size: 14713      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:18:20,668][train][INFO][train.py>_log] ==> #776000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 7.245    Value Loss: 4.793    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 207840     Buffer Size: 14689      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:24:09,957][train][INFO][train.py>_log] ==> #778000     Total Loss: 0.949    [weighted Loss:0.949    Policy Loss: 7.141    Value Loss: 5.115    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 208308     Buffer Size: 14664      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:29:57,445][train][INFO][train.py>_log] ==> #780000     Total Loss: 0.980    [weighted Loss:0.980    Policy Loss: 7.011    Value Loss: 4.652    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 208789     Buffer Size: 14632      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:35:51,298][train][INFO][train.py>_log] ==> #782000     Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 7.128    Value Loss: 4.875    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 209253     Buffer Size: 14613      Transition Number: 1000.047k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:41:42,851][train][INFO][train.py>_log] ==> #784000     Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 7.050    Value Loss: 4.677    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 209727     Buffer Size: 14602      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:47:35,712][train][INFO][train.py>_log] ==> #786000     Total Loss: 0.505    [weighted Loss:0.505    Policy Loss: 7.727    Value Loss: 5.046    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 210206     Buffer Size: 14583      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:53:33,313][train][INFO][train.py>_log] ==> #788000     Total Loss: 0.321    [weighted Loss:0.321    Policy Loss: 7.469    Value Loss: 4.649    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 210683     Buffer Size: 14566      Transition Number: 1000.059k Batch Size: 256        Lr: 0.010   
[2021-11-28 09:59:26,352][train][INFO][train.py>_log] ==> #790000     Total Loss: 0.916    [weighted Loss:0.916    Policy Loss: 6.966    Value Loss: 4.674    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 211147     Buffer Size: 14540      Transition Number: 1000.132k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:05:18,111][train][INFO][train.py>_log] ==> #792000     Total Loss: 1.092    [weighted Loss:1.092    Policy Loss: 7.830    Value Loss: 4.935    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 211634     Buffer Size: 14526      Transition Number: 1000.110k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:11:09,632][train][INFO][train.py>_log] ==> #794000     Total Loss: 1.221    [weighted Loss:1.221    Policy Loss: 7.940    Value Loss: 4.994    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 212112     Buffer Size: 14515      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:16:59,998][train][INFO][train.py>_log] ==> #796000     Total Loss: 0.934    [weighted Loss:0.934    Policy Loss: 7.433    Value Loss: 5.159    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 212593     Buffer Size: 14499      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:22:51,679][train][INFO][train.py>_log] ==> #798000     Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 8.053    Value Loss: 4.896    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 213054     Buffer Size: 14458      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:28:38,290][train][INFO][train.py>_log] ==> #800000     Total Loss: 1.391    [weighted Loss:1.391    Policy Loss: 7.846    Value Loss: 4.585    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 213524     Buffer Size: 14429      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:34:28,524][train][INFO][train.py>_log] ==> #802000     Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 7.647    Value Loss: 5.137    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 213992     Buffer Size: 14418      Transition Number: 999.928 k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:40:18,739][train][INFO][train.py>_log] ==> #804000     Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 7.447    Value Loss: 5.210    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 214475     Buffer Size: 14428      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:46:12,363][train][INFO][train.py>_log] ==> #806000     Total Loss: 0.843    [weighted Loss:0.843    Policy Loss: 7.924    Value Loss: 5.008    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 214946     Buffer Size: 14426      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:52:07,541][train][INFO][train.py>_log] ==> #808000     Total Loss: 1.159    [weighted Loss:1.159    Policy Loss: 7.832    Value Loss: 5.130    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 215438     Buffer Size: 14415      Transition Number: 1000.114k Batch Size: 256        Lr: 0.010   
[2021-11-28 10:58:02,198][train][INFO][train.py>_log] ==> #810000     Total Loss: 1.457    [weighted Loss:1.457    Policy Loss: 7.833    Value Loss: 4.974    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 215906     Buffer Size: 14396      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:03:55,091][train][INFO][train.py>_log] ==> #812000     Total Loss: 1.462    [weighted Loss:1.462    Policy Loss: 7.160    Value Loss: 4.424    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 216385     Buffer Size: 14391      Transition Number: 999.928 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:09:46,119][train][INFO][train.py>_log] ==> #814000     Total Loss: 1.423    [weighted Loss:1.423    Policy Loss: 7.311    Value Loss: 4.725    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 216853     Buffer Size: 14395      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:15:38,216][train][INFO][train.py>_log] ==> #816000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 8.042    Value Loss: 4.825    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 217335     Buffer Size: 14393      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:21:32,665][train][INFO][train.py>_log] ==> #818000     Total Loss: 1.028    [weighted Loss:1.028    Policy Loss: 8.242    Value Loss: 5.350    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 217814     Buffer Size: 14395      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:27:27,512][train][INFO][train.py>_log] ==> #820000     Total Loss: 0.815    [weighted Loss:0.815    Policy Loss: 7.062    Value Loss: 4.826    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 218288     Buffer Size: 14394      Transition Number: 999.946 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:33:20,725][train][INFO][train.py>_log] ==> #822000     Total Loss: 0.630    [weighted Loss:0.630    Policy Loss: 7.494    Value Loss: 4.916    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 218768     Buffer Size: 14391      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:39:13,645][train][INFO][train.py>_log] ==> #824000     Total Loss: 0.969    [weighted Loss:0.969    Policy Loss: 7.298    Value Loss: 4.830    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 219257     Buffer Size: 14386      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:45:03,421][train][INFO][train.py>_log] ==> #826000     Total Loss: 0.869    [weighted Loss:0.869    Policy Loss: 7.426    Value Loss: 5.084    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 219731     Buffer Size: 14391      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:50:56,495][train][INFO][train.py>_log] ==> #828000     Total Loss: 0.805    [weighted Loss:0.805    Policy Loss: 7.253    Value Loss: 4.810    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 220215     Buffer Size: 14387      Transition Number: 999.943 k Batch Size: 256        Lr: 0.010   
[2021-11-28 11:56:46,309][train][INFO][train.py>_log] ==> #830000     Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 7.319    Value Loss: 4.991    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 220680     Buffer Size: 14364      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:02:34,601][train][INFO][train.py>_log] ==> #832000     Total Loss: 0.854    [weighted Loss:0.854    Policy Loss: 6.931    Value Loss: 4.688    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 221161     Buffer Size: 14351      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:08:23,509][train][INFO][train.py>_log] ==> #834000     Total Loss: 0.929    [weighted Loss:0.929    Policy Loss: 6.782    Value Loss: 4.608    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 221616     Buffer Size: 14334      Transition Number: 999.933 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:14:11,719][train][INFO][train.py>_log] ==> #836000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 7.022    Value Loss: 5.054    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 222093     Buffer Size: 14321      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:20:02,465][train][INFO][train.py>_log] ==> #838000     Total Loss: 1.145    [weighted Loss:1.145    Policy Loss: 7.171    Value Loss: 4.631    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 222563     Buffer Size: 14322      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:25:55,780][train][INFO][train.py>_log] ==> #840000     Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 7.453    Value Loss: 4.498    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 223048     Buffer Size: 14320      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:31:51,291][train][INFO][train.py>_log] ==> #842000     Total Loss: 1.323    [weighted Loss:1.323    Policy Loss: 7.091    Value Loss: 4.710    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 223526     Buffer Size: 14319      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:37:42,583][train][INFO][train.py>_log] ==> #844000     Total Loss: 0.628    [weighted Loss:0.628    Policy Loss: 7.330    Value Loss: 5.365    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 224007     Buffer Size: 14309      Transition Number: 1000.029k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:43:33,727][train][INFO][train.py>_log] ==> #846000     Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 6.804    Value Loss: 4.795    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 224474     Buffer Size: 14296      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:49:31,159][train][INFO][train.py>_log] ==> #848000     Total Loss: 0.727    [weighted Loss:0.727    Policy Loss: 6.942    Value Loss: 5.365    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 224960     Buffer Size: 14278      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-11-28 12:55:21,958][train][INFO][train.py>_log] ==> #850000     Total Loss: 1.103    [weighted Loss:1.103    Policy Loss: 6.412    Value Loss: 4.761    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 225434     Buffer Size: 14254      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:01:14,369][train][INFO][train.py>_log] ==> #852000     Total Loss: 0.650    [weighted Loss:0.650    Policy Loss: 7.597    Value Loss: 4.685    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 225922     Buffer Size: 14221      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:07:01,049][train][INFO][train.py>_log] ==> #854000     Total Loss: 0.418    [weighted Loss:0.418    Policy Loss: 6.831    Value Loss: 4.654    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 226379     Buffer Size: 14198      Transition Number: 999.937 k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:12:50,886][train][INFO][train.py>_log] ==> #856000     Total Loss: 0.878    [weighted Loss:0.878    Policy Loss: 7.096    Value Loss: 4.663    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 226863     Buffer Size: 14195      Transition Number: 1000.214k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:18:43,932][train][INFO][train.py>_log] ==> #858000     Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 6.879    Value Loss: 4.678    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 227335     Buffer Size: 14184      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:24:37,618][train][INFO][train.py>_log] ==> #860000     Total Loss: 0.891    [weighted Loss:0.891    Policy Loss: 7.494    Value Loss: 5.104    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 227820     Buffer Size: 14181      Transition Number: 999.929 k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:30:28,757][train][INFO][train.py>_log] ==> #862000     Total Loss: 1.098    [weighted Loss:1.098    Policy Loss: 6.865    Value Loss: 5.247    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 228294     Buffer Size: 14189      Transition Number: 1000.031k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:36:16,666][train][INFO][train.py>_log] ==> #864000     Total Loss: 1.223    [weighted Loss:1.223    Policy Loss: 7.488    Value Loss: 4.965    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 228748     Buffer Size: 14181      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:42:05,026][train][INFO][train.py>_log] ==> #866000     Total Loss: 0.501    [weighted Loss:0.501    Policy Loss: 7.244    Value Loss: 4.492    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 229217     Buffer Size: 14179      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:48:02,752][train][INFO][train.py>_log] ==> #868000     Total Loss: 1.170    [weighted Loss:1.170    Policy Loss: 7.545    Value Loss: 5.128    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 229703     Buffer Size: 14191      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:53:56,357][train][INFO][train.py>_log] ==> #870000     Total Loss: 0.596    [weighted Loss:0.596    Policy Loss: 7.519    Value Loss: 4.692    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 230182     Buffer Size: 14195      Transition Number: 1000.053k Batch Size: 256        Lr: 0.010   
[2021-11-28 13:59:47,124][train][INFO][train.py>_log] ==> #872000     Total Loss: 0.724    [weighted Loss:0.724    Policy Loss: 7.222    Value Loss: 5.023    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 230668     Buffer Size: 14202      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:05:39,894][train][INFO][train.py>_log] ==> #874000     Total Loss: 0.871    [weighted Loss:0.871    Policy Loss: 6.863    Value Loss: 5.100    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 231138     Buffer Size: 14201      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:11:34,061][train][INFO][train.py>_log] ==> #876000     Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 6.483    Value Loss: 4.645    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 231622     Buffer Size: 14200      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:17:30,908][train][INFO][train.py>_log] ==> #878000     Total Loss: 0.581    [weighted Loss:0.581    Policy Loss: 6.752    Value Loss: 4.972    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 232115     Buffer Size: 14215      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:23:25,423][train][INFO][train.py>_log] ==> #880000     Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 7.008    Value Loss: 4.511    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 232594     Buffer Size: 14214      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:29:18,425][train][INFO][train.py>_log] ==> #882000     Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 7.151    Value Loss: 4.667    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 233070     Buffer Size: 14213      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:35:15,081][train][INFO][train.py>_log] ==> #884000     Total Loss: 1.352    [weighted Loss:1.352    Policy Loss: 7.237    Value Loss: 4.133    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 233563     Buffer Size: 14207      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:41:05,898][train][INFO][train.py>_log] ==> #886000     Total Loss: 1.353    [weighted Loss:1.353    Policy Loss: 7.755    Value Loss: 4.630    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 234036     Buffer Size: 14196      Transition Number: 1000.105k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:46:57,344][train][INFO][train.py>_log] ==> #888000     Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 7.263    Value Loss: 4.766    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 234513     Buffer Size: 14193      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:52:51,390][train][INFO][train.py>_log] ==> #890000     Total Loss: 0.809    [weighted Loss:0.809    Policy Loss: 6.877    Value Loss: 4.803    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 234991     Buffer Size: 14213      Transition Number: 1000.138k Batch Size: 256        Lr: 0.010   
[2021-11-28 14:58:44,937][train][INFO][train.py>_log] ==> #892000     Total Loss: 1.009    [weighted Loss:1.009    Policy Loss: 7.684    Value Loss: 4.663    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 235466     Buffer Size: 14226      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:04:40,503][train][INFO][train.py>_log] ==> #894000     Total Loss: 1.338    [weighted Loss:1.338    Policy Loss: 7.003    Value Loss: 4.726    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 235934     Buffer Size: 14233      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:10:28,211][train][INFO][train.py>_log] ==> #896000     Total Loss: 0.913    [weighted Loss:0.913    Policy Loss: 7.527    Value Loss: 4.640    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 236424     Buffer Size: 14278      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:16:23,080][train][INFO][train.py>_log] ==> #898000     Total Loss: 1.239    [weighted Loss:1.239    Policy Loss: 7.135    Value Loss: 4.886    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 236933     Buffer Size: 14342      Transition Number: 1000.014k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:22:08,586][train][INFO][train.py>_log] ==> #900000     Total Loss: 1.102    [weighted Loss:1.102    Policy Loss: 7.615    Value Loss: 5.029    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 237424     Buffer Size: 14383      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:28:01,489][train][INFO][train.py>_log] ==> #902000     Total Loss: 0.522    [weighted Loss:0.522    Policy Loss: 7.076    Value Loss: 4.896    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 237899     Buffer Size: 14399      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:33:54,393][train][INFO][train.py>_log] ==> #904000     Total Loss: 1.384    [weighted Loss:1.384    Policy Loss: 7.453    Value Loss: 4.862    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 238382     Buffer Size: 14414      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:39:47,322][train][INFO][train.py>_log] ==> #906000     Total Loss: 1.693    [weighted Loss:1.693    Policy Loss: 7.187    Value Loss: 5.022    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 238860     Buffer Size: 14427      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:45:42,550][train][INFO][train.py>_log] ==> #908000     Total Loss: 0.692    [weighted Loss:0.692    Policy Loss: 7.357    Value Loss: 5.019    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 239345     Buffer Size: 14444      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:51:35,681][train][INFO][train.py>_log] ==> #910000     Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 7.510    Value Loss: 4.752    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 239820     Buffer Size: 14460      Transition Number: 1000.048k Batch Size: 256        Lr: 0.010   
[2021-11-28 15:57:29,891][train][INFO][train.py>_log] ==> #912000     Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 7.470    Value Loss: 5.194    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 240303     Buffer Size: 14483      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:03:24,422][train][INFO][train.py>_log] ==> #914000     Total Loss: 1.289    [weighted Loss:1.289    Policy Loss: 7.626    Value Loss: 4.650    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 240781     Buffer Size: 14506      Transition Number: 1000.085k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:09:15,684][train][INFO][train.py>_log] ==> #916000     Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 7.155    Value Loss: 4.921    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 241248     Buffer Size: 14518      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:15:04,345][train][INFO][train.py>_log] ==> #918000     Total Loss: 0.891    [weighted Loss:0.891    Policy Loss: 7.177    Value Loss: 4.872    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 241706     Buffer Size: 14543      Transition Number: 1000.056k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:20:55,428][train][INFO][train.py>_log] ==> #920000     Total Loss: 1.204    [weighted Loss:1.204    Policy Loss: 6.888    Value Loss: 4.981    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 242192     Buffer Size: 14565      Transition Number: 1000.035k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:26:46,043][train][INFO][train.py>_log] ==> #922000     Total Loss: 0.891    [weighted Loss:0.891    Policy Loss: 7.248    Value Loss: 4.712    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 242661     Buffer Size: 14562      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:32:35,590][train][INFO][train.py>_log] ==> #924000     Total Loss: 0.802    [weighted Loss:0.802    Policy Loss: 7.182    Value Loss: 4.493    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 243140     Buffer Size: 14565      Transition Number: 1000.022k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:38:26,173][train][INFO][train.py>_log] ==> #926000     Total Loss: 0.966    [weighted Loss:0.966    Policy Loss: 7.834    Value Loss: 4.972    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 243620     Buffer Size: 14554      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:44:17,919][train][INFO][train.py>_log] ==> #928000     Total Loss: 1.294    [weighted Loss:1.294    Policy Loss: 7.397    Value Loss: 4.604    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 244102     Buffer Size: 14547      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:50:10,190][train][INFO][train.py>_log] ==> #930000     Total Loss: 0.676    [weighted Loss:0.676    Policy Loss: 8.783    Value Loss: 4.797    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 244582     Buffer Size: 14548      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-28 16:55:59,708][train][INFO][train.py>_log] ==> #932000     Total Loss: 1.004    [weighted Loss:1.004    Policy Loss: 8.422    Value Loss: 5.062    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 245289     Buffer Size: 14824      Transition Number: 1000.008k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:01:49,835][train][INFO][train.py>_log] ==> #934000     Total Loss: 1.098    [weighted Loss:1.098    Policy Loss: 7.751    Value Loss: 5.101    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 245878     Buffer Size: 14999      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:07:40,820][train][INFO][train.py>_log] ==> #936000     Total Loss: 1.175    [weighted Loss:1.175    Policy Loss: 7.673    Value Loss: 5.210    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 246350     Buffer Size: 15035      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:13:31,986][train][INFO][train.py>_log] ==> #938000     Total Loss: 0.933    [weighted Loss:0.933    Policy Loss: 8.017    Value Loss: 5.206    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 246811     Buffer Size: 15039      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:19:26,885][train][INFO][train.py>_log] ==> #940000     Total Loss: 0.458    [weighted Loss:0.458    Policy Loss: 7.340    Value Loss: 4.861    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 247296     Buffer Size: 15031      Transition Number: 999.949 k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:25:20,299][train][INFO][train.py>_log] ==> #942000     Total Loss: 1.253    [weighted Loss:1.253    Policy Loss: 7.639    Value Loss: 5.109    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 247774     Buffer Size: 15034      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:31:13,211][train][INFO][train.py>_log] ==> #944000     Total Loss: 0.488    [weighted Loss:0.488    Policy Loss: 8.094    Value Loss: 5.144    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 248257     Buffer Size: 15035      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:37:05,932][train][INFO][train.py>_log] ==> #946000     Total Loss: 1.142    [weighted Loss:1.142    Policy Loss: 8.117    Value Loss: 5.005    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 248730     Buffer Size: 15053      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:42:56,664][train][INFO][train.py>_log] ==> #948000     Total Loss: 0.470    [weighted Loss:0.470    Policy Loss: 7.177    Value Loss: 4.937    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 249219     Buffer Size: 15070      Transition Number: 999.925 k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:48:52,881][train][INFO][train.py>_log] ==> #950000     Total Loss: 0.756    [weighted Loss:0.756    Policy Loss: 7.323    Value Loss: 4.930    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 249702     Buffer Size: 15082      Transition Number: 999.942 k Batch Size: 256        Lr: 0.010   
[2021-11-28 17:54:48,781][train][INFO][train.py>_log] ==> #952000     Total Loss: 0.695    [weighted Loss:0.695    Policy Loss: 7.850    Value Loss: 5.340    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 250184     Buffer Size: 15097      Transition Number: 1000.059k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:00:43,666][train][INFO][train.py>_log] ==> #954000     Total Loss: 0.931    [weighted Loss:0.931    Policy Loss: 7.521    Value Loss: 4.666    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 250659     Buffer Size: 15104      Transition Number: 999.947 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:06:27,986][train][INFO][train.py>_log] ==> #956000     Total Loss: 0.993    [weighted Loss:0.993    Policy Loss: 7.125    Value Loss: 4.836    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 251127     Buffer Size: 15118      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:12:21,732][train][INFO][train.py>_log] ==> #958000     Total Loss: 0.376    [weighted Loss:0.376    Policy Loss: 8.199    Value Loss: 4.879    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 251601     Buffer Size: 15092      Transition Number: 999.983 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:18:09,232][train][INFO][train.py>_log] ==> #960000     Total Loss: 0.446    [weighted Loss:0.446    Policy Loss: 8.100    Value Loss: 5.205    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 252073     Buffer Size: 15028      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:24:01,396][train][INFO][train.py>_log] ==> #962000     Total Loss: 1.161    [weighted Loss:1.161    Policy Loss: 7.395    Value Loss: 5.352    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 252549     Buffer Size: 14996      Transition Number: 999.946 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:29:52,717][train][INFO][train.py>_log] ==> #964000     Total Loss: 0.887    [weighted Loss:0.887    Policy Loss: 7.787    Value Loss: 4.956    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 253026     Buffer Size: 14983      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:35:38,162][train][INFO][train.py>_log] ==> #966000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 7.740    Value Loss: 4.669    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 253496     Buffer Size: 14981      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:41:27,389][train][INFO][train.py>_log] ==> #968000     Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 7.947    Value Loss: 4.687    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 253973     Buffer Size: 14990      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:47:19,504][train][INFO][train.py>_log] ==> #970000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 7.969    Value Loss: 4.746    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 254457     Buffer Size: 14996      Transition Number: 999.927 k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:53:11,254][train][INFO][train.py>_log] ==> #972000     Total Loss: 0.980    [weighted Loss:0.980    Policy Loss: 7.945    Value Loss: 5.002    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 254939     Buffer Size: 15005      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-28 18:59:07,380][train][INFO][train.py>_log] ==> #974000     Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 7.536    Value Loss: 5.116    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 255417     Buffer Size: 15002      Transition Number: 999.971 k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:04:59,251][train][INFO][train.py>_log] ==> #976000     Total Loss: 0.920    [weighted Loss:0.920    Policy Loss: 7.746    Value Loss: 4.829    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 255897     Buffer Size: 14998      Transition Number: 999.926 k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:10:53,468][train][INFO][train.py>_log] ==> #978000     Total Loss: 0.621    [weighted Loss:0.621    Policy Loss: 7.390    Value Loss: 5.122    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 256378     Buffer Size: 14990      Transition Number: 999.928 k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:16:45,718][train][INFO][train.py>_log] ==> #980000     Total Loss: 1.165    [weighted Loss:1.165    Policy Loss: 7.873    Value Loss: 4.855    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 256859     Buffer Size: 15000      Transition Number: 999.969 k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:22:37,313][train][INFO][train.py>_log] ==> #982000     Total Loss: 0.751    [weighted Loss:0.751    Policy Loss: 7.770    Value Loss: 4.796    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 257332     Buffer Size: 15003      Transition Number: 999.951 k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:28:26,551][train][INFO][train.py>_log] ==> #984000     Total Loss: 1.292    [weighted Loss:1.292    Policy Loss: 7.935    Value Loss: 4.563    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 257978     Buffer Size: 15238      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:34:15,061][train][INFO][train.py>_log] ==> #986000     Total Loss: 1.467    [weighted Loss:1.467    Policy Loss: 7.282    Value Loss: 4.829    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 258438     Buffer Size: 15259      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:40:01,819][train][INFO][train.py>_log] ==> #988000     Total Loss: 0.834    [weighted Loss:0.834    Policy Loss: 7.005    Value Loss: 4.984    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 258918     Buffer Size: 15275      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:45:46,324][train][INFO][train.py>_log] ==> #990000     Total Loss: 0.757    [weighted Loss:0.757    Policy Loss: 7.287    Value Loss: 5.304    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 259375     Buffer Size: 15294      Transition Number: 1000.044k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:51:37,298][train][INFO][train.py>_log] ==> #992000     Total Loss: 1.301    [weighted Loss:1.301    Policy Loss: 7.576    Value Loss: 4.967    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 259853     Buffer Size: 15302      Transition Number: 1000.114k Batch Size: 256        Lr: 0.010   
[2021-11-28 19:57:27,134][train][INFO][train.py>_log] ==> #994000     Total Loss: 0.844    [weighted Loss:0.844    Policy Loss: 7.632    Value Loss: 5.837    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 260316     Buffer Size: 15039      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-11-28 20:03:17,988][train][INFO][train.py>_log] ==> #996000     Total Loss: 1.066    [weighted Loss:1.066    Policy Loss: 7.524    Value Loss: 5.142    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 260795     Buffer Size: 14857      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-11-28 20:09:13,148][train][INFO][train.py>_log] ==> #998000     Total Loss: 1.026    [weighted Loss:1.026    Policy Loss: 7.867    Value Loss: 4.448    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 261269     Buffer Size: 14844      Transition Number: 999.946 k Batch Size: 256        Lr: 0.010   
[2021-11-28 20:15:06,179][train][INFO][train.py>_log] ==> #1000000    Total Loss: 1.530    [weighted Loss:1.530    Policy Loss: 7.911    Value Loss: 4.982    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 261760     Buffer Size: 14881      Transition Number: 1000.006k Batch Size: 256        Lr: 0.010   
