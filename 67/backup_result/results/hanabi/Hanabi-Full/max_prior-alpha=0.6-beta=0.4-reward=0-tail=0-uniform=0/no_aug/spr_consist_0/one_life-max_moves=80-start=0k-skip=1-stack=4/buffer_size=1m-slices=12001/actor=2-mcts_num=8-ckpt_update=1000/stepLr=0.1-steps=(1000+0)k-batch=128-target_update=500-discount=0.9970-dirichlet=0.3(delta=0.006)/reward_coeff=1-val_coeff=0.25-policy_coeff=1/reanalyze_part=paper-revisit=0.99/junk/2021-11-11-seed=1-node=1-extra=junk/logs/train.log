[2021-11-11 02:45:48,651][train][INFO][train.py>_log] ==> #0          Total Loss: 3.452    [weighted Loss:3.452    Policy Loss: 1.975    Value Loss: 3.308    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 122        Buffer Size: 122        Transition Number: 2.599   k Batch Size: 128        Lr: 0.000   
[2021-11-11 02:57:17,080][train][INFO][train.py>_log] ==> #1000       Total Loss: 1.010    [weighted Loss:1.010    Policy Loss: 0.891    Value Loss: 3.927    Reward Loss: 0.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 10920      Buffer Size: 8712       Transition Number: 399.969 k Batch Size: 128        Lr: 0.010   
[2021-11-11 03:09:57,507][train][INFO][train.py>_log] ==> #2000       Total Loss: 0.922    [weighted Loss:0.922    Policy Loss: 0.944    Value Loss: 4.213    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 23106      Buffer Size: 8684       Transition Number: 399.952 k Batch Size: 128        Lr: 0.020   
