[2021-11-10 05:07:32,743][train][INFO][train.py>_log] ==> #0          Total Loss: 43.526   [weighted Loss:43.526   Policy Loss: 13.528   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 68         Buffer Size: 68         Transition Number: 0.788   k Batch Size: 128        Lr: 0.000   
[2021-11-10 05:10:10,789][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.903    [weighted Loss:5.903    Policy Loss: 13.715   Value Loss: 4.825    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 490        Buffer Size: 490        Transition Number: 6.083   k Batch Size: 128        Lr: 0.010   
[2021-11-10 05:13:24,270][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.882    [weighted Loss:5.882    Policy Loss: 13.771   Value Loss: 3.584    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 1110       Buffer Size: 1110       Transition Number: 12.004  k Batch Size: 128        Lr: 0.020   
[2021-11-10 05:16:43,564][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.995    [weighted Loss:5.995    Policy Loss: 13.107   Value Loss: 2.894    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1759       Buffer Size: 1759       Transition Number: 18.036  k Batch Size: 128        Lr: 0.030   
[2021-11-10 05:20:07,460][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 13.182   Value Loss: 3.010    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 2395       Buffer Size: 2395       Transition Number: 24.183  k Batch Size: 128        Lr: 0.040   
[2021-11-10 05:23:28,003][train][INFO][train.py>_log] ==> #5000       Total Loss: 7.958    [weighted Loss:7.958    Policy Loss: 13.856   Value Loss: 3.260    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 3274       Buffer Size: 3274       Transition Number: 30.211  k Batch Size: 128        Lr: 0.050   
[2021-11-10 05:26:42,763][train][INFO][train.py>_log] ==> #6000       Total Loss: 7.720    [weighted Loss:7.720    Policy Loss: 14.249   Value Loss: 3.222    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 4085       Buffer Size: 4085       Transition Number: 36.015  k Batch Size: 128        Lr: 0.060   
[2021-11-10 05:30:00,183][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.496    [weighted Loss:5.496    Policy Loss: 13.510   Value Loss: 2.849    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 4611       Buffer Size: 4611       Transition Number: 41.487  k Batch Size: 128        Lr: 0.070   
[2021-11-10 05:33:23,393][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.075    [weighted Loss:5.075    Policy Loss: 13.738   Value Loss: 2.916    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 5222       Buffer Size: 5222       Transition Number: 47.530  k Batch Size: 128        Lr: 0.080   
[2021-11-10 05:36:49,375][train][INFO][train.py>_log] ==> #9000       Total Loss: 6.204    [weighted Loss:6.204    Policy Loss: 13.948   Value Loss: 3.006    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 5812       Buffer Size: 5812       Transition Number: 53.637  k Batch Size: 128        Lr: 0.090   
[2021-11-10 05:40:21,636][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.894    [weighted Loss:5.894    Policy Loss: 13.790   Value Loss: 2.809    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 6275       Buffer Size: 6275       Transition Number: 59.713  k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:43:49,907][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.621    [weighted Loss:4.621    Policy Loss: 12.847   Value Loss: 2.721    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 7014       Buffer Size: 7014       Transition Number: 66.186  k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:47:19,549][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.612    [weighted Loss:4.612    Policy Loss: 12.023   Value Loss: 2.434    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 7732       Buffer Size: 7732       Transition Number: 72.552  k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:50:48,444][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.377    [weighted Loss:5.377    Policy Loss: 12.825   Value Loss: 2.639    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 8401       Buffer Size: 8401       Transition Number: 78.848  k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:54:24,242][train][INFO][train.py>_log] ==> #14000      Total Loss: 7.397    [weighted Loss:7.397    Policy Loss: 13.456   Value Loss: 2.532    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 8880       Buffer Size: 8880       Transition Number: 85.156  k Batch Size: 128        Lr: 0.100   
[2021-11-10 05:58:03,100][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.791    [weighted Loss:5.791    Policy Loss: 13.829   Value Loss: 2.803    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 9372       Buffer Size: 9372       Transition Number: 91.504  k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:01:41,490][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.897    [weighted Loss:4.897    Policy Loss: 12.972   Value Loss: 2.908    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 9903       Buffer Size: 9903       Transition Number: 98.054  k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:05:24,780][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.880    [weighted Loss:3.880    Policy Loss: 12.109   Value Loss: 2.649    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 10456      Buffer Size: 10456      Transition Number: 104.599 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:09:11,084][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.886    [weighted Loss:3.886    Policy Loss: 13.774   Value Loss: 2.893    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 11000      Buffer Size: 11000      Transition Number: 111.272 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:12:59,816][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.246    [weighted Loss:4.246    Policy Loss: 12.876   Value Loss: 2.615    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 11488      Buffer Size: 11488      Transition Number: 117.914 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:16:49,751][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.217    [weighted Loss:5.217    Policy Loss: 12.695   Value Loss: 2.850    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 11992      Buffer Size: 11992      Transition Number: 125.059 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:20:38,374][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.495    [weighted Loss:4.495    Policy Loss: 13.256   Value Loss: 2.621    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 12526      Buffer Size: 12526      Transition Number: 131.744 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:24:32,696][train][INFO][train.py>_log] ==> #22000      Total Loss: 5.719    [weighted Loss:5.719    Policy Loss: 12.719   Value Loss: 2.682    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 13007      Buffer Size: 13007      Transition Number: 138.839 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:28:29,244][train][INFO][train.py>_log] ==> #23000      Total Loss: 5.472    [weighted Loss:5.472    Policy Loss: 13.093   Value Loss: 2.770    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 13550      Buffer Size: 13550      Transition Number: 146.053 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:32:29,781][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.793    [weighted Loss:4.793    Policy Loss: 13.250   Value Loss: 3.071    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 14131      Buffer Size: 14131      Transition Number: 153.485 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:36:26,821][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.170    [weighted Loss:5.170    Policy Loss: 13.897   Value Loss: 2.856    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 14706      Buffer Size: 14706      Transition Number: 160.307 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:40:30,552][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.032    [weighted Loss:3.032    Policy Loss: 13.029   Value Loss: 2.757    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 15135      Buffer Size: 15135      Transition Number: 167.276 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:44:52,560][train][INFO][train.py>_log] ==> #27000      Total Loss: 5.975    [weighted Loss:5.975    Policy Loss: 11.698   Value Loss: 2.831    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 15622      Buffer Size: 15622      Transition Number: 175.411 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:49:11,579][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.827    [weighted Loss:3.827    Policy Loss: 12.021   Value Loss: 2.867    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 16079      Buffer Size: 16079      Transition Number: 183.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:53:34,361][train][INFO][train.py>_log] ==> #29000      Total Loss: 6.897    [weighted Loss:6.897    Policy Loss: 12.100   Value Loss: 3.271    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 16500      Buffer Size: 16500      Transition Number: 190.511 k Batch Size: 128        Lr: 0.100   
[2021-11-10 06:57:55,872][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.484    [weighted Loss:1.484    Policy Loss: 13.537   Value Loss: 3.069    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 16882      Buffer Size: 16882      Transition Number: 197.841 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:02:30,759][train][INFO][train.py>_log] ==> #31000      Total Loss: 6.315    [weighted Loss:6.315    Policy Loss: 13.422   Value Loss: 3.066    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 17250      Buffer Size: 17250      Transition Number: 205.400 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:07:22,515][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.187    [weighted Loss:4.187    Policy Loss: 12.346   Value Loss: 3.175    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 17569      Buffer Size: 17569      Transition Number: 212.679 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:12:24,791][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.210    [weighted Loss:4.210    Policy Loss: 12.566   Value Loss: 3.072    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 17802      Buffer Size: 17802      Transition Number: 219.814 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:18:10,951][train][INFO][train.py>_log] ==> #34000      Total Loss: 6.529    [weighted Loss:6.529    Policy Loss: 12.375   Value Loss: 3.398    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 18077      Buffer Size: 18077      Transition Number: 227.945 k Batch Size: 128        Lr: 0.100   
[2021-11-10 07:24:28,157][train][INFO][train.py>_log] ==> #35000      Total Loss: 4.550    [weighted Loss:4.550    Policy Loss: 12.550   Value Loss: 3.661    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 18315      Buffer Size: 18315      Transition Number: 237.362 k Batch Size: 128        Lr: 0.100   
