[2021-11-17 09:30:46,489][train][INFO][train.py>_log] ==> #0          Total Loss: 43.023   [weighted Loss:43.023   Policy Loss: 13.025   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 89         Buffer Size: 89         Transition Number: 0.949   k Batch Size: 256        Lr: 0.000   
[2021-11-17 09:36:05,030][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.403    [weighted Loss:5.403    Policy Loss: 13.403   Value Loss: 3.574    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092       Buffer Size: 1092       Transition Number: 13.169  k Batch Size: 256        Lr: 0.020   
[2021-11-17 09:41:44,752][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.615    [weighted Loss:4.615    Policy Loss: 12.528   Value Loss: 2.810    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 2379       Buffer Size: 2379       Transition Number: 24.755  k Batch Size: 256        Lr: 0.040   
[2021-11-17 09:47:35,871][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.914    [weighted Loss:4.914    Policy Loss: 12.392   Value Loss: 2.648    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 3600       Buffer Size: 3600       Transition Number: 35.930  k Batch Size: 256        Lr: 0.060   
[2021-11-17 09:53:30,762][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.633    [weighted Loss:3.633    Policy Loss: 12.871   Value Loss: 2.601    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 4775       Buffer Size: 4775       Transition Number: 47.311  k Batch Size: 256        Lr: 0.080   
[2021-11-17 09:59:16,173][train][INFO][train.py>_log] ==> #10000      Total Loss: 6.011    [weighted Loss:6.011    Policy Loss: 13.585   Value Loss: 2.669    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 5559       Buffer Size: 5559       Transition Number: 57.480  k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:05:10,332][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.254    [weighted Loss:5.254    Policy Loss: 12.200   Value Loss: 2.626    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 6231       Buffer Size: 6231       Transition Number: 67.774  k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:11:06,970][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 12.045   Value Loss: 2.641    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 7173       Buffer Size: 7173       Transition Number: 78.381  k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:17:05,534][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 11.390   Value Loss: 2.586    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 8112       Buffer Size: 8112       Transition Number: 89.564  k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:22:58,454][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.116    [weighted Loss:4.116    Policy Loss: 11.887   Value Loss: 2.650    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 9117       Buffer Size: 9117       Transition Number: 100.076 k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:28:53,975][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.468    [weighted Loss:5.468    Policy Loss: 11.370   Value Loss: 2.509    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 10507      Buffer Size: 10507      Transition Number: 111.663 k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:34:57,991][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.442    [weighted Loss:3.442    Policy Loss: 11.209   Value Loss: 2.471    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 11981      Buffer Size: 11981      Transition Number: 123.003 k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:40:53,597][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.824    [weighted Loss:2.824    Policy Loss: 10.860   Value Loss: 2.417    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 13298      Buffer Size: 13298      Transition Number: 134.457 k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:46:53,154][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 10.405   Value Loss: 2.504    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 14419      Buffer Size: 14419      Transition Number: 145.076 k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:53:02,142][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 10.576   Value Loss: 2.657    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 15693      Buffer Size: 15693      Transition Number: 156.601 k Batch Size: 256        Lr: 0.100   
[2021-11-17 10:59:01,763][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.247    [weighted Loss:4.247    Policy Loss: 10.575   Value Loss: 2.605    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 16696      Buffer Size: 16696      Transition Number: 167.787 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:04:59,067][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.361    [weighted Loss:4.361    Policy Loss: 11.345   Value Loss: 2.562    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 17585      Buffer Size: 17585      Transition Number: 178.762 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:10:53,645][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.913    [weighted Loss:3.913    Policy Loss: 11.682   Value Loss: 2.648    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 18177      Buffer Size: 18177      Transition Number: 188.170 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:16:47,911][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 11.972   Value Loss: 2.684    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 18653      Buffer Size: 18653      Transition Number: 197.602 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:22:49,200][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.790    [weighted Loss:3.790    Policy Loss: 11.901   Value Loss: 2.725    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 19056      Buffer Size: 19056      Transition Number: 206.019 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:28:39,693][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.085    [weighted Loss:3.085    Policy Loss: 12.034   Value Loss: 2.923    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 19514      Buffer Size: 19514      Transition Number: 214.835 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:34:33,178][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 11.244   Value Loss: 3.046    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 19902      Buffer Size: 19902      Transition Number: 223.686 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:40:23,462][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.613    [weighted Loss:2.613    Policy Loss: 10.802   Value Loss: 2.962    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 20177      Buffer Size: 20177      Transition Number: 231.804 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:46:17,452][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.394    [weighted Loss:3.394    Policy Loss: 10.403   Value Loss: 3.069    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 20398      Buffer Size: 20398      Transition Number: 240.044 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:52:23,040][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 9.895    Value Loss: 3.154    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 20673      Buffer Size: 20673      Transition Number: 249.530 k Batch Size: 256        Lr: 0.100   
[2021-11-17 11:58:27,908][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 9.613    Value Loss: 3.265    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 20943      Buffer Size: 20943      Transition Number: 257.667 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:04:36,059][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.435    [weighted Loss:2.435    Policy Loss: 7.844    Value Loss: 3.006    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 21179      Buffer Size: 21179      Transition Number: 266.593 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:10:41,790][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 7.457    Value Loss: 3.243    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 21476      Buffer Size: 21476      Transition Number: 275.391 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:16:51,132][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.001    [weighted Loss:3.001    Policy Loss: 7.656    Value Loss: 3.528    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 21724      Buffer Size: 21724      Transition Number: 284.583 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:22:50,489][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.434    [weighted Loss:1.434    Policy Loss: 7.722    Value Loss: 3.584    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 21940      Buffer Size: 21940      Transition Number: 293.210 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:28:46,352][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 6.687    Value Loss: 3.433    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 22157      Buffer Size: 22157      Transition Number: 301.517 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:34:44,467][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 6.601    Value Loss: 3.499    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 22363      Buffer Size: 22363      Transition Number: 309.883 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:40:44,063][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.475    [weighted Loss:1.475    Policy Loss: 6.370    Value Loss: 3.451    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 22553      Buffer Size: 22553      Transition Number: 318.667 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:46:44,754][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 6.986    Value Loss: 3.760    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 22755      Buffer Size: 22755      Transition Number: 327.679 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:52:44,102][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.441    [weighted Loss:1.441    Policy Loss: 6.659    Value Loss: 3.408    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 22961      Buffer Size: 22961      Transition Number: 337.154 k Batch Size: 256        Lr: 0.100   
[2021-11-17 12:58:39,035][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 6.662    Value Loss: 3.687    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 23150      Buffer Size: 23150      Transition Number: 346.213 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:04:36,131][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.898    [weighted Loss:2.898    Policy Loss: 5.638    Value Loss: 3.599    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 23348      Buffer Size: 23348      Transition Number: 355.887 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:10:40,170][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.425    [weighted Loss:2.425    Policy Loss: 5.908    Value Loss: 3.636    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 23535      Buffer Size: 23535      Transition Number: 365.000 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:16:53,452][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.539    [weighted Loss:1.539    Policy Loss: 6.799    Value Loss: 3.663    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 23722      Buffer Size: 23722      Transition Number: 375.326 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:22:59,251][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 6.173    Value Loss: 3.532    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 23951      Buffer Size: 23951      Transition Number: 384.933 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:29:05,871][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.703    [weighted Loss:1.703    Policy Loss: 6.355    Value Loss: 3.581    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 24194      Buffer Size: 24194      Transition Number: 393.682 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:35:15,024][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 5.711    Value Loss: 3.659    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 24414      Buffer Size: 24232      Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:41:34,602][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.718    [weighted Loss:1.718    Policy Loss: 5.403    Value Loss: 3.686    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 24656      Buffer Size: 23603      Transition Number: 400.000 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:47:50,034][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 6.305    Value Loss: 3.762    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 24877      Buffer Size: 22850      Transition Number: 399.998 k Batch Size: 256        Lr: 0.100   
[2021-11-17 13:54:08,103][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 6.164    Value Loss: 4.078    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 25098      Buffer Size: 22010      Transition Number: 399.997 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:00:23,410][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.587    [weighted Loss:1.587    Policy Loss: 5.896    Value Loss: 4.001    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 25278      Buffer Size: 21233      Transition Number: 400.000 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:06:33,697][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 7.322    Value Loss: 4.047    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 25457      Buffer Size: 20510      Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:12:45,815][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.851    [weighted Loss:1.851    Policy Loss: 5.545    Value Loss: 4.039    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 25625      Buffer Size: 19933      Transition Number: 400.000 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:18:59,741][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 4.651    Value Loss: 4.140    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 25800      Buffer Size: 19458      Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:25:19,580][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 4.278    Value Loss: 3.859    Reward Loss: 0.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 25963      Buffer Size: 18744      Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:31:42,583][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.097    [weighted Loss:1.097    Policy Loss: 4.419    Value Loss: 3.925    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 26159      Buffer Size: 18089      Transition Number: 399.991 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:38:03,222][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.000    [weighted Loss:1.000    Policy Loss: 5.222    Value Loss: 3.978    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 26340      Buffer Size: 17341      Transition Number: 399.993 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:44:21,538][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.457    [weighted Loss:1.457    Policy Loss: 4.541    Value Loss: 3.870    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 26556      Buffer Size: 16356      Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:50:42,626][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 5.843    Value Loss: 4.034    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 26752      Buffer Size: 15339      Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-17 14:57:04,898][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.544    [weighted Loss:1.544    Policy Loss: 4.339    Value Loss: 3.874    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 26939      Buffer Size: 14269      Transition Number: 399.991 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:03:25,814][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 4.591    Value Loss: 4.034    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 27117      Buffer Size: 13369      Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:09:50,259][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 4.403    Value Loss: 4.265    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 27284      Buffer Size: 12402      Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:16:11,989][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.200    [weighted Loss:1.200    Policy Loss: 4.392    Value Loss: 4.105    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 27460      Buffer Size: 11496      Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:22:34,186][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 3.584    Value Loss: 4.055    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 27631      Buffer Size: 10718      Transition Number: 399.998 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:28:58,291][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.825    [weighted Loss:1.825    Policy Loss: 4.307    Value Loss: 4.324    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 27798      Buffer Size: 10067      Transition Number: 399.991 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:35:19,382][train][INFO][train.py>_log] ==> #120000     Total Loss: 0.949    [weighted Loss:0.949    Policy Loss: 3.739    Value Loss: 4.152    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 27983      Buffer Size: 9603       Transition Number: 399.997 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:41:45,029][train][INFO][train.py>_log] ==> #122000     Total Loss: 0.829    [weighted Loss:0.829    Policy Loss: 3.316    Value Loss: 4.246    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 28153      Buffer Size: 9202       Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:48:10,109][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.155    [weighted Loss:1.155    Policy Loss: 3.771    Value Loss: 4.155    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 28314      Buffer Size: 8769       Transition Number: 399.998 k Batch Size: 256        Lr: 0.100   
[2021-11-17 15:54:28,399][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 3.579    Value Loss: 4.295    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 28479      Buffer Size: 8480       Transition Number: 399.991 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:00:54,464][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.351    [weighted Loss:1.351    Policy Loss: 3.288    Value Loss: 3.982    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 28637      Buffer Size: 8290       Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:07:22,795][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.206    [weighted Loss:1.206    Policy Loss: 3.123    Value Loss: 4.171    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 28801      Buffer Size: 8128       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:13:52,847][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.218    [weighted Loss:1.218    Policy Loss: 3.621    Value Loss: 4.080    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 28984      Buffer Size: 7945       Transition Number: 399.944 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:20:19,122][train][INFO][train.py>_log] ==> #134000     Total Loss: 0.889    [weighted Loss:0.889    Policy Loss: 3.029    Value Loss: 4.265    Reward Loss: 0.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 29149      Buffer Size: 7749       Transition Number: 400.000 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:26:46,330][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.139    [weighted Loss:1.139    Policy Loss: 2.774    Value Loss: 3.988    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 29315      Buffer Size: 7573       Transition Number: 399.983 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:33:09,005][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.094    [weighted Loss:1.094    Policy Loss: 3.386    Value Loss: 4.296    Reward Loss: 0.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 29475      Buffer Size: 7442       Transition Number: 399.998 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:39:33,729][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.424    [weighted Loss:1.424    Policy Loss: 3.561    Value Loss: 4.035    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 29654      Buffer Size: 7304       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:46:00,855][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.428    [weighted Loss:1.428    Policy Loss: 2.951    Value Loss: 3.942    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 29819      Buffer Size: 7220       Transition Number: 399.987 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:52:30,497][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 2.613    Value Loss: 3.941    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 29984      Buffer Size: 7107       Transition Number: 399.982 k Batch Size: 256        Lr: 0.100   
[2021-11-17 16:58:53,735][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.740    [weighted Loss:1.740    Policy Loss: 2.507    Value Loss: 3.914    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 30147      Buffer Size: 7019       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:05:25,783][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 3.057    Value Loss: 3.934    Reward Loss: 0.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 30320      Buffer Size: 6941       Transition Number: 400.070 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:12:03,608][train][INFO][train.py>_log] ==> #150000     Total Loss: 0.876    [weighted Loss:0.876    Policy Loss: 2.550    Value Loss: 3.778    Reward Loss: 0.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 30487      Buffer Size: 6863       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:18:36,044][train][INFO][train.py>_log] ==> #152000     Total Loss: 0.973    [weighted Loss:0.973    Policy Loss: 3.467    Value Loss: 3.948    Reward Loss: 0.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 30680      Buffer Size: 6738       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:25:00,361][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.038    [weighted Loss:1.038    Policy Loss: 2.806    Value Loss: 3.942    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 30848      Buffer Size: 6571       Transition Number: 399.987 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:31:25,637][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.538    [weighted Loss:1.538    Policy Loss: 2.996    Value Loss: 3.640    Reward Loss: 0.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 31028      Buffer Size: 6467       Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:37:50,517][train][INFO][train.py>_log] ==> #158000     Total Loss: 0.745    [weighted Loss:0.745    Policy Loss: 3.043    Value Loss: 3.855    Reward Loss: 0.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 31191      Buffer Size: 6332       Transition Number: 399.997 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:44:16,514][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 3.192    Value Loss: 3.792    Reward Loss: 0.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 31359      Buffer Size: 6214       Transition Number: 399.986 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:50:46,515][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.599    [weighted Loss:1.599    Policy Loss: 3.777    Value Loss: 3.792    Reward Loss: 0.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 31530      Buffer Size: 6136       Transition Number: 399.984 k Batch Size: 256        Lr: 0.100   
[2021-11-17 17:57:10,593][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 4.049    Value Loss: 3.700    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 31718      Buffer Size: 6098       Transition Number: 399.962 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:03:30,136][train][INFO][train.py>_log] ==> #166000     Total Loss: 1.526    [weighted Loss:1.526    Policy Loss: 3.490    Value Loss: 3.731    Reward Loss: 0.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 31866      Buffer Size: 6063       Transition Number: 399.966 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:09:50,707][train][INFO][train.py>_log] ==> #168000     Total Loss: 0.755    [weighted Loss:0.755    Policy Loss: 4.073    Value Loss: 3.925    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 32054      Buffer Size: 6038       Transition Number: 399.940 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:16:18,623][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.138    [weighted Loss:1.138    Policy Loss: 3.621    Value Loss: 3.834    Reward Loss: 0.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 32222      Buffer Size: 5975       Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:22:45,318][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.255    [weighted Loss:1.255    Policy Loss: 3.946    Value Loss: 3.850    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 32396      Buffer Size: 5905       Transition Number: 399.937 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:29:15,852][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.096    [weighted Loss:1.096    Policy Loss: 3.386    Value Loss: 3.638    Reward Loss: 0.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 32572      Buffer Size: 5815       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:35:41,878][train][INFO][train.py>_log] ==> #176000     Total Loss: 0.722    [weighted Loss:0.722    Policy Loss: 3.037    Value Loss: 3.752    Reward Loss: 0.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 32748      Buffer Size: 5755       Transition Number: 399.941 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:42:10,362][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 3.669    Value Loss: 3.831    Reward Loss: 0.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 32919      Buffer Size: 5734       Transition Number: 399.993 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:48:36,938][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.551    [weighted Loss:1.551    Policy Loss: 3.649    Value Loss: 3.869    Reward Loss: 0.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 33101      Buffer Size: 5726       Transition Number: 399.982 k Batch Size: 256        Lr: 0.100   
[2021-11-17 18:55:03,481][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.098    [weighted Loss:1.098    Policy Loss: 3.911    Value Loss: 3.774    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 33276      Buffer Size: 5714       Transition Number: 399.985 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:01:23,880][train][INFO][train.py>_log] ==> #184000     Total Loss: 0.905    [weighted Loss:0.905    Policy Loss: 3.449    Value Loss: 3.704    Reward Loss: 0.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 33445      Buffer Size: 5705       Transition Number: 399.976 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:07:45,877][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 3.301    Value Loss: 3.825    Reward Loss: 0.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 33608      Buffer Size: 5688       Transition Number: 399.980 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:14:15,012][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.271    [weighted Loss:1.271    Policy Loss: 3.723    Value Loss: 3.889    Reward Loss: 0.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 33799      Buffer Size: 5681       Transition Number: 399.948 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:20:43,017][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.255    [weighted Loss:1.255    Policy Loss: 3.518    Value Loss: 3.818    Reward Loss: 0.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 33959      Buffer Size: 5681       Transition Number: 399.936 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:27:06,685][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.477    [weighted Loss:1.477    Policy Loss: 3.591    Value Loss: 3.892    Reward Loss: 0.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 34145      Buffer Size: 5677       Transition Number: 399.973 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:33:30,100][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 3.968    Value Loss: 3.919    Reward Loss: 0.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 34322      Buffer Size: 5692       Transition Number: 399.983 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:39:52,671][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.103    [weighted Loss:1.103    Policy Loss: 3.837    Value Loss: 3.822    Reward Loss: 0.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 34494      Buffer Size: 5698       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:46:14,051][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.171    [weighted Loss:1.171    Policy Loss: 3.859    Value Loss: 3.822    Reward Loss: 0.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 34664      Buffer Size: 5692       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:52:38,700][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 3.384    Value Loss: 3.797    Reward Loss: 0.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 34840      Buffer Size: 5694       Transition Number: 399.926 k Batch Size: 256        Lr: 0.100   
[2021-11-17 19:59:01,734][train][INFO][train.py>_log] ==> #202000     Total Loss: 0.801    [weighted Loss:0.801    Policy Loss: 4.396    Value Loss: 3.857    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 35010      Buffer Size: 5704       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:05:22,761][train][INFO][train.py>_log] ==> #204000     Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 4.016    Value Loss: 3.815    Reward Loss: 0.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 35202      Buffer Size: 5730       Transition Number: 399.982 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:11:47,930][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.170    [weighted Loss:1.170    Policy Loss: 3.532    Value Loss: 3.816    Reward Loss: 0.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 35372      Buffer Size: 5743       Transition Number: 399.949 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:18:11,807][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.536    [weighted Loss:1.536    Policy Loss: 4.288    Value Loss: 3.735    Reward Loss: 0.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 35549      Buffer Size: 5750       Transition Number: 399.995 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:24:32,838][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.098    [weighted Loss:1.098    Policy Loss: 4.071    Value Loss: 4.074    Reward Loss: 0.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 35723      Buffer Size: 5773       Transition Number: 399.938 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:30:59,924][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 4.201    Value Loss: 3.869    Reward Loss: 0.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 35909      Buffer Size: 5814       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:37:22,918][train][INFO][train.py>_log] ==> #214000     Total Loss: 0.659    [weighted Loss:0.659    Policy Loss: 3.737    Value Loss: 3.808    Reward Loss: 0.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 36096      Buffer Size: 5858       Transition Number: 399.999 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:43:48,291][train][INFO][train.py>_log] ==> #216000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.801    Value Loss: 3.641    Reward Loss: 0.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 36266      Buffer Size: 5874       Transition Number: 399.993 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:50:12,465][train][INFO][train.py>_log] ==> #218000     Total Loss: 0.809    [weighted Loss:0.809    Policy Loss: 3.646    Value Loss: 4.078    Reward Loss: 0.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 36442      Buffer Size: 5880       Transition Number: 399.976 k Batch Size: 256        Lr: 0.100   
[2021-11-17 20:56:32,699][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.387    [weighted Loss:1.387    Policy Loss: 3.916    Value Loss: 3.802    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 36625      Buffer Size: 5901       Transition Number: 399.969 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:02:54,765][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.386    [weighted Loss:1.386    Policy Loss: 4.110    Value Loss: 3.893    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 36800      Buffer Size: 5915       Transition Number: 400.068 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:09:17,593][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.042    [weighted Loss:1.042    Policy Loss: 3.441    Value Loss: 3.988    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 36968      Buffer Size: 5921       Transition Number: 399.955 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:15:34,914][train][INFO][train.py>_log] ==> #226000     Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 3.968    Value Loss: 3.813    Reward Loss: 0.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 37142      Buffer Size: 5935       Transition Number: 399.985 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:21:56,032][train][INFO][train.py>_log] ==> #228000     Total Loss: 0.992    [weighted Loss:0.992    Policy Loss: 3.472    Value Loss: 3.906    Reward Loss: 0.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 37317      Buffer Size: 5954       Transition Number: 399.954 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:28:19,841][train][INFO][train.py>_log] ==> #230000     Total Loss: 1.471    [weighted Loss:1.471    Policy Loss: 3.841    Value Loss: 3.728    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 37491      Buffer Size: 5976       Transition Number: 399.965 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:34:44,336][train][INFO][train.py>_log] ==> #232000     Total Loss: 0.980    [weighted Loss:0.980    Policy Loss: 3.830    Value Loss: 3.774    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 37677      Buffer Size: 5980       Transition Number: 399.962 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:41:09,568][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.090    [weighted Loss:1.090    Policy Loss: 3.466    Value Loss: 3.989    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 37843      Buffer Size: 5986       Transition Number: 399.921 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:47:35,686][train][INFO][train.py>_log] ==> #236000     Total Loss: 1.104    [weighted Loss:1.104    Policy Loss: 3.289    Value Loss: 4.002    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 38015      Buffer Size: 5985       Transition Number: 399.939 k Batch Size: 256        Lr: 0.100   
[2021-11-17 21:54:05,136][train][INFO][train.py>_log] ==> #238000     Total Loss: 1.385    [weighted Loss:1.385    Policy Loss: 3.301    Value Loss: 4.007    Reward Loss: 0.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 38189      Buffer Size: 5985       Transition Number: 399.942 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:00:26,106][train][INFO][train.py>_log] ==> #240000     Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 3.863    Value Loss: 3.910    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 38369      Buffer Size: 6002       Transition Number: 399.927 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:06:48,807][train][INFO][train.py>_log] ==> #242000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 3.835    Value Loss: 4.144    Reward Loss: 0.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 38541      Buffer Size: 6025       Transition Number: 399.927 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:13:11,290][train][INFO][train.py>_log] ==> #244000     Total Loss: 0.836    [weighted Loss:0.836    Policy Loss: 3.290    Value Loss: 4.197    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 38731      Buffer Size: 6035       Transition Number: 400.000 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:19:35,865][train][INFO][train.py>_log] ==> #246000     Total Loss: 0.615    [weighted Loss:0.615    Policy Loss: 3.214    Value Loss: 4.055    Reward Loss: 0.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 38909      Buffer Size: 6034       Transition Number: 399.939 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:26:06,134][train][INFO][train.py>_log] ==> #248000     Total Loss: 0.960    [weighted Loss:0.960    Policy Loss: 3.809    Value Loss: 4.251    Reward Loss: 0.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 39081      Buffer Size: 6030       Transition Number: 399.928 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:32:31,207][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.548    [weighted Loss:1.548    Policy Loss: 3.419    Value Loss: 4.073    Reward Loss: 0.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 39251      Buffer Size: 6017       Transition Number: 399.936 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:38:57,976][train][INFO][train.py>_log] ==> #252000     Total Loss: 0.640    [weighted Loss:0.640    Policy Loss: 3.069    Value Loss: 3.960    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 39432      Buffer Size: 6015       Transition Number: 399.930 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:45:23,812][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.177    [weighted Loss:1.177    Policy Loss: 3.344    Value Loss: 3.848    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 39608      Buffer Size: 6013       Transition Number: 399.961 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:51:49,464][train][INFO][train.py>_log] ==> #256000     Total Loss: 0.750    [weighted Loss:0.750    Policy Loss: 3.647    Value Loss: 3.994    Reward Loss: 0.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 39788      Buffer Size: 6016       Transition Number: 400.070 k Batch Size: 256        Lr: 0.100   
[2021-11-17 22:58:16,736][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.296    [weighted Loss:1.296    Policy Loss: 3.732    Value Loss: 4.126    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 39971      Buffer Size: 6026       Transition Number: 399.983 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:04:42,671][train][INFO][train.py>_log] ==> #260000     Total Loss: 0.750    [weighted Loss:0.750    Policy Loss: 4.130    Value Loss: 4.479    Reward Loss: 0.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 40159      Buffer Size: 6047       Transition Number: 399.938 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:11:10,991][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.561    [weighted Loss:1.561    Policy Loss: 3.804    Value Loss: 4.060    Reward Loss: 0.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 40337      Buffer Size: 6055       Transition Number: 399.959 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:17:36,411][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.166    [weighted Loss:1.166    Policy Loss: 3.379    Value Loss: 4.257    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 40542      Buffer Size: 6092       Transition Number: 399.944 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:24:01,076][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 3.583    Value Loss: 4.217    Reward Loss: 0.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 40736      Buffer Size: 6136       Transition Number: 399.969 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:30:29,668][train][INFO][train.py>_log] ==> #268000     Total Loss: 0.632    [weighted Loss:0.632    Policy Loss: 3.087    Value Loss: 4.494    Reward Loss: 0.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 40913      Buffer Size: 6138       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:36:54,177][train][INFO][train.py>_log] ==> #270000     Total Loss: 1.109    [weighted Loss:1.109    Policy Loss: 3.533    Value Loss: 4.038    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 41081      Buffer Size: 6132       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:43:16,628][train][INFO][train.py>_log] ==> #272000     Total Loss: 0.767    [weighted Loss:0.767    Policy Loss: 3.565    Value Loss: 4.096    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 41255      Buffer Size: 6118       Transition Number: 399.936 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:49:42,476][train][INFO][train.py>_log] ==> #274000     Total Loss: 0.876    [weighted Loss:0.876    Policy Loss: 3.313    Value Loss: 4.061    Reward Loss: 0.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 41431      Buffer Size: 6106       Transition Number: 399.946 k Batch Size: 256        Lr: 0.100   
[2021-11-17 23:56:03,704][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 4.028    Value Loss: 4.295    Reward Loss: 0.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 41605      Buffer Size: 6100       Transition Number: 399.974 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:02:24,070][train][INFO][train.py>_log] ==> #278000     Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 3.067    Value Loss: 4.213    Reward Loss: 0.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 41769      Buffer Size: 6089       Transition Number: 399.986 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:08:40,803][train][INFO][train.py>_log] ==> #280000     Total Loss: 0.693    [weighted Loss:0.693    Policy Loss: 3.343    Value Loss: 4.027    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 41963      Buffer Size: 6056       Transition Number: 399.995 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:14:58,724][train][INFO][train.py>_log] ==> #282000     Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 3.444    Value Loss: 4.315    Reward Loss: 0.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 42131      Buffer Size: 6030       Transition Number: 399.976 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:21:22,690][train][INFO][train.py>_log] ==> #284000     Total Loss: 0.734    [weighted Loss:0.734    Policy Loss: 4.078    Value Loss: 4.266    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 42310      Buffer Size: 6033       Transition Number: 399.947 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:27:46,040][train][INFO][train.py>_log] ==> #286000     Total Loss: 0.794    [weighted Loss:0.794    Policy Loss: 3.403    Value Loss: 4.149    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 42479      Buffer Size: 6049       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:34:09,424][train][INFO][train.py>_log] ==> #288000     Total Loss: 0.773    [weighted Loss:0.773    Policy Loss: 3.185    Value Loss: 4.343    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 42656      Buffer Size: 6043       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:40:32,142][train][INFO][train.py>_log] ==> #290000     Total Loss: 1.180    [weighted Loss:1.180    Policy Loss: 3.499    Value Loss: 4.223    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 42830      Buffer Size: 6038       Transition Number: 399.941 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:46:53,172][train][INFO][train.py>_log] ==> #292000     Total Loss: 0.898    [weighted Loss:0.898    Policy Loss: 3.216    Value Loss: 4.139    Reward Loss: 0.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 43014      Buffer Size: 6046       Transition Number: 399.978 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:53:17,566][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.010    [weighted Loss:1.010    Policy Loss: 2.943    Value Loss: 4.133    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 43193      Buffer Size: 6053       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-18 00:59:38,967][train][INFO][train.py>_log] ==> #296000     Total Loss: 1.292    [weighted Loss:1.292    Policy Loss: 3.579    Value Loss: 4.344    Reward Loss: 0.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 43376      Buffer Size: 6052       Transition Number: 400.235 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:05:58,947][train][INFO][train.py>_log] ==> #298000     Total Loss: 0.862    [weighted Loss:0.862    Policy Loss: 3.199    Value Loss: 4.052    Reward Loss: 0.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 43547      Buffer Size: 6051       Transition Number: 399.967 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:12:22,290][train][INFO][train.py>_log] ==> #300000     Total Loss: 1.003    [weighted Loss:1.003    Policy Loss: 3.622    Value Loss: 4.088    Reward Loss: 0.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 43741      Buffer Size: 6053       Transition Number: 399.928 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:18:42,563][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.281    [weighted Loss:1.281    Policy Loss: 3.458    Value Loss: 4.112    Reward Loss: 0.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 43901      Buffer Size: 6056       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:25:13,188][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.107    [weighted Loss:1.107    Policy Loss: 3.366    Value Loss: 4.208    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 44092      Buffer Size: 6056       Transition Number: 399.968 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:31:32,404][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.091    [weighted Loss:1.091    Policy Loss: 3.592    Value Loss: 4.198    Reward Loss: 0.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 44268      Buffer Size: 6071       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:38:00,175][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.465    [weighted Loss:1.465    Policy Loss: 3.871    Value Loss: 4.430    Reward Loss: 0.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 44448      Buffer Size: 6069       Transition Number: 399.989 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:44:28,458][train][INFO][train.py>_log] ==> #310000     Total Loss: 0.724    [weighted Loss:0.724    Policy Loss: 3.476    Value Loss: 4.228    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 44616      Buffer Size: 6054       Transition Number: 399.946 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:50:56,714][train][INFO][train.py>_log] ==> #312000     Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 3.365    Value Loss: 4.169    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 44800      Buffer Size: 6052       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-18 01:57:25,610][train][INFO][train.py>_log] ==> #314000     Total Loss: 1.171    [weighted Loss:1.171    Policy Loss: 3.135    Value Loss: 4.046    Reward Loss: 0.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 44965      Buffer Size: 6044       Transition Number: 399.961 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:03:54,386][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.410    [weighted Loss:1.410    Policy Loss: 3.367    Value Loss: 4.212    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 45144      Buffer Size: 6041       Transition Number: 399.958 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:10:20,073][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.001    [weighted Loss:1.001    Policy Loss: 3.563    Value Loss: 4.274    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 45325      Buffer Size: 6038       Transition Number: 399.988 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:16:38,238][train][INFO][train.py>_log] ==> #320000     Total Loss: 0.637    [weighted Loss:0.637    Policy Loss: 3.417    Value Loss: 4.017    Reward Loss: 0.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 45510      Buffer Size: 6034       Transition Number: 400.000 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:22:56,919][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.564    [weighted Loss:1.564    Policy Loss: 4.331    Value Loss: 4.379    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 45681      Buffer Size: 6034       Transition Number: 399.961 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:29:17,419][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.038    [weighted Loss:1.038    Policy Loss: 3.470    Value Loss: 4.430    Reward Loss: 0.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 45865      Buffer Size: 6039       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:35:42,346][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.122    [weighted Loss:1.122    Policy Loss: 3.699    Value Loss: 4.303    Reward Loss: 0.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 46038      Buffer Size: 6029       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:42:04,819][train][INFO][train.py>_log] ==> #328000     Total Loss: 0.962    [weighted Loss:0.962    Policy Loss: 3.639    Value Loss: 4.373    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 46215      Buffer Size: 6007       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:48:27,715][train][INFO][train.py>_log] ==> #330000     Total Loss: 1.215    [weighted Loss:1.215    Policy Loss: 3.865    Value Loss: 4.277    Reward Loss: 0.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 46387      Buffer Size: 5979       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-18 02:54:50,939][train][INFO][train.py>_log] ==> #332000     Total Loss: 1.318    [weighted Loss:1.318    Policy Loss: 3.565    Value Loss: 4.219    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 46570      Buffer Size: 5937       Transition Number: 399.944 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:01:11,491][train][INFO][train.py>_log] ==> #334000     Total Loss: 0.952    [weighted Loss:0.952    Policy Loss: 3.590    Value Loss: 4.161    Reward Loss: 0.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 46749      Buffer Size: 5917       Transition Number: 399.983 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:07:32,488][train][INFO][train.py>_log] ==> #336000     Total Loss: 1.233    [weighted Loss:1.233    Policy Loss: 3.362    Value Loss: 4.622    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 46916      Buffer Size: 5910       Transition Number: 399.974 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:13:57,151][train][INFO][train.py>_log] ==> #338000     Total Loss: 0.798    [weighted Loss:0.798    Policy Loss: 3.486    Value Loss: 4.141    Reward Loss: 0.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 47091      Buffer Size: 5908       Transition Number: 399.937 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:20:17,432][train][INFO][train.py>_log] ==> #340000     Total Loss: 0.624    [weighted Loss:0.624    Policy Loss: 3.438    Value Loss: 4.162    Reward Loss: 0.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 47265      Buffer Size: 5897       Transition Number: 400.080 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:26:43,939][train][INFO][train.py>_log] ==> #342000     Total Loss: 1.001    [weighted Loss:1.001    Policy Loss: 3.182    Value Loss: 4.099    Reward Loss: 0.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 47433      Buffer Size: 5888       Transition Number: 399.984 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:33:05,006][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.337    [weighted Loss:1.337    Policy Loss: 3.659    Value Loss: 4.244    Reward Loss: 0.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 47631      Buffer Size: 5894       Transition Number: 400.003 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:39:29,038][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.032    [weighted Loss:1.032    Policy Loss: 4.202    Value Loss: 4.162    Reward Loss: 0.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 47805      Buffer Size: 5903       Transition Number: 399.990 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:45:48,589][train][INFO][train.py>_log] ==> #348000     Total Loss: 0.773    [weighted Loss:0.773    Policy Loss: 3.580    Value Loss: 4.182    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 47991      Buffer Size: 5890       Transition Number: 399.960 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:52:12,806][train][INFO][train.py>_log] ==> #350000     Total Loss: 0.739    [weighted Loss:0.739    Policy Loss: 3.581    Value Loss: 4.221    Reward Loss: 0.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 48159      Buffer Size: 5870       Transition Number: 399.981 k Batch Size: 256        Lr: 0.100   
[2021-11-18 03:58:40,460][train][INFO][train.py>_log] ==> #352000     Total Loss: 0.315    [weighted Loss:0.315    Policy Loss: 2.842    Value Loss: 4.248    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 48343      Buffer Size: 5844       Transition Number: 399.931 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:05:05,634][train][INFO][train.py>_log] ==> #354000     Total Loss: 0.894    [weighted Loss:0.894    Policy Loss: 3.178    Value Loss: 4.131    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 48512      Buffer Size: 5835       Transition Number: 400.117 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:11:27,219][train][INFO][train.py>_log] ==> #356000     Total Loss: 0.924    [weighted Loss:0.924    Policy Loss: 3.580    Value Loss: 4.281    Reward Loss: 0.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 48695      Buffer Size: 5808       Transition Number: 399.999 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:17:45,229][train][INFO][train.py>_log] ==> #358000     Total Loss: 1.495    [weighted Loss:1.495    Policy Loss: 3.840    Value Loss: 4.200    Reward Loss: 0.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 48873      Buffer Size: 5777       Transition Number: 399.976 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:24:05,642][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.226    [weighted Loss:1.226    Policy Loss: 3.700    Value Loss: 4.223    Reward Loss: 0.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 49049      Buffer Size: 5760       Transition Number: 399.936 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:30:28,013][train][INFO][train.py>_log] ==> #362000     Total Loss: 1.081    [weighted Loss:1.081    Policy Loss: 4.114    Value Loss: 3.982    Reward Loss: 0.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 49226      Buffer Size: 5743       Transition Number: 399.990 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:36:49,832][train][INFO][train.py>_log] ==> #364000     Total Loss: 0.856    [weighted Loss:0.856    Policy Loss: 4.332    Value Loss: 4.049    Reward Loss: 0.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 49409      Buffer Size: 5729       Transition Number: 399.971 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:43:12,856][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 5.257    Value Loss: 4.048    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 49589      Buffer Size: 5723       Transition Number: 399.999 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:49:37,289][train][INFO][train.py>_log] ==> #368000     Total Loss: 1.665    [weighted Loss:1.665    Policy Loss: 5.256    Value Loss: 3.851    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 49771      Buffer Size: 5719       Transition Number: 399.974 k Batch Size: 256        Lr: 0.100   
[2021-11-18 04:55:54,967][train][INFO][train.py>_log] ==> #370000     Total Loss: 1.355    [weighted Loss:1.355    Policy Loss: 6.821    Value Loss: 4.297    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 49953      Buffer Size: 5728       Transition Number: 400.049 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:02:08,680][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.062    [weighted Loss:1.062    Policy Loss: 4.612    Value Loss: 4.049    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 50134      Buffer Size: 5737       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:08:28,353][train][INFO][train.py>_log] ==> #374000     Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 4.958    Value Loss: 4.145    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 50305      Buffer Size: 5743       Transition Number: 399.962 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:14:50,428][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.185    [weighted Loss:1.185    Policy Loss: 4.799    Value Loss: 4.034    Reward Loss: 0.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 50487      Buffer Size: 5751       Transition Number: 399.931 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:21:10,838][train][INFO][train.py>_log] ==> #378000     Total Loss: 1.467    [weighted Loss:1.467    Policy Loss: 5.969    Value Loss: 4.153    Reward Loss: 0.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 50667      Buffer Size: 5765       Transition Number: 399.941 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:27:25,660][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 5.512    Value Loss: 4.214    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 50863      Buffer Size: 5789       Transition Number: 399.947 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:33:38,089][train][INFO][train.py>_log] ==> #382000     Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 5.997    Value Loss: 3.990    Reward Loss: 0.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 51035      Buffer Size: 5799       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:39:47,928][train][INFO][train.py>_log] ==> #384000     Total Loss: 0.586    [weighted Loss:0.586    Policy Loss: 5.422    Value Loss: 4.426    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 51203      Buffer Size: 5804       Transition Number: 399.947 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:45:58,367][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.008    [weighted Loss:1.008    Policy Loss: 5.182    Value Loss: 4.348    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 51373      Buffer Size: 5814       Transition Number: 399.977 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:52:09,946][train][INFO][train.py>_log] ==> #388000     Total Loss: 0.548    [weighted Loss:0.548    Policy Loss: 5.281    Value Loss: 4.061    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 51549      Buffer Size: 5813       Transition Number: 399.989 k Batch Size: 256        Lr: 0.100   
[2021-11-18 05:58:21,014][train][INFO][train.py>_log] ==> #390000     Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 5.460    Value Loss: 4.187    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 51721      Buffer Size: 5815       Transition Number: 399.995 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:04:38,710][train][INFO][train.py>_log] ==> #392000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 5.325    Value Loss: 4.296    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 51903      Buffer Size: 5823       Transition Number: 399.948 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:10:51,276][train][INFO][train.py>_log] ==> #394000     Total Loss: 1.174    [weighted Loss:1.174    Policy Loss: 5.748    Value Loss: 4.153    Reward Loss: 0.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 52073      Buffer Size: 5829       Transition Number: 399.973 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:17:08,523][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 5.752    Value Loss: 4.092    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 52258      Buffer Size: 5834       Transition Number: 399.969 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:23:28,863][train][INFO][train.py>_log] ==> #398000     Total Loss: 0.348    [weighted Loss:0.348    Policy Loss: 5.234    Value Loss: 4.281    Reward Loss: 0.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 52439      Buffer Size: 5844       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:29:47,280][train][INFO][train.py>_log] ==> #400000     Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 5.062    Value Loss: 4.247    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 52617      Buffer Size: 5848       Transition Number: 399.949 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:36:03,659][train][INFO][train.py>_log] ==> #402000     Total Loss: 0.870    [weighted Loss:0.870    Policy Loss: 4.996    Value Loss: 3.927    Reward Loss: 0.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 52801      Buffer Size: 5868       Transition Number: 399.954 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:42:15,460][train][INFO][train.py>_log] ==> #404000     Total Loss: 0.772    [weighted Loss:0.772    Policy Loss: 5.960    Value Loss: 4.231    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 52984      Buffer Size: 5906       Transition Number: 399.974 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:48:29,676][train][INFO][train.py>_log] ==> #406000     Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 5.142    Value Loss: 4.479    Reward Loss: 0.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 53160      Buffer Size: 5929       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-18 06:54:44,354][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 5.516    Value Loss: 4.417    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 53336      Buffer Size: 5954       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:01:01,751][train][INFO][train.py>_log] ==> #410000     Total Loss: 0.945    [weighted Loss:0.945    Policy Loss: 5.862    Value Loss: 4.321    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 53520      Buffer Size: 5959       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:07:21,281][train][INFO][train.py>_log] ==> #412000     Total Loss: 1.194    [weighted Loss:1.194    Policy Loss: 5.977    Value Loss: 4.150    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 53700      Buffer Size: 5959       Transition Number: 399.980 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:13:30,900][train][INFO][train.py>_log] ==> #414000     Total Loss: 1.504    [weighted Loss:1.504    Policy Loss: 6.805    Value Loss: 4.224    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 53877      Buffer Size: 5977       Transition Number: 399.985 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:19:45,395][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 6.580    Value Loss: 4.250    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 54059      Buffer Size: 5995       Transition Number: 399.973 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:26:03,507][train][INFO][train.py>_log] ==> #418000     Total Loss: 0.848    [weighted Loss:0.848    Policy Loss: 5.539    Value Loss: 4.122    Reward Loss: 0.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 54243      Buffer Size: 6019       Transition Number: 399.940 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:32:21,613][train][INFO][train.py>_log] ==> #420000     Total Loss: 1.196    [weighted Loss:1.196    Policy Loss: 6.683    Value Loss: 4.307    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 54434      Buffer Size: 6057       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:38:38,296][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 6.970    Value Loss: 4.195    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 54610      Buffer Size: 6092       Transition Number: 399.964 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:44:48,109][train][INFO][train.py>_log] ==> #424000     Total Loss: 1.661    [weighted Loss:1.661    Policy Loss: 5.845    Value Loss: 4.231    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 54786      Buffer Size: 6119       Transition Number: 399.983 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:50:58,479][train][INFO][train.py>_log] ==> #426000     Total Loss: 1.646    [weighted Loss:1.646    Policy Loss: 5.966    Value Loss: 4.346    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 54958      Buffer Size: 6143       Transition Number: 399.930 k Batch Size: 256        Lr: 0.100   
[2021-11-18 07:57:09,239][train][INFO][train.py>_log] ==> #428000     Total Loss: 0.848    [weighted Loss:0.848    Policy Loss: 5.539    Value Loss: 4.539    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 55138      Buffer Size: 6169       Transition Number: 399.923 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:03:20,692][train][INFO][train.py>_log] ==> #430000     Total Loss: 0.922    [weighted Loss:0.922    Policy Loss: 6.046    Value Loss: 4.323    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 55316      Buffer Size: 6201       Transition Number: 399.951 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:09:33,750][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.454    [weighted Loss:1.454    Policy Loss: 5.912    Value Loss: 4.256    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 55498      Buffer Size: 6225       Transition Number: 399.989 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:15:43,200][train][INFO][train.py>_log] ==> #434000     Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 6.790    Value Loss: 4.392    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 55673      Buffer Size: 6250       Transition Number: 399.956 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:21:57,179][train][INFO][train.py>_log] ==> #436000     Total Loss: 1.437    [weighted Loss:1.437    Policy Loss: 6.184    Value Loss: 4.289    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 55845      Buffer Size: 6259       Transition Number: 399.999 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:28:12,677][train][INFO][train.py>_log] ==> #438000     Total Loss: 1.212    [weighted Loss:1.212    Policy Loss: 5.330    Value Loss: 4.244    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 56013      Buffer Size: 6259       Transition Number: 399.978 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:34:27,732][train][INFO][train.py>_log] ==> #440000     Total Loss: 0.543    [weighted Loss:0.543    Policy Loss: 7.299    Value Loss: 4.763    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 56202      Buffer Size: 6247       Transition Number: 399.978 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:40:40,506][train][INFO][train.py>_log] ==> #442000     Total Loss: 1.145    [weighted Loss:1.145    Policy Loss: 6.007    Value Loss: 4.387    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 56370      Buffer Size: 6242       Transition Number: 399.973 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:46:46,573][train][INFO][train.py>_log] ==> #444000     Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 5.768    Value Loss: 4.276    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 56541      Buffer Size: 6243       Transition Number: 399.982 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:53:00,839][train][INFO][train.py>_log] ==> #446000     Total Loss: 1.596    [weighted Loss:1.596    Policy Loss: 5.623    Value Loss: 4.364    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 56711      Buffer Size: 6243       Transition Number: 399.942 k Batch Size: 256        Lr: 0.100   
[2021-11-18 08:59:15,907][train][INFO][train.py>_log] ==> #448000     Total Loss: 0.499    [weighted Loss:0.499    Policy Loss: 5.778    Value Loss: 4.117    Reward Loss: 0.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 56889      Buffer Size: 6250       Transition Number: 399.971 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:05:30,778][train][INFO][train.py>_log] ==> #450000     Total Loss: 0.952    [weighted Loss:0.952    Policy Loss: 5.957    Value Loss: 4.176    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 57058      Buffer Size: 6239       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:11:41,470][train][INFO][train.py>_log] ==> #452000     Total Loss: 0.405    [weighted Loss:0.405    Policy Loss: 7.202    Value Loss: 4.295    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 57231      Buffer Size: 6242       Transition Number: 399.943 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:17:51,877][train][INFO][train.py>_log] ==> #454000     Total Loss: 0.577    [weighted Loss:0.577    Policy Loss: 6.918    Value Loss: 4.499    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 57404      Buffer Size: 6252       Transition Number: 399.981 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:24:02,739][train][INFO][train.py>_log] ==> #456000     Total Loss: 0.941    [weighted Loss:0.941    Policy Loss: 5.875    Value Loss: 4.373    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 57572      Buffer Size: 6252       Transition Number: 399.998 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:30:12,714][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.031    [weighted Loss:1.031    Policy Loss: 5.573    Value Loss: 4.429    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 57742      Buffer Size: 6255       Transition Number: 399.966 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:36:22,390][train][INFO][train.py>_log] ==> #460000     Total Loss: 0.975    [weighted Loss:0.975    Policy Loss: 6.086    Value Loss: 4.290    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 57926      Buffer Size: 6266       Transition Number: 399.945 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:42:32,651][train][INFO][train.py>_log] ==> #462000     Total Loss: 1.152    [weighted Loss:1.152    Policy Loss: 5.767    Value Loss: 4.151    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 58106      Buffer Size: 6278       Transition Number: 399.965 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:48:47,443][train][INFO][train.py>_log] ==> #464000     Total Loss: 0.849    [weighted Loss:0.849    Policy Loss: 6.440    Value Loss: 4.553    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 58285      Buffer Size: 6274       Transition Number: 399.943 k Batch Size: 256        Lr: 0.100   
[2021-11-18 09:54:56,656][train][INFO][train.py>_log] ==> #466000     Total Loss: 0.803    [weighted Loss:0.803    Policy Loss: 6.582    Value Loss: 4.358    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 58465      Buffer Size: 6288       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:01:04,177][train][INFO][train.py>_log] ==> #468000     Total Loss: 1.287    [weighted Loss:1.287    Policy Loss: 6.851    Value Loss: 4.398    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 58636      Buffer Size: 6305       Transition Number: 399.958 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:07:12,521][train][INFO][train.py>_log] ==> #470000     Total Loss: 0.933    [weighted Loss:0.933    Policy Loss: 6.109    Value Loss: 4.376    Reward Loss: 0.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 58798      Buffer Size: 6298       Transition Number: 399.976 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:13:22,434][train][INFO][train.py>_log] ==> #472000     Total Loss: 1.457    [weighted Loss:1.457    Policy Loss: 6.181    Value Loss: 4.238    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 58976      Buffer Size: 6299       Transition Number: 400.102 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:19:37,929][train][INFO][train.py>_log] ==> #474000     Total Loss: 0.613    [weighted Loss:0.613    Policy Loss: 6.322    Value Loss: 4.271    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 59148      Buffer Size: 6275       Transition Number: 399.997 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:25:53,070][train][INFO][train.py>_log] ==> #476000     Total Loss: 0.595    [weighted Loss:0.595    Policy Loss: 6.666    Value Loss: 4.427    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 59330      Buffer Size: 6250       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:32:04,459][train][INFO][train.py>_log] ==> #478000     Total Loss: 0.760    [weighted Loss:0.760    Policy Loss: 6.670    Value Loss: 4.345    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 59499      Buffer Size: 6230       Transition Number: 399.931 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:38:13,618][train][INFO][train.py>_log] ==> #480000     Total Loss: 0.764    [weighted Loss:0.764    Policy Loss: 6.578    Value Loss: 4.349    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 59675      Buffer Size: 6219       Transition Number: 399.980 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:44:29,631][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 6.886    Value Loss: 4.372    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 59851      Buffer Size: 6218       Transition Number: 399.933 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:50:45,834][train][INFO][train.py>_log] ==> #484000     Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 7.013    Value Loss: 4.402    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 60027      Buffer Size: 6209       Transition Number: 399.989 k Batch Size: 256        Lr: 0.100   
[2021-11-18 10:56:58,357][train][INFO][train.py>_log] ==> #486000     Total Loss: 0.923    [weighted Loss:0.923    Policy Loss: 6.321    Value Loss: 4.379    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 60197      Buffer Size: 6198       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:03:14,399][train][INFO][train.py>_log] ==> #488000     Total Loss: 0.770    [weighted Loss:0.770    Policy Loss: 7.004    Value Loss: 4.334    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 60382      Buffer Size: 6184       Transition Number: 399.990 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:09:26,402][train][INFO][train.py>_log] ==> #490000     Total Loss: 1.715    [weighted Loss:1.715    Policy Loss: 6.553    Value Loss: 4.322    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 60548      Buffer Size: 6165       Transition Number: 399.982 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:15:36,398][train][INFO][train.py>_log] ==> #492000     Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 6.857    Value Loss: 4.313    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 60720      Buffer Size: 6130       Transition Number: 399.964 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:21:43,486][train][INFO][train.py>_log] ==> #494000     Total Loss: 0.633    [weighted Loss:0.633    Policy Loss: 8.320    Value Loss: 4.586    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 60898      Buffer Size: 6134       Transition Number: 399.944 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:34:56,984][train][INFO][train.py>_log] ==> #496000     Total Loss: 1.014    [weighted Loss:1.014    Policy Loss: 6.619    Value Loss: 4.046    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 61280      Buffer Size: 6153       Transition Number: 399.938 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:41:04,516][train][INFO][train.py>_log] ==> #498000     Total Loss: 1.048    [weighted Loss:1.048    Policy Loss: 6.720    Value Loss: 4.538    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 61446      Buffer Size: 6139       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:47:20,093][train][INFO][train.py>_log] ==> #500000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 7.690    Value Loss: 4.746    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 61626      Buffer Size: 6127       Transition Number: 399.988 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:53:33,078][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 6.968    Value Loss: 4.225    Reward Loss: 0.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 61800      Buffer Size: 6117       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-18 11:59:39,552][train][INFO][train.py>_log] ==> #504000     Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 6.121    Value Loss: 4.239    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 61972      Buffer Size: 6126       Transition Number: 399.983 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:05:49,650][train][INFO][train.py>_log] ==> #506000     Total Loss: 1.320    [weighted Loss:1.320    Policy Loss: 8.655    Value Loss: 4.157    Reward Loss: 0.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 62205      Buffer Size: 6207       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:11:58,973][train][INFO][train.py>_log] ==> #508000     Total Loss: 1.165    [weighted Loss:1.165    Policy Loss: 7.839    Value Loss: 4.249    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 62392      Buffer Size: 6234       Transition Number: 399.982 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:18:09,642][train][INFO][train.py>_log] ==> #510000     Total Loss: 0.959    [weighted Loss:0.959    Policy Loss: 7.188    Value Loss: 4.225    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 62566      Buffer Size: 6237       Transition Number: 399.986 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:24:22,644][train][INFO][train.py>_log] ==> #512000     Total Loss: 0.886    [weighted Loss:0.886    Policy Loss: 7.500    Value Loss: 4.688    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 62750      Buffer Size: 6241       Transition Number: 399.986 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:30:32,541][train][INFO][train.py>_log] ==> #514000     Total Loss: 0.773    [weighted Loss:0.773    Policy Loss: 7.654    Value Loss: 4.363    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 62930      Buffer Size: 6260       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:36:43,345][train][INFO][train.py>_log] ==> #516000     Total Loss: 1.454    [weighted Loss:1.454    Policy Loss: 7.895    Value Loss: 4.627    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 63109      Buffer Size: 6248       Transition Number: 400.005 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:42:56,796][train][INFO][train.py>_log] ==> #518000     Total Loss: 1.811    [weighted Loss:1.811    Policy Loss: 7.212    Value Loss: 4.473    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 63287      Buffer Size: 6237       Transition Number: 399.961 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:49:08,665][train][INFO][train.py>_log] ==> #520000     Total Loss: 0.377    [weighted Loss:0.377    Policy Loss: 6.572    Value Loss: 4.235    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 63463      Buffer Size: 6221       Transition Number: 399.931 k Batch Size: 256        Lr: 0.100   
[2021-11-18 12:55:24,529][train][INFO][train.py>_log] ==> #522000     Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 7.585    Value Loss: 4.345    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 63635      Buffer Size: 6218       Transition Number: 400.062 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:01:36,437][train][INFO][train.py>_log] ==> #524000     Total Loss: 1.471    [weighted Loss:1.471    Policy Loss: 7.924    Value Loss: 4.330    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 63815      Buffer Size: 6224       Transition Number: 399.954 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:07:41,299][train][INFO][train.py>_log] ==> #526000     Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 8.406    Value Loss: 4.531    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 63985      Buffer Size: 6228       Transition Number: 399.988 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:13:55,693][train][INFO][train.py>_log] ==> #528000     Total Loss: 0.621    [weighted Loss:0.621    Policy Loss: 6.509    Value Loss: 4.128    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 64167      Buffer Size: 6215       Transition Number: 399.950 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:20:04,014][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.768    [weighted Loss:1.768    Policy Loss: 7.742    Value Loss: 4.179    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 64335      Buffer Size: 6199       Transition Number: 399.924 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:26:12,055][train][INFO][train.py>_log] ==> #532000     Total Loss: 1.307    [weighted Loss:1.307    Policy Loss: 8.215    Value Loss: 4.609    Reward Loss: 0.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 64509      Buffer Size: 6195       Transition Number: 399.944 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:32:21,965][train][INFO][train.py>_log] ==> #534000     Total Loss: 1.343    [weighted Loss:1.343    Policy Loss: 7.189    Value Loss: 4.256    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 64682      Buffer Size: 6181       Transition Number: 399.946 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:38:35,200][train][INFO][train.py>_log] ==> #536000     Total Loss: 0.818    [weighted Loss:0.818    Policy Loss: 7.862    Value Loss: 4.242    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 64888      Buffer Size: 6192       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:44:43,429][train][INFO][train.py>_log] ==> #538000     Total Loss: 1.062    [weighted Loss:1.062    Policy Loss: 7.415    Value Loss: 4.260    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 65052      Buffer Size: 6200       Transition Number: 399.931 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:50:53,342][train][INFO][train.py>_log] ==> #540000     Total Loss: 1.086    [weighted Loss:1.086    Policy Loss: 7.537    Value Loss: 3.962    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 65241      Buffer Size: 6194       Transition Number: 399.998 k Batch Size: 256        Lr: 0.100   
[2021-11-18 13:57:02,091][train][INFO][train.py>_log] ==> #542000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 8.142    Value Loss: 4.106    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 65419      Buffer Size: 6224       Transition Number: 399.987 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:03:03,345][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 8.186    Value Loss: 4.605    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 65595      Buffer Size: 6246       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:09:09,158][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.349    [weighted Loss:1.349    Policy Loss: 6.669    Value Loss: 4.344    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 65764      Buffer Size: 6245       Transition Number: 399.932 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:15:15,916][train][INFO][train.py>_log] ==> #548000     Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 7.939    Value Loss: 4.539    Reward Loss: 0.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 65935      Buffer Size: 6248       Transition Number: 399.974 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:21:31,616][train][INFO][train.py>_log] ==> #550000     Total Loss: 1.450    [weighted Loss:1.450    Policy Loss: 7.260    Value Loss: 4.711    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 66110      Buffer Size: 6249       Transition Number: 399.971 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:27:44,528][train][INFO][train.py>_log] ==> #552000     Total Loss: 0.690    [weighted Loss:0.690    Policy Loss: 7.466    Value Loss: 4.251    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 66301      Buffer Size: 6255       Transition Number: 399.987 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:33:50,959][train][INFO][train.py>_log] ==> #554000     Total Loss: 1.230    [weighted Loss:1.230    Policy Loss: 7.280    Value Loss: 4.423    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 66472      Buffer Size: 6280       Transition Number: 399.941 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:39:59,127][train][INFO][train.py>_log] ==> #556000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 7.883    Value Loss: 4.423    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 66659      Buffer Size: 6315       Transition Number: 399.932 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:46:10,120][train][INFO][train.py>_log] ==> #558000     Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 9.245    Value Loss: 4.748    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 66841      Buffer Size: 6344       Transition Number: 399.977 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:52:19,312][train][INFO][train.py>_log] ==> #560000     Total Loss: 1.300    [weighted Loss:1.300    Policy Loss: 7.999    Value Loss: 4.745    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 67025      Buffer Size: 6370       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-18 14:58:28,567][train][INFO][train.py>_log] ==> #562000     Total Loss: 1.785    [weighted Loss:1.785    Policy Loss: 8.346    Value Loss: 4.277    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 67199      Buffer Size: 6389       Transition Number: 399.932 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:04:37,101][train][INFO][train.py>_log] ==> #564000     Total Loss: 2.112    [weighted Loss:2.112    Policy Loss: 8.148    Value Loss: 4.545    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 67388      Buffer Size: 6405       Transition Number: 399.986 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:10:45,320][train][INFO][train.py>_log] ==> #566000     Total Loss: 0.885    [weighted Loss:0.885    Policy Loss: 7.415    Value Loss: 4.227    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 67556      Buffer Size: 6396       Transition Number: 399.990 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:16:50,664][train][INFO][train.py>_log] ==> #568000     Total Loss: 0.939    [weighted Loss:0.939    Policy Loss: 7.605    Value Loss: 4.269    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 67733      Buffer Size: 6394       Transition Number: 400.029 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:23:00,637][train][INFO][train.py>_log] ==> #570000     Total Loss: 1.720    [weighted Loss:1.720    Policy Loss: 8.033    Value Loss: 4.587    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 67906      Buffer Size: 6393       Transition Number: 399.935 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:29:09,813][train][INFO][train.py>_log] ==> #572000     Total Loss: 1.637    [weighted Loss:1.637    Policy Loss: 8.071    Value Loss: 4.496    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 68095      Buffer Size: 6407       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:35:17,389][train][INFO][train.py>_log] ==> #574000     Total Loss: 1.210    [weighted Loss:1.210    Policy Loss: 6.579    Value Loss: 4.320    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 68250      Buffer Size: 6403       Transition Number: 399.942 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:41:28,573][train][INFO][train.py>_log] ==> #576000     Total Loss: 0.851    [weighted Loss:0.851    Policy Loss: 6.677    Value Loss: 4.312    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 68442      Buffer Size: 6364       Transition Number: 399.964 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:47:39,727][train][INFO][train.py>_log] ==> #578000     Total Loss: 1.031    [weighted Loss:1.031    Policy Loss: 7.623    Value Loss: 4.241    Reward Loss: 0.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 68615      Buffer Size: 6314       Transition Number: 399.965 k Batch Size: 256        Lr: 0.100   
[2021-11-18 15:53:53,217][train][INFO][train.py>_log] ==> #580000     Total Loss: 1.132    [weighted Loss:1.132    Policy Loss: 6.780    Value Loss: 4.235    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 68793      Buffer Size: 6303       Transition Number: 399.993 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:00:01,740][train][INFO][train.py>_log] ==> #582000     Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 7.412    Value Loss: 4.384    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 68965      Buffer Size: 6308       Transition Number: 399.966 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:06:14,463][train][INFO][train.py>_log] ==> #584000     Total Loss: 0.533    [weighted Loss:0.533    Policy Loss: 7.184    Value Loss: 4.077    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 69174      Buffer Size: 6348       Transition Number: 399.944 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:12:28,031][train][INFO][train.py>_log] ==> #586000     Total Loss: 2.110    [weighted Loss:2.110    Policy Loss: 7.544    Value Loss: 4.552    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 69363      Buffer Size: 6371       Transition Number: 399.935 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:18:37,867][train][INFO][train.py>_log] ==> #588000     Total Loss: 1.301    [weighted Loss:1.301    Policy Loss: 7.937    Value Loss: 4.174    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 69547      Buffer Size: 6402       Transition Number: 399.950 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:24:50,554][train][INFO][train.py>_log] ==> #590000     Total Loss: 1.370    [weighted Loss:1.370    Policy Loss: 9.727    Value Loss: 4.500    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 69732      Buffer Size: 6432       Transition Number: 399.956 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:30:58,161][train][INFO][train.py>_log] ==> #592000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 8.113    Value Loss: 4.458    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 69920      Buffer Size: 6471       Transition Number: 399.929 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:37:05,564][train][INFO][train.py>_log] ==> #594000     Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 7.715    Value Loss: 4.663    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 70092      Buffer Size: 6488       Transition Number: 399.972 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:43:14,746][train][INFO][train.py>_log] ==> #596000     Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 8.485    Value Loss: 4.502    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 70280      Buffer Size: 6515       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:49:24,461][train][INFO][train.py>_log] ==> #598000     Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 8.657    Value Loss: 4.340    Reward Loss: 0.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 70461      Buffer Size: 6542       Transition Number: 400.014 k Batch Size: 256        Lr: 0.100   
[2021-11-18 16:55:30,550][train][INFO][train.py>_log] ==> #600000     Total Loss: 0.888    [weighted Loss:0.888    Policy Loss: 7.963    Value Loss: 4.161    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 70804      Buffer Size: 6736       Transition Number: 399.997 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:01:34,378][train][INFO][train.py>_log] ==> #602000     Total Loss: 0.492    [weighted Loss:0.492    Policy Loss: 8.113    Value Loss: 4.416    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 71084      Buffer Size: 6878       Transition Number: 399.940 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:07:44,296][train][INFO][train.py>_log] ==> #604000     Total Loss: 0.463    [weighted Loss:0.463    Policy Loss: 7.088    Value Loss: 4.242    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 71260      Buffer Size: 6896       Transition Number: 399.929 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:13:52,808][train][INFO][train.py>_log] ==> #606000     Total Loss: 0.715    [weighted Loss:0.715    Policy Loss: 7.579    Value Loss: 4.585    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 71443      Buffer Size: 6925       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:20:00,175][train][INFO][train.py>_log] ==> #608000     Total Loss: 1.190    [weighted Loss:1.190    Policy Loss: 7.323    Value Loss: 4.282    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 71615      Buffer Size: 6934       Transition Number: 399.951 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:26:11,979][train][INFO][train.py>_log] ==> #610000     Total Loss: 0.588    [weighted Loss:0.588    Policy Loss: 7.118    Value Loss: 4.576    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 71791      Buffer Size: 6937       Transition Number: 399.935 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:32:22,342][train][INFO][train.py>_log] ==> #612000     Total Loss: 0.931    [weighted Loss:0.931    Policy Loss: 7.954    Value Loss: 4.498    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 71975      Buffer Size: 6950       Transition Number: 399.928 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:38:31,634][train][INFO][train.py>_log] ==> #614000     Total Loss: 0.629    [weighted Loss:0.629    Policy Loss: 7.015    Value Loss: 4.440    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 72149      Buffer Size: 6974       Transition Number: 399.959 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:44:42,572][train][INFO][train.py>_log] ==> #616000     Total Loss: 1.067    [weighted Loss:1.067    Policy Loss: 7.632    Value Loss: 4.341    Reward Loss: 0.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 72322      Buffer Size: 6959       Transition Number: 399.976 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:50:53,507][train][INFO][train.py>_log] ==> #618000     Total Loss: 1.080    [weighted Loss:1.080    Policy Loss: 7.571    Value Loss: 4.705    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 72503      Buffer Size: 6962       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-18 17:57:03,528][train][INFO][train.py>_log] ==> #620000     Total Loss: 2.632    [weighted Loss:2.632    Policy Loss: 8.007    Value Loss: 4.660    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 72679      Buffer Size: 6973       Transition Number: 399.978 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:03:15,367][train][INFO][train.py>_log] ==> #622000     Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 7.548    Value Loss: 4.202    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 72849      Buffer Size: 6980       Transition Number: 399.962 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:09:26,857][train][INFO][train.py>_log] ==> #624000     Total Loss: 1.013    [weighted Loss:1.013    Policy Loss: 7.137    Value Loss: 4.430    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 73048      Buffer Size: 7004       Transition Number: 399.972 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:15:34,853][train][INFO][train.py>_log] ==> #626000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 7.635    Value Loss: 4.479    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 73235      Buffer Size: 7048       Transition Number: 399.959 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:21:49,362][train][INFO][train.py>_log] ==> #628000     Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 7.316    Value Loss: 4.404    Reward Loss: 0.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 73413      Buffer Size: 7050       Transition Number: 399.949 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:27:56,476][train][INFO][train.py>_log] ==> #630000     Total Loss: 0.992    [weighted Loss:0.992    Policy Loss: 8.226    Value Loss: 4.570    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 73583      Buffer Size: 7045       Transition Number: 399.953 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:34:05,458][train][INFO][train.py>_log] ==> #632000     Total Loss: 0.950    [weighted Loss:0.950    Policy Loss: 8.192    Value Loss: 4.490    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 73791      Buffer Size: 7077       Transition Number: 400.005 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:40:13,415][train][INFO][train.py>_log] ==> #634000     Total Loss: 0.809    [weighted Loss:0.809    Policy Loss: 7.348    Value Loss: 4.467    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 73975      Buffer Size: 7096       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:46:19,579][train][INFO][train.py>_log] ==> #636000     Total Loss: 1.510    [weighted Loss:1.510    Policy Loss: 7.465    Value Loss: 4.695    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 74155      Buffer Size: 7105       Transition Number: 399.937 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:52:26,126][train][INFO][train.py>_log] ==> #638000     Total Loss: 0.922    [weighted Loss:0.922    Policy Loss: 8.053    Value Loss: 4.688    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 74325      Buffer Size: 7095       Transition Number: 399.966 k Batch Size: 256        Lr: 0.100   
[2021-11-18 18:58:35,304][train][INFO][train.py>_log] ==> #640000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 8.038    Value Loss: 4.691    Reward Loss: 0.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 74502      Buffer Size: 7085       Transition Number: 399.927 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:04:43,956][train][INFO][train.py>_log] ==> #642000     Total Loss: 1.084    [weighted Loss:1.084    Policy Loss: 7.670    Value Loss: 4.321    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 74678      Buffer Size: 7095       Transition Number: 399.972 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:10:58,921][train][INFO][train.py>_log] ==> #644000     Total Loss: 0.673    [weighted Loss:0.673    Policy Loss: 8.361    Value Loss: 4.435    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 74862      Buffer Size: 7098       Transition Number: 399.942 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:17:10,557][train][INFO][train.py>_log] ==> #646000     Total Loss: 1.388    [weighted Loss:1.388    Policy Loss: 7.850    Value Loss: 4.588    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 75043      Buffer Size: 7109       Transition Number: 399.962 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:23:12,924][train][INFO][train.py>_log] ==> #648000     Total Loss: 1.021    [weighted Loss:1.021    Policy Loss: 8.521    Value Loss: 4.472    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 75222      Buffer Size: 7116       Transition Number: 399.932 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:29:21,498][train][INFO][train.py>_log] ==> #650000     Total Loss: 1.399    [weighted Loss:1.399    Policy Loss: 7.366    Value Loss: 4.635    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 75398      Buffer Size: 7138       Transition Number: 400.124 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:35:33,796][train][INFO][train.py>_log] ==> #652000     Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 7.962    Value Loss: 4.369    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 75573      Buffer Size: 7158       Transition Number: 399.947 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:41:43,881][train][INFO][train.py>_log] ==> #654000     Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 7.005    Value Loss: 4.333    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 75741      Buffer Size: 7165       Transition Number: 399.933 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:47:54,969][train][INFO][train.py>_log] ==> #656000     Total Loss: 0.926    [weighted Loss:0.926    Policy Loss: 8.375    Value Loss: 4.759    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 75922      Buffer Size: 7177       Transition Number: 399.940 k Batch Size: 256        Lr: 0.100   
[2021-11-18 19:54:04,034][train][INFO][train.py>_log] ==> #658000     Total Loss: 0.619    [weighted Loss:0.619    Policy Loss: 8.108    Value Loss: 4.523    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 76102      Buffer Size: 7208       Transition Number: 399.958 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:00:08,642][train][INFO][train.py>_log] ==> #660000     Total Loss: 1.280    [weighted Loss:1.280    Policy Loss: 8.738    Value Loss: 4.598    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 76304      Buffer Size: 7219       Transition Number: 399.972 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:06:11,461][train][INFO][train.py>_log] ==> #662000     Total Loss: 1.105    [weighted Loss:1.105    Policy Loss: 9.266    Value Loss: 4.672    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 76487      Buffer Size: 7208       Transition Number: 399.963 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:12:11,878][train][INFO][train.py>_log] ==> #664000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 8.852    Value Loss: 4.668    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 76701      Buffer Size: 7246       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:18:15,570][train][INFO][train.py>_log] ==> #666000     Total Loss: 1.671    [weighted Loss:1.671    Policy Loss: 9.737    Value Loss: 4.659    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 76909      Buffer Size: 7286       Transition Number: 399.954 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:24:19,867][train][INFO][train.py>_log] ==> #668000     Total Loss: 0.925    [weighted Loss:0.925    Policy Loss: 8.380    Value Loss: 4.457    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 77092      Buffer Size: 7299       Transition Number: 399.981 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:30:28,641][train][INFO][train.py>_log] ==> #670000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 7.343    Value Loss: 4.913    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 77263      Buffer Size: 7285       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:36:31,568][train][INFO][train.py>_log] ==> #672000     Total Loss: 0.940    [weighted Loss:0.940    Policy Loss: 7.141    Value Loss: 4.376    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 77446      Buffer Size: 7298       Transition Number: 400.064 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:42:33,664][train][INFO][train.py>_log] ==> #674000     Total Loss: 1.244    [weighted Loss:1.244    Policy Loss: 8.030    Value Loss: 4.456    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 77628      Buffer Size: 7305       Transition Number: 399.961 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:48:39,350][train][INFO][train.py>_log] ==> #676000     Total Loss: 1.200    [weighted Loss:1.200    Policy Loss: 7.009    Value Loss: 4.560    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 77790      Buffer Size: 7255       Transition Number: 399.988 k Batch Size: 256        Lr: 0.100   
[2021-11-18 20:54:47,916][train][INFO][train.py>_log] ==> #678000     Total Loss: 0.441    [weighted Loss:0.441    Policy Loss: 7.452    Value Loss: 4.361    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 77962      Buffer Size: 7039       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:00:58,795][train][INFO][train.py>_log] ==> #680000     Total Loss: 0.949    [weighted Loss:0.949    Policy Loss: 8.444    Value Loss: 4.952    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 78158      Buffer Size: 6988       Transition Number: 399.964 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:07:10,143][train][INFO][train.py>_log] ==> #682000     Total Loss: 1.286    [weighted Loss:1.286    Policy Loss: 7.841    Value Loss: 4.859    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 78339      Buffer Size: 7015       Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:13:14,430][train][INFO][train.py>_log] ==> #684000     Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 6.925    Value Loss: 4.584    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 78519      Buffer Size: 7021       Transition Number: 399.985 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:19:22,479][train][INFO][train.py>_log] ==> #686000     Total Loss: 0.943    [weighted Loss:0.943    Policy Loss: 7.859    Value Loss: 4.812    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 78711      Buffer Size: 7051       Transition Number: 399.934 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:25:30,835][train][INFO][train.py>_log] ==> #688000     Total Loss: 1.024    [weighted Loss:1.024    Policy Loss: 9.545    Value Loss: 4.494    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 78941      Buffer Size: 7117       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:31:32,706][train][INFO][train.py>_log] ==> #690000     Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 8.932    Value Loss: 4.448    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 79136      Buffer Size: 7152       Transition Number: 399.950 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:37:35,330][train][INFO][train.py>_log] ==> #692000     Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 9.142    Value Loss: 4.653    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 79335      Buffer Size: 7187       Transition Number: 399.930 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:43:41,743][train][INFO][train.py>_log] ==> #694000     Total Loss: 0.788    [weighted Loss:0.788    Policy Loss: 9.539    Value Loss: 4.545    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 79523      Buffer Size: 7228       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:49:45,784][train][INFO][train.py>_log] ==> #696000     Total Loss: 1.832    [weighted Loss:1.832    Policy Loss: 9.159    Value Loss: 4.697    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 79707      Buffer Size: 7249       Transition Number: 399.988 k Batch Size: 256        Lr: 0.100   
[2021-11-18 21:55:54,516][train][INFO][train.py>_log] ==> #698000     Total Loss: 0.253    [weighted Loss:0.253    Policy Loss: 9.092    Value Loss: 4.487    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 79896      Buffer Size: 7281       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:01:59,486][train][INFO][train.py>_log] ==> #700000     Total Loss: 0.887    [weighted Loss:0.887    Policy Loss: 8.609    Value Loss: 4.580    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 80084      Buffer Size: 7321       Transition Number: 399.968 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:08:14,292][train][INFO][train.py>_log] ==> #702000     Total Loss: 1.285    [weighted Loss:1.285    Policy Loss: 9.458    Value Loss: 4.754    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 80278      Buffer Size: 7358       Transition Number: 399.975 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:14:23,412][train][INFO][train.py>_log] ==> #704000     Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 7.774    Value Loss: 4.702    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 80542      Buffer Size: 7439       Transition Number: 399.966 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:20:33,113][train][INFO][train.py>_log] ==> #706000     Total Loss: 1.670    [weighted Loss:1.670    Policy Loss: 9.449    Value Loss: 4.687    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 80752      Buffer Size: 7470       Transition Number: 399.978 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:26:43,144][train][INFO][train.py>_log] ==> #708000     Total Loss: 0.448    [weighted Loss:0.448    Policy Loss: 10.808   Value Loss: 4.976    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 81018      Buffer Size: 7570       Transition Number: 399.997 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:32:48,292][train][INFO][train.py>_log] ==> #710000     Total Loss: 1.170    [weighted Loss:1.170    Policy Loss: 9.783    Value Loss: 4.581    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 81199      Buffer Size: 7599       Transition Number: 399.998 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:38:52,906][train][INFO][train.py>_log] ==> #712000     Total Loss: 1.199    [weighted Loss:1.199    Policy Loss: 8.816    Value Loss: 4.743    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 81383      Buffer Size: 7579       Transition Number: 400.050 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:45:04,010][train][INFO][train.py>_log] ==> #714000     Total Loss: 1.060    [weighted Loss:1.060    Policy Loss: 8.743    Value Loss: 4.636    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 81575      Buffer Size: 7578       Transition Number: 399.971 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:51:10,469][train][INFO][train.py>_log] ==> #716000     Total Loss: 0.766    [weighted Loss:0.766    Policy Loss: 7.962    Value Loss: 4.841    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 81751      Buffer Size: 7572       Transition Number: 399.954 k Batch Size: 256        Lr: 0.100   
[2021-11-18 22:57:19,954][train][INFO][train.py>_log] ==> #718000     Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 8.547    Value Loss: 4.875    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 81921      Buffer Size: 7583       Transition Number: 400.000 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:03:28,579][train][INFO][train.py>_log] ==> #720000     Total Loss: 0.552    [weighted Loss:0.552    Policy Loss: 8.877    Value Loss: 4.902    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 82111      Buffer Size: 7599       Transition Number: 399.980 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:09:39,502][train][INFO][train.py>_log] ==> #722000     Total Loss: 0.793    [weighted Loss:0.793    Policy Loss: 8.237    Value Loss: 4.741    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 82274      Buffer Size: 7602       Transition Number: 399.965 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:15:51,648][train][INFO][train.py>_log] ==> #724000     Total Loss: 0.536    [weighted Loss:0.536    Policy Loss: 8.260    Value Loss: 4.812    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 82449      Buffer Size: 7600       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:22:08,169][train][INFO][train.py>_log] ==> #726000     Total Loss: 1.005    [weighted Loss:1.005    Policy Loss: 9.106    Value Loss: 5.096    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 82623      Buffer Size: 7586       Transition Number: 399.984 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:28:17,744][train][INFO][train.py>_log] ==> #728000     Total Loss: 1.139    [weighted Loss:1.139    Policy Loss: 6.582    Value Loss: 4.593    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 82805      Buffer Size: 7569       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:34:31,655][train][INFO][train.py>_log] ==> #730000     Total Loss: 1.271    [weighted Loss:1.271    Policy Loss: 7.478    Value Loss: 4.846    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 82979      Buffer Size: 7542       Transition Number: 399.972 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:40:39,018][train][INFO][train.py>_log] ==> #732000     Total Loss: 0.896    [weighted Loss:0.896    Policy Loss: 7.193    Value Loss: 4.586    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 83154      Buffer Size: 7519       Transition Number: 400.044 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:46:50,374][train][INFO][train.py>_log] ==> #734000     Total Loss: 1.239    [weighted Loss:1.239    Policy Loss: 7.706    Value Loss: 4.626    Reward Loss: 0.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 83334      Buffer Size: 7527       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:53:07,138][train][INFO][train.py>_log] ==> #736000     Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 7.637    Value Loss: 4.731    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 83535      Buffer Size: 7531       Transition Number: 399.965 k Batch Size: 256        Lr: 0.100   
[2021-11-18 23:59:14,732][train][INFO][train.py>_log] ==> #738000     Total Loss: 0.662    [weighted Loss:0.662    Policy Loss: 8.082    Value Loss: 4.846    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 83716      Buffer Size: 7535       Transition Number: 399.977 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:05:23,225][train][INFO][train.py>_log] ==> #740000     Total Loss: 1.450    [weighted Loss:1.450    Policy Loss: 7.405    Value Loss: 4.851    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 83896      Buffer Size: 7519       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:11:26,604][train][INFO][train.py>_log] ==> #742000     Total Loss: 0.743    [weighted Loss:0.743    Policy Loss: 8.163    Value Loss: 5.053    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 84069      Buffer Size: 7496       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:17:30,700][train][INFO][train.py>_log] ==> #744000     Total Loss: 0.494    [weighted Loss:0.494    Policy Loss: 7.891    Value Loss: 4.731    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 84257      Buffer Size: 7460       Transition Number: 399.980 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:23:43,165][train][INFO][train.py>_log] ==> #746000     Total Loss: 0.345    [weighted Loss:0.345    Policy Loss: 7.691    Value Loss: 4.947    Reward Loss: 0.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 84443      Buffer Size: 7445       Transition Number: 399.985 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:29:54,789][train][INFO][train.py>_log] ==> #748000     Total Loss: 1.154    [weighted Loss:1.154    Policy Loss: 6.541    Value Loss: 4.660    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 84616      Buffer Size: 7436       Transition Number: 400.184 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:36:10,514][train][INFO][train.py>_log] ==> #750000     Total Loss: 0.383    [weighted Loss:0.383    Policy Loss: 6.403    Value Loss: 4.717    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 84783      Buffer Size: 7416       Transition Number: 399.955 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:42:23,284][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 6.708    Value Loss: 4.978    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 84966      Buffer Size: 7395       Transition Number: 400.063 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:48:32,374][train][INFO][train.py>_log] ==> #754000     Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 7.489    Value Loss: 4.967    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 85145      Buffer Size: 7404       Transition Number: 399.957 k Batch Size: 256        Lr: 0.100   
[2021-11-19 00:54:40,944][train][INFO][train.py>_log] ==> #756000     Total Loss: 1.388    [weighted Loss:1.388    Policy Loss: 8.062    Value Loss: 4.777    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 85327      Buffer Size: 7423       Transition Number: 399.934 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:00:57,395][train][INFO][train.py>_log] ==> #758000     Total Loss: 1.238    [weighted Loss:1.238    Policy Loss: 8.306    Value Loss: 4.831    Reward Loss: 0.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 85499      Buffer Size: 7405       Transition Number: 399.948 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:07:15,229][train][INFO][train.py>_log] ==> #760000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 8.382    Value Loss: 4.647    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 85700      Buffer Size: 7407       Transition Number: 399.997 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:13:24,706][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 8.742    Value Loss: 4.536    Reward Loss: 0.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 85889      Buffer Size: 7421       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:19:32,336][train][INFO][train.py>_log] ==> #764000     Total Loss: 1.994    [weighted Loss:1.994    Policy Loss: 7.961    Value Loss: 4.932    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 86069      Buffer Size: 7416       Transition Number: 399.973 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:25:45,376][train][INFO][train.py>_log] ==> #766000     Total Loss: 0.347    [weighted Loss:0.347    Policy Loss: 7.218    Value Loss: 4.645    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 86250      Buffer Size: 7367       Transition Number: 399.979 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:31:59,634][train][INFO][train.py>_log] ==> #768000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 7.805    Value Loss: 5.003    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 86477      Buffer Size: 7376       Transition Number: 399.955 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:38:08,348][train][INFO][train.py>_log] ==> #770000     Total Loss: 0.548    [weighted Loss:0.548    Policy Loss: 7.264    Value Loss: 4.786    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 86688      Buffer Size: 7389       Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:44:22,091][train][INFO][train.py>_log] ==> #772000     Total Loss: 0.454    [weighted Loss:0.454    Policy Loss: 7.713    Value Loss: 4.415    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 86902      Buffer Size: 7411       Transition Number: 399.953 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:50:26,202][train][INFO][train.py>_log] ==> #774000     Total Loss: 1.033    [weighted Loss:1.033    Policy Loss: 6.414    Value Loss: 4.945    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 87091      Buffer Size: 7424       Transition Number: 399.992 k Batch Size: 256        Lr: 0.100   
[2021-11-19 01:56:37,858][train][INFO][train.py>_log] ==> #776000     Total Loss: 1.127    [weighted Loss:1.127    Policy Loss: 6.602    Value Loss: 4.828    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 87277      Buffer Size: 7423       Transition Number: 400.074 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:02:52,934][train][INFO][train.py>_log] ==> #778000     Total Loss: 0.670    [weighted Loss:0.670    Policy Loss: 6.450    Value Loss: 4.771    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 87465      Buffer Size: 7409       Transition Number: 399.971 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:09:06,485][train][INFO][train.py>_log] ==> #780000     Total Loss: 1.099    [weighted Loss:1.099    Policy Loss: 7.635    Value Loss: 4.845    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 87645      Buffer Size: 7393       Transition Number: 399.980 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:15:14,297][train][INFO][train.py>_log] ==> #782000     Total Loss: 0.613    [weighted Loss:0.613    Policy Loss: 7.085    Value Loss: 4.653    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 87825      Buffer Size: 7336       Transition Number: 399.989 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:21:21,537][train][INFO][train.py>_log] ==> #784000     Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 6.992    Value Loss: 4.673    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 88031      Buffer Size: 7327       Transition Number: 399.967 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:27:27,594][train][INFO][train.py>_log] ==> #786000     Total Loss: 0.613    [weighted Loss:0.613    Policy Loss: 6.614    Value Loss: 4.871    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 88211      Buffer Size: 7272       Transition Number: 399.986 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:33:38,828][train][INFO][train.py>_log] ==> #788000     Total Loss: 1.285    [weighted Loss:1.285    Policy Loss: 7.734    Value Loss: 4.548    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 88471      Buffer Size: 7314       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:39:46,978][train][INFO][train.py>_log] ==> #790000     Total Loss: 1.202    [weighted Loss:1.202    Policy Loss: 6.793    Value Loss: 4.677    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 88673      Buffer Size: 7338       Transition Number: 399.999 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:45:58,209][train][INFO][train.py>_log] ==> #792000     Total Loss: 1.487    [weighted Loss:1.487    Policy Loss: 6.680    Value Loss: 4.522    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 88867      Buffer Size: 7353       Transition Number: 399.938 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:52:07,679][train][INFO][train.py>_log] ==> #794000     Total Loss: 0.701    [weighted Loss:0.701    Policy Loss: 7.336    Value Loss: 4.901    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 89060      Buffer Size: 7369       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-19 02:58:20,559][train][INFO][train.py>_log] ==> #796000     Total Loss: 0.635    [weighted Loss:0.635    Policy Loss: 7.772    Value Loss: 4.847    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 89290      Buffer Size: 7423       Transition Number: 399.972 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:04:27,398][train][INFO][train.py>_log] ==> #798000     Total Loss: 1.319    [weighted Loss:1.319    Policy Loss: 6.860    Value Loss: 4.930    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 89509      Buffer Size: 7479       Transition Number: 399.978 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:10:37,104][train][INFO][train.py>_log] ==> #800000     Total Loss: 1.224    [weighted Loss:1.224    Policy Loss: 7.790    Value Loss: 4.666    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 89713      Buffer Size: 7515       Transition Number: 399.978 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:16:50,710][train][INFO][train.py>_log] ==> #802000     Total Loss: 0.886    [weighted Loss:0.886    Policy Loss: 7.059    Value Loss: 4.764    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 89888      Buffer Size: 7541       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:23:06,241][train][INFO][train.py>_log] ==> #804000     Total Loss: 0.663    [weighted Loss:0.663    Policy Loss: 5.556    Value Loss: 4.968    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 90084      Buffer Size: 7564       Transition Number: 399.968 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:29:23,890][train][INFO][train.py>_log] ==> #806000     Total Loss: 0.215    [weighted Loss:0.215    Policy Loss: 6.695    Value Loss: 4.877    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 90255      Buffer Size: 7583       Transition Number: 399.987 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:35:37,317][train][INFO][train.py>_log] ==> #808000     Total Loss: 0.348    [weighted Loss:0.348    Policy Loss: 6.750    Value Loss: 4.995    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 90437      Buffer Size: 7603       Transition Number: 399.983 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:41:55,808][train][INFO][train.py>_log] ==> #810000     Total Loss: 0.844    [weighted Loss:0.844    Policy Loss: 5.781    Value Loss: 4.791    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 90642      Buffer Size: 7652       Transition Number: 399.933 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:48:07,445][train][INFO][train.py>_log] ==> #812000     Total Loss: 0.459    [weighted Loss:0.459    Policy Loss: 8.168    Value Loss: 4.730    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 90855      Buffer Size: 7711       Transition Number: 399.995 k Batch Size: 256        Lr: 0.100   
[2021-11-19 03:54:22,715][train][INFO][train.py>_log] ==> #814000     Total Loss: 0.488    [weighted Loss:0.488    Policy Loss: 5.694    Value Loss: 5.009    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 91039      Buffer Size: 7720       Transition Number: 399.934 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:00:37,065][train][INFO][train.py>_log] ==> #816000     Total Loss: 0.449    [weighted Loss:0.449    Policy Loss: 5.446    Value Loss: 4.834    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 91204      Buffer Size: 7695       Transition Number: 399.955 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:06:55,355][train][INFO][train.py>_log] ==> #818000     Total Loss: 0.944    [weighted Loss:0.944    Policy Loss: 5.324    Value Loss: 4.840    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 91378      Buffer Size: 7660       Transition Number: 399.996 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:13:09,835][train][INFO][train.py>_log] ==> #820000     Total Loss: 0.349    [weighted Loss:0.349    Policy Loss: 5.066    Value Loss: 4.907    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 91549      Buffer Size: 7637       Transition Number: 399.958 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:19:24,785][train][INFO][train.py>_log] ==> #822000     Total Loss: 0.095    [weighted Loss:0.095    Policy Loss: 5.335    Value Loss: 4.913    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 91718      Buffer Size: 7618       Transition Number: 399.998 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:25:34,709][train][INFO][train.py>_log] ==> #824000     Total Loss: 0.563    [weighted Loss:0.563    Policy Loss: 5.462    Value Loss: 4.868    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 91905      Buffer Size: 7610       Transition Number: 399.942 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:31:56,063][train][INFO][train.py>_log] ==> #826000     Total Loss: 0.680    [weighted Loss:0.680    Policy Loss: 4.335    Value Loss: 4.973    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 92078      Buffer Size: 7592       Transition Number: 399.982 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:38:17,929][train][INFO][train.py>_log] ==> #828000     Total Loss: 0.328    [weighted Loss:0.328    Policy Loss: 3.618    Value Loss: 5.173    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 92255      Buffer Size: 7587       Transition Number: 399.974 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:44:39,480][train][INFO][train.py>_log] ==> #830000     Total Loss: 0.440    [weighted Loss:0.440    Policy Loss: 4.093    Value Loss: 4.959    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 92432      Buffer Size: 7586       Transition Number: 399.967 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:51:06,242][train][INFO][train.py>_log] ==> #832000     Total Loss: 1.054    [weighted Loss:1.054    Policy Loss: 3.932    Value Loss: 4.557    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 92634      Buffer Size: 7570       Transition Number: 399.929 k Batch Size: 256        Lr: 0.100   
[2021-11-19 04:57:33,845][train][INFO][train.py>_log] ==> #834000     Total Loss: 0.806    [weighted Loss:0.806    Policy Loss: 3.630    Value Loss: 5.214    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 92818      Buffer Size: 7538       Transition Number: 399.985 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:03:54,830][train][INFO][train.py>_log] ==> #836000     Total Loss: 0.311    [weighted Loss:0.311    Policy Loss: 4.581    Value Loss: 4.886    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 92993      Buffer Size: 7525       Transition Number: 399.991 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:10:13,148][train][INFO][train.py>_log] ==> #838000     Total Loss: 1.362    [weighted Loss:1.362    Policy Loss: 4.370    Value Loss: 4.869    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 93162      Buffer Size: 7492       Transition Number: 399.981 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:16:34,904][train][INFO][train.py>_log] ==> #840000     Total Loss: 0.384    [weighted Loss:0.384    Policy Loss: 4.337    Value Loss: 4.983    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 93339      Buffer Size: 7439       Transition Number: 399.984 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:22:54,349][train][INFO][train.py>_log] ==> #842000     Total Loss: 0.409    [weighted Loss:0.409    Policy Loss: 4.449    Value Loss: 4.459    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 93523      Buffer Size: 7416       Transition Number: 399.930 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:29:19,356][train][INFO][train.py>_log] ==> #844000     Total Loss: 0.544    [weighted Loss:0.544    Policy Loss: 3.967    Value Loss: 5.022    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 93723      Buffer Size: 7418       Transition Number: 399.941 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:35:40,945][train][INFO][train.py>_log] ==> #846000     Total Loss: 0.692    [weighted Loss:0.692    Policy Loss: 4.492    Value Loss: 5.012    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 93905      Buffer Size: 7372       Transition Number: 399.931 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:42:05,979][train][INFO][train.py>_log] ==> #848000     Total Loss: 0.304    [weighted Loss:0.304    Policy Loss: 3.519    Value Loss: 5.022    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 94080      Buffer Size: 7291       Transition Number: 399.991 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:48:28,141][train][INFO][train.py>_log] ==> #850000     Total Loss: 0.320    [weighted Loss:0.320    Policy Loss: 3.837    Value Loss: 4.946    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 94268      Buffer Size: 7200       Transition Number: 399.974 k Batch Size: 256        Lr: 0.100   
[2021-11-19 05:54:45,219][train][INFO][train.py>_log] ==> #852000     Total Loss: 0.746    [weighted Loss:0.746    Policy Loss: 4.089    Value Loss: 4.883    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 94445      Buffer Size: 7151       Transition Number: 399.962 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:01:03,698][train][INFO][train.py>_log] ==> #854000     Total Loss: 0.821    [weighted Loss:0.821    Policy Loss: 5.367    Value Loss: 4.759    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 94628      Buffer Size: 7128       Transition Number: 399.986 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:07:21,083][train][INFO][train.py>_log] ==> #856000     Total Loss: 0.448    [weighted Loss:0.448    Policy Loss: 4.436    Value Loss: 5.239    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 94798      Buffer Size: 7092       Transition Number: 399.944 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:13:43,215][train][INFO][train.py>_log] ==> #858000     Total Loss: 0.532    [weighted Loss:0.532    Policy Loss: 4.141    Value Loss: 4.683    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 94974      Buffer Size: 7031       Transition Number: 399.949 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:19:59,447][train][INFO][train.py>_log] ==> #860000     Total Loss: 0.554    [weighted Loss:0.554    Policy Loss: 4.959    Value Loss: 4.560    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 95166      Buffer Size: 6986       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:26:18,215][train][INFO][train.py>_log] ==> #862000     Total Loss: 0.448    [weighted Loss:0.448    Policy Loss: 5.512    Value Loss: 4.687    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 95340      Buffer Size: 6883       Transition Number: 400.000 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:32:34,999][train][INFO][train.py>_log] ==> #864000     Total Loss: 1.478    [weighted Loss:1.478    Policy Loss: 5.056    Value Loss: 4.815    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 95523      Buffer Size: 6814       Transition Number: 399.940 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:38:54,675][train][INFO][train.py>_log] ==> #866000     Total Loss: 0.435    [weighted Loss:0.435    Policy Loss: 4.303    Value Loss: 4.635    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 95703      Buffer Size: 6769       Transition Number: 399.997 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:45:11,299][train][INFO][train.py>_log] ==> #868000     Total Loss: 0.596    [weighted Loss:0.596    Policy Loss: 4.276    Value Loss: 4.560    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 95882      Buffer Size: 6699       Transition Number: 399.943 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:51:31,896][train][INFO][train.py>_log] ==> #870000     Total Loss: 0.398    [weighted Loss:0.398    Policy Loss: 3.785    Value Loss: 4.687    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 96069      Buffer Size: 6588       Transition Number: 399.961 k Batch Size: 256        Lr: 0.100   
[2021-11-19 06:57:48,131][train][INFO][train.py>_log] ==> #872000     Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 4.789    Value Loss: 4.733    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 96246      Buffer Size: 6512       Transition Number: 399.974 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:04:04,663][train][INFO][train.py>_log] ==> #874000     Total Loss: 0.867    [weighted Loss:0.867    Policy Loss: 6.388    Value Loss: 4.916    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 96472      Buffer Size: 6546       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:10:16,166][train][INFO][train.py>_log] ==> #876000     Total Loss: 0.325    [weighted Loss:0.325    Policy Loss: 6.614    Value Loss: 5.328    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 96655      Buffer Size: 6550       Transition Number: 399.946 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:16:27,874][train][INFO][train.py>_log] ==> #878000     Total Loss: 0.910    [weighted Loss:0.910    Policy Loss: 6.387    Value Loss: 4.600    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 96844      Buffer Size: 6562       Transition Number: 399.941 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:22:42,038][train][INFO][train.py>_log] ==> #880000     Total Loss: 0.663    [weighted Loss:0.663    Policy Loss: 6.611    Value Loss: 4.858    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 97022      Buffer Size: 6567       Transition Number: 399.995 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:28:57,637][train][INFO][train.py>_log] ==> #882000     Total Loss: 1.132    [weighted Loss:1.132    Policy Loss: 6.000    Value Loss: 4.729    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 97200      Buffer Size: 6517       Transition Number: 400.040 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:35:11,591][train][INFO][train.py>_log] ==> #884000     Total Loss: 0.527    [weighted Loss:0.527    Policy Loss: 7.306    Value Loss: 4.978    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 97382      Buffer Size: 6466       Transition Number: 399.952 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:41:22,689][train][INFO][train.py>_log] ==> #886000     Total Loss: 0.327    [weighted Loss:0.327    Policy Loss: 5.637    Value Loss: 4.634    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 97561      Buffer Size: 6464       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:47:32,185][train][INFO][train.py>_log] ==> #888000     Total Loss: 0.467    [weighted Loss:0.467    Policy Loss: 6.192    Value Loss: 4.773    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 97765      Buffer Size: 6506       Transition Number: 399.939 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:53:42,266][train][INFO][train.py>_log] ==> #890000     Total Loss: 0.234    [weighted Loss:0.234    Policy Loss: 5.309    Value Loss: 4.805    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 97947      Buffer Size: 6538       Transition Number: 399.960 k Batch Size: 256        Lr: 0.100   
[2021-11-19 07:59:55,046][train][INFO][train.py>_log] ==> #892000     Total Loss: 0.455    [weighted Loss:0.455    Policy Loss: 5.913    Value Loss: 4.733    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 98144      Buffer Size: 6566       Transition Number: 399.970 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:06:06,548][train][INFO][train.py>_log] ==> #894000     Total Loss: 0.349    [weighted Loss:0.349    Policy Loss: 5.323    Value Loss: 4.923    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 98322      Buffer Size: 6582       Transition Number: 399.943 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:12:23,815][train][INFO][train.py>_log] ==> #896000     Total Loss: 0.638    [weighted Loss:0.638    Policy Loss: 4.769    Value Loss: 4.862    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 98501      Buffer Size: 6566       Transition Number: 400.013 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:18:42,507][train][INFO][train.py>_log] ==> #898000     Total Loss: 0.471    [weighted Loss:0.471    Policy Loss: 4.295    Value Loss: 5.186    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 98672      Buffer Size: 6554       Transition Number: 399.943 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:24:56,997][train][INFO][train.py>_log] ==> #900000     Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 6.556    Value Loss: 4.751    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 98892      Buffer Size: 6608       Transition Number: 400.062 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:31:15,219][train][INFO][train.py>_log] ==> #902000     Total Loss: 0.350    [weighted Loss:0.350    Policy Loss: 5.031    Value Loss: 4.723    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 99079      Buffer Size: 6620       Transition Number: 399.995 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:37:35,036][train][INFO][train.py>_log] ==> #904000     Total Loss: 0.678    [weighted Loss:0.678    Policy Loss: 5.227    Value Loss: 4.748    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 99258      Buffer Size: 6616       Transition Number: 399.946 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:43:50,888][train][INFO][train.py>_log] ==> #906000     Total Loss: 0.776    [weighted Loss:0.776    Policy Loss: 5.480    Value Loss: 4.691    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 99436      Buffer Size: 6620       Transition Number: 399.938 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:50:02,990][train][INFO][train.py>_log] ==> #908000     Total Loss: 0.299    [weighted Loss:0.299    Policy Loss: 4.514    Value Loss: 5.075    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 99632      Buffer Size: 6645       Transition Number: 399.949 k Batch Size: 256        Lr: 0.100   
[2021-11-19 08:56:18,870][train][INFO][train.py>_log] ==> #910000     Total Loss: 1.047    [weighted Loss:1.047    Policy Loss: 4.136    Value Loss: 4.770    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 99805      Buffer Size: 6651       Transition Number: 399.948 k Batch Size: 256        Lr: 0.100   
[2021-11-19 09:02:36,606][train][INFO][train.py>_log] ==> #912000     Total Loss: 0.479    [weighted Loss:0.479    Policy Loss: 5.426    Value Loss: 4.817    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 99980      Buffer Size: 6658       Transition Number: 399.994 k Batch Size: 256        Lr: 0.100   
