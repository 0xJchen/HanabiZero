[2021-11-09 14:27:00,164][train][INFO][train.py>_log] ==> #0          Total Loss: 42.987   [weighted Loss:42.987   Policy Loss: 12.990   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 52         Buffer Size: 52         Transition Number: 0.551   k Batch Size: 128        Lr: 0.000   
[2021-11-09 14:29:27,377][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.213    [weighted Loss:4.213    Policy Loss: 14.183   Value Loss: 5.171    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 486        Buffer Size: 486        Transition Number: 5.790   k Batch Size: 128        Lr: 0.010   
[2021-11-09 14:32:35,215][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.210    [weighted Loss:6.210    Policy Loss: 13.730   Value Loss: 3.372    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 1161       Buffer Size: 1161       Transition Number: 12.070  k Batch Size: 128        Lr: 0.020   
[2021-11-09 14:36:07,862][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.744    [weighted Loss:5.744    Policy Loss: 13.532   Value Loss: 3.004    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1842       Buffer Size: 1842       Transition Number: 19.063  k Batch Size: 128        Lr: 0.030   
[2021-11-09 14:39:46,214][train][INFO][train.py>_log] ==> #4000       Total Loss: 7.257    [weighted Loss:7.257    Policy Loss: 13.963   Value Loss: 3.327    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 2427       Buffer Size: 2427       Transition Number: 26.080  k Batch Size: 128        Lr: 0.040   
[2021-11-09 14:43:25,710][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.210    [weighted Loss:4.210    Policy Loss: 11.883   Value Loss: 2.698    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 3444       Buffer Size: 3444       Transition Number: 33.405  k Batch Size: 128        Lr: 0.050   
[2021-11-09 14:47:10,585][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.390    [weighted Loss:5.390    Policy Loss: 13.206   Value Loss: 2.759    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 4053       Buffer Size: 4053       Transition Number: 40.634  k Batch Size: 128        Lr: 0.060   
[2021-11-09 14:50:51,425][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.396    [weighted Loss:5.396    Policy Loss: 14.864   Value Loss: 3.077    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 4653       Buffer Size: 4653       Transition Number: 47.849  k Batch Size: 128        Lr: 0.070   
[2021-11-09 14:54:38,513][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.522    [weighted Loss:5.522    Policy Loss: 14.067   Value Loss: 2.836    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 5255       Buffer Size: 5255       Transition Number: 55.023  k Batch Size: 128        Lr: 0.080   
[2021-11-09 14:58:39,392][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.429    [weighted Loss:4.429    Policy Loss: 13.208   Value Loss: 2.915    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 6019       Buffer Size: 6019       Transition Number: 62.912  k Batch Size: 128        Lr: 0.090   
[2021-11-09 15:02:34,426][train][INFO][train.py>_log] ==> #10000      Total Loss: 7.119    [weighted Loss:7.119    Policy Loss: 12.336   Value Loss: 3.112    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 6896       Buffer Size: 6896       Transition Number: 70.789  k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:06:29,680][train][INFO][train.py>_log] ==> #11000      Total Loss: 6.171    [weighted Loss:6.171    Policy Loss: 10.916   Value Loss: 2.892    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 7779       Buffer Size: 7779       Transition Number: 78.654  k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:10:22,938][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.066    [weighted Loss:5.066    Policy Loss: 11.452   Value Loss: 2.905    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 8697       Buffer Size: 8697       Transition Number: 86.304  k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:14:10,644][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.797    [weighted Loss:5.797    Policy Loss: 13.084   Value Loss: 2.614    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 9536       Buffer Size: 9536       Transition Number: 93.890  k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:17:56,834][train][INFO][train.py>_log] ==> #14000      Total Loss: 6.328    [weighted Loss:6.328    Policy Loss: 13.247   Value Loss: 2.850    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 10280      Buffer Size: 10280      Transition Number: 101.154 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:21:47,691][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.230    [weighted Loss:5.230    Policy Loss: 11.709   Value Loss: 2.587    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 10970      Buffer Size: 10970      Transition Number: 108.436 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:25:34,757][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.762    [weighted Loss:3.762    Policy Loss: 13.556   Value Loss: 2.720    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 11635      Buffer Size: 11635      Transition Number: 115.743 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:29:35,506][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.348    [weighted Loss:4.348    Policy Loss: 12.238   Value Loss: 2.827    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 12370      Buffer Size: 12370      Transition Number: 123.474 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:33:29,857][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.480    [weighted Loss:4.480    Policy Loss: 12.964   Value Loss: 2.867    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 13058      Buffer Size: 13058      Transition Number: 131.022 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:37:26,114][train][INFO][train.py>_log] ==> #19000      Total Loss: 5.928    [weighted Loss:5.928    Policy Loss: 13.152   Value Loss: 2.803    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 13719      Buffer Size: 13719      Transition Number: 138.402 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:41:32,673][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 13.307   Value Loss: 2.813    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 14591      Buffer Size: 14591      Transition Number: 146.459 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:45:31,226][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.633    [weighted Loss:4.633    Policy Loss: 14.006   Value Loss: 3.209    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 15434      Buffer Size: 15434      Transition Number: 154.101 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:49:29,026][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.361    [weighted Loss:3.361    Policy Loss: 13.166   Value Loss: 2.893    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 16100      Buffer Size: 16100      Transition Number: 161.154 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:53:49,299][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.667    [weighted Loss:4.667    Policy Loss: 12.970   Value Loss: 2.833    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 16706      Buffer Size: 16706      Transition Number: 168.710 k Batch Size: 128        Lr: 0.100   
[2021-11-09 15:58:11,707][train][INFO][train.py>_log] ==> #24000      Total Loss: 6.014    [weighted Loss:6.014    Policy Loss: 12.066   Value Loss: 2.830    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 17345      Buffer Size: 17345      Transition Number: 176.768 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:02:38,053][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.395    [weighted Loss:3.395    Policy Loss: 10.999   Value Loss: 2.724    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 18004      Buffer Size: 18004      Transition Number: 184.491 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:07:01,277][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.917    [weighted Loss:3.917    Policy Loss: 10.758   Value Loss: 2.871    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 18645      Buffer Size: 18645      Transition Number: 192.141 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:11:36,195][train][INFO][train.py>_log] ==> #27000      Total Loss: 4.568    [weighted Loss:4.568    Policy Loss: 12.005   Value Loss: 2.694    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 19254      Buffer Size: 19254      Transition Number: 200.240 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:16:15,540][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.745    [weighted Loss:4.745    Policy Loss: 11.117   Value Loss: 2.684    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 19823      Buffer Size: 19823      Transition Number: 208.301 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:21:05,884][train][INFO][train.py>_log] ==> #29000      Total Loss: 5.643    [weighted Loss:5.643    Policy Loss: 11.698   Value Loss: 3.049    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 20261      Buffer Size: 20261      Transition Number: 215.521 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:26:10,807][train][INFO][train.py>_log] ==> #30000      Total Loss: 6.068    [weighted Loss:6.068    Policy Loss: 12.526   Value Loss: 2.857    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 21022      Buffer Size: 21022      Transition Number: 224.238 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:31:18,041][train][INFO][train.py>_log] ==> #31000      Total Loss: 5.119    [weighted Loss:5.119    Policy Loss: 12.401   Value Loss: 3.007    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 21468      Buffer Size: 21468      Transition Number: 232.329 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:36:49,564][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.735    [weighted Loss:4.735    Policy Loss: 12.398   Value Loss: 3.162    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 21904      Buffer Size: 21904      Transition Number: 240.640 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:42:32,590][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.257    [weighted Loss:3.257    Policy Loss: 10.981   Value Loss: 2.932    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 22339      Buffer Size: 22339      Transition Number: 249.014 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:48:14,277][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.466    [weighted Loss:3.466    Policy Loss: 12.042   Value Loss: 3.457    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 22748      Buffer Size: 22748      Transition Number: 257.313 k Batch Size: 128        Lr: 0.100   
[2021-11-09 16:54:12,567][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.648    [weighted Loss:3.648    Policy Loss: 9.809    Value Loss: 3.176    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 23041      Buffer Size: 23041      Transition Number: 265.733 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:00:33,509][train][INFO][train.py>_log] ==> #36000      Total Loss: 4.810    [weighted Loss:4.810    Policy Loss: 9.463    Value Loss: 3.587    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 23352      Buffer Size: 23352      Transition Number: 275.191 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:07:37,370][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 8.327    Value Loss: 3.636    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 23729      Buffer Size: 23729      Transition Number: 286.113 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:14:29,929][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 7.095    Value Loss: 3.657    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 23982      Buffer Size: 23982      Transition Number: 296.810 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:21:25,241][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 5.968    Value Loss: 4.115    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 24468      Buffer Size: 24468      Transition Number: 306.970 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:28:34,523][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 5.267    Value Loss: 3.897    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 25135      Buffer Size: 25135      Transition Number: 317.650 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:35:16,905][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 4.309    Value Loss: 3.611    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 25714      Buffer Size: 25714      Transition Number: 327.360 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:42:16,797][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 4.320    Value Loss: 4.133    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 26242      Buffer Size: 26242      Transition Number: 337.938 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:49:28,609][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 3.864    Value Loss: 3.758    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 26901      Buffer Size: 26901      Transition Number: 349.229 k Batch Size: 128        Lr: 0.100   
[2021-11-09 17:56:24,474][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 3.871    Value Loss: 3.795    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 27993      Buffer Size: 27993      Transition Number: 361.930 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:03:05,188][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 4.795    Value Loss: 3.442    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 29116      Buffer Size: 29116      Transition Number: 373.849 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:09:50,882][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 5.167    Value Loss: 3.793    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 29789      Buffer Size: 29789      Transition Number: 384.636 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:16:59,701][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 4.562    Value Loss: 3.879    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 30161      Buffer Size: 30161      Transition Number: 394.893 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:24:19,956][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 3.906    Value Loss: 3.709    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 30522      Buffer Size: 30051      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:31:51,706][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 4.694    Value Loss: 3.965    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 30958      Buffer Size: 29360      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:39:35,259][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 4.247    Value Loss: 4.152    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 31466      Buffer Size: 28703      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:47:35,161][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.733    [weighted Loss:2.733    Policy Loss: 5.202    Value Loss: 4.310    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 32132      Buffer Size: 28038      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 18:55:55,316][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.417    [weighted Loss:1.417    Policy Loss: 4.446    Value Loss: 4.077    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 32740      Buffer Size: 27687      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:04:12,012][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 4.142    Value Loss: 3.901    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 33338      Buffer Size: 27037      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:12:46,831][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.330    [weighted Loss:1.330    Policy Loss: 3.335    Value Loss: 3.990    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 33996      Buffer Size: 26165      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:21:18,330][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.075    [weighted Loss:1.075    Policy Loss: 3.270    Value Loss: 3.822    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 35365      Buffer Size: 25881      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:29:12,763][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 3.985    Value Loss: 3.830    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 37305      Buffer Size: 26530      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:37:14,028][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 3.140    Value Loss: 4.063    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 38951      Buffer Size: 26934      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:45:09,600][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.134    [weighted Loss:1.134    Policy Loss: 3.488    Value Loss: 3.941    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 40269      Buffer Size: 27078      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 19:53:02,347][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 3.490    Value Loss: 4.079    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 41582      Buffer Size: 27134      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:00:59,172][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 3.516    Value Loss: 3.919    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 42731      Buffer Size: 26923      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:09:06,485][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 3.011    Value Loss: 3.877    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 43309      Buffer Size: 26494      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:17:32,008][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 4.235    Value Loss: 4.120    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 43943      Buffer Size: 26056      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:26:11,196][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 3.709    Value Loss: 3.876    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 44668      Buffer Size: 25677      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:35:03,831][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.363    [weighted Loss:1.363    Policy Loss: 4.239    Value Loss: 3.847    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 45310      Buffer Size: 25291      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:44:19,070][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 4.573    Value Loss: 4.075    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 45924      Buffer Size: 24826      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-09 20:53:59,089][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 3.197    Value Loss: 4.165    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 46472      Buffer Size: 24584      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:03:13,633][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.811    [weighted Loss:1.811    Policy Loss: 2.548    Value Loss: 4.116    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 46873      Buffer Size: 24251      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:13:12,101][train][INFO][train.py>_log] ==> #68000      Total Loss: 0.886    [weighted Loss:0.886    Policy Loss: 2.579    Value Loss: 4.155    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 47240      Buffer Size: 24025      Transition Number: 400.022 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:23:27,148][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.570    [weighted Loss:1.570    Policy Loss: 2.357    Value Loss: 4.089    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 47747      Buffer Size: 24025      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:33:09,650][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 2.085    Value Loss: 4.251    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 48323      Buffer Size: 24100      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:42:59,464][train][INFO][train.py>_log] ==> #71000      Total Loss: 0.902    [weighted Loss:0.902    Policy Loss: 6.539    Value Loss: 4.047    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 48917      Buffer Size: 23816      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 21:52:45,522][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 3.076    Value Loss: 3.892    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 49491      Buffer Size: 23587      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:02:43,354][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.325    [weighted Loss:1.325    Policy Loss: 2.105    Value Loss: 3.857    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 50078      Buffer Size: 23309      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:12:29,520][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 3.081    Value Loss: 4.092    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 50432      Buffer Size: 22370      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:22:43,702][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 3.881    Value Loss: 3.814    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 51178      Buffer Size: 21741      Transition Number: 400.002 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:32:50,817][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 3.222    Value Loss: 3.918    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 52231      Buffer Size: 22110      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:43:13,745][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.093    [weighted Loss:4.093    Policy Loss: 5.043    Value Loss: 4.108    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 53585      Buffer Size: 22919      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-09 22:53:53,914][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.625    [weighted Loss:2.625    Policy Loss: 5.277    Value Loss: 4.122    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 54380      Buffer Size: 23095      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:04:56,828][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 4.801    Value Loss: 4.301    Reward Loss: 0.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 54867      Buffer Size: 22694      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:15:31,153][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.891    [weighted Loss:2.891    Policy Loss: 5.689    Value Loss: 4.220    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 55885      Buffer Size: 22922      Transition Number: 399.928 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:26:20,205][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 6.732    Value Loss: 4.232    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 57218      Buffer Size: 23460      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:36:39,945][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 7.171    Value Loss: 4.047    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 58140      Buffer Size: 23250      Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:47:51,611][train][INFO][train.py>_log] ==> #83000      Total Loss: 4.355    [weighted Loss:4.355    Policy Loss: 7.317    Value Loss: 4.238    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 58716      Buffer Size: 21699      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-09 23:59:14,238][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.088    [weighted Loss:3.088    Policy Loss: 5.651    Value Loss: 4.263    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 59378      Buffer Size: 20255      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:10:39,323][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 6.130    Value Loss: 4.360    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 60024      Buffer Size: 19109      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:22:27,497][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 4.700    Value Loss: 4.517    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 60840      Buffer Size: 18337      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:34:36,034][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 4.716    Value Loss: 4.148    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 61563      Buffer Size: 18067      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:47:00,855][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 3.839    Value Loss: 4.608    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 61953      Buffer Size: 17376      Transition Number: 399.929 k Batch Size: 128        Lr: 0.100   
[2021-11-10 00:59:29,863][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.427    [weighted Loss:1.427    Policy Loss: 4.208    Value Loss: 4.849    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 62354      Buffer Size: 16874      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:11:45,851][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.088    [weighted Loss:3.088    Policy Loss: 4.285    Value Loss: 4.387    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 62732      Buffer Size: 16463      Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:24:06,518][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 4.475    Value Loss: 4.660    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 63191      Buffer Size: 16318      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:36:14,669][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.530    [weighted Loss:2.530    Policy Loss: 4.863    Value Loss: 4.330    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 63579      Buffer Size: 16222      Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-10 01:48:19,169][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.138    [weighted Loss:3.138    Policy Loss: 5.084    Value Loss: 4.358    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 63927      Buffer Size: 15885      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:00:22,700][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.032    [weighted Loss:2.032    Policy Loss: 3.730    Value Loss: 4.330    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 64270      Buffer Size: 15458      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:13:14,719][train][INFO][train.py>_log] ==> #95000      Total Loss: 3.391    [weighted Loss:3.391    Policy Loss: 5.495    Value Loss: 4.818    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 64729      Buffer Size: 15086      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:25:45,542][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.975    [weighted Loss:2.975    Policy Loss: 5.395    Value Loss: 4.670    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 65174      Buffer Size: 14908      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:38:33,988][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 4.788    Value Loss: 4.521    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 65578      Buffer Size: 14527      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-10 02:51:36,309][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.844    [weighted Loss:3.844    Policy Loss: 5.827    Value Loss: 4.789    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 65969      Buffer Size: 13352      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
