[2021-11-08 14:08:44,673][train][INFO][train.py>_log] ==> #0          Total Loss: 44.509   [weighted Loss:44.509   Policy Loss: 14.511   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 44         Buffer Size: 44         Transition Number: 0.567   k Batch Size: 128        Lr: 0.000   
[2021-11-08 14:11:10,298][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.064    [weighted Loss:5.064    Policy Loss: 14.230   Value Loss: 4.500    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 452        Buffer Size: 452        Transition Number: 5.651   k Batch Size: 128        Lr: 0.010   
[2021-11-08 14:14:29,890][train][INFO][train.py>_log] ==> #2000       Total Loss: 8.763    [weighted Loss:8.763    Policy Loss: 14.154   Value Loss: 3.226    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1036       Buffer Size: 1036       Transition Number: 12.741  k Batch Size: 128        Lr: 0.020   
[2021-11-08 14:17:59,029][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.441    [weighted Loss:6.441    Policy Loss: 13.526   Value Loss: 3.272    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1796       Buffer Size: 1796       Transition Number: 19.620  k Batch Size: 128        Lr: 0.030   
