[2021-11-25 00:30:21,760][train][INFO][train.py>_log] ==> #0          Total Loss: 70.555   [weighted Loss:70.555   Policy Loss: 12.217   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 75         Buffer Size: 75         Transition Number: 0.663   k Batch Size: 256        Lr: 0.000   
[2021-11-25 00:35:37,976][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.507    [weighted Loss:4.507    Policy Loss: 14.773   Value Loss: 5.364    Reward Loss: 1.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 1200       Buffer Size: 1200       Transition Number: 14.573  k Batch Size: 256        Lr: 0.002   
[2021-11-25 00:41:31,771][train][INFO][train.py>_log] ==> #4000       Total Loss: 7.162    [weighted Loss:7.162    Policy Loss: 14.262   Value Loss: 3.300    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 2662       Buffer Size: 2662       Transition Number: 28.745  k Batch Size: 256        Lr: 0.004   
[2021-11-25 00:47:19,561][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.683    [weighted Loss:4.683    Policy Loss: 14.005   Value Loss: 3.037    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 3846       Buffer Size: 3846       Transition Number: 42.026  k Batch Size: 256        Lr: 0.006   
[2021-11-25 00:53:14,767][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.585    [weighted Loss:5.585    Policy Loss: 13.942   Value Loss: 2.990    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 5018       Buffer Size: 5018       Transition Number: 55.554  k Batch Size: 256        Lr: 0.008   
[2021-11-25 00:59:22,157][train][INFO][train.py>_log] ==> #10000      Total Loss: 6.283    [weighted Loss:6.283    Policy Loss: 14.039   Value Loss: 3.098    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 6052       Buffer Size: 6052       Transition Number: 69.069  k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:05:33,870][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.559    [weighted Loss:6.559    Policy Loss: 14.485   Value Loss: 3.068    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 6997       Buffer Size: 6997       Transition Number: 82.909  k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:11:48,356][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.391    [weighted Loss:5.391    Policy Loss: 13.770   Value Loss: 2.770    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 7892       Buffer Size: 7892       Transition Number: 96.427  k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:18:04,379][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.709    [weighted Loss:2.709    Policy Loss: 13.781   Value Loss: 2.789    Reward Loss: 0.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 8680       Buffer Size: 8680       Transition Number: 110.170 k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:24:20,811][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.876    [weighted Loss:4.876    Policy Loss: 14.248   Value Loss: 2.960    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 9316       Buffer Size: 9316       Transition Number: 122.511 k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:30:42,455][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.370    [weighted Loss:4.370    Policy Loss: 14.637   Value Loss: 3.130    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 9803       Buffer Size: 9803       Transition Number: 134.891 k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:37:06,856][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.911    [weighted Loss:3.911    Policy Loss: 14.371   Value Loss: 2.984    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 10277      Buffer Size: 10277      Transition Number: 146.343 k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:43:26,248][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.073    [weighted Loss:5.073    Policy Loss: 14.809   Value Loss: 2.925    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 10718      Buffer Size: 10718      Transition Number: 157.522 k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:49:45,642][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.082    [weighted Loss:5.082    Policy Loss: 14.439   Value Loss: 2.896    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 11017      Buffer Size: 11017      Transition Number: 166.324 k Batch Size: 256        Lr: 0.010   
[2021-11-25 01:56:13,575][train][INFO][train.py>_log] ==> #28000      Total Loss: 5.436    [weighted Loss:5.436    Policy Loss: 14.247   Value Loss: 2.940    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 11280      Buffer Size: 11280      Transition Number: 174.816 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:02:40,403][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.769    [weighted Loss:4.769    Policy Loss: 14.343   Value Loss: 2.769    Reward Loss: 0.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 11514      Buffer Size: 11514      Transition Number: 182.927 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:09:02,460][train][INFO][train.py>_log] ==> #32000      Total Loss: 5.559    [weighted Loss:5.559    Policy Loss: 14.843   Value Loss: 2.964    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 11691      Buffer Size: 11691      Transition Number: 189.318 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:15:21,208][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.957    [weighted Loss:3.957    Policy Loss: 14.318   Value Loss: 3.106    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 11811      Buffer Size: 11811      Transition Number: 194.071 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:21:46,111][train][INFO][train.py>_log] ==> #36000      Total Loss: 6.024    [weighted Loss:6.024    Policy Loss: 14.043   Value Loss: 2.949    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 11954      Buffer Size: 11954      Transition Number: 199.305 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:28:14,961][train][INFO][train.py>_log] ==> #38000      Total Loss: 5.953    [weighted Loss:5.953    Policy Loss: 14.017   Value Loss: 2.863    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 12078      Buffer Size: 12078      Transition Number: 204.386 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:34:54,195][train][INFO][train.py>_log] ==> #40000      Total Loss: 6.247    [weighted Loss:6.247    Policy Loss: 14.303   Value Loss: 2.896    Reward Loss: 0.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 12170      Buffer Size: 12170      Transition Number: 208.338 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:41:24,955][train][INFO][train.py>_log] ==> #42000      Total Loss: 5.124    [weighted Loss:5.124    Policy Loss: 14.042   Value Loss: 3.022    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 12318      Buffer Size: 12318      Transition Number: 213.597 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:48:00,835][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 14.182   Value Loss: 2.930    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 12440      Buffer Size: 12440      Transition Number: 218.362 k Batch Size: 256        Lr: 0.010   
[2021-11-25 02:54:33,584][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.321    [weighted Loss:4.321    Policy Loss: 14.000   Value Loss: 3.007    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 12567      Buffer Size: 12567      Transition Number: 222.620 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:01:08,717][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 14.313   Value Loss: 2.903    Reward Loss: 0.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 12679      Buffer Size: 12679      Transition Number: 226.622 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:07:38,119][train][INFO][train.py>_log] ==> #50000      Total Loss: 4.265    [weighted Loss:4.265    Policy Loss: 14.246   Value Loss: 3.139    Reward Loss: 0.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 12779      Buffer Size: 12779      Transition Number: 230.525 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:14:08,502][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 13.770   Value Loss: 2.972    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 12865      Buffer Size: 12865      Transition Number: 234.120 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:20:52,990][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 13.514   Value Loss: 3.067    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 12968      Buffer Size: 12968      Transition Number: 238.600 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:27:31,419][train][INFO][train.py>_log] ==> #56000      Total Loss: 4.944    [weighted Loss:4.944    Policy Loss: 14.423   Value Loss: 3.063    Reward Loss: 0.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 13050      Buffer Size: 13050      Transition Number: 242.648 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:34:07,144][train][INFO][train.py>_log] ==> #58000      Total Loss: 4.574    [weighted Loss:4.574    Policy Loss: 13.709   Value Loss: 3.009    Reward Loss: 0.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 13149      Buffer Size: 13149      Transition Number: 246.970 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:40:43,946][train][INFO][train.py>_log] ==> #60000      Total Loss: 6.414    [weighted Loss:6.414    Policy Loss: 13.681   Value Loss: 3.070    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 13250      Buffer Size: 13250      Transition Number: 250.543 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:47:20,092][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.701    [weighted Loss:4.701    Policy Loss: 13.978   Value Loss: 2.927    Reward Loss: 0.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 13330      Buffer Size: 13330      Transition Number: 253.843 k Batch Size: 256        Lr: 0.010   
[2021-11-25 03:53:51,957][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.441    [weighted Loss:3.441    Policy Loss: 13.380   Value Loss: 2.806    Reward Loss: 0.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 13425      Buffer Size: 13425      Transition Number: 257.903 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:00:31,140][train][INFO][train.py>_log] ==> #66000      Total Loss: 6.182    [weighted Loss:6.182    Policy Loss: 13.947   Value Loss: 3.088    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 13485      Buffer Size: 13485      Transition Number: 260.585 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:07:02,637][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.360    [weighted Loss:3.360    Policy Loss: 13.396   Value Loss: 2.986    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 13531      Buffer Size: 13531      Transition Number: 262.972 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:13:37,932][train][INFO][train.py>_log] ==> #70000      Total Loss: 4.637    [weighted Loss:4.637    Policy Loss: 13.840   Value Loss: 2.927    Reward Loss: 0.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 13606      Buffer Size: 13606      Transition Number: 266.031 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:20:17,204][train][INFO][train.py>_log] ==> #72000      Total Loss: 5.582    [weighted Loss:5.582    Policy Loss: 13.791   Value Loss: 2.988    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 13691      Buffer Size: 13691      Transition Number: 269.571 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:26:53,868][train][INFO][train.py>_log] ==> #74000      Total Loss: 5.612    [weighted Loss:5.612    Policy Loss: 13.635   Value Loss: 3.102    Reward Loss: 0.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 13748      Buffer Size: 13748      Transition Number: 272.488 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:33:30,255][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.637    [weighted Loss:4.637    Policy Loss: 13.298   Value Loss: 3.017    Reward Loss: 0.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 13799      Buffer Size: 13799      Transition Number: 274.784 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:40:06,165][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.362    [weighted Loss:4.362    Policy Loss: 13.707   Value Loss: 3.065    Reward Loss: 0.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 13888      Buffer Size: 13888      Transition Number: 278.777 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:46:43,822][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.993    [weighted Loss:3.993    Policy Loss: 13.215   Value Loss: 3.016    Reward Loss: 0.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 13979      Buffer Size: 13979      Transition Number: 283.350 k Batch Size: 256        Lr: 0.010   
[2021-11-25 04:53:21,748][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.589    [weighted Loss:3.589    Policy Loss: 13.657   Value Loss: 3.079    Reward Loss: 0.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 14038      Buffer Size: 14038      Transition Number: 285.921 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:00:03,364][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.653    [weighted Loss:4.653    Policy Loss: 13.225   Value Loss: 3.001    Reward Loss: 0.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 14115      Buffer Size: 14115      Transition Number: 289.892 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:06:40,653][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.862    [weighted Loss:3.862    Policy Loss: 13.347   Value Loss: 3.030    Reward Loss: 0.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 14174      Buffer Size: 14174      Transition Number: 292.631 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:13:17,301][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.588    [weighted Loss:4.588    Policy Loss: 13.633   Value Loss: 3.029    Reward Loss: 0.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 14252      Buffer Size: 14252      Transition Number: 296.401 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:19:43,150][train][INFO][train.py>_log] ==> #90000      Total Loss: 5.372    [weighted Loss:5.372    Policy Loss: 13.365   Value Loss: 3.102    Reward Loss: 0.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 14309      Buffer Size: 14309      Transition Number: 299.207 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:26:09,348][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 13.322   Value Loss: 2.820    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 14356      Buffer Size: 14356      Transition Number: 301.366 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:32:30,683][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 13.275   Value Loss: 2.952    Reward Loss: 0.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 14421      Buffer Size: 14421      Transition Number: 304.115 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:38:52,800][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 13.470   Value Loss: 3.019    Reward Loss: 0.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 14480      Buffer Size: 14480      Transition Number: 306.678 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:45:14,313][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.682    [weighted Loss:3.682    Policy Loss: 13.654   Value Loss: 3.196    Reward Loss: 0.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 14534      Buffer Size: 14534      Transition Number: 309.595 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:51:28,332][train][INFO][train.py>_log] ==> #100000     Total Loss: 5.038    [weighted Loss:5.038    Policy Loss: 13.458   Value Loss: 3.223    Reward Loss: 0.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 14613      Buffer Size: 14613      Transition Number: 313.267 k Batch Size: 256        Lr: 0.010   
[2021-11-25 05:57:49,058][train][INFO][train.py>_log] ==> #102000     Total Loss: 4.200    [weighted Loss:4.200    Policy Loss: 13.859   Value Loss: 3.133    Reward Loss: 0.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 14678      Buffer Size: 14678      Transition Number: 316.063 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:04:11,193][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 12.850   Value Loss: 2.977    Reward Loss: 0.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 14738      Buffer Size: 14738      Transition Number: 318.969 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:10:36,218][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 13.604   Value Loss: 3.257    Reward Loss: 0.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 14817      Buffer Size: 14817      Transition Number: 322.843 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:16:58,116][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 13.122   Value Loss: 3.049    Reward Loss: 0.352    Consistency Loss: 0.000    ] Replay Episodes Collected: 14887      Buffer Size: 14887      Transition Number: 325.836 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:23:18,082][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.953    [weighted Loss:3.953    Policy Loss: 13.035   Value Loss: 3.037    Reward Loss: 0.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 14953      Buffer Size: 14953      Transition Number: 329.115 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:29:37,551][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.339    [weighted Loss:2.339    Policy Loss: 13.096   Value Loss: 3.074    Reward Loss: 0.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 15028      Buffer Size: 15028      Transition Number: 332.352 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:36:06,304][train][INFO][train.py>_log] ==> #114000     Total Loss: 4.681    [weighted Loss:4.681    Policy Loss: 12.671   Value Loss: 2.997    Reward Loss: 0.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 15085      Buffer Size: 15085      Transition Number: 335.022 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:42:36,134][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.207    [weighted Loss:4.207    Policy Loss: 12.887   Value Loss: 3.151    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 15144      Buffer Size: 15144      Transition Number: 337.815 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:49:08,163][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.885    [weighted Loss:3.885    Policy Loss: 13.125   Value Loss: 3.102    Reward Loss: 0.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 15191      Buffer Size: 15191      Transition Number: 339.973 k Batch Size: 256        Lr: 0.010   
[2021-11-25 06:55:38,912][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 13.187   Value Loss: 3.195    Reward Loss: 0.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 15252      Buffer Size: 15252      Transition Number: 342.661 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:02:08,711][train][INFO][train.py>_log] ==> #122000     Total Loss: 4.536    [weighted Loss:4.536    Policy Loss: 13.325   Value Loss: 3.300    Reward Loss: 0.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 15305      Buffer Size: 15305      Transition Number: 345.256 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:08:36,405][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.052    [weighted Loss:4.052    Policy Loss: 12.878   Value Loss: 3.091    Reward Loss: 0.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 15365      Buffer Size: 15365      Transition Number: 348.195 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:15:10,153][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.431    [weighted Loss:4.431    Policy Loss: 12.600   Value Loss: 3.005    Reward Loss: 0.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 15428      Buffer Size: 15428      Transition Number: 351.338 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:21:36,625][train][INFO][train.py>_log] ==> #128000     Total Loss: 4.314    [weighted Loss:4.314    Policy Loss: 13.081   Value Loss: 3.104    Reward Loss: 0.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 15508      Buffer Size: 15508      Transition Number: 354.801 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:28:09,543][train][INFO][train.py>_log] ==> #130000     Total Loss: 4.588    [weighted Loss:4.588    Policy Loss: 13.464   Value Loss: 2.988    Reward Loss: 0.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 15562      Buffer Size: 15562      Transition Number: 357.254 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:34:37,721][train][INFO][train.py>_log] ==> #132000     Total Loss: 4.555    [weighted Loss:4.555    Policy Loss: 13.413   Value Loss: 3.063    Reward Loss: 0.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 15613      Buffer Size: 15613      Transition Number: 359.552 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:41:06,538][train][INFO][train.py>_log] ==> #134000     Total Loss: 6.246    [weighted Loss:6.246    Policy Loss: 12.697   Value Loss: 3.043    Reward Loss: 0.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 15670      Buffer Size: 15670      Transition Number: 362.469 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:47:33,021][train][INFO][train.py>_log] ==> #136000     Total Loss: 4.561    [weighted Loss:4.561    Policy Loss: 13.315   Value Loss: 3.009    Reward Loss: 0.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 15727      Buffer Size: 15727      Transition Number: 365.626 k Batch Size: 256        Lr: 0.010   
[2021-11-25 07:53:58,966][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.679    [weighted Loss:3.679    Policy Loss: 13.305   Value Loss: 3.131    Reward Loss: 0.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 15788      Buffer Size: 15788      Transition Number: 368.639 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:00:25,438][train][INFO][train.py>_log] ==> #140000     Total Loss: 4.411    [weighted Loss:4.411    Policy Loss: 12.592   Value Loss: 2.931    Reward Loss: 0.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 15839      Buffer Size: 15839      Transition Number: 370.958 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:06:50,944][train][INFO][train.py>_log] ==> #142000     Total Loss: 4.942    [weighted Loss:4.942    Policy Loss: 13.109   Value Loss: 3.228    Reward Loss: 0.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 15888      Buffer Size: 15888      Transition Number: 373.285 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:13:16,055][train][INFO][train.py>_log] ==> #144000     Total Loss: 4.413    [weighted Loss:4.413    Policy Loss: 13.123   Value Loss: 3.065    Reward Loss: 0.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 15945      Buffer Size: 15945      Transition Number: 375.918 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:19:44,757][train][INFO][train.py>_log] ==> #146000     Total Loss: 5.261    [weighted Loss:5.261    Policy Loss: 13.353   Value Loss: 3.093    Reward Loss: 0.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 16000      Buffer Size: 16000      Transition Number: 378.812 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:26:16,151][train][INFO][train.py>_log] ==> #148000     Total Loss: 6.079    [weighted Loss:6.079    Policy Loss: 13.294   Value Loss: 3.122    Reward Loss: 0.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 16048      Buffer Size: 16048      Transition Number: 381.276 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:32:42,598][train][INFO][train.py>_log] ==> #150000     Total Loss: 4.855    [weighted Loss:4.855    Policy Loss: 13.239   Value Loss: 3.238    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 16124      Buffer Size: 16124      Transition Number: 384.759 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:39:10,326][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 12.984   Value Loss: 3.246    Reward Loss: 0.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 16185      Buffer Size: 16185      Transition Number: 388.121 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:45:39,947][train][INFO][train.py>_log] ==> #154000     Total Loss: 4.017    [weighted Loss:4.017    Policy Loss: 12.556   Value Loss: 2.984    Reward Loss: 0.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 16241      Buffer Size: 16241      Transition Number: 391.075 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:52:08,541][train][INFO][train.py>_log] ==> #156000     Total Loss: 4.050    [weighted Loss:4.050    Policy Loss: 13.195   Value Loss: 3.311    Reward Loss: 0.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 16346      Buffer Size: 16346      Transition Number: 395.004 k Batch Size: 256        Lr: 0.010   
[2021-11-25 08:58:35,979][train][INFO][train.py>_log] ==> #158000     Total Loss: 4.952    [weighted Loss:4.952    Policy Loss: 13.091   Value Loss: 3.142    Reward Loss: 0.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 16408      Buffer Size: 16408      Transition Number: 397.764 k Batch Size: 256        Lr: 0.010   
[2021-11-25 09:05:09,515][train][INFO][train.py>_log] ==> #160000     Total Loss: 3.193    [weighted Loss:3.193    Policy Loss: 12.522   Value Loss: 3.049    Reward Loss: 0.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 16469      Buffer Size: 16469      Transition Number: 400.710 k Batch Size: 256        Lr: 0.010   
