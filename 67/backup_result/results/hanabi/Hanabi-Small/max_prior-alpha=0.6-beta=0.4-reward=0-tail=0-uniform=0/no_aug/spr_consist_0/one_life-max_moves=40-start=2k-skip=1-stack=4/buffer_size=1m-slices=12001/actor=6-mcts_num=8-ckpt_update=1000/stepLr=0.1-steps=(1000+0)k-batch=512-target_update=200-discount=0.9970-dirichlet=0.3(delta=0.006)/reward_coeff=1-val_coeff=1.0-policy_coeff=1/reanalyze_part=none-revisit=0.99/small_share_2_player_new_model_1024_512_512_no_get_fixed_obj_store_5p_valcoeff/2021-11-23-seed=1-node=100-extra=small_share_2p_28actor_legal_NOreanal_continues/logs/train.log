[2021-11-23 20:47:54,609][train][INFO][train.py>_log] ==> #0          Total Loss: 50.744   [weighted Loss:50.744   Policy Loss: 7.494    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 602        Buffer Size: 602        Transition Number: 2.175   k Batch Size: 512        Lr: 0.000   
[2021-11-23 20:50:15,913][train][INFO][train.py>_log] ==> #1000       Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 7.947    Value Loss: 3.292    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 2218       Buffer Size: 2218       Transition Number: 8.465   k Batch Size: 512        Lr: 0.010   
[2021-11-23 20:52:44,668][train][INFO][train.py>_log] ==> #2000       Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 7.023    Value Loss: 1.821    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 3979       Buffer Size: 3979       Transition Number: 14.016  k Batch Size: 512        Lr: 0.020   
[2021-11-23 20:55:23,318][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 6.532    Value Loss: 1.865    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 5762       Buffer Size: 5762       Transition Number: 19.895  k Batch Size: 512        Lr: 0.030   
[2021-11-23 20:58:06,453][train][INFO][train.py>_log] ==> #4000       Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 6.443    Value Loss: 1.860    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 7381       Buffer Size: 7381       Transition Number: 25.777  k Batch Size: 512        Lr: 0.040   
[2021-11-23 21:00:59,021][train][INFO][train.py>_log] ==> #5000       Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 6.213    Value Loss: 1.798    Reward Loss: 0.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 9039       Buffer Size: 9039       Transition Number: 32.016  k Batch Size: 512        Lr: 0.050   
[2021-11-23 21:03:54,657][train][INFO][train.py>_log] ==> #6000       Total Loss: 1.861    [weighted Loss:1.861    Policy Loss: 5.948    Value Loss: 1.842    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 10626      Buffer Size: 10626      Transition Number: 38.410  k Batch Size: 512        Lr: 0.060   
[2021-11-23 21:06:47,361][train][INFO][train.py>_log] ==> #7000       Total Loss: 1.508    [weighted Loss:1.508    Policy Loss: 5.810    Value Loss: 1.693    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 12094      Buffer Size: 12094      Transition Number: 44.717  k Batch Size: 512        Lr: 0.070   
[2021-11-23 21:09:45,439][train][INFO][train.py>_log] ==> #8000       Total Loss: 1.930    [weighted Loss:1.930    Policy Loss: 6.287    Value Loss: 1.631    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 13382      Buffer Size: 13382      Transition Number: 50.998  k Batch Size: 512        Lr: 0.080   
[2021-11-23 21:12:38,858][train][INFO][train.py>_log] ==> #9000       Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 6.506    Value Loss: 1.898    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 14648      Buffer Size: 14648      Transition Number: 57.135  k Batch Size: 512        Lr: 0.090   
[2021-11-23 21:15:40,982][train][INFO][train.py>_log] ==> #10000      Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 6.603    Value Loss: 1.936    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 15980      Buffer Size: 15980      Transition Number: 63.570  k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:18:41,576][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 6.229    Value Loss: 1.745    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 17234      Buffer Size: 17234      Transition Number: 69.963  k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:21:42,985][train][INFO][train.py>_log] ==> #12000      Total Loss: 1.626    [weighted Loss:1.626    Policy Loss: 6.699    Value Loss: 1.896    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 18405      Buffer Size: 18405      Transition Number: 76.268  k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:24:47,208][train][INFO][train.py>_log] ==> #13000      Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 6.315    Value Loss: 1.779    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 19606      Buffer Size: 19606      Transition Number: 82.768  k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:27:47,664][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 6.855    Value Loss: 1.832    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 20713      Buffer Size: 20713      Transition Number: 88.856  k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:30:49,862][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 6.675    Value Loss: 1.852    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 21731      Buffer Size: 21731      Transition Number: 95.080  k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:33:55,171][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 6.732    Value Loss: 1.829    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 22865      Buffer Size: 22865      Transition Number: 101.659 k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:37:03,349][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 7.157    Value Loss: 2.016    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 24064      Buffer Size: 24064      Transition Number: 108.223 k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:40:11,240][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.269    [weighted Loss:1.269    Policy Loss: 7.242    Value Loss: 1.942    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 25047      Buffer Size: 25047      Transition Number: 114.538 k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:43:22,954][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 6.998    Value Loss: 1.914    Reward Loss: 0.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 26188      Buffer Size: 26188      Transition Number: 121.238 k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:46:30,452][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 6.607    Value Loss: 1.812    Reward Loss: 0.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 27239      Buffer Size: 27239      Transition Number: 127.714 k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:49:42,124][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 6.997    Value Loss: 2.003    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 28253      Buffer Size: 28253      Transition Number: 134.037 k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:52:52,715][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.672    [weighted Loss:1.672    Policy Loss: 7.219    Value Loss: 2.106    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 29242      Buffer Size: 29242      Transition Number: 140.400 k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:56:01,936][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 6.912    Value Loss: 1.977    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 30136      Buffer Size: 30136      Transition Number: 146.692 k Batch Size: 512        Lr: 0.100   
[2021-11-23 21:59:08,887][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.099    [weighted Loss:1.099    Policy Loss: 7.077    Value Loss: 1.998    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 30971      Buffer Size: 30971      Transition Number: 152.945 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:02:17,947][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.471    [weighted Loss:1.471    Policy Loss: 6.990    Value Loss: 1.965    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 31794      Buffer Size: 31794      Transition Number: 159.112 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:05:27,927][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 7.281    Value Loss: 2.109    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 32571      Buffer Size: 32571      Transition Number: 164.946 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:08:39,901][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 7.224    Value Loss: 2.143    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 33454      Buffer Size: 33454      Transition Number: 171.251 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:11:47,674][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.119    [weighted Loss:1.119    Policy Loss: 7.248    Value Loss: 2.187    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 34187      Buffer Size: 34187      Transition Number: 176.938 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:14:56,231][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 7.516    Value Loss: 2.211    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 34975      Buffer Size: 34975      Transition Number: 183.058 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:18:06,610][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 7.422    Value Loss: 2.261    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 35610      Buffer Size: 35610      Transition Number: 189.015 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:21:15,112][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.851    [weighted Loss:1.851    Policy Loss: 7.498    Value Loss: 2.387    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 36250      Buffer Size: 36250      Transition Number: 194.615 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:24:25,309][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 7.372    Value Loss: 2.419    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 36895      Buffer Size: 36895      Transition Number: 200.233 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:27:42,904][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.583    [weighted Loss:1.583    Policy Loss: 7.370    Value Loss: 2.280    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 37419      Buffer Size: 37419      Transition Number: 206.001 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:30:57,535][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 7.125    Value Loss: 2.315    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 37922      Buffer Size: 37922      Transition Number: 211.669 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:34:11,831][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.467    [weighted Loss:1.467    Policy Loss: 7.231    Value Loss: 2.382    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 38439      Buffer Size: 38439      Transition Number: 217.271 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:37:30,008][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 7.246    Value Loss: 2.373    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 38944      Buffer Size: 38944      Transition Number: 222.960 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:40:42,805][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.398    [weighted Loss:1.398    Policy Loss: 7.222    Value Loss: 2.551    Reward Loss: 0.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 39345      Buffer Size: 39345      Transition Number: 228.634 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:43:57,085][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 6.961    Value Loss: 2.494    Reward Loss: 0.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 39796      Buffer Size: 39796      Transition Number: 234.597 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:47:11,316][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 7.041    Value Loss: 2.545    Reward Loss: 0.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 40183      Buffer Size: 40183      Transition Number: 240.373 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:50:32,608][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 6.959    Value Loss: 2.608    Reward Loss: 0.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 40613      Buffer Size: 40613      Transition Number: 246.771 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:53:50,306][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 6.975    Value Loss: 2.770    Reward Loss: 0.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 40967      Buffer Size: 40967      Transition Number: 252.608 k Batch Size: 512        Lr: 0.100   
[2021-11-23 22:57:08,152][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.633    [weighted Loss:1.633    Policy Loss: 6.840    Value Loss: 2.899    Reward Loss: 0.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 41336      Buffer Size: 41336      Transition Number: 258.576 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:00:26,646][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.800    [weighted Loss:1.800    Policy Loss: 6.637    Value Loss: 2.839    Reward Loss: 0.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 41700      Buffer Size: 41700      Transition Number: 264.706 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:03:41,010][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.251    [weighted Loss:1.251    Policy Loss: 6.724    Value Loss: 2.945    Reward Loss: 0.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 42028      Buffer Size: 42028      Transition Number: 270.964 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:07:00,468][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 6.739    Value Loss: 2.906    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 42384      Buffer Size: 42384      Transition Number: 277.148 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:10:20,786][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.205    [weighted Loss:3.205    Policy Loss: 6.627    Value Loss: 3.023    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 42744      Buffer Size: 42744      Transition Number: 283.312 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:13:43,775][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.771    [weighted Loss:1.771    Policy Loss: 6.583    Value Loss: 2.749    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 43115      Buffer Size: 43115      Transition Number: 289.897 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:17:00,704][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 6.380    Value Loss: 3.024    Reward Loss: 0.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 43423      Buffer Size: 43423      Transition Number: 295.779 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:20:21,603][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 6.613    Value Loss: 3.165    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 43737      Buffer Size: 43737      Transition Number: 301.806 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:23:39,587][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 6.447    Value Loss: 2.998    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 44021      Buffer Size: 44021      Transition Number: 308.220 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:26:59,107][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 6.352    Value Loss: 3.310    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 44328      Buffer Size: 44328      Transition Number: 314.894 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:30:19,041][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 6.311    Value Loss: 3.020    Reward Loss: 0.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 44626      Buffer Size: 44626      Transition Number: 321.045 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:33:36,009][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 6.498    Value Loss: 3.164    Reward Loss: 0.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 44905      Buffer Size: 44905      Transition Number: 327.391 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:36:56,191][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 6.178    Value Loss: 3.211    Reward Loss: 0.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 45189      Buffer Size: 45189      Transition Number: 333.646 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:40:22,915][train][INFO][train.py>_log] ==> #55000      Total Loss: 0.761    [weighted Loss:0.761    Policy Loss: 6.168    Value Loss: 3.107    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 45506      Buffer Size: 45506      Transition Number: 340.606 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:43:45,218][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.094    [weighted Loss:1.094    Policy Loss: 6.391    Value Loss: 3.298    Reward Loss: 0.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 45752      Buffer Size: 45752      Transition Number: 346.849 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:47:16,439][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.363    [weighted Loss:1.363    Policy Loss: 6.171    Value Loss: 3.401    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 46062      Buffer Size: 46062      Transition Number: 354.071 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:50:43,464][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 6.297    Value Loss: 3.434    Reward Loss: 0.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 46354      Buffer Size: 46354      Transition Number: 360.902 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:54:05,578][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 6.075    Value Loss: 3.522    Reward Loss: 0.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 46606      Buffer Size: 46606      Transition Number: 367.555 k Batch Size: 512        Lr: 0.100   
[2021-11-23 23:57:24,198][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.837    [weighted Loss:1.837    Policy Loss: 6.212    Value Loss: 3.447    Reward Loss: 0.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 46885      Buffer Size: 46885      Transition Number: 374.317 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:00:49,202][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 6.103    Value Loss: 3.495    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 47155      Buffer Size: 47155      Transition Number: 381.078 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:04:11,777][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.478    [weighted Loss:2.478    Policy Loss: 5.921    Value Loss: 3.507    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 47428      Buffer Size: 47428      Transition Number: 387.975 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:07:34,522][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 6.058    Value Loss: 3.552    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 47704      Buffer Size: 47704      Transition Number: 394.529 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:10:54,983][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.931    [weighted Loss:1.931    Policy Loss: 6.099    Value Loss: 3.517    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 47961      Buffer Size: 47961      Transition Number: 401.180 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:14:17,914][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 5.711    Value Loss: 3.403    Reward Loss: 0.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 48236      Buffer Size: 48236      Transition Number: 408.005 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:17:44,130][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.361    [weighted Loss:3.361    Policy Loss: 5.896    Value Loss: 3.502    Reward Loss: 0.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 48481      Buffer Size: 48481      Transition Number: 414.282 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:21:02,761][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 6.108    Value Loss: 3.755    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 48760      Buffer Size: 48760      Transition Number: 421.409 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:24:21,095][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 5.895    Value Loss: 3.640    Reward Loss: 0.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 49012      Buffer Size: 49012      Transition Number: 427.726 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:27:43,720][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 5.999    Value Loss: 3.723    Reward Loss: 0.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 49261      Buffer Size: 49261      Transition Number: 434.092 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:31:07,605][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.304    [weighted Loss:3.304    Policy Loss: 6.016    Value Loss: 3.695    Reward Loss: 0.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 49532      Buffer Size: 49532      Transition Number: 441.281 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:34:31,042][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 5.970    Value Loss: 3.773    Reward Loss: 0.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 49780      Buffer Size: 49780      Transition Number: 447.414 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:37:52,884][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 5.846    Value Loss: 3.749    Reward Loss: 0.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 50054      Buffer Size: 50054      Transition Number: 454.088 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:41:12,666][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 5.841    Value Loss: 3.696    Reward Loss: 0.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 50309      Buffer Size: 50309      Transition Number: 461.028 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:44:33,604][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.727    [weighted Loss:2.727    Policy Loss: 5.789    Value Loss: 3.742    Reward Loss: 0.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 50559      Buffer Size: 50559      Transition Number: 467.526 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:47:57,053][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.906    [weighted Loss:1.906    Policy Loss: 5.910    Value Loss: 3.844    Reward Loss: 0.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 50817      Buffer Size: 50817      Transition Number: 474.472 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:51:17,757][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 6.000    Value Loss: 3.753    Reward Loss: 0.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 51080      Buffer Size: 51080      Transition Number: 481.467 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:54:40,600][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.216    [weighted Loss:2.216    Policy Loss: 5.693    Value Loss: 3.628    Reward Loss: 0.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 51331      Buffer Size: 51331      Transition Number: 487.936 k Batch Size: 512        Lr: 0.100   
[2021-11-24 00:58:04,100][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 5.768    Value Loss: 3.844    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 51605      Buffer Size: 51605      Transition Number: 495.103 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:01:26,403][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 5.654    Value Loss: 3.712    Reward Loss: 0.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 51842      Buffer Size: 51502      Transition Number: 499.995 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:04:58,365][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.584    [weighted Loss:1.584    Policy Loss: 5.851    Value Loss: 3.853    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 52122      Buffer Size: 49864      Transition Number: 499.997 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:08:27,130][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 5.874    Value Loss: 3.938    Reward Loss: 0.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 52381      Buffer Size: 48015      Transition Number: 499.987 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:11:59,531][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 5.695    Value Loss: 3.828    Reward Loss: 0.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 52673      Buffer Size: 46124      Transition Number: 499.998 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:15:33,490][train][INFO][train.py>_log] ==> #83000      Total Loss: 0.810    [weighted Loss:0.810    Policy Loss: 5.685    Value Loss: 3.699    Reward Loss: 0.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 52937      Buffer Size: 44476      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:19:10,521][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 5.932    Value Loss: 3.850    Reward Loss: 0.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 53201      Buffer Size: 42924      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:22:46,023][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.158    [weighted Loss:3.158    Policy Loss: 5.707    Value Loss: 4.013    Reward Loss: 0.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 53467      Buffer Size: 41481      Transition Number: 499.998 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:26:16,267][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 5.864    Value Loss: 4.113    Reward Loss: 0.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 53729      Buffer Size: 40299      Transition Number: 499.998 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:29:51,130][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 5.642    Value Loss: 4.113    Reward Loss: 0.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 53992      Buffer Size: 39116      Transition Number: 499.998 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:33:21,135][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 5.744    Value Loss: 3.844    Reward Loss: 0.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 54244      Buffer Size: 37951      Transition Number: 499.998 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:36:57,889][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 5.857    Value Loss: 4.099    Reward Loss: 0.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 54513      Buffer Size: 36810      Transition Number: 499.993 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:40:38,771][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 5.477    Value Loss: 4.040    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 54779      Buffer Size: 35744      Transition Number: 499.999 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:44:16,145][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.286    [weighted Loss:2.286    Policy Loss: 5.629    Value Loss: 4.260    Reward Loss: 0.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 55056      Buffer Size: 34669      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:47:50,320][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 5.592    Value Loss: 4.180    Reward Loss: 0.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 55335      Buffer Size: 33681      Transition Number: 499.999 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:51:26,248][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.949    [weighted Loss:2.949    Policy Loss: 5.397    Value Loss: 4.149    Reward Loss: 0.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 55604      Buffer Size: 32743      Transition Number: 499.990 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:54:59,901][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.430    [weighted Loss:1.430    Policy Loss: 5.394    Value Loss: 4.149    Reward Loss: 0.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 55847      Buffer Size: 31762      Transition Number: 499.997 k Batch Size: 512        Lr: 0.100   
[2021-11-24 01:58:39,958][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 5.445    Value Loss: 4.027    Reward Loss: 0.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 56119      Buffer Size: 30865      Transition Number: 499.994 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:02:16,901][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 5.552    Value Loss: 4.167    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 56391      Buffer Size: 29950      Transition Number: 499.996 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:05:51,502][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 5.389    Value Loss: 4.300    Reward Loss: 0.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 56653      Buffer Size: 29022      Transition Number: 499.996 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:09:27,983][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 5.527    Value Loss: 4.273    Reward Loss: 0.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 56921      Buffer Size: 28180      Transition Number: 499.999 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:13:02,667][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 5.306    Value Loss: 4.446    Reward Loss: 0.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 57189      Buffer Size: 27373      Transition Number: 499.992 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:16:36,094][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.772    [weighted Loss:3.772    Policy Loss: 5.327    Value Loss: 4.271    Reward Loss: 0.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 57455      Buffer Size: 26706      Transition Number: 499.996 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:20:06,382][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.328    [weighted Loss:3.328    Policy Loss: 5.439    Value Loss: 4.560    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 57701      Buffer Size: 26014      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:23:33,366][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 5.399    Value Loss: 4.456    Reward Loss: 0.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 57958      Buffer Size: 25330      Transition Number: 499.984 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:27:00,880][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 5.176    Value Loss: 4.430    Reward Loss: 0.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 58204      Buffer Size: 24617      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:30:31,114][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 5.209    Value Loss: 4.256    Reward Loss: 0.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 58451      Buffer Size: 23981      Transition Number: 499.997 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:34:05,038][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 5.255    Value Loss: 4.432    Reward Loss: 0.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 58707      Buffer Size: 23368      Transition Number: 499.992 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:37:34,123][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.549    [weighted Loss:2.549    Policy Loss: 5.327    Value Loss: 4.583    Reward Loss: 0.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 58959      Buffer Size: 22869      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:41:01,452][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.872    [weighted Loss:1.872    Policy Loss: 5.262    Value Loss: 4.338    Reward Loss: 0.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 59204      Buffer Size: 22347      Transition Number: 499.995 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:44:33,332][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 4.882    Value Loss: 4.427    Reward Loss: 0.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 59465      Buffer Size: 21917      Transition Number: 499.984 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:48:04,000][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 5.193    Value Loss: 4.647    Reward Loss: 0.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 59726      Buffer Size: 21511      Transition Number: 499.972 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:51:32,034][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 5.179    Value Loss: 4.691    Reward Loss: 0.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 59970      Buffer Size: 21129      Transition Number: 499.986 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:54:59,746][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 5.197    Value Loss: 4.546    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 60222      Buffer Size: 20873      Transition Number: 499.988 k Batch Size: 512        Lr: 0.100   
[2021-11-24 02:58:26,226][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 5.176    Value Loss: 4.532    Reward Loss: 0.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 60475      Buffer Size: 20582      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:01:58,165][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 5.029    Value Loss: 4.535    Reward Loss: 0.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 60725      Buffer Size: 20361      Transition Number: 499.993 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:05:28,229][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.430    [weighted Loss:2.430    Policy Loss: 5.018    Value Loss: 4.617    Reward Loss: 0.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 60970      Buffer Size: 20142      Transition Number: 500.062 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:08:56,649][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 5.096    Value Loss: 4.562    Reward Loss: 0.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 61223      Buffer Size: 19967      Transition Number: 499.996 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:12:29,053][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.626    [weighted Loss:1.626    Policy Loss: 4.908    Value Loss: 4.371    Reward Loss: 0.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 61484      Buffer Size: 19787      Transition Number: 499.998 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:16:04,696][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 4.832    Value Loss: 4.496    Reward Loss: 0.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 61755      Buffer Size: 19670      Transition Number: 499.984 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:19:38,355][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 4.862    Value Loss: 4.430    Reward Loss: 0.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 62016      Buffer Size: 19500      Transition Number: 499.974 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:23:15,134][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.207    [weighted Loss:3.207    Policy Loss: 5.012    Value Loss: 4.506    Reward Loss: 0.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 62274      Buffer Size: 19329      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:26:46,396][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 4.760    Value Loss: 4.659    Reward Loss: 0.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 62533      Buffer Size: 19200      Transition Number: 499.987 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:30:20,649][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.041    [weighted Loss:2.041    Policy Loss: 4.827    Value Loss: 4.479    Reward Loss: 0.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 62797      Buffer Size: 19092      Transition Number: 499.980 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:33:53,084][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 5.255    Value Loss: 4.412    Reward Loss: 0.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 63061      Buffer Size: 19036      Transition Number: 499.979 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:37:23,309][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 5.205    Value Loss: 4.650    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 63320      Buffer Size: 18965      Transition Number: 499.980 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:40:50,112][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.672    [weighted Loss:2.672    Policy Loss: 5.093    Value Loss: 4.589    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 63579      Buffer Size: 18882      Transition Number: 500.033 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:44:17,955][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.115    [weighted Loss:2.115    Policy Loss: 5.175    Value Loss: 4.589    Reward Loss: 0.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 63834      Buffer Size: 18821      Transition Number: 499.997 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:47:44,985][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 4.927    Value Loss: 4.366    Reward Loss: 0.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 64069      Buffer Size: 18739      Transition Number: 499.995 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:51:13,466][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 5.014    Value Loss: 4.450    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 64316      Buffer Size: 18684      Transition Number: 499.995 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:54:42,115][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 5.245    Value Loss: 4.663    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 64579      Buffer Size: 18654      Transition Number: 499.969 k Batch Size: 512        Lr: 0.100   
[2021-11-24 03:58:13,956][train][INFO][train.py>_log] ==> #129000     Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 5.109    Value Loss: 4.513    Reward Loss: 0.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 64849      Buffer Size: 18609      Transition Number: 499.975 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:01:43,259][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 5.174    Value Loss: 4.565    Reward Loss: 0.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 65122      Buffer Size: 18581      Transition Number: 499.984 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:05:14,294][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.101    [weighted Loss:3.101    Policy Loss: 5.090    Value Loss: 4.448    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 65384      Buffer Size: 18552      Transition Number: 499.971 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:08:44,878][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.333    [weighted Loss:3.333    Policy Loss: 5.230    Value Loss: 4.570    Reward Loss: 0.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 65646      Buffer Size: 18548      Transition Number: 500.055 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:12:16,568][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 5.070    Value Loss: 4.688    Reward Loss: 0.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 65905      Buffer Size: 18513      Transition Number: 499.987 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:15:49,515][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 5.013    Value Loss: 4.351    Reward Loss: 0.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 66160      Buffer Size: 18458      Transition Number: 499.988 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:19:20,326][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 5.127    Value Loss: 4.682    Reward Loss: 0.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 66424      Buffer Size: 18440      Transition Number: 499.991 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:22:50,595][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.397    [weighted Loss:1.397    Policy Loss: 5.004    Value Loss: 4.427    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 66683      Buffer Size: 18421      Transition Number: 499.975 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:26:19,154][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 5.164    Value Loss: 4.666    Reward Loss: 0.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 66963      Buffer Size: 18414      Transition Number: 499.988 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:29:49,467][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 5.176    Value Loss: 4.664    Reward Loss: 0.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 67220      Buffer Size: 18391      Transition Number: 500.007 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:33:21,889][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 5.098    Value Loss: 4.653    Reward Loss: 0.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 67476      Buffer Size: 18376      Transition Number: 499.982 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:36:53,192][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.838    [weighted Loss:2.838    Policy Loss: 5.193    Value Loss: 4.651    Reward Loss: 0.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 67733      Buffer Size: 18346      Transition Number: 499.990 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:40:22,293][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 5.438    Value Loss: 4.622    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 68005      Buffer Size: 18336      Transition Number: 499.983 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:43:54,596][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 5.238    Value Loss: 4.550    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 68274      Buffer Size: 18320      Transition Number: 499.967 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:47:25,970][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 5.187    Value Loss: 4.455    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 68540      Buffer Size: 18305      Transition Number: 499.984 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:50:58,924][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 5.486    Value Loss: 4.546    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 68802      Buffer Size: 18290      Transition Number: 499.993 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:54:26,805][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.971    [weighted Loss:2.971    Policy Loss: 5.291    Value Loss: 4.759    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 69055      Buffer Size: 18294      Transition Number: 500.027 k Batch Size: 512        Lr: 0.100   
[2021-11-24 04:57:56,616][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.610    [weighted Loss:3.610    Policy Loss: 5.260    Value Loss: 4.854    Reward Loss: 0.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 69322      Buffer Size: 18275      Transition Number: 499.974 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:01:30,542][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.644    [weighted Loss:2.644    Policy Loss: 5.398    Value Loss: 4.598    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 69594      Buffer Size: 18267      Transition Number: 499.986 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:04:58,830][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 5.276    Value Loss: 4.634    Reward Loss: 0.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 69860      Buffer Size: 18249      Transition Number: 499.996 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:08:27,048][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.465    [weighted Loss:2.465    Policy Loss: 5.452    Value Loss: 4.522    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 70108      Buffer Size: 18247      Transition Number: 499.983 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:11:57,110][train][INFO][train.py>_log] ==> #150000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 5.284    Value Loss: 4.670    Reward Loss: 0.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 70366      Buffer Size: 18224      Transition Number: 499.966 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:15:29,371][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 5.575    Value Loss: 4.568    Reward Loss: 0.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 70619      Buffer Size: 18212      Transition Number: 499.992 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:18:59,426][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 5.312    Value Loss: 4.666    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 70883      Buffer Size: 18194      Transition Number: 499.979 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:22:28,525][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 5.393    Value Loss: 4.856    Reward Loss: 0.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 71144      Buffer Size: 18200      Transition Number: 499.992 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:25:58,867][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.865    [weighted Loss:1.865    Policy Loss: 5.458    Value Loss: 4.712    Reward Loss: 0.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 71397      Buffer Size: 18186      Transition Number: 499.982 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:29:29,171][train][INFO][train.py>_log] ==> #155000     Total Loss: 1.249    [weighted Loss:1.249    Policy Loss: 5.578    Value Loss: 4.560    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 71662      Buffer Size: 18178      Transition Number: 499.999 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:32:55,141][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 5.699    Value Loss: 4.712    Reward Loss: 0.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 71936      Buffer Size: 18197      Transition Number: 499.973 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:36:28,281][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.618    [weighted Loss:2.618    Policy Loss: 5.406    Value Loss: 4.460    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 72196      Buffer Size: 18211      Transition Number: 499.990 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:39:55,681][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 5.404    Value Loss: 4.540    Reward Loss: 0.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 72450      Buffer Size: 18215      Transition Number: 499.991 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:43:26,599][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 5.265    Value Loss: 4.625    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 72709      Buffer Size: 18207      Transition Number: 500.013 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:46:54,209][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 5.578    Value Loss: 4.681    Reward Loss: 0.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 72973      Buffer Size: 18206      Transition Number: 499.974 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:50:23,864][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 5.412    Value Loss: 4.559    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 73239      Buffer Size: 18204      Transition Number: 499.997 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:53:51,570][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 5.651    Value Loss: 4.726    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 73492      Buffer Size: 18200      Transition Number: 499.988 k Batch Size: 512        Lr: 0.100   
[2021-11-24 05:57:25,186][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 5.408    Value Loss: 4.603    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 73766      Buffer Size: 18209      Transition Number: 499.968 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:00:53,410][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 5.508    Value Loss: 4.838    Reward Loss: 0.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 74005      Buffer Size: 18207      Transition Number: 499.982 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:04:22,396][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.941    [weighted Loss:1.941    Policy Loss: 5.484    Value Loss: 4.749    Reward Loss: 0.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 74290      Buffer Size: 18232      Transition Number: 499.981 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:07:56,333][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 5.485    Value Loss: 4.625    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 74561      Buffer Size: 18238      Transition Number: 499.993 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:11:26,874][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 5.743    Value Loss: 4.908    Reward Loss: 0.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 74809      Buffer Size: 18244      Transition Number: 499.982 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:14:54,881][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 5.781    Value Loss: 4.779    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 75061      Buffer Size: 18237      Transition Number: 500.028 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:18:23,266][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 5.712    Value Loss: 4.736    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 75319      Buffer Size: 18233      Transition Number: 499.982 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:21:54,484][train][INFO][train.py>_log] ==> #170000     Total Loss: 3.114    [weighted Loss:3.114    Policy Loss: 5.586    Value Loss: 4.556    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 75583      Buffer Size: 18232      Transition Number: 499.998 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:25:24,533][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.108    [weighted Loss:3.108    Policy Loss: 5.643    Value Loss: 4.605    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 75842      Buffer Size: 18234      Transition Number: 499.980 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:28:55,148][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.782    [weighted Loss:1.782    Policy Loss: 5.746    Value Loss: 4.650    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 76100      Buffer Size: 18241      Transition Number: 499.989 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:32:24,260][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 5.809    Value Loss: 4.607    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 76367      Buffer Size: 18267      Transition Number: 499.991 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:35:56,496][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 5.656    Value Loss: 4.740    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 76635      Buffer Size: 18280      Transition Number: 499.994 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:39:27,702][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 5.756    Value Loss: 4.787    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 76904      Buffer Size: 18293      Transition Number: 499.990 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:43:02,349][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.726    [weighted Loss:2.726    Policy Loss: 5.905    Value Loss: 4.677    Reward Loss: 0.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 77174      Buffer Size: 18308      Transition Number: 499.986 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:46:32,358][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 5.837    Value Loss: 4.749    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 77435      Buffer Size: 18310      Transition Number: 499.992 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:50:04,471][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 5.621    Value Loss: 4.609    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 77700      Buffer Size: 18321      Transition Number: 499.978 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:53:40,264][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 5.879    Value Loss: 4.435    Reward Loss: 0.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 77964      Buffer Size: 18334      Transition Number: 499.985 k Batch Size: 512        Lr: 0.100   
[2021-11-24 06:57:08,195][train][INFO][train.py>_log] ==> #180000     Total Loss: 0.888    [weighted Loss:0.888    Policy Loss: 5.915    Value Loss: 4.684    Reward Loss: 0.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 78216      Buffer Size: 18344      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:00:37,702][train][INFO][train.py>_log] ==> #181000     Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 5.888    Value Loss: 4.782    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 78478      Buffer Size: 18350      Transition Number: 499.979 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:04:07,955][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.702    [weighted Loss:2.702    Policy Loss: 5.763    Value Loss: 4.327    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 78742      Buffer Size: 18373      Transition Number: 499.978 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:07:38,948][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 5.732    Value Loss: 4.653    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 78997      Buffer Size: 18383      Transition Number: 499.971 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:11:06,375][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.939    [weighted Loss:1.939    Policy Loss: 6.028    Value Loss: 4.694    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 79255      Buffer Size: 18397      Transition Number: 499.999 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:14:34,682][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 5.861    Value Loss: 4.637    Reward Loss: 0.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 79515      Buffer Size: 18414      Transition Number: 500.019 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:18:06,785][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.619    [weighted Loss:1.619    Policy Loss: 6.076    Value Loss: 4.664    Reward Loss: 0.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 79776      Buffer Size: 18414      Transition Number: 499.975 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:21:34,226][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 5.854    Value Loss: 4.482    Reward Loss: 0.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 80031      Buffer Size: 18422      Transition Number: 499.990 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:25:01,084][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 6.016    Value Loss: 4.707    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 80284      Buffer Size: 18426      Transition Number: 500.026 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:28:31,341][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 5.885    Value Loss: 4.692    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 80546      Buffer Size: 18438      Transition Number: 499.967 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:31:58,891][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.013    [weighted Loss:3.013    Policy Loss: 5.997    Value Loss: 4.630    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 80806      Buffer Size: 18443      Transition Number: 499.988 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:35:27,726][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 5.890    Value Loss: 4.728    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 81075      Buffer Size: 18455      Transition Number: 499.988 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:38:59,527][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 6.102    Value Loss: 4.890    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 81332      Buffer Size: 18453      Transition Number: 499.992 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:42:28,656][train][INFO][train.py>_log] ==> #193000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 6.054    Value Loss: 4.836    Reward Loss: 0.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 81592      Buffer Size: 18462      Transition Number: 500.049 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:45:59,063][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.239    [weighted Loss:2.239    Policy Loss: 6.381    Value Loss: 4.761    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 81852      Buffer Size: 18471      Transition Number: 499.992 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:49:28,949][train][INFO][train.py>_log] ==> #195000     Total Loss: 1.997    [weighted Loss:1.997    Policy Loss: 5.948    Value Loss: 4.760    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 82124      Buffer Size: 18489      Transition Number: 499.995 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:52:57,166][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 6.048    Value Loss: 4.457    Reward Loss: 0.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 82381      Buffer Size: 18501      Transition Number: 499.972 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:56:24,595][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 5.932    Value Loss: 4.629    Reward Loss: 0.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 82637      Buffer Size: 18515      Transition Number: 499.995 k Batch Size: 512        Lr: 0.100   
[2021-11-24 07:59:53,444][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 6.229    Value Loss: 4.620    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 82888      Buffer Size: 18537      Transition Number: 499.988 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:03:25,464][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 6.010    Value Loss: 4.735    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 83146      Buffer Size: 18526      Transition Number: 499.973 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:06:56,659][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 5.931    Value Loss: 4.702    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 83415      Buffer Size: 18520      Transition Number: 499.979 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:10:28,550][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.962    [weighted Loss:2.962    Policy Loss: 6.298    Value Loss: 4.558    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 83685      Buffer Size: 18528      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:14:00,632][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 6.187    Value Loss: 4.708    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 83952      Buffer Size: 18530      Transition Number: 499.978 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:17:30,579][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 6.142    Value Loss: 4.642    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 84213      Buffer Size: 18525      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:21:01,887][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 6.095    Value Loss: 4.638    Reward Loss: 0.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 84473      Buffer Size: 18546      Transition Number: 499.984 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:24:31,905][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 6.154    Value Loss: 4.696    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 84721      Buffer Size: 18552      Transition Number: 499.987 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:28:04,184][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 6.490    Value Loss: 4.707    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 84975      Buffer Size: 18555      Transition Number: 499.991 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:31:36,040][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.701    [weighted Loss:2.701    Policy Loss: 6.166    Value Loss: 4.662    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 85240      Buffer Size: 18551      Transition Number: 499.970 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:35:11,534][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 6.024    Value Loss: 4.532    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 85505      Buffer Size: 18541      Transition Number: 500.000 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:38:45,763][train][INFO][train.py>_log] ==> #209000     Total Loss: 0.909    [weighted Loss:0.909    Policy Loss: 6.424    Value Loss: 4.643    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 85763      Buffer Size: 18528      Transition Number: 499.992 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:42:15,592][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.382    Value Loss: 4.743    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 86017      Buffer Size: 18526      Transition Number: 499.973 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:45:46,525][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.152    [weighted Loss:2.152    Policy Loss: 6.169    Value Loss: 4.624    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 86272      Buffer Size: 18532      Transition Number: 499.987 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:49:13,262][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.522    [weighted Loss:1.522    Policy Loss: 6.253    Value Loss: 4.625    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 86527      Buffer Size: 18529      Transition Number: 499.997 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:52:45,098][train][INFO][train.py>_log] ==> #213000     Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 6.259    Value Loss: 4.789    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 86797      Buffer Size: 18526      Transition Number: 499.988 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:56:16,322][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 6.257    Value Loss: 4.533    Reward Loss: 0.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 87064      Buffer Size: 18535      Transition Number: 499.991 k Batch Size: 512        Lr: 0.100   
[2021-11-24 08:59:48,791][train][INFO][train.py>_log] ==> #215000     Total Loss: 0.646    [weighted Loss:0.646    Policy Loss: 6.130    Value Loss: 4.537    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 87317      Buffer Size: 18531      Transition Number: 499.979 k Batch Size: 512        Lr: 0.100   
[2021-11-24 09:03:23,629][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 6.425    Value Loss: 4.661    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 87591      Buffer Size: 18536      Transition Number: 500.012 k Batch Size: 512        Lr: 0.100   
[2021-11-24 09:06:53,919][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.082    [weighted Loss:2.082    Policy Loss: 6.428    Value Loss: 4.623    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 87842      Buffer Size: 18536      Transition Number: 499.972 k Batch Size: 512        Lr: 0.100   
[2021-11-24 09:10:25,438][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 6.480    Value Loss: 4.780    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 88104      Buffer Size: 18537      Transition Number: 499.971 k Batch Size: 512        Lr: 0.100   
[2021-11-24 09:14:00,114][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.142    [weighted Loss:1.142    Policy Loss: 6.203    Value Loss: 4.349    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 88376      Buffer Size: 18539      Transition Number: 499.978 k Batch Size: 512        Lr: 0.100   
[2021-11-24 09:17:31,918][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 6.434    Value Loss: 4.450    Reward Loss: 0.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 88645      Buffer Size: 18537      Transition Number: 499.991 k Batch Size: 512        Lr: 0.100   
[2021-11-24 09:21:05,544][train][INFO][train.py>_log] ==> #221000     Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 6.570    Value Loss: 4.665    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 88897      Buffer Size: 18542      Transition Number: 500.006 k Batch Size: 512        Lr: 0.100   
[2021-11-24 09:24:40,642][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 6.257    Value Loss: 4.614    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 89163      Buffer Size: 18542      Transition Number: 499.970 k Batch Size: 512        Lr: 0.100   
