[2021-11-12 15:31:59,118][train][INFO][train.py>_log] ==> #0          Total Loss: 43.549   [weighted Loss:43.549   Policy Loss: 13.551   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 112        Buffer Size: 112        Transition Number: 1.327   k Batch Size: 128        Lr: 0.000   
[2021-11-12 15:37:59,687][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.951    [weighted Loss:6.951    Policy Loss: 14.220   Value Loss: 3.891    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 1474       Buffer Size: 1474       Transition Number: 17.974  k Batch Size: 128        Lr: 0.020   
[2021-11-12 15:45:22,815][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.548    [weighted Loss:4.548    Policy Loss: 13.247   Value Loss: 3.458    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 3359       Buffer Size: 3359       Transition Number: 37.928  k Batch Size: 128        Lr: 0.040   
[2021-11-12 15:52:33,771][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.498    [weighted Loss:5.498    Policy Loss: 13.014   Value Loss: 3.308    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 5275       Buffer Size: 5275       Transition Number: 55.317  k Batch Size: 128        Lr: 0.060   
[2021-11-12 15:59:39,236][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.902    [weighted Loss:5.902    Policy Loss: 12.019   Value Loss: 2.773    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 7362       Buffer Size: 7362       Transition Number: 72.371  k Batch Size: 128        Lr: 0.080   
[2021-11-12 16:07:09,369][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.406    [weighted Loss:4.406    Policy Loss: 12.608   Value Loss: 2.826    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 8718       Buffer Size: 8718       Transition Number: 89.297  k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:14:38,991][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.297    [weighted Loss:6.297    Policy Loss: 12.355   Value Loss: 3.212    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 9977       Buffer Size: 9977       Transition Number: 106.295 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:22:44,971][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.976    [weighted Loss:4.976    Policy Loss: 11.608   Value Loss: 2.867    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 11525      Buffer Size: 11525      Transition Number: 124.174 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:31:44,826][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.814    [weighted Loss:5.814    Policy Loss: 11.838   Value Loss: 2.819    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 13189      Buffer Size: 13189      Transition Number: 144.560 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:40:47,135][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.699    [weighted Loss:4.699    Policy Loss: 12.258   Value Loss: 3.166    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 15091      Buffer Size: 15091      Transition Number: 165.227 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:49:37,453][train][INFO][train.py>_log] ==> #20000      Total Loss: 6.345    [weighted Loss:6.345    Policy Loss: 12.651   Value Loss: 2.929    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 17085      Buffer Size: 17085      Transition Number: 185.997 k Batch Size: 128        Lr: 0.100   
[2021-11-12 16:58:40,881][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.949    [weighted Loss:3.949    Policy Loss: 12.017   Value Loss: 2.713    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 19007      Buffer Size: 19007      Transition Number: 206.608 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:08:38,724][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.470    [weighted Loss:5.470    Policy Loss: 11.519   Value Loss: 2.908    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 19949      Buffer Size: 19949      Transition Number: 223.916 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:19:37,862][train][INFO][train.py>_log] ==> #26000      Total Loss: 4.688    [weighted Loss:4.688    Policy Loss: 10.165   Value Loss: 3.191    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 20836      Buffer Size: 20836      Transition Number: 242.649 k Batch Size: 128        Lr: 0.100   
[2021-11-12 17:32:10,829][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.418    [weighted Loss:3.418    Policy Loss: 9.332    Value Loss: 3.151    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 21605      Buffer Size: 21605      Transition Number: 265.194 k Batch Size: 128        Lr: 0.100   
