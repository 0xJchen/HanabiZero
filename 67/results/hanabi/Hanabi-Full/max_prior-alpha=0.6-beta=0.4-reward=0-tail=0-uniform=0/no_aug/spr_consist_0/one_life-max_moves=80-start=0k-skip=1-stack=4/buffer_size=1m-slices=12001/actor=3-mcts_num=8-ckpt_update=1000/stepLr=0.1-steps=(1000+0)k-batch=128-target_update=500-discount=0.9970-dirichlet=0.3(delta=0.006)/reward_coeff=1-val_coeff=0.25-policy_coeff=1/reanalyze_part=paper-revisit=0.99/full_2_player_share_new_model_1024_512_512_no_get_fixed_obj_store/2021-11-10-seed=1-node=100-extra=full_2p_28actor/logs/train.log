[2021-11-10 17:15:24,830][train][INFO][train.py>_log] ==> #0          Total Loss: 43.713   [weighted Loss:43.713   Policy Loss: 13.715   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 52         Buffer Size: 52         Transition Number: 0.586   k Batch Size: 128        Lr: 0.000   
[2021-11-10 17:18:23,316][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.089    [weighted Loss:6.089    Policy Loss: 14.206   Value Loss: 5.114    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 691        Buffer Size: 691        Transition Number: 8.232   k Batch Size: 128        Lr: 0.010   
[2021-11-10 17:22:04,312][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.324    [weighted Loss:3.324    Policy Loss: 14.639   Value Loss: 3.856    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1452       Buffer Size: 1452       Transition Number: 16.889  k Batch Size: 128        Lr: 0.020   
[2021-11-10 17:25:54,917][train][INFO][train.py>_log] ==> #3000       Total Loss: 8.302    [weighted Loss:8.302    Policy Loss: 15.128   Value Loss: 3.446    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2221       Buffer Size: 2221       Transition Number: 25.466  k Batch Size: 128        Lr: 0.030   
[2021-11-10 17:29:49,458][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.472    [weighted Loss:5.472    Policy Loss: 13.605   Value Loss: 3.110    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 3033       Buffer Size: 3033       Transition Number: 34.414  k Batch Size: 128        Lr: 0.040   
[2021-11-10 17:33:42,190][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.787    [weighted Loss:5.787    Policy Loss: 13.142   Value Loss: 2.833    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 3845       Buffer Size: 3845       Transition Number: 43.120  k Batch Size: 128        Lr: 0.050   
[2021-11-10 17:37:43,511][train][INFO][train.py>_log] ==> #6000       Total Loss: 7.416    [weighted Loss:7.416    Policy Loss: 14.417   Value Loss: 2.909    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 4604       Buffer Size: 4604       Transition Number: 52.216  k Batch Size: 128        Lr: 0.060   
[2021-11-10 17:41:38,691][train][INFO][train.py>_log] ==> #7000       Total Loss: 6.765    [weighted Loss:6.765    Policy Loss: 12.912   Value Loss: 2.787    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 5278       Buffer Size: 5278       Transition Number: 60.849  k Batch Size: 128        Lr: 0.070   
[2021-11-10 17:45:32,613][train][INFO][train.py>_log] ==> #8000       Total Loss: 6.526    [weighted Loss:6.526    Policy Loss: 12.926   Value Loss: 2.781    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 6293       Buffer Size: 6293       Transition Number: 69.922  k Batch Size: 128        Lr: 0.080   
[2021-11-10 17:49:24,488][train][INFO][train.py>_log] ==> #9000       Total Loss: 6.789    [weighted Loss:6.789    Policy Loss: 13.039   Value Loss: 2.648    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 7153       Buffer Size: 7153       Transition Number: 78.596  k Batch Size: 128        Lr: 0.090   
[2021-11-10 17:53:23,393][train][INFO][train.py>_log] ==> #10000      Total Loss: 7.660    [weighted Loss:7.660    Policy Loss: 13.551   Value Loss: 2.835    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 7889       Buffer Size: 7889       Transition Number: 87.498  k Batch Size: 128        Lr: 0.100   
[2021-11-10 17:57:47,825][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.914    [weighted Loss:5.914    Policy Loss: 13.280   Value Loss: 2.736    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 8727       Buffer Size: 8727       Transition Number: 97.547  k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:01:48,197][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.029    [weighted Loss:6.029    Policy Loss: 13.105   Value Loss: 3.158    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 9588       Buffer Size: 9588       Transition Number: 106.934 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:05:47,902][train][INFO][train.py>_log] ==> #13000      Total Loss: 6.087    [weighted Loss:6.087    Policy Loss: 13.892   Value Loss: 3.064    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 10411      Buffer Size: 10411      Transition Number: 115.741 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:09:56,378][train][INFO][train.py>_log] ==> #14000      Total Loss: 6.217    [weighted Loss:6.217    Policy Loss: 13.735   Value Loss: 2.989    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 11284      Buffer Size: 11284      Transition Number: 125.287 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:14:00,886][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.010    [weighted Loss:5.010    Policy Loss: 13.363   Value Loss: 2.743    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 12025      Buffer Size: 12025      Transition Number: 134.446 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:18:06,432][train][INFO][train.py>_log] ==> #16000      Total Loss: 7.361    [weighted Loss:7.361    Policy Loss: 14.535   Value Loss: 2.858    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 12584      Buffer Size: 12584      Transition Number: 143.388 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:22:19,120][train][INFO][train.py>_log] ==> #17000      Total Loss: 6.074    [weighted Loss:6.074    Policy Loss: 13.981   Value Loss: 2.774    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 13118      Buffer Size: 13118      Transition Number: 152.440 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:26:39,809][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.566    [weighted Loss:4.566    Policy Loss: 13.091   Value Loss: 3.080    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 13735      Buffer Size: 13735      Transition Number: 161.980 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:30:57,035][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 12.757   Value Loss: 2.738    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 14497      Buffer Size: 14497      Transition Number: 171.841 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:35:11,922][train][INFO][train.py>_log] ==> #20000      Total Loss: 7.236    [weighted Loss:7.236    Policy Loss: 12.911   Value Loss: 2.708    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 15244      Buffer Size: 15244      Transition Number: 181.132 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:39:31,864][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.888    [weighted Loss:4.888    Policy Loss: 12.797   Value Loss: 2.615    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 16062      Buffer Size: 16062      Transition Number: 190.762 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:43:50,468][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.016    [weighted Loss:4.016    Policy Loss: 12.836   Value Loss: 2.842    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 16887      Buffer Size: 16887      Transition Number: 200.338 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:48:21,237][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.598    [weighted Loss:3.598    Policy Loss: 14.171   Value Loss: 2.615    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 17513      Buffer Size: 17513      Transition Number: 209.730 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:52:51,982][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.475    [weighted Loss:5.475    Policy Loss: 14.075   Value Loss: 3.043    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 18094      Buffer Size: 18094      Transition Number: 219.028 k Batch Size: 128        Lr: 0.100   
[2021-11-10 18:57:29,067][train][INFO][train.py>_log] ==> #25000      Total Loss: 6.064    [weighted Loss:6.064    Policy Loss: 13.328   Value Loss: 2.821    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 18562      Buffer Size: 18562      Transition Number: 227.041 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:02:15,841][train][INFO][train.py>_log] ==> #26000      Total Loss: 4.731    [weighted Loss:4.731    Policy Loss: 14.001   Value Loss: 3.095    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 19064      Buffer Size: 19064      Transition Number: 236.602 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:07:33,850][train][INFO][train.py>_log] ==> #27000      Total Loss: 4.778    [weighted Loss:4.778    Policy Loss: 12.055   Value Loss: 2.826    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 19505      Buffer Size: 19505      Transition Number: 245.705 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:13:02,705][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.460    [weighted Loss:4.460    Policy Loss: 12.079   Value Loss: 3.017    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 19867      Buffer Size: 19867      Transition Number: 254.736 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:18:54,572][train][INFO][train.py>_log] ==> #29000      Total Loss: 5.224    [weighted Loss:5.224    Policy Loss: 12.849   Value Loss: 3.385    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 20250      Buffer Size: 20250      Transition Number: 264.652 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:25:16,847][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 11.235   Value Loss: 3.186    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 20637      Buffer Size: 20637      Transition Number: 275.297 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:32:13,279][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.865    [weighted Loss:4.865    Policy Loss: 10.659   Value Loss: 3.766    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 21020      Buffer Size: 21020      Transition Number: 287.363 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:39:03,965][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.214    [weighted Loss:4.214    Policy Loss: 8.802    Value Loss: 3.476    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 21359      Buffer Size: 21359      Transition Number: 299.459 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:46:03,536][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.765    [weighted Loss:3.765    Policy Loss: 8.359    Value Loss: 3.555    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 21710      Buffer Size: 21710      Transition Number: 310.521 k Batch Size: 128        Lr: 0.100   
[2021-11-10 19:53:22,523][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.325    [weighted Loss:3.325    Policy Loss: 6.997    Value Loss: 3.501    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 22068      Buffer Size: 22068      Transition Number: 323.343 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:01:15,524][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 5.992    Value Loss: 3.626    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 22493      Buffer Size: 22493      Transition Number: 337.064 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:08:51,691][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.594    [weighted Loss:3.594    Policy Loss: 5.605    Value Loss: 3.695    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 23873      Buffer Size: 23873      Transition Number: 351.929 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:15:56,156][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 4.611    Value Loss: 3.569    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 26839      Buffer Size: 26839      Transition Number: 367.372 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:23:12,696][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 4.087    Value Loss: 3.560    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 27503      Buffer Size: 27503      Transition Number: 379.537 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:31:03,748][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 10.208   Value Loss: 3.983    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 28256      Buffer Size: 28256      Transition Number: 392.942 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:38:49,152][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.670    [weighted Loss:1.670    Policy Loss: 2.950    Value Loss: 4.003    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 28907      Buffer Size: 28366      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:46:47,979][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 3.094    Value Loss: 3.766    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 29544      Buffer Size: 27852      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 20:54:52,037][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.315    [weighted Loss:1.315    Policy Loss: 2.880    Value Loss: 3.580    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 30367      Buffer Size: 27539      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:03:19,453][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 2.329    Value Loss: 4.334    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 30942      Buffer Size: 26734      Transition Number: 400.055 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:11:51,464][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 2.766    Value Loss: 4.251    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 31474      Buffer Size: 26197      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:20:16,115][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.243    [weighted Loss:1.243    Policy Loss: 3.962    Value Loss: 3.963    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 32063      Buffer Size: 25311      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:29:03,150][train][INFO][train.py>_log] ==> #46000      Total Loss: 0.828    [weighted Loss:0.828    Policy Loss: 2.407    Value Loss: 3.906    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 32669      Buffer Size: 24621      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:38:14,524][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.097    [weighted Loss:1.097    Policy Loss: 1.962    Value Loss: 4.085    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 33066      Buffer Size: 23528      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:47:56,613][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.323    [weighted Loss:1.323    Policy Loss: 2.230    Value Loss: 3.950    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 33567      Buffer Size: 22426      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-10 21:57:50,447][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 2.061    Value Loss: 4.113    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 34051      Buffer Size: 21627      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:07:52,737][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.225    [weighted Loss:1.225    Policy Loss: 1.325    Value Loss: 4.116    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 34710      Buffer Size: 21379      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:17:46,077][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 3.279    Value Loss: 4.107    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 35353      Buffer Size: 20960      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:27:39,552][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 3.150    Value Loss: 3.854    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 36256      Buffer Size: 20663      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:36:58,572][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.744    [weighted Loss:1.744    Policy Loss: 1.433    Value Loss: 4.273    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 38248      Buffer Size: 21200      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:46:29,853][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 2.541    Value Loss: 4.024    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 39290      Buffer Size: 21255      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-10 22:56:11,971][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.076    [weighted Loss:1.076    Policy Loss: 2.319    Value Loss: 3.916    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 40096      Buffer Size: 21191      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:06:08,749][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 1.690    Value Loss: 4.213    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 40855      Buffer Size: 21191      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:16:22,947][train][INFO][train.py>_log] ==> #57000      Total Loss: 1.590    [weighted Loss:1.590    Policy Loss: 2.210    Value Loss: 4.127    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 41408      Buffer Size: 21045      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:26:32,467][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 2.110    Value Loss: 3.986    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 42078      Buffer Size: 21134      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:36:45,367][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 2.044    Value Loss: 4.281    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 42730      Buffer Size: 21237      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:46:33,682][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.722    [weighted Loss:1.722    Policy Loss: 2.250    Value Loss: 4.094    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 43413      Buffer Size: 21394      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-10 23:56:10,188][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 2.453    Value Loss: 4.200    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 44485      Buffer Size: 21829      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:05:29,360][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 6.930    Value Loss: 4.551    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 45708      Buffer Size: 20677      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:14:16,402][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 4.573    Value Loss: 4.022    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 48203      Buffer Size: 20878      Transition Number: 400.002 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:23:07,683][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.940    [weighted Loss:2.940    Policy Loss: 4.337    Value Loss: 3.970    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 50011      Buffer Size: 21769      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:32:12,402][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 3.608    Value Loss: 4.131    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 51064      Buffer Size: 22077      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:41:31,794][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 4.880    Value Loss: 3.968    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 51693      Buffer Size: 21843      Transition Number: 400.009 k Batch Size: 128        Lr: 0.100   
[2021-11-11 00:51:05,675][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 7.513    Value Loss: 4.405    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 52250      Buffer Size: 21559      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:00:51,709][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.052    [weighted Loss:4.052    Policy Loss: 7.539    Value Loss: 4.311    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 52770      Buffer Size: 21393      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:10:12,844][train][INFO][train.py>_log] ==> #69000      Total Loss: 5.187    [weighted Loss:5.187    Policy Loss: 9.595    Value Loss: 4.433    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 54058      Buffer Size: 21974      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:19:27,122][train][INFO][train.py>_log] ==> #70000      Total Loss: 4.209    [weighted Loss:4.209    Policy Loss: 9.187    Value Loss: 4.406    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 54674      Buffer Size: 21946      Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:29:09,067][train][INFO][train.py>_log] ==> #71000      Total Loss: 5.961    [weighted Loss:5.961    Policy Loss: 9.703    Value Loss: 4.631    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 55135      Buffer Size: 22002      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-11 01:38:42,341][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.561    [weighted Loss:3.561    Policy Loss: 8.708    Value Loss: 4.515    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 55554      Buffer Size: 21952      Transition Number: 399.925 k Batch Size: 128        Lr: 0.100   
