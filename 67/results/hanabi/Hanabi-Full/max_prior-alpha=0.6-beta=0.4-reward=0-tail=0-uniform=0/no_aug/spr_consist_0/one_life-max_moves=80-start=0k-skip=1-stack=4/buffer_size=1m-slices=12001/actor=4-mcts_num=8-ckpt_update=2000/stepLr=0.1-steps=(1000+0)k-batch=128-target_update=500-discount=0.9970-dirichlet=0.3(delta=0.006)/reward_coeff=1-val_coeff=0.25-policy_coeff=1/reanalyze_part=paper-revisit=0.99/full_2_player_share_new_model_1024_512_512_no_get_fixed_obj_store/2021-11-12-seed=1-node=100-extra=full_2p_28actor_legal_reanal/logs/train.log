[2021-11-12 19:35:55,153][train][INFO][train.py>_log] ==> #0          Total Loss: 44.087   [weighted Loss:44.087   Policy Loss: 14.090   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 54         Buffer Size: 54         Transition Number: 0.673   k Batch Size: 128        Lr: 0.000   
[2021-11-12 19:40:43,191][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.680    [weighted Loss:4.680    Policy Loss: 14.450   Value Loss: 3.882    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 1119       Buffer Size: 1119       Transition Number: 13.467  k Batch Size: 128        Lr: 0.020   
[2021-11-12 19:45:53,486][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.567    [weighted Loss:5.567    Policy Loss: 12.745   Value Loss: 3.101    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 2268       Buffer Size: 2268       Transition Number: 26.396  k Batch Size: 128        Lr: 0.040   
[2021-11-12 19:51:02,200][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.350    [weighted Loss:5.350    Policy Loss: 12.374   Value Loss: 3.040    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 3752       Buffer Size: 3752       Transition Number: 39.204  k Batch Size: 128        Lr: 0.060   
[2021-11-12 19:56:14,078][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.230    [weighted Loss:5.230    Policy Loss: 11.888   Value Loss: 2.915    Reward Loss: 0.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 5242       Buffer Size: 5242       Transition Number: 52.274  k Batch Size: 128        Lr: 0.080   
[2021-11-12 20:01:29,108][train][INFO][train.py>_log] ==> #10000      Total Loss: 6.030    [weighted Loss:6.030    Policy Loss: 12.280   Value Loss: 2.658    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 6302       Buffer Size: 6302       Transition Number: 65.144  k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:06:38,237][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.277    [weighted Loss:5.277    Policy Loss: 11.947   Value Loss: 2.608    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 7234       Buffer Size: 7234       Transition Number: 77.535  k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:11:48,383][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.629    [weighted Loss:4.629    Policy Loss: 10.708   Value Loss: 2.685    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 8410       Buffer Size: 8410       Transition Number: 90.220  k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:16:59,908][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.403    [weighted Loss:5.403    Policy Loss: 12.277   Value Loss: 3.047    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 10095      Buffer Size: 10095      Transition Number: 103.307 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:22:11,544][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.675    [weighted Loss:5.675    Policy Loss: 12.093   Value Loss: 2.627    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 11601      Buffer Size: 11601      Transition Number: 116.414 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:27:23,812][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 12.258   Value Loss: 2.800    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 13046      Buffer Size: 13046      Transition Number: 129.442 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:32:59,286][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.923    [weighted Loss:4.923    Policy Loss: 12.413   Value Loss: 2.772    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 14443      Buffer Size: 14443      Transition Number: 141.875 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:38:28,562][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.980    [weighted Loss:3.980    Policy Loss: 11.723   Value Loss: 2.766    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 15523      Buffer Size: 15523      Transition Number: 151.224 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:44:02,914][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 11.115   Value Loss: 2.681    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 16428      Buffer Size: 16428      Transition Number: 159.651 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:49:36,676][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.482    [weighted Loss:3.482    Policy Loss: 11.242   Value Loss: 2.719    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 17287      Buffer Size: 17287      Transition Number: 168.267 k Batch Size: 128        Lr: 0.100   
[2021-11-12 20:55:13,388][train][INFO][train.py>_log] ==> #30000      Total Loss: 5.229    [weighted Loss:5.229    Policy Loss: 11.835   Value Loss: 2.861    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 18090      Buffer Size: 18090      Transition Number: 176.776 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:00:47,057][train][INFO][train.py>_log] ==> #32000      Total Loss: 5.331    [weighted Loss:5.331    Policy Loss: 11.728   Value Loss: 3.064    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 18984      Buffer Size: 18984      Transition Number: 185.361 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:06:22,289][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.219    [weighted Loss:3.219    Policy Loss: 11.416   Value Loss: 2.819    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 19994      Buffer Size: 19994      Transition Number: 194.068 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:11:57,209][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 10.433   Value Loss: 2.461    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 20892      Buffer Size: 20892      Transition Number: 202.798 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:17:32,343][train][INFO][train.py>_log] ==> #38000      Total Loss: 4.586    [weighted Loss:4.586    Policy Loss: 11.296   Value Loss: 2.634    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 21600      Buffer Size: 21600      Transition Number: 211.228 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:23:05,722][train][INFO][train.py>_log] ==> #40000      Total Loss: 6.711    [weighted Loss:6.711    Policy Loss: 12.773   Value Loss: 2.709    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 22229      Buffer Size: 22229      Transition Number: 219.500 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:28:37,472][train][INFO][train.py>_log] ==> #42000      Total Loss: 5.410    [weighted Loss:5.410    Policy Loss: 11.885   Value Loss: 2.739    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 22830      Buffer Size: 22830      Transition Number: 227.618 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:34:11,379][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.575    [weighted Loss:3.575    Policy Loss: 11.625   Value Loss: 3.042    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 23437      Buffer Size: 23437      Transition Number: 235.643 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:39:47,691][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.555    [weighted Loss:4.555    Policy Loss: 11.488   Value Loss: 2.887    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 23971      Buffer Size: 23971      Transition Number: 243.349 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:45:20,800][train][INFO][train.py>_log] ==> #48000      Total Loss: 6.185    [weighted Loss:6.185    Policy Loss: 10.952   Value Loss: 2.767    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 24415      Buffer Size: 24415      Transition Number: 250.365 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:50:57,260][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.121    [weighted Loss:3.121    Policy Loss: 8.809    Value Loss: 3.083    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 24833      Buffer Size: 24833      Transition Number: 256.949 k Batch Size: 128        Lr: 0.100   
[2021-11-12 21:56:31,339][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 9.381    Value Loss: 3.012    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 25401      Buffer Size: 25401      Transition Number: 263.914 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:02:08,737][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.415    [weighted Loss:3.415    Policy Loss: 9.165    Value Loss: 3.091    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 25918      Buffer Size: 25918      Transition Number: 270.151 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:07:42,681][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.510    [weighted Loss:3.510    Policy Loss: 8.586    Value Loss: 3.266    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 26430      Buffer Size: 26430      Transition Number: 276.824 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:13:21,258][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 9.387    Value Loss: 3.160    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 27023      Buffer Size: 27023      Transition Number: 283.535 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:18:54,012][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.978    [weighted Loss:3.978    Policy Loss: 9.157    Value Loss: 2.938    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 27507      Buffer Size: 27507      Transition Number: 289.699 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:24:29,914][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.129    [weighted Loss:2.129    Policy Loss: 8.376    Value Loss: 3.208    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 28027      Buffer Size: 28027      Transition Number: 295.556 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:30:03,937][train][INFO][train.py>_log] ==> #64000      Total Loss: 5.083    [weighted Loss:5.083    Policy Loss: 8.777    Value Loss: 3.103    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 28732      Buffer Size: 28732      Transition Number: 302.940 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:35:39,957][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 9.147    Value Loss: 3.232    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 29447      Buffer Size: 29447      Transition Number: 310.220 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:41:15,958][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 9.552    Value Loss: 3.322    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 30157      Buffer Size: 30157      Transition Number: 318.137 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:46:54,659][train][INFO][train.py>_log] ==> #70000      Total Loss: 4.486    [weighted Loss:4.486    Policy Loss: 8.865    Value Loss: 3.335    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 30527      Buffer Size: 30527      Transition Number: 324.226 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:52:30,613][train][INFO][train.py>_log] ==> #72000      Total Loss: 4.674    [weighted Loss:4.674    Policy Loss: 8.160    Value Loss: 3.248    Reward Loss: 1.269    Consistency Loss: 0.000    ] Replay Episodes Collected: 30915      Buffer Size: 30915      Transition Number: 330.842 k Batch Size: 128        Lr: 0.100   
[2021-11-12 22:58:09,703][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.398    [weighted Loss:4.398    Policy Loss: 8.103    Value Loss: 3.119    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 31222      Buffer Size: 31222      Transition Number: 337.177 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:03:44,644][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.429    [weighted Loss:2.429    Policy Loss: 8.587    Value Loss: 3.649    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 31481      Buffer Size: 31481      Transition Number: 343.397 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:09:24,834][train][INFO][train.py>_log] ==> #78000      Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 7.551    Value Loss: 3.145    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 31705      Buffer Size: 31705      Transition Number: 349.464 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:15:03,028][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.643    [weighted Loss:3.643    Policy Loss: 7.001    Value Loss: 3.527    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 31919      Buffer Size: 31919      Transition Number: 354.777 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:20:45,744][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 5.314    Value Loss: 3.348    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 32135      Buffer Size: 32135      Transition Number: 360.303 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:26:24,527][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 5.781    Value Loss: 3.526    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 32447      Buffer Size: 32447      Transition Number: 366.605 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:32:09,750][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.467    [weighted Loss:1.467    Policy Loss: 5.179    Value Loss: 3.450    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 32677      Buffer Size: 32677      Transition Number: 372.000 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:37:54,189][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 5.465    Value Loss: 3.675    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 32911      Buffer Size: 32911      Transition Number: 377.621 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:43:37,317][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 4.212    Value Loss: 3.419    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 33112      Buffer Size: 33112      Transition Number: 383.757 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:49:21,194][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.958    [weighted Loss:2.958    Policy Loss: 5.681    Value Loss: 3.576    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 33215      Buffer Size: 33215      Transition Number: 389.246 k Batch Size: 128        Lr: 0.100   
[2021-11-12 23:55:02,465][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.195    [weighted Loss:3.195    Policy Loss: 4.901    Value Loss: 3.989    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 33349      Buffer Size: 33349      Transition Number: 395.366 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:00:46,911][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 5.434    Value Loss: 3.923    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 33497      Buffer Size: 33399      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:06:28,259][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.397    [weighted Loss:1.397    Policy Loss: 4.988    Value Loss: 3.826    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 33654      Buffer Size: 33013      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:12:08,333][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 4.504    Value Loss: 3.353    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 33762      Buffer Size: 32660      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:17:51,915][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 4.127    Value Loss: 3.911    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 33884      Buffer Size: 32281      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:23:37,876][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 4.111    Value Loss: 3.561    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 33978      Buffer Size: 31897      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:29:25,924][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.255    [weighted Loss:1.255    Policy Loss: 4.188    Value Loss: 3.685    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 34065      Buffer Size: 31372      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:35:05,476][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 4.355    Value Loss: 3.840    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 34157      Buffer Size: 30740      Transition Number: 400.124 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:40:48,474][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.438    [weighted Loss:1.438    Policy Loss: 5.006    Value Loss: 3.952    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 34274      Buffer Size: 30228      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:46:28,148][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.409    [weighted Loss:2.409    Policy Loss: 5.053    Value Loss: 4.116    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 34406      Buffer Size: 29602      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:52:10,612][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 4.030    Value Loss: 3.812    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 34506      Buffer Size: 29042      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-13 00:57:51,905][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.678    [weighted Loss:1.678    Policy Loss: 3.630    Value Loss: 3.720    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 34616      Buffer Size: 28581      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:03:37,125][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 3.763    Value Loss: 3.888    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 34749      Buffer Size: 28112      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:09:19,196][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 4.560    Value Loss: 3.991    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 34880      Buffer Size: 27600      Transition Number: 400.073 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:15:03,396][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 3.433    Value Loss: 4.064    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 35002      Buffer Size: 26971      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:20:26,909][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 3.487    Value Loss: 3.749    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 35103      Buffer Size: 26260      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:25:48,129][train][INFO][train.py>_log] ==> #126000     Total Loss: 0.946    [weighted Loss:0.946    Policy Loss: 3.278    Value Loss: 3.895    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 35267      Buffer Size: 25317      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:31:06,891][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.550    [weighted Loss:1.550    Policy Loss: 3.793    Value Loss: 4.337    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 35442      Buffer Size: 24433      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:36:29,078][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.938    [weighted Loss:1.938    Policy Loss: 3.140    Value Loss: 4.441    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 35610      Buffer Size: 23508      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:41:47,585][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.671    [weighted Loss:1.671    Policy Loss: 4.477    Value Loss: 4.614    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 35772      Buffer Size: 22501      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:47:09,703][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.424    [weighted Loss:1.424    Policy Loss: 3.374    Value Loss: 4.037    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 35960      Buffer Size: 21320      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:52:26,035][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.442    [weighted Loss:1.442    Policy Loss: 3.254    Value Loss: 4.149    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 36134      Buffer Size: 20247      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 01:57:50,268][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.296    [weighted Loss:1.296    Policy Loss: 3.064    Value Loss: 4.276    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 36294      Buffer Size: 19276      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:03:09,469][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.698    [weighted Loss:1.698    Policy Loss: 4.191    Value Loss: 4.597    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 36466      Buffer Size: 18324      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:08:29,192][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.488    [weighted Loss:1.488    Policy Loss: 3.856    Value Loss: 4.631    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 36635      Buffer Size: 17341      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:13:44,992][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 3.809    Value Loss: 4.658    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 36813      Buffer Size: 16185      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:19:06,751][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 3.796    Value Loss: 4.596    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 36986      Buffer Size: 15358      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:24:24,302][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 4.172    Value Loss: 4.467    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 37178      Buffer Size: 14715      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:29:43,684][train][INFO][train.py>_log] ==> #150000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 3.645    Value Loss: 4.614    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 37344      Buffer Size: 14042      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:35:00,469][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 3.816    Value Loss: 4.555    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 37532      Buffer Size: 13379      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:40:19,826][train][INFO][train.py>_log] ==> #154000     Total Loss: 0.886    [weighted Loss:0.886    Policy Loss: 3.519    Value Loss: 4.487    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 37725      Buffer Size: 12960      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:45:38,130][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 4.236    Value Loss: 4.554    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 37907      Buffer Size: 12210      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:50:59,175][train][INFO][train.py>_log] ==> #158000     Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 3.970    Value Loss: 4.462    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 38086      Buffer Size: 11455      Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-13 02:56:17,250][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 3.629    Value Loss: 4.332    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 38263      Buffer Size: 10563      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:01:34,557][train][INFO][train.py>_log] ==> #162000     Total Loss: 0.847    [weighted Loss:0.847    Policy Loss: 4.143    Value Loss: 4.445    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 38433      Buffer Size: 9655       Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:06:50,228][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 6.325    Value Loss: 4.898    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 38617      Buffer Size: 8724       Transition Number: 399.927 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:12:08,283][train][INFO][train.py>_log] ==> #166000     Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 4.464    Value Loss: 4.650    Reward Loss: 0.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 38790      Buffer Size: 8151       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:17:23,438][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.552    [weighted Loss:1.552    Policy Loss: 4.209    Value Loss: 4.873    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 38982      Buffer Size: 7740       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:22:40,948][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 3.849    Value Loss: 4.792    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 39157      Buffer Size: 7527       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:27:55,943][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 4.524    Value Loss: 4.572    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 39335      Buffer Size: 7240       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:33:12,759][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 4.476    Value Loss: 4.634    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 39516      Buffer Size: 6892       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:38:27,450][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 3.779    Value Loss: 4.756    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 39710      Buffer Size: 6671       Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:43:43,289][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.673    [weighted Loss:1.673    Policy Loss: 3.903    Value Loss: 4.545    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 39898      Buffer Size: 6610       Transition Number: 399.933 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:48:57,551][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 3.716    Value Loss: 5.161    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 40084      Buffer Size: 6532       Transition Number: 400.061 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:54:17,194][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.485    [weighted Loss:1.485    Policy Loss: 3.664    Value Loss: 4.511    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 40268      Buffer Size: 6481       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-13 03:59:34,126][train][INFO][train.py>_log] ==> #184000     Total Loss: 0.998    [weighted Loss:0.998    Policy Loss: 3.916    Value Loss: 4.657    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 40501      Buffer Size: 6508       Transition Number: 400.012 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:04:51,802][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.295    [weighted Loss:1.295    Policy Loss: 3.587    Value Loss: 4.980    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 40723      Buffer Size: 6587       Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:10:08,222][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 4.518    Value Loss: 4.910    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 40944      Buffer Size: 6609       Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:15:25,580][train][INFO][train.py>_log] ==> #190000     Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 4.136    Value Loss: 4.681    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 41154      Buffer Size: 6651       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:20:44,683][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 3.828    Value Loss: 4.536    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 41335      Buffer Size: 6653       Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:26:08,978][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 3.699    Value Loss: 4.408    Reward Loss: 0.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 41525      Buffer Size: 6677       Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:31:26,631][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.410    [weighted Loss:1.410    Policy Loss: 3.671    Value Loss: 4.746    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 41906      Buffer Size: 6904       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:36:44,505][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.405    [weighted Loss:2.405    Policy Loss: 3.689    Value Loss: 4.885    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 42175      Buffer Size: 7024       Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:41:59,420][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 3.543    Value Loss: 5.366    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 42407      Buffer Size: 7063       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:47:18,436][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.006    [weighted Loss:2.006    Policy Loss: 3.603    Value Loss: 4.634    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 42599      Buffer Size: 7026       Transition Number: 399.928 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:52:34,577][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 3.792    Value Loss: 4.646    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 42789      Buffer Size: 7046       Transition Number: 399.936 k Batch Size: 128        Lr: 0.100   
[2021-11-13 04:57:50,662][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 4.423    Value Loss: 4.610    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 42981      Buffer Size: 7080       Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:03:07,408][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 3.560    Value Loss: 4.973    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 43162      Buffer Size: 7075       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:08:24,382][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 3.143    Value Loss: 4.695    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 43340      Buffer Size: 7077       Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:13:41,363][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.574    [weighted Loss:1.574    Policy Loss: 3.367    Value Loss: 4.454    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 43528      Buffer Size: 7083       Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:18:58,297][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.199    [weighted Loss:2.199    Policy Loss: 3.718    Value Loss: 4.525    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 43701      Buffer Size: 7087       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:24:16,559][train][INFO][train.py>_log] ==> #216000     Total Loss: 1.317    [weighted Loss:1.317    Policy Loss: 3.246    Value Loss: 4.423    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 43881      Buffer Size: 7087       Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:29:35,582][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 3.590    Value Loss: 5.001    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 44051      Buffer Size: 7078       Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:34:52,292][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 3.445    Value Loss: 5.056    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 44264      Buffer Size: 7080       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:40:13,383][train][INFO][train.py>_log] ==> #222000     Total Loss: 0.946    [weighted Loss:0.946    Policy Loss: 3.182    Value Loss: 4.625    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 44460      Buffer Size: 7119       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:45:33,883][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.221    [weighted Loss:1.221    Policy Loss: 3.467    Value Loss: 4.722    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 44649      Buffer Size: 7116       Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:51:01,766][train][INFO][train.py>_log] ==> #226000     Total Loss: 1.290    [weighted Loss:1.290    Policy Loss: 3.346    Value Loss: 4.767    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 44834      Buffer Size: 7069       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-13 05:56:19,502][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.341    [weighted Loss:1.341    Policy Loss: 3.523    Value Loss: 4.893    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 45012      Buffer Size: 7053       Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:01:43,100][train][INFO][train.py>_log] ==> #230000     Total Loss: 1.856    [weighted Loss:1.856    Policy Loss: 3.246    Value Loss: 4.669    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 45193      Buffer Size: 7064       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:07:04,494][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 3.741    Value Loss: 4.578    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 45372      Buffer Size: 7078       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:12:20,035][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 4.548    Value Loss: 4.943    Reward Loss: 0.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 45568      Buffer Size: 7110       Transition Number: 399.930 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:17:36,586][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 3.663    Value Loss: 5.115    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 45756      Buffer Size: 7119       Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:22:56,522][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 3.598    Value Loss: 5.485    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 45938      Buffer Size: 7116       Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:28:13,676][train][INFO][train.py>_log] ==> #240000     Total Loss: 0.527    [weighted Loss:0.527    Policy Loss: 3.582    Value Loss: 4.919    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 46132      Buffer Size: 7112       Transition Number: 399.935 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:33:35,390][train][INFO][train.py>_log] ==> #242000     Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 3.719    Value Loss: 4.611    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 46322      Buffer Size: 7118       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:38:51,644][train][INFO][train.py>_log] ==> #244000     Total Loss: 1.275    [weighted Loss:1.275    Policy Loss: 4.130    Value Loss: 5.051    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 46528      Buffer Size: 7171       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:44:09,519][train][INFO][train.py>_log] ==> #246000     Total Loss: 0.774    [weighted Loss:0.774    Policy Loss: 3.938    Value Loss: 4.912    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 46763      Buffer Size: 7231       Transition Number: 399.932 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:49:28,210][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 3.828    Value Loss: 4.873    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 46995      Buffer Size: 7276       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 06:54:48,985][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 3.964    Value Loss: 5.211    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 47213      Buffer Size: 7296       Transition Number: 400.065 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:00:08,306][train][INFO][train.py>_log] ==> #252000     Total Loss: 0.927    [weighted Loss:0.927    Policy Loss: 3.852    Value Loss: 4.736    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 47401      Buffer Size: 7294       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:05:25,447][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 3.464    Value Loss: 4.659    Reward Loss: 0.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 47583      Buffer Size: 7284       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:10:41,498][train][INFO][train.py>_log] ==> #256000     Total Loss: 1.852    [weighted Loss:1.852    Policy Loss: 4.088    Value Loss: 4.794    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 47782      Buffer Size: 7244       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:16:01,603][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.166    [weighted Loss:1.166    Policy Loss: 3.987    Value Loss: 5.163    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 47969      Buffer Size: 7178       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:21:17,781][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 5.101    Value Loss: 4.988    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 48294      Buffer Size: 7261       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:26:36,511][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.267    [weighted Loss:1.267    Policy Loss: 4.601    Value Loss: 4.789    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 48607      Buffer Size: 7387       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:31:52,862][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 4.512    Value Loss: 5.084    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 48909      Buffer Size: 7500       Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:37:09,671][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 4.779    Value Loss: 4.930    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 49116      Buffer Size: 7464       Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:42:24,036][train][INFO][train.py>_log] ==> #268000     Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 4.971    Value Loss: 4.767    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 49343      Buffer Size: 7350       Transition Number: 400.014 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:47:40,353][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 5.091    Value Loss: 4.515    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 49534      Buffer Size: 7279       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:52:55,007][train][INFO][train.py>_log] ==> #272000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 4.137    Value Loss: 5.226    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 49725      Buffer Size: 7261       Transition Number: 400.003 k Batch Size: 128        Lr: 0.100   
[2021-11-13 07:58:12,759][train][INFO][train.py>_log] ==> #274000     Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 5.131    Value Loss: 5.029    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 49950      Buffer Size: 7313       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:03:30,273][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 4.218    Value Loss: 4.893    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 50182      Buffer Size: 7339       Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:08:49,296][train][INFO][train.py>_log] ==> #278000     Total Loss: 1.360    [weighted Loss:1.360    Policy Loss: 3.468    Value Loss: 5.078    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 50377      Buffer Size: 7345       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:14:06,569][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.515    [weighted Loss:1.515    Policy Loss: 4.103    Value Loss: 4.822    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 50599      Buffer Size: 7403       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:19:26,070][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.948    [weighted Loss:1.948    Policy Loss: 4.312    Value Loss: 5.097    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 50819      Buffer Size: 7461       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:24:42,753][train][INFO][train.py>_log] ==> #284000     Total Loss: 1.803    [weighted Loss:1.803    Policy Loss: 4.683    Value Loss: 4.770    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 51012      Buffer Size: 7492       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:30:00,016][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 5.098    Value Loss: 4.930    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 51244      Buffer Size: 7567       Transition Number: 400.006 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:35:15,782][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 5.645    Value Loss: 5.175    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 51475      Buffer Size: 7648       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:40:34,714][train][INFO][train.py>_log] ==> #290000     Total Loss: 1.289    [weighted Loss:1.289    Policy Loss: 4.736    Value Loss: 5.356    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 51675      Buffer Size: 7703       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:45:48,421][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.103    [weighted Loss:1.103    Policy Loss: 3.940    Value Loss: 5.049    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 51888      Buffer Size: 7758       Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:51:07,504][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 4.080    Value Loss: 5.451    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 52076      Buffer Size: 7762       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-13 08:56:24,636][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.356    [weighted Loss:2.356    Policy Loss: 5.697    Value Loss: 5.162    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 52379      Buffer Size: 7872       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:01:42,251][train][INFO][train.py>_log] ==> #298000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 3.977    Value Loss: 5.197    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 52621      Buffer Size: 7966       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:06:58,985][train][INFO][train.py>_log] ==> #300000     Total Loss: 1.977    [weighted Loss:1.977    Policy Loss: 4.031    Value Loss: 5.268    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 52814      Buffer Size: 7992       Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:12:16,825][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 4.024    Value Loss: 5.387    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 53003      Buffer Size: 8025       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:17:34,850][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.053    [weighted Loss:1.053    Policy Loss: 3.867    Value Loss: 5.652    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 53194      Buffer Size: 8047       Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:22:55,144][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.136    [weighted Loss:1.136    Policy Loss: 3.784    Value Loss: 4.805    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 53436      Buffer Size: 8139       Transition Number: 399.932 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:28:11,502][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 4.017    Value Loss: 5.062    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 53674      Buffer Size: 8202       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:33:27,878][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.236    [weighted Loss:1.236    Policy Loss: 4.099    Value Loss: 5.183    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 53856      Buffer Size: 8201       Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:38:47,429][train][INFO][train.py>_log] ==> #312000     Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 4.912    Value Loss: 5.091    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 54049      Buffer Size: 8207       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:44:04,800][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 4.461    Value Loss: 4.875    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 54235      Buffer Size: 8221       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:49:21,926][train][INFO][train.py>_log] ==> #316000     Total Loss: 2.309    [weighted Loss:2.309    Policy Loss: 4.048    Value Loss: 5.244    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 54415      Buffer Size: 8218       Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:54:42,690][train][INFO][train.py>_log] ==> #318000     Total Loss: 0.555    [weighted Loss:0.555    Policy Loss: 3.627    Value Loss: 4.719    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 54589      Buffer Size: 8164       Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-13 09:59:57,120][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 4.277    Value Loss: 5.168    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 54769      Buffer Size: 8077       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:05:14,393][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 3.980    Value Loss: 5.521    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 54946      Buffer Size: 8007       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:10:30,648][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.313    [weighted Loss:1.313    Policy Loss: 5.224    Value Loss: 5.140    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 55122      Buffer Size: 7963       Transition Number: 400.033 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:15:47,443][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 4.102    Value Loss: 4.919    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 55303      Buffer Size: 7948       Transition Number: 400.066 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:21:02,784][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 3.705    Value Loss: 5.147    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 55606      Buffer Size: 8068       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:26:20,766][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 4.392    Value Loss: 4.912    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 55837      Buffer Size: 8122       Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:31:36,610][train][INFO][train.py>_log] ==> #332000     Total Loss: 0.962    [weighted Loss:0.962    Policy Loss: 4.958    Value Loss: 4.946    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 56034      Buffer Size: 8142       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:36:53,468][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.542    [weighted Loss:1.542    Policy Loss: 4.618    Value Loss: 5.171    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 56361      Buffer Size: 8213       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:42:08,818][train][INFO][train.py>_log] ==> #336000     Total Loss: 1.236    [weighted Loss:1.236    Policy Loss: 4.220    Value Loss: 5.104    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 56623      Buffer Size: 8146       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:47:28,206][train][INFO][train.py>_log] ==> #338000     Total Loss: 1.214    [weighted Loss:1.214    Policy Loss: 4.894    Value Loss: 5.185    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 56891      Buffer Size: 8092       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:52:42,217][train][INFO][train.py>_log] ==> #340000     Total Loss: 1.175    [weighted Loss:1.175    Policy Loss: 4.033    Value Loss: 5.167    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 57103      Buffer Size: 8061       Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-13 10:58:00,598][train][INFO][train.py>_log] ==> #342000     Total Loss: 1.093    [weighted Loss:1.093    Policy Loss: 3.538    Value Loss: 5.095    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 57284      Buffer Size: 8020       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:03:20,233][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.536    [weighted Loss:1.536    Policy Loss: 3.365    Value Loss: 5.340    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 57485      Buffer Size: 8005       Transition Number: 399.929 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:08:40,675][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.145    [weighted Loss:1.145    Policy Loss: 3.198    Value Loss: 4.926    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 57671      Buffer Size: 7994       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:13:57,034][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.013    [weighted Loss:1.013    Policy Loss: 4.054    Value Loss: 5.269    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 57852      Buffer Size: 7940       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:19:15,732][train][INFO][train.py>_log] ==> #350000     Total Loss: 1.045    [weighted Loss:1.045    Policy Loss: 4.291    Value Loss: 5.444    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 58129      Buffer Size: 7982       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:24:32,078][train][INFO][train.py>_log] ==> #352000     Total Loss: 1.422    [weighted Loss:1.422    Policy Loss: 3.402    Value Loss: 4.835    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 58424      Buffer Size: 8069       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:29:50,914][train][INFO][train.py>_log] ==> #354000     Total Loss: 0.735    [weighted Loss:0.735    Policy Loss: 3.471    Value Loss: 5.412    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 58603      Buffer Size: 8015       Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:35:06,808][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 4.017    Value Loss: 5.825    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 58790      Buffer Size: 7965       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:40:23,050][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 3.821    Value Loss: 5.186    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 58970      Buffer Size: 7931       Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:45:44,088][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.740    [weighted Loss:1.740    Policy Loss: 3.640    Value Loss: 4.843    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 59152      Buffer Size: 7844       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:51:04,904][train][INFO][train.py>_log] ==> #362000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 3.712    Value Loss: 5.057    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 59345      Buffer Size: 7772       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-13 11:56:24,735][train][INFO][train.py>_log] ==> #364000     Total Loss: 0.910    [weighted Loss:0.910    Policy Loss: 4.085    Value Loss: 5.190    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 59542      Buffer Size: 7743       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:01:42,092][train][INFO][train.py>_log] ==> #366000     Total Loss: 0.928    [weighted Loss:0.928    Policy Loss: 3.877    Value Loss: 4.901    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 59742      Buffer Size: 7726       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:07:01,232][train][INFO][train.py>_log] ==> #368000     Total Loss: 1.491    [weighted Loss:1.491    Policy Loss: 4.060    Value Loss: 4.448    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 59935      Buffer Size: 7640       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:12:21,323][train][INFO][train.py>_log] ==> #370000     Total Loss: 0.809    [weighted Loss:0.809    Policy Loss: 3.378    Value Loss: 5.356    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 60117      Buffer Size: 7525       Transition Number: 400.009 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:17:39,576][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.254    [weighted Loss:1.254    Policy Loss: 3.837    Value Loss: 4.954    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 60301      Buffer Size: 7484       Transition Number: 400.126 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:22:59,768][train][INFO][train.py>_log] ==> #374000     Total Loss: 0.552    [weighted Loss:0.552    Policy Loss: 3.601    Value Loss: 4.736    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 60484      Buffer Size: 7444       Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:28:18,719][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.354    [weighted Loss:1.354    Policy Loss: 3.347    Value Loss: 4.563    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 60662      Buffer Size: 7401       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:33:39,409][train][INFO][train.py>_log] ==> #378000     Total Loss: 1.607    [weighted Loss:1.607    Policy Loss: 4.178    Value Loss: 4.871    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 60848      Buffer Size: 7276       Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:38:55,737][train][INFO][train.py>_log] ==> #380000     Total Loss: 0.943    [weighted Loss:0.943    Policy Loss: 3.867    Value Loss: 4.971    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 61036      Buffer Size: 7246       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:44:15,107][train][INFO][train.py>_log] ==> #382000     Total Loss: 0.737    [weighted Loss:0.737    Policy Loss: 3.606    Value Loss: 5.077    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 61229      Buffer Size: 7247       Transition Number: 400.132 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:49:31,492][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 3.488    Value Loss: 4.851    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 61410      Buffer Size: 7241       Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-13 12:54:49,773][train][INFO][train.py>_log] ==> #386000     Total Loss: 0.629    [weighted Loss:0.629    Policy Loss: 4.359    Value Loss: 5.035    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 61585      Buffer Size: 7236       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:00:05,679][train][INFO][train.py>_log] ==> #388000     Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 3.508    Value Loss: 4.742    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 61776      Buffer Size: 7263       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:05:26,543][train][INFO][train.py>_log] ==> #390000     Total Loss: 0.767    [weighted Loss:0.767    Policy Loss: 3.561    Value Loss: 4.876    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 61952      Buffer Size: 7276       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:10:46,939][train][INFO][train.py>_log] ==> #392000     Total Loss: 0.914    [weighted Loss:0.914    Policy Loss: 3.847    Value Loss: 5.070    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 62136      Buffer Size: 7280       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:16:09,809][train][INFO][train.py>_log] ==> #394000     Total Loss: 0.992    [weighted Loss:0.992    Policy Loss: 3.389    Value Loss: 4.620    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 62319      Buffer Size: 7285       Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:21:29,036][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.402    [weighted Loss:1.402    Policy Loss: 3.680    Value Loss: 5.164    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 62608      Buffer Size: 7398       Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:26:50,446][train][INFO][train.py>_log] ==> #398000     Total Loss: 1.537    [weighted Loss:1.537    Policy Loss: 3.249    Value Loss: 4.944    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 62872      Buffer Size: 7453       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:32:06,909][train][INFO][train.py>_log] ==> #400000     Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 3.848    Value Loss: 5.586    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 63058      Buffer Size: 7346       Transition Number: 399.934 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:37:26,920][train][INFO][train.py>_log] ==> #402000     Total Loss: 1.395    [weighted Loss:1.395    Policy Loss: 2.905    Value Loss: 5.075    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 63279      Buffer Size: 7325       Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:42:46,764][train][INFO][train.py>_log] ==> #404000     Total Loss: 1.002    [weighted Loss:1.002    Policy Loss: 2.804    Value Loss: 4.990    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 63509      Buffer Size: 7264       Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:48:08,359][train][INFO][train.py>_log] ==> #406000     Total Loss: 1.204    [weighted Loss:1.204    Policy Loss: 3.137    Value Loss: 4.976    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 63684      Buffer Size: 7115       Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:53:27,077][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 3.462    Value Loss: 4.859    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 63872      Buffer Size: 6999       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-13 13:58:46,354][train][INFO][train.py>_log] ==> #410000     Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 3.811    Value Loss: 4.859    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 64089      Buffer Size: 6977       Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:04:01,772][train][INFO][train.py>_log] ==> #412000     Total Loss: 0.994    [weighted Loss:0.994    Policy Loss: 4.008    Value Loss: 4.857    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 64377      Buffer Size: 7074       Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:09:20,515][train][INFO][train.py>_log] ==> #414000     Total Loss: 0.644    [weighted Loss:0.644    Policy Loss: 4.206    Value Loss: 4.822    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 64561      Buffer Size: 7080       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:14:36,375][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.776    [weighted Loss:1.776    Policy Loss: 3.397    Value Loss: 5.000    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 64809      Buffer Size: 7140       Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:19:55,065][train][INFO][train.py>_log] ==> #418000     Total Loss: 0.995    [weighted Loss:0.995    Policy Loss: 3.572    Value Loss: 4.975    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 65062      Buffer Size: 7234       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:25:12,801][train][INFO][train.py>_log] ==> #420000     Total Loss: 1.331    [weighted Loss:1.331    Policy Loss: 2.991    Value Loss: 5.022    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 65251      Buffer Size: 7172       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:30:31,605][train][INFO][train.py>_log] ==> #422000     Total Loss: 0.765    [weighted Loss:0.765    Policy Loss: 3.324    Value Loss: 4.865    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 65442      Buffer Size: 7071       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:35:50,599][train][INFO][train.py>_log] ==> #424000     Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 3.060    Value Loss: 4.743    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 65693      Buffer Size: 7126       Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:41:09,830][train][INFO][train.py>_log] ==> #426000     Total Loss: 1.349    [weighted Loss:1.349    Policy Loss: 3.074    Value Loss: 4.668    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 65930      Buffer Size: 7175       Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:46:28,401][train][INFO][train.py>_log] ==> #428000     Total Loss: 1.047    [weighted Loss:1.047    Policy Loss: 3.258    Value Loss: 5.137    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 66137      Buffer Size: 7202       Transition Number: 400.059 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:51:50,697][train][INFO][train.py>_log] ==> #430000     Total Loss: 1.617    [weighted Loss:1.617    Policy Loss: 3.051    Value Loss: 4.807    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 66322      Buffer Size: 7224       Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-13 14:57:09,705][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.669    [weighted Loss:1.669    Policy Loss: 3.571    Value Loss: 4.986    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 66511      Buffer Size: 7218       Transition Number: 399.948 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:02:29,775][train][INFO][train.py>_log] ==> #434000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 3.403    Value Loss: 4.972    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 66704      Buffer Size: 7223       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:07:51,467][train][INFO][train.py>_log] ==> #436000     Total Loss: 0.791    [weighted Loss:0.791    Policy Loss: 3.459    Value Loss: 4.914    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 66894      Buffer Size: 7212       Transition Number: 400.010 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:13:11,630][train][INFO][train.py>_log] ==> #438000     Total Loss: 0.713    [weighted Loss:0.713    Policy Loss: 3.479    Value Loss: 5.563    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 67078      Buffer Size: 7199       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:18:29,991][train][INFO][train.py>_log] ==> #440000     Total Loss: 1.286    [weighted Loss:1.286    Policy Loss: 4.168    Value Loss: 5.131    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 67335      Buffer Size: 7273       Transition Number: 400.088 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:23:48,999][train][INFO][train.py>_log] ==> #442000     Total Loss: 1.290    [weighted Loss:1.290    Policy Loss: 4.714    Value Loss: 5.236    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 67619      Buffer Size: 7399       Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:29:06,718][train][INFO][train.py>_log] ==> #444000     Total Loss: 1.261    [weighted Loss:1.261    Policy Loss: 3.971    Value Loss: 5.323    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 67818      Buffer Size: 7424       Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:34:25,757][train][INFO][train.py>_log] ==> #446000     Total Loss: 0.576    [weighted Loss:0.576    Policy Loss: 3.281    Value Loss: 5.369    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 67985      Buffer Size: 7432       Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:39:44,456][train][INFO][train.py>_log] ==> #448000     Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 3.429    Value Loss: 4.727    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 68167      Buffer Size: 7432       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:45:03,976][train][INFO][train.py>_log] ==> #450000     Total Loss: 0.752    [weighted Loss:0.752    Policy Loss: 4.022    Value Loss: 4.758    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 68341      Buffer Size: 7427       Transition Number: 400.207 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:50:22,093][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 3.688    Value Loss: 4.812    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 68532      Buffer Size: 7423       Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-13 15:55:42,372][train][INFO][train.py>_log] ==> #454000     Total Loss: 1.487    [weighted Loss:1.487    Policy Loss: 3.595    Value Loss: 4.999    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 68727      Buffer Size: 7427       Transition Number: 399.960 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:01:00,152][train][INFO][train.py>_log] ==> #456000     Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 4.251    Value Loss: 5.248    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 68928      Buffer Size: 7444       Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:06:18,951][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.473    [weighted Loss:1.473    Policy Loss: 3.681    Value Loss: 5.494    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 69117      Buffer Size: 7464       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:11:36,336][train][INFO][train.py>_log] ==> #460000     Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 3.330    Value Loss: 4.960    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 69310      Buffer Size: 7471       Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:16:54,193][train][INFO][train.py>_log] ==> #462000     Total Loss: 1.181    [weighted Loss:1.181    Policy Loss: 3.744    Value Loss: 5.164    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 69489      Buffer Size: 7490       Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:22:10,928][train][INFO][train.py>_log] ==> #464000     Total Loss: 1.515    [weighted Loss:1.515    Policy Loss: 3.911    Value Loss: 5.138    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 69682      Buffer Size: 7515       Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:27:29,506][train][INFO][train.py>_log] ==> #466000     Total Loss: 1.091    [weighted Loss:1.091    Policy Loss: 4.441    Value Loss: 5.262    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 69890      Buffer Size: 7565       Transition Number: 400.047 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:32:47,246][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 4.091    Value Loss: 5.440    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 70102      Buffer Size: 7502       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:38:06,573][train][INFO][train.py>_log] ==> #470000     Total Loss: 1.188    [weighted Loss:1.188    Policy Loss: 3.411    Value Loss: 4.635    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 70290      Buffer Size: 7408       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:43:24,207][train][INFO][train.py>_log] ==> #472000     Total Loss: 1.263    [weighted Loss:1.263    Policy Loss: 3.451    Value Loss: 5.394    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 70472      Buffer Size: 7391       Transition Number: 399.936 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:48:45,487][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 3.832    Value Loss: 5.326    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 70658      Buffer Size: 7342       Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:54:02,912][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 5.340    Value Loss: 4.927    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 71075      Buffer Size: 7539       Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-13 16:59:24,506][train][INFO][train.py>_log] ==> #478000     Total Loss: 1.476    [weighted Loss:1.476    Policy Loss: 3.565    Value Loss: 4.961    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 71289      Buffer Size: 7593       Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:04:41,891][train][INFO][train.py>_log] ==> #480000     Total Loss: 1.099    [weighted Loss:1.099    Policy Loss: 3.484    Value Loss: 5.154    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 71489      Buffer Size: 7632       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:10:02,479][train][INFO][train.py>_log] ==> #482000     Total Loss: 1.530    [weighted Loss:1.530    Policy Loss: 3.187    Value Loss: 5.158    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 71677      Buffer Size: 7606       Transition Number: 399.936 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:15:19,018][train][INFO][train.py>_log] ==> #484000     Total Loss: 0.796    [weighted Loss:0.796    Policy Loss: 3.120    Value Loss: 5.625    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 71866      Buffer Size: 7493       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:20:38,313][train][INFO][train.py>_log] ==> #486000     Total Loss: 0.848    [weighted Loss:0.848    Policy Loss: 3.234    Value Loss: 5.609    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 72055      Buffer Size: 7447       Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:25:55,999][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.048    [weighted Loss:1.048    Policy Loss: 3.754    Value Loss: 5.207    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 72253      Buffer Size: 7358       Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:31:17,705][train][INFO][train.py>_log] ==> #490000     Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 3.493    Value Loss: 5.335    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 72493      Buffer Size: 7340       Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:36:35,501][train][INFO][train.py>_log] ==> #492000     Total Loss: 0.601    [weighted Loss:0.601    Policy Loss: 4.067    Value Loss: 4.947    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 72790      Buffer Size: 7454       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:41:53,195][train][INFO][train.py>_log] ==> #494000     Total Loss: 0.344    [weighted Loss:0.344    Policy Loss: 4.189    Value Loss: 5.049    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 72993      Buffer Size: 7459       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:47:10,551][train][INFO][train.py>_log] ==> #496000     Total Loss: 0.976    [weighted Loss:0.976    Policy Loss: 3.885    Value Loss: 4.695    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 73192      Buffer Size: 7409       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:53:08,070][train][INFO][train.py>_log] ==> #498000     Total Loss: 1.461    [weighted Loss:1.461    Policy Loss: 4.350    Value Loss: 5.253    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 73409      Buffer Size: 7375       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-13 17:58:29,069][train][INFO][train.py>_log] ==> #500000     Total Loss: 1.339    [weighted Loss:1.339    Policy Loss: 4.011    Value Loss: 5.170    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 73623      Buffer Size: 7369       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:03:55,938][train][INFO][train.py>_log] ==> #502000     Total Loss: 0.902    [weighted Loss:0.902    Policy Loss: 3.677    Value Loss: 5.559    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 73849      Buffer Size: 7410       Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:09:12,300][train][INFO][train.py>_log] ==> #504000     Total Loss: 1.652    [weighted Loss:1.652    Policy Loss: 3.421    Value Loss: 4.722    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 74042      Buffer Size: 7407       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:14:29,637][train][INFO][train.py>_log] ==> #506000     Total Loss: 1.447    [weighted Loss:1.447    Policy Loss: 4.491    Value Loss: 5.221    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 74230      Buffer Size: 7399       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:19:43,210][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.122    [weighted Loss:2.122    Policy Loss: 4.253    Value Loss: 5.100    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 74490      Buffer Size: 7494       Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:25:01,338][train][INFO][train.py>_log] ==> #510000     Total Loss: 0.568    [weighted Loss:0.568    Policy Loss: 3.867    Value Loss: 5.176    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 74786      Buffer Size: 7570       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:30:16,911][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 4.169    Value Loss: 5.285    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 74960      Buffer Size: 7488       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:35:37,669][train][INFO][train.py>_log] ==> #514000     Total Loss: 1.388    [weighted Loss:1.388    Policy Loss: 3.697    Value Loss: 5.216    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 75174      Buffer Size: 7482       Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:40:53,239][train][INFO][train.py>_log] ==> #516000     Total Loss: 1.144    [weighted Loss:1.144    Policy Loss: 4.135    Value Loss: 4.911    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 75372      Buffer Size: 7504       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:46:14,082][train][INFO][train.py>_log] ==> #518000     Total Loss: 1.025    [weighted Loss:1.025    Policy Loss: 3.746    Value Loss: 5.270    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 75665      Buffer Size: 7640       Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:51:31,221][train][INFO][train.py>_log] ==> #520000     Total Loss: 1.129    [weighted Loss:1.129    Policy Loss: 3.315    Value Loss: 4.930    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 75921      Buffer Size: 7750       Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-13 18:56:50,283][train][INFO][train.py>_log] ==> #522000     Total Loss: 0.772    [weighted Loss:0.772    Policy Loss: 2.885    Value Loss: 5.313    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 76090      Buffer Size: 7754       Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:02:08,312][train][INFO][train.py>_log] ==> #524000     Total Loss: 1.069    [weighted Loss:1.069    Policy Loss: 3.265    Value Loss: 5.399    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 76278      Buffer Size: 7758       Transition Number: 400.091 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:07:28,015][train][INFO][train.py>_log] ==> #526000     Total Loss: 0.606    [weighted Loss:0.606    Policy Loss: 3.370    Value Loss: 5.427    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 76454      Buffer Size: 7745       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:12:46,165][train][INFO][train.py>_log] ==> #528000     Total Loss: 0.951    [weighted Loss:0.951    Policy Loss: 3.161    Value Loss: 5.524    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 76667      Buffer Size: 7761       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:18:06,230][train][INFO][train.py>_log] ==> #530000     Total Loss: 0.768    [weighted Loss:0.768    Policy Loss: 3.722    Value Loss: 5.037    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 76896      Buffer Size: 7804       Transition Number: 399.930 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:23:26,088][train][INFO][train.py>_log] ==> #532000     Total Loss: 1.068    [weighted Loss:1.068    Policy Loss: 3.123    Value Loss: 5.711    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 77099      Buffer Size: 7819       Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:28:45,618][train][INFO][train.py>_log] ==> #534000     Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 4.050    Value Loss: 4.819    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 77324      Buffer Size: 7856       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:34:02,078][train][INFO][train.py>_log] ==> #536000     Total Loss: 0.530    [weighted Loss:0.530    Policy Loss: 3.223    Value Loss: 4.951    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 77534      Buffer Size: 7869       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:39:23,240][train][INFO][train.py>_log] ==> #538000     Total Loss: 1.005    [weighted Loss:1.005    Policy Loss: 3.459    Value Loss: 4.885    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 77759      Buffer Size: 7868       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:44:40,899][train][INFO][train.py>_log] ==> #540000     Total Loss: 1.245    [weighted Loss:1.245    Policy Loss: 3.629    Value Loss: 5.698    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 77965      Buffer Size: 7862       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:49:59,865][train][INFO][train.py>_log] ==> #542000     Total Loss: 1.138    [weighted Loss:1.138    Policy Loss: 3.465    Value Loss: 5.179    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 78158      Buffer Size: 7872       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-13 19:55:17,681][train][INFO][train.py>_log] ==> #544000     Total Loss: 0.940    [weighted Loss:0.940    Policy Loss: 3.151    Value Loss: 5.194    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 78342      Buffer Size: 7878       Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:00:34,950][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 4.143    Value Loss: 5.354    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 78601      Buffer Size: 7972       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:05:52,255][train][INFO][train.py>_log] ==> #548000     Total Loss: 1.481    [weighted Loss:1.481    Policy Loss: 3.193    Value Loss: 4.942    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 78792      Buffer Size: 7813       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:11:12,621][train][INFO][train.py>_log] ==> #550000     Total Loss: 1.417    [weighted Loss:1.417    Policy Loss: 3.867    Value Loss: 5.403    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 78980      Buffer Size: 7698       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:16:28,736][train][INFO][train.py>_log] ==> #552000     Total Loss: 1.096    [weighted Loss:1.096    Policy Loss: 3.303    Value Loss: 5.318    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 79181      Buffer Size: 7684       Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:21:47,243][train][INFO][train.py>_log] ==> #554000     Total Loss: 0.639    [weighted Loss:0.639    Policy Loss: 2.814    Value Loss: 5.141    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 79386      Buffer Size: 7714       Transition Number: 399.948 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:27:03,328][train][INFO][train.py>_log] ==> #556000     Total Loss: 1.513    [weighted Loss:1.513    Policy Loss: 3.972    Value Loss: 5.284    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 79591      Buffer Size: 7736       Transition Number: 399.969 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:32:21,620][train][INFO][train.py>_log] ==> #558000     Total Loss: 0.796    [weighted Loss:0.796    Policy Loss: 3.505    Value Loss: 4.854    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 79769      Buffer Size: 7756       Transition Number: 399.937 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:37:36,974][train][INFO][train.py>_log] ==> #560000     Total Loss: 1.254    [weighted Loss:1.254    Policy Loss: 3.593    Value Loss: 5.382    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 79962      Buffer Size: 7768       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:42:56,168][train][INFO][train.py>_log] ==> #562000     Total Loss: 0.939    [weighted Loss:0.939    Policy Loss: 3.131    Value Loss: 5.051    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 80138      Buffer Size: 7751       Transition Number: 399.932 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:48:13,476][train][INFO][train.py>_log] ==> #564000     Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 3.304    Value Loss: 5.236    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 80320      Buffer Size: 7649       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:53:33,322][train][INFO][train.py>_log] ==> #566000     Total Loss: 0.983    [weighted Loss:0.983    Policy Loss: 3.656    Value Loss: 5.027    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 80505      Buffer Size: 7574       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-13 20:58:51,483][train][INFO][train.py>_log] ==> #568000     Total Loss: 0.634    [weighted Loss:0.634    Policy Loss: 3.718    Value Loss: 5.331    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 80689      Buffer Size: 7557       Transition Number: 400.052 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:04:12,089][train][INFO][train.py>_log] ==> #570000     Total Loss: 0.866    [weighted Loss:0.866    Policy Loss: 3.337    Value Loss: 5.045    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 80873      Buffer Size: 7547       Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:09:29,646][train][INFO][train.py>_log] ==> #572000     Total Loss: 1.213    [weighted Loss:1.213    Policy Loss: 3.641    Value Loss: 5.370    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 81053      Buffer Size: 7554       Transition Number: 399.958 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:14:49,595][train][INFO][train.py>_log] ==> #574000     Total Loss: 0.635    [weighted Loss:0.635    Policy Loss: 4.042    Value Loss: 5.615    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 81242      Buffer Size: 7549       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:20:07,361][train][INFO][train.py>_log] ==> #576000     Total Loss: 1.800    [weighted Loss:1.800    Policy Loss: 3.624    Value Loss: 5.510    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 81439      Buffer Size: 7523       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:25:26,467][train][INFO][train.py>_log] ==> #578000     Total Loss: 0.891    [weighted Loss:0.891    Policy Loss: 3.086    Value Loss: 5.025    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 81619      Buffer Size: 7505       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:30:42,892][train][INFO][train.py>_log] ==> #580000     Total Loss: 0.911    [weighted Loss:0.911    Policy Loss: 3.395    Value Loss: 5.066    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 81833      Buffer Size: 7514       Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:36:02,954][train][INFO][train.py>_log] ==> #582000     Total Loss: 0.316    [weighted Loss:0.316    Policy Loss: 3.476    Value Loss: 5.129    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 82049      Buffer Size: 7461       Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:41:21,509][train][INFO][train.py>_log] ==> #584000     Total Loss: 0.964    [weighted Loss:0.964    Policy Loss: 4.186    Value Loss: 4.957    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 82231      Buffer Size: 7374       Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:46:40,669][train][INFO][train.py>_log] ==> #586000     Total Loss: 1.093    [weighted Loss:1.093    Policy Loss: 3.510    Value Loss: 5.082    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 82468      Buffer Size: 7388       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:51:58,776][train][INFO][train.py>_log] ==> #588000     Total Loss: 1.712    [weighted Loss:1.712    Policy Loss: 3.761    Value Loss: 5.167    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 82679      Buffer Size: 7381       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-13 21:57:18,341][train][INFO][train.py>_log] ==> #590000     Total Loss: 1.029    [weighted Loss:1.029    Policy Loss: 3.595    Value Loss: 5.010    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 82863      Buffer Size: 7321       Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:02:34,707][train][INFO][train.py>_log] ==> #592000     Total Loss: 0.790    [weighted Loss:0.790    Policy Loss: 3.845    Value Loss: 5.219    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 83045      Buffer Size: 7212       Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:07:52,985][train][INFO][train.py>_log] ==> #594000     Total Loss: 0.590    [weighted Loss:0.590    Policy Loss: 3.600    Value Loss: 5.984    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 83225      Buffer Size: 7189       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:13:09,134][train][INFO][train.py>_log] ==> #596000     Total Loss: 1.617    [weighted Loss:1.617    Policy Loss: 4.260    Value Loss: 5.811    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 83417      Buffer Size: 7222       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:18:28,681][train][INFO][train.py>_log] ==> #598000     Total Loss: 0.315    [weighted Loss:0.315    Policy Loss: 2.957    Value Loss: 5.194    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 83628      Buffer Size: 7267       Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:23:46,713][train][INFO][train.py>_log] ==> #600000     Total Loss: 0.824    [weighted Loss:0.824    Policy Loss: 3.994    Value Loss: 5.077    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 83798      Buffer Size: 7248       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:29:05,737][train][INFO][train.py>_log] ==> #602000     Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 3.819    Value Loss: 5.479    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 83979      Buffer Size: 7182       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:34:21,760][train][INFO][train.py>_log] ==> #604000     Total Loss: 0.588    [weighted Loss:0.588    Policy Loss: 3.958    Value Loss: 5.354    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 84147      Buffer Size: 7128       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:39:40,198][train][INFO][train.py>_log] ==> #606000     Total Loss: 0.526    [weighted Loss:0.526    Policy Loss: 3.400    Value Loss: 4.969    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 84327      Buffer Size: 7086       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:45:04,186][train][INFO][train.py>_log] ==> #608000     Total Loss: 1.013    [weighted Loss:1.013    Policy Loss: 3.842    Value Loss: 5.313    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 84475      Buffer Size: 7039       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:50:49,692][train][INFO][train.py>_log] ==> #610000     Total Loss: 0.890    [weighted Loss:0.890    Policy Loss: 3.428    Value Loss: 5.190    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 84601      Buffer Size: 7003       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-13 22:56:33,542][train][INFO][train.py>_log] ==> #612000     Total Loss: 0.716    [weighted Loss:0.716    Policy Loss: 3.885    Value Loss: 5.031    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 84725      Buffer Size: 6961       Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:02:18,295][train][INFO][train.py>_log] ==> #614000     Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 3.723    Value Loss: 5.840    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 84855      Buffer Size: 6924       Transition Number: 399.960 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:08:02,394][train][INFO][train.py>_log] ==> #616000     Total Loss: 0.659    [weighted Loss:0.659    Policy Loss: 3.553    Value Loss: 5.119    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 84984      Buffer Size: 6913       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:13:48,820][train][INFO][train.py>_log] ==> #618000     Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 3.569    Value Loss: 5.204    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 85110      Buffer Size: 6899       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:19:34,415][train][INFO][train.py>_log] ==> #620000     Total Loss: 1.255    [weighted Loss:1.255    Policy Loss: 3.305    Value Loss: 5.202    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 85247      Buffer Size: 6885       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:25:20,305][train][INFO][train.py>_log] ==> #622000     Total Loss: 0.544    [weighted Loss:0.544    Policy Loss: 3.441    Value Loss: 5.283    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 85373      Buffer Size: 6818       Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:31:04,448][train][INFO][train.py>_log] ==> #624000     Total Loss: 1.390    [weighted Loss:1.390    Policy Loss: 3.364    Value Loss: 5.151    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 85495      Buffer Size: 6788       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:36:57,099][train][INFO][train.py>_log] ==> #626000     Total Loss: 0.555    [weighted Loss:0.555    Policy Loss: 3.963    Value Loss: 5.273    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 85629      Buffer Size: 6791       Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:42:42,060][train][INFO][train.py>_log] ==> #628000     Total Loss: 1.220    [weighted Loss:1.220    Policy Loss: 3.815    Value Loss: 5.033    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 85789      Buffer Size: 6830       Transition Number: 399.972 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:48:28,757][train][INFO][train.py>_log] ==> #630000     Total Loss: 0.622    [weighted Loss:0.622    Policy Loss: 3.295    Value Loss: 5.146    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 85928      Buffer Size: 6844       Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:54:14,432][train][INFO][train.py>_log] ==> #632000     Total Loss: 0.824    [weighted Loss:0.824    Policy Loss: 3.311    Value Loss: 5.148    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 86093      Buffer Size: 6875       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-13 23:59:59,308][train][INFO][train.py>_log] ==> #634000     Total Loss: 1.042    [weighted Loss:1.042    Policy Loss: 3.567    Value Loss: 5.093    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 86250      Buffer Size: 6895       Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:05:44,729][train][INFO][train.py>_log] ==> #636000     Total Loss: 1.251    [weighted Loss:1.251    Policy Loss: 3.854    Value Loss: 4.879    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 86400      Buffer Size: 6911       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:11:30,496][train][INFO][train.py>_log] ==> #638000     Total Loss: 1.339    [weighted Loss:1.339    Policy Loss: 3.591    Value Loss: 5.283    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 86551      Buffer Size: 6922       Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:17:12,718][train][INFO][train.py>_log] ==> #640000     Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 3.823    Value Loss: 5.628    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 86732      Buffer Size: 6974       Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:23:00,570][train][INFO][train.py>_log] ==> #642000     Total Loss: 1.246    [weighted Loss:1.246    Policy Loss: 3.795    Value Loss: 5.430    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 86874      Buffer Size: 6987       Transition Number: 400.033 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:28:43,353][train][INFO][train.py>_log] ==> #644000     Total Loss: 0.692    [weighted Loss:0.692    Policy Loss: 3.676    Value Loss: 5.148    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 87007      Buffer Size: 6998       Transition Number: 399.936 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:34:30,129][train][INFO][train.py>_log] ==> #646000     Total Loss: 1.330    [weighted Loss:1.330    Policy Loss: 3.572    Value Loss: 5.206    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 87138      Buffer Size: 7008       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:40:11,951][train][INFO][train.py>_log] ==> #648000     Total Loss: 0.609    [weighted Loss:0.609    Policy Loss: 3.794    Value Loss: 5.220    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 87270      Buffer Size: 7020       Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:46:00,579][train][INFO][train.py>_log] ==> #650000     Total Loss: 1.062    [weighted Loss:1.062    Policy Loss: 3.577    Value Loss: 5.272    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 87391      Buffer Size: 7018       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:51:42,559][train][INFO][train.py>_log] ==> #652000     Total Loss: 0.647    [weighted Loss:0.647    Policy Loss: 4.121    Value Loss: 5.968    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 87526      Buffer Size: 7030       Transition Number: 399.967 k Batch Size: 128        Lr: 0.100   
[2021-11-14 00:57:28,811][train][INFO][train.py>_log] ==> #654000     Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 3.640    Value Loss: 5.299    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 87679      Buffer Size: 7061       Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:03:12,923][train][INFO][train.py>_log] ==> #656000     Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 3.519    Value Loss: 5.093    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 87814      Buffer Size: 7072       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:08:56,797][train][INFO][train.py>_log] ==> #658000     Total Loss: 0.880    [weighted Loss:0.880    Policy Loss: 3.480    Value Loss: 5.509    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 87937      Buffer Size: 7066       Transition Number: 400.026 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:14:41,260][train][INFO][train.py>_log] ==> #660000     Total Loss: 1.669    [weighted Loss:1.669    Policy Loss: 4.035    Value Loss: 5.328    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 88072      Buffer Size: 7061       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:20:13,093][train][INFO][train.py>_log] ==> #662000     Total Loss: 1.579    [weighted Loss:1.579    Policy Loss: 3.207    Value Loss: 4.841    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 88206      Buffer Size: 7065       Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:25:42,676][train][INFO][train.py>_log] ==> #664000     Total Loss: 0.855    [weighted Loss:0.855    Policy Loss: 3.391    Value Loss: 5.304    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 88336      Buffer Size: 7052       Transition Number: 399.960 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:31:12,808][train][INFO][train.py>_log] ==> #666000     Total Loss: 0.517    [weighted Loss:0.517    Policy Loss: 3.232    Value Loss: 5.288    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 88500      Buffer Size: 7082       Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:36:38,516][train][INFO][train.py>_log] ==> #668000     Total Loss: 0.411    [weighted Loss:0.411    Policy Loss: 3.306    Value Loss: 4.885    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 88650      Buffer Size: 7110       Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:42:07,761][train][INFO][train.py>_log] ==> #670000     Total Loss: 1.276    [weighted Loss:1.276    Policy Loss: 3.538    Value Loss: 5.335    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 88798      Buffer Size: 7128       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:47:37,202][train][INFO][train.py>_log] ==> #672000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 3.314    Value Loss: 5.001    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 88946      Buffer Size: 7123       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:53:06,524][train][INFO][train.py>_log] ==> #674000     Total Loss: 0.757    [weighted Loss:0.757    Policy Loss: 3.506    Value Loss: 5.215    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 89082      Buffer Size: 7104       Transition Number: 399.952 k Batch Size: 128        Lr: 0.100   
[2021-11-14 01:58:34,824][train][INFO][train.py>_log] ==> #676000     Total Loss: 0.426    [weighted Loss:0.426    Policy Loss: 3.778    Value Loss: 5.316    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 89249      Buffer Size: 7135       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:04:08,679][train][INFO][train.py>_log] ==> #678000     Total Loss: 0.414    [weighted Loss:0.414    Policy Loss: 3.278    Value Loss: 5.229    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 89431      Buffer Size: 7175       Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:09:33,100][train][INFO][train.py>_log] ==> #680000     Total Loss: 0.488    [weighted Loss:0.488    Policy Loss: 3.472    Value Loss: 4.902    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 89578      Buffer Size: 7136       Transition Number: 399.937 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:14:53,275][train][INFO][train.py>_log] ==> #682000     Total Loss: 1.192    [weighted Loss:1.192    Policy Loss: 3.055    Value Loss: 5.250    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 89720      Buffer Size: 7100       Transition Number: 400.018 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:20:12,028][train][INFO][train.py>_log] ==> #684000     Total Loss: 0.845    [weighted Loss:0.845    Policy Loss: 3.732    Value Loss: 4.987    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 89869      Buffer Size: 7063       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:25:32,505][train][INFO][train.py>_log] ==> #686000     Total Loss: 0.392    [weighted Loss:0.392    Policy Loss: 2.955    Value Loss: 5.526    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 90009      Buffer Size: 7038       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:30:51,258][train][INFO][train.py>_log] ==> #688000     Total Loss: 1.158    [weighted Loss:1.158    Policy Loss: 3.900    Value Loss: 5.154    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 90161      Buffer Size: 7028       Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:36:10,147][train][INFO][train.py>_log] ==> #690000     Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 3.393    Value Loss: 4.878    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 90312      Buffer Size: 7039       Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:41:30,716][train][INFO][train.py>_log] ==> #692000     Total Loss: 1.366    [weighted Loss:1.366    Policy Loss: 4.051    Value Loss: 5.061    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 90510      Buffer Size: 7051       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:46:49,775][train][INFO][train.py>_log] ==> #694000     Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 4.170    Value Loss: 5.635    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 90680      Buffer Size: 7052       Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:52:08,427][train][INFO][train.py>_log] ==> #696000     Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 4.142    Value Loss: 5.001    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 90852      Buffer Size: 7093       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-14 02:57:30,436][train][INFO][train.py>_log] ==> #698000     Total Loss: 0.883    [weighted Loss:0.883    Policy Loss: 3.253    Value Loss: 5.149    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 91019      Buffer Size: 7119       Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:02:49,362][train][INFO][train.py>_log] ==> #700000     Total Loss: 0.974    [weighted Loss:0.974    Policy Loss: 3.147    Value Loss: 5.600    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 91185      Buffer Size: 7106       Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:08:09,720][train][INFO][train.py>_log] ==> #702000     Total Loss: 1.109    [weighted Loss:1.109    Policy Loss: 3.699    Value Loss: 5.054    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 91348      Buffer Size: 7099       Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:13:26,797][train][INFO][train.py>_log] ==> #704000     Total Loss: 1.187    [weighted Loss:1.187    Policy Loss: 3.152    Value Loss: 5.354    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 91528      Buffer Size: 7110       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:18:45,696][train][INFO][train.py>_log] ==> #706000     Total Loss: 1.032    [weighted Loss:1.032    Policy Loss: 3.377    Value Loss: 6.111    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 91758      Buffer Size: 7188       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:24:01,191][train][INFO][train.py>_log] ==> #708000     Total Loss: 0.863    [weighted Loss:0.863    Policy Loss: 3.492    Value Loss: 5.083    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 91942      Buffer Size: 7205       Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:29:23,866][train][INFO][train.py>_log] ==> #710000     Total Loss: 0.790    [weighted Loss:0.790    Policy Loss: 2.823    Value Loss: 5.488    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 92124      Buffer Size: 7211       Transition Number: 400.061 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:34:39,911][train][INFO][train.py>_log] ==> #712000     Total Loss: 0.677    [weighted Loss:0.677    Policy Loss: 3.066    Value Loss: 5.218    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 92301      Buffer Size: 7202       Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:39:59,404][train][INFO][train.py>_log] ==> #714000     Total Loss: 0.763    [weighted Loss:0.763    Policy Loss: 3.022    Value Loss: 5.137    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 92470      Buffer Size: 7205       Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:45:19,454][train][INFO][train.py>_log] ==> #716000     Total Loss: 0.739    [weighted Loss:0.739    Policy Loss: 2.947    Value Loss: 5.533    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 92645      Buffer Size: 7195       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:50:40,264][train][INFO][train.py>_log] ==> #718000     Total Loss: 0.900    [weighted Loss:0.900    Policy Loss: 2.835    Value Loss: 5.359    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 92825      Buffer Size: 7170       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-14 03:55:59,279][train][INFO][train.py>_log] ==> #720000     Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 2.966    Value Loss: 5.061    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 93011      Buffer Size: 7102       Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:01:17,502][train][INFO][train.py>_log] ==> #722000     Total Loss: 0.781    [weighted Loss:0.781    Policy Loss: 3.471    Value Loss: 5.023    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 93182      Buffer Size: 7024       Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:06:36,175][train][INFO][train.py>_log] ==> #724000     Total Loss: 1.144    [weighted Loss:1.144    Policy Loss: 3.272    Value Loss: 5.188    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 93363      Buffer Size: 6971       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:11:56,173][train][INFO][train.py>_log] ==> #726000     Total Loss: 0.710    [weighted Loss:0.710    Policy Loss: 2.956    Value Loss: 5.011    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 93537      Buffer Size: 6891       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:17:13,875][train][INFO][train.py>_log] ==> #728000     Total Loss: 0.794    [weighted Loss:0.794    Policy Loss: 3.017    Value Loss: 5.330    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 93718      Buffer Size: 6828       Transition Number: 399.935 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:22:33,191][train][INFO][train.py>_log] ==> #730000     Total Loss: 0.368    [weighted Loss:0.368    Policy Loss: 3.194    Value Loss: 5.031    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 93885      Buffer Size: 6786       Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:27:48,338][train][INFO][train.py>_log] ==> #732000     Total Loss: 1.309    [weighted Loss:1.309    Policy Loss: 3.429    Value Loss: 5.007    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 94062      Buffer Size: 6759       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:33:05,919][train][INFO][train.py>_log] ==> #734000     Total Loss: 0.947    [weighted Loss:0.947    Policy Loss: 3.392    Value Loss: 5.046    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 94240      Buffer Size: 6732       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:38:24,368][train][INFO][train.py>_log] ==> #736000     Total Loss: 0.412    [weighted Loss:0.412    Policy Loss: 3.467    Value Loss: 4.750    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 94426      Buffer Size: 6686       Transition Number: 399.938 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:43:43,893][train][INFO][train.py>_log] ==> #738000     Total Loss: 0.418    [weighted Loss:0.418    Policy Loss: 3.763    Value Loss: 4.653    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 94603      Buffer Size: 6688       Transition Number: 399.936 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:49:01,934][train][INFO][train.py>_log] ==> #740000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 3.650    Value Loss: 5.179    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 94787      Buffer Size: 6692       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:54:18,980][train][INFO][train.py>_log] ==> #742000     Total Loss: 0.931    [weighted Loss:0.931    Policy Loss: 4.270    Value Loss: 4.938    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 94971      Buffer Size: 6694       Transition Number: 399.953 k Batch Size: 128        Lr: 0.100   
[2021-11-14 04:59:35,795][train][INFO][train.py>_log] ==> #744000     Total Loss: 0.789    [weighted Loss:0.789    Policy Loss: 3.694    Value Loss: 5.053    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 95369      Buffer Size: 6910       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:04:54,720][train][INFO][train.py>_log] ==> #746000     Total Loss: 0.947    [weighted Loss:0.947    Policy Loss: 3.737    Value Loss: 5.871    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 96104      Buffer Size: 7456       Transition Number: 400.048 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:10:11,772][train][INFO][train.py>_log] ==> #748000     Total Loss: 0.873    [weighted Loss:0.873    Policy Loss: 4.002    Value Loss: 4.632    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 96285      Buffer Size: 7433       Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:15:29,924][train][INFO][train.py>_log] ==> #750000     Total Loss: 0.897    [weighted Loss:0.897    Policy Loss: 3.837    Value Loss: 4.753    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 96459      Buffer Size: 7410       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:20:43,410][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.071    [weighted Loss:1.071    Policy Loss: 4.984    Value Loss: 5.128    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 96627      Buffer Size: 7345       Transition Number: 399.943 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:26:01,073][train][INFO][train.py>_log] ==> #754000     Total Loss: 0.529    [weighted Loss:0.529    Policy Loss: 3.936    Value Loss: 4.994    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 96799      Buffer Size: 7307       Transition Number: 399.934 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:31:18,641][train][INFO][train.py>_log] ==> #756000     Total Loss: 0.874    [weighted Loss:0.874    Policy Loss: 4.135    Value Loss: 5.132    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 96975      Buffer Size: 7303       Transition Number: 400.051 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:36:33,770][train][INFO][train.py>_log] ==> #758000     Total Loss: 0.777    [weighted Loss:0.777    Policy Loss: 4.186    Value Loss: 4.695    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 97154      Buffer Size: 7312       Transition Number: 399.945 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:41:51,090][train][INFO][train.py>_log] ==> #760000     Total Loss: 0.456    [weighted Loss:0.456    Policy Loss: 4.493    Value Loss: 5.085    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 97491      Buffer Size: 7486       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:47:06,829][train][INFO][train.py>_log] ==> #762000     Total Loss: 0.837    [weighted Loss:0.837    Policy Loss: 4.272    Value Loss: 5.098    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 97789      Buffer Size: 7637       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:52:21,838][train][INFO][train.py>_log] ==> #764000     Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 4.273    Value Loss: 4.897    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 97961      Buffer Size: 7615       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-14 05:57:38,142][train][INFO][train.py>_log] ==> #766000     Total Loss: 1.479    [weighted Loss:1.479    Policy Loss: 4.437    Value Loss: 5.168    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 98137      Buffer Size: 7560       Transition Number: 399.932 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:02:52,502][train][INFO][train.py>_log] ==> #768000     Total Loss: 1.463    [weighted Loss:1.463    Policy Loss: 4.323    Value Loss: 4.805    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 98303      Buffer Size: 7491       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:08:09,263][train][INFO][train.py>_log] ==> #770000     Total Loss: 0.617    [weighted Loss:0.617    Policy Loss: 3.898    Value Loss: 4.837    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 98491      Buffer Size: 7458       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:13:24,297][train][INFO][train.py>_log] ==> #772000     Total Loss: 0.612    [weighted Loss:0.612    Policy Loss: 4.145    Value Loss: 4.569    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 98680      Buffer Size: 7471       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:18:42,412][train][INFO][train.py>_log] ==> #774000     Total Loss: 0.749    [weighted Loss:0.749    Policy Loss: 4.360    Value Loss: 4.383    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 98849      Buffer Size: 7457       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:23:53,921][train][INFO][train.py>_log] ==> #776000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 4.842    Value Loss: 5.090    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 99021      Buffer Size: 7420       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:29:09,913][train][INFO][train.py>_log] ==> #778000     Total Loss: 0.767    [weighted Loss:0.767    Policy Loss: 4.341    Value Loss: 4.931    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 99194      Buffer Size: 7348       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:34:24,504][train][INFO][train.py>_log] ==> #780000     Total Loss: 1.108    [weighted Loss:1.108    Policy Loss: 4.631    Value Loss: 4.872    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 99364      Buffer Size: 7333       Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:39:40,334][train][INFO][train.py>_log] ==> #782000     Total Loss: 0.348    [weighted Loss:0.348    Policy Loss: 4.165    Value Loss: 6.050    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 99538      Buffer Size: 7350       Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:44:55,701][train][INFO][train.py>_log] ==> #784000     Total Loss: 0.838    [weighted Loss:0.838    Policy Loss: 4.888    Value Loss: 5.741    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 99718      Buffer Size: 7357       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:50:13,492][train][INFO][train.py>_log] ==> #786000     Total Loss: 1.132    [weighted Loss:1.132    Policy Loss: 3.862    Value Loss: 5.448    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 99889      Buffer Size: 7357       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-14 06:55:29,121][train][INFO][train.py>_log] ==> #788000     Total Loss: 0.933    [weighted Loss:0.933    Policy Loss: 4.512    Value Loss: 5.117    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 100068     Buffer Size: 7361       Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:00:49,105][train][INFO][train.py>_log] ==> #790000     Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 5.296    Value Loss: 4.770    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 100241     Buffer Size: 7369       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:06:03,987][train][INFO][train.py>_log] ==> #792000     Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 4.784    Value Loss: 5.892    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 100423     Buffer Size: 7388       Transition Number: 399.960 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:11:22,431][train][INFO][train.py>_log] ==> #794000     Total Loss: 0.787    [weighted Loss:0.787    Policy Loss: 4.235    Value Loss: 4.668    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 100600     Buffer Size: 7400       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:16:36,753][train][INFO][train.py>_log] ==> #796000     Total Loss: 0.714    [weighted Loss:0.714    Policy Loss: 3.897    Value Loss: 5.474    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 100772     Buffer Size: 7392       Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:21:54,849][train][INFO][train.py>_log] ==> #798000     Total Loss: 0.822    [weighted Loss:0.822    Policy Loss: 3.483    Value Loss: 5.299    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 100946     Buffer Size: 7401       Transition Number: 400.041 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:27:12,443][train][INFO][train.py>_log] ==> #800000     Total Loss: 0.477    [weighted Loss:0.477    Policy Loss: 3.492    Value Loss: 4.922    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 101135     Buffer Size: 7403       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:32:34,565][train][INFO][train.py>_log] ==> #802000     Total Loss: 1.021    [weighted Loss:1.021    Policy Loss: 3.393    Value Loss: 5.141    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 101305     Buffer Size: 7408       Transition Number: 399.956 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:37:51,753][train][INFO][train.py>_log] ==> #804000     Total Loss: 1.009    [weighted Loss:1.009    Policy Loss: 3.734    Value Loss: 5.062    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 101488     Buffer Size: 7410       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:43:09,265][train][INFO][train.py>_log] ==> #806000     Total Loss: 1.297    [weighted Loss:1.297    Policy Loss: 3.645    Value Loss: 5.189    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 101653     Buffer Size: 7414       Transition Number: 399.930 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:48:27,459][train][INFO][train.py>_log] ==> #808000     Total Loss: 1.097    [weighted Loss:1.097    Policy Loss: 3.687    Value Loss: 4.950    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 101839     Buffer Size: 7413       Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:53:43,763][train][INFO][train.py>_log] ==> #810000     Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 4.533    Value Loss: 5.376    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 102016     Buffer Size: 7405       Transition Number: 399.931 k Batch Size: 128        Lr: 0.100   
[2021-11-14 07:59:01,200][train][INFO][train.py>_log] ==> #812000     Total Loss: 0.733    [weighted Loss:0.733    Policy Loss: 3.721    Value Loss: 5.412    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 102190     Buffer Size: 7375       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:04:20,194][train][INFO][train.py>_log] ==> #814000     Total Loss: 0.989    [weighted Loss:0.989    Policy Loss: 3.716    Value Loss: 5.086    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 102372     Buffer Size: 7318       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:09:36,535][train][INFO][train.py>_log] ==> #816000     Total Loss: 0.470    [weighted Loss:0.470    Policy Loss: 3.548    Value Loss: 5.335    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 102558     Buffer Size: 6867       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:14:54,346][train][INFO][train.py>_log] ==> #818000     Total Loss: 0.484    [weighted Loss:0.484    Policy Loss: 3.133    Value Loss: 4.685    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 102732     Buffer Size: 6539       Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:20:10,131][train][INFO][train.py>_log] ==> #820000     Total Loss: 0.671    [weighted Loss:0.671    Policy Loss: 3.331    Value Loss: 5.485    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 102911     Buffer Size: 6535       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:25:28,448][train][INFO][train.py>_log] ==> #822000     Total Loss: 0.804    [weighted Loss:0.804    Policy Loss: 3.293    Value Loss: 4.882    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 103081     Buffer Size: 6537       Transition Number: 399.936 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:30:44,191][train][INFO][train.py>_log] ==> #824000     Total Loss: 0.895    [weighted Loss:0.895    Policy Loss: 3.401    Value Loss: 4.807    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 103266     Buffer Size: 6526       Transition Number: 399.976 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:36:01,765][train][INFO][train.py>_log] ==> #826000     Total Loss: 0.630    [weighted Loss:0.630    Policy Loss: 2.725    Value Loss: 4.700    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 103451     Buffer Size: 6537       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:41:17,671][train][INFO][train.py>_log] ==> #828000     Total Loss: 0.534    [weighted Loss:0.534    Policy Loss: 3.393    Value Loss: 4.808    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 103623     Buffer Size: 6529       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:46:37,494][train][INFO][train.py>_log] ==> #830000     Total Loss: 0.586    [weighted Loss:0.586    Policy Loss: 3.574    Value Loss: 5.096    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 103801     Buffer Size: 6404       Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:51:52,790][train][INFO][train.py>_log] ==> #832000     Total Loss: 0.594    [weighted Loss:0.594    Policy Loss: 3.376    Value Loss: 4.744    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 104022     Buffer Size: 6257       Transition Number: 399.965 k Batch Size: 128        Lr: 0.100   
[2021-11-14 08:57:11,854][train][INFO][train.py>_log] ==> #834000     Total Loss: 0.708    [weighted Loss:0.708    Policy Loss: 3.927    Value Loss: 5.208    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 104270     Buffer Size: 6333       Transition Number: 400.071 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:02:27,291][train][INFO][train.py>_log] ==> #836000     Total Loss: 1.053    [weighted Loss:1.053    Policy Loss: 3.335    Value Loss: 4.927    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 104470     Buffer Size: 6358       Transition Number: 400.054 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:07:47,205][train][INFO][train.py>_log] ==> #838000     Total Loss: 0.749    [weighted Loss:0.749    Policy Loss: 3.777    Value Loss: 5.044    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 104723     Buffer Size: 6449       Transition Number: 399.991 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:13:03,591][train][INFO][train.py>_log] ==> #840000     Total Loss: 0.889    [weighted Loss:0.889    Policy Loss: 2.953    Value Loss: 4.783    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 104911     Buffer Size: 6475       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:18:23,804][train][INFO][train.py>_log] ==> #842000     Total Loss: 0.611    [weighted Loss:0.611    Policy Loss: 3.006    Value Loss: 5.144    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 105090     Buffer Size: 6457       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:23:41,020][train][INFO][train.py>_log] ==> #844000     Total Loss: 0.577    [weighted Loss:0.577    Policy Loss: 3.585    Value Loss: 5.082    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 105265     Buffer Size: 6460       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:28:57,979][train][INFO][train.py>_log] ==> #846000     Total Loss: 0.912    [weighted Loss:0.912    Policy Loss: 3.072    Value Loss: 4.821    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 105435     Buffer Size: 6470       Transition Number: 399.974 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:34:13,798][train][INFO][train.py>_log] ==> #848000     Total Loss: 0.476    [weighted Loss:0.476    Policy Loss: 3.519    Value Loss: 5.044    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 105618     Buffer Size: 6490       Transition Number: 400.040 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:39:31,401][train][INFO][train.py>_log] ==> #850000     Total Loss: 0.644    [weighted Loss:0.644    Policy Loss: 3.352    Value Loss: 5.079    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 105819     Buffer Size: 6537       Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:44:49,373][train][INFO][train.py>_log] ==> #852000     Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 3.377    Value Loss: 5.011    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 106012     Buffer Size: 6556       Transition Number: 400.006 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:50:07,750][train][INFO][train.py>_log] ==> #854000     Total Loss: 1.173    [weighted Loss:1.173    Policy Loss: 3.625    Value Loss: 4.971    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 106197     Buffer Size: 6557       Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-14 09:55:23,849][train][INFO][train.py>_log] ==> #856000     Total Loss: 0.326    [weighted Loss:0.326    Policy Loss: 3.629    Value Loss: 5.193    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 106386     Buffer Size: 6576       Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:00:42,728][train][INFO][train.py>_log] ==> #858000     Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 3.893    Value Loss: 4.897    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 106570     Buffer Size: 6610       Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:05:58,656][train][INFO][train.py>_log] ==> #860000     Total Loss: 1.099    [weighted Loss:1.099    Policy Loss: 3.871    Value Loss: 5.454    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 106767     Buffer Size: 6643       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:11:15,905][train][INFO][train.py>_log] ==> #862000     Total Loss: 0.641    [weighted Loss:0.641    Policy Loss: 3.600    Value Loss: 5.047    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 106960     Buffer Size: 6678       Transition Number: 399.940 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:16:33,024][train][INFO][train.py>_log] ==> #864000     Total Loss: 0.794    [weighted Loss:0.794    Policy Loss: 4.037    Value Loss: 5.788    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 107153     Buffer Size: 6699       Transition Number: 399.936 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:21:49,167][train][INFO][train.py>_log] ==> #866000     Total Loss: 0.347    [weighted Loss:0.347    Policy Loss: 3.972    Value Loss: 5.242    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 107327     Buffer Size: 6699       Transition Number: 399.959 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:27:05,380][train][INFO][train.py>_log] ==> #868000     Total Loss: 0.926    [weighted Loss:0.926    Policy Loss: 3.853    Value Loss: 5.076    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 107495     Buffer Size: 6694       Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:32:25,340][train][INFO][train.py>_log] ==> #870000     Total Loss: 0.747    [weighted Loss:0.747    Policy Loss: 3.690    Value Loss: 5.020    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 107674     Buffer Size: 6689       Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:37:41,681][train][INFO][train.py>_log] ==> #872000     Total Loss: 0.945    [weighted Loss:0.945    Policy Loss: 3.682    Value Loss: 5.630    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 107853     Buffer Size: 6680       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:42:59,402][train][INFO][train.py>_log] ==> #874000     Total Loss: 0.930    [weighted Loss:0.930    Policy Loss: 3.481    Value Loss: 5.288    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 108029     Buffer Size: 6683       Transition Number: 399.944 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:48:17,076][train][INFO][train.py>_log] ==> #876000     Total Loss: 1.013    [weighted Loss:1.013    Policy Loss: 3.632    Value Loss: 5.361    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 108209     Buffer Size: 6684       Transition Number: 399.977 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:53:36,153][train][INFO][train.py>_log] ==> #878000     Total Loss: 0.882    [weighted Loss:0.882    Policy Loss: 3.744    Value Loss: 4.757    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 108379     Buffer Size: 6692       Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-14 10:58:52,898][train][INFO][train.py>_log] ==> #880000     Total Loss: 0.462    [weighted Loss:0.462    Policy Loss: 4.181    Value Loss: 5.528    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 108556     Buffer Size: 6685       Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-14 11:04:12,326][train][INFO][train.py>_log] ==> #882000     Total Loss: 0.698    [weighted Loss:0.698    Policy Loss: 3.747    Value Loss: 5.681    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 108735     Buffer Size: 6683       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-14 11:09:26,826][train][INFO][train.py>_log] ==> #884000     Total Loss: 0.360    [weighted Loss:0.360    Policy Loss: 3.750    Value Loss: 5.805    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 108921     Buffer Size: 6718       Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-14 11:14:45,615][train][INFO][train.py>_log] ==> #886000     Total Loss: 0.840    [weighted Loss:0.840    Policy Loss: 4.006    Value Loss: 4.947    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 109107     Buffer Size: 6742       Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
