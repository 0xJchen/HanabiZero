[2021-11-07 07:57:26,818][train][INFO][train.py>_log] ==> #0          Total Loss: 43.783   [weighted Loss:43.783   Policy Loss: 13.785   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 43         Buffer Size: 43         Transition Number: 0.555   k Batch Size: 128        Lr: 0.000   
[2021-11-07 07:59:39,106][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.814    [weighted Loss:5.814    Policy Loss: 14.464   Value Loss: 4.486    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 296        Buffer Size: 296        Transition Number: 3.727   k Batch Size: 128        Lr: 0.010   
[2021-11-07 08:02:40,605][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.652    [weighted Loss:6.652    Policy Loss: 14.537   Value Loss: 3.213    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 709        Buffer Size: 709        Transition Number: 8.841   k Batch Size: 128        Lr: 0.020   
[2021-11-07 08:06:00,559][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.078    [weighted Loss:4.078    Policy Loss: 14.465   Value Loss: 3.302    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216       Buffer Size: 1216       Transition Number: 14.060  k Batch Size: 128        Lr: 0.030   
[2021-11-07 08:09:22,807][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.956    [weighted Loss:5.956    Policy Loss: 14.035   Value Loss: 3.048    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1852       Buffer Size: 1852       Transition Number: 19.331  k Batch Size: 128        Lr: 0.040   
[2021-11-07 08:12:56,012][train][INFO][train.py>_log] ==> #5000       Total Loss: 6.160    [weighted Loss:6.160    Policy Loss: 13.121   Value Loss: 2.937    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2413       Buffer Size: 2413       Transition Number: 24.744  k Batch Size: 128        Lr: 0.050   
[2021-11-07 08:16:31,198][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.588    [weighted Loss:5.588    Policy Loss: 12.962   Value Loss: 2.851    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 3042       Buffer Size: 3042       Transition Number: 30.418  k Batch Size: 128        Lr: 0.060   
[2021-11-07 08:20:19,532][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.497    [weighted Loss:4.497    Policy Loss: 14.005   Value Loss: 2.936    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 3683       Buffer Size: 3683       Transition Number: 36.264  k Batch Size: 128        Lr: 0.070   
[2021-11-07 08:23:59,612][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.868    [weighted Loss:3.868    Policy Loss: 12.743   Value Loss: 2.621    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 4345       Buffer Size: 4345       Transition Number: 42.215  k Batch Size: 128        Lr: 0.080   
[2021-11-07 08:27:43,164][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.634    [weighted Loss:4.634    Policy Loss: 13.619   Value Loss: 2.895    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 4924       Buffer Size: 4924       Transition Number: 47.756  k Batch Size: 128        Lr: 0.090   
[2021-11-07 08:31:29,525][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.843    [weighted Loss:5.843    Policy Loss: 13.792   Value Loss: 2.765    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 5509       Buffer Size: 5509       Transition Number: 53.617  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:35:18,281][train][INFO][train.py>_log] ==> #11000      Total Loss: 6.079    [weighted Loss:6.079    Policy Loss: 12.772   Value Loss: 2.979    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 6078       Buffer Size: 6078       Transition Number: 59.204  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:39:03,494][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.812    [weighted Loss:6.812    Policy Loss: 13.810   Value Loss: 2.797    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 6878       Buffer Size: 6878       Transition Number: 65.327  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:42:51,528][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.226    [weighted Loss:5.226    Policy Loss: 12.932   Value Loss: 2.959    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 7426       Buffer Size: 7426       Transition Number: 71.035  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:46:38,562][train][INFO][train.py>_log] ==> #14000      Total Loss: 7.175    [weighted Loss:7.175    Policy Loss: 12.420   Value Loss: 2.730    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 8047       Buffer Size: 8047       Transition Number: 77.109  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:50:31,464][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.229    [weighted Loss:5.229    Policy Loss: 12.582   Value Loss: 2.801    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 8697       Buffer Size: 8697       Transition Number: 83.336  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:54:10,720][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.379    [weighted Loss:5.379    Policy Loss: 12.774   Value Loss: 2.918    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 9402       Buffer Size: 9402       Transition Number: 89.177  k Batch Size: 128        Lr: 0.100   
[2021-11-07 08:58:06,027][train][INFO][train.py>_log] ==> #17000      Total Loss: 6.439    [weighted Loss:6.439    Policy Loss: 13.261   Value Loss: 2.856    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 10077      Buffer Size: 10077      Transition Number: 95.226  k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:01:49,204][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.483    [weighted Loss:4.483    Policy Loss: 13.444   Value Loss: 2.734    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 10645      Buffer Size: 10645      Transition Number: 101.067 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:05:37,021][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.423    [weighted Loss:3.423    Policy Loss: 12.558   Value Loss: 2.971    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 11169      Buffer Size: 11169      Transition Number: 106.940 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:09:25,824][train][INFO][train.py>_log] ==> #20000      Total Loss: 6.681    [weighted Loss:6.681    Policy Loss: 12.926   Value Loss: 2.828    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 11743      Buffer Size: 11743      Transition Number: 112.941 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:13:17,622][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.736    [weighted Loss:5.736    Policy Loss: 12.368   Value Loss: 2.515    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 12334      Buffer Size: 12334      Transition Number: 119.107 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:17:05,507][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 12.553   Value Loss: 2.596    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 12846      Buffer Size: 12846      Transition Number: 124.902 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:21:03,482][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.854    [weighted Loss:4.854    Policy Loss: 12.224   Value Loss: 2.478    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 13312      Buffer Size: 13312      Transition Number: 131.101 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:25:05,278][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.280    [weighted Loss:4.280    Policy Loss: 12.934   Value Loss: 2.461    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 13773      Buffer Size: 13773      Transition Number: 137.373 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:29:17,776][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.587    [weighted Loss:4.587    Policy Loss: 12.639   Value Loss: 3.082    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 14179      Buffer Size: 14179      Transition Number: 143.840 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:33:24,820][train][INFO][train.py>_log] ==> #26000      Total Loss: 6.126    [weighted Loss:6.126    Policy Loss: 14.108   Value Loss: 2.804    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 14600      Buffer Size: 14600      Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:37:37,900][train][INFO][train.py>_log] ==> #27000      Total Loss: 5.890    [weighted Loss:5.890    Policy Loss: 12.445   Value Loss: 2.882    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 15015      Buffer Size: 15015      Transition Number: 156.421 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:41:45,782][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.747    [weighted Loss:2.747    Policy Loss: 12.331   Value Loss: 2.868    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 15397      Buffer Size: 15397      Transition Number: 162.605 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:45:58,345][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.305    [weighted Loss:4.305    Policy Loss: 12.373   Value Loss: 2.919    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 15753      Buffer Size: 15753      Transition Number: 168.645 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:50:09,371][train][INFO][train.py>_log] ==> #30000      Total Loss: 5.480    [weighted Loss:5.480    Policy Loss: 12.651   Value Loss: 3.014    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 16047      Buffer Size: 16047      Transition Number: 174.625 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:54:37,276][train][INFO][train.py>_log] ==> #31000      Total Loss: 6.181    [weighted Loss:6.181    Policy Loss: 12.780   Value Loss: 2.967    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 16307      Buffer Size: 16307      Transition Number: 180.393 k Batch Size: 128        Lr: 0.100   
[2021-11-07 09:59:22,104][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.468    [weighted Loss:4.468    Policy Loss: 13.204   Value Loss: 2.960    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 16567      Buffer Size: 16567      Transition Number: 186.931 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:04:28,373][train][INFO][train.py>_log] ==> #33000      Total Loss: 5.765    [weighted Loss:5.765    Policy Loss: 13.128   Value Loss: 3.095    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 16779      Buffer Size: 16779      Transition Number: 193.479 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:10:00,660][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 11.461   Value Loss: 3.108    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 16958      Buffer Size: 16958      Transition Number: 200.666 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:16:04,732][train][INFO][train.py>_log] ==> #35000      Total Loss: 4.850    [weighted Loss:4.850    Policy Loss: 11.442   Value Loss: 3.257    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 17163      Buffer Size: 17163      Transition Number: 207.940 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:22:24,863][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.632    [weighted Loss:3.632    Policy Loss: 10.491   Value Loss: 3.211    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 17418      Buffer Size: 17418      Transition Number: 216.249 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:29:04,841][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.185    [weighted Loss:4.185    Policy Loss: 8.014    Value Loss: 3.576    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 17677      Buffer Size: 17677      Transition Number: 224.144 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:35:55,493][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 8.833    Value Loss: 3.320    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 17944      Buffer Size: 17944      Transition Number: 233.365 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:43:04,750][train][INFO][train.py>_log] ==> #39000      Total Loss: 4.696    [weighted Loss:4.696    Policy Loss: 13.484   Value Loss: 3.901    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 18172      Buffer Size: 18172      Transition Number: 243.162 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:50:39,929][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 7.996    Value Loss: 3.525    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 18416      Buffer Size: 18416      Transition Number: 254.138 k Batch Size: 128        Lr: 0.100   
[2021-11-07 10:58:37,870][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.579    [weighted Loss:3.579    Policy Loss: 6.720    Value Loss: 3.554    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 18653      Buffer Size: 18653      Transition Number: 265.406 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:06:36,187][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 6.740    Value Loss: 3.435    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 18933      Buffer Size: 18933      Transition Number: 276.850 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:14:56,668][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 5.886    Value Loss: 3.775    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 19264      Buffer Size: 19264      Transition Number: 288.429 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:23:39,455][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.547    [weighted Loss:3.547    Policy Loss: 6.355    Value Loss: 3.749    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 19707      Buffer Size: 19707      Transition Number: 300.518 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:31:42,002][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 5.115    Value Loss: 3.715    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 20295      Buffer Size: 20295      Transition Number: 312.339 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:39:55,476][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 4.498    Value Loss: 3.934    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 21183      Buffer Size: 21183      Transition Number: 324.925 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:48:25,909][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 4.857    Value Loss: 3.925    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 21613      Buffer Size: 21613      Transition Number: 336.407 k Batch Size: 128        Lr: 0.100   
[2021-11-07 11:58:08,131][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.756    [weighted Loss:1.756    Policy Loss: 4.307    Value Loss: 3.874    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 22052      Buffer Size: 22052      Transition Number: 350.285 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:06:33,216][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 4.751    Value Loss: 3.814    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 22424      Buffer Size: 22424      Transition Number: 361.903 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:14:51,078][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 3.521    Value Loss: 3.504    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 22960      Buffer Size: 22960      Transition Number: 373.840 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:23:19,464][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 3.593    Value Loss: 3.894    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 23472      Buffer Size: 23472      Transition Number: 385.831 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:31:49,428][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 4.003    Value Loss: 4.487    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 23922      Buffer Size: 23922      Transition Number: 397.717 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:40:17,021][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 3.331    Value Loss: 3.958    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 24363      Buffer Size: 23569      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:48:55,711][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.291    [weighted Loss:1.291    Policy Loss: 3.026    Value Loss: 4.208    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 24787      Buffer Size: 22692      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-07 12:58:08,303][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.967    [weighted Loss:1.967    Policy Loss: 3.180    Value Loss: 4.203    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 25229      Buffer Size: 21757      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:07:37,903][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.758    [weighted Loss:2.758    Policy Loss: 4.484    Value Loss: 3.815    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 25650      Buffer Size: 20742      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:17:30,118][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 3.850    Value Loss: 4.145    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 26087      Buffer Size: 19812      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:27:26,731][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 3.862    Value Loss: 3.785    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 26477      Buffer Size: 18663      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:37:39,939][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.933    [weighted Loss:3.933    Policy Loss: 6.727    Value Loss: 4.017    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 26904      Buffer Size: 17497      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:48:08,659][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.544    [weighted Loss:1.544    Policy Loss: 2.628    Value Loss: 4.364    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 27368      Buffer Size: 16466      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:58:57,967][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.054    [weighted Loss:2.054    Policy Loss: 3.428    Value Loss: 4.049    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 27782      Buffer Size: 15402      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:09:27,767][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 6.026    Value Loss: 4.181    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 28641      Buffer Size: 15095      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:20:19,904][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 3.857    Value Loss: 4.054    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 29176      Buffer Size: 14597      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:31:20,027][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 4.476    Value Loss: 4.316    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 29557      Buffer Size: 13928      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:42:32,777][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 3.659    Value Loss: 4.190    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 30019      Buffer Size: 13616      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:54:16,037][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.504    [weighted Loss:1.504    Policy Loss: 2.632    Value Loss: 4.362    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 30461      Buffer Size: 13519      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:05:48,687][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 2.917    Value Loss: 4.135    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 30887      Buffer Size: 13398      Transition Number: 399.924 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:16:58,827][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.941    [weighted Loss:1.941    Policy Loss: 3.552    Value Loss: 4.490    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 31602      Buffer Size: 13636      Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:28:03,171][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 3.821    Value Loss: 4.323    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 32173      Buffer Size: 13849      Transition Number: 399.982 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:38:47,160][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 3.753    Value Loss: 4.370    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 32789      Buffer Size: 14134      Transition Number: 399.973 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:49:35,520][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.784    [weighted Loss:3.784    Policy Loss: 6.467    Value Loss: 4.361    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 33290      Buffer Size: 14278      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:00:15,450][train][INFO][train.py>_log] ==> #72000      Total Loss: 4.834    [weighted Loss:4.834    Policy Loss: 8.157    Value Loss: 4.686    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 33789      Buffer Size: 14299      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:11:20,198][train][INFO][train.py>_log] ==> #73000      Total Loss: 4.095    [weighted Loss:4.095    Policy Loss: 8.650    Value Loss: 4.470    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 34331      Buffer Size: 14134      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:22:22,280][train][INFO][train.py>_log] ==> #74000      Total Loss: 5.419    [weighted Loss:5.419    Policy Loss: 9.595    Value Loss: 4.178    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 34753      Buffer Size: 13491      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:33:17,577][train][INFO][train.py>_log] ==> #75000      Total Loss: 5.979    [weighted Loss:5.979    Policy Loss: 9.404    Value Loss: 4.587    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 35345      Buffer Size: 13562      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:44:20,667][train][INFO][train.py>_log] ==> #76000      Total Loss: 6.162    [weighted Loss:6.162    Policy Loss: 10.826   Value Loss: 4.676    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 35788      Buffer Size: 13471      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:55:48,229][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.206    [weighted Loss:4.206    Policy Loss: 8.440    Value Loss: 4.075    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 36291      Buffer Size: 13279      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:07:04,670][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 8.228    Value Loss: 4.566    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 36775      Buffer Size: 13113      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:18:41,245][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.970    [weighted Loss:3.970    Policy Loss: 8.479    Value Loss: 4.695    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 37285      Buffer Size: 12991      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:30:18,582][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 8.244    Value Loss: 4.688    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 37806      Buffer Size: 12916      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:41:55,517][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.511    [weighted Loss:4.511    Policy Loss: 8.228    Value Loss: 4.593    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 38300      Buffer Size: 12833      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:53:30,777][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 7.343    Value Loss: 4.833    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 38728      Buffer Size: 12680      Transition Number: 399.930 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:04:55,660][train][INFO][train.py>_log] ==> #83000      Total Loss: 5.441    [weighted Loss:5.441    Policy Loss: 8.792    Value Loss: 4.775    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 39118      Buffer Size: 12622      Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:16:12,658][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.393    [weighted Loss:3.393    Policy Loss: 8.555    Value Loss: 4.702    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 39525      Buffer Size: 12521      Transition Number: 399.939 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:27:26,703][train][INFO][train.py>_log] ==> #85000      Total Loss: 4.948    [weighted Loss:4.948    Policy Loss: 9.077    Value Loss: 4.904    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 40018      Buffer Size: 12544      Transition Number: 400.034 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:38:43,139][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 7.442    Value Loss: 4.621    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 40406      Buffer Size: 12360      Transition Number: 400.153 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:50:23,589][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.388    [weighted Loss:4.388    Policy Loss: 7.833    Value Loss: 4.968    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 40874      Buffer Size: 11973      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:01:40,543][train][INFO][train.py>_log] ==> #88000      Total Loss: 3.623    [weighted Loss:3.623    Policy Loss: 7.845    Value Loss: 4.902    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 41336      Buffer Size: 11958      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:13:02,711][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 8.702    Value Loss: 4.905    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 41696      Buffer Size: 11885      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:25:18,124][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 9.273    Value Loss: 4.851    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 42099      Buffer Size: 11813      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:36:51,329][train][INFO][train.py>_log] ==> #91000      Total Loss: 4.501    [weighted Loss:4.501    Policy Loss: 8.605    Value Loss: 5.040    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 42492      Buffer Size: 11767      Transition Number: 399.978 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:48:20,083][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 8.060    Value Loss: 5.056    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 42880      Buffer Size: 11581      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:59:52,309][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.495    [weighted Loss:3.495    Policy Loss: 9.665    Value Loss: 4.914    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 43303      Buffer Size: 11321      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:11:27,319][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 9.480    Value Loss: 4.719    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 43738      Buffer Size: 11102      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:23:01,018][train][INFO][train.py>_log] ==> #95000      Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 9.295    Value Loss: 4.962    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 44230      Buffer Size: 10987      Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:35:16,666][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 8.336    Value Loss: 5.059    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 44658      Buffer Size: 10837      Transition Number: 399.928 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:47:38,925][train][INFO][train.py>_log] ==> #97000      Total Loss: 3.639    [weighted Loss:3.639    Policy Loss: 7.776    Value Loss: 4.721    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 45075      Buffer Size: 10654      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:59:58,329][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.495    [weighted Loss:1.495    Policy Loss: 7.631    Value Loss: 5.005    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 45531      Buffer Size: 10593      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:12:09,936][train][INFO][train.py>_log] ==> #99000      Total Loss: 5.150    [weighted Loss:5.150    Policy Loss: 7.672    Value Loss: 4.728    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 45973      Buffer Size: 10411      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:24:11,437][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.183    [weighted Loss:4.183    Policy Loss: 9.191    Value Loss: 5.046    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 46326      Buffer Size: 10220      Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:36:29,616][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.033    [weighted Loss:3.033    Policy Loss: 7.352    Value Loss: 5.006    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 46706      Buffer Size: 10039      Transition Number: 399.936 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:49:01,631][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.108    [weighted Loss:3.108    Policy Loss: 6.250    Value Loss: 4.725    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 47031      Buffer Size: 9758       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:01:49,670][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 6.144    Value Loss: 4.928    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 47433      Buffer Size: 9522       Transition Number: 399.964 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:14:57,962][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 5.418    Value Loss: 4.809    Reward Loss: 0.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 47887      Buffer Size: 9432       Transition Number: 399.971 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:27:56,832][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 4.893    Value Loss: 4.835    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 48399      Buffer Size: 9478       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:40:53,417][train][INFO][train.py>_log] ==> #106000     Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 5.392    Value Loss: 5.150    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 48790      Buffer Size: 9381       Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:53:54,307][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 5.601    Value Loss: 5.161    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 49236      Buffer Size: 9247       Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:07:30,214][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 5.322    Value Loss: 4.922    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 49686      Buffer Size: 9190       Transition Number: 399.980 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:21:00,034][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 5.437    Value Loss: 4.948    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 50111      Buffer Size: 9037       Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:34:31,959][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.966    [weighted Loss:2.966    Policy Loss: 5.679    Value Loss: 4.893    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 50584      Buffer Size: 9021       Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:47:58,692][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.793    [weighted Loss:3.793    Policy Loss: 5.946    Value Loss: 4.637    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 51000      Buffer Size: 8995       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:01:55,556][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 5.177    Value Loss: 5.157    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 51378      Buffer Size: 8876       Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:15:40,107][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 5.604    Value Loss: 5.208    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 52052      Buffer Size: 9068       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:29:19,475][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.336    [weighted Loss:3.336    Policy Loss: 5.812    Value Loss: 4.655    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 52595      Buffer Size: 9083       Transition Number: 399.929 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:42:32,434][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 5.469    Value Loss: 4.812    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 52998      Buffer Size: 8924       Transition Number: 400.030 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:56:09,666][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.295    [weighted Loss:3.295    Policy Loss: 6.073    Value Loss: 5.060    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 53473      Buffer Size: 8882       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:08:54,997][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 6.458    Value Loss: 5.213    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 53903      Buffer Size: 8877       Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:22:11,936][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.522    [weighted Loss:2.522    Policy Loss: 4.737    Value Loss: 4.780    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 54290      Buffer Size: 8744       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:36:23,222][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 5.379    Value Loss: 5.240    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 54700      Buffer Size: 8615       Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:49:58,383][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.872    [weighted Loss:2.872    Policy Loss: 5.335    Value Loss: 5.227    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 55388      Buffer Size: 8902       Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:03:12,916][train][INFO][train.py>_log] ==> #121000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 5.250    Value Loss: 5.209    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 56001      Buffer Size: 9165       Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:15:48,665][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.885    [weighted Loss:2.885    Policy Loss: 5.557    Value Loss: 5.141    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 56667      Buffer Size: 9510       Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:28:44,955][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 6.044    Value Loss: 5.550    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 57366      Buffer Size: 9833       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:42:01,986][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.736    [weighted Loss:2.736    Policy Loss: 4.948    Value Loss: 4.933    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 57826      Buffer Size: 9828       Transition Number: 399.968 k Batch Size: 128        Lr: 0.100   
[2021-11-08 02:54:50,869][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.636    [weighted Loss:1.636    Policy Loss: 5.233    Value Loss: 5.102    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 58202      Buffer Size: 9693       Transition Number: 399.934 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:07:35,928][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 4.808    Value Loss: 5.264    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 59154      Buffer Size: 10264      Transition Number: 399.948 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:20:13,811][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 5.495    Value Loss: 5.076    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 59670      Buffer Size: 10367      Transition Number: 400.082 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:33:35,060][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 5.014    Value Loss: 5.053    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 60073      Buffer Size: 10329      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:46:01,483][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.161    [weighted Loss:2.161    Policy Loss: 5.045    Value Loss: 4.997    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 60423      Buffer Size: 10286      Transition Number: 399.963 k Batch Size: 128        Lr: 0.100   
[2021-11-08 03:58:20,185][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.368    [weighted Loss:3.368    Policy Loss: 5.613    Value Loss: 5.384    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 60782      Buffer Size: 10193      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:11:15,762][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.240    [weighted Loss:3.240    Policy Loss: 5.189    Value Loss: 4.869    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 61241      Buffer Size: 10264      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:24:05,494][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 5.129    Value Loss: 5.614    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 61628      Buffer Size: 10306      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:37:11,734][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.395    [weighted Loss:2.395    Policy Loss: 4.995    Value Loss: 5.504    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 62049      Buffer Size: 10139      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-08 04:49:40,921][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 4.244    Value Loss: 5.288    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 62555      Buffer Size: 10097      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:01:56,652][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 4.044    Value Loss: 5.387    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 63074      Buffer Size: 10218      Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:14:50,754][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 3.548    Value Loss: 5.477    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 63629      Buffer Size: 10358      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:27:38,606][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 4.841    Value Loss: 5.004    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 64128      Buffer Size: 10451      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:40:13,137][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 3.822    Value Loss: 5.454    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 64571      Buffer Size: 10510      Transition Number: 399.950 k Batch Size: 128        Lr: 0.100   
[2021-11-08 05:52:55,529][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 3.351    Value Loss: 5.468    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 65208      Buffer Size: 10815      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:05:32,543][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.648    [weighted Loss:2.648    Policy Loss: 4.434    Value Loss: 5.081    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 65841      Buffer Size: 11058      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:18:02,769][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 5.365    Value Loss: 5.304    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 66271      Buffer Size: 10884      Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:30:30,967][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 4.250    Value Loss: 5.427    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 66631      Buffer Size: 10647      Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:43:02,890][train][INFO][train.py>_log] ==> #143000     Total Loss: 4.311    [weighted Loss:4.311    Policy Loss: 8.118    Value Loss: 5.642    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 67415      Buffer Size: 10778      Transition Number: 399.955 k Batch Size: 128        Lr: 0.100   
[2021-11-08 06:55:33,014][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 6.634    Value Loss: 5.200    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 68008      Buffer Size: 10689      Transition Number: 399.949 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:08:01,304][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 5.915    Value Loss: 5.158    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 68389      Buffer Size: 10654      Transition Number: 399.951 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:20:46,827][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 5.643    Value Loss: 4.940    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 68821      Buffer Size: 10695      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:33:21,209][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.830    [weighted Loss:1.830    Policy Loss: 5.852    Value Loss: 5.720    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 69208      Buffer Size: 10337      Transition Number: 399.986 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:45:43,921][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.170    [weighted Loss:3.170    Policy Loss: 6.231    Value Loss: 5.597    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 69663      Buffer Size: 10105      Transition Number: 400.044 k Batch Size: 128        Lr: 0.100   
[2021-11-08 07:58:28,321][train][INFO][train.py>_log] ==> #149000     Total Loss: 1.020    [weighted Loss:1.020    Policy Loss: 4.438    Value Loss: 5.387    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 70047      Buffer Size: 10086      Transition Number: 399.975 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:11:10,704][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 4.724    Value Loss: 5.314    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 70960      Buffer Size: 10631      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:23:38,868][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 4.730    Value Loss: 5.230    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 72014      Buffer Size: 11332      Transition Number: 399.933 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:35:40,345][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 4.400    Value Loss: 5.145    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 72659      Buffer Size: 11592      Transition Number: 399.985 k Batch Size: 128        Lr: 0.100   
[2021-11-08 08:47:59,257][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 5.162    Value Loss: 5.338    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 73087      Buffer Size: 11623      Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:00:04,362][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 5.840    Value Loss: 5.469    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 73460      Buffer Size: 11637      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:12:40,712][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 4.387    Value Loss: 5.270    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 73812      Buffer Size: 11532      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:25:40,052][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 5.531    Value Loss: 5.008    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 74190      Buffer Size: 11338      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:38:25,838][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 4.810    Value Loss: 5.293    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 75306      Buffer Size: 11894      Transition Number: 399.970 k Batch Size: 128        Lr: 0.100   
[2021-11-08 09:51:02,268][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 4.831    Value Loss: 5.681    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 76516      Buffer Size: 12588      Transition Number: 399.932 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:02:45,175][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.006    [weighted Loss:2.006    Policy Loss: 4.757    Value Loss: 5.024    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 77397      Buffer Size: 13023      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:14:27,339][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 4.333    Value Loss: 5.459    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 77910      Buffer Size: 13022      Transition Number: 399.979 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:26:03,856][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 5.797    Value Loss: 5.305    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 78365      Buffer Size: 12935      Transition Number: 399.954 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:38:12,489][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 4.628    Value Loss: 5.085    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 78991      Buffer Size: 13010      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 10:50:33,665][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 4.229    Value Loss: 5.448    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 79487      Buffer Size: 13103      Transition Number: 399.983 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:03:05,543][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 4.415    Value Loss: 5.250    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 79972      Buffer Size: 13088      Transition Number: 399.946 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:15:03,501][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.397    [weighted Loss:1.397    Policy Loss: 4.749    Value Loss: 4.953    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 80432      Buffer Size: 12830      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:27:29,472][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.006    [weighted Loss:2.006    Policy Loss: 3.897    Value Loss: 5.253    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 80854      Buffer Size: 12705      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:40:04,402][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 4.467    Value Loss: 5.316    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 81285      Buffer Size: 12749      Transition Number: 399.962 k Batch Size: 128        Lr: 0.100   
[2021-11-08 11:53:04,959][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 3.320    Value Loss: 5.188    Reward Loss: 1.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 81698      Buffer Size: 12732      Transition Number: 399.960 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:05:50,571][train][INFO][train.py>_log] ==> #169000     Total Loss: 4.170    [weighted Loss:4.170    Policy Loss: 7.457    Value Loss: 5.350    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 82057      Buffer Size: 12677      Transition Number: 399.966 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:18:10,455][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 4.282    Value Loss: 5.047    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 82532      Buffer Size: 12745      Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:30:42,313][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 6.269    Value Loss: 5.067    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 82958      Buffer Size: 12645      Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-08 12:43:26,076][train][INFO][train.py>_log] ==> #172000     Total Loss: 4.349    [weighted Loss:4.349    Policy Loss: 8.805    Value Loss: 5.679    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 83485      Buffer Size: 12263      Transition Number: 399.941 k Batch Size: 128        Lr: 0.100   
