[2021-11-05 20:21:00,007][train][INFO][train.py>_log] ==> #0          Total Loss: 43.900   [weighted Loss:43.900   Policy Loss: 13.902   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 47         Buffer Size: 47         Transition Number: 0.540   k Batch Size: 128        Lr: 0.000   
[2021-11-05 20:25:12,099][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.877    [weighted Loss:3.877    Policy Loss: 13.510   Value Loss: 4.836    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 357        Buffer Size: 357        Transition Number: 4.373   k Batch Size: 128        Lr: 0.010   
[2021-11-05 20:29:35,552][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.938    [weighted Loss:6.938    Policy Loss: 13.713   Value Loss: 3.548    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 686        Buffer Size: 686        Transition Number: 8.250   k Batch Size: 128        Lr: 0.020   
[2021-11-05 20:34:01,152][train][INFO][train.py>_log] ==> #3000       Total Loss: 7.381    [weighted Loss:7.381    Policy Loss: 12.963   Value Loss: 3.011    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117       Buffer Size: 1117       Transition Number: 11.727  k Batch Size: 128        Lr: 0.030   
[2021-11-05 20:38:28,662][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.096    [weighted Loss:6.096    Policy Loss: 12.870   Value Loss: 3.004    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 1479       Buffer Size: 1479       Transition Number: 15.212  k Batch Size: 128        Lr: 0.040   
[2021-11-05 20:42:54,698][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.241    [weighted Loss:5.241    Policy Loss: 13.883   Value Loss: 2.788    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1819       Buffer Size: 1819       Transition Number: 18.561  k Batch Size: 128        Lr: 0.050   
[2021-11-05 20:47:20,334][train][INFO][train.py>_log] ==> #6000       Total Loss: 6.143    [weighted Loss:6.143    Policy Loss: 12.339   Value Loss: 2.905    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 2103       Buffer Size: 2103       Transition Number: 21.911  k Batch Size: 128        Lr: 0.060   
[2021-11-05 20:51:50,300][train][INFO][train.py>_log] ==> #7000       Total Loss: 6.618    [weighted Loss:6.618    Policy Loss: 11.844   Value Loss: 2.866    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 2398       Buffer Size: 2398       Transition Number: 25.202  k Batch Size: 128        Lr: 0.070   
[2021-11-05 20:56:17,444][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.002    [weighted Loss:5.002    Policy Loss: 12.357   Value Loss: 2.804    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 2776       Buffer Size: 2776       Transition Number: 28.738  k Batch Size: 128        Lr: 0.080   
[2021-11-05 21:00:45,461][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.667    [weighted Loss:4.667    Policy Loss: 11.280   Value Loss: 2.402    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 3107       Buffer Size: 3107       Transition Number: 32.043  k Batch Size: 128        Lr: 0.090   
[2021-11-05 21:05:17,240][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.964    [weighted Loss:5.964    Policy Loss: 13.759   Value Loss: 2.880    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 3393       Buffer Size: 3393       Transition Number: 35.502  k Batch Size: 128        Lr: 0.100   
[2021-11-05 21:09:42,105][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.411    [weighted Loss:4.411    Policy Loss: 12.955   Value Loss: 2.657    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 3794       Buffer Size: 3794       Transition Number: 38.867  k Batch Size: 128        Lr: 0.100   
[2021-11-05 21:14:12,528][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.273    [weighted Loss:6.273    Policy Loss: 11.521   Value Loss: 2.586    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 4068       Buffer Size: 4068       Transition Number: 42.097  k Batch Size: 128        Lr: 0.100   
[2021-11-05 21:18:42,708][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 12.773   Value Loss: 2.704    Reward Loss: 0.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 4332       Buffer Size: 4332       Transition Number: 45.338  k Batch Size: 128        Lr: 0.100   
[2021-11-05 21:23:11,047][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.471    [weighted Loss:5.471    Policy Loss: 12.243   Value Loss: 2.509    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 4725       Buffer Size: 4725       Transition Number: 48.784  k Batch Size: 128        Lr: 0.100   
[2021-11-05 21:27:44,267][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.316    [weighted Loss:4.316    Policy Loss: 12.754   Value Loss: 2.699    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 5001       Buffer Size: 5001       Transition Number: 52.015  k Batch Size: 128        Lr: 0.100   
[2021-11-05 21:32:20,867][train][INFO][train.py>_log] ==> #16000      Total Loss: 6.392    [weighted Loss:6.392    Policy Loss: 12.597   Value Loss: 2.968    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 5397       Buffer Size: 5397       Transition Number: 55.728  k Batch Size: 128        Lr: 0.100   
