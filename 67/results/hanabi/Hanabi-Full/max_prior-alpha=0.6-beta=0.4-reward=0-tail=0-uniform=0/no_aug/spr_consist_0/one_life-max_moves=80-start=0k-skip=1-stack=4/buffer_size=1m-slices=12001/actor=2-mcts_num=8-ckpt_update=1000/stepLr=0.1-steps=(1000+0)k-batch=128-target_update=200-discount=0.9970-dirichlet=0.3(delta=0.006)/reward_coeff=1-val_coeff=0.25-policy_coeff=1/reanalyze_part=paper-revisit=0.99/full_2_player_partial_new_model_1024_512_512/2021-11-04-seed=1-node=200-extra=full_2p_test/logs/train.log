[2021-11-04 07:49:09,403][train][INFO][train.py>_log] ==> #0          Total Loss: 43.760   [weighted Loss:43.760   Policy Loss: 13.762   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 41         Buffer Size: 41         Transition Number: 0.450   k Batch Size: 128        Lr: 0.000   
[2021-11-04 07:53:38,771][train][INFO][train.py>_log] ==> #1000       Total Loss: 8.357    [weighted Loss:8.357    Policy Loss: 14.076   Value Loss: 4.503    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 323        Buffer Size: 323        Transition Number: 4.097   k Batch Size: 128        Lr: 0.010   
[2021-11-04 07:58:42,222][train][INFO][train.py>_log] ==> #2000       Total Loss: 8.869    [weighted Loss:8.869    Policy Loss: 13.850   Value Loss: 3.376    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 682        Buffer Size: 682        Transition Number: 8.465   k Batch Size: 128        Lr: 0.020   
[2021-11-04 08:03:56,472][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.838    [weighted Loss:3.838    Policy Loss: 12.797   Value Loss: 2.880    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 1065       Buffer Size: 1065       Transition Number: 12.246  k Batch Size: 128        Lr: 0.030   
[2021-11-04 08:08:55,748][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.534    [weighted Loss:6.534    Policy Loss: 13.378   Value Loss: 2.906    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 1509       Buffer Size: 1509       Transition Number: 15.905  k Batch Size: 128        Lr: 0.040   
[2021-11-04 08:14:19,247][train][INFO][train.py>_log] ==> #5000       Total Loss: 6.862    [weighted Loss:6.862    Policy Loss: 13.240   Value Loss: 2.859    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 1958       Buffer Size: 1958       Transition Number: 19.791  k Batch Size: 128        Lr: 0.050   
[2021-11-04 08:19:31,719][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.545    [weighted Loss:4.545    Policy Loss: 12.806   Value Loss: 2.813    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 2332       Buffer Size: 2332       Transition Number: 23.564  k Batch Size: 128        Lr: 0.060   
[2021-11-04 08:24:47,895][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.084    [weighted Loss:4.084    Policy Loss: 12.487   Value Loss: 2.695    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 2689       Buffer Size: 2689       Transition Number: 27.326  k Batch Size: 128        Lr: 0.070   
[2021-11-04 08:30:10,189][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 13.111   Value Loss: 2.535    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 3079       Buffer Size: 3079       Transition Number: 31.300  k Batch Size: 128        Lr: 0.080   
[2021-11-04 08:35:33,633][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.429    [weighted Loss:5.429    Policy Loss: 13.296   Value Loss: 2.571    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 3429       Buffer Size: 3429       Transition Number: 35.093  k Batch Size: 128        Lr: 0.090   
[2021-11-04 08:41:27,949][train][INFO][train.py>_log] ==> #10000      Total Loss: 6.643    [weighted Loss:6.643    Policy Loss: 12.229   Value Loss: 2.670    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 3848       Buffer Size: 3848       Transition Number: 39.264  k Batch Size: 128        Lr: 0.100   
[2021-11-04 08:47:52,444][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.222    [weighted Loss:4.222    Policy Loss: 13.244   Value Loss: 2.899    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 4223       Buffer Size: 4223       Transition Number: 43.634  k Batch Size: 128        Lr: 0.100   
[2021-11-04 08:53:53,209][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.818    [weighted Loss:5.818    Policy Loss: 11.764   Value Loss: 2.746    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 4761       Buffer Size: 4761       Transition Number: 48.142  k Batch Size: 128        Lr: 0.100   
[2021-11-04 08:59:08,019][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.986    [weighted Loss:4.986    Policy Loss: 12.661   Value Loss: 2.457    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 5187       Buffer Size: 5187       Transition Number: 51.909  k Batch Size: 128        Lr: 0.100   
[2021-11-04 09:04:59,272][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.932    [weighted Loss:4.932    Policy Loss: 12.688   Value Loss: 2.656    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 5641       Buffer Size: 5641       Transition Number: 56.086  k Batch Size: 128        Lr: 0.100   
[2021-11-04 09:10:36,256][train][INFO][train.py>_log] ==> #15000      Total Loss: 6.672    [weighted Loss:6.672    Policy Loss: 12.375   Value Loss: 2.542    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 6094       Buffer Size: 6094       Transition Number: 60.083  k Batch Size: 128        Lr: 0.100   
[2021-11-04 09:16:07,074][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.165    [weighted Loss:4.165    Policy Loss: 11.718   Value Loss: 2.955    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 6633       Buffer Size: 6633       Transition Number: 64.112  k Batch Size: 128        Lr: 0.100   
[2021-11-04 09:21:54,184][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.077    [weighted Loss:4.077    Policy Loss: 13.197   Value Loss: 2.927    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 7123       Buffer Size: 7123       Transition Number: 68.241  k Batch Size: 128        Lr: 0.100   
[2021-11-04 09:27:41,945][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.141    [weighted Loss:4.141    Policy Loss: 11.332   Value Loss: 2.785    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 7671       Buffer Size: 7671       Transition Number: 72.510  k Batch Size: 128        Lr: 0.100   
