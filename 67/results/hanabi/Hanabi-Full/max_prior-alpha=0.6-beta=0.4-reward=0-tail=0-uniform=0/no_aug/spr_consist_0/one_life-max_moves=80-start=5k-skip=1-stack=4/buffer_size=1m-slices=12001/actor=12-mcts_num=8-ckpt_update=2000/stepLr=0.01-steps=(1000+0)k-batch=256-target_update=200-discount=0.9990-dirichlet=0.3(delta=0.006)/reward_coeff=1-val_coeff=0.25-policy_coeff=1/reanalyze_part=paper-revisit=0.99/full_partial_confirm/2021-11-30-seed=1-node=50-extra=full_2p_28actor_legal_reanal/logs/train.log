[2021-11-30 07:58:20,374][train][INFO][train.py>_log] ==> #0          Total Loss: 48.737   [weighted Loss:48.737   Policy Loss: 14.265   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 476        Buffer Size: 476        Transition Number: 5.872   k Batch Size: 256        Lr: 0.000   
[2021-11-30 08:03:21,392][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.414    [weighted Loss:3.414    Policy Loss: 12.306   Value Loss: 5.987    Reward Loss: 2.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 2958       Buffer Size: 2958       Transition Number: 35.652  k Batch Size: 256        Lr: 0.002   
[2021-11-30 08:08:10,337][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.051    [weighted Loss:6.051    Policy Loss: 10.338   Value Loss: 4.722    Reward Loss: 1.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 6239       Buffer Size: 6239       Transition Number: 61.705  k Batch Size: 256        Lr: 0.004   
[2021-11-30 08:13:11,666][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.925    [weighted Loss:3.925    Policy Loss: 7.572    Value Loss: 4.064    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 10428      Buffer Size: 10428      Transition Number: 87.487  k Batch Size: 256        Lr: 0.006   
[2021-11-30 08:18:13,030][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.739    [weighted Loss:5.739    Policy Loss: 8.068    Value Loss: 3.563    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 11278      Buffer Size: 11278      Transition Number: 103.710 k Batch Size: 256        Lr: 0.008   
[2021-11-30 08:23:24,244][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.384    [weighted Loss:4.384    Policy Loss: 8.888    Value Loss: 3.437    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 13523      Buffer Size: 13523      Transition Number: 128.861 k Batch Size: 256        Lr: 0.010   
[2021-11-30 08:28:04,620][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.922    [weighted Loss:2.922    Policy Loss: 8.600    Value Loss: 3.112    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 15557      Buffer Size: 15557      Transition Number: 149.560 k Batch Size: 256        Lr: 0.010   
[2021-11-30 08:32:38,215][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.593    [weighted Loss:1.593    Policy Loss: 9.151    Value Loss: 2.981    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 17093      Buffer Size: 17093      Transition Number: 167.733 k Batch Size: 256        Lr: 0.010   
[2021-11-30 08:37:12,689][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.261    [weighted Loss:4.261    Policy Loss: 9.539    Value Loss: 3.105    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 18369      Buffer Size: 18369      Transition Number: 186.374 k Batch Size: 256        Lr: 0.010   
[2021-11-30 08:41:53,453][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 8.312    Value Loss: 2.922    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 19250      Buffer Size: 19250      Transition Number: 202.695 k Batch Size: 256        Lr: 0.010   
[2021-11-30 08:46:37,896][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 8.024    Value Loss: 2.943    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 19893      Buffer Size: 19893      Transition Number: 218.536 k Batch Size: 256        Lr: 0.010   
[2021-11-30 08:51:21,210][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 7.735    Value Loss: 3.131    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 20492      Buffer Size: 20492      Transition Number: 235.604 k Batch Size: 256        Lr: 0.010   
[2021-11-30 08:56:04,159][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 5.881    Value Loss: 3.065    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 21009      Buffer Size: 21009      Transition Number: 252.187 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:00:38,908][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.843    [weighted Loss:2.843    Policy Loss: 5.554    Value Loss: 3.132    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 21401      Buffer Size: 21401      Transition Number: 269.588 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:05:10,329][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 3.939    Value Loss: 3.041    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 21678      Buffer Size: 21678      Transition Number: 286.816 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:09:47,578][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.592    [weighted Loss:1.592    Policy Loss: 3.996    Value Loss: 2.814    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 21929      Buffer Size: 21929      Transition Number: 305.547 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:14:25,371][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 3.570    Value Loss: 2.994    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 22170      Buffer Size: 22170      Transition Number: 323.609 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:19:00,235][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.381    [weighted Loss:1.381    Policy Loss: 3.583    Value Loss: 3.098    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 22355      Buffer Size: 22355      Transition Number: 337.702 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:23:36,849][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.764    [weighted Loss:1.764    Policy Loss: 3.671    Value Loss: 3.245    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 22531      Buffer Size: 22531      Transition Number: 351.206 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:28:20,964][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.071    [weighted Loss:1.071    Policy Loss: 3.779    Value Loss: 3.192    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 22700      Buffer Size: 22700      Transition Number: 363.934 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:33:03,639][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 4.303    Value Loss: 3.236    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 22831      Buffer Size: 22831      Transition Number: 373.882 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:37:46,471][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 4.261    Value Loss: 3.384    Reward Loss: 0.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 22966      Buffer Size: 22966      Transition Number: 384.187 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:42:29,196][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.189    [weighted Loss:1.189    Policy Loss: 4.385    Value Loss: 3.216    Reward Loss: 0.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 23183      Buffer Size: 23183      Transition Number: 400.269 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:47:05,891][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 4.737    Value Loss: 3.219    Reward Loss: 0.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 23378      Buffer Size: 23378      Transition Number: 414.470 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:51:50,141][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.180    [weighted Loss:1.180    Policy Loss: 4.901    Value Loss: 3.190    Reward Loss: 0.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 23562      Buffer Size: 23562      Transition Number: 427.507 k Batch Size: 256        Lr: 0.010   
[2021-11-30 09:56:35,902][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 5.151    Value Loss: 3.287    Reward Loss: 0.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 23739      Buffer Size: 23739      Transition Number: 440.236 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:01:14,444][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.728    [weighted Loss:1.728    Policy Loss: 5.036    Value Loss: 3.221    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 23939      Buffer Size: 23939      Transition Number: 454.301 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:05:59,761][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 4.986    Value Loss: 3.378    Reward Loss: 0.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 24131      Buffer Size: 24131      Transition Number: 467.921 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:10:57,740][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 4.718    Value Loss: 3.448    Reward Loss: 0.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 24312      Buffer Size: 24312      Transition Number: 480.985 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:15:36,226][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 4.775    Value Loss: 3.082    Reward Loss: 0.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 24546      Buffer Size: 24546      Transition Number: 498.247 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:20:19,236][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 4.833    Value Loss: 3.184    Reward Loss: 0.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 24798      Buffer Size: 24798      Transition Number: 517.675 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:25:02,795][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 5.265    Value Loss: 3.465    Reward Loss: 0.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 25048      Buffer Size: 25048      Transition Number: 536.497 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:29:46,687][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.787    [weighted Loss:1.787    Policy Loss: 4.733    Value Loss: 3.383    Reward Loss: 0.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 25335      Buffer Size: 25335      Transition Number: 558.521 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:34:24,929][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.326    [weighted Loss:1.326    Policy Loss: 4.552    Value Loss: 3.571    Reward Loss: 0.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 25598      Buffer Size: 25598      Transition Number: 578.734 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:39:15,024][train][INFO][train.py>_log] ==> #68000      Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 4.518    Value Loss: 3.437    Reward Loss: 0.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 25880      Buffer Size: 25880      Transition Number: 600.268 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:44:03,039][train][INFO][train.py>_log] ==> #70000      Total Loss: 0.882    [weighted Loss:0.882    Policy Loss: 4.400    Value Loss: 3.558    Reward Loss: 0.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 26151      Buffer Size: 26151      Transition Number: 620.982 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:48:49,418][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 4.572    Value Loss: 3.685    Reward Loss: 0.420    Consistency Loss: 0.000    ] Replay Episodes Collected: 26442      Buffer Size: 26442      Transition Number: 642.937 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:53:31,775][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 4.502    Value Loss: 3.548    Reward Loss: 0.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 26705      Buffer Size: 26705      Transition Number: 663.013 k Batch Size: 256        Lr: 0.010   
[2021-11-30 10:58:16,653][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.932    [weighted Loss:1.932    Policy Loss: 4.087    Value Loss: 3.558    Reward Loss: 0.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 26992      Buffer Size: 26992      Transition Number: 684.634 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:03:00,319][train][INFO][train.py>_log] ==> #78000      Total Loss: 0.986    [weighted Loss:0.986    Policy Loss: 4.219    Value Loss: 3.651    Reward Loss: 0.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 27286      Buffer Size: 27286      Transition Number: 706.980 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:07:53,194][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.844    [weighted Loss:1.844    Policy Loss: 4.128    Value Loss: 3.679    Reward Loss: 0.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 27615      Buffer Size: 27615      Transition Number: 731.599 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:12:38,357][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 4.280    Value Loss: 3.608    Reward Loss: 0.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 27917      Buffer Size: 27917      Transition Number: 754.011 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:17:26,683][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.943    [weighted Loss:1.943    Policy Loss: 4.075    Value Loss: 3.761    Reward Loss: 0.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 28240      Buffer Size: 28240      Transition Number: 778.612 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:22:13,327][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 3.903    Value Loss: 3.516    Reward Loss: 0.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 28574      Buffer Size: 28574      Transition Number: 803.759 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:27:02,697][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.095    [weighted Loss:1.095    Policy Loss: 4.139    Value Loss: 3.602    Reward Loss: 0.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 28853      Buffer Size: 28853      Transition Number: 825.064 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:31:52,808][train][INFO][train.py>_log] ==> #90000      Total Loss: 0.887    [weighted Loss:0.887    Policy Loss: 3.358    Value Loss: 3.582    Reward Loss: 0.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 29193      Buffer Size: 29193      Transition Number: 850.941 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:36:43,217][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 3.714    Value Loss: 3.547    Reward Loss: 0.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 29484      Buffer Size: 29484      Transition Number: 872.524 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:41:32,709][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 3.461    Value Loss: 3.695    Reward Loss: 0.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 29814      Buffer Size: 29814      Transition Number: 897.614 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:46:27,135][train][INFO][train.py>_log] ==> #96000      Total Loss: 0.490    [weighted Loss:0.490    Policy Loss: 3.579    Value Loss: 3.611    Reward Loss: 0.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 30139      Buffer Size: 30139      Transition Number: 921.948 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:51:24,537][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.104    [weighted Loss:1.104    Policy Loss: 3.811    Value Loss: 3.698    Reward Loss: 0.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 30440      Buffer Size: 30440      Transition Number: 944.462 k Batch Size: 256        Lr: 0.010   
[2021-11-30 11:56:23,986][train][INFO][train.py>_log] ==> #100000     Total Loss: 0.943    [weighted Loss:0.943    Policy Loss: 3.584    Value Loss: 3.662    Reward Loss: 0.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 30740      Buffer Size: 30740      Transition Number: 967.487 k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:01:24,360][train][INFO][train.py>_log] ==> #102000     Total Loss: 1.046    [weighted Loss:1.046    Policy Loss: 3.722    Value Loss: 3.698    Reward Loss: 0.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 31042      Buffer Size: 31042      Transition Number: 990.384 k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:06:33,707][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.150    [weighted Loss:1.150    Policy Loss: 3.380    Value Loss: 3.667    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 31343      Buffer Size: 30259      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:11:49,434][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 3.511    Value Loss: 3.768    Reward Loss: 0.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 31671      Buffer Size: 28476      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:17:05,625][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.510    [weighted Loss:1.510    Policy Loss: 3.581    Value Loss: 3.655    Reward Loss: 0.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 31969      Buffer Size: 25866      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:22:19,205][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.332    [weighted Loss:1.332    Policy Loss: 3.466    Value Loss: 3.796    Reward Loss: 0.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 32276      Buffer Size: 22463      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:27:38,710][train][INFO][train.py>_log] ==> #112000     Total Loss: 1.264    [weighted Loss:1.264    Policy Loss: 3.698    Value Loss: 3.675    Reward Loss: 0.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 32591      Buffer Size: 21091      Transition Number: 1000.070k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:32:56,727][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.317    [weighted Loss:1.317    Policy Loss: 3.577    Value Loss: 3.743    Reward Loss: 0.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 32878      Buffer Size: 19301      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:38:16,520][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.564    [weighted Loss:1.564    Policy Loss: 3.989    Value Loss: 3.622    Reward Loss: 0.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 33162      Buffer Size: 17501      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:43:43,986][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.503    [weighted Loss:1.503    Policy Loss: 3.829    Value Loss: 3.732    Reward Loss: 0.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 33477      Buffer Size: 15893      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:49:10,031][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.492    [weighted Loss:1.492    Policy Loss: 3.896    Value Loss: 3.946    Reward Loss: 0.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 33814      Buffer Size: 14752      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-11-30 12:54:38,766][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.083    [weighted Loss:1.083    Policy Loss: 4.274    Value Loss: 3.855    Reward Loss: 0.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 34152      Buffer Size: 14067      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:00:08,122][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 4.247    Value Loss: 3.691    Reward Loss: 0.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 34470      Buffer Size: 13582      Transition Number: 1000.117k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:05:36,122][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.098    [weighted Loss:1.098    Policy Loss: 4.068    Value Loss: 3.753    Reward Loss: 0.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 34782      Buffer Size: 13356      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:11:02,004][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 4.533    Value Loss: 3.828    Reward Loss: 0.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 35108      Buffer Size: 13311      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:16:28,209][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.113    [weighted Loss:1.113    Policy Loss: 4.476    Value Loss: 3.805    Reward Loss: 0.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 35430      Buffer Size: 13316      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:21:54,026][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 4.725    Value Loss: 3.876    Reward Loss: 0.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 35740      Buffer Size: 13319      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:27:24,661][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 4.583    Value Loss: 3.658    Reward Loss: 0.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 36089      Buffer Size: 13327      Transition Number: 999.982 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:32:53,938][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.258    [weighted Loss:1.258    Policy Loss: 5.131    Value Loss: 3.868    Reward Loss: 0.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 36419      Buffer Size: 13330      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:38:22,329][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 5.472    Value Loss: 3.937    Reward Loss: 0.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 36751      Buffer Size: 13327      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:43:54,219][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 5.295    Value Loss: 3.888    Reward Loss: 0.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 37080      Buffer Size: 13317      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:49:26,620][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 5.107    Value Loss: 3.833    Reward Loss: 0.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 37416      Buffer Size: 13299      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-30 13:54:55,049][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 5.201    Value Loss: 4.099    Reward Loss: 0.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 37732      Buffer Size: 13302      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:00:27,039][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 5.678    Value Loss: 4.097    Reward Loss: 0.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 38050      Buffer Size: 13315      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:06:00,182][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.848    [weighted Loss:2.848    Policy Loss: 5.847    Value Loss: 3.959    Reward Loss: 0.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 38329      Buffer Size: 13321      Transition Number: 999.921 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:11:33,479][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.185    [weighted Loss:2.185    Policy Loss: 5.621    Value Loss: 3.905    Reward Loss: 0.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 38613      Buffer Size: 13337      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:17:08,414][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 6.071    Value Loss: 3.830    Reward Loss: 0.336    Consistency Loss: 0.000    ] Replay Episodes Collected: 38898      Buffer Size: 13350      Transition Number: 999.922 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:22:40,887][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.637    [weighted Loss:1.637    Policy Loss: 6.094    Value Loss: 3.830    Reward Loss: 0.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 39232      Buffer Size: 13363      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:28:11,780][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 5.555    Value Loss: 4.027    Reward Loss: 0.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 39608      Buffer Size: 13389      Transition Number: 999.929 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:33:46,933][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 5.735    Value Loss: 4.021    Reward Loss: 0.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 39998      Buffer Size: 13420      Transition Number: 999.971 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:39:17,905][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 5.391    Value Loss: 3.993    Reward Loss: 0.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 40380      Buffer Size: 13460      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:44:48,563][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 5.163    Value Loss: 4.205    Reward Loss: 0.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 40767      Buffer Size: 13504      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:50:19,021][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 4.695    Value Loss: 4.139    Reward Loss: 0.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 41141      Buffer Size: 13529      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-11-30 14:55:51,734][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 4.675    Value Loss: 3.882    Reward Loss: 0.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 41526      Buffer Size: 13548      Transition Number: 999.978 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:01:20,404][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 4.862    Value Loss: 4.123    Reward Loss: 0.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 41903      Buffer Size: 13558      Transition Number: 999.930 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:06:56,588][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 4.476    Value Loss: 4.333    Reward Loss: 0.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 42298      Buffer Size: 13594      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:12:31,341][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 4.413    Value Loss: 4.011    Reward Loss: 0.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 42684      Buffer Size: 13624      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:18:05,802][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 4.567    Value Loss: 4.001    Reward Loss: 0.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 43070      Buffer Size: 13648      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:23:39,519][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.061    [weighted Loss:1.061    Policy Loss: 4.574    Value Loss: 4.046    Reward Loss: 0.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 43461      Buffer Size: 13684      Transition Number: 999.971 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:29:12,088][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.687    [weighted Loss:1.687    Policy Loss: 4.556    Value Loss: 4.193    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 43845      Buffer Size: 13715      Transition Number: 1000.010k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:34:44,233][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 4.687    Value Loss: 4.197    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 44234      Buffer Size: 13755      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:40:09,501][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.984    [weighted Loss:1.984    Policy Loss: 4.718    Value Loss: 4.279    Reward Loss: 0.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 44613      Buffer Size: 13787      Transition Number: 999.926 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:45:39,497][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 5.412    Value Loss: 4.247    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 45003      Buffer Size: 13833      Transition Number: 1000.118k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:51:15,095][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 4.699    Value Loss: 4.247    Reward Loss: 0.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 45396      Buffer Size: 13878      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-30 15:56:51,446][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.904    [weighted Loss:1.904    Policy Loss: 5.272    Value Loss: 4.098    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 45796      Buffer Size: 13933      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:02:25,602][train][INFO][train.py>_log] ==> #190000     Total Loss: 0.989    [weighted Loss:0.989    Policy Loss: 5.196    Value Loss: 4.427    Reward Loss: 0.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 46179      Buffer Size: 13984      Transition Number: 1000.073k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:08:02,677][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 5.149    Value Loss: 4.325    Reward Loss: 0.471    Consistency Loss: 0.000    ] Replay Episodes Collected: 46587      Buffer Size: 14039      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:13:36,250][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.914    [weighted Loss:1.914    Policy Loss: 5.667    Value Loss: 4.351    Reward Loss: 0.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 46974      Buffer Size: 14094      Transition Number: 999.982 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:19:07,568][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 4.722    Value Loss: 4.233    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 47367      Buffer Size: 14146      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:24:39,135][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 5.137    Value Loss: 4.142    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 47759      Buffer Size: 14188      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:30:11,742][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 5.394    Value Loss: 4.205    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 48156      Buffer Size: 14236      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:35:45,534][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 5.127    Value Loss: 4.319    Reward Loss: 0.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 48554      Buffer Size: 14282      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:41:22,492][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 5.197    Value Loss: 4.217    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 48939      Buffer Size: 14330      Transition Number: 999.969 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:46:57,187][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 5.085    Value Loss: 4.259    Reward Loss: 0.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 49339      Buffer Size: 14378      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:52:27,480][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 5.330    Value Loss: 4.204    Reward Loss: 0.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 49731      Buffer Size: 14432      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-11-30 16:57:56,359][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.180    [weighted Loss:2.180    Policy Loss: 5.159    Value Loss: 4.078    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 50120      Buffer Size: 14475      Transition Number: 999.985 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:03:26,787][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 5.808    Value Loss: 4.563    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 50515      Buffer Size: 14528      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:08:58,099][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.157    [weighted Loss:1.157    Policy Loss: 5.616    Value Loss: 4.580    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 50898      Buffer Size: 14577      Transition Number: 1000.003k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:14:28,511][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 5.773    Value Loss: 4.600    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 51279      Buffer Size: 14612      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:20:00,414][train][INFO][train.py>_log] ==> #218000     Total Loss: 0.906    [weighted Loss:0.906    Policy Loss: 5.230    Value Loss: 4.350    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 51666      Buffer Size: 14650      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:25:34,798][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.268    [weighted Loss:1.268    Policy Loss: 5.525    Value Loss: 4.501    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 52063      Buffer Size: 14698      Transition Number: 1000.125k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:31:08,785][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.721    [weighted Loss:1.721    Policy Loss: 5.412    Value Loss: 4.344    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 52446      Buffer Size: 14735      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:36:40,781][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 5.582    Value Loss: 4.385    Reward Loss: 0.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 52838      Buffer Size: 14765      Transition Number: 999.937 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:42:12,090][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 5.453    Value Loss: 4.387    Reward Loss: 0.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 53237      Buffer Size: 14818      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:47:42,434][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 5.429    Value Loss: 4.372    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 53625      Buffer Size: 14858      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:53:19,010][train][INFO][train.py>_log] ==> #230000     Total Loss: 1.454    [weighted Loss:1.454    Policy Loss: 5.322    Value Loss: 4.511    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 54017      Buffer Size: 14902      Transition Number: 999.930 k Batch Size: 256        Lr: 0.010   
[2021-11-30 17:58:50,085][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.447    [weighted Loss:1.447    Policy Loss: 5.520    Value Loss: 4.488    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 54411      Buffer Size: 14934      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:04:21,497][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 5.721    Value Loss: 4.455    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 54803      Buffer Size: 14965      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:09:53,716][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 5.668    Value Loss: 4.734    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 55196      Buffer Size: 14983      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:15:27,035][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 5.595    Value Loss: 4.895    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 55603      Buffer Size: 14990      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:20:59,574][train][INFO][train.py>_log] ==> #240000     Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 5.793    Value Loss: 4.637    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 55997      Buffer Size: 14994      Transition Number: 999.948 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:26:33,288][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 5.614    Value Loss: 4.545    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 56394      Buffer Size: 15013      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:32:03,352][train][INFO][train.py>_log] ==> #244000     Total Loss: 1.744    [weighted Loss:1.744    Policy Loss: 4.701    Value Loss: 4.693    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 56779      Buffer Size: 15036      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:37:34,077][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 5.234    Value Loss: 4.830    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 57173      Buffer Size: 15048      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:43:08,199][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 5.083    Value Loss: 4.598    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 57566      Buffer Size: 15062      Transition Number: 1000.056k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:48:41,782][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 5.137    Value Loss: 4.520    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 57959      Buffer Size: 15077      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:54:15,305][train][INFO][train.py>_log] ==> #252000     Total Loss: 0.916    [weighted Loss:0.916    Policy Loss: 5.297    Value Loss: 4.505    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 58350      Buffer Size: 15083      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-30 18:59:52,105][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 5.024    Value Loss: 4.714    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 58757      Buffer Size: 15085      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:05:19,536][train][INFO][train.py>_log] ==> #256000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 5.331    Value Loss: 4.972    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 59150      Buffer Size: 15085      Transition Number: 999.980 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:10:52,226][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 5.045    Value Loss: 4.561    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 59544      Buffer Size: 15076      Transition Number: 999.942 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:16:27,409][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 5.701    Value Loss: 4.624    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 59928      Buffer Size: 15075      Transition Number: 999.951 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:21:55,282][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 5.198    Value Loss: 5.351    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 60325      Buffer Size: 15060      Transition Number: 999.978 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:27:29,951][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.640    [weighted Loss:1.640    Policy Loss: 4.988    Value Loss: 4.210    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 60738      Buffer Size: 15045      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:33:00,885][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.922    [weighted Loss:1.922    Policy Loss: 5.244    Value Loss: 4.594    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 61148      Buffer Size: 15032      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:38:34,510][train][INFO][train.py>_log] ==> #268000     Total Loss: 1.441    [weighted Loss:1.441    Policy Loss: 5.359    Value Loss: 4.451    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 61561      Buffer Size: 15005      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:44:05,317][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 5.026    Value Loss: 4.647    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 61961      Buffer Size: 14978      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:49:39,626][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 5.054    Value Loss: 4.617    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 62367      Buffer Size: 14955      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-11-30 19:55:15,773][train][INFO][train.py>_log] ==> #274000     Total Loss: 1.851    [weighted Loss:1.851    Policy Loss: 5.375    Value Loss: 4.592    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 62775      Buffer Size: 14939      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:00:53,141][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 5.362    Value Loss: 4.348    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 63186      Buffer Size: 14915      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:06:34,180][train][INFO][train.py>_log] ==> #278000     Total Loss: 1.496    [weighted Loss:1.496    Policy Loss: 5.185    Value Loss: 4.365    Reward Loss: 0.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 63602      Buffer Size: 14895      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:12:10,835][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 5.215    Value Loss: 4.453    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 64012      Buffer Size: 14870      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:17:46,530][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.805    [weighted Loss:2.805    Policy Loss: 5.139    Value Loss: 4.685    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 64421      Buffer Size: 14853      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:23:24,450][train][INFO][train.py>_log] ==> #284000     Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 4.709    Value Loss: 4.519    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 64839      Buffer Size: 14831      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:28:59,381][train][INFO][train.py>_log] ==> #286000     Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 5.446    Value Loss: 4.275    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 65251      Buffer Size: 14800      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:34:32,154][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.619    [weighted Loss:1.619    Policy Loss: 4.916    Value Loss: 4.296    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 65646      Buffer Size: 14774      Transition Number: 999.982 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:40:08,002][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 5.092    Value Loss: 4.356    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 66069      Buffer Size: 14787      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:45:45,053][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.530    [weighted Loss:1.530    Policy Loss: 5.166    Value Loss: 4.601    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 66484      Buffer Size: 14787      Transition Number: 999.933 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:51:18,290][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.776    [weighted Loss:1.776    Policy Loss: 5.468    Value Loss: 4.387    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 66891      Buffer Size: 14775      Transition Number: 999.978 k Batch Size: 256        Lr: 0.010   
[2021-11-30 20:56:53,844][train][INFO][train.py>_log] ==> #296000     Total Loss: 1.321    [weighted Loss:1.321    Policy Loss: 4.583    Value Loss: 4.339    Reward Loss: 0.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 67315      Buffer Size: 14748      Transition Number: 999.983 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:02:29,533][train][INFO][train.py>_log] ==> #298000     Total Loss: 1.074    [weighted Loss:1.074    Policy Loss: 4.943    Value Loss: 4.518    Reward Loss: 0.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 67719      Buffer Size: 14721      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:08:04,546][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.508    [weighted Loss:2.508    Policy Loss: 5.072    Value Loss: 4.376    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 68131      Buffer Size: 14688      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:13:41,205][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 5.099    Value Loss: 4.246    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 68562      Buffer Size: 14667      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:19:13,355][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.084    [weighted Loss:1.084    Policy Loss: 5.205    Value Loss: 4.334    Reward Loss: 0.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 68975      Buffer Size: 14642      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:24:51,682][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 4.727    Value Loss: 4.312    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 69386      Buffer Size: 14628      Transition Number: 999.937 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:30:29,066][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.398    [weighted Loss:1.398    Policy Loss: 4.491    Value Loss: 4.473    Reward Loss: 0.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 69826      Buffer Size: 14608      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:36:03,071][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 5.016    Value Loss: 4.279    Reward Loss: 0.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 70229      Buffer Size: 14591      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:41:39,656][train][INFO][train.py>_log] ==> #312000     Total Loss: 1.047    [weighted Loss:1.047    Policy Loss: 4.650    Value Loss: 4.337    Reward Loss: 0.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 70650      Buffer Size: 14582      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:47:11,374][train][INFO][train.py>_log] ==> #314000     Total Loss: 0.646    [weighted Loss:0.646    Policy Loss: 4.440    Value Loss: 4.335    Reward Loss: 0.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 71068      Buffer Size: 14569      Transition Number: 1000.021k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:52:49,208][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.548    [weighted Loss:1.548    Policy Loss: 4.543    Value Loss: 4.462    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 71489      Buffer Size: 14553      Transition Number: 999.947 k Batch Size: 256        Lr: 0.010   
[2021-11-30 21:58:27,773][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 4.902    Value Loss: 4.184    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 71907      Buffer Size: 14551      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:04:03,140][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 5.196    Value Loss: 4.432    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 72333      Buffer Size: 14535      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:09:36,990][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 4.385    Value Loss: 4.576    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 72743      Buffer Size: 14538      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:15:18,510][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.569    [weighted Loss:1.569    Policy Loss: 4.368    Value Loss: 4.552    Reward Loss: 0.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 73179      Buffer Size: 14538      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:20:57,456][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.360    [weighted Loss:1.360    Policy Loss: 4.450    Value Loss: 4.409    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 73606      Buffer Size: 14526      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:26:31,491][train][INFO][train.py>_log] ==> #328000     Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 4.317    Value Loss: 4.494    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 74034      Buffer Size: 14525      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:32:04,518][train][INFO][train.py>_log] ==> #330000     Total Loss: 1.636    [weighted Loss:1.636    Policy Loss: 4.736    Value Loss: 4.461    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 74451      Buffer Size: 14526      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:37:42,209][train][INFO][train.py>_log] ==> #332000     Total Loss: 1.480    [weighted Loss:1.480    Policy Loss: 4.349    Value Loss: 4.296    Reward Loss: 0.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 74889      Buffer Size: 14514      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:43:22,104][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 4.466    Value Loss: 4.405    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 75319      Buffer Size: 14506      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:49:00,476][train][INFO][train.py>_log] ==> #336000     Total Loss: 0.850    [weighted Loss:0.850    Policy Loss: 4.128    Value Loss: 4.316    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 75751      Buffer Size: 14499      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-30 22:54:40,904][train][INFO][train.py>_log] ==> #338000     Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 3.965    Value Loss: 4.332    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 76172      Buffer Size: 14492      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:00:16,168][train][INFO][train.py>_log] ==> #340000     Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 3.938    Value Loss: 4.503    Reward Loss: 0.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 76622      Buffer Size: 14482      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:05:53,177][train][INFO][train.py>_log] ==> #342000     Total Loss: 0.865    [weighted Loss:0.865    Policy Loss: 4.273    Value Loss: 4.516    Reward Loss: 0.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 77039      Buffer Size: 14470      Transition Number: 1000.057k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:11:34,151][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 4.672    Value Loss: 4.466    Reward Loss: 0.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 77487      Buffer Size: 14454      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:17:12,657][train][INFO][train.py>_log] ==> #346000     Total Loss: 0.889    [weighted Loss:0.889    Policy Loss: 4.106    Value Loss: 4.253    Reward Loss: 0.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 77912      Buffer Size: 14430      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:22:52,446][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.285    [weighted Loss:1.285    Policy Loss: 3.814    Value Loss: 4.741    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 78356      Buffer Size: 14408      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:28:27,966][train][INFO][train.py>_log] ==> #350000     Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 4.551    Value Loss: 4.434    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 78788      Buffer Size: 14375      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:34:08,921][train][INFO][train.py>_log] ==> #352000     Total Loss: 1.587    [weighted Loss:1.587    Policy Loss: 4.244    Value Loss: 4.590    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 79240      Buffer Size: 14353      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:39:44,776][train][INFO][train.py>_log] ==> #354000     Total Loss: 0.942    [weighted Loss:0.942    Policy Loss: 4.080    Value Loss: 4.488    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 79658      Buffer Size: 14339      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:45:24,214][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.110    [weighted Loss:1.110    Policy Loss: 3.861    Value Loss: 4.728    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 80111      Buffer Size: 14314      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:51:02,463][train][INFO][train.py>_log] ==> #358000     Total Loss: 1.570    [weighted Loss:1.570    Policy Loss: 4.208    Value Loss: 4.566    Reward Loss: 0.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 80531      Buffer Size: 14275      Transition Number: 1000.038k Batch Size: 256        Lr: 0.010   
[2021-11-30 23:56:43,730][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 4.028    Value Loss: 4.254    Reward Loss: 0.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 80981      Buffer Size: 14235      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:02:29,582][train][INFO][train.py>_log] ==> #362000     Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 4.062    Value Loss: 4.410    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 81428      Buffer Size: 14218      Transition Number: 999.930 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:08:10,813][train][INFO][train.py>_log] ==> #364000     Total Loss: 1.071    [weighted Loss:1.071    Policy Loss: 4.014    Value Loss: 4.609    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 81858      Buffer Size: 14206      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:13:51,198][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.261    [weighted Loss:1.261    Policy Loss: 3.766    Value Loss: 4.324    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 82320      Buffer Size: 14182      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:19:33,413][train][INFO][train.py>_log] ==> #368000     Total Loss: 1.175    [weighted Loss:1.175    Policy Loss: 3.915    Value Loss: 4.314    Reward Loss: 0.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 82728      Buffer Size: 14154      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:25:17,528][train][INFO][train.py>_log] ==> #370000     Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 4.053    Value Loss: 4.673    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 83182      Buffer Size: 14127      Transition Number: 999.942 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:31:02,866][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.087    [weighted Loss:1.087    Policy Loss: 3.753    Value Loss: 4.683    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 83639      Buffer Size: 14088      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:36:44,300][train][INFO][train.py>_log] ==> #374000     Total Loss: 1.357    [weighted Loss:1.357    Policy Loss: 4.429    Value Loss: 4.641    Reward Loss: 0.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 84076      Buffer Size: 14050      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:42:27,791][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.252    [weighted Loss:1.252    Policy Loss: 3.874    Value Loss: 4.634    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 84534      Buffer Size: 14020      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:48:11,218][train][INFO][train.py>_log] ==> #378000     Total Loss: 1.174    [weighted Loss:1.174    Policy Loss: 4.348    Value Loss: 4.558    Reward Loss: 0.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 84963      Buffer Size: 13990      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:53:50,790][train][INFO][train.py>_log] ==> #380000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 4.309    Value Loss: 4.135    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 85412      Buffer Size: 13970      Transition Number: 1000.006k Batch Size: 256        Lr: 0.010   
[2021-12-01 00:59:34,783][train][INFO][train.py>_log] ==> #382000     Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 4.209    Value Loss: 4.564    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 85860      Buffer Size: 13938      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:05:17,075][train][INFO][train.py>_log] ==> #384000     Total Loss: 0.494    [weighted Loss:0.494    Policy Loss: 4.315    Value Loss: 4.160    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 86292      Buffer Size: 13924      Transition Number: 999.948 k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:10:56,806][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 4.337    Value Loss: 4.465    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 86752      Buffer Size: 13912      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:16:35,215][train][INFO][train.py>_log] ==> #388000     Total Loss: 0.799    [weighted Loss:0.799    Policy Loss: 3.855    Value Loss: 4.490    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 87202      Buffer Size: 13891      Transition Number: 1000.059k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:22:16,839][train][INFO][train.py>_log] ==> #390000     Total Loss: 0.530    [weighted Loss:0.530    Policy Loss: 3.942    Value Loss: 4.523    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 87627      Buffer Size: 13867      Transition Number: 1000.017k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:27:57,667][train][INFO][train.py>_log] ==> #392000     Total Loss: 0.991    [weighted Loss:0.991    Policy Loss: 3.786    Value Loss: 4.184    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 88082      Buffer Size: 13836      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:33:40,485][train][INFO][train.py>_log] ==> #394000     Total Loss: 1.401    [weighted Loss:1.401    Policy Loss: 3.852    Value Loss: 4.182    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 88539      Buffer Size: 13809      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:39:22,870][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 4.134    Value Loss: 4.502    Reward Loss: 0.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 88973      Buffer Size: 13784      Transition Number: 999.930 k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:45:06,009][train][INFO][train.py>_log] ==> #398000     Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 4.124    Value Loss: 4.570    Reward Loss: 0.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 89419      Buffer Size: 13750      Transition Number: 999.974 k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:50:49,838][train][INFO][train.py>_log] ==> #400000     Total Loss: 0.673    [weighted Loss:0.673    Policy Loss: 4.106    Value Loss: 4.622    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 89874      Buffer Size: 13727      Transition Number: 999.937 k Batch Size: 256        Lr: 0.010   
[2021-12-01 01:56:36,155][train][INFO][train.py>_log] ==> #402000     Total Loss: 0.845    [weighted Loss:0.845    Policy Loss: 3.980    Value Loss: 4.570    Reward Loss: 0.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 90337      Buffer Size: 13709      Transition Number: 999.978 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:02:20,264][train][INFO][train.py>_log] ==> #404000     Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 4.245    Value Loss: 4.388    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 90793      Buffer Size: 13693      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:08:07,173][train][INFO][train.py>_log] ==> #406000     Total Loss: 1.030    [weighted Loss:1.030    Policy Loss: 4.354    Value Loss: 4.506    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 91244      Buffer Size: 13676      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:13:54,936][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.087    [weighted Loss:1.087    Policy Loss: 4.022    Value Loss: 4.525    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 91684      Buffer Size: 13666      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:19:43,011][train][INFO][train.py>_log] ==> #410000     Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 3.900    Value Loss: 4.399    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 92136      Buffer Size: 13651      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:25:28,987][train][INFO][train.py>_log] ==> #412000     Total Loss: 0.714    [weighted Loss:0.714    Policy Loss: 3.757    Value Loss: 4.479    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 92573      Buffer Size: 13643      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:31:17,305][train][INFO][train.py>_log] ==> #414000     Total Loss: 0.992    [weighted Loss:0.992    Policy Loss: 3.883    Value Loss: 4.258    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 93014      Buffer Size: 13633      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:37:01,467][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.065    [weighted Loss:1.065    Policy Loss: 3.832    Value Loss: 4.284    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 93467      Buffer Size: 13617      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:42:45,964][train][INFO][train.py>_log] ==> #418000     Total Loss: 1.217    [weighted Loss:1.217    Policy Loss: 3.795    Value Loss: 4.115    Reward Loss: 0.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 93876      Buffer Size: 13600      Transition Number: 999.947 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:48:26,568][train][INFO][train.py>_log] ==> #420000     Total Loss: 0.570    [weighted Loss:0.570    Policy Loss: 3.400    Value Loss: 4.257    Reward Loss: 0.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 94318      Buffer Size: 13580      Transition Number: 999.968 k Batch Size: 256        Lr: 0.010   
[2021-12-01 02:54:13,747][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.123    [weighted Loss:1.123    Policy Loss: 3.787    Value Loss: 4.286    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 94758      Buffer Size: 13556      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:00:02,887][train][INFO][train.py>_log] ==> #424000     Total Loss: 1.203    [weighted Loss:1.203    Policy Loss: 3.560    Value Loss: 4.130    Reward Loss: 0.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 95219      Buffer Size: 13539      Transition Number: 999.968 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:05:49,546][train][INFO][train.py>_log] ==> #426000     Total Loss: 0.871    [weighted Loss:0.871    Policy Loss: 3.724    Value Loss: 4.263    Reward Loss: 0.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 95662      Buffer Size: 13528      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:11:32,080][train][INFO][train.py>_log] ==> #428000     Total Loss: 0.801    [weighted Loss:0.801    Policy Loss: 3.477    Value Loss: 4.590    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 96069      Buffer Size: 13515      Transition Number: 999.964 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:17:22,241][train][INFO][train.py>_log] ==> #430000     Total Loss: 1.398    [weighted Loss:1.398    Policy Loss: 3.610    Value Loss: 4.185    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 96513      Buffer Size: 13510      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:23:03,741][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 3.710    Value Loss: 4.581    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 96944      Buffer Size: 13507      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:28:52,289][train][INFO][train.py>_log] ==> #434000     Total Loss: 0.831    [weighted Loss:0.831    Policy Loss: 3.535    Value Loss: 4.218    Reward Loss: 0.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 97387      Buffer Size: 13496      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:34:35,939][train][INFO][train.py>_log] ==> #436000     Total Loss: 1.100    [weighted Loss:1.100    Policy Loss: 3.815    Value Loss: 4.252    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 97816      Buffer Size: 13485      Transition Number: 999.974 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:40:17,027][train][INFO][train.py>_log] ==> #438000     Total Loss: 1.079    [weighted Loss:1.079    Policy Loss: 3.154    Value Loss: 4.376    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 98259      Buffer Size: 13477      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:46:00,499][train][INFO][train.py>_log] ==> #440000     Total Loss: 1.318    [weighted Loss:1.318    Policy Loss: 3.528    Value Loss: 4.391    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 98687      Buffer Size: 13464      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:51:43,541][train][INFO][train.py>_log] ==> #442000     Total Loss: 0.525    [weighted Loss:0.525    Policy Loss: 3.434    Value Loss: 4.210    Reward Loss: 0.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 99134      Buffer Size: 13446      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-12-01 03:57:25,229][train][INFO][train.py>_log] ==> #444000     Total Loss: 1.616    [weighted Loss:1.616    Policy Loss: 3.518    Value Loss: 4.089    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 99572      Buffer Size: 13421      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:03:06,898][train][INFO][train.py>_log] ==> #446000     Total Loss: 1.047    [weighted Loss:1.047    Policy Loss: 3.150    Value Loss: 4.248    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 99988      Buffer Size: 13394      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:08:48,548][train][INFO][train.py>_log] ==> #448000     Total Loss: 0.944    [weighted Loss:0.944    Policy Loss: 3.386    Value Loss: 4.404    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 100407     Buffer Size: 13369      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:14:35,658][train][INFO][train.py>_log] ==> #450000     Total Loss: 0.951    [weighted Loss:0.951    Policy Loss: 3.214    Value Loss: 3.956    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 100868     Buffer Size: 13350      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:20:15,306][train][INFO][train.py>_log] ==> #452000     Total Loss: 0.809    [weighted Loss:0.809    Policy Loss: 3.244    Value Loss: 4.134    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 101316     Buffer Size: 13343      Transition Number: 1000.154k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:26:02,402][train][INFO][train.py>_log] ==> #454000     Total Loss: 0.976    [weighted Loss:0.976    Policy Loss: 3.548    Value Loss: 4.409    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 101734     Buffer Size: 13319      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:31:43,063][train][INFO][train.py>_log] ==> #456000     Total Loss: 0.818    [weighted Loss:0.818    Policy Loss: 3.282    Value Loss: 4.157    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 102155     Buffer Size: 13304      Transition Number: 1000.023k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:37:27,724][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 3.842    Value Loss: 4.129    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 102552     Buffer Size: 13295      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:43:12,073][train][INFO][train.py>_log] ==> #460000     Total Loss: 0.935    [weighted Loss:0.935    Policy Loss: 3.594    Value Loss: 4.759    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 102975     Buffer Size: 13280      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:48:59,022][train][INFO][train.py>_log] ==> #462000     Total Loss: 0.561    [weighted Loss:0.561    Policy Loss: 3.879    Value Loss: 4.334    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 103426     Buffer Size: 13266      Transition Number: 999.925 k Batch Size: 256        Lr: 0.010   
[2021-12-01 04:54:47,210][train][INFO][train.py>_log] ==> #464000     Total Loss: 0.615    [weighted Loss:0.615    Policy Loss: 3.749    Value Loss: 4.247    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 103867     Buffer Size: 13250      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:00:36,348][train][INFO][train.py>_log] ==> #466000     Total Loss: 0.641    [weighted Loss:0.641    Policy Loss: 3.485    Value Loss: 4.097    Reward Loss: 0.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 104292     Buffer Size: 13227      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:06:25,868][train][INFO][train.py>_log] ==> #468000     Total Loss: 1.177    [weighted Loss:1.177    Policy Loss: 3.514    Value Loss: 4.168    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 104703     Buffer Size: 13204      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:12:12,392][train][INFO][train.py>_log] ==> #470000     Total Loss: 0.815    [weighted Loss:0.815    Policy Loss: 3.720    Value Loss: 4.043    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 105117     Buffer Size: 13187      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:17:57,225][train][INFO][train.py>_log] ==> #472000     Total Loss: 0.759    [weighted Loss:0.759    Policy Loss: 3.500    Value Loss: 4.393    Reward Loss: 0.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 105534     Buffer Size: 13172      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:23:43,501][train][INFO][train.py>_log] ==> #474000     Total Loss: 0.989    [weighted Loss:0.989    Policy Loss: 3.735    Value Loss: 4.533    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 105956     Buffer Size: 13154      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:29:29,520][train][INFO][train.py>_log] ==> #476000     Total Loss: 0.753    [weighted Loss:0.753    Policy Loss: 3.472    Value Loss: 4.205    Reward Loss: 0.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 106377     Buffer Size: 13150      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:35:14,977][train][INFO][train.py>_log] ==> #478000     Total Loss: 0.710    [weighted Loss:0.710    Policy Loss: 3.839    Value Loss: 4.045    Reward Loss: 0.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 106792     Buffer Size: 13157      Transition Number: 999.922 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:41:04,372][train][INFO][train.py>_log] ==> #480000     Total Loss: 0.936    [weighted Loss:0.936    Policy Loss: 3.472    Value Loss: 4.064    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 107217     Buffer Size: 13156      Transition Number: 999.946 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:46:49,430][train][INFO][train.py>_log] ==> #482000     Total Loss: 1.188    [weighted Loss:1.188    Policy Loss: 3.708    Value Loss: 4.309    Reward Loss: 0.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 107638     Buffer Size: 13149      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:52:34,740][train][INFO][train.py>_log] ==> #484000     Total Loss: 1.068    [weighted Loss:1.068    Policy Loss: 3.591    Value Loss: 3.998    Reward Loss: 0.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 108076     Buffer Size: 13137      Transition Number: 999.933 k Batch Size: 256        Lr: 0.010   
[2021-12-01 05:58:18,761][train][INFO][train.py>_log] ==> #486000     Total Loss: 1.198    [weighted Loss:1.198    Policy Loss: 3.616    Value Loss: 3.941    Reward Loss: 0.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 108506     Buffer Size: 13126      Transition Number: 999.930 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:03:59,167][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.046    [weighted Loss:1.046    Policy Loss: 3.892    Value Loss: 4.413    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 108920     Buffer Size: 13118      Transition Number: 999.947 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:09:46,008][train][INFO][train.py>_log] ==> #490000     Total Loss: 1.009    [weighted Loss:1.009    Policy Loss: 3.875    Value Loss: 4.467    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 109350     Buffer Size: 13119      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:15:24,871][train][INFO][train.py>_log] ==> #492000     Total Loss: 1.409    [weighted Loss:1.409    Policy Loss: 3.717    Value Loss: 4.276    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 109780     Buffer Size: 13105      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:21:06,837][train][INFO][train.py>_log] ==> #494000     Total Loss: 0.602    [weighted Loss:0.602    Policy Loss: 4.415    Value Loss: 4.419    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 110206     Buffer Size: 13098      Transition Number: 1000.143k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:26:53,736][train][INFO][train.py>_log] ==> #496000     Total Loss: 0.862    [weighted Loss:0.862    Policy Loss: 3.876    Value Loss: 4.529    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 110646     Buffer Size: 13094      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:32:39,736][train][INFO][train.py>_log] ==> #498000     Total Loss: 1.393    [weighted Loss:1.393    Policy Loss: 3.950    Value Loss: 4.325    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 111097     Buffer Size: 13092      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:38:26,452][train][INFO][train.py>_log] ==> #500000     Total Loss: 0.545    [weighted Loss:0.545    Policy Loss: 3.529    Value Loss: 4.710    Reward Loss: 0.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 111528     Buffer Size: 13089      Transition Number: 999.933 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:44:12,695][train][INFO][train.py>_log] ==> #502000     Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 3.519    Value Loss: 4.224    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 111962     Buffer Size: 13089      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:50:02,283][train][INFO][train.py>_log] ==> #504000     Total Loss: 0.547    [weighted Loss:0.547    Policy Loss: 4.153    Value Loss: 4.310    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 112410     Buffer Size: 13088      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-12-01 06:55:50,222][train][INFO][train.py>_log] ==> #506000     Total Loss: 0.747    [weighted Loss:0.747    Policy Loss: 3.864    Value Loss: 4.352    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 112851     Buffer Size: 13094      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:01:39,564][train][INFO][train.py>_log] ==> #508000     Total Loss: 0.805    [weighted Loss:0.805    Policy Loss: 3.711    Value Loss: 4.191    Reward Loss: 0.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 113308     Buffer Size: 13091      Transition Number: 999.986 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:07:26,107][train][INFO][train.py>_log] ==> #510000     Total Loss: 0.582    [weighted Loss:0.582    Policy Loss: 3.471    Value Loss: 4.091    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 113747     Buffer Size: 13086      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:13:09,888][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 3.580    Value Loss: 4.306    Reward Loss: 0.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 114177     Buffer Size: 13082      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:18:54,843][train][INFO][train.py>_log] ==> #514000     Total Loss: 0.595    [weighted Loss:0.595    Policy Loss: 3.517    Value Loss: 4.264    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 114623     Buffer Size: 13081      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:24:43,359][train][INFO][train.py>_log] ==> #516000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.553    Value Loss: 4.374    Reward Loss: 0.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 115082     Buffer Size: 13088      Transition Number: 999.921 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:30:27,556][train][INFO][train.py>_log] ==> #518000     Total Loss: 0.788    [weighted Loss:0.788    Policy Loss: 3.508    Value Loss: 4.048    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 115523     Buffer Size: 13094      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:36:12,810][train][INFO][train.py>_log] ==> #520000     Total Loss: 0.999    [weighted Loss:0.999    Policy Loss: 3.636    Value Loss: 4.259    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 115955     Buffer Size: 13095      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:41:57,503][train][INFO][train.py>_log] ==> #522000     Total Loss: 1.335    [weighted Loss:1.335    Policy Loss: 3.861    Value Loss: 4.086    Reward Loss: 0.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 116402     Buffer Size: 13093      Transition Number: 999.922 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:47:47,079][train][INFO][train.py>_log] ==> #524000     Total Loss: 0.740    [weighted Loss:0.740    Policy Loss: 3.818    Value Loss: 4.204    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 116847     Buffer Size: 13096      Transition Number: 999.942 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:53:30,723][train][INFO][train.py>_log] ==> #526000     Total Loss: 0.832    [weighted Loss:0.832    Policy Loss: 3.798    Value Loss: 4.448    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 117284     Buffer Size: 13106      Transition Number: 999.950 k Batch Size: 256        Lr: 0.010   
[2021-12-01 07:59:18,048][train][INFO][train.py>_log] ==> #528000     Total Loss: 1.348    [weighted Loss:1.348    Policy Loss: 3.858    Value Loss: 4.300    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 117727     Buffer Size: 13118      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:05:08,280][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.073    [weighted Loss:1.073    Policy Loss: 3.858    Value Loss: 4.390    Reward Loss: 0.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 118185     Buffer Size: 13130      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:11:01,613][train][INFO][train.py>_log] ==> #532000     Total Loss: 0.768    [weighted Loss:0.768    Policy Loss: 3.999    Value Loss: 4.341    Reward Loss: 0.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 118633     Buffer Size: 13146      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:16:50,506][train][INFO][train.py>_log] ==> #534000     Total Loss: 0.446    [weighted Loss:0.446    Policy Loss: 3.918    Value Loss: 4.218    Reward Loss: 0.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 119083     Buffer Size: 13154      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:22:40,254][train][INFO][train.py>_log] ==> #536000     Total Loss: 0.770    [weighted Loss:0.770    Policy Loss: 3.585    Value Loss: 4.262    Reward Loss: 0.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 119530     Buffer Size: 13152      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:28:31,618][train][INFO][train.py>_log] ==> #538000     Total Loss: 0.612    [weighted Loss:0.612    Policy Loss: 3.796    Value Loss: 4.318    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 119994     Buffer Size: 13141      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:34:21,145][train][INFO][train.py>_log] ==> #540000     Total Loss: 1.183    [weighted Loss:1.183    Policy Loss: 3.857    Value Loss: 4.772    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 120456     Buffer Size: 13145      Transition Number: 999.942 k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:40:11,589][train][INFO][train.py>_log] ==> #542000     Total Loss: 1.340    [weighted Loss:1.340    Policy Loss: 3.758    Value Loss: 4.562    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 120913     Buffer Size: 13161      Transition Number: 1000.054k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:46:00,960][train][INFO][train.py>_log] ==> #544000     Total Loss: 0.619    [weighted Loss:0.619    Policy Loss: 3.693    Value Loss: 4.272    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 121364     Buffer Size: 13175      Transition Number: 999.985 k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:51:51,776][train][INFO][train.py>_log] ==> #546000     Total Loss: 0.540    [weighted Loss:0.540    Policy Loss: 3.494    Value Loss: 4.125    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 121828     Buffer Size: 13182      Transition Number: 1000.011k Batch Size: 256        Lr: 0.010   
[2021-12-01 08:57:47,333][train][INFO][train.py>_log] ==> #548000     Total Loss: 1.490    [weighted Loss:1.490    Policy Loss: 3.795    Value Loss: 4.379    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 122286     Buffer Size: 13186      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:03:35,253][train][INFO][train.py>_log] ==> #550000     Total Loss: 1.373    [weighted Loss:1.373    Policy Loss: 4.051    Value Loss: 4.074    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 122749     Buffer Size: 13194      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:09:24,167][train][INFO][train.py>_log] ==> #552000     Total Loss: 1.285    [weighted Loss:1.285    Policy Loss: 3.618    Value Loss: 4.189    Reward Loss: 0.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 123194     Buffer Size: 13208      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:15:11,658][train][INFO][train.py>_log] ==> #554000     Total Loss: 0.780    [weighted Loss:0.780    Policy Loss: 3.795    Value Loss: 4.030    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 123665     Buffer Size: 13223      Transition Number: 1000.062k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:20:58,616][train][INFO][train.py>_log] ==> #556000     Total Loss: 0.827    [weighted Loss:0.827    Policy Loss: 3.666    Value Loss: 4.143    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 124126     Buffer Size: 13243      Transition Number: 999.978 k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:26:45,700][train][INFO][train.py>_log] ==> #558000     Total Loss: 0.687    [weighted Loss:0.687    Policy Loss: 3.613    Value Loss: 3.984    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 124584     Buffer Size: 13268      Transition Number: 1000.013k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:32:31,676][train][INFO][train.py>_log] ==> #560000     Total Loss: 0.871    [weighted Loss:0.871    Policy Loss: 3.566    Value Loss: 4.183    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 125026     Buffer Size: 13287      Transition Number: 999.949 k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:38:17,098][train][INFO][train.py>_log] ==> #562000     Total Loss: 0.460    [weighted Loss:0.460    Policy Loss: 3.930    Value Loss: 4.292    Reward Loss: 0.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 125490     Buffer Size: 13302      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:44:02,150][train][INFO][train.py>_log] ==> #564000     Total Loss: 0.717    [weighted Loss:0.717    Policy Loss: 3.415    Value Loss: 4.198    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 125961     Buffer Size: 13331      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:49:50,047][train][INFO][train.py>_log] ==> #566000     Total Loss: 0.682    [weighted Loss:0.682    Policy Loss: 3.683    Value Loss: 4.172    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 126417     Buffer Size: 13354      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-12-01 09:55:34,408][train][INFO][train.py>_log] ==> #568000     Total Loss: 0.770    [weighted Loss:0.770    Policy Loss: 3.917    Value Loss: 4.031    Reward Loss: 0.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 126886     Buffer Size: 13378      Transition Number: 999.974 k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:01:27,609][train][INFO][train.py>_log] ==> #570000     Total Loss: 0.953    [weighted Loss:0.953    Policy Loss: 4.032    Value Loss: 4.513    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 127364     Buffer Size: 13430      Transition Number: 999.978 k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:07:15,200][train][INFO][train.py>_log] ==> #572000     Total Loss: 1.159    [weighted Loss:1.159    Policy Loss: 3.858    Value Loss: 3.994    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 127817     Buffer Size: 13480      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:12:59,462][train][INFO][train.py>_log] ==> #574000     Total Loss: 1.177    [weighted Loss:1.177    Policy Loss: 3.842    Value Loss: 4.120    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 128263     Buffer Size: 13523      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:18:45,627][train][INFO][train.py>_log] ==> #576000     Total Loss: 1.123    [weighted Loss:1.123    Policy Loss: 3.694    Value Loss: 4.305    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 128722     Buffer Size: 13570      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:24:30,143][train][INFO][train.py>_log] ==> #578000     Total Loss: 0.864    [weighted Loss:0.864    Policy Loss: 3.518    Value Loss: 4.006    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 129188     Buffer Size: 13606      Transition Number: 1000.009k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:30:16,127][train][INFO][train.py>_log] ==> #580000     Total Loss: 1.154    [weighted Loss:1.154    Policy Loss: 3.579    Value Loss: 3.898    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 129627     Buffer Size: 13643      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:35:53,211][train][INFO][train.py>_log] ==> #582000     Total Loss: 0.784    [weighted Loss:0.784    Policy Loss: 3.684    Value Loss: 4.367    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 130072     Buffer Size: 13683      Transition Number: 1000.046k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:41:39,007][train][INFO][train.py>_log] ==> #584000     Total Loss: 1.235    [weighted Loss:1.235    Policy Loss: 3.803    Value Loss: 4.060    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 130539     Buffer Size: 13725      Transition Number: 1000.098k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:47:23,138][train][INFO][train.py>_log] ==> #586000     Total Loss: 1.183    [weighted Loss:1.183    Policy Loss: 3.721    Value Loss: 4.070    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 130985     Buffer Size: 13767      Transition Number: 999.930 k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:53:08,783][train][INFO][train.py>_log] ==> #588000     Total Loss: 0.317    [weighted Loss:0.317    Policy Loss: 4.148    Value Loss: 4.399    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 131451     Buffer Size: 13809      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-12-01 10:58:53,257][train][INFO][train.py>_log] ==> #590000     Total Loss: 0.650    [weighted Loss:0.650    Policy Loss: 3.978    Value Loss: 4.525    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 131920     Buffer Size: 13858      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:04:33,850][train][INFO][train.py>_log] ==> #592000     Total Loss: 1.015    [weighted Loss:1.015    Policy Loss: 3.496    Value Loss: 4.181    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 132373     Buffer Size: 13903      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:10:17,994][train][INFO][train.py>_log] ==> #594000     Total Loss: 0.922    [weighted Loss:0.922    Policy Loss: 3.600    Value Loss: 4.111    Reward Loss: 0.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 132806     Buffer Size: 13924      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:16:01,998][train][INFO][train.py>_log] ==> #596000     Total Loss: 0.823    [weighted Loss:0.823    Policy Loss: 4.148    Value Loss: 4.338    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 133276     Buffer Size: 13968      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:21:44,863][train][INFO][train.py>_log] ==> #598000     Total Loss: 0.880    [weighted Loss:0.880    Policy Loss: 3.538    Value Loss: 4.481    Reward Loss: 0.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 133744     Buffer Size: 14019      Transition Number: 999.980 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:27:31,504][train][INFO][train.py>_log] ==> #600000     Total Loss: 1.142    [weighted Loss:1.142    Policy Loss: 4.058    Value Loss: 4.085    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 134200     Buffer Size: 14070      Transition Number: 1000.007k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:33:13,665][train][INFO][train.py>_log] ==> #602000     Total Loss: 0.893    [weighted Loss:0.893    Policy Loss: 3.304    Value Loss: 4.310    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 134634     Buffer Size: 14123      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:38:57,291][train][INFO][train.py>_log] ==> #604000     Total Loss: 0.909    [weighted Loss:0.909    Policy Loss: 3.841    Value Loss: 4.382    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 135106     Buffer Size: 14177      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:44:38,648][train][INFO][train.py>_log] ==> #606000     Total Loss: 0.685    [weighted Loss:0.685    Policy Loss: 4.181    Value Loss: 4.268    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 135540     Buffer Size: 14237      Transition Number: 999.976 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:50:14,480][train][INFO][train.py>_log] ==> #608000     Total Loss: 0.886    [weighted Loss:0.886    Policy Loss: 4.047    Value Loss: 4.435    Reward Loss: 0.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 135989     Buffer Size: 14294      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-12-01 11:55:55,767][train][INFO][train.py>_log] ==> #610000     Total Loss: 0.576    [weighted Loss:0.576    Policy Loss: 3.808    Value Loss: 4.428    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 136428     Buffer Size: 14343      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:01:40,915][train][INFO][train.py>_log] ==> #612000     Total Loss: 1.408    [weighted Loss:1.408    Policy Loss: 3.839    Value Loss: 4.369    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 136882     Buffer Size: 14399      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:07:23,934][train][INFO][train.py>_log] ==> #614000     Total Loss: 0.958    [weighted Loss:0.958    Policy Loss: 3.785    Value Loss: 4.360    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 137341     Buffer Size: 14443      Transition Number: 1000.024k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:12:57,847][train][INFO][train.py>_log] ==> #616000     Total Loss: 0.695    [weighted Loss:0.695    Policy Loss: 3.931    Value Loss: 4.350    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 137771     Buffer Size: 14478      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:18:39,654][train][INFO][train.py>_log] ==> #618000     Total Loss: 0.780    [weighted Loss:0.780    Policy Loss: 3.720    Value Loss: 4.405    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 138223     Buffer Size: 14508      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:24:20,622][train][INFO][train.py>_log] ==> #620000     Total Loss: 0.507    [weighted Loss:0.507    Policy Loss: 3.748    Value Loss: 4.350    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 138664     Buffer Size: 14532      Transition Number: 999.969 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:30:04,634][train][INFO][train.py>_log] ==> #622000     Total Loss: 0.340    [weighted Loss:0.340    Policy Loss: 3.601    Value Loss: 4.379    Reward Loss: 0.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 139116     Buffer Size: 14554      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:35:47,872][train][INFO][train.py>_log] ==> #624000     Total Loss: 0.925    [weighted Loss:0.925    Policy Loss: 3.839    Value Loss: 4.518    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 139563     Buffer Size: 14578      Transition Number: 999.961 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:41:27,544][train][INFO][train.py>_log] ==> #626000     Total Loss: 0.660    [weighted Loss:0.660    Policy Loss: 3.863    Value Loss: 4.394    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 140005     Buffer Size: 14608      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:47:09,904][train][INFO][train.py>_log] ==> #628000     Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 3.815    Value Loss: 4.606    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 140459     Buffer Size: 14621      Transition Number: 999.951 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:52:52,108][train][INFO][train.py>_log] ==> #630000     Total Loss: 0.569    [weighted Loss:0.569    Policy Loss: 3.150    Value Loss: 4.300    Reward Loss: 0.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 140921     Buffer Size: 14638      Transition Number: 999.960 k Batch Size: 256        Lr: 0.010   
[2021-12-01 12:58:29,998][train][INFO][train.py>_log] ==> #632000     Total Loss: 1.039    [weighted Loss:1.039    Policy Loss: 3.192    Value Loss: 4.758    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 141352     Buffer Size: 14647      Transition Number: 999.927 k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:04:13,115][train][INFO][train.py>_log] ==> #634000     Total Loss: 0.406    [weighted Loss:0.406    Policy Loss: 3.121    Value Loss: 4.441    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 141816     Buffer Size: 14643      Transition Number: 1000.101k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:09:54,596][train][INFO][train.py>_log] ==> #636000     Total Loss: 0.786    [weighted Loss:0.786    Policy Loss: 3.731    Value Loss: 4.554    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 142271     Buffer Size: 14626      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:15:33,114][train][INFO][train.py>_log] ==> #638000     Total Loss: 0.579    [weighted Loss:0.579    Policy Loss: 3.141    Value Loss: 4.896    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 142707     Buffer Size: 14616      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:21:14,521][train][INFO][train.py>_log] ==> #640000     Total Loss: 0.838    [weighted Loss:0.838    Policy Loss: 3.810    Value Loss: 4.402    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 143168     Buffer Size: 14598      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:26:53,053][train][INFO][train.py>_log] ==> #642000     Total Loss: 0.842    [weighted Loss:0.842    Policy Loss: 3.214    Value Loss: 4.549    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 143621     Buffer Size: 14593      Transition Number: 999.944 k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:32:37,623][train][INFO][train.py>_log] ==> #644000     Total Loss: 0.740    [weighted Loss:0.740    Policy Loss: 3.543    Value Loss: 4.524    Reward Loss: 0.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 144062     Buffer Size: 14583      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:38:22,615][train][INFO][train.py>_log] ==> #646000     Total Loss: 0.899    [weighted Loss:0.899    Policy Loss: 3.424    Value Loss: 4.584    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 144529     Buffer Size: 14573      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:44:00,136][train][INFO][train.py>_log] ==> #648000     Total Loss: 0.707    [weighted Loss:0.707    Policy Loss: 3.287    Value Loss: 4.483    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 144978     Buffer Size: 14563      Transition Number: 999.970 k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:49:41,617][train][INFO][train.py>_log] ==> #650000     Total Loss: 0.810    [weighted Loss:0.810    Policy Loss: 3.143    Value Loss: 4.558    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 145419     Buffer Size: 14542      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-12-01 13:55:26,044][train][INFO][train.py>_log] ==> #652000     Total Loss: 0.486    [weighted Loss:0.486    Policy Loss: 3.362    Value Loss: 4.347    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 145878     Buffer Size: 14527      Transition Number: 1000.049k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:01:03,455][train][INFO][train.py>_log] ==> #654000     Total Loss: 0.844    [weighted Loss:0.844    Policy Loss: 2.924    Value Loss: 4.267    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 146333     Buffer Size: 14499      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:06:47,571][train][INFO][train.py>_log] ==> #656000     Total Loss: 1.007    [weighted Loss:1.007    Policy Loss: 3.211    Value Loss: 4.578    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 146780     Buffer Size: 14474      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:12:28,196][train][INFO][train.py>_log] ==> #658000     Total Loss: 0.801    [weighted Loss:0.801    Policy Loss: 3.106    Value Loss: 4.152    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 147232     Buffer Size: 14464      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:18:09,730][train][INFO][train.py>_log] ==> #660000     Total Loss: 0.730    [weighted Loss:0.730    Policy Loss: 2.986    Value Loss: 4.377    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 147696     Buffer Size: 14454      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:23:52,083][train][INFO][train.py>_log] ==> #662000     Total Loss: 0.630    [weighted Loss:0.630    Policy Loss: 3.043    Value Loss: 4.115    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 148161     Buffer Size: 14426      Transition Number: 999.981 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:29:36,592][train][INFO][train.py>_log] ==> #664000     Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 3.500    Value Loss: 4.394    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 148613     Buffer Size: 14454      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:35:19,621][train][INFO][train.py>_log] ==> #666000     Total Loss: 0.802    [weighted Loss:0.802    Policy Loss: 3.292    Value Loss: 4.535    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 149072     Buffer Size: 14419      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:41:02,893][train][INFO][train.py>_log] ==> #668000     Total Loss: 0.716    [weighted Loss:0.716    Policy Loss: 3.274    Value Loss: 4.471    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 149526     Buffer Size: 14373      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:46:46,050][train][INFO][train.py>_log] ==> #670000     Total Loss: 1.038    [weighted Loss:1.038    Policy Loss: 3.294    Value Loss: 4.216    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 149980     Buffer Size: 14327      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:52:28,043][train][INFO][train.py>_log] ==> #672000     Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 3.445    Value Loss: 4.005    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 150445     Buffer Size: 14281      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-12-01 14:58:16,016][train][INFO][train.py>_log] ==> #674000     Total Loss: 0.231    [weighted Loss:0.231    Policy Loss: 3.115    Value Loss: 4.023    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 150905     Buffer Size: 14240      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:03:59,623][train][INFO][train.py>_log] ==> #676000     Total Loss: 1.131    [weighted Loss:1.131    Policy Loss: 3.281    Value Loss: 4.270    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 151361     Buffer Size: 14208      Transition Number: 999.988 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:09:41,978][train][INFO][train.py>_log] ==> #678000     Total Loss: 0.398    [weighted Loss:0.398    Policy Loss: 3.219    Value Loss: 4.207    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 151810     Buffer Size: 14181      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:15:22,104][train][INFO][train.py>_log] ==> #680000     Total Loss: 0.461    [weighted Loss:0.461    Policy Loss: 3.242    Value Loss: 4.172    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 152270     Buffer Size: 14160      Transition Number: 999.995 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:21:03,638][train][INFO][train.py>_log] ==> #682000     Total Loss: 1.009    [weighted Loss:1.009    Policy Loss: 3.584    Value Loss: 4.091    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 152726     Buffer Size: 14140      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:26:44,626][train][INFO][train.py>_log] ==> #684000     Total Loss: 1.036    [weighted Loss:1.036    Policy Loss: 3.628    Value Loss: 4.386    Reward Loss: 0.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 153187     Buffer Size: 14116      Transition Number: 999.952 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:32:27,607][train][INFO][train.py>_log] ==> #686000     Total Loss: 0.356    [weighted Loss:0.356    Policy Loss: 3.989    Value Loss: 4.130    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 153657     Buffer Size: 14100      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:38:10,404][train][INFO][train.py>_log] ==> #688000     Total Loss: 1.058    [weighted Loss:1.058    Policy Loss: 3.942    Value Loss: 3.933    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 154094     Buffer Size: 14081      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:43:52,406][train][INFO][train.py>_log] ==> #690000     Total Loss: 0.756    [weighted Loss:0.756    Policy Loss: 3.865    Value Loss: 4.145    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 154561     Buffer Size: 14083      Transition Number: 1000.049k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:49:40,222][train][INFO][train.py>_log] ==> #692000     Total Loss: 0.672    [weighted Loss:0.672    Policy Loss: 4.131    Value Loss: 4.045    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 155029     Buffer Size: 14074      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-12-01 15:55:24,634][train][INFO][train.py>_log] ==> #694000     Total Loss: 1.442    [weighted Loss:1.442    Policy Loss: 4.067    Value Loss: 4.225    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 155476     Buffer Size: 14084      Transition Number: 1000.092k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:01:08,836][train][INFO][train.py>_log] ==> #696000     Total Loss: 0.937    [weighted Loss:0.937    Policy Loss: 3.979    Value Loss: 4.349    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 155926     Buffer Size: 14094      Transition Number: 999.977 k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:06:48,125][train][INFO][train.py>_log] ==> #698000     Total Loss: 0.570    [weighted Loss:0.570    Policy Loss: 3.916    Value Loss: 3.859    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 156382     Buffer Size: 14096      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:12:33,505][train][INFO][train.py>_log] ==> #700000     Total Loss: 1.082    [weighted Loss:1.082    Policy Loss: 4.285    Value Loss: 4.328    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 156852     Buffer Size: 14094      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:18:18,649][train][INFO][train.py>_log] ==> #702000     Total Loss: 0.661    [weighted Loss:0.661    Policy Loss: 4.161    Value Loss: 3.920    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 157312     Buffer Size: 14098      Transition Number: 999.945 k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:24:06,447][train][INFO][train.py>_log] ==> #704000     Total Loss: 0.576    [weighted Loss:0.576    Policy Loss: 4.485    Value Loss: 4.229    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 157755     Buffer Size: 14098      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:29:51,642][train][INFO][train.py>_log] ==> #706000     Total Loss: 0.929    [weighted Loss:0.929    Policy Loss: 4.386    Value Loss: 4.383    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 158218     Buffer Size: 14112      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:35:36,730][train][INFO][train.py>_log] ==> #708000     Total Loss: 1.062    [weighted Loss:1.062    Policy Loss: 4.856    Value Loss: 4.727    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 158688     Buffer Size: 14126      Transition Number: 1000.033k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:41:24,591][train][INFO][train.py>_log] ==> #710000     Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 4.962    Value Loss: 4.652    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 159163     Buffer Size: 14132      Transition Number: 999.997 k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:47:10,989][train][INFO][train.py>_log] ==> #712000     Total Loss: 1.670    [weighted Loss:1.670    Policy Loss: 4.989    Value Loss: 4.198    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 159622     Buffer Size: 14157      Transition Number: 1000.042k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:52:58,966][train][INFO][train.py>_log] ==> #714000     Total Loss: 0.538    [weighted Loss:0.538    Policy Loss: 5.307    Value Loss: 4.795    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 160087     Buffer Size: 14178      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-12-01 16:58:48,847][train][INFO][train.py>_log] ==> #716000     Total Loss: 0.632    [weighted Loss:0.632    Policy Loss: 4.989    Value Loss: 4.628    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 160543     Buffer Size: 14184      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:04:33,232][train][INFO][train.py>_log] ==> #718000     Total Loss: 0.676    [weighted Loss:0.676    Policy Loss: 5.079    Value Loss: 4.484    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 161012     Buffer Size: 14193      Transition Number: 999.987 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:10:21,358][train][INFO][train.py>_log] ==> #720000     Total Loss: 1.067    [weighted Loss:1.067    Policy Loss: 4.963    Value Loss: 4.518    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 161464     Buffer Size: 14201      Transition Number: 999.940 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:16:04,877][train][INFO][train.py>_log] ==> #722000     Total Loss: 0.900    [weighted Loss:0.900    Policy Loss: 4.746    Value Loss: 4.471    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 161922     Buffer Size: 14197      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:21:50,875][train][INFO][train.py>_log] ==> #724000     Total Loss: 0.897    [weighted Loss:0.897    Policy Loss: 4.896    Value Loss: 4.401    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 162391     Buffer Size: 14192      Transition Number: 999.980 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:27:41,633][train][INFO][train.py>_log] ==> #726000     Total Loss: 0.833    [weighted Loss:0.833    Policy Loss: 4.939    Value Loss: 4.356    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 162854     Buffer Size: 14143      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:33:29,732][train][INFO][train.py>_log] ==> #728000     Total Loss: 0.829    [weighted Loss:0.829    Policy Loss: 4.506    Value Loss: 4.557    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 163331     Buffer Size: 14145      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:39:16,414][train][INFO][train.py>_log] ==> #730000     Total Loss: 0.529    [weighted Loss:0.529    Policy Loss: 5.016    Value Loss: 4.467    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 163779     Buffer Size: 14160      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:45:03,309][train][INFO][train.py>_log] ==> #732000     Total Loss: 0.730    [weighted Loss:0.730    Policy Loss: 4.705    Value Loss: 4.580    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 164232     Buffer Size: 14180      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:50:50,898][train][INFO][train.py>_log] ==> #734000     Total Loss: 0.797    [weighted Loss:0.797    Policy Loss: 4.436    Value Loss: 4.960    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 164696     Buffer Size: 14191      Transition Number: 999.943 k Batch Size: 256        Lr: 0.010   
[2021-12-01 17:56:35,015][train][INFO][train.py>_log] ==> #736000     Total Loss: 1.045    [weighted Loss:1.045    Policy Loss: 4.927    Value Loss: 4.727    Reward Loss: 0.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 165151     Buffer Size: 14207      Transition Number: 999.984 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:02:19,992][train][INFO][train.py>_log] ==> #738000     Total Loss: 1.555    [weighted Loss:1.555    Policy Loss: 4.995    Value Loss: 4.432    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 165608     Buffer Size: 14217      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:08:04,089][train][INFO][train.py>_log] ==> #740000     Total Loss: 0.780    [weighted Loss:0.780    Policy Loss: 4.333    Value Loss: 4.544    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 166069     Buffer Size: 14225      Transition Number: 999.992 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:13:48,694][train][INFO][train.py>_log] ==> #742000     Total Loss: 0.675    [weighted Loss:0.675    Policy Loss: 4.779    Value Loss: 4.674    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 166502     Buffer Size: 14221      Transition Number: 1000.037k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:19:29,930][train][INFO][train.py>_log] ==> #744000     Total Loss: 0.707    [weighted Loss:0.707    Policy Loss: 4.445    Value Loss: 4.609    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 166947     Buffer Size: 14215      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:25:18,020][train][INFO][train.py>_log] ==> #746000     Total Loss: 0.748    [weighted Loss:0.748    Policy Loss: 4.272    Value Loss: 4.833    Reward Loss: 0.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 167418     Buffer Size: 14204      Transition Number: 999.930 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:31:05,717][train][INFO][train.py>_log] ==> #748000     Total Loss: 0.425    [weighted Loss:0.425    Policy Loss: 4.626    Value Loss: 4.864    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 167869     Buffer Size: 14210      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:36:48,333][train][INFO][train.py>_log] ==> #750000     Total Loss: 0.479    [weighted Loss:0.479    Policy Loss: 4.446    Value Loss: 4.699    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 168315     Buffer Size: 14210      Transition Number: 999.939 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:42:30,718][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.107    [weighted Loss:1.107    Policy Loss: 4.587    Value Loss: 4.693    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 168772     Buffer Size: 14188      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:48:19,138][train][INFO][train.py>_log] ==> #754000     Total Loss: 0.825    [weighted Loss:0.825    Policy Loss: 4.427    Value Loss: 4.594    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 169235     Buffer Size: 14171      Transition Number: 1000.038k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:54:04,835][train][INFO][train.py>_log] ==> #756000     Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 4.141    Value Loss: 5.041    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 169672     Buffer Size: 14153      Transition Number: 999.936 k Batch Size: 256        Lr: 0.010   
[2021-12-01 18:59:51,374][train][INFO][train.py>_log] ==> #758000     Total Loss: 0.905    [weighted Loss:0.905    Policy Loss: 4.253    Value Loss: 4.940    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 170126     Buffer Size: 14129      Transition Number: 999.949 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:05:35,194][train][INFO][train.py>_log] ==> #760000     Total Loss: 0.869    [weighted Loss:0.869    Policy Loss: 4.153    Value Loss: 4.632    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 170597     Buffer Size: 14112      Transition Number: 999.973 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:11:23,018][train][INFO][train.py>_log] ==> #762000     Total Loss: 0.622    [weighted Loss:0.622    Policy Loss: 3.888    Value Loss: 4.968    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 171041     Buffer Size: 14091      Transition Number: 1000.048k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:17:13,159][train][INFO][train.py>_log] ==> #764000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 4.599    Value Loss: 4.793    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 171496     Buffer Size: 14071      Transition Number: 999.985 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:23:04,471][train][INFO][train.py>_log] ==> #766000     Total Loss: 0.195    [weighted Loss:0.195    Policy Loss: 3.947    Value Loss: 4.948    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 171966     Buffer Size: 14071      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:28:51,589][train][INFO][train.py>_log] ==> #768000     Total Loss: 0.880    [weighted Loss:0.880    Policy Loss: 3.880    Value Loss: 4.607    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 172409     Buffer Size: 14054      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:34:39,953][train][INFO][train.py>_log] ==> #770000     Total Loss: 0.908    [weighted Loss:0.908    Policy Loss: 4.056    Value Loss: 4.934    Reward Loss: 0.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 172864     Buffer Size: 14023      Transition Number: 999.928 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:40:28,896][train][INFO][train.py>_log] ==> #772000     Total Loss: 0.732    [weighted Loss:0.732    Policy Loss: 4.034    Value Loss: 4.761    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 173325     Buffer Size: 13987      Transition Number: 999.993 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:46:21,024][train][INFO][train.py>_log] ==> #774000     Total Loss: 1.089    [weighted Loss:1.089    Policy Loss: 3.922    Value Loss: 4.691    Reward Loss: 0.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 173792     Buffer Size: 13940      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:52:15,171][train][INFO][train.py>_log] ==> #776000     Total Loss: 0.472    [weighted Loss:0.472    Policy Loss: 3.844    Value Loss: 4.547    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 174240     Buffer Size: 13901      Transition Number: 999.989 k Batch Size: 256        Lr: 0.010   
[2021-12-01 19:58:00,381][train][INFO][train.py>_log] ==> #778000     Total Loss: 0.085    [weighted Loss:0.085    Policy Loss: 4.387    Value Loss: 4.749    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 174685     Buffer Size: 13887      Transition Number: 999.961 k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:03:50,733][train][INFO][train.py>_log] ==> #780000     Total Loss: 0.332    [weighted Loss:0.332    Policy Loss: 3.809    Value Loss: 4.527    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 175146     Buffer Size: 13867      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:09:37,620][train][INFO][train.py>_log] ==> #782000     Total Loss: 0.600    [weighted Loss:0.600    Policy Loss: 3.777    Value Loss: 4.734    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 175579     Buffer Size: 13848      Transition Number: 1000.000k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:15:22,405][train][INFO][train.py>_log] ==> #784000     Total Loss: 0.544    [weighted Loss:0.544    Policy Loss: 3.564    Value Loss: 4.480    Reward Loss: 0.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 176027     Buffer Size: 13831      Transition Number: 999.937 k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:21:10,471][train][INFO][train.py>_log] ==> #786000     Total Loss: 0.835    [weighted Loss:0.835    Policy Loss: 3.672    Value Loss: 4.638    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 176495     Buffer Size: 13804      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:27:01,219][train][INFO][train.py>_log] ==> #788000     Total Loss: 0.825    [weighted Loss:0.825    Policy Loss: 3.650    Value Loss: 4.200    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 176951     Buffer Size: 13774      Transition Number: 1000.061k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:32:47,068][train][INFO][train.py>_log] ==> #790000     Total Loss: 0.823    [weighted Loss:0.823    Policy Loss: 3.887    Value Loss: 4.686    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 177399     Buffer Size: 13732      Transition Number: 999.941 k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:38:36,869][train][INFO][train.py>_log] ==> #792000     Total Loss: 0.166    [weighted Loss:0.166    Policy Loss: 3.741    Value Loss: 4.524    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 177854     Buffer Size: 13697      Transition Number: 999.958 k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:44:26,475][train][INFO][train.py>_log] ==> #794000     Total Loss: 0.572    [weighted Loss:0.572    Policy Loss: 3.373    Value Loss: 4.489    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 178297     Buffer Size: 13665      Transition Number: 999.966 k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:50:16,829][train][INFO][train.py>_log] ==> #796000     Total Loss: 0.619    [weighted Loss:0.619    Policy Loss: 3.802    Value Loss: 4.559    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 178764     Buffer Size: 13633      Transition Number: 999.999 k Batch Size: 256        Lr: 0.010   
[2021-12-01 20:56:08,001][train][INFO][train.py>_log] ==> #798000     Total Loss: 0.624    [weighted Loss:0.624    Policy Loss: 3.690    Value Loss: 4.343    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 179210     Buffer Size: 13608      Transition Number: 999.965 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:01:55,952][train][INFO][train.py>_log] ==> #800000     Total Loss: 0.463    [weighted Loss:0.463    Policy Loss: 3.776    Value Loss: 4.236    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 179662     Buffer Size: 13583      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:07:39,453][train][INFO][train.py>_log] ==> #802000     Total Loss: 0.698    [weighted Loss:0.698    Policy Loss: 3.324    Value Loss: 4.579    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 180106     Buffer Size: 13567      Transition Number: 999.980 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:13:28,459][train][INFO][train.py>_log] ==> #804000     Total Loss: 0.582    [weighted Loss:0.582    Policy Loss: 3.634    Value Loss: 4.805    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 180567     Buffer Size: 13545      Transition Number: 999.969 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:19:15,506][train][INFO][train.py>_log] ==> #806000     Total Loss: 0.699    [weighted Loss:0.699    Policy Loss: 3.256    Value Loss: 4.790    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 181005     Buffer Size: 13529      Transition Number: 999.971 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:25:07,667][train][INFO][train.py>_log] ==> #808000     Total Loss: 0.594    [weighted Loss:0.594    Policy Loss: 3.656    Value Loss: 4.722    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 181463     Buffer Size: 13501      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:31:01,091][train][INFO][train.py>_log] ==> #810000     Total Loss: 0.768    [weighted Loss:0.768    Policy Loss: 3.904    Value Loss: 4.384    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 181926     Buffer Size: 13484      Transition Number: 999.979 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:36:47,560][train][INFO][train.py>_log] ==> #812000     Total Loss: 0.520    [weighted Loss:0.520    Policy Loss: 3.961    Value Loss: 4.765    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 182378     Buffer Size: 13478      Transition Number: 999.990 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:42:41,144][train][INFO][train.py>_log] ==> #814000     Total Loss: 0.695    [weighted Loss:0.695    Policy Loss: 3.824    Value Loss: 4.742    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 182832     Buffer Size: 13470      Transition Number: 999.971 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:48:35,430][train][INFO][train.py>_log] ==> #816000     Total Loss: 0.582    [weighted Loss:0.582    Policy Loss: 3.514    Value Loss: 4.159    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 183287     Buffer Size: 13445      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-12-01 21:54:26,229][train][INFO][train.py>_log] ==> #818000     Total Loss: 0.781    [weighted Loss:0.781    Policy Loss: 3.899    Value Loss: 4.369    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 183743     Buffer Size: 13424      Transition Number: 999.957 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:00:15,998][train][INFO][train.py>_log] ==> #820000     Total Loss: 0.816    [weighted Loss:0.816    Policy Loss: 3.992    Value Loss: 5.028    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 184182     Buffer Size: 13424      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:06:08,378][train][INFO][train.py>_log] ==> #822000     Total Loss: 0.853    [weighted Loss:0.853    Policy Loss: 4.008    Value Loss: 4.359    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 184640     Buffer Size: 13414      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:11:57,691][train][INFO][train.py>_log] ==> #824000     Total Loss: 0.992    [weighted Loss:0.992    Policy Loss: 4.074    Value Loss: 4.370    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 185073     Buffer Size: 13399      Transition Number: 999.972 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:17:47,616][train][INFO][train.py>_log] ==> #826000     Total Loss: 0.507    [weighted Loss:0.507    Policy Loss: 4.458    Value Loss: 4.259    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 185513     Buffer Size: 13371      Transition Number: 999.938 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:23:36,251][train][INFO][train.py>_log] ==> #828000     Total Loss: 0.222    [weighted Loss:0.222    Policy Loss: 3.788    Value Loss: 4.505    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 185957     Buffer Size: 13356      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:29:26,216][train][INFO][train.py>_log] ==> #830000     Total Loss: 0.743    [weighted Loss:0.743    Policy Loss: 3.784    Value Loss: 4.132    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 186399     Buffer Size: 13357      Transition Number: 999.998 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:35:16,545][train][INFO][train.py>_log] ==> #832000     Total Loss: 1.078    [weighted Loss:1.078    Policy Loss: 4.144    Value Loss: 4.727    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 186847     Buffer Size: 13353      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:41:15,094][train][INFO][train.py>_log] ==> #834000     Total Loss: 0.626    [weighted Loss:0.626    Policy Loss: 4.112    Value Loss: 4.178    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 187296     Buffer Size: 13352      Transition Number: 999.963 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:47:10,048][train][INFO][train.py>_log] ==> #836000     Total Loss: 0.872    [weighted Loss:0.872    Policy Loss: 4.636    Value Loss: 4.600    Reward Loss: 0.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 187743     Buffer Size: 13354      Transition Number: 1000.312k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:52:59,192][train][INFO][train.py>_log] ==> #838000     Total Loss: 0.703    [weighted Loss:0.703    Policy Loss: 4.098    Value Loss: 4.827    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 188173     Buffer Size: 13350      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-12-01 22:58:50,920][train][INFO][train.py>_log] ==> #840000     Total Loss: 0.835    [weighted Loss:0.835    Policy Loss: 4.284    Value Loss: 4.521    Reward Loss: 0.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 188610     Buffer Size: 13336      Transition Number: 1000.045k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:04:42,437][train][INFO][train.py>_log] ==> #842000     Total Loss: 0.474    [weighted Loss:0.474    Policy Loss: 4.199    Value Loss: 4.623    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 189043     Buffer Size: 13327      Transition Number: 999.934 k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:10:32,170][train][INFO][train.py>_log] ==> #844000     Total Loss: 0.505    [weighted Loss:0.505    Policy Loss: 4.167    Value Loss: 4.904    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 189497     Buffer Size: 13329      Transition Number: 999.954 k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:16:21,680][train][INFO][train.py>_log] ==> #846000     Total Loss: 0.752    [weighted Loss:0.752    Policy Loss: 4.127    Value Loss: 4.508    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 189936     Buffer Size: 13334      Transition Number: 999.929 k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:22:09,589][train][INFO][train.py>_log] ==> #848000     Total Loss: 0.889    [weighted Loss:0.889    Policy Loss: 3.914    Value Loss: 4.544    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 190360     Buffer Size: 13341      Transition Number: 1000.031k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:27:51,587][train][INFO][train.py>_log] ==> #850000     Total Loss: 0.408    [weighted Loss:0.408    Policy Loss: 4.024    Value Loss: 4.667    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 190790     Buffer Size: 13350      Transition Number: 999.946 k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:33:40,629][train][INFO][train.py>_log] ==> #852000     Total Loss: 0.884    [weighted Loss:0.884    Policy Loss: 4.728    Value Loss: 4.399    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 191233     Buffer Size: 13349      Transition Number: 999.996 k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:39:29,884][train][INFO][train.py>_log] ==> #854000     Total Loss: 0.941    [weighted Loss:0.941    Policy Loss: 4.006    Value Loss: 4.629    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 191681     Buffer Size: 13354      Transition Number: 999.923 k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:45:18,871][train][INFO][train.py>_log] ==> #856000     Total Loss: 0.547    [weighted Loss:0.547    Policy Loss: 4.275    Value Loss: 4.647    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 192122     Buffer Size: 13359      Transition Number: 999.956 k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:51:11,570][train][INFO][train.py>_log] ==> #858000     Total Loss: 0.575    [weighted Loss:0.575    Policy Loss: 3.956    Value Loss: 5.308    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 192555     Buffer Size: 13351      Transition Number: 1000.070k Batch Size: 256        Lr: 0.010   
[2021-12-01 23:57:05,851][train][INFO][train.py>_log] ==> #860000     Total Loss: 0.462    [weighted Loss:0.462    Policy Loss: 4.658    Value Loss: 4.465    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 193006     Buffer Size: 13338      Transition Number: 999.967 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:02:54,529][train][INFO][train.py>_log] ==> #862000     Total Loss: 0.441    [weighted Loss:0.441    Policy Loss: 4.508    Value Loss: 4.469    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 193454     Buffer Size: 13331      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:08:43,790][train][INFO][train.py>_log] ==> #864000     Total Loss: 0.525    [weighted Loss:0.525    Policy Loss: 4.219    Value Loss: 4.374    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 193890     Buffer Size: 13333      Transition Number: 999.991 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:14:33,802][train][INFO][train.py>_log] ==> #866000     Total Loss: 0.451    [weighted Loss:0.451    Policy Loss: 4.102    Value Loss: 4.319    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 194334     Buffer Size: 13323      Transition Number: 999.943 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:20:25,817][train][INFO][train.py>_log] ==> #868000     Total Loss: 0.830    [weighted Loss:0.830    Policy Loss: 4.175    Value Loss: 4.768    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 194779     Buffer Size: 13319      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:26:14,879][train][INFO][train.py>_log] ==> #870000     Total Loss: 0.694    [weighted Loss:0.694    Policy Loss: 3.895    Value Loss: 4.409    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 195224     Buffer Size: 13312      Transition Number: 999.978 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:31:57,573][train][INFO][train.py>_log] ==> #872000     Total Loss: 0.818    [weighted Loss:0.818    Policy Loss: 4.272    Value Loss: 4.518    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 195633     Buffer Size: 13297      Transition Number: 999.959 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:37:47,284][train][INFO][train.py>_log] ==> #874000     Total Loss: 0.650    [weighted Loss:0.650    Policy Loss: 3.870    Value Loss: 4.435    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 196068     Buffer Size: 13282      Transition Number: 999.975 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:43:38,769][train][INFO][train.py>_log] ==> #876000     Total Loss: 0.567    [weighted Loss:0.567    Policy Loss: 3.907    Value Loss: 4.551    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 196516     Buffer Size: 13278      Transition Number: 999.955 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:49:27,680][train][INFO][train.py>_log] ==> #878000     Total Loss: 0.898    [weighted Loss:0.898    Policy Loss: 4.136    Value Loss: 4.815    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 196959     Buffer Size: 13276      Transition Number: 999.953 k Batch Size: 256        Lr: 0.010   
[2021-12-02 00:55:21,415][train][INFO][train.py>_log] ==> #880000     Total Loss: 0.293    [weighted Loss:0.293    Policy Loss: 4.170    Value Loss: 4.743    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 197399     Buffer Size: 13262      Transition Number: 999.994 k Batch Size: 256        Lr: 0.010   
[2021-12-02 01:01:10,968][train][INFO][train.py>_log] ==> #882000     Total Loss: 0.215    [weighted Loss:0.215    Policy Loss: 4.350    Value Loss: 4.974    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 197825     Buffer Size: 13251      Transition Number: 999.962 k Batch Size: 256        Lr: 0.010   
[2021-12-02 01:07:04,372][train][INFO][train.py>_log] ==> #884000     Total Loss: 1.089    [weighted Loss:1.089    Policy Loss: 4.159    Value Loss: 4.926    Reward Loss: 0.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 198266     Buffer Size: 13248      Transition Number: 999.935 k Batch Size: 256        Lr: 0.010   
[2021-12-02 01:12:49,823][train][INFO][train.py>_log] ==> #886000     Total Loss: 0.238    [weighted Loss:0.238    Policy Loss: 4.145    Value Loss: 4.693    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 198705     Buffer Size: 13246      Transition Number: 999.931 k Batch Size: 256        Lr: 0.010   
[2021-12-02 01:18:43,378][train][INFO][train.py>_log] ==> #888000     Total Loss: 0.560    [weighted Loss:0.560    Policy Loss: 4.122    Value Loss: 4.598    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 199159     Buffer Size: 13241      Transition Number: 999.932 k Batch Size: 256        Lr: 0.010   
[2021-12-02 01:24:31,620][train][INFO][train.py>_log] ==> #890000     Total Loss: 0.357    [weighted Loss:0.357    Policy Loss: 4.612    Value Loss: 4.657    Reward Loss: 0.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 199602     Buffer Size: 13244      Transition Number: 1000.095k Batch Size: 256        Lr: 0.010   
