[2021-12-24 14:20:55,108][train][INFO][train.py>_log] ==> #0          Total Loss: 48.222   [weighted Loss:48.222   Policy Loss: 13.750   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 227        Buffer Size: 227        Transition Number: 2.579   k Batch Size: 256        Lr: 0.000   
[2021-12-24 14:23:46,507][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.666    [weighted Loss:3.666    Policy Loss: 14.169   Value Loss: 3.227    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 931        Buffer Size: 931        Transition Number: 11.806  k Batch Size: 256        Lr: 0.100   
[2021-12-24 14:26:40,721][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.114    [weighted Loss:5.114    Policy Loss: 13.870   Value Loss: 3.083    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1600       Buffer Size: 1600       Transition Number: 20.236  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:29:31,416][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.470    [weighted Loss:5.470    Policy Loss: 13.266   Value Loss: 2.845    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2451       Buffer Size: 2451       Transition Number: 28.009  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:32:23,270][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.139    [weighted Loss:4.139    Policy Loss: 12.081   Value Loss: 2.812    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 3278       Buffer Size: 3278       Transition Number: 35.136  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:35:14,418][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.383    [weighted Loss:5.383    Policy Loss: 11.898   Value Loss: 2.591    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 4075       Buffer Size: 4075       Transition Number: 42.261  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:38:08,582][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.949    [weighted Loss:3.949    Policy Loss: 12.091   Value Loss: 2.641    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 4885       Buffer Size: 4885       Transition Number: 49.531  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:41:02,008][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.961    [weighted Loss:4.961    Policy Loss: 12.212   Value Loss: 2.652    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 5792       Buffer Size: 5792       Transition Number: 56.926  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:43:56,478][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.484    [weighted Loss:4.484    Policy Loss: 12.058   Value Loss: 2.847    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 6738       Buffer Size: 6738       Transition Number: 64.334  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:46:48,169][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.115    [weighted Loss:3.115    Policy Loss: 12.945   Value Loss: 2.699    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 7485       Buffer Size: 7485       Transition Number: 70.985  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:49:41,759][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.323    [weighted Loss:4.323    Policy Loss: 12.328   Value Loss: 2.620    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 8246       Buffer Size: 8246       Transition Number: 78.259  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:52:39,615][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.078    [weighted Loss:4.078    Policy Loss: 11.817   Value Loss: 2.713    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 9140       Buffer Size: 9140       Transition Number: 85.525  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:55:32,725][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.947    [weighted Loss:3.947    Policy Loss: 11.474   Value Loss: 2.603    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 10029      Buffer Size: 10029      Transition Number: 93.016  k Batch Size: 256        Lr: 0.200   
[2021-12-24 14:58:32,851][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 11.149   Value Loss: 2.833    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 10782      Buffer Size: 10782      Transition Number: 99.974  k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:01:56,799][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 10.980   Value Loss: 2.648    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 11707      Buffer Size: 11707      Transition Number: 108.830 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:05:05,441][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.142    [weighted Loss:5.142    Policy Loss: 12.361   Value Loss: 2.530    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 12519      Buffer Size: 12519      Transition Number: 116.472 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:08:10,976][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 11.870   Value Loss: 2.511    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 13375      Buffer Size: 13375      Transition Number: 124.577 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:11:15,456][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.349    [weighted Loss:4.349    Policy Loss: 11.747   Value Loss: 2.633    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 14180      Buffer Size: 14180      Transition Number: 132.017 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:14:23,494][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.695    [weighted Loss:5.695    Policy Loss: 12.079   Value Loss: 2.683    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 15040      Buffer Size: 15040      Transition Number: 140.189 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:17:33,966][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.457    [weighted Loss:4.457    Policy Loss: 11.501   Value Loss: 2.640    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 15894      Buffer Size: 15894      Transition Number: 148.079 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:20:39,537][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.583    [weighted Loss:3.583    Policy Loss: 11.438   Value Loss: 2.762    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 16758      Buffer Size: 16758      Transition Number: 156.063 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:23:43,904][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 12.341   Value Loss: 2.670    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 17321      Buffer Size: 17321      Transition Number: 163.059 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:26:53,616][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.217    [weighted Loss:4.217    Policy Loss: 11.705   Value Loss: 2.660    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 17965      Buffer Size: 17965      Transition Number: 171.266 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:29:59,669][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.901    [weighted Loss:4.901    Policy Loss: 12.836   Value Loss: 2.782    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 18584      Buffer Size: 18584      Transition Number: 178.581 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:33:03,932][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.988    [weighted Loss:4.988    Policy Loss: 11.725   Value Loss: 2.972    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 19197      Buffer Size: 19197      Transition Number: 186.513 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:36:06,944][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 12.327   Value Loss: 2.853    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 19847      Buffer Size: 19847      Transition Number: 193.867 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:39:11,785][train][INFO][train.py>_log] ==> #26000      Total Loss: 6.193    [weighted Loss:6.193    Policy Loss: 11.890   Value Loss: 2.899    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 20519      Buffer Size: 20519      Transition Number: 201.654 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:42:15,777][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.830    [weighted Loss:3.830    Policy Loss: 12.053   Value Loss: 3.086    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 21053      Buffer Size: 21053      Transition Number: 209.135 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:45:21,398][train][INFO][train.py>_log] ==> #28000      Total Loss: 5.337    [weighted Loss:5.337    Policy Loss: 12.266   Value Loss: 3.160    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 21558      Buffer Size: 21558      Transition Number: 216.384 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:48:24,784][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 12.201   Value Loss: 3.017    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 22035      Buffer Size: 22035      Transition Number: 223.584 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:51:33,612][train][INFO][train.py>_log] ==> #30000      Total Loss: 5.773    [weighted Loss:5.773    Policy Loss: 12.014   Value Loss: 3.027    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 22540      Buffer Size: 22540      Transition Number: 230.547 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:54:43,017][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.748    [weighted Loss:4.748    Policy Loss: 11.883   Value Loss: 3.016    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 23034      Buffer Size: 23034      Transition Number: 238.583 k Batch Size: 256        Lr: 0.200   
[2021-12-24 15:57:51,804][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.349    [weighted Loss:4.349    Policy Loss: 11.284   Value Loss: 3.053    Reward Loss: 1.093    Consistency Loss: 0.000    ] Replay Episodes Collected: 23538      Buffer Size: 23538      Transition Number: 245.909 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:00:57,853][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.561    [weighted Loss:4.561    Policy Loss: 12.490   Value Loss: 3.030    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 24011      Buffer Size: 24011      Transition Number: 253.686 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:03:57,528][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.541    [weighted Loss:4.541    Policy Loss: 11.993   Value Loss: 3.037    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 24424      Buffer Size: 24424      Transition Number: 260.012 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:07:03,458][train][INFO][train.py>_log] ==> #35000      Total Loss: 4.726    [weighted Loss:4.726    Policy Loss: 13.250   Value Loss: 3.144    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 24991      Buffer Size: 24991      Transition Number: 268.114 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:10:04,560][train][INFO][train.py>_log] ==> #36000      Total Loss: 4.549    [weighted Loss:4.549    Policy Loss: 12.062   Value Loss: 3.038    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 25560      Buffer Size: 25560      Transition Number: 275.062 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:13:02,555][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.170    [weighted Loss:3.170    Policy Loss: 12.372   Value Loss: 3.060    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 26078      Buffer Size: 26078      Transition Number: 282.121 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:16:08,341][train][INFO][train.py>_log] ==> #38000      Total Loss: 5.861    [weighted Loss:5.861    Policy Loss: 11.671   Value Loss: 3.160    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 26645      Buffer Size: 26645      Transition Number: 289.348 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:19:11,077][train][INFO][train.py>_log] ==> #39000      Total Loss: 4.929    [weighted Loss:4.929    Policy Loss: 12.202   Value Loss: 3.094    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 27453      Buffer Size: 27453      Transition Number: 297.549 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:22:13,455][train][INFO][train.py>_log] ==> #40000      Total Loss: 5.322    [weighted Loss:5.322    Policy Loss: 12.036   Value Loss: 2.943    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 28232      Buffer Size: 28232      Transition Number: 305.041 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:25:17,153][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 11.454   Value Loss: 2.945    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 28855      Buffer Size: 28855      Transition Number: 312.083 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:28:18,061][train][INFO][train.py>_log] ==> #42000      Total Loss: 4.003    [weighted Loss:4.003    Policy Loss: 11.603   Value Loss: 3.209    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 29442      Buffer Size: 29442      Transition Number: 319.399 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:31:20,989][train][INFO][train.py>_log] ==> #43000      Total Loss: 5.355    [weighted Loss:5.355    Policy Loss: 11.657   Value Loss: 3.065    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 30140      Buffer Size: 30140      Transition Number: 326.865 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:34:24,920][train][INFO][train.py>_log] ==> #44000      Total Loss: 5.118    [weighted Loss:5.118    Policy Loss: 11.662   Value Loss: 3.110    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 30769      Buffer Size: 30769      Transition Number: 334.128 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:37:26,673][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 12.468   Value Loss: 3.236    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 31363      Buffer Size: 31363      Transition Number: 341.640 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:40:28,719][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 12.202   Value Loss: 3.162    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 31987      Buffer Size: 31987      Transition Number: 349.327 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:43:31,109][train][INFO][train.py>_log] ==> #47000      Total Loss: 5.075    [weighted Loss:5.075    Policy Loss: 11.333   Value Loss: 3.383    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 32621      Buffer Size: 32621      Transition Number: 356.705 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:46:38,867][train][INFO][train.py>_log] ==> #48000      Total Loss: 4.942    [weighted Loss:4.942    Policy Loss: 11.578   Value Loss: 3.466    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 33268      Buffer Size: 33268      Transition Number: 364.368 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:49:44,407][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 12.606   Value Loss: 3.214    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 33740      Buffer Size: 33740      Transition Number: 371.471 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:52:44,406][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.658    [weighted Loss:3.658    Policy Loss: 12.194   Value Loss: 3.493    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 34204      Buffer Size: 34204      Transition Number: 379.097 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:55:48,395][train][INFO][train.py>_log] ==> #51000      Total Loss: 4.872    [weighted Loss:4.872    Policy Loss: 12.280   Value Loss: 3.097    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 34733      Buffer Size: 34733      Transition Number: 386.452 k Batch Size: 256        Lr: 0.200   
[2021-12-24 16:58:48,197][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.060    [weighted Loss:3.060    Policy Loss: 11.721   Value Loss: 3.250    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 35291      Buffer Size: 35291      Transition Number: 393.876 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:01:48,471][train][INFO][train.py>_log] ==> #53000      Total Loss: 4.629    [weighted Loss:4.629    Policy Loss: 12.474   Value Loss: 3.200    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 35851      Buffer Size: 35851      Transition Number: 400.644 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:04:49,859][train][INFO][train.py>_log] ==> #54000      Total Loss: 5.445    [weighted Loss:5.445    Policy Loss: 12.081   Value Loss: 3.110    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 36444      Buffer Size: 36444      Transition Number: 408.116 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:07:52,840][train][INFO][train.py>_log] ==> #55000      Total Loss: 4.312    [weighted Loss:4.312    Policy Loss: 12.554   Value Loss: 3.315    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 37016      Buffer Size: 37016      Transition Number: 415.386 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:10:53,179][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.800    [weighted Loss:3.800    Policy Loss: 12.456   Value Loss: 3.520    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 37538      Buffer Size: 37538      Transition Number: 422.268 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:14:00,320][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 12.506   Value Loss: 3.288    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 37964      Buffer Size: 37964      Transition Number: 429.511 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:17:05,025][train][INFO][train.py>_log] ==> #58000      Total Loss: 5.592    [weighted Loss:5.592    Policy Loss: 12.986   Value Loss: 3.398    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 38350      Buffer Size: 38350      Transition Number: 436.416 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:20:20,371][train][INFO][train.py>_log] ==> #59000      Total Loss: 5.173    [weighted Loss:5.173    Policy Loss: 11.979   Value Loss: 3.643    Reward Loss: 1.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 38777      Buffer Size: 38777      Transition Number: 444.232 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:23:24,226][train][INFO][train.py>_log] ==> #60000      Total Loss: 4.925    [weighted Loss:4.925    Policy Loss: 12.610   Value Loss: 3.297    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 39155      Buffer Size: 39155      Transition Number: 451.289 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:26:24,967][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.411    [weighted Loss:4.411    Policy Loss: 11.807   Value Loss: 3.331    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 39524      Buffer Size: 39524      Transition Number: 458.491 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:29:26,390][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 11.497   Value Loss: 3.423    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 39902      Buffer Size: 39902      Transition Number: 465.446 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:32:32,466][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.457    [weighted Loss:4.457    Policy Loss: 11.470   Value Loss: 3.609    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 40330      Buffer Size: 40330      Transition Number: 473.081 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:35:37,754][train][INFO][train.py>_log] ==> #64000      Total Loss: 4.612    [weighted Loss:4.612    Policy Loss: 11.798   Value Loss: 3.443    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 40729      Buffer Size: 40729      Transition Number: 479.876 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:38:38,426][train][INFO][train.py>_log] ==> #65000      Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 11.137   Value Loss: 3.372    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 41108      Buffer Size: 41108      Transition Number: 486.676 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:41:40,929][train][INFO][train.py>_log] ==> #66000      Total Loss: 5.031    [weighted Loss:5.031    Policy Loss: 11.235   Value Loss: 3.240    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 41507      Buffer Size: 41507      Transition Number: 493.971 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:44:48,187][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 11.146   Value Loss: 3.448    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 42078      Buffer Size: 42078      Transition Number: 501.812 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:47:55,243][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 10.540   Value Loss: 3.216    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 42655      Buffer Size: 42655      Transition Number: 509.389 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:50:59,468][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 11.692   Value Loss: 3.322    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 42981      Buffer Size: 42981      Transition Number: 515.074 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:54:00,799][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 11.529   Value Loss: 3.371    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 43254      Buffer Size: 43254      Transition Number: 521.302 k Batch Size: 256        Lr: 0.200   
[2021-12-24 17:57:01,577][train][INFO][train.py>_log] ==> #71000      Total Loss: 4.993    [weighted Loss:4.993    Policy Loss: 11.119   Value Loss: 3.514    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 43596      Buffer Size: 43596      Transition Number: 528.750 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:00:08,986][train][INFO][train.py>_log] ==> #72000      Total Loss: 4.481    [weighted Loss:4.481    Policy Loss: 10.964   Value Loss: 3.709    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 43941      Buffer Size: 43941      Transition Number: 536.233 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:03:10,173][train][INFO][train.py>_log] ==> #73000      Total Loss: 4.147    [weighted Loss:4.147    Policy Loss: 11.408   Value Loss: 3.540    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 44291      Buffer Size: 44291      Transition Number: 542.894 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:06:13,257][train][INFO][train.py>_log] ==> #74000      Total Loss: 5.573    [weighted Loss:5.573    Policy Loss: 10.855   Value Loss: 3.515    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 44696      Buffer Size: 44696      Transition Number: 550.186 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:09:15,919][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 11.018   Value Loss: 3.520    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 45131      Buffer Size: 45131      Transition Number: 556.646 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:12:20,217][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.094    [weighted Loss:4.094    Policy Loss: 11.552   Value Loss: 3.575    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 45589      Buffer Size: 45589      Transition Number: 564.383 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:15:22,830][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 11.104   Value Loss: 3.614    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 45849      Buffer Size: 45849      Transition Number: 569.583 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:18:25,095][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.413    [weighted Loss:4.413    Policy Loss: 10.539   Value Loss: 3.804    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 46105      Buffer Size: 46105      Transition Number: 576.889 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:21:35,652][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.299    [weighted Loss:4.299    Policy Loss: 10.010   Value Loss: 3.833    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 46420      Buffer Size: 46420      Transition Number: 584.433 k Batch Size: 256        Lr: 0.200   
[2021-12-24 18:24:37,571][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.827    [weighted Loss:3.827    Policy Loss: 10.012   Value Loss: 3.699    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 46742      Buffer Size: 46742      Transition Number: 591.140 k Batch Size: 256        Lr: 0.200   
