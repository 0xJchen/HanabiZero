[2021-11-10 04:29:37,260][train][INFO][train.py>_log] ==> #0          Total Loss: 44.579   [weighted Loss:44.579   Policy Loss: 14.581   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 24636      Buffer Size: 24636      Transition Number: 300.598 k Batch Size: 128        Lr: 0.000   
[2021-11-10 04:33:42,455][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.649    [weighted Loss:5.649    Policy Loss: 14.159   Value Loss: 4.382    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 26559      Buffer Size: 26559      Transition Number: 323.885 k Batch Size: 128        Lr: 0.010   
[2021-11-10 04:37:53,124][train][INFO][train.py>_log] ==> #2000       Total Loss: 8.416    [weighted Loss:8.416    Policy Loss: 14.291   Value Loss: 4.407    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 28200      Buffer Size: 28200      Transition Number: 343.749 k Batch Size: 128        Lr: 0.020   
[2021-11-10 04:42:12,392][train][INFO][train.py>_log] ==> #3000       Total Loss: 7.939    [weighted Loss:7.939    Policy Loss: 13.677   Value Loss: 3.366    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 29663      Buffer Size: 29663      Transition Number: 362.069 k Batch Size: 128        Lr: 0.030   
[2021-11-10 04:46:39,146][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.354    [weighted Loss:6.354    Policy Loss: 13.284   Value Loss: 3.194    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 31390      Buffer Size: 31390      Transition Number: 381.396 k Batch Size: 128        Lr: 0.040   
[2021-11-10 04:51:08,966][train][INFO][train.py>_log] ==> #5000       Total Loss: 7.378    [weighted Loss:7.378    Policy Loss: 11.992   Value Loss: 3.008    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 33337      Buffer Size: 33262      Transition Number: 400.008 k Batch Size: 128        Lr: 0.050   
[2021-11-10 04:55:36,236][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.518    [weighted Loss:5.518    Policy Loss: 12.404   Value Loss: 3.097    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 35654      Buffer Size: 33978      Transition Number: 399.995 k Batch Size: 128        Lr: 0.060   
[2021-11-10 04:59:58,069][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.974    [weighted Loss:5.974    Policy Loss: 11.824   Value Loss: 3.113    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 38604      Buffer Size: 35249      Transition Number: 399.983 k Batch Size: 128        Lr: 0.070   
