[2022-01-21 19:53:10,035][train][INFO][train.py>_log] ==> #0          Total Loss: 48.281   [weighted Loss:48.281   Policy Loss: 13.809   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1082       Buffer Size: 1082       Transition Number: 11.834  k Batch Size: 256        Lr: 0.00000 
[2022-01-21 19:56:59,223][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.043    [weighted Loss:4.043    Policy Loss: 13.998   Value Loss: 3.595    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 7094       Buffer Size: 7094       Transition Number: 87.413  k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:00:44,470][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.949    [weighted Loss:3.949    Policy Loss: 13.424   Value Loss: 3.180    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 12995      Buffer Size: 12995      Transition Number: 161.402 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:04:28,015][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.806    [weighted Loss:3.806    Policy Loss: 13.149   Value Loss: 2.982    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 19949      Buffer Size: 19949      Transition Number: 235.697 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:08:11,062][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.897    [weighted Loss:4.897    Policy Loss: 12.761   Value Loss: 3.019    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 26886      Buffer Size: 26886      Transition Number: 307.959 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:12:01,909][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.589    [weighted Loss:5.589    Policy Loss: 12.892   Value Loss: 2.905    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 33399      Buffer Size: 33399      Transition Number: 379.254 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:15:49,305][train][INFO][train.py>_log] ==> #6000       Total Loss: 6.035    [weighted Loss:6.035    Policy Loss: 12.886   Value Loss: 2.969    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 40108      Buffer Size: 40108      Transition Number: 452.518 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:19:35,107][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.964    [weighted Loss:4.964    Policy Loss: 12.350   Value Loss: 2.900    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 47341      Buffer Size: 47341      Transition Number: 528.404 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:23:24,287][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.131    [weighted Loss:5.131    Policy Loss: 12.383   Value Loss: 3.016    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 54576      Buffer Size: 54576      Transition Number: 603.939 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:27:23,161][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 12.333   Value Loss: 2.611    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 61287      Buffer Size: 61287      Transition Number: 678.861 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:31:13,869][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 12.973   Value Loss: 2.710    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 68080      Buffer Size: 68080      Transition Number: 754.920 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:35:05,101][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 11.730   Value Loss: 2.798    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 74840      Buffer Size: 74840      Transition Number: 829.969 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:38:56,631][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.574    [weighted Loss:5.574    Policy Loss: 12.145   Value Loss: 2.998    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 81633      Buffer Size: 81633      Transition Number: 905.573 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:42:52,619][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.077    [weighted Loss:3.077    Policy Loss: 11.082   Value Loss: 2.673    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 90204      Buffer Size: 90204      Transition Number: 982.906 k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:46:41,363][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.365    [weighted Loss:4.365    Policy Loss: 10.873   Value Loss: 2.727    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 98720      Buffer Size: 98720      Transition Number: 1058.452k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:50:31,172][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.454    [weighted Loss:4.454    Policy Loss: 11.235   Value Loss: 2.841    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 108254     Buffer Size: 108254     Transition Number: 1135.682k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:54:21,699][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 11.231   Value Loss: 2.719    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 117909     Buffer Size: 116745     Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-21 20:58:17,319][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.512    [weighted Loss:3.512    Policy Loss: 10.926   Value Loss: 2.617    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 126650     Buffer Size: 119481     Transition Number: 1200.084k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:02:08,675][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 10.710   Value Loss: 3.014    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 135462     Buffer Size: 122217     Transition Number: 1200.100k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:05:57,989][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.600    [weighted Loss:3.600    Policy Loss: 10.379   Value Loss: 3.020    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 143626     Buffer Size: 123516     Transition Number: 1200.042k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:09:47,015][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.130    [weighted Loss:3.130    Policy Loss: 10.264   Value Loss: 2.713    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 151678     Buffer Size: 124465     Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:13:42,812][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 10.839   Value Loss: 3.043    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 157763     Buffer Size: 124315     Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:17:31,797][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.358    [weighted Loss:4.358    Policy Loss: 11.075   Value Loss: 3.255    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 163715     Buffer Size: 123738     Transition Number: 1200.047k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:21:23,666][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.302    [weighted Loss:3.302    Policy Loss: 9.732    Value Loss: 3.214    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 167638     Buffer Size: 121755     Transition Number: 1200.251k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:25:11,527][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 8.666    Value Loss: 3.416    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 171454     Buffer Size: 119383     Transition Number: 1200.057k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:29:08,436][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 6.987    Value Loss: 3.587    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 172870     Buffer Size: 115350     Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:33:00,200][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 5.682    Value Loss: 3.235    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 174404     Buffer Size: 110560     Transition Number: 1200.063k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:36:49,733][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.491    [weighted Loss:1.491    Policy Loss: 4.623    Value Loss: 3.212    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 175637     Buffer Size: 105531     Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:40:40,202][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 3.951    Value Loss: 3.522    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 176818     Buffer Size: 100955     Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:44:36,523][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 3.573    Value Loss: 3.422    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 177947     Buffer Size: 95805      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:48:29,404][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.417    [weighted Loss:1.417    Policy Loss: 3.085    Value Loss: 3.516    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 179095     Buffer Size: 88921      Transition Number: 1200.225k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:52:20,880][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.403    [weighted Loss:1.403    Policy Loss: 2.929    Value Loss: 3.630    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 180090     Buffer Size: 82632      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-21 21:56:09,373][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 3.301    Value Loss: 3.459    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 181193     Buffer Size: 74989      Transition Number: 1200.184k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:00:04,569][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.084    [weighted Loss:1.084    Policy Loss: 3.045    Value Loss: 3.461    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 182225     Buffer Size: 67846      Transition Number: 1200.097k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:03:54,567][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.030    [weighted Loss:1.030    Policy Loss: 3.577    Value Loss: 3.567    Reward Loss: 0.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 183358     Buffer Size: 60127      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:07:44,035][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.039    [weighted Loss:1.039    Policy Loss: 3.164    Value Loss: 3.412    Reward Loss: 0.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 184497     Buffer Size: 53511      Transition Number: 1200.087k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:11:33,608][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 3.631    Value Loss: 3.775    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 185569     Buffer Size: 47414      Transition Number: 1200.143k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:15:29,668][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 3.385    Value Loss: 3.626    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 186630     Buffer Size: 41530      Transition Number: 1200.044k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:19:20,782][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 3.792    Value Loss: 3.738    Reward Loss: 0.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 187765     Buffer Size: 35439      Transition Number: 1200.122k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:23:09,095][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.356    [weighted Loss:1.356    Policy Loss: 3.673    Value Loss: 3.811    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 188953     Buffer Size: 30461      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:27:00,182][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.876    Value Loss: 3.929    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 190109     Buffer Size: 25791      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:30:55,053][train][INFO][train.py>_log] ==> #41000      Total Loss: 0.868    [weighted Loss:0.868    Policy Loss: 3.994    Value Loss: 4.067    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 191197     Buffer Size: 22972      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:34:43,899][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 3.820    Value Loss: 3.944    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 192304     Buffer Size: 20539      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:38:34,501][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.457    [weighted Loss:1.457    Policy Loss: 4.101    Value Loss: 3.914    Reward Loss: 0.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 193383     Buffer Size: 20105      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:42:23,760][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 4.376    Value Loss: 4.089    Reward Loss: 0.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 194487     Buffer Size: 19758      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:46:21,239][train][INFO][train.py>_log] ==> #45000      Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 4.619    Value Loss: 3.921    Reward Loss: 0.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 195586     Buffer Size: 19753      Transition Number: 1200.808k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:50:08,952][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.419    [weighted Loss:1.419    Policy Loss: 4.499    Value Loss: 3.967    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 196729     Buffer Size: 19697      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:53:57,480][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 4.763    Value Loss: 4.121    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 197890     Buffer Size: 19748      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-21 22:57:44,268][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 4.195    Value Loss: 4.003    Reward Loss: 0.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 199008     Buffer Size: 19819      Transition Number: 1200.042k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:01:41,285][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 4.314    Value Loss: 4.078    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 200063     Buffer Size: 19886      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:05:28,715][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 4.648    Value Loss: 3.871    Reward Loss: 0.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 201158     Buffer Size: 19919      Transition Number: 1199.941k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:09:18,198][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 5.324    Value Loss: 4.007    Reward Loss: 0.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 202288     Buffer Size: 19954      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:13:06,799][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 4.699    Value Loss: 3.985    Reward Loss: 0.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 203361     Buffer Size: 20019      Transition Number: 1199.946k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:16:59,972][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 4.633    Value Loss: 4.080    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 204564     Buffer Size: 20118      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:20:47,938][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.269    [weighted Loss:1.269    Policy Loss: 4.791    Value Loss: 4.264    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 205758     Buffer Size: 20172      Transition Number: 1199.930k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:24:35,377][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 5.089    Value Loss: 4.054    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 206968     Buffer Size: 20284      Transition Number: 1200.195k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:28:24,988][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.102    [weighted Loss:2.102    Policy Loss: 4.553    Value Loss: 4.236    Reward Loss: 0.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 208215     Buffer Size: 20398      Transition Number: 1199.932k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:32:18,718][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.350    [weighted Loss:2.350    Policy Loss: 4.411    Value Loss: 4.447    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 209251     Buffer Size: 20471      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:36:08,278][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 4.296    Value Loss: 4.323    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 210319     Buffer Size: 20482      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:39:58,846][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.636    [weighted Loss:1.636    Policy Loss: 4.604    Value Loss: 4.437    Reward Loss: 0.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 211732     Buffer Size: 20717      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:43:47,541][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 4.070    Value Loss: 4.438    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 213073     Buffer Size: 20930      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:47:44,733][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 4.620    Value Loss: 4.584    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 214322     Buffer Size: 21059      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:51:33,589][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 3.751    Value Loss: 4.558    Reward Loss: 0.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 215441     Buffer Size: 21176      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:55:23,992][train][INFO][train.py>_log] ==> #63000      Total Loss: 1.415    [weighted Loss:1.415    Policy Loss: 3.586    Value Loss: 4.399    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 216560     Buffer Size: 21146      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-21 23:59:12,549][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 3.799    Value Loss: 4.400    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 217716     Buffer Size: 21100      Transition Number: 1199.946k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:03:06,615][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 3.838    Value Loss: 4.124    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 218836     Buffer Size: 21084      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:06:54,187][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 3.638    Value Loss: 4.583    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 219956     Buffer Size: 21063      Transition Number: 1200.014k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:10:43,557][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 3.210    Value Loss: 4.330    Reward Loss: 0.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 220933     Buffer Size: 21038      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:14:32,409][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 3.283    Value Loss: 4.450    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 222012     Buffer Size: 21014      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:18:26,921][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 3.295    Value Loss: 4.332    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 223000     Buffer Size: 20954      Transition Number: 1199.953k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:22:15,552][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.491    [weighted Loss:1.491    Policy Loss: 3.650    Value Loss: 4.175    Reward Loss: 0.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 224080     Buffer Size: 20890      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:26:07,393][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 3.249    Value Loss: 4.262    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 225126     Buffer Size: 20702      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:29:55,995][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 3.485    Value Loss: 4.488    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 226254     Buffer Size: 20446      Transition Number: 1200.188k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:33:53,732][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.626    [weighted Loss:1.626    Policy Loss: 3.286    Value Loss: 4.391    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 227280     Buffer Size: 20194      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:37:42,889][train][INFO][train.py>_log] ==> #74000      Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 3.412    Value Loss: 4.310    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 228405     Buffer Size: 19914      Transition Number: 1200.209k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:41:31,638][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.082    [weighted Loss:2.082    Policy Loss: 3.456    Value Loss: 4.475    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 229468     Buffer Size: 19806      Transition Number: 1200.748k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:45:20,848][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 3.315    Value Loss: 4.563    Reward Loss: 0.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 230517     Buffer Size: 19667      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:49:14,402][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.887    [weighted Loss:1.887    Policy Loss: 3.033    Value Loss: 4.213    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 231594     Buffer Size: 19320      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:53:04,770][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.670    [weighted Loss:1.670    Policy Loss: 3.022    Value Loss: 4.334    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 232585     Buffer Size: 19025      Transition Number: 1200.058k Batch Size: 256        Lr: 0.10000 
[2022-01-22 00:56:53,636][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 3.031    Value Loss: 4.203    Reward Loss: 0.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 233652     Buffer Size: 18828      Transition Number: 1199.936k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:00:42,419][train][INFO][train.py>_log] ==> #80000      Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 3.279    Value Loss: 4.169    Reward Loss: 0.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 234692     Buffer Size: 18706      Transition Number: 1199.953k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:04:37,079][train][INFO][train.py>_log] ==> #81000      Total Loss: 1.292    [weighted Loss:1.292    Policy Loss: 3.125    Value Loss: 4.143    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 235790     Buffer Size: 18698      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:08:26,108][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.845    [weighted Loss:1.845    Policy Loss: 3.208    Value Loss: 4.298    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 236868     Buffer Size: 18641      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:12:15,111][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 3.282    Value Loss: 4.521    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 237906     Buffer Size: 18546      Transition Number: 1200.234k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:16:03,335][train][INFO][train.py>_log] ==> #84000      Total Loss: 1.943    [weighted Loss:1.943    Policy Loss: 3.461    Value Loss: 4.283    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 238970     Buffer Size: 18475      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:19:58,821][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.081    [weighted Loss:1.081    Policy Loss: 3.245    Value Loss: 4.132    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 240018     Buffer Size: 18438      Transition Number: 1200.207k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:23:46,443][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.665    [weighted Loss:1.665    Policy Loss: 2.952    Value Loss: 4.292    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 241046     Buffer Size: 18406      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:27:36,347][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.527    [weighted Loss:1.527    Policy Loss: 2.860    Value Loss: 4.019    Reward Loss: 0.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 242141     Buffer Size: 18341      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:31:24,720][train][INFO][train.py>_log] ==> #88000      Total Loss: 1.548    [weighted Loss:1.548    Policy Loss: 2.941    Value Loss: 4.168    Reward Loss: 0.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 243266     Buffer Size: 18291      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:35:19,463][train][INFO][train.py>_log] ==> #89000      Total Loss: 1.384    [weighted Loss:1.384    Policy Loss: 3.045    Value Loss: 4.198    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 244348     Buffer Size: 18242      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:39:09,848][train][INFO][train.py>_log] ==> #90000      Total Loss: 1.289    [weighted Loss:1.289    Policy Loss: 2.910    Value Loss: 4.055    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 245368     Buffer Size: 18223      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:43:00,246][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.572    [weighted Loss:1.572    Policy Loss: 3.245    Value Loss: 4.150    Reward Loss: 0.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 246373     Buffer Size: 18170      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:46:51,224][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.331    [weighted Loss:1.331    Policy Loss: 3.079    Value Loss: 3.903    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 247393     Buffer Size: 18086      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:50:47,276][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 2.953    Value Loss: 4.166    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 248532     Buffer Size: 18072      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:54:37,393][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.722    [weighted Loss:1.722    Policy Loss: 3.094    Value Loss: 3.863    Reward Loss: 0.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 249678     Buffer Size: 18045      Transition Number: 1200.042k Batch Size: 256        Lr: 0.10000 
[2022-01-22 01:58:25,428][train][INFO][train.py>_log] ==> #95000      Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 3.468    Value Loss: 4.098    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 250830     Buffer Size: 18058      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:02:14,508][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 3.105    Value Loss: 4.088    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 251911     Buffer Size: 18060      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:06:08,885][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 3.201    Value Loss: 3.987    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 252942     Buffer Size: 18009      Transition Number: 1200.322k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:09:58,625][train][INFO][train.py>_log] ==> #98000      Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 3.447    Value Loss: 4.058    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 253984     Buffer Size: 17908      Transition Number: 1199.933k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:13:49,112][train][INFO][train.py>_log] ==> #99000      Total Loss: 0.923    [weighted Loss:0.923    Policy Loss: 3.571    Value Loss: 4.159    Reward Loss: 0.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 255087     Buffer Size: 17832      Transition Number: 1200.156k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:17:42,184][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 3.289    Value Loss: 4.208    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 256127     Buffer Size: 17800      Transition Number: 1200.553k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:21:40,865][train][INFO][train.py>_log] ==> #101000     Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 3.493    Value Loss: 4.166    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 257148     Buffer Size: 17795      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:25:31,268][train][INFO][train.py>_log] ==> #102000     Total Loss: 0.767    [weighted Loss:0.767    Policy Loss: 3.386    Value Loss: 3.970    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 258260     Buffer Size: 17828      Transition Number: 1199.959k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:29:19,957][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 3.355    Value Loss: 4.336    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 259250     Buffer Size: 17861      Transition Number: 1199.941k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:33:13,346][train][INFO][train.py>_log] ==> #104000     Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 3.135    Value Loss: 4.504    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 260346     Buffer Size: 17912      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:37:07,982][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 3.129    Value Loss: 4.652    Reward Loss: 0.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 261461     Buffer Size: 17949      Transition Number: 1200.185k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:40:57,495][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.230    [weighted Loss:1.230    Policy Loss: 3.103    Value Loss: 4.268    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 262443     Buffer Size: 17978      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:44:45,872][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 2.935    Value Loss: 4.542    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 263512     Buffer Size: 18022      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:48:34,839][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.407    [weighted Loss:1.407    Policy Loss: 2.887    Value Loss: 4.230    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 264596     Buffer Size: 18069      Transition Number: 1200.113k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:52:33,542][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.510    [weighted Loss:1.510    Policy Loss: 2.729    Value Loss: 4.406    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 265613     Buffer Size: 18125      Transition Number: 1200.006k Batch Size: 256        Lr: 0.10000 
[2022-01-22 02:56:21,646][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.472    [weighted Loss:1.472    Policy Loss: 2.890    Value Loss: 4.253    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 266681     Buffer Size: 18089      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:00:12,647][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.614    [weighted Loss:1.614    Policy Loss: 2.965    Value Loss: 4.414    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 267805     Buffer Size: 18114      Transition Number: 1200.037k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:04:05,676][train][INFO][train.py>_log] ==> #112000     Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 2.653    Value Loss: 4.257    Reward Loss: 0.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 268915     Buffer Size: 18101      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:08:00,623][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.169    [weighted Loss:1.169    Policy Loss: 2.802    Value Loss: 4.258    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 269851     Buffer Size: 18059      Transition Number: 1200.032k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:11:48,355][train][INFO][train.py>_log] ==> #114000     Total Loss: 0.734    [weighted Loss:0.734    Policy Loss: 3.246    Value Loss: 4.314    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 270888     Buffer Size: 18058      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:15:38,543][train][INFO][train.py>_log] ==> #115000     Total Loss: 1.584    [weighted Loss:1.584    Policy Loss: 3.102    Value Loss: 4.258    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 271972     Buffer Size: 18081      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:19:28,221][train][INFO][train.py>_log] ==> #116000     Total Loss: 1.083    [weighted Loss:1.083    Policy Loss: 2.993    Value Loss: 4.291    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 273063     Buffer Size: 18092      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:23:23,959][train][INFO][train.py>_log] ==> #117000     Total Loss: 0.362    [weighted Loss:0.362    Policy Loss: 3.260    Value Loss: 4.275    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 274184     Buffer Size: 18149      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:27:12,462][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.898    [weighted Loss:1.898    Policy Loss: 3.141    Value Loss: 4.383    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 275135     Buffer Size: 18221      Transition Number: 1199.983k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:30:59,849][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 2.899    Value Loss: 4.256    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 276170     Buffer Size: 18213      Transition Number: 1200.398k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:34:51,539][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 3.286    Value Loss: 4.221    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 277238     Buffer Size: 18176      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:38:46,082][train][INFO][train.py>_log] ==> #121000     Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 3.254    Value Loss: 4.490    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 278334     Buffer Size: 18155      Transition Number: 1199.959k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:42:37,356][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 3.295    Value Loss: 4.001    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 279417     Buffer Size: 18140      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:46:27,053][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.261    [weighted Loss:1.261    Policy Loss: 3.512    Value Loss: 4.214    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 280550     Buffer Size: 18171      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:50:17,767][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 3.375    Value Loss: 4.106    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 281634     Buffer Size: 18189      Transition Number: 1200.064k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:54:15,887][train][INFO][train.py>_log] ==> #125000     Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 3.923    Value Loss: 4.208    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 282718     Buffer Size: 18235      Transition Number: 1200.166k Batch Size: 256        Lr: 0.10000 
[2022-01-22 03:58:05,997][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 3.366    Value Loss: 4.174    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 283778     Buffer Size: 18251      Transition Number: 1200.047k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:01:58,010][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 4.002    Value Loss: 4.679    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 284932     Buffer Size: 18313      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:05:48,474][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.283    [weighted Loss:1.283    Policy Loss: 3.649    Value Loss: 4.288    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 286078     Buffer Size: 18359      Transition Number: 1199.936k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:09:42,723][train][INFO][train.py>_log] ==> #129000     Total Loss: 1.012    [weighted Loss:1.012    Policy Loss: 3.262    Value Loss: 4.260    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 287158     Buffer Size: 18387      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:13:32,039][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.943    [weighted Loss:1.943    Policy Loss: 3.337    Value Loss: 4.246    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 288226     Buffer Size: 18452      Transition Number: 1200.100k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:17:22,865][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 3.412    Value Loss: 4.308    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 289319     Buffer Size: 18514      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:21:14,519][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 3.576    Value Loss: 4.182    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 290421     Buffer Size: 18559      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:25:11,151][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 3.005    Value Loss: 4.313    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 291427     Buffer Size: 18586      Transition Number: 1200.164k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:29:00,272][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.052    [weighted Loss:1.052    Policy Loss: 3.639    Value Loss: 4.450    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 292508     Buffer Size: 18567      Transition Number: 1200.499k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:32:50,620][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 3.267    Value Loss: 4.106    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 293573     Buffer Size: 18535      Transition Number: 1200.072k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:36:40,010][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 3.536    Value Loss: 4.385    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 294679     Buffer Size: 18562      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:40:35,609][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.683    [weighted Loss:1.683    Policy Loss: 3.367    Value Loss: 4.433    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 295794     Buffer Size: 18574      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:44:24,579][train][INFO][train.py>_log] ==> #138000     Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 3.396    Value Loss: 4.689    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 296868     Buffer Size: 18592      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:48:16,747][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 3.276    Value Loss: 4.196    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 297968     Buffer Size: 18616      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:52:08,380][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 3.077    Value Loss: 4.136    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 299066     Buffer Size: 18614      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:56:05,167][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 3.084    Value Loss: 4.290    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 300164     Buffer Size: 18604      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-22 04:59:55,529][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.480    [weighted Loss:1.480    Policy Loss: 3.150    Value Loss: 4.312    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 301302     Buffer Size: 18575      Transition Number: 1200.004k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:03:45,438][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 3.550    Value Loss: 4.286    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 302428     Buffer Size: 18562      Transition Number: 1199.935k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:07:35,268][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 3.119    Value Loss: 4.281    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 303541     Buffer Size: 18506      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:11:33,590][train][INFO][train.py>_log] ==> #145000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 2.886    Value Loss: 4.237    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 304704     Buffer Size: 18520      Transition Number: 1200.411k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:15:24,307][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 3.190    Value Loss: 4.061    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 305840     Buffer Size: 18543      Transition Number: 1200.235k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:19:18,441][train][INFO][train.py>_log] ==> #147000     Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 3.140    Value Loss: 4.269    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 306974     Buffer Size: 18546      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:23:08,420][train][INFO][train.py>_log] ==> #148000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 3.389    Value Loss: 4.272    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 308105     Buffer Size: 18576      Transition Number: 1200.365k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:27:05,962][train][INFO][train.py>_log] ==> #149000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 3.366    Value Loss: 4.043    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 309223     Buffer Size: 18560      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:30:59,778][train][INFO][train.py>_log] ==> #150000     Total Loss: 1.046    [weighted Loss:1.046    Policy Loss: 3.252    Value Loss: 4.394    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 310418     Buffer Size: 18594      Transition Number: 1200.636k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:34:50,834][train][INFO][train.py>_log] ==> #151000     Total Loss: 1.364    [weighted Loss:1.364    Policy Loss: 3.105    Value Loss: 4.283    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 311557     Buffer Size: 18575      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:38:44,105][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 3.316    Value Loss: 4.492    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 312710     Buffer Size: 18556      Transition Number: 1200.040k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:42:40,593][train][INFO][train.py>_log] ==> #153000     Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 3.105    Value Loss: 4.174    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 313843     Buffer Size: 18596      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:46:33,164][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 3.259    Value Loss: 4.129    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 314947     Buffer Size: 18649      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:50:22,615][train][INFO][train.py>_log] ==> #155000     Total Loss: 1.466    [weighted Loss:1.466    Policy Loss: 2.984    Value Loss: 3.928    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 316052     Buffer Size: 18639      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:54:11,761][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.677    [weighted Loss:1.677    Policy Loss: 3.456    Value Loss: 4.185    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 317156     Buffer Size: 18628      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-22 05:58:09,153][train][INFO][train.py>_log] ==> #157000     Total Loss: 1.757    [weighted Loss:1.757    Policy Loss: 3.249    Value Loss: 4.263    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 318262     Buffer Size: 18639      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:01:59,716][train][INFO][train.py>_log] ==> #158000     Total Loss: 1.730    [weighted Loss:1.730    Policy Loss: 3.152    Value Loss: 4.384    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 319333     Buffer Size: 18668      Transition Number: 1200.185k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:05:53,775][train][INFO][train.py>_log] ==> #159000     Total Loss: 1.264    [weighted Loss:1.264    Policy Loss: 3.123    Value Loss: 4.089    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 320423     Buffer Size: 18684      Transition Number: 1199.946k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:09:44,568][train][INFO][train.py>_log] ==> #160000     Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 3.366    Value Loss: 4.224    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 321565     Buffer Size: 18703      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:13:40,200][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 3.404    Value Loss: 4.505    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 322746     Buffer Size: 18782      Transition Number: 1200.003k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:17:29,224][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.085    [weighted Loss:2.085    Policy Loss: 3.390    Value Loss: 4.268    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 323920     Buffer Size: 18824      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:21:18,035][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 3.372    Value Loss: 4.606    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 325000     Buffer Size: 18832      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:25:09,466][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.447    [weighted Loss:1.447    Policy Loss: 3.815    Value Loss: 4.068    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 326109     Buffer Size: 18847      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:29:07,422][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.887    [weighted Loss:1.887    Policy Loss: 3.590    Value Loss: 4.608    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 327357     Buffer Size: 18968      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:33:00,651][train][INFO][train.py>_log] ==> #166000     Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 2.772    Value Loss: 4.986    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 328621     Buffer Size: 19119      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:36:49,933][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.349    [weighted Loss:1.349    Policy Loss: 3.115    Value Loss: 4.606    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 329723     Buffer Size: 19148      Transition Number: 1200.739k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:40:41,739][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 3.306    Value Loss: 4.635    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 330857     Buffer Size: 19174      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:44:37,698][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.941    [weighted Loss:1.941    Policy Loss: 3.221    Value Loss: 4.624    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 331934     Buffer Size: 19172      Transition Number: 1200.213k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:48:26,437][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.249    [weighted Loss:1.249    Policy Loss: 2.860    Value Loss: 4.366    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 333041     Buffer Size: 19124      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:52:15,920][train][INFO][train.py>_log] ==> #171000     Total Loss: 2.385    [weighted Loss:2.385    Policy Loss: 3.486    Value Loss: 4.625    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 334146     Buffer Size: 19087      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-22 06:56:07,288][train][INFO][train.py>_log] ==> #172000     Total Loss: 1.669    [weighted Loss:1.669    Policy Loss: 2.824    Value Loss: 4.164    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 335279     Buffer Size: 19109      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:00:02,695][train][INFO][train.py>_log] ==> #173000     Total Loss: 0.762    [weighted Loss:0.762    Policy Loss: 2.862    Value Loss: 4.227    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 336407     Buffer Size: 19106      Transition Number: 1199.950k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:03:54,558][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 3.438    Value Loss: 4.223    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 337532     Buffer Size: 19080      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:07:46,116][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 3.407    Value Loss: 4.247    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 338647     Buffer Size: 19066      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:11:37,839][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 3.049    Value Loss: 4.809    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 339770     Buffer Size: 19062      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:15:36,985][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 3.557    Value Loss: 4.222    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 340872     Buffer Size: 19055      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:19:26,439][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 3.445    Value Loss: 4.223    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 342000     Buffer Size: 18952      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:23:17,373][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 3.905    Value Loss: 4.393    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 343135     Buffer Size: 18870      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:27:06,576][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 3.540    Value Loss: 4.459    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 344234     Buffer Size: 18852      Transition Number: 1200.127k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:31:03,452][train][INFO][train.py>_log] ==> #181000     Total Loss: 1.296    [weighted Loss:1.296    Policy Loss: 2.867    Value Loss: 4.270    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 345295     Buffer Size: 18776      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:34:52,738][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 3.187    Value Loss: 4.481    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 346410     Buffer Size: 18630      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:38:45,646][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 3.549    Value Loss: 4.372    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 347534     Buffer Size: 18521      Transition Number: 1200.012k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:42:38,664][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 4.048    Value Loss: 4.300    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 348673     Buffer Size: 18506      Transition Number: 1199.944k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:46:33,989][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 3.918    Value Loss: 4.313    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 349903     Buffer Size: 18619      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:50:24,038][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.901    [weighted Loss:1.901    Policy Loss: 4.278    Value Loss: 4.236    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 351140     Buffer Size: 18754      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:54:13,781][train][INFO][train.py>_log] ==> #187000     Total Loss: 1.999    [weighted Loss:1.999    Policy Loss: 4.130    Value Loss: 4.538    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 352498     Buffer Size: 19021      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-22 07:58:05,636][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 3.799    Value Loss: 4.501    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 353807     Buffer Size: 19280      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:02:02,862][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.712    [weighted Loss:1.712    Policy Loss: 4.102    Value Loss: 4.647    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 354934     Buffer Size: 19366      Transition Number: 1200.107k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:05:52,294][train][INFO][train.py>_log] ==> #190000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 3.443    Value Loss: 4.721    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 356033     Buffer Size: 19448      Transition Number: 1200.379k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:09:43,927][train][INFO][train.py>_log] ==> #191000     Total Loss: 1.442    [weighted Loss:1.442    Policy Loss: 3.341    Value Loss: 4.431    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 357095     Buffer Size: 19460      Transition Number: 1199.933k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:13:34,595][train][INFO][train.py>_log] ==> #192000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 3.078    Value Loss: 4.738    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 358192     Buffer Size: 19471      Transition Number: 1200.323k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:17:32,158][train][INFO][train.py>_log] ==> #193000     Total Loss: 1.974    [weighted Loss:1.974    Policy Loss: 3.545    Value Loss: 4.517    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 359266     Buffer Size: 19464      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:21:23,790][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 3.461    Value Loss: 4.732    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 360364     Buffer Size: 19468      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:25:15,437][train][INFO][train.py>_log] ==> #195000     Total Loss: 1.829    [weighted Loss:1.829    Policy Loss: 3.259    Value Loss: 4.438    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 361444     Buffer Size: 19460      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:29:09,948][train][INFO][train.py>_log] ==> #196000     Total Loss: 1.661    [weighted Loss:1.661    Policy Loss: 3.040    Value Loss: 4.247    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 362591     Buffer Size: 19430      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:33:07,345][train][INFO][train.py>_log] ==> #197000     Total Loss: 1.551    [weighted Loss:1.551    Policy Loss: 3.368    Value Loss: 4.617    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 363669     Buffer Size: 19386      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:36:57,833][train][INFO][train.py>_log] ==> #198000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 3.817    Value Loss: 4.258    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 364794     Buffer Size: 19344      Transition Number: 1200.046k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:40:46,385][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.280    [weighted Loss:1.280    Policy Loss: 3.457    Value Loss: 4.214    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 365913     Buffer Size: 19348      Transition Number: 1199.952k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:44:37,567][train][INFO][train.py>_log] ==> #200000     Total Loss: 1.632    [weighted Loss:1.632    Policy Loss: 4.149    Value Loss: 4.896    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 366970     Buffer Size: 19356      Transition Number: 1200.051k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:48:36,047][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.226    [weighted Loss:1.226    Policy Loss: 3.189    Value Loss: 4.357    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 368074     Buffer Size: 19364      Transition Number: 1200.088k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:52:26,291][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.238    [weighted Loss:1.238    Policy Loss: 3.366    Value Loss: 4.352    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 369189     Buffer Size: 19243      Transition Number: 1199.932k Batch Size: 256        Lr: 0.10000 
[2022-01-22 08:56:18,570][train][INFO][train.py>_log] ==> #203000     Total Loss: 1.534    [weighted Loss:1.534    Policy Loss: 3.824    Value Loss: 4.329    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 370274     Buffer Size: 19152      Transition Number: 1200.099k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:00:10,330][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 3.110    Value Loss: 4.585    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 371365     Buffer Size: 18902      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:04:06,762][train][INFO][train.py>_log] ==> #205000     Total Loss: 1.773    [weighted Loss:1.773    Policy Loss: 3.293    Value Loss: 4.595    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 372509     Buffer Size: 18650      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:07:57,210][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 4.087    Value Loss: 4.770    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 373622     Buffer Size: 18587      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:11:46,179][train][INFO][train.py>_log] ==> #207000     Total Loss: 1.271    [weighted Loss:1.271    Policy Loss: 4.542    Value Loss: 4.447    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 375144     Buffer Size: 18965      Transition Number: 1199.937k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:15:33,880][train][INFO][train.py>_log] ==> #208000     Total Loss: 1.183    [weighted Loss:1.183    Policy Loss: 4.185    Value Loss: 4.677    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 376577     Buffer Size: 19425      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:19:28,451][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 4.347    Value Loss: 4.774    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 377760     Buffer Size: 19538      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:23:17,212][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 4.462    Value Loss: 4.781    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 378981     Buffer Size: 19663      Transition Number: 1200.198k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:27:06,517][train][INFO][train.py>_log] ==> #211000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 4.560    Value Loss: 4.514    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 380096     Buffer Size: 19712      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:30:57,117][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 4.683    Value Loss: 4.475    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 381248     Buffer Size: 19784      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:34:53,155][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 4.736    Value Loss: 4.708    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 382407     Buffer Size: 19917      Transition Number: 1200.096k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:38:40,643][train][INFO][train.py>_log] ==> #214000     Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 3.929    Value Loss: 4.721    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 383524     Buffer Size: 20052      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:42:31,783][train][INFO][train.py>_log] ==> #215000     Total Loss: 1.794    [weighted Loss:1.794    Policy Loss: 4.214    Value Loss: 4.992    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 384509     Buffer Size: 20107      Transition Number: 1200.228k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:46:23,376][train][INFO][train.py>_log] ==> #216000     Total Loss: 1.390    [weighted Loss:1.390    Policy Loss: 3.951    Value Loss: 5.002    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 385575     Buffer Size: 20119      Transition Number: 1200.161k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:50:19,828][train][INFO][train.py>_log] ==> #217000     Total Loss: 1.674    [weighted Loss:1.674    Policy Loss: 3.510    Value Loss: 4.418    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 386714     Buffer Size: 20108      Transition Number: 1200.020k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:54:12,243][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 4.035    Value Loss: 4.369    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 387854     Buffer Size: 20102      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-22 09:58:00,615][train][INFO][train.py>_log] ==> #219000     Total Loss: 2.112    [weighted Loss:2.112    Policy Loss: 4.267    Value Loss: 4.704    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 389000     Buffer Size: 20111      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:01:49,564][train][INFO][train.py>_log] ==> #220000     Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 3.962    Value Loss: 4.930    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 390104     Buffer Size: 20138      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:05:45,203][train][INFO][train.py>_log] ==> #221000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 4.187    Value Loss: 4.810    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 391173     Buffer Size: 20145      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:09:36,116][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 4.039    Value Loss: 4.782    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 392309     Buffer Size: 20151      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:13:27,991][train][INFO][train.py>_log] ==> #223000     Total Loss: 1.667    [weighted Loss:1.667    Policy Loss: 3.397    Value Loss: 4.650    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 393452     Buffer Size: 20162      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:17:17,682][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.711    [weighted Loss:1.711    Policy Loss: 3.891    Value Loss: 4.373    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 394579     Buffer Size: 19881      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:21:16,233][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 3.965    Value Loss: 4.549    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 395687     Buffer Size: 19382      Transition Number: 1200.070k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:25:09,540][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 4.059    Value Loss: 4.463    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 396796     Buffer Size: 19229      Transition Number: 1200.365k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:28:58,416][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 4.832    Value Loss: 4.444    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 397814     Buffer Size: 19151      Transition Number: 1200.351k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:32:50,870][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 4.455    Value Loss: 4.560    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 398902     Buffer Size: 19115      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:36:48,600][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 5.661    Value Loss: 4.363    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 400044     Buffer Size: 19113      Transition Number: 1199.950k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:40:37,616][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 4.531    Value Loss: 4.529    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 401161     Buffer Size: 19072      Transition Number: 1199.953k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:44:28,522][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 4.330    Value Loss: 4.983    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 402393     Buffer Size: 19111      Transition Number: 1200.246k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:48:17,733][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 4.646    Value Loss: 4.781    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 403592     Buffer Size: 19220      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:52:15,201][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 4.391    Value Loss: 4.752    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 404684     Buffer Size: 19337      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:56:06,803][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 4.944    Value Loss: 4.811    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 405885     Buffer Size: 19479      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 10:59:56,011][train][INFO][train.py>_log] ==> #235000     Total Loss: 0.715    [weighted Loss:0.715    Policy Loss: 3.780    Value Loss: 4.839    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 407072     Buffer Size: 19564      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:03:43,729][train][INFO][train.py>_log] ==> #236000     Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 3.674    Value Loss: 4.931    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 408245     Buffer Size: 19645      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:07:40,629][train][INFO][train.py>_log] ==> #237000     Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 3.640    Value Loss: 4.371    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 409312     Buffer Size: 19628      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:11:32,899][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 5.118    Value Loss: 4.769    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 410403     Buffer Size: 19609      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:15:22,542][train][INFO][train.py>_log] ==> #239000     Total Loss: 1.953    [weighted Loss:1.953    Policy Loss: 4.735    Value Loss: 4.773    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 411662     Buffer Size: 19768      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:19:09,688][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.110    [weighted Loss:2.110    Policy Loss: 4.210    Value Loss: 5.035    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 412800     Buffer Size: 19900      Transition Number: 1200.303k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:23:05,692][train][INFO][train.py>_log] ==> #241000     Total Loss: 1.376    [weighted Loss:1.376    Policy Loss: 4.037    Value Loss: 5.172    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 414068     Buffer Size: 20074      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:26:55,237][train][INFO][train.py>_log] ==> #242000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 3.848    Value Loss: 5.130    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 415296     Buffer Size: 20249      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:30:47,914][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 3.904    Value Loss: 5.147    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 416423     Buffer Size: 20351      Transition Number: 1200.136k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:34:37,466][train][INFO][train.py>_log] ==> #244000     Total Loss: 0.655    [weighted Loss:0.655    Policy Loss: 4.418    Value Loss: 4.815    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 417565     Buffer Size: 20424      Transition Number: 1200.491k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:38:33,455][train][INFO][train.py>_log] ==> #245000     Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 3.303    Value Loss: 4.993    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 418594     Buffer Size: 20407      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:42:26,894][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 4.074    Value Loss: 5.154    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 419713     Buffer Size: 20381      Transition Number: 1200.063k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:46:16,269][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 3.617    Value Loss: 4.800    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 420846     Buffer Size: 20324      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:50:05,363][train][INFO][train.py>_log] ==> #248000     Total Loss: 1.501    [weighted Loss:1.501    Policy Loss: 3.276    Value Loss: 4.486    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 421874     Buffer Size: 20258      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:54:00,691][train][INFO][train.py>_log] ==> #249000     Total Loss: 0.586    [weighted Loss:0.586    Policy Loss: 3.888    Value Loss: 4.639    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 424175     Buffer Size: 21220      Transition Number: 1200.092k Batch Size: 256        Lr: 0.10000 
[2022-01-22 11:57:51,909][train][INFO][train.py>_log] ==> #250000     Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 3.783    Value Loss: 5.327    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 426418     Buffer Size: 22222      Transition Number: 1200.071k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:01:41,974][train][INFO][train.py>_log] ==> #251000     Total Loss: 2.115    [weighted Loss:2.115    Policy Loss: 3.657    Value Loss: 5.100    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 428078     Buffer Size: 22637      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:05:30,242][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.826    [weighted Loss:1.826    Policy Loss: 4.080    Value Loss: 5.028    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 429664     Buffer Size: 23042      Transition Number: 1200.004k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:09:26,204][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 3.671    Value Loss: 4.863    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 430772     Buffer Size: 23057      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:13:16,441][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.722    [weighted Loss:1.722    Policy Loss: 4.236    Value Loss: 4.811    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 431909     Buffer Size: 23108      Transition Number: 1200.078k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:17:06,283][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 4.718    Value Loss: 4.802    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 433034     Buffer Size: 23211      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:20:57,570][train][INFO][train.py>_log] ==> #256000     Total Loss: 1.649    [weighted Loss:1.649    Policy Loss: 3.568    Value Loss: 4.685    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 434242     Buffer Size: 23282      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:24:54,903][train][INFO][train.py>_log] ==> #257000     Total Loss: 1.718    [weighted Loss:1.718    Policy Loss: 4.044    Value Loss: 4.882    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 435309     Buffer Size: 23158      Transition Number: 1200.287k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:28:47,947][train][INFO][train.py>_log] ==> #258000     Total Loss: 1.987    [weighted Loss:1.987    Policy Loss: 3.503    Value Loss: 4.839    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 436379     Buffer Size: 22992      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:32:38,128][train][INFO][train.py>_log] ==> #259000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 3.932    Value Loss: 4.929    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 437527     Buffer Size: 22823      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:36:28,623][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.618    [weighted Loss:1.618    Policy Loss: 3.348    Value Loss: 4.899    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 438619     Buffer Size: 22705      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:40:25,203][train][INFO][train.py>_log] ==> #261000     Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 3.720    Value Loss: 5.075    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 439714     Buffer Size: 22658      Transition Number: 1200.145k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:44:15,520][train][INFO][train.py>_log] ==> #262000     Total Loss: 1.785    [weighted Loss:1.785    Policy Loss: 3.448    Value Loss: 4.612    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 440844     Buffer Size: 22627      Transition Number: 1199.952k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:48:06,244][train][INFO][train.py>_log] ==> #263000     Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 3.937    Value Loss: 4.791    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 441917     Buffer Size: 22662      Transition Number: 1200.615k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:51:55,170][train][INFO][train.py>_log] ==> #264000     Total Loss: 1.601    [weighted Loss:1.601    Policy Loss: 3.823    Value Loss: 4.843    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 442984     Buffer Size: 22663      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:55:52,117][train][INFO][train.py>_log] ==> #265000     Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 3.523    Value Loss: 4.675    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 444116     Buffer Size: 22687      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-22 12:59:43,552][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 3.612    Value Loss: 4.767    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 445278     Buffer Size: 22168      Transition Number: 1200.037k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:03:33,317][train][INFO][train.py>_log] ==> #267000     Total Loss: 1.469    [weighted Loss:1.469    Policy Loss: 3.459    Value Loss: 4.500    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 446398     Buffer Size: 20929      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:07:22,791][train][INFO][train.py>_log] ==> #268000     Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 4.141    Value Loss: 4.783    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 447538     Buffer Size: 20108      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:11:21,727][train][INFO][train.py>_log] ==> #269000     Total Loss: 1.081    [weighted Loss:1.081    Policy Loss: 3.770    Value Loss: 4.768    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 448632     Buffer Size: 19659      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:15:10,772][train][INFO][train.py>_log] ==> #270000     Total Loss: 1.360    [weighted Loss:1.360    Policy Loss: 3.709    Value Loss: 4.625    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 449702     Buffer Size: 19404      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:19:00,485][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 3.952    Value Loss: 4.630    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 451048     Buffer Size: 19546      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:22:47,746][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 3.827    Value Loss: 4.931    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 452360     Buffer Size: 19675      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:26:44,979][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 3.697    Value Loss: 4.838    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 453571     Buffer Size: 19673      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:30:36,142][train][INFO][train.py>_log] ==> #274000     Total Loss: 1.139    [weighted Loss:1.139    Policy Loss: 3.728    Value Loss: 4.607    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 454742     Buffer Size: 19735      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:34:27,761][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.153    [weighted Loss:2.153    Policy Loss: 3.791    Value Loss: 4.863    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 455804     Buffer Size: 19752      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:38:17,734][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 4.045    Value Loss: 4.588    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 456885     Buffer Size: 19759      Transition Number: 1200.099k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:42:14,399][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.086    [weighted Loss:1.086    Policy Loss: 4.043    Value Loss: 4.637    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 457984     Buffer Size: 19749      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:46:05,941][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.102    [weighted Loss:2.102    Policy Loss: 4.014    Value Loss: 4.607    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 459107     Buffer Size: 19751      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:49:57,374][train][INFO][train.py>_log] ==> #279000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 3.780    Value Loss: 4.672    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 460215     Buffer Size: 19748      Transition Number: 1199.950k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:53:46,977][train][INFO][train.py>_log] ==> #280000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 4.135    Value Loss: 4.738    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 461329     Buffer Size: 19744      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-22 13:57:42,821][train][INFO][train.py>_log] ==> #281000     Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 4.121    Value Loss: 4.589    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 462419     Buffer Size: 19725      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:01:32,248][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.535    [weighted Loss:1.535    Policy Loss: 5.081    Value Loss: 4.658    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 463498     Buffer Size: 19709      Transition Number: 1200.030k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:05:23,180][train][INFO][train.py>_log] ==> #283000     Total Loss: 1.120    [weighted Loss:1.120    Policy Loss: 3.866    Value Loss: 4.565    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 464580     Buffer Size: 19713      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:09:13,864][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.380    [weighted Loss:2.380    Policy Loss: 4.476    Value Loss: 4.654    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 465720     Buffer Size: 19719      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:13:09,464][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 4.356    Value Loss: 4.618    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 466832     Buffer Size: 19711      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:17:00,220][train][INFO][train.py>_log] ==> #286000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 4.115    Value Loss: 4.663    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 467918     Buffer Size: 19695      Transition Number: 1200.204k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:20:49,484][train][INFO][train.py>_log] ==> #287000     Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 4.198    Value Loss: 4.690    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 469042     Buffer Size: 19671      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:24:43,272][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.518    [weighted Loss:1.518    Policy Loss: 3.675    Value Loss: 4.718    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 470123     Buffer Size: 19544      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:28:40,302][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 4.232    Value Loss: 5.079    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 471304     Buffer Size: 19391      Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:32:30,694][train][INFO][train.py>_log] ==> #290000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 4.697    Value Loss: 4.672    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 472438     Buffer Size: 19313      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:36:24,675][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.098    [weighted Loss:1.098    Policy Loss: 4.431    Value Loss: 4.538    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 473575     Buffer Size: 19220      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:40:17,333][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.589    [weighted Loss:1.589    Policy Loss: 4.051    Value Loss: 4.451    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 474700     Buffer Size: 19224      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:44:14,290][train][INFO][train.py>_log] ==> #293000     Total Loss: 1.550    [weighted Loss:1.550    Policy Loss: 4.819    Value Loss: 4.520    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 475849     Buffer Size: 19262      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:48:04,618][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 5.167    Value Loss: 4.591    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 476997     Buffer Size: 19304      Transition Number: 1200.112k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:51:56,876][train][INFO][train.py>_log] ==> #295000     Total Loss: 1.811    [weighted Loss:1.811    Policy Loss: 4.312    Value Loss: 4.684    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 478141     Buffer Size: 19336      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:55:48,450][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.076    [weighted Loss:2.076    Policy Loss: 4.224    Value Loss: 4.823    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 479248     Buffer Size: 19368      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 14:59:43,565][train][INFO][train.py>_log] ==> #297000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 3.896    Value Loss: 4.598    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 480496     Buffer Size: 19519      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:03:35,539][train][INFO][train.py>_log] ==> #298000     Total Loss: 1.247    [weighted Loss:1.247    Policy Loss: 3.629    Value Loss: 4.794    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 481739     Buffer Size: 19706      Transition Number: 1200.055k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:07:30,584][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.115    [weighted Loss:2.115    Policy Loss: 4.205    Value Loss: 4.679    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 482863     Buffer Size: 19748      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:11:28,310][train][INFO][train.py>_log] ==> #300000     Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 4.258    Value Loss: 4.757    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 483945     Buffer Size: 19760      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:15:28,911][train][INFO][train.py>_log] ==> #301000     Total Loss: 1.384    [weighted Loss:1.384    Policy Loss: 3.739    Value Loss: 4.351    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 485072     Buffer Size: 19737      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:19:24,781][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.859    [weighted Loss:1.859    Policy Loss: 3.974    Value Loss: 4.412    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 486215     Buffer Size: 19714      Transition Number: 1200.249k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:23:19,476][train][INFO][train.py>_log] ==> #303000     Total Loss: 1.663    [weighted Loss:1.663    Policy Loss: 3.305    Value Loss: 4.576    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 487375     Buffer Size: 19707      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:27:13,702][train][INFO][train.py>_log] ==> #304000     Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 3.744    Value Loss: 4.772    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 488529     Buffer Size: 19701      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:31:10,916][train][INFO][train.py>_log] ==> #305000     Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 4.223    Value Loss: 4.508    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 489657     Buffer Size: 19697      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:35:04,457][train][INFO][train.py>_log] ==> #306000     Total Loss: 2.075    [weighted Loss:2.075    Policy Loss: 3.465    Value Loss: 4.767    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 490799     Buffer Size: 19632      Transition Number: 1200.316k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:38:58,400][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 3.892    Value Loss: 4.840    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 491961     Buffer Size: 19590      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:42:51,598][train][INFO][train.py>_log] ==> #308000     Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 3.664    Value Loss: 4.548    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 493119     Buffer Size: 19615      Transition Number: 1200.042k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:46:51,271][train][INFO][train.py>_log] ==> #309000     Total Loss: 1.943    [weighted Loss:1.943    Policy Loss: 3.876    Value Loss: 4.810    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 494339     Buffer Size: 19672      Transition Number: 1200.012k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:50:43,605][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 3.623    Value Loss: 4.722    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 495489     Buffer Size: 19712      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:54:40,176][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 3.551    Value Loss: 4.885    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 496594     Buffer Size: 19662      Transition Number: 1200.619k Batch Size: 256        Lr: 0.10000 
[2022-01-22 15:58:32,809][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 4.621    Value Loss: 4.515    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 497711     Buffer Size: 19590      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:02:31,710][train][INFO][train.py>_log] ==> #313000     Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 4.101    Value Loss: 4.599    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 498881     Buffer Size: 19609      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:06:24,924][train][INFO][train.py>_log] ==> #314000     Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 4.050    Value Loss: 4.526    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 500009     Buffer Size: 19503      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:10:15,517][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 3.984    Value Loss: 4.769    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 501150     Buffer Size: 19388      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:14:06,519][train][INFO][train.py>_log] ==> #316000     Total Loss: 0.830    [weighted Loss:0.830    Policy Loss: 3.690    Value Loss: 4.516    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 502281     Buffer Size: 19435      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:18:07,552][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 4.086    Value Loss: 4.846    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 503399     Buffer Size: 19502      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:22:00,636][train][INFO][train.py>_log] ==> #318000     Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 4.929    Value Loss: 4.875    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 504589     Buffer Size: 19598      Transition Number: 1200.099k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:25:51,757][train][INFO][train.py>_log] ==> #319000     Total Loss: 1.457    [weighted Loss:1.457    Policy Loss: 4.485    Value Loss: 5.089    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 505801     Buffer Size: 19772      Transition Number: 1200.066k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:29:46,962][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 4.223    Value Loss: 5.328    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 507034     Buffer Size: 19964      Transition Number: 1200.213k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:33:43,877][train][INFO][train.py>_log] ==> #321000     Total Loss: 1.268    [weighted Loss:1.268    Policy Loss: 4.939    Value Loss: 5.188    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 508308     Buffer Size: 20141      Transition Number: 1199.936k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:37:37,189][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 3.722    Value Loss: 4.863    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 509514     Buffer Size: 20298      Transition Number: 1200.398k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:41:28,735][train][INFO][train.py>_log] ==> #323000     Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 3.763    Value Loss: 5.040    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 510666     Buffer Size: 20339      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:45:24,722][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 3.781    Value Loss: 5.141    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 511783     Buffer Size: 20360      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:49:21,778][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 4.038    Value Loss: 5.233    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 512944     Buffer Size: 20349      Transition Number: 1200.069k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:53:15,136][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.058    [weighted Loss:2.058    Policy Loss: 3.915    Value Loss: 4.962    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 514055     Buffer Size: 20300      Transition Number: 1199.937k Batch Size: 256        Lr: 0.10000 
[2022-01-22 16:57:09,623][train][INFO][train.py>_log] ==> #327000     Total Loss: 1.020    [weighted Loss:1.020    Policy Loss: 4.082    Value Loss: 5.261    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 515625     Buffer Size: 20699      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:01:01,303][train][INFO][train.py>_log] ==> #328000     Total Loss: 1.073    [weighted Loss:1.073    Policy Loss: 3.869    Value Loss: 5.030    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 517245     Buffer Size: 21175      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:05:01,357][train][INFO][train.py>_log] ==> #329000     Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 3.802    Value Loss: 4.905    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 518323     Buffer Size: 21269      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:08:55,183][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.149    [weighted Loss:2.149    Policy Loss: 3.879    Value Loss: 4.832    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 519510     Buffer Size: 21302      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:12:46,898][train][INFO][train.py>_log] ==> #331000     Total Loss: 1.242    [weighted Loss:1.242    Policy Loss: 3.658    Value Loss: 4.804    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 520606     Buffer Size: 21285      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:16:38,906][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 4.379    Value Loss: 5.096    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 521725     Buffer Size: 21269      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:20:38,528][train][INFO][train.py>_log] ==> #333000     Total Loss: 1.974    [weighted Loss:1.974    Policy Loss: 3.481    Value Loss: 4.814    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 522839     Buffer Size: 21204      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:24:34,359][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.092    [weighted Loss:2.092    Policy Loss: 3.853    Value Loss: 4.860    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 524005     Buffer Size: 21142      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:28:26,137][train][INFO][train.py>_log] ==> #335000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 3.641    Value Loss: 5.053    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 525170     Buffer Size: 21099      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:32:19,115][train][INFO][train.py>_log] ==> #336000     Total Loss: 1.506    [weighted Loss:1.506    Policy Loss: 4.002    Value Loss: 4.983    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 526305     Buffer Size: 21009      Transition Number: 1200.139k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:36:19,743][train][INFO][train.py>_log] ==> #337000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 3.522    Value Loss: 4.806    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 527388     Buffer Size: 20830      Transition Number: 1200.249k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:40:16,349][train][INFO][train.py>_log] ==> #338000     Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 3.593    Value Loss: 4.826    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 528525     Buffer Size: 20666      Transition Number: 1200.196k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:44:11,355][train][INFO][train.py>_log] ==> #339000     Total Loss: 1.272    [weighted Loss:1.272    Policy Loss: 3.716    Value Loss: 4.794    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 529670     Buffer Size: 20486      Transition Number: 1199.983k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:48:04,078][train][INFO][train.py>_log] ==> #340000     Total Loss: 1.564    [weighted Loss:1.564    Policy Loss: 4.708    Value Loss: 4.625    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 530746     Buffer Size: 20379      Transition Number: 1200.324k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:52:05,731][train][INFO][train.py>_log] ==> #341000     Total Loss: 1.652    [weighted Loss:1.652    Policy Loss: 4.550    Value Loss: 4.467    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 531867     Buffer Size: 20362      Transition Number: 1200.006k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:56:00,058][train][INFO][train.py>_log] ==> #342000     Total Loss: 1.004    [weighted Loss:1.004    Policy Loss: 4.186    Value Loss: 4.541    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 533058     Buffer Size: 20367      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-22 17:59:55,101][train][INFO][train.py>_log] ==> #343000     Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 4.161    Value Loss: 4.787    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 534228     Buffer Size: 20372      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:03:44,895][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.110    [weighted Loss:2.110    Policy Loss: 4.480    Value Loss: 4.759    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 535295     Buffer Size: 20048      Transition Number: 1200.211k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:07:42,867][train][INFO][train.py>_log] ==> #345000     Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 4.375    Value Loss: 4.880    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 536517     Buffer Size: 19617      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:11:36,687][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.060    [weighted Loss:1.060    Policy Loss: 4.510    Value Loss: 5.109    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 537759     Buffer Size: 19557      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:15:32,065][train][INFO][train.py>_log] ==> #347000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 4.344    Value Loss: 4.740    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 538986     Buffer Size: 19682      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:19:23,467][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.323    [weighted Loss:1.323    Policy Loss: 4.494    Value Loss: 4.778    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 540267     Buffer Size: 19812      Transition Number: 1200.116k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:23:22,281][train][INFO][train.py>_log] ==> #349000     Total Loss: 1.219    [weighted Loss:1.219    Policy Loss: 3.974    Value Loss: 5.143    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 541512     Buffer Size: 19938      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:27:17,782][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 3.970    Value Loss: 4.841    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 542750     Buffer Size: 20071      Transition Number: 1200.349k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:31:11,805][train][INFO][train.py>_log] ==> #351000     Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 3.966    Value Loss: 4.993    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 543919     Buffer Size: 20068      Transition Number: 1200.061k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:35:05,516][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.306    [weighted Loss:2.306    Policy Loss: 4.621    Value Loss: 4.862    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 545083     Buffer Size: 20024      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:39:06,586][train][INFO][train.py>_log] ==> #353000     Total Loss: 1.715    [weighted Loss:1.715    Policy Loss: 4.628    Value Loss: 5.043    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 546666     Buffer Size: 20449      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:42:59,614][train][INFO][train.py>_log] ==> #354000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 4.157    Value Loss: 5.021    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 548254     Buffer Size: 20958      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:46:50,811][train][INFO][train.py>_log] ==> #355000     Total Loss: 2.161    [weighted Loss:2.161    Policy Loss: 4.288    Value Loss: 5.301    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 549598     Buffer Size: 21186      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:50:42,925][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 4.462    Value Loss: 5.114    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 550870     Buffer Size: 21421      Transition Number: 1200.024k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:54:40,847][train][INFO][train.py>_log] ==> #357000     Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 3.562    Value Loss: 5.153    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 551988     Buffer Size: 21445      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-22 18:58:33,349][train][INFO][train.py>_log] ==> #358000     Total Loss: 1.964    [weighted Loss:1.964    Policy Loss: 3.603    Value Loss: 4.942    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 553129     Buffer Size: 21410      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:02:24,217][train][INFO][train.py>_log] ==> #359000     Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 3.360    Value Loss: 5.000    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 554243     Buffer Size: 21346      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:06:12,937][train][INFO][train.py>_log] ==> #360000     Total Loss: 0.981    [weighted Loss:0.981    Policy Loss: 3.563    Value Loss: 4.629    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 555292     Buffer Size: 21304      Transition Number: 1200.057k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:10:06,768][train][INFO][train.py>_log] ==> #361000     Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 3.581    Value Loss: 4.277    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 556364     Buffer Size: 21249      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:13:57,028][train][INFO][train.py>_log] ==> #362000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 3.579    Value Loss: 5.278    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 557498     Buffer Size: 21142      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:17:48,182][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 3.953    Value Loss: 4.683    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 558641     Buffer Size: 21033      Transition Number: 1200.019k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:21:36,043][train][INFO][train.py>_log] ==> #364000     Total Loss: 1.513    [weighted Loss:1.513    Policy Loss: 3.745    Value Loss: 4.877    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 559778     Buffer Size: 20896      Transition Number: 1200.028k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:25:29,787][train][INFO][train.py>_log] ==> #365000     Total Loss: 1.208    [weighted Loss:1.208    Policy Loss: 4.160    Value Loss: 4.485    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 560838     Buffer Size: 20747      Transition Number: 1200.044k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:29:18,613][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 4.025    Value Loss: 4.735    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 561985     Buffer Size: 20589      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:33:09,193][train][INFO][train.py>_log] ==> #367000     Total Loss: 1.147    [weighted Loss:1.147    Policy Loss: 4.113    Value Loss: 4.295    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 563055     Buffer Size: 20453      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:37:00,160][train][INFO][train.py>_log] ==> #368000     Total Loss: 1.329    [weighted Loss:1.329    Policy Loss: 4.205    Value Loss: 4.463    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 564171     Buffer Size: 20426      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:40:58,478][train][INFO][train.py>_log] ==> #369000     Total Loss: 1.325    [weighted Loss:1.325    Policy Loss: 4.596    Value Loss: 4.697    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 565316     Buffer Size: 20439      Transition Number: 1200.051k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:44:49,314][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 4.166    Value Loss: 4.499    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 566449     Buffer Size: 20113      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:48:38,611][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 4.151    Value Loss: 4.665    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 567633     Buffer Size: 19703      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:52:28,650][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 4.317    Value Loss: 5.082    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 568812     Buffer Size: 19498      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-22 19:56:24,413][train][INFO][train.py>_log] ==> #373000     Total Loss: 1.596    [weighted Loss:1.596    Policy Loss: 3.925    Value Loss: 4.726    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 569953     Buffer Size: 19291      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:00:14,492][train][INFO][train.py>_log] ==> #374000     Total Loss: 1.337    [weighted Loss:1.337    Policy Loss: 4.523    Value Loss: 4.540    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 571089     Buffer Size: 19271      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:04:04,574][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 4.110    Value Loss: 4.557    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 572217     Buffer Size: 19308      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:07:56,558][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 4.557    Value Loss: 4.580    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 573334     Buffer Size: 19347      Transition Number: 1200.087k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:11:54,354][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 4.155    Value Loss: 4.842    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 574506     Buffer Size: 19413      Transition Number: 1200.010k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:15:42,911][train][INFO][train.py>_log] ==> #378000     Total Loss: 0.983    [weighted Loss:0.983    Policy Loss: 3.601    Value Loss: 4.596    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 575680     Buffer Size: 19477      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:19:33,011][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 4.628    Value Loss: 4.554    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 576815     Buffer Size: 19512      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:23:22,038][train][INFO][train.py>_log] ==> #380000     Total Loss: 1.977    [weighted Loss:1.977    Policy Loss: 4.649    Value Loss: 4.618    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 577969     Buffer Size: 19519      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:27:17,036][train][INFO][train.py>_log] ==> #381000     Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 4.060    Value Loss: 4.644    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 579105     Buffer Size: 19499      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:31:07,478][train][INFO][train.py>_log] ==> #382000     Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 3.920    Value Loss: 4.793    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 580134     Buffer Size: 19485      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:34:58,995][train][INFO][train.py>_log] ==> #383000     Total Loss: 0.479    [weighted Loss:0.479    Policy Loss: 4.003    Value Loss: 4.613    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 581286     Buffer Size: 19490      Transition Number: 1200.114k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:38:48,218][train][INFO][train.py>_log] ==> #384000     Total Loss: 1.391    [weighted Loss:1.391    Policy Loss: 3.498    Value Loss: 4.543    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 582443     Buffer Size: 19498      Transition Number: 1199.953k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:42:43,534][train][INFO][train.py>_log] ==> #385000     Total Loss: 1.561    [weighted Loss:1.561    Policy Loss: 3.819    Value Loss: 4.441    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 583540     Buffer Size: 19500      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:46:31,704][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 4.017    Value Loss: 4.689    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 584695     Buffer Size: 19518      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:50:22,479][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 3.800    Value Loss: 4.516    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 585818     Buffer Size: 19505      Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:54:12,127][train][INFO][train.py>_log] ==> #388000     Total Loss: 1.473    [weighted Loss:1.473    Policy Loss: 4.005    Value Loss: 4.639    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 586962     Buffer Size: 19398      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-22 20:58:05,668][train][INFO][train.py>_log] ==> #389000     Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 4.050    Value Loss: 4.540    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 588102     Buffer Size: 19317      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:01:55,410][train][INFO][train.py>_log] ==> #390000     Total Loss: 1.744    [weighted Loss:1.744    Policy Loss: 4.590    Value Loss: 4.747    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 589203     Buffer Size: 19326      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:05:47,956][train][INFO][train.py>_log] ==> #391000     Total Loss: 1.922    [weighted Loss:1.922    Policy Loss: 4.109    Value Loss: 4.526    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 590403     Buffer Size: 19377      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:09:37,866][train][INFO][train.py>_log] ==> #392000     Total Loss: 1.619    [weighted Loss:1.619    Policy Loss: 4.244    Value Loss: 4.566    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 591575     Buffer Size: 19410      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:13:34,240][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.115    [weighted Loss:2.115    Policy Loss: 4.200    Value Loss: 4.769    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 592729     Buffer Size: 19419      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:17:23,190][train][INFO][train.py>_log] ==> #394000     Total Loss: 1.782    [weighted Loss:1.782    Policy Loss: 5.165    Value Loss: 4.759    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 593893     Buffer Size: 19390      Transition Number: 1200.120k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:21:12,721][train][INFO][train.py>_log] ==> #395000     Total Loss: 1.138    [weighted Loss:1.138    Policy Loss: 4.355    Value Loss: 4.958    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 595480     Buffer Size: 19840      Transition Number: 1200.006k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:25:02,570][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 5.691    Value Loss: 4.534    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 597035     Buffer Size: 20311      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:28:56,447][train][INFO][train.py>_log] ==> #397000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 5.085    Value Loss: 5.001    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 598438     Buffer Size: 20636      Transition Number: 1200.116k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:32:44,446][train][INFO][train.py>_log] ==> #398000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 4.898    Value Loss: 4.959    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 599791     Buffer Size: 20949      Transition Number: 1199.950k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:36:32,907][train][INFO][train.py>_log] ==> #399000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 4.785    Value Loss: 5.477    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 600845     Buffer Size: 21049      Transition Number: 1200.006k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:40:21,447][train][INFO][train.py>_log] ==> #400000     Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 4.649    Value Loss: 5.422    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 601996     Buffer Size: 21120      Transition Number: 1200.075k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:44:15,916][train][INFO][train.py>_log] ==> #401000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 4.156    Value Loss: 5.119    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 603113     Buffer Size: 21158      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:48:08,064][train][INFO][train.py>_log] ==> #402000     Total Loss: 1.599    [weighted Loss:1.599    Policy Loss: 3.494    Value Loss: 5.097    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 604268     Buffer Size: 21196      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:51:57,975][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 4.373    Value Loss: 5.176    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 605415     Buffer Size: 21221      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:55:48,388][train][INFO][train.py>_log] ==> #404000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 3.818    Value Loss: 5.255    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 606520     Buffer Size: 21275      Transition Number: 1200.172k Batch Size: 256        Lr: 0.10000 
[2022-01-22 21:59:46,452][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 4.212    Value Loss: 5.022    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 607606     Buffer Size: 21300      Transition Number: 1200.286k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:03:40,234][train][INFO][train.py>_log] ==> #406000     Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 4.045    Value Loss: 4.973    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 608623     Buffer Size: 21326      Transition Number: 1200.028k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:07:34,425][train][INFO][train.py>_log] ==> #407000     Total Loss: 0.635    [weighted Loss:0.635    Policy Loss: 4.531    Value Loss: 4.826    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 609766     Buffer Size: 21321      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:11:25,413][train][INFO][train.py>_log] ==> #408000     Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 4.871    Value Loss: 4.879    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 610914     Buffer Size: 21300      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:15:24,649][train][INFO][train.py>_log] ==> #409000     Total Loss: 1.269    [weighted Loss:1.269    Policy Loss: 3.845    Value Loss: 5.093    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 612070     Buffer Size: 21310      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:19:14,055][train][INFO][train.py>_log] ==> #410000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 4.146    Value Loss: 5.080    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 613275     Buffer Size: 21344      Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:23:02,933][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 3.943    Value Loss: 5.576    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 614409     Buffer Size: 21373      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:26:55,645][train][INFO][train.py>_log] ==> #412000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 4.005    Value Loss: 5.063    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 615533     Buffer Size: 21309      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:30:53,446][train][INFO][train.py>_log] ==> #413000     Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 3.584    Value Loss: 5.473    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 616661     Buffer Size: 20790      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:34:46,295][train][INFO][train.py>_log] ==> #414000     Total Loss: 1.157    [weighted Loss:1.157    Policy Loss: 3.538    Value Loss: 5.053    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 617776     Buffer Size: 20377      Transition Number: 1200.310k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:38:38,390][train][INFO][train.py>_log] ==> #415000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 4.451    Value Loss: 4.774    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 618995     Buffer Size: 20161      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:42:29,761][train][INFO][train.py>_log] ==> #416000     Total Loss: 0.766    [weighted Loss:0.766    Policy Loss: 3.526    Value Loss: 4.960    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 620215     Buffer Size: 20040      Transition Number: 1200.072k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:46:28,802][train][INFO][train.py>_log] ==> #417000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 4.125    Value Loss: 4.840    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 621345     Buffer Size: 20023      Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:50:22,441][train][INFO][train.py>_log] ==> #418000     Total Loss: 1.562    [weighted Loss:1.562    Policy Loss: 4.426    Value Loss: 4.784    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 622454     Buffer Size: 20013      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:54:18,994][train][INFO][train.py>_log] ==> #419000     Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 3.555    Value Loss: 4.739    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 623604     Buffer Size: 19945      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-22 22:58:11,089][train][INFO][train.py>_log] ==> #420000     Total Loss: 1.590    [weighted Loss:1.590    Policy Loss: 4.094    Value Loss: 5.068    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 624740     Buffer Size: 19894      Transition Number: 1200.010k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:02:08,813][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 4.450    Value Loss: 4.955    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 625868     Buffer Size: 19871      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:06:00,792][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 3.973    Value Loss: 4.531    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 626980     Buffer Size: 19854      Transition Number: 1200.233k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:09:55,340][train][INFO][train.py>_log] ==> #423000     Total Loss: 0.921    [weighted Loss:0.921    Policy Loss: 4.655    Value Loss: 4.599    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 628071     Buffer Size: 19821      Transition Number: 1200.497k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:13:47,882][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 4.656    Value Loss: 4.889    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 629182     Buffer Size: 19792      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:17:47,262][train][INFO][train.py>_log] ==> #425000     Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 4.557    Value Loss: 4.591    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 630300     Buffer Size: 19785      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:21:40,314][train][INFO][train.py>_log] ==> #426000     Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 4.380    Value Loss: 4.450    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 631452     Buffer Size: 19734      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:25:33,492][train][INFO][train.py>_log] ==> #427000     Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 4.534    Value Loss: 4.532    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 632564     Buffer Size: 19677      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:29:25,482][train][INFO][train.py>_log] ==> #428000     Total Loss: 1.320    [weighted Loss:1.320    Policy Loss: 4.246    Value Loss: 4.405    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 633694     Buffer Size: 19634      Transition Number: 1200.111k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:33:27,475][train][INFO][train.py>_log] ==> #429000     Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 4.890    Value Loss: 4.693    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 634867     Buffer Size: 19615      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:37:25,326][train][INFO][train.py>_log] ==> #430000     Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 4.872    Value Loss: 4.283    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 636021     Buffer Size: 19619      Transition Number: 1200.443k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:41:22,769][train][INFO][train.py>_log] ==> #431000     Total Loss: 1.447    [weighted Loss:1.447    Policy Loss: 5.199    Value Loss: 4.342    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 637184     Buffer Size: 19616      Transition Number: 1200.116k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:45:18,680][train][INFO][train.py>_log] ==> #432000     Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 5.471    Value Loss: 4.393    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 638363     Buffer Size: 19533      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:49:17,893][train][INFO][train.py>_log] ==> #433000     Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 5.586    Value Loss: 4.884    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 639549     Buffer Size: 19449      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:53:09,080][train][INFO][train.py>_log] ==> #434000     Total Loss: 1.964    [weighted Loss:1.964    Policy Loss: 5.405    Value Loss: 4.658    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 640721     Buffer Size: 19436      Transition Number: 1200.464k Batch Size: 256        Lr: 0.10000 
[2022-01-22 23:57:00,862][train][INFO][train.py>_log] ==> #435000     Total Loss: 1.099    [weighted Loss:1.099    Policy Loss: 5.792    Value Loss: 4.666    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 642132     Buffer Size: 19671      Transition Number: 1199.941k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:00:53,773][train][INFO][train.py>_log] ==> #436000     Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 4.370    Value Loss: 4.799    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 643570     Buffer Size: 20017      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:04:53,064][train][INFO][train.py>_log] ==> #437000     Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 4.227    Value Loss: 5.177    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 644749     Buffer Size: 20106      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:08:46,008][train][INFO][train.py>_log] ==> #438000     Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 4.189    Value Loss: 5.077    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 645941     Buffer Size: 20158      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:12:39,388][train][INFO][train.py>_log] ==> #439000     Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 4.337    Value Loss: 5.002    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 647066     Buffer Size: 20144      Transition Number: 1200.071k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:16:32,117][train][INFO][train.py>_log] ==> #440000     Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 3.658    Value Loss: 5.163    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 648158     Buffer Size: 20146      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:20:29,680][train][INFO][train.py>_log] ==> #441000     Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 3.791    Value Loss: 4.890    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 649233     Buffer Size: 20143      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:24:23,387][train][INFO][train.py>_log] ==> #442000     Total Loss: 1.989    [weighted Loss:1.989    Policy Loss: 4.556    Value Loss: 5.354    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 650349     Buffer Size: 20123      Transition Number: 1199.935k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:28:19,337][train][INFO][train.py>_log] ==> #443000     Total Loss: 1.974    [weighted Loss:1.974    Policy Loss: 5.044    Value Loss: 4.762    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 651493     Buffer Size: 20179      Transition Number: 1200.108k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:32:09,762][train][INFO][train.py>_log] ==> #444000     Total Loss: 1.692    [weighted Loss:1.692    Policy Loss: 4.389    Value Loss: 4.848    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 652597     Buffer Size: 20236      Transition Number: 1200.340k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:36:09,494][train][INFO][train.py>_log] ==> #445000     Total Loss: 1.270    [weighted Loss:1.270    Policy Loss: 3.836    Value Loss: 4.893    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 653718     Buffer Size: 20256      Transition Number: 1200.055k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:40:02,494][train][INFO][train.py>_log] ==> #446000     Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 4.466    Value Loss: 5.085    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 654859     Buffer Size: 20276      Transition Number: 1199.935k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:43:53,634][train][INFO][train.py>_log] ==> #447000     Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 4.307    Value Loss: 5.158    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 656073     Buffer Size: 20325      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:47:45,953][train][INFO][train.py>_log] ==> #448000     Total Loss: 1.280    [weighted Loss:1.280    Policy Loss: 3.904    Value Loss: 5.315    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 657258     Buffer Size: 20365      Transition Number: 1200.082k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:51:46,829][train][INFO][train.py>_log] ==> #449000     Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 3.926    Value Loss: 4.869    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 658358     Buffer Size: 20360      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:55:38,784][train][INFO][train.py>_log] ==> #450000     Total Loss: 1.779    [weighted Loss:1.779    Policy Loss: 4.396    Value Loss: 4.940    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 659490     Buffer Size: 20340      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-23 00:59:30,210][train][INFO][train.py>_log] ==> #451000     Total Loss: 1.746    [weighted Loss:1.746    Policy Loss: 4.169    Value Loss: 5.050    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 660663     Buffer Size: 20325      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:03:22,234][train][INFO][train.py>_log] ==> #452000     Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 4.439    Value Loss: 4.956    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 661795     Buffer Size: 20192      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:07:23,315][train][INFO][train.py>_log] ==> #453000     Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 4.673    Value Loss: 4.630    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 662971     Buffer Size: 19954      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:11:18,361][train][INFO][train.py>_log] ==> #454000     Total Loss: 1.390    [weighted Loss:1.390    Policy Loss: 4.938    Value Loss: 4.645    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 664137     Buffer Size: 19834      Transition Number: 1200.205k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:15:13,124][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 4.678    Value Loss: 4.707    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 665305     Buffer Size: 19775      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:19:06,030][train][INFO][train.py>_log] ==> #456000     Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 4.560    Value Loss: 4.791    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 666465     Buffer Size: 19761      Transition Number: 1200.051k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:23:05,950][train][INFO][train.py>_log] ==> #457000     Total Loss: 0.864    [weighted Loss:0.864    Policy Loss: 5.268    Value Loss: 5.014    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 667669     Buffer Size: 19847      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:26:58,729][train][INFO][train.py>_log] ==> #458000     Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 5.332    Value Loss: 4.943    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 668861     Buffer Size: 19933      Transition Number: 1200.054k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:30:50,638][train][INFO][train.py>_log] ==> #459000     Total Loss: 0.949    [weighted Loss:0.949    Policy Loss: 4.850    Value Loss: 5.350    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 670055     Buffer Size: 20099      Transition Number: 1200.064k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:34:41,953][train][INFO][train.py>_log] ==> #460000     Total Loss: 1.138    [weighted Loss:1.138    Policy Loss: 4.458    Value Loss: 5.128    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 671247     Buffer Size: 20254      Transition Number: 1200.305k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:38:39,074][train][INFO][train.py>_log] ==> #461000     Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 5.576    Value Loss: 4.978    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 672386     Buffer Size: 20268      Transition Number: 1200.039k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:42:33,226][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.487    [weighted Loss:2.487    Policy Loss: 5.288    Value Loss: 4.914    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 673558     Buffer Size: 20306      Transition Number: 1200.188k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:46:24,864][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 4.741    Value Loss: 4.775    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 674891     Buffer Size: 20464      Transition Number: 1200.011k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:50:16,520][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.670    [weighted Loss:2.670    Policy Loss: 5.422    Value Loss: 5.212    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 676176     Buffer Size: 20619      Transition Number: 1199.946k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:54:14,621][train][INFO][train.py>_log] ==> #465000     Total Loss: 2.257    [weighted Loss:2.257    Policy Loss: 4.525    Value Loss: 5.285    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 677385     Buffer Size: 20701      Transition Number: 1199.952k Batch Size: 256        Lr: 0.10000 
[2022-01-23 01:58:08,776][train][INFO][train.py>_log] ==> #466000     Total Loss: 1.599    [weighted Loss:1.599    Policy Loss: 4.404    Value Loss: 5.314    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 678633     Buffer Size: 20814      Transition Number: 1200.273k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:01:59,302][train][INFO][train.py>_log] ==> #467000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 3.861    Value Loss: 4.930    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 679744     Buffer Size: 20862      Transition Number: 1200.143k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:05:53,490][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 4.294    Value Loss: 4.952    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 680850     Buffer Size: 20875      Transition Number: 1200.077k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:09:51,229][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 4.562    Value Loss: 5.065    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 682147     Buffer Size: 21042      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:13:46,596][train][INFO][train.py>_log] ==> #470000     Total Loss: 1.572    [weighted Loss:1.572    Policy Loss: 4.137    Value Loss: 5.086    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 683493     Buffer Size: 21194      Transition Number: 1200.148k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:17:39,320][train][INFO][train.py>_log] ==> #471000     Total Loss: 1.002    [weighted Loss:1.002    Policy Loss: 3.708    Value Loss: 5.189    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 684735     Buffer Size: 21262      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:21:34,073][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 3.794    Value Loss: 5.365    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 685994     Buffer Size: 21351      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:25:33,011][train][INFO][train.py>_log] ==> #473000     Total Loss: 1.445    [weighted Loss:1.445    Policy Loss: 4.119    Value Loss: 4.860    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 687180     Buffer Size: 21419      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:29:25,108][train][INFO][train.py>_log] ==> #474000     Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 4.386    Value Loss: 5.202    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 688356     Buffer Size: 21469      Transition Number: 1200.300k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:33:17,033][train][INFO][train.py>_log] ==> #475000     Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 4.343    Value Loss: 5.072    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 689480     Buffer Size: 21415      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:37:11,860][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.844    [weighted Loss:1.844    Policy Loss: 4.487    Value Loss: 4.888    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 690627     Buffer Size: 21376      Transition Number: 1200.001k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:41:10,926][train][INFO][train.py>_log] ==> #477000     Total Loss: 0.899    [weighted Loss:0.899    Policy Loss: 3.926    Value Loss: 5.060    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 691971     Buffer Size: 21419      Transition Number: 1200.066k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:45:05,496][train][INFO][train.py>_log] ==> #478000     Total Loss: 1.495    [weighted Loss:1.495    Policy Loss: 3.899    Value Loss: 5.067    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 693309     Buffer Size: 21516      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:48:57,779][train][INFO][train.py>_log] ==> #479000     Total Loss: 1.350    [weighted Loss:1.350    Policy Loss: 3.859    Value Loss: 5.024    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 694473     Buffer Size: 21519      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:52:51,125][train][INFO][train.py>_log] ==> #480000     Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 3.725    Value Loss: 4.829    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 695611     Buffer Size: 21466      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-23 02:56:49,317][train][INFO][train.py>_log] ==> #481000     Total Loss: 0.546    [weighted Loss:0.546    Policy Loss: 3.983    Value Loss: 5.145    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 696785     Buffer Size: 21307      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:00:39,496][train][INFO][train.py>_log] ==> #482000     Total Loss: 1.166    [weighted Loss:1.166    Policy Loss: 3.548    Value Loss: 5.173    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 697942     Buffer Size: 21199      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:04:30,105][train][INFO][train.py>_log] ==> #483000     Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 3.971    Value Loss: 4.618    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 699064     Buffer Size: 21108      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:08:22,213][train][INFO][train.py>_log] ==> #484000     Total Loss: 2.071    [weighted Loss:2.071    Policy Loss: 4.621    Value Loss: 4.839    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 700204     Buffer Size: 21005      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:12:19,486][train][INFO][train.py>_log] ==> #485000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 3.856    Value Loss: 5.095    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 701339     Buffer Size: 20980      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:16:10,169][train][INFO][train.py>_log] ==> #486000     Total Loss: 1.135    [weighted Loss:1.135    Policy Loss: 3.959    Value Loss: 4.905    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 702424     Buffer Size: 20883      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:20:01,113][train][INFO][train.py>_log] ==> #487000     Total Loss: 1.619    [weighted Loss:1.619    Policy Loss: 4.333    Value Loss: 4.836    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 703552     Buffer Size: 20719      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:23:55,865][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.601    [weighted Loss:1.601    Policy Loss: 4.702    Value Loss: 5.128    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 704703     Buffer Size: 20595      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:27:53,440][train][INFO][train.py>_log] ==> #489000     Total Loss: 1.679    [weighted Loss:1.679    Policy Loss: 5.019    Value Loss: 4.775    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 705816     Buffer Size: 20508      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:31:44,185][train][INFO][train.py>_log] ==> #490000     Total Loss: 1.511    [weighted Loss:1.511    Policy Loss: 4.383    Value Loss: 4.808    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 706976     Buffer Size: 20445      Transition Number: 1200.062k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:35:38,630][train][INFO][train.py>_log] ==> #491000     Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 5.173    Value Loss: 4.993    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 708134     Buffer Size: 20441      Transition Number: 1200.001k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:39:30,589][train][INFO][train.py>_log] ==> #492000     Total Loss: 2.651    [weighted Loss:2.651    Policy Loss: 4.818    Value Loss: 4.983    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 709284     Buffer Size: 20433      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:43:29,295][train][INFO][train.py>_log] ==> #493000     Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 4.345    Value Loss: 4.755    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 710409     Buffer Size: 20372      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:47:20,336][train][INFO][train.py>_log] ==> #494000     Total Loss: 1.179    [weighted Loss:1.179    Policy Loss: 3.983    Value Loss: 4.655    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 711561     Buffer Size: 20239      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:51:09,536][train][INFO][train.py>_log] ==> #495000     Total Loss: 1.626    [weighted Loss:1.626    Policy Loss: 4.594    Value Loss: 4.857    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 713186     Buffer Size: 20601      Transition Number: 1200.073k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:54:59,254][train][INFO][train.py>_log] ==> #496000     Total Loss: 1.434    [weighted Loss:1.434    Policy Loss: 4.135    Value Loss: 4.993    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 714947     Buffer Size: 21088      Transition Number: 1200.042k Batch Size: 256        Lr: 0.10000 
[2022-01-23 03:58:55,587][train][INFO][train.py>_log] ==> #497000     Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 4.208    Value Loss: 4.836    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 716287     Buffer Size: 21332      Transition Number: 1200.018k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:02:46,700][train][INFO][train.py>_log] ==> #498000     Total Loss: 1.415    [weighted Loss:1.415    Policy Loss: 4.143    Value Loss: 4.904    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 717586     Buffer Size: 21527      Transition Number: 1200.058k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:06:37,452][train][INFO][train.py>_log] ==> #499000     Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 4.092    Value Loss: 5.057    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 718768     Buffer Size: 21557      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:10:30,582][train][INFO][train.py>_log] ==> #500000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 4.245    Value Loss: 5.279    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 719911     Buffer Size: 21563      Transition Number: 1200.201k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:14:31,110][train][INFO][train.py>_log] ==> #501000     Total Loss: 1.612    [weighted Loss:1.612    Policy Loss: 3.901    Value Loss: 4.900    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 721029     Buffer Size: 21578      Transition Number: 1200.377k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:18:26,286][train][INFO][train.py>_log] ==> #502000     Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 4.095    Value Loss: 5.293    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 722096     Buffer Size: 21595      Transition Number: 1200.305k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:22:18,114][train][INFO][train.py>_log] ==> #503000     Total Loss: 1.677    [weighted Loss:1.677    Policy Loss: 3.738    Value Loss: 5.282    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 723265     Buffer Size: 21607      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:26:11,252][train][INFO][train.py>_log] ==> #504000     Total Loss: 1.904    [weighted Loss:1.904    Policy Loss: 3.773    Value Loss: 5.231    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 724448     Buffer Size: 21612      Transition Number: 1200.006k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:30:09,783][train][INFO][train.py>_log] ==> #505000     Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 3.419    Value Loss: 5.131    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 725598     Buffer Size: 21573      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:34:00,549][train][INFO][train.py>_log] ==> #506000     Total Loss: 1.930    [weighted Loss:1.930    Policy Loss: 4.476    Value Loss: 4.886    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 726705     Buffer Size: 21540      Transition Number: 1200.150k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:37:54,323][train][INFO][train.py>_log] ==> #507000     Total Loss: 1.308    [weighted Loss:1.308    Policy Loss: 4.746    Value Loss: 4.955    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 728279     Buffer Size: 21967      Transition Number: 1200.078k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:41:43,953][train][INFO][train.py>_log] ==> #508000     Total Loss: 1.013    [weighted Loss:1.013    Policy Loss: 4.115    Value Loss: 5.269    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 729826     Buffer Size: 22405      Transition Number: 1200.256k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:45:41,777][train][INFO][train.py>_log] ==> #509000     Total Loss: 1.325    [weighted Loss:1.325    Policy Loss: 4.264    Value Loss: 5.007    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 731046     Buffer Size: 22512      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:49:30,185][train][INFO][train.py>_log] ==> #510000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 3.592    Value Loss: 5.148    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 732298     Buffer Size: 22624      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:53:21,568][train][INFO][train.py>_log] ==> #511000     Total Loss: 1.232    [weighted Loss:1.232    Policy Loss: 4.040    Value Loss: 5.244    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 733461     Buffer Size: 22690      Transition Number: 1200.306k Batch Size: 256        Lr: 0.10000 
[2022-01-23 04:57:11,443][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.543    [weighted Loss:1.543    Policy Loss: 4.489    Value Loss: 5.221    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 734483     Buffer Size: 22664      Transition Number: 1200.379k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:01:08,730][train][INFO][train.py>_log] ==> #513000     Total Loss: 1.275    [weighted Loss:1.275    Policy Loss: 4.000    Value Loss: 4.586    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 735554     Buffer Size: 22055      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:05:00,699][train][INFO][train.py>_log] ==> #514000     Total Loss: 2.333    [weighted Loss:2.333    Policy Loss: 4.348    Value Loss: 5.038    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 736710     Buffer Size: 21458      Transition Number: 1200.182k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:08:49,068][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 4.654    Value Loss: 4.684    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 737927     Buffer Size: 21213      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:12:38,809][train][INFO][train.py>_log] ==> #516000     Total Loss: 1.310    [weighted Loss:1.310    Policy Loss: 4.284    Value Loss: 4.799    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 739101     Buffer Size: 21079      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:16:37,875][train][INFO][train.py>_log] ==> #517000     Total Loss: 1.119    [weighted Loss:1.119    Policy Loss: 3.802    Value Loss: 4.998    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 740198     Buffer Size: 21036      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:20:31,619][train][INFO][train.py>_log] ==> #518000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 4.330    Value Loss: 5.022    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 741312     Buffer Size: 20993      Transition Number: 1200.064k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:24:23,973][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.253    [weighted Loss:1.253    Policy Loss: 4.155    Value Loss: 5.190    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 742464     Buffer Size: 20957      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:28:15,244][train][INFO][train.py>_log] ==> #520000     Total Loss: 1.297    [weighted Loss:1.297    Policy Loss: 4.801    Value Loss: 4.928    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 743556     Buffer Size: 20937      Transition Number: 1199.932k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:32:10,848][train][INFO][train.py>_log] ==> #521000     Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 4.033    Value Loss: 4.710    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 744660     Buffer Size: 20947      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:36:01,854][train][INFO][train.py>_log] ==> #522000     Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 3.843    Value Loss: 4.845    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 745799     Buffer Size: 20941      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:39:52,779][train][INFO][train.py>_log] ==> #523000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 4.785    Value Loss: 5.101    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 746918     Buffer Size: 20955      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:43:42,806][train][INFO][train.py>_log] ==> #524000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 4.214    Value Loss: 4.852    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 748071     Buffer Size: 20832      Transition Number: 1200.011k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:47:41,270][train][INFO][train.py>_log] ==> #525000     Total Loss: 1.095    [weighted Loss:1.095    Policy Loss: 4.383    Value Loss: 4.993    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 749267     Buffer Size: 20457      Transition Number: 1200.082k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:51:33,874][train][INFO][train.py>_log] ==> #526000     Total Loss: 1.399    [weighted Loss:1.399    Policy Loss: 4.422    Value Loss: 4.934    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 750408     Buffer Size: 20229      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:55:24,416][train][INFO][train.py>_log] ==> #527000     Total Loss: 0.921    [weighted Loss:0.921    Policy Loss: 5.258    Value Loss: 4.891    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 751567     Buffer Size: 20138      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-23 05:59:13,073][train][INFO][train.py>_log] ==> #528000     Total Loss: 1.054    [weighted Loss:1.054    Policy Loss: 4.566    Value Loss: 4.852    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 752733     Buffer Size: 20067      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:03:08,079][train][INFO][train.py>_log] ==> #529000     Total Loss: 1.244    [weighted Loss:1.244    Policy Loss: 5.137    Value Loss: 5.058    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 754220     Buffer Size: 20366      Transition Number: 1200.076k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:06:58,750][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.366    [weighted Loss:1.366    Policy Loss: 5.790    Value Loss: 4.821    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 755727     Buffer Size: 20710      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:10:48,237][train][INFO][train.py>_log] ==> #531000     Total Loss: 1.345    [weighted Loss:1.345    Policy Loss: 4.886    Value Loss: 5.163    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 757035     Buffer Size: 20929      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:14:37,137][train][INFO][train.py>_log] ==> #532000     Total Loss: 0.726    [weighted Loss:0.726    Policy Loss: 4.120    Value Loss: 5.482    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 758321     Buffer Size: 21119      Transition Number: 1200.085k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:18:33,034][train][INFO][train.py>_log] ==> #533000     Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 4.260    Value Loss: 5.041    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 759412     Buffer Size: 21195      Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:22:23,422][train][INFO][train.py>_log] ==> #534000     Total Loss: 1.585    [weighted Loss:1.585    Policy Loss: 4.744    Value Loss: 5.167    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 760663     Buffer Size: 21275      Transition Number: 1200.032k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:26:14,279][train][INFO][train.py>_log] ==> #535000     Total Loss: 1.372    [weighted Loss:1.372    Policy Loss: 3.778    Value Loss: 5.368    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 761856     Buffer Size: 21363      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:30:10,033][train][INFO][train.py>_log] ==> #536000     Total Loss: 2.515    [weighted Loss:2.515    Policy Loss: 4.448    Value Loss: 5.024    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 763043     Buffer Size: 21480      Transition Number: 1200.094k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:34:08,780][train][INFO][train.py>_log] ==> #537000     Total Loss: 1.537    [weighted Loss:1.537    Policy Loss: 3.661    Value Loss: 5.210    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 764120     Buffer Size: 21509      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:37:59,556][train][INFO][train.py>_log] ==> #538000     Total Loss: 1.753    [weighted Loss:1.753    Policy Loss: 4.798    Value Loss: 5.241    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 765251     Buffer Size: 21508      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:41:50,822][train][INFO][train.py>_log] ==> #539000     Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 4.057    Value Loss: 4.929    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 766460     Buffer Size: 21600      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:45:41,909][train][INFO][train.py>_log] ==> #540000     Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 4.302    Value Loss: 5.167    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 767648     Buffer Size: 21671      Transition Number: 1200.038k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:49:37,192][train][INFO][train.py>_log] ==> #541000     Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 4.079    Value Loss: 5.220    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 768919     Buffer Size: 21816      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:53:30,748][train][INFO][train.py>_log] ==> #542000     Total Loss: 1.670    [weighted Loss:1.670    Policy Loss: 4.109    Value Loss: 5.758    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 770145     Buffer Size: 21957      Transition Number: 1200.228k Batch Size: 256        Lr: 0.10000 
[2022-01-23 06:57:21,508][train][INFO][train.py>_log] ==> #543000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 4.322    Value Loss: 5.159    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 771282     Buffer Size: 21953      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:01:12,711][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 3.336    Value Loss: 5.161    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 772509     Buffer Size: 21943      Transition Number: 1200.047k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:05:10,308][train][INFO][train.py>_log] ==> #545000     Total Loss: 1.356    [weighted Loss:1.356    Policy Loss: 3.464    Value Loss: 5.094    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 773571     Buffer Size: 21876      Transition Number: 1200.073k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:09:03,931][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 3.405    Value Loss: 5.033    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 774703     Buffer Size: 21770      Transition Number: 1200.054k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:12:57,744][train][INFO][train.py>_log] ==> #547000     Total Loss: 1.401    [weighted Loss:1.401    Policy Loss: 3.644    Value Loss: 5.027    Reward Loss: 0.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 775814     Buffer Size: 21353      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:16:52,822][train][INFO][train.py>_log] ==> #548000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 3.762    Value Loss: 4.689    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 776919     Buffer Size: 20990      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:20:50,364][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 4.564    Value Loss: 4.951    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 778008     Buffer Size: 20731      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:24:43,469][train][INFO][train.py>_log] ==> #550000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 4.527    Value Loss: 4.977    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 779027     Buffer Size: 20530      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:28:35,144][train][INFO][train.py>_log] ==> #551000     Total Loss: 0.975    [weighted Loss:0.975    Policy Loss: 4.763    Value Loss: 5.092    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 780169     Buffer Size: 20443      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:32:26,105][train][INFO][train.py>_log] ==> #552000     Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 4.466    Value Loss: 4.880    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 781382     Buffer Size: 20374      Transition Number: 1200.086k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:36:23,671][train][INFO][train.py>_log] ==> #553000     Total Loss: 1.419    [weighted Loss:1.419    Policy Loss: 4.501    Value Loss: 5.111    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 782644     Buffer Size: 20400      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:40:15,611][train][INFO][train.py>_log] ==> #554000     Total Loss: 1.108    [weighted Loss:1.108    Policy Loss: 4.727    Value Loss: 4.881    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 783892     Buffer Size: 20458      Transition Number: 1200.064k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:44:08,945][train][INFO][train.py>_log] ==> #555000     Total Loss: 1.736    [weighted Loss:1.736    Policy Loss: 3.725    Value Loss: 4.842    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 785092     Buffer Size: 20587      Transition Number: 1199.944k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:48:03,258][train][INFO][train.py>_log] ==> #556000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 4.249    Value Loss: 4.869    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 786364     Buffer Size: 20705      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:52:03,752][train][INFO][train.py>_log] ==> #557000     Total Loss: 0.526    [weighted Loss:0.526    Policy Loss: 4.142    Value Loss: 4.815    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 787510     Buffer Size: 20612      Transition Number: 1199.959k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:55:58,340][train][INFO][train.py>_log] ==> #558000     Total Loss: 1.141    [weighted Loss:1.141    Policy Loss: 4.133    Value Loss: 4.737    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 788656     Buffer Size: 20477      Transition Number: 1200.320k Batch Size: 256        Lr: 0.10000 
[2022-01-23 07:59:53,403][train][INFO][train.py>_log] ==> #559000     Total Loss: 1.406    [weighted Loss:1.406    Policy Loss: 4.029    Value Loss: 4.530    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 789733     Buffer Size: 20245      Transition Number: 1200.004k Batch Size: 256        Lr: 0.10000 
