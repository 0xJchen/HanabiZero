[2021-11-07 13:04:42,341][train][INFO][train.py>_log] ==> #0          Total Loss: 44.626   [weighted Loss:44.626   Policy Loss: 14.628   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 38         Buffer Size: 38         Transition Number: 0.450   k Batch Size: 128        Lr: 0.000   
[2021-11-07 13:06:16,124][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.853    [weighted Loss:4.853    Policy Loss: 13.343   Value Loss: 4.049    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 225        Buffer Size: 225        Transition Number: 2.730   k Batch Size: 128        Lr: 0.010   
[2021-11-07 13:08:17,775][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.479    [weighted Loss:5.479    Policy Loss: 11.778   Value Loss: 3.292    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 576        Buffer Size: 576        Transition Number: 5.538   k Batch Size: 128        Lr: 0.020   
[2021-11-07 13:10:36,645][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 10.718   Value Loss: 2.903    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 926        Buffer Size: 926        Transition Number: 8.658   k Batch Size: 128        Lr: 0.030   
[2021-11-07 13:12:51,106][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.888    [weighted Loss:5.888    Policy Loss: 11.713   Value Loss: 3.062    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 1244       Buffer Size: 1244       Transition Number: 11.705  k Batch Size: 128        Lr: 0.040   
[2021-11-07 13:15:06,737][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.226    [weighted Loss:5.226    Policy Loss: 11.297   Value Loss: 2.935    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1630       Buffer Size: 1630       Transition Number: 14.632  k Batch Size: 128        Lr: 0.050   
[2021-11-07 13:17:26,471][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.703    [weighted Loss:5.703    Policy Loss: 11.093   Value Loss: 2.725    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 2006       Buffer Size: 2006       Transition Number: 17.799  k Batch Size: 128        Lr: 0.060   
[2021-11-07 13:19:48,130][train][INFO][train.py>_log] ==> #7000       Total Loss: 6.104    [weighted Loss:6.104    Policy Loss: 11.899   Value Loss: 2.587    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 2300       Buffer Size: 2300       Transition Number: 20.924  k Batch Size: 128        Lr: 0.070   
[2021-11-07 13:22:12,426][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.947    [weighted Loss:3.947    Policy Loss: 11.343   Value Loss: 2.741    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 2667       Buffer Size: 2667       Transition Number: 24.182  k Batch Size: 128        Lr: 0.080   
[2021-11-07 13:24:39,262][train][INFO][train.py>_log] ==> #9000       Total Loss: 6.382    [weighted Loss:6.382    Policy Loss: 11.817   Value Loss: 2.715    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 2982       Buffer Size: 2982       Transition Number: 27.258  k Batch Size: 128        Lr: 0.090   
[2021-11-07 13:27:09,829][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 12.043   Value Loss: 2.690    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 3231       Buffer Size: 3231       Transition Number: 30.498  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:29:45,937][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.315    [weighted Loss:4.315    Policy Loss: 12.174   Value Loss: 2.994    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 3535       Buffer Size: 3535       Transition Number: 33.815  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:32:21,319][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.543    [weighted Loss:3.543    Policy Loss: 12.285   Value Loss: 3.015    Reward Loss: 0.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 3980       Buffer Size: 3980       Transition Number: 37.438  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:34:57,857][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.877    [weighted Loss:3.877    Policy Loss: 12.534   Value Loss: 2.812    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 4365       Buffer Size: 4365       Transition Number: 40.887  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:37:35,191][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.713    [weighted Loss:4.713    Policy Loss: 11.157   Value Loss: 2.825    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 4765       Buffer Size: 4765       Transition Number: 44.463  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:40:10,982][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 11.162   Value Loss: 2.750    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 5127       Buffer Size: 5127       Transition Number: 47.980  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:42:47,810][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.372    [weighted Loss:3.372    Policy Loss: 12.266   Value Loss: 2.904    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 5475       Buffer Size: 5475       Transition Number: 51.510  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:45:24,629][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.478    [weighted Loss:4.478    Policy Loss: 11.511   Value Loss: 2.632    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 5828       Buffer Size: 5828       Transition Number: 54.721  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:48:01,729][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.795    [weighted Loss:5.795    Policy Loss: 11.631   Value Loss: 2.761    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 6160       Buffer Size: 6160       Transition Number: 58.359  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:50:40,261][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.253    [weighted Loss:4.253    Policy Loss: 11.319   Value Loss: 2.719    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 6544       Buffer Size: 6544       Transition Number: 61.944  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:53:17,880][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.965    [weighted Loss:4.965    Policy Loss: 11.933   Value Loss: 2.918    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 6997       Buffer Size: 6997       Transition Number: 65.718  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:55:53,743][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.145    [weighted Loss:5.145    Policy Loss: 11.510   Value Loss: 2.607    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 7419       Buffer Size: 7419       Transition Number: 69.239  k Batch Size: 128        Lr: 0.100   
[2021-11-07 13:58:32,910][train][INFO][train.py>_log] ==> #22000      Total Loss: 7.056    [weighted Loss:7.056    Policy Loss: 11.754   Value Loss: 3.152    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 7869       Buffer Size: 7869       Transition Number: 72.869  k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:01:10,913][train][INFO][train.py>_log] ==> #23000      Total Loss: 5.794    [weighted Loss:5.794    Policy Loss: 12.430   Value Loss: 3.166    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 8218       Buffer Size: 8218       Transition Number: 76.486  k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:03:51,329][train][INFO][train.py>_log] ==> #24000      Total Loss: 6.949    [weighted Loss:6.949    Policy Loss: 11.877   Value Loss: 2.845    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 8618       Buffer Size: 8618       Transition Number: 80.273  k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:06:52,010][train][INFO][train.py>_log] ==> #25000      Total Loss: 6.714    [weighted Loss:6.714    Policy Loss: 12.153   Value Loss: 2.880    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 9055       Buffer Size: 9055       Transition Number: 84.309  k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:09:30,272][train][INFO][train.py>_log] ==> #26000      Total Loss: 4.087    [weighted Loss:4.087    Policy Loss: 11.832   Value Loss: 2.799    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 9464       Buffer Size: 9464       Transition Number: 87.986  k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:12:07,729][train][INFO][train.py>_log] ==> #27000      Total Loss: 6.071    [weighted Loss:6.071    Policy Loss: 11.301   Value Loss: 2.861    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 9920       Buffer Size: 9920       Transition Number: 91.656  k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:14:46,973][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.434    [weighted Loss:4.434    Policy Loss: 11.872   Value Loss: 3.143    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 10252      Buffer Size: 10252      Transition Number: 95.207  k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:17:29,259][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.490    [weighted Loss:4.490    Policy Loss: 12.191   Value Loss: 2.758    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 10543      Buffer Size: 10543      Transition Number: 98.521  k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:20:45,732][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.864    [weighted Loss:4.864    Policy Loss: 11.310   Value Loss: 2.900    Reward Loss: 0.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 11005      Buffer Size: 11005      Transition Number: 103.303 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:23:28,632][train][INFO][train.py>_log] ==> #31000      Total Loss: 5.385    [weighted Loss:5.385    Policy Loss: 12.107   Value Loss: 2.889    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 11322      Buffer Size: 11322      Transition Number: 106.893 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:26:13,954][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.853    [weighted Loss:4.853    Policy Loss: 11.258   Value Loss: 2.822    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 11651      Buffer Size: 11651      Transition Number: 110.639 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:28:59,038][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 12.001   Value Loss: 2.766    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 12002      Buffer Size: 12002      Transition Number: 114.323 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:31:44,985][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.356    [weighted Loss:4.356    Policy Loss: 12.034   Value Loss: 2.927    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 12392      Buffer Size: 12392      Transition Number: 118.163 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:34:30,660][train][INFO][train.py>_log] ==> #35000      Total Loss: 5.133    [weighted Loss:5.133    Policy Loss: 12.139   Value Loss: 2.914    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 12815      Buffer Size: 12815      Transition Number: 122.006 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:37:18,838][train][INFO][train.py>_log] ==> #36000      Total Loss: 4.946    [weighted Loss:4.946    Policy Loss: 11.844   Value Loss: 2.854    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 13230      Buffer Size: 13230      Transition Number: 125.889 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:40:09,199][train][INFO][train.py>_log] ==> #37000      Total Loss: 5.757    [weighted Loss:5.757    Policy Loss: 12.099   Value Loss: 2.884    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 13452      Buffer Size: 13452      Transition Number: 129.257 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:43:00,381][train][INFO][train.py>_log] ==> #38000      Total Loss: 4.227    [weighted Loss:4.227    Policy Loss: 12.250   Value Loss: 3.150    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 13761      Buffer Size: 13761      Transition Number: 133.159 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:45:54,130][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.448    [weighted Loss:3.448    Policy Loss: 11.665   Value Loss: 3.037    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 14110      Buffer Size: 14110      Transition Number: 137.073 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:48:48,699][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.913    [weighted Loss:4.913    Policy Loss: 11.043   Value Loss: 2.696    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 14422      Buffer Size: 14422      Transition Number: 141.063 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:51:45,824][train][INFO][train.py>_log] ==> #41000      Total Loss: 5.727    [weighted Loss:5.727    Policy Loss: 11.337   Value Loss: 2.812    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 14730      Buffer Size: 14730      Transition Number: 144.640 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:54:41,265][train][INFO][train.py>_log] ==> #42000      Total Loss: 4.394    [weighted Loss:4.394    Policy Loss: 11.750   Value Loss: 2.897    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 15124      Buffer Size: 15124      Transition Number: 148.623 k Batch Size: 128        Lr: 0.100   
[2021-11-07 14:57:38,699][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 12.539   Value Loss: 2.885    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 15546      Buffer Size: 15546      Transition Number: 152.707 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:00:35,337][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 12.026   Value Loss: 3.023    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 16011      Buffer Size: 16011      Transition Number: 156.954 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:03:33,124][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.983    [weighted Loss:4.983    Policy Loss: 11.875   Value Loss: 2.665    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 16359      Buffer Size: 16359      Transition Number: 160.438 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:06:31,346][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 11.257   Value Loss: 2.556    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 16726      Buffer Size: 16726      Transition Number: 164.402 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:09:31,878][train][INFO][train.py>_log] ==> #47000      Total Loss: 6.060    [weighted Loss:6.060    Policy Loss: 12.843   Value Loss: 3.220    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 17087      Buffer Size: 17087      Transition Number: 168.391 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:12:35,170][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.956    [weighted Loss:3.956    Policy Loss: 11.573   Value Loss: 2.764    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 17368      Buffer Size: 17368      Transition Number: 172.361 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:15:40,580][train][INFO][train.py>_log] ==> #49000      Total Loss: 5.105    [weighted Loss:5.105    Policy Loss: 11.659   Value Loss: 2.890    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 17637      Buffer Size: 17637      Transition Number: 176.424 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:18:45,289][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.730    [weighted Loss:3.730    Policy Loss: 11.398   Value Loss: 3.026    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 18134      Buffer Size: 18134      Transition Number: 180.905 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:21:48,918][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 11.704   Value Loss: 2.726    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 18554      Buffer Size: 18554      Transition Number: 185.079 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:25:00,668][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.983    [weighted Loss:3.983    Policy Loss: 12.823   Value Loss: 3.171    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 18893      Buffer Size: 18893      Transition Number: 189.321 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:28:10,331][train][INFO][train.py>_log] ==> #53000      Total Loss: 6.490    [weighted Loss:6.490    Policy Loss: 12.058   Value Loss: 3.014    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 19154      Buffer Size: 19154      Transition Number: 192.919 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:31:22,108][train][INFO][train.py>_log] ==> #54000      Total Loss: 4.358    [weighted Loss:4.358    Policy Loss: 11.808   Value Loss: 2.797    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 19602      Buffer Size: 19602      Transition Number: 197.153 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:34:33,435][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 12.126   Value Loss: 2.903    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 20064      Buffer Size: 20064      Transition Number: 201.498 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:37:44,559][train][INFO][train.py>_log] ==> #56000      Total Loss: 5.840    [weighted Loss:5.840    Policy Loss: 12.076   Value Loss: 2.875    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 20641      Buffer Size: 20641      Transition Number: 206.105 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:40:58,373][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.396    [weighted Loss:4.396    Policy Loss: 11.436   Value Loss: 2.846    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 20874      Buffer Size: 20874      Transition Number: 209.667 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:44:14,304][train][INFO][train.py>_log] ==> #58000      Total Loss: 5.456    [weighted Loss:5.456    Policy Loss: 12.186   Value Loss: 2.873    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 21166      Buffer Size: 21166      Transition Number: 213.939 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:47:37,031][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 12.178   Value Loss: 3.035    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 21429      Buffer Size: 21429      Transition Number: 218.328 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:51:00,561][train][INFO][train.py>_log] ==> #60000      Total Loss: 5.815    [weighted Loss:5.815    Policy Loss: 11.414   Value Loss: 2.931    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 21750      Buffer Size: 21750      Transition Number: 222.386 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:54:21,319][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.552    [weighted Loss:4.552    Policy Loss: 11.875   Value Loss: 2.961    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 22068      Buffer Size: 22068      Transition Number: 226.161 k Batch Size: 128        Lr: 0.100   
[2021-11-07 15:57:45,859][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.018    [weighted Loss:4.018    Policy Loss: 11.829   Value Loss: 2.938    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 22296      Buffer Size: 22296      Transition Number: 229.920 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:01:10,639][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.447    [weighted Loss:4.447    Policy Loss: 11.390   Value Loss: 3.023    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 22679      Buffer Size: 22679      Transition Number: 234.297 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:04:38,929][train][INFO][train.py>_log] ==> #64000      Total Loss: 6.274    [weighted Loss:6.274    Policy Loss: 11.657   Value Loss: 3.159    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 23019      Buffer Size: 23019      Transition Number: 238.228 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:08:09,607][train][INFO][train.py>_log] ==> #65000      Total Loss: 4.470    [weighted Loss:4.470    Policy Loss: 12.352   Value Loss: 3.306    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 23328      Buffer Size: 23328      Transition Number: 242.114 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:11:45,936][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.986    [weighted Loss:3.986    Policy Loss: 11.760   Value Loss: 3.009    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 23716      Buffer Size: 23716      Transition Number: 246.830 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:15:25,564][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 12.835   Value Loss: 3.359    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 24005      Buffer Size: 24005      Transition Number: 250.552 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:19:06,647][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.041    [weighted Loss:4.041    Policy Loss: 12.252   Value Loss: 3.281    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 24289      Buffer Size: 24289      Transition Number: 254.475 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:22:52,409][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 12.442   Value Loss: 3.289    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 24597      Buffer Size: 24597      Transition Number: 258.602 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:26:38,082][train][INFO][train.py>_log] ==> #70000      Total Loss: 5.562    [weighted Loss:5.562    Policy Loss: 11.668   Value Loss: 2.880    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 24867      Buffer Size: 24867      Transition Number: 262.992 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:30:25,885][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.356    [weighted Loss:2.356    Policy Loss: 11.657   Value Loss: 2.748    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 25165      Buffer Size: 25165      Transition Number: 267.289 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:34:17,077][train][INFO][train.py>_log] ==> #72000      Total Loss: 5.561    [weighted Loss:5.561    Policy Loss: 11.535   Value Loss: 2.748    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 25438      Buffer Size: 25438      Transition Number: 271.425 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:38:09,219][train][INFO][train.py>_log] ==> #73000      Total Loss: 4.186    [weighted Loss:4.186    Policy Loss: 11.237   Value Loss: 3.070    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 25695      Buffer Size: 25695      Transition Number: 275.273 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:42:04,918][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.199    [weighted Loss:3.199    Policy Loss: 12.149   Value Loss: 3.089    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 25999      Buffer Size: 25999      Transition Number: 279.618 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:45:58,685][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.942    [weighted Loss:3.942    Policy Loss: 12.430   Value Loss: 3.447    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 26297      Buffer Size: 26297      Transition Number: 283.531 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:50:00,697][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 11.449   Value Loss: 3.197    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 26528      Buffer Size: 26528      Transition Number: 287.526 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:54:11,021][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.446    [weighted Loss:3.446    Policy Loss: 12.242   Value Loss: 3.207    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 26712      Buffer Size: 26712      Transition Number: 291.558 k Batch Size: 128        Lr: 0.100   
[2021-11-07 16:58:26,036][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.113    [weighted Loss:5.113    Policy Loss: 11.511   Value Loss: 3.230    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 26938      Buffer Size: 26938      Transition Number: 296.072 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:02:46,327][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.470    [weighted Loss:4.470    Policy Loss: 12.226   Value Loss: 3.174    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 27158      Buffer Size: 27158      Transition Number: 301.085 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:07:13,824][train][INFO][train.py>_log] ==> #80000      Total Loss: 4.742    [weighted Loss:4.742    Policy Loss: 12.280   Value Loss: 3.492    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 27324      Buffer Size: 27324      Transition Number: 306.224 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:11:44,072][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.588    [weighted Loss:4.588    Policy Loss: 11.587   Value Loss: 3.286    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 27471      Buffer Size: 27471      Transition Number: 310.803 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:16:15,287][train][INFO][train.py>_log] ==> #82000      Total Loss: 6.044    [weighted Loss:6.044    Policy Loss: 11.791   Value Loss: 3.834    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 27688      Buffer Size: 27688      Transition Number: 314.705 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:20:47,016][train][INFO][train.py>_log] ==> #83000      Total Loss: 4.391    [weighted Loss:4.391    Policy Loss: 11.552   Value Loss: 3.726    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 27973      Buffer Size: 27973      Transition Number: 319.051 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:25:23,667][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 11.498   Value Loss: 3.599    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 28145      Buffer Size: 28145      Transition Number: 324.475 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:30:11,314][train][INFO][train.py>_log] ==> #85000      Total Loss: 5.071    [weighted Loss:5.071    Policy Loss: 11.709   Value Loss: 3.610    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 28319      Buffer Size: 28319      Transition Number: 329.180 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:35:01,277][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.849    [weighted Loss:4.849    Policy Loss: 11.077   Value Loss: 4.061    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 28473      Buffer Size: 28473      Transition Number: 334.653 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:39:53,295][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.452    [weighted Loss:4.452    Policy Loss: 11.131   Value Loss: 3.416    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 28786      Buffer Size: 28786      Transition Number: 339.313 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:44:41,015][train][INFO][train.py>_log] ==> #88000      Total Loss: 5.599    [weighted Loss:5.599    Policy Loss: 12.172   Value Loss: 3.956    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 29151      Buffer Size: 29151      Transition Number: 344.374 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:49:37,078][train][INFO][train.py>_log] ==> #89000      Total Loss: 5.875    [weighted Loss:5.875    Policy Loss: 11.399   Value Loss: 3.829    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 29297      Buffer Size: 29297      Transition Number: 348.434 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:54:38,845][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.643    [weighted Loss:3.643    Policy Loss: 12.102   Value Loss: 3.615    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 29473      Buffer Size: 29473      Transition Number: 353.402 k Batch Size: 128        Lr: 0.100   
[2021-11-07 17:59:46,249][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 11.698   Value Loss: 3.716    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 29647      Buffer Size: 29647      Transition Number: 359.295 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:05:09,702][train][INFO][train.py>_log] ==> #92000      Total Loss: 5.202    [weighted Loss:5.202    Policy Loss: 10.560   Value Loss: 3.905    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 29786      Buffer Size: 29786      Transition Number: 365.550 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:10:39,412][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 11.212   Value Loss: 3.705    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 29933      Buffer Size: 29933      Transition Number: 371.841 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:16:09,937][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.375    [weighted Loss:4.375    Policy Loss: 11.003   Value Loss: 3.772    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 30102      Buffer Size: 30102      Transition Number: 378.336 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:21:43,248][train][INFO][train.py>_log] ==> #95000      Total Loss: 6.413    [weighted Loss:6.413    Policy Loss: 11.198   Value Loss: 3.586    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 30298      Buffer Size: 30298      Transition Number: 384.017 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:27:20,229][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.494    [weighted Loss:3.494    Policy Loss: 10.775   Value Loss: 3.542    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 30479      Buffer Size: 30479      Transition Number: 390.439 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:33:02,305][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.878    [weighted Loss:2.878    Policy Loss: 11.510   Value Loss: 3.765    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 30662      Buffer Size: 30662      Transition Number: 396.423 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:38:51,826][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.628    [weighted Loss:3.628    Policy Loss: 11.068   Value Loss: 3.730    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 30811      Buffer Size: 30570      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:44:54,699][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 10.229   Value Loss: 3.352    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 30968      Buffer Size: 29825      Transition Number: 399.988 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:51:10,243][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.495    [weighted Loss:3.495    Policy Loss: 10.999   Value Loss: 3.753    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 31142      Buffer Size: 29034      Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-07 18:57:31,405][train][INFO][train.py>_log] ==> #101000     Total Loss: 4.212    [weighted Loss:4.212    Policy Loss: 10.796   Value Loss: 4.114    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 31315      Buffer Size: 28440      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:03:59,686][train][INFO][train.py>_log] ==> #102000     Total Loss: 4.408    [weighted Loss:4.408    Policy Loss: 10.192   Value Loss: 3.843    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 31479      Buffer Size: 27853      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:10:39,332][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.245    [weighted Loss:3.245    Policy Loss: 9.787    Value Loss: 3.621    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 31628      Buffer Size: 27078      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:17:29,152][train][INFO][train.py>_log] ==> #104000     Total Loss: 7.159    [weighted Loss:7.159    Policy Loss: 11.167   Value Loss: 3.889    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 31788      Buffer Size: 26301      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:24:31,100][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.752    [weighted Loss:3.752    Policy Loss: 9.246    Value Loss: 3.740    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 31930      Buffer Size: 25474      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:31:43,955][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.756    [weighted Loss:2.756    Policy Loss: 9.531    Value Loss: 3.855    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 32089      Buffer Size: 24461      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:39:01,585][train][INFO][train.py>_log] ==> #107000     Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 9.878    Value Loss: 3.735    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 32279      Buffer Size: 23691      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:46:38,281][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.442    [weighted Loss:3.442    Policy Loss: 9.694    Value Loss: 4.080    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 32445      Buffer Size: 22667      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 19:54:23,548][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.473    [weighted Loss:3.473    Policy Loss: 9.343    Value Loss: 3.793    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 32642      Buffer Size: 21862      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:02:13,661][train][INFO][train.py>_log] ==> #110000     Total Loss: 5.128    [weighted Loss:5.128    Policy Loss: 8.687    Value Loss: 3.935    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 32910      Buffer Size: 21286      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:10:10,719][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 8.743    Value Loss: 3.849    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 33213      Buffer Size: 20696      Transition Number: 399.995 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:18:16,685][train][INFO][train.py>_log] ==> #112000     Total Loss: 4.674    [weighted Loss:4.674    Policy Loss: 8.869    Value Loss: 3.864    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 33422      Buffer Size: 19907      Transition Number: 399.996 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:26:29,960][train][INFO][train.py>_log] ==> #113000     Total Loss: 3.829    [weighted Loss:3.829    Policy Loss: 8.277    Value Loss: 3.881    Reward Loss: 0.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 33723      Buffer Size: 19428      Transition Number: 400.001 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:34:45,764][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 7.651    Value Loss: 4.262    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 33961      Buffer Size: 18918      Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:43:07,793][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.352    [weighted Loss:3.352    Policy Loss: 8.372    Value Loss: 3.828    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 34154      Buffer Size: 17980      Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-07 20:51:34,189][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 8.455    Value Loss: 3.795    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 34459      Buffer Size: 17277      Transition Number: 399.989 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:00:07,671][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.216    [weighted Loss:3.216    Policy Loss: 7.410    Value Loss: 3.973    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 34669      Buffer Size: 16590      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:08:52,782][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.769    [weighted Loss:1.769    Policy Loss: 8.479    Value Loss: 4.057    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 34898      Buffer Size: 15798      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:17:50,312][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 6.869    Value Loss: 3.627    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 35093      Buffer Size: 14585      Transition Number: 399.981 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:26:53,755][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 7.760    Value Loss: 3.837    Reward Loss: 0.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 35300      Buffer Size: 13975      Transition Number: 399.984 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:36:09,196][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 6.847    Value Loss: 3.674    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 35493      Buffer Size: 13256      Transition Number: 400.067 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:45:36,832][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 8.278    Value Loss: 4.116    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 35724      Buffer Size: 12414      Transition Number: 399.997 k Batch Size: 128        Lr: 0.100   
[2021-11-07 21:55:09,173][train][INFO][train.py>_log] ==> #123000     Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 6.501    Value Loss: 4.098    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 35981      Buffer Size: 11695      Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:04:51,468][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 7.175    Value Loss: 3.936    Reward Loss: 0.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 36201      Buffer Size: 10924      Transition Number: 399.994 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:14:49,753][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 6.680    Value Loss: 3.582    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 36412      Buffer Size: 10142      Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:24:55,991][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 6.089    Value Loss: 3.727    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 36693      Buffer Size: 9735       Transition Number: 399.999 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:35:31,930][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.013    [weighted Loss:3.013    Policy Loss: 6.754    Value Loss: 3.799    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 36999      Buffer Size: 9555       Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:46:24,546][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 6.256    Value Loss: 3.859    Reward Loss: 0.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 37257      Buffer Size: 9110       Transition Number: 399.990 k Batch Size: 128        Lr: 0.100   
[2021-11-07 22:57:34,074][train][INFO][train.py>_log] ==> #129000     Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 5.892    Value Loss: 3.893    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 37538      Buffer Size: 8785       Transition Number: 399.998 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:08:43,174][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 6.990    Value Loss: 3.908    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 37777      Buffer Size: 8373       Transition Number: 399.947 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:19:31,019][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.589    [weighted Loss:2.589    Policy Loss: 5.841    Value Loss: 3.997    Reward Loss: 0.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 38082      Buffer Size: 8288       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:29:58,978][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.448    [weighted Loss:2.448    Policy Loss: 5.667    Value Loss: 3.689    Reward Loss: 0.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 38323      Buffer Size: 8143       Transition Number: 400.000 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:40:46,130][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 6.248    Value Loss: 3.935    Reward Loss: 0.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 38588      Buffer Size: 7984       Transition Number: 400.147 k Batch Size: 128        Lr: 0.100   
[2021-11-07 23:51:28,072][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 5.826    Value Loss: 3.880    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 38817      Buffer Size: 7856       Transition Number: 399.961 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:02:32,894][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 5.540    Value Loss: 3.806    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 39072      Buffer Size: 7747       Transition Number: 399.987 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:13:19,152][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.513    [weighted Loss:2.513    Policy Loss: 5.499    Value Loss: 3.704    Reward Loss: 0.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 39323      Buffer Size: 7703       Transition Number: 399.957 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:24:34,305][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 5.707    Value Loss: 3.610    Reward Loss: 0.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 39575      Buffer Size: 7696       Transition Number: 400.145 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:35:13,999][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 5.465    Value Loss: 4.049    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 39814      Buffer Size: 7697       Transition Number: 399.942 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:45:58,298][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 5.152    Value Loss: 3.722    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 40083      Buffer Size: 7677       Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
[2021-11-08 00:56:34,768][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.825    [weighted Loss:2.825    Policy Loss: 6.587    Value Loss: 3.720    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 40425      Buffer Size: 7763       Transition Number: 399.992 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:07:21,773][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 6.190    Value Loss: 4.133    Reward Loss: 0.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 40660      Buffer Size: 7582       Transition Number: 399.929 k Batch Size: 128        Lr: 0.100   
[2021-11-08 01:18:17,150][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 6.430    Value Loss: 4.063    Reward Loss: 0.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 41006      Buffer Size: 7604       Transition Number: 399.993 k Batch Size: 128        Lr: 0.100   
