[2022-02-23 16:14:30,634][train][INFO][train.py>_log] ==> #0          Total Loss: 47.731   [weighted Loss:47.731   Policy Loss: 13.259   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1123       Buffer Size: 1123       Transition Number: 11.248  k Batch Size: 256        Lr: 0.00000 
[2022-02-23 16:17:14,961][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.944    [weighted Loss:6.944    Policy Loss: 14.083   Value Loss: 4.855    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 11639      Buffer Size: 11639      Transition Number: 145.320 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:19:55,833][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 12.902   Value Loss: 4.511    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 21765      Buffer Size: 21765      Transition Number: 270.818 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:22:37,336][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.090    [weighted Loss:4.090    Policy Loss: 11.791   Value Loss: 4.196    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 39698      Buffer Size: 39698      Transition Number: 402.627 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:25:20,005][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.571    [weighted Loss:4.571    Policy Loss: 11.195   Value Loss: 4.315    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 57739      Buffer Size: 57739      Transition Number: 532.225 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:28:00,621][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.618    [weighted Loss:4.618    Policy Loss: 9.816    Value Loss: 4.053    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 74085      Buffer Size: 74085      Transition Number: 661.905 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:30:40,834][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.323    [weighted Loss:5.323    Policy Loss: 9.929    Value Loss: 4.209    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 90321      Buffer Size: 90321      Transition Number: 789.399 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:33:27,161][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.166    [weighted Loss:4.166    Policy Loss: 9.424    Value Loss: 4.032    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 105157     Buffer Size: 105157     Transition Number: 913.766 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:36:23,180][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.255    [weighted Loss:5.255    Policy Loss: 10.313   Value Loss: 4.174    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 120959     Buffer Size: 116709     Transition Number: 1000.081k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:39:27,004][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.621    [weighted Loss:3.621    Policy Loss: 9.239    Value Loss: 3.957    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 135458     Buffer Size: 119822     Transition Number: 1000.124k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:42:22,383][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.853    [weighted Loss:4.853    Policy Loss: 9.171    Value Loss: 4.225    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 149192     Buffer Size: 119646     Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:45:15,120][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.807    [weighted Loss:5.807    Policy Loss: 9.014    Value Loss: 4.237    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 157157     Buffer Size: 110926     Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:48:08,522][train][INFO][train.py>_log] ==> #12000      Total Loss: 5.009    [weighted Loss:5.009    Policy Loss: 9.449    Value Loss: 3.987    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 164931     Buffer Size: 102058     Transition Number: 1000.182k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:51:04,598][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.586    [weighted Loss:4.586    Policy Loss: 7.270    Value Loss: 4.103    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 172280     Buffer Size: 92489      Transition Number: 1000.220k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:54:00,884][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.947    [weighted Loss:3.947    Policy Loss: 6.054    Value Loss: 4.425    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 179264     Buffer Size: 83814      Transition Number: 1000.139k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:56:55,955][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 6.025    Value Loss: 4.446    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 188210     Buffer Size: 77435      Transition Number: 1000.298k Batch Size: 256        Lr: 0.10000 
[2022-02-23 16:59:49,485][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.651    [weighted Loss:3.651    Policy Loss: 5.228    Value Loss: 4.677    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 196920     Buffer Size: 71480      Transition Number: 1000.132k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:02:41,695][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 5.260    Value Loss: 4.514    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 203084     Buffer Size: 65603      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:05:32,735][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.318    [weighted Loss:2.318    Policy Loss: 5.597    Value Loss: 4.413    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 209252     Buffer Size: 59313      Transition Number: 1000.210k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:08:20,110][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.387    [weighted Loss:3.387    Policy Loss: 5.494    Value Loss: 4.531    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 213804     Buffer Size: 56579      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:11:10,259][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.992    [weighted Loss:2.992    Policy Loss: 5.271    Value Loss: 4.487    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 218277     Buffer Size: 53804      Transition Number: 1000.165k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:13:53,678][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.449    [weighted Loss:3.449    Policy Loss: 4.674    Value Loss: 4.264    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 221050     Buffer Size: 50772      Transition Number: 1000.453k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:16:38,190][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 4.424    Value Loss: 4.172    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 223847     Buffer Size: 47566      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:19:23,661][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 5.006    Value Loss: 4.280    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 225832     Buffer Size: 42910      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:22:07,570][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 4.082    Value Loss: 4.161    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 227784     Buffer Size: 37492      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:24:54,134][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.044    [weighted Loss:1.044    Policy Loss: 3.573    Value Loss: 4.010    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 229635     Buffer Size: 31733      Transition Number: 1000.180k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:27:39,357][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 3.577    Value Loss: 4.047    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 231491     Buffer Size: 27676      Transition Number: 1000.024k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:30:22,249][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 3.689    Value Loss: 4.371    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 233326     Buffer Size: 23850      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:33:09,699][train][INFO][train.py>_log] ==> #28000      Total Loss: 1.330    [weighted Loss:1.330    Policy Loss: 3.401    Value Loss: 4.248    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 235194     Buffer Size: 20953      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:35:56,901][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.854    [weighted Loss:1.854    Policy Loss: 3.375    Value Loss: 4.231    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 237018     Buffer Size: 18366      Transition Number: 1000.239k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:38:39,929][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.185    [weighted Loss:2.185    Policy Loss: 3.511    Value Loss: 4.502    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 238771     Buffer Size: 17213      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:41:23,262][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 3.660    Value Loss: 4.316    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 240711     Buffer Size: 16279      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:44:06,179][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.795    [weighted Loss:1.795    Policy Loss: 3.653    Value Loss: 4.613    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 242503     Buffer Size: 16159      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:46:47,827][train][INFO][train.py>_log] ==> #33000      Total Loss: 0.651    [weighted Loss:0.651    Policy Loss: 3.597    Value Loss: 4.712    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 244521     Buffer Size: 16150      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:49:29,402][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.678    [weighted Loss:1.678    Policy Loss: 3.825    Value Loss: 4.421    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 246359     Buffer Size: 16287      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:52:12,093][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.384    [weighted Loss:1.384    Policy Loss: 3.883    Value Loss: 4.393    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 248429     Buffer Size: 16498      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:54:52,995][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 4.036    Value Loss: 4.498    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 250415     Buffer Size: 16736      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 17:57:32,413][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.780    [weighted Loss:1.780    Policy Loss: 4.049    Value Loss: 4.431    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 252344     Buffer Size: 16980      Transition Number: 1000.353k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:00:15,056][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 4.238    Value Loss: 4.617    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 254315     Buffer Size: 17156      Transition Number: 999.941 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:02:58,245][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.296    [weighted Loss:1.296    Policy Loss: 3.425    Value Loss: 4.486    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 256218     Buffer Size: 17289      Transition Number: 1000.506k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:05:41,815][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.641    [weighted Loss:1.641    Policy Loss: 3.625    Value Loss: 4.700    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 258181     Buffer Size: 17388      Transition Number: 1000.081k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:08:26,956][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 3.717    Value Loss: 4.713    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 260167     Buffer Size: 17399      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:11:08,964][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 3.430    Value Loss: 4.636    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 261996     Buffer Size: 17389      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:13:54,065][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.819    [weighted Loss:1.819    Policy Loss: 3.465    Value Loss: 4.837    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 263950     Buffer Size: 17260      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:16:36,107][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 3.649    Value Loss: 4.752    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 265847     Buffer Size: 17058      Transition Number: 1000.138k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:19:17,768][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 4.202    Value Loss: 4.978    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 267759     Buffer Size: 16962      Transition Number: 1000.266k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:22:00,141][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 4.261    Value Loss: 5.393    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 269658     Buffer Size: 16899      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:24:43,796][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 4.365    Value Loss: 4.957    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 271697     Buffer Size: 16932      Transition Number: 1000.216k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:27:24,172][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 4.037    Value Loss: 5.217    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 273744     Buffer Size: 17092      Transition Number: 1000.143k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:30:08,006][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.745    [weighted Loss:1.745    Policy Loss: 3.673    Value Loss: 5.005    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 275821     Buffer Size: 17205      Transition Number: 1000.205k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:32:50,195][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 3.142    Value Loss: 4.810    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 277850     Buffer Size: 17359      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:35:31,729][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.010    [weighted Loss:2.010    Policy Loss: 4.130    Value Loss: 5.074    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 280013     Buffer Size: 17625      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:38:13,299][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 3.649    Value Loss: 4.965    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 282136     Buffer Size: 18002      Transition Number: 1000.087k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:40:56,898][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.222    [weighted Loss:1.222    Policy Loss: 3.918    Value Loss: 5.086    Reward Loss: 0.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 284369     Buffer Size: 18375      Transition Number: 1000.157k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:43:38,236][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.539    [weighted Loss:1.539    Policy Loss: 3.508    Value Loss: 5.018    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 286568     Buffer Size: 18673      Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:46:19,727][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 3.445    Value Loss: 5.256    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 288708     Buffer Size: 18927      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:49:02,999][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 3.422    Value Loss: 5.150    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 290866     Buffer Size: 19052      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:51:43,730][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 3.950    Value Loss: 5.396    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 292945     Buffer Size: 19187      Transition Number: 1000.101k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:54:26,449][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 3.869    Value Loss: 5.400    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 295071     Buffer Size: 19264      Transition Number: 1000.128k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:57:09,257][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 3.746    Value Loss: 5.224    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 297245     Buffer Size: 19366      Transition Number: 1000.106k Batch Size: 256        Lr: 0.10000 
[2022-02-23 18:59:51,506][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 4.089    Value Loss: 5.264    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 299396     Buffer Size: 19340      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:02:34,479][train][INFO][train.py>_log] ==> #61000      Total Loss: 1.914    [weighted Loss:1.914    Policy Loss: 3.866    Value Loss: 5.013    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 301414     Buffer Size: 19257      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:05:17,055][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.567    [weighted Loss:1.567    Policy Loss: 3.696    Value Loss: 4.957    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 303517     Buffer Size: 19136      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:07:57,818][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 3.560    Value Loss: 5.374    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 305621     Buffer Size: 18997      Transition Number: 1000.195k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:10:42,283][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.400    [weighted Loss:1.400    Policy Loss: 3.372    Value Loss: 5.000    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 307811     Buffer Size: 18876      Transition Number: 1000.085k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:13:25,452][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 3.341    Value Loss: 5.416    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 309722     Buffer Size: 18715      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:16:08,004][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 4.024    Value Loss: 5.003    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 311732     Buffer Size: 18574      Transition Number: 1000.260k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:18:51,871][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 3.628    Value Loss: 5.078    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 313764     Buffer Size: 18485      Transition Number: 1000.144k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:21:34,611][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 3.601    Value Loss: 5.021    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 315823     Buffer Size: 18375      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:24:16,701][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 3.765    Value Loss: 4.948    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 317821     Buffer Size: 18176      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:27:00,761][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.335    [weighted Loss:2.335    Policy Loss: 4.003    Value Loss: 5.192    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 319809     Buffer Size: 18092      Transition Number: 1000.291k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:29:43,878][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 3.902    Value Loss: 5.054    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 321810     Buffer Size: 17976      Transition Number: 1000.119k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:32:26,689][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 3.686    Value Loss: 5.055    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 323822     Buffer Size: 17940      Transition Number: 1000.139k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:35:09,850][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 4.122    Value Loss: 5.104    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 325800     Buffer Size: 17880      Transition Number: 1000.131k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:37:53,576][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 3.897    Value Loss: 5.273    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 327823     Buffer Size: 17918      Transition Number: 1000.226k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:40:36,201][train][INFO][train.py>_log] ==> #75000      Total Loss: 1.106    [weighted Loss:1.106    Policy Loss: 4.095    Value Loss: 4.912    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 329929     Buffer Size: 17937      Transition Number: 1000.017k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:43:18,169][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 4.324    Value Loss: 5.110    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 331958     Buffer Size: 17972      Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:46:04,002][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.112    [weighted Loss:2.112    Policy Loss: 4.475    Value Loss: 5.117    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 333988     Buffer Size: 17942      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:48:43,504][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.432    [weighted Loss:1.432    Policy Loss: 3.990    Value Loss: 5.047    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 335972     Buffer Size: 18015      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:51:29,315][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 3.952    Value Loss: 5.133    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 337979     Buffer Size: 18010      Transition Number: 1000.002k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:54:13,007][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.312    [weighted Loss:2.312    Policy Loss: 3.951    Value Loss: 5.106    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 339993     Buffer Size: 18021      Transition Number: 1000.103k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:56:57,734][train][INFO][train.py>_log] ==> #81000      Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 3.830    Value Loss: 5.263    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 342019     Buffer Size: 17999      Transition Number: 1000.160k Batch Size: 256        Lr: 0.10000 
[2022-02-23 19:59:40,559][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.008    [weighted Loss:2.008    Policy Loss: 4.079    Value Loss: 5.387    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 344042     Buffer Size: 18021      Transition Number: 1000.081k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:02:24,247][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.220    [weighted Loss:2.220    Policy Loss: 3.901    Value Loss: 4.874    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 346076     Buffer Size: 17995      Transition Number: 1000.180k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:05:07,510][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 4.745    Value Loss: 4.967    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 348106     Buffer Size: 17919      Transition Number: 1000.205k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:07:53,820][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 4.025    Value Loss: 5.173    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 350205     Buffer Size: 17928      Transition Number: 1000.164k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:10:39,132][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.127    [weighted Loss:2.127    Policy Loss: 3.876    Value Loss: 5.166    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 352279     Buffer Size: 17941      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:13:24,950][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 3.378    Value Loss: 4.852    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 354309     Buffer Size: 17920      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:16:10,766][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 3.783    Value Loss: 5.071    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 356284     Buffer Size: 17919      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:18:54,795][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 3.641    Value Loss: 5.324    Reward Loss: 0.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 358341     Buffer Size: 17885      Transition Number: 1000.310k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:21:38,963][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 3.708    Value Loss: 5.236    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 360351     Buffer Size: 17935      Transition Number: 1000.252k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:24:28,213][train][INFO][train.py>_log] ==> #91000      Total Loss: 1.188    [weighted Loss:1.188    Policy Loss: 3.805    Value Loss: 5.162    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 362488     Buffer Size: 17930      Transition Number: 1000.120k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:27:13,401][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 3.867    Value Loss: 5.073    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 364536     Buffer Size: 17963      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:29:57,340][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.695    [weighted Loss:1.695    Policy Loss: 3.920    Value Loss: 5.100    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 366517     Buffer Size: 17885      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:32:42,848][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 4.495    Value Loss: 5.496    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 368490     Buffer Size: 17815      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:35:28,535][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.119    [weighted Loss:2.119    Policy Loss: 4.529    Value Loss: 4.972    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 370540     Buffer Size: 17757      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:38:09,146][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.268    [weighted Loss:1.268    Policy Loss: 4.319    Value Loss: 5.132    Reward Loss: 0.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 372516     Buffer Size: 17806      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:40:52,673][train][INFO][train.py>_log] ==> #97000      Total Loss: 1.666    [weighted Loss:1.666    Policy Loss: 4.122    Value Loss: 4.992    Reward Loss: 0.996    Consistency Loss: 0.000    ] Replay Episodes Collected: 374559     Buffer Size: 17772      Transition Number: 999.956 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:43:36,267][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 4.262    Value Loss: 5.231    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 376536     Buffer Size: 17790      Transition Number: 1000.305k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:46:16,603][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 4.475    Value Loss: 5.005    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 378582     Buffer Size: 17798      Transition Number: 999.982 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:48:59,949][train][INFO][train.py>_log] ==> #100000     Total Loss: 1.447    [weighted Loss:1.447    Policy Loss: 4.318    Value Loss: 5.326    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 380548     Buffer Size: 17845      Transition Number: 1000.322k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:51:43,171][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 4.119    Value Loss: 5.612    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 382621     Buffer Size: 17830      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:54:25,461][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 4.619    Value Loss: 5.083    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 384601     Buffer Size: 17884      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:57:08,245][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 4.377    Value Loss: 5.306    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 386489     Buffer Size: 17873      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 20:59:51,164][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 3.855    Value Loss: 5.014    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 388466     Buffer Size: 17813      Transition Number: 1000.022k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:02:33,206][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.442    [weighted Loss:1.442    Policy Loss: 3.902    Value Loss: 5.068    Reward Loss: 0.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 390427     Buffer Size: 17762      Transition Number: 1000.076k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:05:17,379][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.217    [weighted Loss:1.217    Policy Loss: 3.605    Value Loss: 4.968    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 392382     Buffer Size: 17733      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:08:00,791][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 4.041    Value Loss: 4.991    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 394341     Buffer Size: 17702      Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:10:42,590][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.994    [weighted Loss:1.994    Policy Loss: 3.732    Value Loss: 4.987    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 396283     Buffer Size: 17605      Transition Number: 1000.272k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:13:26,329][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.973    [weighted Loss:1.973    Policy Loss: 4.115    Value Loss: 5.227    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 398217     Buffer Size: 17546      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:16:12,422][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 3.794    Value Loss: 5.100    Reward Loss: 0.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 400281     Buffer Size: 17490      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:18:58,406][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 3.880    Value Loss: 5.040    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 402236     Buffer Size: 17388      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:21:40,174][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 4.059    Value Loss: 5.057    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 404093     Buffer Size: 17272      Transition Number: 999.934 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:24:24,709][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 3.917    Value Loss: 5.018    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 406139     Buffer Size: 17227      Transition Number: 1000.217k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:27:07,597][train][INFO][train.py>_log] ==> #114000     Total Loss: 0.986    [weighted Loss:0.986    Policy Loss: 4.108    Value Loss: 5.148    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 408127     Buffer Size: 17249      Transition Number: 1000.075k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:29:51,962][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 4.262    Value Loss: 5.084    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 410124     Buffer Size: 17272      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:32:37,645][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 4.087    Value Loss: 5.264    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 412118     Buffer Size: 17243      Transition Number: 1000.186k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:35:22,579][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 4.369    Value Loss: 5.092    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 414068     Buffer Size: 17166      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:38:07,646][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 4.388    Value Loss: 5.157    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 416063     Buffer Size: 17086      Transition Number: 1000.085k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:40:50,317][train][INFO][train.py>_log] ==> #119000     Total Loss: 1.267    [weighted Loss:1.267    Policy Loss: 3.989    Value Loss: 5.398    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 417926     Buffer Size: 17140      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:43:33,032][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.096    [weighted Loss:1.096    Policy Loss: 3.999    Value Loss: 5.311    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 419906     Buffer Size: 17177      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:46:17,672][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 4.397    Value Loss: 5.495    Reward Loss: 0.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 421888     Buffer Size: 17239      Transition Number: 1000.005k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:49:02,575][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.101    [weighted Loss:2.101    Policy Loss: 4.532    Value Loss: 5.383    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 423829     Buffer Size: 17237      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:51:47,056][train][INFO][train.py>_log] ==> #123000     Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 4.762    Value Loss: 5.591    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 425750     Buffer Size: 17196      Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:54:34,410][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 5.275    Value Loss: 4.927    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 427710     Buffer Size: 17123      Transition Number: 1000.039k Batch Size: 256        Lr: 0.10000 
[2022-02-23 21:57:21,127][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 5.222    Value Loss: 5.362    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 429748     Buffer Size: 17201      Transition Number: 1000.017k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:00:05,855][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 5.764    Value Loss: 5.589    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 431846     Buffer Size: 17285      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:02:50,728][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 5.015    Value Loss: 5.645    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 433781     Buffer Size: 17309      Transition Number: 1000.186k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:05:35,036][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.726    [weighted Loss:2.726    Policy Loss: 5.111    Value Loss: 5.556    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 435722     Buffer Size: 17319      Transition Number: 1000.145k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:08:20,326][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 5.498    Value Loss: 5.258    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 437773     Buffer Size: 17306      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:11:04,104][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 6.150    Value Loss: 5.466    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 439667     Buffer Size: 17327      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:13:51,175][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 5.198    Value Loss: 5.655    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 441715     Buffer Size: 17291      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:16:34,953][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 5.686    Value Loss: 5.333    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 443666     Buffer Size: 17326      Transition Number: 1000.219k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:19:20,413][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.135    [weighted Loss:1.135    Policy Loss: 5.420    Value Loss: 5.278    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 445494     Buffer Size: 17239      Transition Number: 1000.158k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:22:08,405][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.149    [weighted Loss:2.149    Policy Loss: 5.335    Value Loss: 5.040    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 447407     Buffer Size: 17036      Transition Number: 1000.261k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:24:58,176][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 5.839    Value Loss: 5.133    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 449351     Buffer Size: 16876      Transition Number: 1000.486k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:27:45,631][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.906    [weighted Loss:1.906    Policy Loss: 5.084    Value Loss: 5.490    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 451264     Buffer Size: 16722      Transition Number: 1000.005k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:30:31,017][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 5.611    Value Loss: 5.352    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 453150     Buffer Size: 16656      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:33:17,520][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.223    [weighted Loss:3.223    Policy Loss: 6.011    Value Loss: 5.405    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 455071     Buffer Size: 16560      Transition Number: 1000.027k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:36:05,503][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 6.036    Value Loss: 5.262    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 457022     Buffer Size: 16501      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:38:49,830][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 6.033    Value Loss: 5.366    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 458904     Buffer Size: 16410      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:41:37,313][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 6.565    Value Loss: 5.334    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 460949     Buffer Size: 16442      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:44:22,679][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.741    [weighted Loss:2.741    Policy Loss: 6.111    Value Loss: 5.265    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 462918     Buffer Size: 16567      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:47:09,778][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.188    Value Loss: 5.300    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 464789     Buffer Size: 16593      Transition Number: 1000.131k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:49:56,180][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.482    [weighted Loss:3.482    Policy Loss: 5.845    Value Loss: 5.326    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 466604     Buffer Size: 16641      Transition Number: 1000.103k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:52:43,920][train][INFO][train.py>_log] ==> #145000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 5.485    Value Loss: 5.383    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 468542     Buffer Size: 16599      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:55:31,255][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 6.201    Value Loss: 5.192    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 470488     Buffer Size: 16513      Transition Number: 999.925 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 22:58:18,613][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 5.942    Value Loss: 4.978    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 472340     Buffer Size: 16526      Transition Number: 1000.002k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:01:05,387][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 6.039    Value Loss: 5.176    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 474318     Buffer Size: 16524      Transition Number: 1000.102k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:03:54,967][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.013    [weighted Loss:3.013    Policy Loss: 5.102    Value Loss: 5.501    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 476238     Buffer Size: 16508      Transition Number: 1000.005k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:06:44,800][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.726    [weighted Loss:2.726    Policy Loss: 5.547    Value Loss: 5.486    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 478204     Buffer Size: 16392      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:09:33,255][train][INFO][train.py>_log] ==> #151000     Total Loss: 3.524    [weighted Loss:3.524    Policy Loss: 6.234    Value Loss: 5.655    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 480062     Buffer Size: 16278      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:12:21,916][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.848    [weighted Loss:2.848    Policy Loss: 5.094    Value Loss: 5.071    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 481953     Buffer Size: 16224      Transition Number: 1000.373k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:15:08,995][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.515    [weighted Loss:2.515    Policy Loss: 5.292    Value Loss: 4.984    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 483863     Buffer Size: 16190      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:17:58,866][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 5.426    Value Loss: 5.034    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 485802     Buffer Size: 16248      Transition Number: 1000.095k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:20:47,029][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.759    [weighted Loss:2.759    Policy Loss: 5.350    Value Loss: 5.361    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 487795     Buffer Size: 16256      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:23:33,295][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 5.748    Value Loss: 5.168    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 489707     Buffer Size: 16282      Transition Number: 1000.035k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:26:21,618][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 5.266    Value Loss: 5.358    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 491622     Buffer Size: 16252      Transition Number: 1000.207k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:29:09,779][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.519    [weighted Loss:2.519    Policy Loss: 5.103    Value Loss: 5.261    Reward Loss: 0.987    Consistency Loss: 0.000    ] Replay Episodes Collected: 493513     Buffer Size: 16222      Transition Number: 1000.291k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:31:58,034][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 5.123    Value Loss: 5.118    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 495325     Buffer Size: 16153      Transition Number: 1000.071k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:34:43,611][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.407    [weighted Loss:1.407    Policy Loss: 5.637    Value Loss: 5.026    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 497173     Buffer Size: 16127      Transition Number: 1000.172k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:37:34,193][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 4.734    Value Loss: 5.185    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 499271     Buffer Size: 16133      Transition Number: 999.978 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:40:21,933][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.075    [weighted Loss:1.075    Policy Loss: 4.732    Value Loss: 5.285    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 501219     Buffer Size: 16197      Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:43:09,350][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.678    [weighted Loss:2.678    Policy Loss: 5.000    Value Loss: 4.929    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 503125     Buffer Size: 16174      Transition Number: 1000.060k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:45:58,437][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 4.887    Value Loss: 5.028    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 505003     Buffer Size: 16060      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:48:48,003][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 5.164    Value Loss: 5.199    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 506833     Buffer Size: 15998      Transition Number: 1000.022k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:51:35,149][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 4.932    Value Loss: 5.188    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 508759     Buffer Size: 15913      Transition Number: 1000.033k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:54:22,816][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 4.355    Value Loss: 5.207    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 510667     Buffer Size: 15878      Transition Number: 999.928 k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:57:07,553][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.356    [weighted Loss:2.356    Policy Loss: 5.572    Value Loss: 4.992    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 512472     Buffer Size: 15900      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-23 23:59:54,776][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 5.709    Value Loss: 4.858    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 514368     Buffer Size: 15930      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:02:42,179][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 6.046    Value Loss: 5.237    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 516350     Buffer Size: 15950      Transition Number: 1000.087k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:05:32,581][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 5.728    Value Loss: 5.311    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 518322     Buffer Size: 15985      Transition Number: 1000.094k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:08:20,080][train][INFO][train.py>_log] ==> #172000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 5.567    Value Loss: 5.032    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 520251     Buffer Size: 16047      Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:11:06,532][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 5.987    Value Loss: 5.054    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 522111     Buffer Size: 16119      Transition Number: 1000.509k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:13:56,382][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 6.396    Value Loss: 5.095    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 524030     Buffer Size: 16178      Transition Number: 1000.221k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:16:45,415][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 6.279    Value Loss: 5.422    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 525944     Buffer Size: 16195      Transition Number: 1000.117k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:19:38,004][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 6.665    Value Loss: 5.119    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 527914     Buffer Size: 16182      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:22:24,800][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.667    [weighted Loss:1.667    Policy Loss: 6.623    Value Loss: 5.309    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 529860     Buffer Size: 16265      Transition Number: 1000.075k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:25:10,148][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 7.002    Value Loss: 5.244    Reward Loss: 0.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 531769     Buffer Size: 16246      Transition Number: 999.933 k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:27:57,625][train][INFO][train.py>_log] ==> #179000     Total Loss: 3.702    [weighted Loss:3.702    Policy Loss: 6.773    Value Loss: 4.898    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 533642     Buffer Size: 16175      Transition Number: 1000.079k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:30:45,380][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.927    [weighted Loss:2.927    Policy Loss: 6.560    Value Loss: 5.083    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 535550     Buffer Size: 16088      Transition Number: 1000.303k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:33:34,822][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 6.718    Value Loss: 5.088    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 537475     Buffer Size: 15990      Transition Number: 999.943 k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:36:23,290][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.520    [weighted Loss:3.520    Policy Loss: 6.691    Value Loss: 5.028    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 539408     Buffer Size: 15906      Transition Number: 1000.252k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:39:10,376][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.312    [weighted Loss:3.312    Policy Loss: 6.866    Value Loss: 4.703    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 541287     Buffer Size: 15878      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:41:58,869][train][INFO][train.py>_log] ==> #184000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 6.452    Value Loss: 4.872    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 543173     Buffer Size: 15883      Transition Number: 1000.061k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:44:47,310][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.879    [weighted Loss:2.879    Policy Loss: 7.249    Value Loss: 5.079    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 545119     Buffer Size: 15902      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:47:34,017][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.705    [weighted Loss:2.705    Policy Loss: 6.732    Value Loss: 5.218    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 547127     Buffer Size: 15897      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:50:21,377][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 7.006    Value Loss: 5.142    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 548982     Buffer Size: 15884      Transition Number: 1000.022k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:53:08,991][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 7.033    Value Loss: 4.936    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 550876     Buffer Size: 15874      Transition Number: 1000.187k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:55:57,700][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.921    [weighted Loss:2.921    Policy Loss: 6.379    Value Loss: 4.755    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 552802     Buffer Size: 15914      Transition Number: 1000.278k Batch Size: 256        Lr: 0.10000 
[2022-02-24 00:58:49,229][train][INFO][train.py>_log] ==> #190000     Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 6.527    Value Loss: 5.093    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 554706     Buffer Size: 15980      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:01:39,502][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 6.499    Value Loss: 5.179    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 556684     Buffer Size: 16048      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:04:28,656][train][INFO][train.py>_log] ==> #192000     Total Loss: 3.454    [weighted Loss:3.454    Policy Loss: 6.428    Value Loss: 5.119    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 558617     Buffer Size: 16122      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:07:16,262][train][INFO][train.py>_log] ==> #193000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 6.643    Value Loss: 5.067    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 560542     Buffer Size: 16126      Transition Number: 1000.238k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:10:02,655][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.744    [weighted Loss:3.744    Policy Loss: 6.476    Value Loss: 4.882    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 562413     Buffer Size: 16104      Transition Number: 1000.324k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:12:51,877][train][INFO][train.py>_log] ==> #195000     Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 6.351    Value Loss: 4.940    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 564241     Buffer Size: 16010      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:15:39,394][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.830    [weighted Loss:2.830    Policy Loss: 6.515    Value Loss: 4.957    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 566104     Buffer Size: 15921      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:18:28,662][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 5.832    Value Loss: 4.734    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 568049     Buffer Size: 15934      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:21:16,593][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 6.266    Value Loss: 4.878    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 569953     Buffer Size: 15964      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:24:04,322][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 6.399    Value Loss: 4.802    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 571833     Buffer Size: 15930      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:27:05,632][train][INFO][train.py>_log] ==> #200000     Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 5.746    Value Loss: 4.836    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 573726     Buffer Size: 15851      Transition Number: 1000.214k Batch Size: 256        Lr: 0.10000 
[2022-02-24 01:29:56,379][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 5.553    Value Loss: 4.769    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 575842     Buffer Size: 15910      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:32:46,702][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 5.444    Value Loss: 5.049    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 577869     Buffer Size: 15967      Transition Number: 999.962 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:35:33,862][train][INFO][train.py>_log] ==> #203000     Total Loss: 3.198    [weighted Loss:3.198    Policy Loss: 5.161    Value Loss: 4.947    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 579714     Buffer Size: 15952      Transition Number: 999.960 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:38:22,911][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.872    [weighted Loss:2.872    Policy Loss: 5.233    Value Loss: 4.884    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 581492     Buffer Size: 15954      Transition Number: 999.979 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:41:11,426][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 5.602    Value Loss: 4.757    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 583453     Buffer Size: 15947      Transition Number: 1000.139k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:44:01,485][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 5.188    Value Loss: 5.119    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 585312     Buffer Size: 15898      Transition Number: 1000.078k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:46:52,765][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.805    [weighted Loss:2.805    Policy Loss: 5.277    Value Loss: 5.190    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 587170     Buffer Size: 15855      Transition Number: 1000.057k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:49:42,519][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 5.538    Value Loss: 5.034    Reward Loss: 0.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 589098     Buffer Size: 15814      Transition Number: 999.972 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:52:31,265][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 5.456    Value Loss: 4.753    Reward Loss: 0.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 590923     Buffer Size: 15737      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:55:19,497][train][INFO][train.py>_log] ==> #210000     Total Loss: 1.408    [weighted Loss:1.408    Policy Loss: 5.341    Value Loss: 4.620    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 592772     Buffer Size: 15560      Transition Number: 1000.015k Batch Size: 256        Lr: 0.02000 
[2022-02-24 01:58:11,766][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 5.076    Value Loss: 4.839    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 594692     Buffer Size: 15468      Transition Number: 1000.057k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:01:02,098][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.470    [weighted Loss:3.470    Policy Loss: 5.502    Value Loss: 5.054    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 596565     Buffer Size: 15490      Transition Number: 1000.038k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:03:53,715][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 5.355    Value Loss: 4.677    Reward Loss: 0.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 598463     Buffer Size: 15460      Transition Number: 1000.033k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:06:45,226][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 5.176    Value Loss: 4.799    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 600376     Buffer Size: 15413      Transition Number: 1000.157k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:09:35,431][train][INFO][train.py>_log] ==> #215000     Total Loss: 1.767    [weighted Loss:1.767    Policy Loss: 4.551    Value Loss: 4.432    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 602251     Buffer Size: 15386      Transition Number: 1000.035k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:12:23,718][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 5.129    Value Loss: 4.677    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 604072     Buffer Size: 15365      Transition Number: 1000.048k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:15:13,595][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 5.379    Value Loss: 4.903    Reward Loss: 0.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 605946     Buffer Size: 15273      Transition Number: 1000.043k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:18:03,967][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.915    [weighted Loss:2.915    Policy Loss: 4.986    Value Loss: 4.721    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 607801     Buffer Size: 15210      Transition Number: 1000.103k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:20:56,163][train][INFO][train.py>_log] ==> #219000     Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 4.806    Value Loss: 4.814    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 609697     Buffer Size: 15167      Transition Number: 999.995 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:23:44,727][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 4.831    Value Loss: 4.785    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 611554     Buffer Size: 15097      Transition Number: 1000.061k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:26:36,924][train][INFO][train.py>_log] ==> #221000     Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 5.027    Value Loss: 4.839    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 613372     Buffer Size: 15003      Transition Number: 999.948 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:29:27,567][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 4.335    Value Loss: 4.584    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 615280     Buffer Size: 14857      Transition Number: 1000.115k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:32:17,519][train][INFO][train.py>_log] ==> #223000     Total Loss: 1.622    [weighted Loss:1.622    Policy Loss: 4.541    Value Loss: 4.574    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 617124     Buffer Size: 14797      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:35:11,885][train][INFO][train.py>_log] ==> #224000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 4.308    Value Loss: 4.494    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 618989     Buffer Size: 14739      Transition Number: 999.964 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:38:03,070][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.333    [weighted Loss:2.333    Policy Loss: 4.443    Value Loss: 4.577    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 620880     Buffer Size: 14650      Transition Number: 1000.075k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:40:56,804][train][INFO][train.py>_log] ==> #226000     Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 4.523    Value Loss: 4.499    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 622756     Buffer Size: 14605      Transition Number: 1000.046k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:43:48,175][train][INFO][train.py>_log] ==> #227000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 4.421    Value Loss: 4.434    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 624597     Buffer Size: 14512      Transition Number: 1000.037k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:46:37,125][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.356    [weighted Loss:1.356    Policy Loss: 4.108    Value Loss: 4.557    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 626484     Buffer Size: 14450      Transition Number: 999.931 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:49:29,617][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 4.479    Value Loss: 4.752    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 628378     Buffer Size: 14449      Transition Number: 1000.053k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:52:19,989][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 4.320    Value Loss: 4.646    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 630231     Buffer Size: 14412      Transition Number: 1000.013k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:55:08,154][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 4.365    Value Loss: 4.537    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 632087     Buffer Size: 14334      Transition Number: 1000.189k Batch Size: 256        Lr: 0.02000 
[2022-02-24 02:57:59,443][train][INFO][train.py>_log] ==> #232000     Total Loss: 1.872    [weighted Loss:1.872    Policy Loss: 3.993    Value Loss: 4.522    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 633948     Buffer Size: 14281      Transition Number: 1000.002k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:00:51,477][train][INFO][train.py>_log] ==> #233000     Total Loss: 1.782    [weighted Loss:1.782    Policy Loss: 4.171    Value Loss: 4.350    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 635931     Buffer Size: 14267      Transition Number: 1000.088k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:03:44,369][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.796    [weighted Loss:1.796    Policy Loss: 4.393    Value Loss: 4.572    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 637878     Buffer Size: 14285      Transition Number: 1000.283k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:06:35,522][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.152    [weighted Loss:2.152    Policy Loss: 4.612    Value Loss: 4.307    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 639695     Buffer Size: 14328      Transition Number: 1000.021k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:09:27,199][train][INFO][train.py>_log] ==> #236000     Total Loss: 1.901    [weighted Loss:1.901    Policy Loss: 4.832    Value Loss: 4.955    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 641641     Buffer Size: 14326      Transition Number: 1000.085k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:12:19,659][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 4.559    Value Loss: 4.155    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 643578     Buffer Size: 14323      Transition Number: 1000.263k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:15:06,330][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 4.561    Value Loss: 4.193    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 645411     Buffer Size: 14370      Transition Number: 1000.021k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:17:56,238][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 4.474    Value Loss: 4.251    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 647304     Buffer Size: 14402      Transition Number: 1000.231k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:20:46,372][train][INFO][train.py>_log] ==> #240000     Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 4.562    Value Loss: 4.578    Reward Loss: 0.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 649203     Buffer Size: 14441      Transition Number: 1000.171k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:23:37,092][train][INFO][train.py>_log] ==> #241000     Total Loss: 1.247    [weighted Loss:1.247    Policy Loss: 4.095    Value Loss: 4.337    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 651160     Buffer Size: 14455      Transition Number: 999.976 k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:26:27,711][train][INFO][train.py>_log] ==> #242000     Total Loss: 1.756    [weighted Loss:1.756    Policy Loss: 4.136    Value Loss: 4.181    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 653104     Buffer Size: 14468      Transition Number: 1000.048k Batch Size: 256        Lr: 0.02000 
[2022-02-24 03:29:16,699][train][INFO][train.py>_log] ==> #243000     Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 4.110    Value Loss: 4.507    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 655022     Buffer Size: 14477      Transition Number: 1000.005k Batch Size: 256        Lr: 0.02000 
