[2021-10-29 08:53:02,937][train][INFO][train.py>_log] ==> #0          Total Loss: 33.219   [weighted Loss:33.219   Policy Loss: 7.663    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 1135       Buffer Size: 1135       Transition Number: 4.587   k Batch Size: 256        Lr: 0.000   
[2021-10-29 08:56:08,812][train][INFO][train.py>_log] ==> #1000       Total Loss: 2.942    [weighted Loss:2.942    Policy Loss: 8.168    Value Loss: 3.979    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 7116       Buffer Size: 7116       Transition Number: 27.847  k Batch Size: 256        Lr: 0.010   
[2021-10-29 08:59:36,468][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.410    [weighted Loss:4.410    Policy Loss: 8.720    Value Loss: 3.659    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 14385      Buffer Size: 14385      Transition Number: 55.526  k Batch Size: 256        Lr: 0.020   
[2021-10-29 09:03:19,115][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.534    [weighted Loss:3.534    Policy Loss: 9.312    Value Loss: 3.451    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 20477      Buffer Size: 20477      Transition Number: 78.250  k Batch Size: 256        Lr: 0.030   
[2021-10-29 09:07:13,735][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 9.489    Value Loss: 3.176    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 25973      Buffer Size: 25973      Transition Number: 102.186 k Batch Size: 256        Lr: 0.040   
[2021-10-29 09:11:25,838][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 9.381    Value Loss: 2.741    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 32296      Buffer Size: 32296      Transition Number: 129.175 k Batch Size: 256        Lr: 0.050   
[2021-10-29 09:15:57,654][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.466    [weighted Loss:3.466    Policy Loss: 8.871    Value Loss: 2.479    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 39141      Buffer Size: 36960      Transition Number: 150.023 k Batch Size: 256        Lr: 0.060   
[2021-10-29 09:20:30,208][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 8.140    Value Loss: 2.639    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 45211      Buffer Size: 35562      Transition Number: 150.061 k Batch Size: 256        Lr: 0.070   
[2021-10-29 09:25:03,034][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.236    [weighted Loss:3.236    Policy Loss: 7.597    Value Loss: 2.595    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 53038      Buffer Size: 35055      Transition Number: 150.024 k Batch Size: 256        Lr: 0.080   
[2021-10-29 09:29:44,853][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.084    [weighted Loss:3.084    Policy Loss: 6.796    Value Loss: 2.564    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 62118      Buffer Size: 36738      Transition Number: 150.000 k Batch Size: 256        Lr: 0.090   
[2021-10-29 09:34:21,786][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.145    [weighted Loss:3.145    Policy Loss: 6.098    Value Loss: 2.121    Reward Loss: 0.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 70717      Buffer Size: 38482      Transition Number: 150.049 k Batch Size: 256        Lr: 0.100   
[2021-10-29 09:38:57,373][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 6.153    Value Loss: 2.113    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 76911      Buffer Size: 37924      Transition Number: 150.136 k Batch Size: 256        Lr: 0.100   
[2021-10-29 09:43:37,949][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 4.338    Value Loss: 1.890    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 83982      Buffer Size: 38840      Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-29 09:48:19,199][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 6.002    Value Loss: 2.045    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 89703      Buffer Size: 37065      Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 09:53:02,837][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.077    [weighted Loss:3.077    Policy Loss: 6.465    Value Loss: 2.232    Reward Loss: 0.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 95839      Buffer Size: 34262      Transition Number: 150.014 k Batch Size: 256        Lr: 0.100   
[2021-10-29 09:57:54,397][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 6.900    Value Loss: 2.387    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 100861     Buffer Size: 30301      Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:03:04,393][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 6.938    Value Loss: 2.426    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 105573     Buffer Size: 28019      Transition Number: 150.061 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:08:17,883][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.966    [weighted Loss:2.966    Policy Loss: 7.121    Value Loss: 3.031    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 109442     Buffer Size: 24369      Transition Number: 150.020 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:13:42,539][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.762    [weighted Loss:3.762    Policy Loss: 8.178    Value Loss: 3.798    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 112956     Buffer Size: 21560      Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:19:43,041][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 7.952    Value Loss: 3.834    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 116563     Buffer Size: 18272      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:26:06,653][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 7.332    Value Loss: 4.244    Reward Loss: 1.093    Consistency Loss: 0.000    ] Replay Episodes Collected: 119547     Buffer Size: 15284      Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:32:33,719][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.092    [weighted Loss:4.092    Policy Loss: 8.007    Value Loss: 4.366    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 122555     Buffer Size: 13433      Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:38:44,816][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.990    [weighted Loss:3.990    Policy Loss: 7.632    Value Loss: 4.819    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 124810     Buffer Size: 11803      Transition Number: 150.044 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:45:20,100][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.459    [weighted Loss:4.459    Policy Loss: 6.690    Value Loss: 4.488    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 127071     Buffer Size: 10407      Transition Number: 150.040 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:51:47,550][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.752    [weighted Loss:3.752    Policy Loss: 7.929    Value Loss: 5.317    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 129092     Buffer Size: 9661       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-29 10:58:23,378][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 6.446    Value Loss: 4.980    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 131240     Buffer Size: 8862       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:05:05,238][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 6.293    Value Loss: 5.091    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 133313     Buffer Size: 8499       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:11:44,892][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 6.522    Value Loss: 5.271    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 135310     Buffer Size: 8271       Transition Number: 149.981 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:18:31,613][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.195    [weighted Loss:3.195    Policy Loss: 6.242    Value Loss: 4.948    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 137358     Buffer Size: 8184       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:25:23,446][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.771    [weighted Loss:3.771    Policy Loss: 6.163    Value Loss: 5.286    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 139447     Buffer Size: 8052       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:32:16,568][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.800    [weighted Loss:3.800    Policy Loss: 5.975    Value Loss: 4.820    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 141513     Buffer Size: 7970       Transition Number: 149.973 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:39:11,132][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 6.215    Value Loss: 5.199    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 143646     Buffer Size: 8024       Transition Number: 150.036 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:45:59,630][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.324    [weighted Loss:3.324    Policy Loss: 6.126    Value Loss: 4.886    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 145775     Buffer Size: 8039       Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:52:55,436][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.717    [weighted Loss:3.717    Policy Loss: 6.544    Value Loss: 5.023    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 147860     Buffer Size: 8037       Transition Number: 150.002 k Batch Size: 256        Lr: 0.100   
[2021-10-29 11:59:50,246][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.157    [weighted Loss:3.157    Policy Loss: 5.862    Value Loss: 5.073    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 150025     Buffer Size: 8082       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
