[2021-10-29 13:55:44,120][train][INFO][train.py>_log] ==> #0          Total Loss: 32.704   [weighted Loss:32.704   Policy Loss: 7.147    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 648        Buffer Size: 648        Transition Number: 2.404   k Batch Size: 256        Lr: 0.000   
[2021-10-29 13:59:33,852][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 8.299    Value Loss: 3.732    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 2843       Buffer Size: 2843       Transition Number: 10.887  k Batch Size: 256        Lr: 0.010   
[2021-10-29 14:03:31,376][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.181    [weighted Loss:3.181    Policy Loss: 10.219   Value Loss: 3.938    Reward Loss: 0.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 4536       Buffer Size: 4536       Transition Number: 17.285  k Batch Size: 256        Lr: 0.020   
[2021-10-29 14:08:05,342][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.469    [weighted Loss:3.469    Policy Loss: 9.440    Value Loss: 3.278    Reward Loss: 0.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 6585       Buffer Size: 6585       Transition Number: 24.618  k Batch Size: 256        Lr: 0.030   
[2021-10-29 14:12:53,002][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.308    [weighted Loss:4.308    Policy Loss: 8.825    Value Loss: 2.766    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 8801       Buffer Size: 8801       Transition Number: 32.804  k Batch Size: 256        Lr: 0.040   
[2021-10-29 14:17:41,090][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 9.493    Value Loss: 2.557    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 10925      Buffer Size: 10925      Transition Number: 41.123  k Batch Size: 256        Lr: 0.050   
[2021-10-29 14:22:28,469][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 8.296    Value Loss: 2.600    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 12976      Buffer Size: 12976      Transition Number: 49.320  k Batch Size: 256        Lr: 0.060   
[2021-10-29 14:27:22,446][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.332    [weighted Loss:4.332    Policy Loss: 9.096    Value Loss: 2.618    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 15520      Buffer Size: 15520      Transition Number: 58.673  k Batch Size: 256        Lr: 0.070   
[2021-10-29 14:32:05,973][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 8.214    Value Loss: 2.371    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 17339      Buffer Size: 17339      Transition Number: 66.981  k Batch Size: 256        Lr: 0.080   
[2021-10-29 14:36:46,669][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 7.655    Value Loss: 2.359    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 19121      Buffer Size: 19121      Transition Number: 75.375  k Batch Size: 256        Lr: 0.090   
[2021-10-29 14:41:35,432][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 7.894    Value Loss: 2.287    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 21386      Buffer Size: 21386      Transition Number: 84.318  k Batch Size: 256        Lr: 0.100   
[2021-10-29 14:46:19,395][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.315    [weighted Loss:4.315    Policy Loss: 8.160    Value Loss: 2.346    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 23750      Buffer Size: 23750      Transition Number: 93.009  k Batch Size: 256        Lr: 0.100   
[2021-10-29 14:51:03,327][train][INFO][train.py>_log] ==> #12000      Total Loss: 1.404    [weighted Loss:1.404    Policy Loss: 7.788    Value Loss: 2.182    Reward Loss: 0.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 25807      Buffer Size: 25807      Transition Number: 101.508 k Batch Size: 256        Lr: 0.100   
[2021-10-29 14:55:51,953][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.991    [weighted Loss:3.991    Policy Loss: 7.942    Value Loss: 2.114    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 28169      Buffer Size: 28169      Transition Number: 110.224 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:00:49,504][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 6.930    Value Loss: 2.125    Reward Loss: 0.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 30815      Buffer Size: 30815      Transition Number: 119.957 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:05:39,966][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.018    [weighted Loss:4.018    Policy Loss: 7.618    Value Loss: 2.163    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 32921      Buffer Size: 32921      Transition Number: 128.898 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:10:32,627][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.705    [weighted Loss:2.705    Policy Loss: 7.030    Value Loss: 2.134    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 35127      Buffer Size: 35127      Transition Number: 138.483 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:15:20,724][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 7.114    Value Loss: 2.217    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 36824      Buffer Size: 36824      Transition Number: 147.042 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:20:19,450][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 6.534    Value Loss: 2.359    Reward Loss: 1.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 39033      Buffer Size: 37261      Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:25:16,431][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 6.938    Value Loss: 2.462    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 41287      Buffer Size: 36970      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:30:25,616][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 6.164    Value Loss: 2.675    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 42884      Buffer Size: 35969      Transition Number: 150.002 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:35:21,684][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.554    [weighted Loss:3.554    Policy Loss: 6.716    Value Loss: 2.518    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 44277      Buffer Size: 35087      Transition Number: 150.001 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:40:32,770][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.771    [weighted Loss:2.771    Policy Loss: 5.321    Value Loss: 3.049    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 45700      Buffer Size: 34154      Transition Number: 150.024 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:45:48,777][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.776    [weighted Loss:2.776    Policy Loss: 5.149    Value Loss: 3.346    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 46877      Buffer Size: 33048      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:51:08,720][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 5.467    Value Loss: 3.214    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 48133      Buffer Size: 31910      Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:56:31,330][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.611    [weighted Loss:2.611    Policy Loss: 5.467    Value Loss: 3.768    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 49061      Buffer Size: 30804      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:02:03,101][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 5.005    Value Loss: 4.001    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 49895      Buffer Size: 29242      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:07:43,610][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 5.387    Value Loss: 4.302    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 50780      Buffer Size: 27354      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:13:13,431][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 5.820    Value Loss: 4.491    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 51531      Buffer Size: 25727      Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:18:58,763][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.574    [weighted Loss:1.574    Policy Loss: 5.463    Value Loss: 4.554    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 52281      Buffer Size: 23586      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:24:52,445][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.674    [weighted Loss:2.674    Policy Loss: 6.254    Value Loss: 4.639    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 52951      Buffer Size: 21374      Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:30:59,903][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.727    [weighted Loss:2.727    Policy Loss: 6.009    Value Loss: 4.298    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 53682      Buffer Size: 19536      Transition Number: 150.004 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:37:18,042][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 6.265    Value Loss: 5.005    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 54422      Buffer Size: 17755      Transition Number: 150.026 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:43:45,924][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.440    [weighted Loss:1.440    Policy Loss: 5.579    Value Loss: 4.753    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 55139      Buffer Size: 15781      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:50:13,539][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 6.524    Value Loss: 5.126    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 55864      Buffer Size: 13939      Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:56:33,548][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 6.008    Value Loss: 5.217    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 56573      Buffer Size: 12731      Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:02:55,931][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.144    [weighted Loss:3.144    Policy Loss: 6.043    Value Loss: 5.107    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 57302      Buffer Size: 11589      Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:09:16,933][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.654    [weighted Loss:3.654    Policy Loss: 5.540    Value Loss: 4.981    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 57935      Buffer Size: 10685      Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:15:50,681][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 5.677    Value Loss: 4.800    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 58611      Buffer Size: 9903       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:22:18,930][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 5.701    Value Loss: 5.054    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 59239      Buffer Size: 9523       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:28:58,802][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 5.661    Value Loss: 5.051    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 59887      Buffer Size: 9119       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:35:27,836][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 6.002    Value Loss: 5.238    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 60564      Buffer Size: 8921       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:42:00,410][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 6.332    Value Loss: 5.023    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 61327      Buffer Size: 8798       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:48:35,027][train][INFO][train.py>_log] ==> #43000      Total Loss: 4.011    [weighted Loss:4.011    Policy Loss: 6.218    Value Loss: 4.896    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 61951      Buffer Size: 8668       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:55:14,108][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.028    [weighted Loss:3.028    Policy Loss: 6.305    Value Loss: 5.182    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 62623      Buffer Size: 8539       Transition Number: 150.057 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:01:48,474][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.605    [weighted Loss:3.605    Policy Loss: 6.828    Value Loss: 5.135    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 63264      Buffer Size: 8439       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:08:23,508][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 6.185    Value Loss: 5.259    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 63951      Buffer Size: 8328       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:15:22,970][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 6.755    Value Loss: 5.304    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 64722      Buffer Size: 8256       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:22:21,283][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 6.608    Value Loss: 5.266    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 65467      Buffer Size: 8199       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:29:13,701][train][INFO][train.py>_log] ==> #49000      Total Loss: 4.055    [weighted Loss:4.055    Policy Loss: 6.871    Value Loss: 5.100    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 66140      Buffer Size: 8142       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:36:10,345][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 7.334    Value Loss: 4.989    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 66821      Buffer Size: 8090       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:43:10,901][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 6.393    Value Loss: 5.099    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 67506      Buffer Size: 8042       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:50:12,612][train][INFO][train.py>_log] ==> #52000      Total Loss: 4.378    [weighted Loss:4.378    Policy Loss: 6.610    Value Loss: 5.162    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 68198      Buffer Size: 7997       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:57:35,495][train][INFO][train.py>_log] ==> #53000      Total Loss: 4.699    [weighted Loss:4.699    Policy Loss: 7.092    Value Loss: 5.061    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 68929      Buffer Size: 7856       Transition Number: 150.025 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:04:48,168][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.683    [weighted Loss:3.683    Policy Loss: 6.362    Value Loss: 4.885    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 69615      Buffer Size: 7802       Transition Number: 150.051 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:12:04,667][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 5.986    Value Loss: 4.949    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 70326      Buffer Size: 7794       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:19:09,624][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.092    [weighted Loss:3.092    Policy Loss: 6.223    Value Loss: 4.919    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 71032      Buffer Size: 7789       Transition Number: 150.053 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:25:57,290][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 6.066    Value Loss: 5.192    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 71720      Buffer Size: 7772       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:32:58,812][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 6.376    Value Loss: 5.131    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 72403      Buffer Size: 7689       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:39:58,387][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 6.107    Value Loss: 4.783    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 73074      Buffer Size: 7625       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:47:11,247][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 5.863    Value Loss: 4.717    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 73777      Buffer Size: 7596       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:54:07,911][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.959    [weighted Loss:2.959    Policy Loss: 5.783    Value Loss: 5.191    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 74443      Buffer Size: 7564       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:01:20,567][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.869    [weighted Loss:2.869    Policy Loss: 6.118    Value Loss: 5.136    Reward Loss: 1.274    Consistency Loss: 0.000    ] Replay Episodes Collected: 75220      Buffer Size: 7625       Transition Number: 149.972 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:08:44,243][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.644    [weighted Loss:3.644    Policy Loss: 5.668    Value Loss: 5.057    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 76005      Buffer Size: 7662       Transition Number: 150.118 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:15:28,534][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 6.209    Value Loss: 4.978    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 76630      Buffer Size: 7642       Transition Number: 149.972 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:22:30,518][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 5.564    Value Loss: 4.863    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 77366      Buffer Size: 7681       Transition Number: 150.037 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:29:18,741][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 5.922    Value Loss: 5.017    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 78015      Buffer Size: 7659       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:36:11,319][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 5.537    Value Loss: 5.197    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 78692      Buffer Size: 7627       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:42:59,640][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.141    [weighted Loss:3.141    Policy Loss: 4.952    Value Loss: 4.987    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 79367      Buffer Size: 7595       Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:49:52,858][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 5.241    Value Loss: 4.925    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 80047      Buffer Size: 7612       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:56:48,261][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 4.817    Value Loss: 5.109    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 80873      Buffer Size: 7746       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:03:39,614][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.981    [weighted Loss:2.981    Policy Loss: 5.354    Value Loss: 5.358    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 81682      Buffer Size: 7871       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:10:22,781][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 5.565    Value Loss: 5.461    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 82410      Buffer Size: 7978       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:17:11,571][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.295    [weighted Loss:3.295    Policy Loss: 5.153    Value Loss: 5.086    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 83187      Buffer Size: 8016       Transition Number: 150.017 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:23:46,240][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 5.882    Value Loss: 5.354    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 83868      Buffer Size: 8011       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:30:25,069][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.683    [weighted Loss:2.683    Policy Loss: 6.081    Value Loss: 5.054    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 84638      Buffer Size: 8126       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:37:08,008][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.147    [weighted Loss:2.147    Policy Loss: 5.968    Value Loss: 5.628    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 85384      Buffer Size: 8199       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:43:39,986][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 5.979    Value Loss: 5.513    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 86147      Buffer Size: 8335       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:50:26,040][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.971    [weighted Loss:2.971    Policy Loss: 5.957    Value Loss: 4.938    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 86871      Buffer Size: 8387       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:57:11,182][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 5.461    Value Loss: 5.274    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 87645      Buffer Size: 8490       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:03:54,482][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 5.824    Value Loss: 5.040    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 88349      Buffer Size: 8511       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:10:42,927][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.568    [weighted Loss:3.568    Policy Loss: 6.156    Value Loss: 5.363    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 89046      Buffer Size: 8461       Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:17:25,364][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.687    [weighted Loss:3.687    Policy Loss: 5.633    Value Loss: 5.296    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 89803      Buffer Size: 8433       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:24:05,762][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 6.012    Value Loss: 5.326    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 90608      Buffer Size: 8453       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:30:40,840][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.666    [weighted Loss:2.666    Policy Loss: 5.608    Value Loss: 5.197    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 91345      Buffer Size: 8487       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:37:13,630][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 5.953    Value Loss: 5.178    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 92021      Buffer Size: 8478       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:43:59,035][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 5.198    Value Loss: 5.306    Reward Loss: 1.282    Consistency Loss: 0.000    ] Replay Episodes Collected: 92784      Buffer Size: 8505       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:50:31,650][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 5.594    Value Loss: 5.440    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 93602      Buffer Size: 8575       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:57:09,506][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 5.202    Value Loss: 5.344    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 94382      Buffer Size: 8605       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:03:49,813][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 5.288    Value Loss: 5.165    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 95132      Buffer Size: 8593       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:10:33,226][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 5.290    Value Loss: 5.326    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 95865      Buffer Size: 8616       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:17:09,442][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 5.335    Value Loss: 5.142    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 96574      Buffer Size: 8595       Transition Number: 149.974 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:23:45,038][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 4.760    Value Loss: 4.931    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 97260      Buffer Size: 8616       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:30:24,067][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.188    [weighted Loss:3.188    Policy Loss: 6.025    Value Loss: 5.553    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 97951      Buffer Size: 8608       Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:37:06,043][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 5.217    Value Loss: 5.372    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 98546      Buffer Size: 8510       Transition Number: 150.062 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:43:49,684][train][INFO][train.py>_log] ==> #95000      Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 5.514    Value Loss: 5.581    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 99215      Buffer Size: 8408       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:50:37,916][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 4.950    Value Loss: 5.393    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 99880      Buffer Size: 8312       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:57:16,542][train][INFO][train.py>_log] ==> #97000      Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 5.260    Value Loss: 5.365    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 100534     Buffer Size: 8264       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:04:09,497][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 4.365    Value Loss: 4.861    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 101217     Buffer Size: 8160       Transition Number: 150.027 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:10:59,695][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 4.803    Value Loss: 5.524    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 102009     Buffer Size: 8074       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:17:44,820][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.335    [weighted Loss:2.335    Policy Loss: 4.814    Value Loss: 5.137    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 102716     Buffer Size: 8010       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:24:30,930][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.116    [weighted Loss:2.116    Policy Loss: 4.860    Value Loss: 5.042    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 103432     Buffer Size: 7971       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:31:19,332][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 4.296    Value Loss: 4.897    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 104194     Buffer Size: 7990       Transition Number: 150.004 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:38:10,009][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 5.040    Value Loss: 5.121    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 104974     Buffer Size: 8044       Transition Number: 150.019 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:44:58,313][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 4.560    Value Loss: 5.027    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 105725     Buffer Size: 8064       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:51:45,019][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 4.837    Value Loss: 4.791    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 106425     Buffer Size: 8089       Transition Number: 150.012 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:58:35,189][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 4.750    Value Loss: 5.307    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 107252     Buffer Size: 8210       Transition Number: 150.002 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:05:28,089][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 4.487    Value Loss: 5.040    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 107981     Buffer Size: 8251       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:12:07,883][train][INFO][train.py>_log] ==> #108000     Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 4.504    Value Loss: 5.504    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 108736     Buffer Size: 8316       Transition Number: 150.078 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:19:19,976][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.429    [weighted Loss:2.429    Policy Loss: 4.565    Value Loss: 5.223    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 109558     Buffer Size: 8375       Transition Number: 150.031 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:26:23,488][train][INFO][train.py>_log] ==> #110000     Total Loss: 1.953    [weighted Loss:1.953    Policy Loss: 4.708    Value Loss: 5.332    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 110318     Buffer Size: 8342       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:33:14,399][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 3.977    Value Loss: 5.316    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 111123     Buffer Size: 8427       Transition Number: 150.033 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:40:12,212][train][INFO][train.py>_log] ==> #112000     Total Loss: 1.136    [weighted Loss:1.136    Policy Loss: 4.483    Value Loss: 5.207    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 111959     Buffer Size: 8505       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:47:19,616][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 3.871    Value Loss: 5.299    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 112843     Buffer Size: 8553       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:54:24,737][train][INFO][train.py>_log] ==> #114000     Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 3.869    Value Loss: 4.900    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 113643     Buffer Size: 8546       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:01:24,454][train][INFO][train.py>_log] ==> #115000     Total Loss: 1.370    [weighted Loss:1.370    Policy Loss: 3.614    Value Loss: 5.081    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 114461     Buffer Size: 8585       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:08:14,944][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 4.166    Value Loss: 4.902    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 115265     Buffer Size: 8641       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:15:13,973][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.232    [weighted Loss:2.232    Policy Loss: 3.908    Value Loss: 5.242    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 116066     Buffer Size: 8613       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:22:23,859][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 3.702    Value Loss: 5.449    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 116880     Buffer Size: 8610       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:29:28,563][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 3.766    Value Loss: 4.964    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 117644     Buffer Size: 8597       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:36:33,500][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 3.818    Value Loss: 5.026    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 118468     Buffer Size: 8633       Transition Number: 150.021 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:43:41,199][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 3.585    Value Loss: 5.065    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 119284     Buffer Size: 8640       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:50:43,229][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.252    [weighted Loss:1.252    Policy Loss: 3.963    Value Loss: 5.199    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 120063     Buffer Size: 8598       Transition Number: 150.027 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:57:33,882][train][INFO][train.py>_log] ==> #123000     Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 3.604    Value Loss: 4.981    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 120765     Buffer Size: 8498       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:04:40,383][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 3.820    Value Loss: 4.991    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 121599     Buffer Size: 8461       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:11:54,477][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 3.801    Value Loss: 5.287    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 122347     Buffer Size: 8396       Transition Number: 150.029 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:19:11,866][train][INFO][train.py>_log] ==> #126000     Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 4.048    Value Loss: 4.936    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 123173     Buffer Size: 8277       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:26:33,885][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 3.349    Value Loss: 5.068    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 124027     Buffer Size: 8274       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:33:43,374][train][INFO][train.py>_log] ==> #128000     Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 3.424    Value Loss: 5.107    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 125012     Buffer Size: 8416       Transition Number: 150.047 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:41:04,074][train][INFO][train.py>_log] ==> #129000     Total Loss: 1.385    [weighted Loss:1.385    Policy Loss: 3.653    Value Loss: 5.133    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 125949     Buffer Size: 8513       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:48:18,601][train][INFO][train.py>_log] ==> #130000     Total Loss: 1.627    [weighted Loss:1.627    Policy Loss: 3.833    Value Loss: 5.270    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 126843     Buffer Size: 8575       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:55:18,358][train][INFO][train.py>_log] ==> #131000     Total Loss: 1.287    [weighted Loss:1.287    Policy Loss: 3.656    Value Loss: 4.666    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 127632     Buffer Size: 8581       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:02:30,954][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 3.778    Value Loss: 5.190    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 128404     Buffer Size: 8541       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:09:44,295][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 3.735    Value Loss: 4.932    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 129240     Buffer Size: 8561       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:16:43,679][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 3.830    Value Loss: 5.393    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 130038     Buffer Size: 8544       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:23:44,101][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 3.707    Value Loss: 5.363    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 130850     Buffer Size: 8606       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:30:46,423][train][INFO][train.py>_log] ==> #136000     Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 3.243    Value Loss: 4.983    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 131569     Buffer Size: 8589       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:37:52,039][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 3.566    Value Loss: 5.108    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 132343     Buffer Size: 8606       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:44:51,727][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 4.357    Value Loss: 5.069    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 133142     Buffer Size: 8557       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:52:14,884][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 3.690    Value Loss: 4.987    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 133904     Buffer Size: 8370       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:59:33,564][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 4.142    Value Loss: 5.234    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 134647     Buffer Size: 8208       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:06:43,001][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 3.856    Value Loss: 5.391    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 135360     Buffer Size: 8072       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:14:01,722][train][INFO][train.py>_log] ==> #142000     Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 3.557    Value Loss: 5.478    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 136131     Buffer Size: 8043       Transition Number: 150.087 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:21:00,648][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.145    [weighted Loss:2.145    Policy Loss: 4.017    Value Loss: 5.324    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 136886     Buffer Size: 8074       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:28:28,603][train][INFO][train.py>_log] ==> #144000     Total Loss: 1.698    [weighted Loss:1.698    Policy Loss: 3.761    Value Loss: 5.014    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 137622     Buffer Size: 8008       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:35:31,060][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.190    [weighted Loss:2.190    Policy Loss: 3.694    Value Loss: 5.030    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 138436     Buffer Size: 8016       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:42:48,004][train][INFO][train.py>_log] ==> #146000     Total Loss: 1.477    [weighted Loss:1.477    Policy Loss: 4.083    Value Loss: 5.344    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 139203     Buffer Size: 7977       Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:50:07,269][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 3.924    Value Loss: 4.933    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 139964     Buffer Size: 7958       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:57:25,981][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.496    [weighted Loss:2.496    Policy Loss: 3.937    Value Loss: 5.063    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 140671     Buffer Size: 7839       Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:04:49,013][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 3.393    Value Loss: 5.329    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 141393     Buffer Size: 7789       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:12:10,351][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.216    [weighted Loss:2.216    Policy Loss: 3.753    Value Loss: 5.585    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 142121     Buffer Size: 7803       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:19:37,534][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 4.005    Value Loss: 5.032    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 142901     Buffer Size: 7856       Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:26:54,050][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 4.132    Value Loss: 5.341    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 143705     Buffer Size: 7869       Transition Number: 150.004 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:34:03,124][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 3.430    Value Loss: 5.223    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 144561     Buffer Size: 7934       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:41:08,871][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.112    [weighted Loss:2.112    Policy Loss: 4.150    Value Loss: 4.938    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 145320     Buffer Size: 7968       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:48:24,228][train][INFO][train.py>_log] ==> #155000     Total Loss: 1.753    [weighted Loss:1.753    Policy Loss: 3.485    Value Loss: 5.083    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 146102     Buffer Size: 7937       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:55:43,698][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.908    [weighted Loss:1.908    Policy Loss: 3.778    Value Loss: 5.175    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 146827     Buffer Size: 7882       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:03:05,652][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.340    [weighted Loss:2.340    Policy Loss: 3.635    Value Loss: 5.319    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 147557     Buffer Size: 7862       Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:10:12,538][train][INFO][train.py>_log] ==> #158000     Total Loss: 1.672    [weighted Loss:1.672    Policy Loss: 3.793    Value Loss: 4.903    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 148271     Buffer Size: 7876       Transition Number: 149.974 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:17:26,225][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 3.510    Value Loss: 5.131    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 149006     Buffer Size: 7889       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:24:45,966][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.826    [weighted Loss:1.826    Policy Loss: 3.697    Value Loss: 5.158    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 149744     Buffer Size: 7891       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:32:01,988][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.768    [weighted Loss:1.768    Policy Loss: 3.338    Value Loss: 4.863    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 150515     Buffer Size: 7897       Transition Number: 150.097 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:39:18,202][train][INFO][train.py>_log] ==> #162000     Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 3.797    Value Loss: 4.953    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 151227     Buffer Size: 7807       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:46:43,576][train][INFO][train.py>_log] ==> #163000     Total Loss: 1.561    [weighted Loss:1.561    Policy Loss: 3.097    Value Loss: 4.912    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 151985     Buffer Size: 7695       Transition Number: 150.074 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:54:22,364][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.930    [weighted Loss:1.930    Policy Loss: 3.582    Value Loss: 4.887    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 152766     Buffer Size: 7578       Transition Number: 150.010 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:01:59,199][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 3.302    Value Loss: 5.131    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 153542     Buffer Size: 7530       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:09:40,690][train][INFO][train.py>_log] ==> #166000     Total Loss: 1.407    [weighted Loss:1.407    Policy Loss: 3.736    Value Loss: 5.087    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 154571     Buffer Size: 7696       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:16:53,598][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 3.427    Value Loss: 5.397    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 155509     Buffer Size: 7856       Transition Number: 150.029 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:24:07,934][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 3.477    Value Loss: 5.111    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 156257     Buffer Size: 7878       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:31:34,746][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 4.340    Value Loss: 5.173    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 157099     Buffer Size: 7940       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:39:06,785][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 4.065    Value Loss: 5.135    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 157900     Buffer Size: 7968       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:46:39,525][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.520    [weighted Loss:1.520    Policy Loss: 3.691    Value Loss: 5.028    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 158801     Buffer Size: 8054       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:53:50,628][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.076    [weighted Loss:2.076    Policy Loss: 3.749    Value Loss: 5.142    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 159565     Buffer Size: 8117       Transition Number: 150.023 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:01:04,646][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.958    [weighted Loss:1.958    Policy Loss: 4.097    Value Loss: 5.406    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 160318     Buffer Size: 8150       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:08:38,210][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 4.104    Value Loss: 5.292    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 161170     Buffer Size: 8239       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:15:49,000][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 3.838    Value Loss: 5.343    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 161897     Buffer Size: 8239       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:23:03,581][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 4.703    Value Loss: 5.256    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 162638     Buffer Size: 8076       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:30:18,330][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 3.943    Value Loss: 5.208    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 163367     Buffer Size: 7913       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:37:40,305][train][INFO][train.py>_log] ==> #178000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 4.151    Value Loss: 5.124    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 164090     Buffer Size: 7859       Transition Number: 150.020 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:44:59,564][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 3.725    Value Loss: 4.967    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 164799     Buffer Size: 7768       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:52:17,529][train][INFO][train.py>_log] ==> #180000     Total Loss: 1.973    [weighted Loss:1.973    Policy Loss: 4.295    Value Loss: 5.158    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 165488     Buffer Size: 7693       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:59:31,049][train][INFO][train.py>_log] ==> #181000     Total Loss: 1.364    [weighted Loss:1.364    Policy Loss: 3.753    Value Loss: 4.895    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 166204     Buffer Size: 7587       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:06:55,691][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 3.531    Value Loss: 5.025    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 166969     Buffer Size: 7559       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:14:05,427][train][INFO][train.py>_log] ==> #183000     Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 3.561    Value Loss: 4.965    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 167665     Buffer Size: 7548       Transition Number: 150.028 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:21:13,997][train][INFO][train.py>_log] ==> #184000     Total Loss: 2.312    [weighted Loss:2.312    Policy Loss: 3.333    Value Loss: 4.868    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 168450     Buffer Size: 7525       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:28:50,875][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.035    [weighted Loss:2.035    Policy Loss: 3.336    Value Loss: 4.470    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 169245     Buffer Size: 7502       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:36:05,858][train][INFO][train.py>_log] ==> #186000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 3.763    Value Loss: 4.965    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 169943     Buffer Size: 7507       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:43:24,728][train][INFO][train.py>_log] ==> #187000     Total Loss: 1.665    [weighted Loss:1.665    Policy Loss: 3.451    Value Loss: 4.895    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 170680     Buffer Size: 7479       Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:50:23,032][train][INFO][train.py>_log] ==> #188000     Total Loss: 1.413    [weighted Loss:1.413    Policy Loss: 3.428    Value Loss: 5.114    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 171410     Buffer Size: 7515       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:57:18,125][train][INFO][train.py>_log] ==> #189000     Total Loss: 1.222    [weighted Loss:1.222    Policy Loss: 3.616    Value Loss: 4.767    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 172082     Buffer Size: 7527       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
