[2021-10-30 11:01:26,095][train][INFO][train.py>_log] ==> #0          Total Loss: 32.863   [weighted Loss:32.863   Policy Loss: 7.307    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 669        Buffer Size: 669        Transition Number: 2.520   k Batch Size: 256        Lr: 0.000   
[2021-10-30 11:04:36,662][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.684    [weighted Loss:5.684    Policy Loss: 8.505    Value Loss: 3.846    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 5053       Buffer Size: 5053       Transition Number: 19.412  k Batch Size: 256        Lr: 0.010   
[2021-10-30 11:08:14,648][train][INFO][train.py>_log] ==> #2000       Total Loss: 2.674    [weighted Loss:2.674    Policy Loss: 9.554    Value Loss: 3.521    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 9801       Buffer Size: 9801       Transition Number: 38.582  k Batch Size: 256        Lr: 0.020   
[2021-10-30 11:12:09,726][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 9.798    Value Loss: 3.200    Reward Loss: 0.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 13871      Buffer Size: 13871      Transition Number: 56.279  k Batch Size: 256        Lr: 0.030   
[2021-10-30 11:16:12,341][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 9.747    Value Loss: 3.016    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 18090      Buffer Size: 18090      Transition Number: 75.021  k Batch Size: 256        Lr: 0.040   
[2021-10-30 11:20:23,909][train][INFO][train.py>_log] ==> #5000       Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 8.998    Value Loss: 2.524    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 21894      Buffer Size: 21894      Transition Number: 94.514  k Batch Size: 256        Lr: 0.050   
[2021-10-30 11:24:54,928][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 9.077    Value Loss: 2.607    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 25923      Buffer Size: 25923      Transition Number: 115.737 k Batch Size: 256        Lr: 0.060   
[2021-10-30 11:29:25,507][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 8.605    Value Loss: 2.488    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 29399      Buffer Size: 29399      Transition Number: 137.076 k Batch Size: 256        Lr: 0.070   
[2021-10-30 11:34:05,605][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 7.785    Value Loss: 2.362    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 33368      Buffer Size: 30932      Transition Number: 150.006 k Batch Size: 256        Lr: 0.080   
[2021-10-30 11:38:58,664][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 7.298    Value Loss: 2.435    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 36864      Buffer Size: 28657      Transition Number: 150.031 k Batch Size: 256        Lr: 0.090   
[2021-10-30 11:44:02,322][train][INFO][train.py>_log] ==> #10000      Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 6.661    Value Loss: 2.567    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 40480      Buffer Size: 26838      Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 11:48:47,491][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.741    [weighted Loss:3.741    Policy Loss: 6.593    Value Loss: 2.528    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 44587      Buffer Size: 25869      Transition Number: 150.061 k Batch Size: 256        Lr: 0.100   
[2021-10-30 11:54:03,970][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.088    [weighted Loss:3.088    Policy Loss: 6.160    Value Loss: 2.714    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 48191      Buffer Size: 24702      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 11:59:12,852][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.121    [weighted Loss:3.121    Policy Loss: 6.201    Value Loss: 2.544    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 52712      Buffer Size: 24735      Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:04:34,310][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 6.354    Value Loss: 2.976    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 56096      Buffer Size: 23684      Transition Number: 150.019 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:10:01,403][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.141    [weighted Loss:3.141    Policy Loss: 5.818    Value Loss: 3.210    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 60079      Buffer Size: 23369      Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:15:24,577][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.228    [weighted Loss:2.228    Policy Loss: 6.483    Value Loss: 3.611    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 63288      Buffer Size: 22494      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:20:59,788][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.950    [weighted Loss:2.950    Policy Loss: 7.130    Value Loss: 3.547    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 66404      Buffer Size: 21052      Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:26:47,158][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.158    [weighted Loss:3.158    Policy Loss: 5.649    Value Loss: 4.045    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 68977      Buffer Size: 19321      Transition Number: 150.045 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:33:05,557][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 6.919    Value Loss: 4.451    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 71441      Buffer Size: 17113      Transition Number: 150.166 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:39:38,851][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.115    Value Loss: 4.119    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 73899      Buffer Size: 15189      Transition Number: 150.049 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:46:07,953][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.703    [weighted Loss:3.703    Policy Loss: 7.152    Value Loss: 4.477    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 75984      Buffer Size: 13299      Transition Number: 150.064 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:53:05,428][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 6.334    Value Loss: 4.605    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 78275      Buffer Size: 11763      Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:00:23,801][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.561    [weighted Loss:4.561    Policy Loss: 7.258    Value Loss: 5.021    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 80288      Buffer Size: 10685      Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:07:42,487][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.868    [weighted Loss:3.868    Policy Loss: 6.719    Value Loss: 4.844    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 82345      Buffer Size: 9976       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:14:57,383][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.161    [weighted Loss:4.161    Policy Loss: 6.350    Value Loss: 4.982    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 84080      Buffer Size: 9225       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:22:34,187][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 6.240    Value Loss: 4.695    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 85837      Buffer Size: 8529       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:30:23,587][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 5.871    Value Loss: 4.887    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 87817      Buffer Size: 8222       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:38:27,600][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.395    [weighted Loss:2.395    Policy Loss: 6.234    Value Loss: 4.946    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 89868      Buffer Size: 7992       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:46:11,365][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.933    [weighted Loss:3.933    Policy Loss: 6.080    Value Loss: 5.405    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 91787      Buffer Size: 7973       Transition Number: 150.094 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:54:02,789][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.544    [weighted Loss:4.544    Policy Loss: 6.567    Value Loss: 5.104    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 93728      Buffer Size: 8076       Transition Number: 150.354 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:01:42,102][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.430    [weighted Loss:3.430    Policy Loss: 7.130    Value Loss: 4.936    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 95695      Buffer Size: 8144       Transition Number: 150.053 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:09:44,683][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.498    [weighted Loss:3.498    Policy Loss: 6.573    Value Loss: 4.882    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 97677      Buffer Size: 8058       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:17:36,725][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 5.929    Value Loss: 5.167    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 99633      Buffer Size: 8074       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:25:41,340][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 6.592    Value Loss: 5.198    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 101594     Buffer Size: 8054       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:33:29,157][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.765    [weighted Loss:3.765    Policy Loss: 5.826    Value Loss: 5.085    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 103648     Buffer Size: 8073       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:40:56,636][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.479    [weighted Loss:3.479    Policy Loss: 6.103    Value Loss: 4.861    Reward Loss: 1.093    Consistency Loss: 0.000    ] Replay Episodes Collected: 105542     Buffer Size: 8151       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:48:35,721][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.559    [weighted Loss:4.559    Policy Loss: 5.971    Value Loss: 5.105    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 107599     Buffer Size: 8292       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:56:14,225][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.917    [weighted Loss:3.917    Policy Loss: 6.385    Value Loss: 5.075    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 109683     Buffer Size: 8497       Transition Number: 150.072 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:03:45,634][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 5.792    Value Loss: 4.994    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 111675     Buffer Size: 8548       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:11:18,972][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 6.445    Value Loss: 5.064    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 113707     Buffer Size: 8603       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:19:05,871][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.935    [weighted Loss:3.935    Policy Loss: 5.781    Value Loss: 4.948    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 115716     Buffer Size: 8587       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:26:47,675][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 6.534    Value Loss: 4.855    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 117678     Buffer Size: 8458       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:34:30,931][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.582    [weighted Loss:3.582    Policy Loss: 5.649    Value Loss: 5.245    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 119604     Buffer Size: 8318       Transition Number: 150.021 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:42:21,069][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.761    [weighted Loss:3.761    Policy Loss: 6.258    Value Loss: 5.164    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 121844     Buffer Size: 8439       Transition Number: 150.193 k Batch Size: 256        Lr: 0.100   
