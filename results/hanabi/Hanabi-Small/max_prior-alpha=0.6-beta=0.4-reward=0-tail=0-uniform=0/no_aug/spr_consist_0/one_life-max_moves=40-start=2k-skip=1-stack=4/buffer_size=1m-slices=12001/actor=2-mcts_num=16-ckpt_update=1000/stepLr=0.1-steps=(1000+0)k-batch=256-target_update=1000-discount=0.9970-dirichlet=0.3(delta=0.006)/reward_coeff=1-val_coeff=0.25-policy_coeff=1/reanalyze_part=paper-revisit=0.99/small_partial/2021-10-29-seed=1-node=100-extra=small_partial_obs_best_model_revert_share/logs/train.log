[2021-10-29 14:03:22,054][train][INFO][train.py>_log] ==> #0          Total Loss: 33.800   [weighted Loss:33.800   Policy Loss: 8.243    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 632        Buffer Size: 632        Transition Number: 2.463   k Batch Size: 256        Lr: 0.000   
[2021-10-29 14:07:09,984][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.173    [weighted Loss:5.173    Policy Loss: 8.730    Value Loss: 4.093    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 2523       Buffer Size: 2523       Transition Number: 9.996   k Batch Size: 256        Lr: 0.010   
[2021-10-29 14:11:08,978][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 9.610    Value Loss: 3.383    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 3810       Buffer Size: 3810       Transition Number: 15.988  k Batch Size: 256        Lr: 0.020   
[2021-10-29 14:15:41,877][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.166    [weighted Loss:4.166    Policy Loss: 9.970    Value Loss: 3.032    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 5444       Buffer Size: 5444       Transition Number: 23.079  k Batch Size: 256        Lr: 0.030   
[2021-10-29 14:20:25,972][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.266    [weighted Loss:4.266    Policy Loss: 9.896    Value Loss: 3.081    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 7212       Buffer Size: 7212       Transition Number: 31.199  k Batch Size: 256        Lr: 0.040   
[2021-10-29 14:25:20,404][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.147    [weighted Loss:4.147    Policy Loss: 8.803    Value Loss: 2.589    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 8886       Buffer Size: 8886       Transition Number: 39.702  k Batch Size: 256        Lr: 0.050   
[2021-10-29 14:29:53,003][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.000    [weighted Loss:3.000    Policy Loss: 9.163    Value Loss: 2.349    Reward Loss: 0.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 10045      Buffer Size: 10045      Transition Number: 46.695  k Batch Size: 256        Lr: 0.060   
[2021-10-29 14:34:36,685][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 8.654    Value Loss: 2.395    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 11297      Buffer Size: 11297      Transition Number: 54.441  k Batch Size: 256        Lr: 0.070   
[2021-10-29 14:39:20,724][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.001    [weighted Loss:3.001    Policy Loss: 7.704    Value Loss: 2.209    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 12680      Buffer Size: 12680      Transition Number: 62.206  k Batch Size: 256        Lr: 0.080   
[2021-10-29 14:43:55,428][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 8.277    Value Loss: 2.319    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 14098      Buffer Size: 14098      Transition Number: 69.726  k Batch Size: 256        Lr: 0.090   
[2021-10-29 14:48:33,282][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.176    [weighted Loss:3.176    Policy Loss: 7.563    Value Loss: 1.936    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 15512      Buffer Size: 15512      Transition Number: 77.447  k Batch Size: 256        Lr: 0.100   
[2021-10-29 14:53:21,944][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.080    [weighted Loss:4.080    Policy Loss: 8.310    Value Loss: 2.252    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 16853      Buffer Size: 16853      Transition Number: 85.339  k Batch Size: 256        Lr: 0.100   
[2021-10-29 14:58:13,553][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.358    [weighted Loss:3.358    Policy Loss: 7.722    Value Loss: 2.222    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 18298      Buffer Size: 18298      Transition Number: 93.514  k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:03:02,483][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.413    [weighted Loss:3.413    Policy Loss: 8.090    Value Loss: 2.349    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 19491      Buffer Size: 19491      Transition Number: 100.897 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:08:03,450][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 7.042    Value Loss: 2.244    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 21008      Buffer Size: 21008      Transition Number: 109.659 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:13:01,913][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.949    [weighted Loss:2.949    Policy Loss: 7.103    Value Loss: 2.162    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 22255      Buffer Size: 22255      Transition Number: 117.441 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:18:05,835][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.651    [weighted Loss:1.651    Policy Loss: 6.193    Value Loss: 2.134    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 23851      Buffer Size: 23851      Transition Number: 126.387 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:23:24,260][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 7.418    Value Loss: 2.439    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 25019      Buffer Size: 25019      Transition Number: 135.226 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:28:38,978][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.084    [weighted Loss:2.084    Policy Loss: 8.348    Value Loss: 2.701    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 26063      Buffer Size: 26063      Transition Number: 143.613 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:34:09,879][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 7.678    Value Loss: 2.738    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 27292      Buffer Size: 26611      Transition Number: 150.047 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:39:41,227][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 6.670    Value Loss: 3.100    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 28485      Buffer Size: 25484      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:45:23,315][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 7.998    Value Loss: 3.673    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 29477      Buffer Size: 24322      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:50:58,408][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.098    [weighted Loss:3.098    Policy Loss: 6.952    Value Loss: 3.810    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 30274      Buffer Size: 23053      Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-29 15:56:34,598][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.314    Value Loss: 3.795    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 30940      Buffer Size: 21867      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:02:19,769][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.527    [weighted Loss:3.527    Policy Loss: 7.187    Value Loss: 3.931    Reward Loss: 0.973    Consistency Loss: 0.000    ] Replay Episodes Collected: 31606      Buffer Size: 20973      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:08:11,501][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.202    [weighted Loss:3.202    Policy Loss: 7.714    Value Loss: 4.733    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 32153      Buffer Size: 19969      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:14:08,939][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.317    [weighted Loss:2.317    Policy Loss: 6.826    Value Loss: 4.482    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 32720      Buffer Size: 18739      Transition Number: 150.065 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:20:16,695][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.112    [weighted Loss:3.112    Policy Loss: 7.065    Value Loss: 4.267    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 33210      Buffer Size: 17427      Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:26:45,539][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.262    [weighted Loss:3.262    Policy Loss: 6.176    Value Loss: 4.868    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 33756      Buffer Size: 16079      Transition Number: 150.031 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:33:16,308][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 5.524    Value Loss: 4.469    Reward Loss: 0.995    Consistency Loss: 0.000    ] Replay Episodes Collected: 34309      Buffer Size: 14828      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:39:56,030][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 5.873    Value Loss: 4.792    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 34926      Buffer Size: 13473      Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:46:26,646][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.086    [weighted Loss:3.086    Policy Loss: 6.189    Value Loss: 4.972    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 35523      Buffer Size: 12104      Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-29 16:53:08,101][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.846    [weighted Loss:2.846    Policy Loss: 5.503    Value Loss: 4.887    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 36144      Buffer Size: 11015      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:00:14,078][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.805    [weighted Loss:3.805    Policy Loss: 5.606    Value Loss: 4.929    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 36768      Buffer Size: 10026      Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:07:08,539][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.315    [weighted Loss:4.315    Policy Loss: 6.051    Value Loss: 5.210    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 37384      Buffer Size: 9046       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:14:11,269][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 5.833    Value Loss: 4.991    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 38009      Buffer Size: 8361       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:21:14,269][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 6.299    Value Loss: 4.908    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 38636      Buffer Size: 8009       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:28:20,621][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 6.159    Value Loss: 4.845    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 39287      Buffer Size: 7753       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:35:30,983][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 6.532    Value Loss: 4.954    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 39917      Buffer Size: 7587       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:42:43,442][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 6.496    Value Loss: 4.855    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 40540      Buffer Size: 7521       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:49:53,310][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.477    [weighted Loss:4.477    Policy Loss: 6.108    Value Loss: 4.803    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 41109      Buffer Size: 7462       Transition Number: 150.026 k Batch Size: 256        Lr: 0.100   
[2021-10-29 17:57:06,858][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.324    [weighted Loss:1.324    Policy Loss: 6.430    Value Loss: 4.958    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 41742      Buffer Size: 7437       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:04:12,168][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.213    [weighted Loss:3.213    Policy Loss: 5.804    Value Loss: 4.866    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 42392      Buffer Size: 7373       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:11:11,113][train][INFO][train.py>_log] ==> #43000      Total Loss: 4.079    [weighted Loss:4.079    Policy Loss: 6.430    Value Loss: 4.597    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 43032      Buffer Size: 7337       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:18:15,898][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 6.856    Value Loss: 4.653    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 43667      Buffer Size: 7311       Transition Number: 150.023 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:25:29,561][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 6.051    Value Loss: 4.825    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 44292      Buffer Size: 7297       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:32:30,047][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.729    [weighted Loss:3.729    Policy Loss: 6.662    Value Loss: 4.971    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 44912      Buffer Size: 7277       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:39:42,046][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.385    [weighted Loss:3.385    Policy Loss: 6.504    Value Loss: 4.725    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 45579      Buffer Size: 7278       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:46:45,261][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 7.287    Value Loss: 4.992    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 46167      Buffer Size: 7240       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 18:53:54,816][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.599    [weighted Loss:3.599    Policy Loss: 6.697    Value Loss: 4.543    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 46808      Buffer Size: 7198       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:01:00,140][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.360    [weighted Loss:3.360    Policy Loss: 6.523    Value Loss: 4.824    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 47415      Buffer Size: 7184       Transition Number: 150.032 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:08:04,948][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 6.407    Value Loss: 4.755    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 48000      Buffer Size: 7205       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:15:12,097][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 6.126    Value Loss: 4.696    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 48630      Buffer Size: 7231       Transition Number: 150.016 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:22:15,037][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.427    [weighted Loss:3.427    Policy Loss: 6.961    Value Loss: 4.899    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 49294      Buffer Size: 7223       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:29:18,883][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 6.676    Value Loss: 4.581    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 49966      Buffer Size: 7263       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:36:24,353][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 6.375    Value Loss: 4.724    Reward Loss: 1.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 50589      Buffer Size: 7239       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:43:28,644][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.906    [weighted Loss:1.906    Policy Loss: 6.668    Value Loss: 4.812    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 51191      Buffer Size: 7224       Transition Number: 149.981 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:50:31,477][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.183    [weighted Loss:4.183    Policy Loss: 7.513    Value Loss: 4.761    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 51819      Buffer Size: 7253       Transition Number: 150.060 k Batch Size: 256        Lr: 0.100   
[2021-10-29 19:57:43,481][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.131    [weighted Loss:3.131    Policy Loss: 6.767    Value Loss: 5.098    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 52426      Buffer Size: 7220       Transition Number: 149.974 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:04:41,966][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 6.642    Value Loss: 5.101    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 53075      Buffer Size: 7253       Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:11:50,926][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 6.290    Value Loss: 5.081    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 53768      Buffer Size: 7331       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:18:59,742][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 6.207    Value Loss: 4.900    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 54402      Buffer Size: 7343       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:25:59,199][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 6.407    Value Loss: 4.810    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 55039      Buffer Size: 7368       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:32:57,930][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.724    [weighted Loss:3.724    Policy Loss: 6.253    Value Loss: 4.926    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 55659      Buffer Size: 7375       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:39:59,722][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 6.497    Value Loss: 4.586    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 56230      Buffer Size: 7334       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:47:10,214][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.492    [weighted Loss:3.492    Policy Loss: 6.704    Value Loss: 4.673    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 56984      Buffer Size: 7393       Transition Number: 150.061 k Batch Size: 256        Lr: 0.100   
[2021-10-29 20:54:10,982][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.410    [weighted Loss:3.410    Policy Loss: 6.257    Value Loss: 4.608    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 57630      Buffer Size: 7404       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:01:08,873][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 6.350    Value Loss: 4.857    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 58312      Buffer Size: 7462       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:08:03,710][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 6.352    Value Loss: 5.086    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 59030      Buffer Size: 7553       Transition Number: 150.014 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:14:56,040][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.602    [weighted Loss:3.602    Policy Loss: 6.673    Value Loss: 5.304    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 59704      Buffer Size: 7601       Transition Number: 150.048 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:21:53,403][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 6.262    Value Loss: 4.887    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 60436      Buffer Size: 7694       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:28:57,668][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 6.422    Value Loss: 5.381    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 61055      Buffer Size: 7666       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:36:01,308][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 6.502    Value Loss: 5.127    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 61688      Buffer Size: 7648       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:42:57,640][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 6.411    Value Loss: 5.166    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 62327      Buffer Size: 7690       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:50:00,685][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.027    [weighted Loss:4.027    Policy Loss: 6.394    Value Loss: 5.130    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 62955      Buffer Size: 7680       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-29 21:57:02,766][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 6.137    Value Loss: 4.863    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 63625      Buffer Size: 7710       Transition Number: 149.981 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:03:55,555][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 5.926    Value Loss: 5.031    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 64241      Buffer Size: 7717       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:10:55,514][train][INFO][train.py>_log] ==> #77000      Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 5.658    Value Loss: 4.635    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 64856      Buffer Size: 7649       Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:17:50,412][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 5.764    Value Loss: 5.145    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 65500      Buffer Size: 7634       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:24:53,520][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 6.213    Value Loss: 5.079    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 66130      Buffer Size: 7591       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:32:00,670][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.701    [weighted Loss:3.701    Policy Loss: 6.699    Value Loss: 4.661    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 66750      Buffer Size: 7520       Transition Number: 150.044 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:39:14,109][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.293    [weighted Loss:3.293    Policy Loss: 6.258    Value Loss: 4.382    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 67380      Buffer Size: 7447       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:46:16,717][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 5.968    Value Loss: 5.067    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 67994      Buffer Size: 7369       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-29 22:53:16,205][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 6.275    Value Loss: 4.794    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 68591      Buffer Size: 7356       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:00:23,399][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 5.794    Value Loss: 4.600    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 69245      Buffer Size: 7355       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:07:39,347][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.131    [weighted Loss:3.131    Policy Loss: 6.298    Value Loss: 4.910    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 69910      Buffer Size: 7335       Transition Number: 150.010 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:14:45,201][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 5.968    Value Loss: 4.908    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 70562      Buffer Size: 7343       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:21:51,640][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 5.903    Value Loss: 4.757    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 71208      Buffer Size: 7334       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:28:57,057][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 6.249    Value Loss: 4.795    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 71861      Buffer Size: 7335       Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:36:05,651][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 6.371    Value Loss: 4.942    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 72556      Buffer Size: 7350       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:43:12,543][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 6.735    Value Loss: 4.860    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 73196      Buffer Size: 7344       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:50:20,141][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 6.057    Value Loss: 4.577    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 73899      Buffer Size: 7392       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-29 23:57:21,232][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 6.492    Value Loss: 4.878    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 74578      Buffer Size: 7426       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:04:36,986][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 6.699    Value Loss: 4.688    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 75234      Buffer Size: 7427       Transition Number: 150.021 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:11:42,796][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.822    [weighted Loss:3.822    Policy Loss: 6.768    Value Loss: 5.249    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 75854      Buffer Size: 7432       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:18:52,363][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 6.318    Value Loss: 4.885    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 76491      Buffer Size: 7410       Transition Number: 150.001 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:25:52,714][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 6.879    Value Loss: 5.057    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 77157      Buffer Size: 7440       Transition Number: 149.974 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:33:02,642][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 6.062    Value Loss: 5.005    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 77810      Buffer Size: 7411       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:40:11,087][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 6.487    Value Loss: 4.663    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 78433      Buffer Size: 7397       Transition Number: 150.020 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:47:13,340][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.453    [weighted Loss:3.453    Policy Loss: 6.353    Value Loss: 5.073    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 79186      Buffer Size: 7474       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-30 00:54:17,824][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 6.090    Value Loss: 4.710    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 79882      Buffer Size: 7486       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:01:09,068][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.707    [weighted Loss:2.707    Policy Loss: 6.898    Value Loss: 4.810    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 80519      Buffer Size: 7490       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:08:10,427][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.997    [weighted Loss:2.997    Policy Loss: 6.278    Value Loss: 4.839    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 81160      Buffer Size: 7472       Transition Number: 149.974 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:15:15,868][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.843    [weighted Loss:2.843    Policy Loss: 6.541    Value Loss: 5.207    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 81804      Buffer Size: 7434       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:22:23,771][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 6.390    Value Loss: 4.736    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 82432      Buffer Size: 7426       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:29:38,094][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 6.770    Value Loss: 4.791    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 83095      Buffer Size: 7433       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:36:39,697][train][INFO][train.py>_log] ==> #106000     Total Loss: 3.298    [weighted Loss:3.298    Policy Loss: 6.609    Value Loss: 5.114    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 83763      Buffer Size: 7470       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:43:46,304][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 6.376    Value Loss: 5.327    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 84381      Buffer Size: 7434       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:50:55,988][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 6.473    Value Loss: 5.098    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 84986      Buffer Size: 7413       Transition Number: 150.060 k Batch Size: 256        Lr: 0.100   
[2021-10-30 01:58:05,636][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.854    [weighted Loss:1.854    Policy Loss: 6.719    Value Loss: 4.759    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 85638      Buffer Size: 7406       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:05:23,212][train][INFO][train.py>_log] ==> #110000     Total Loss: 4.038    [weighted Loss:4.038    Policy Loss: 6.601    Value Loss: 5.026    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 86352      Buffer Size: 7396       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:12:44,249][train][INFO][train.py>_log] ==> #111000     Total Loss: 1.954    [weighted Loss:1.954    Policy Loss: 6.364    Value Loss: 5.057    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 87011      Buffer Size: 7318       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:20:01,163][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 6.707    Value Loss: 4.871    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 87648      Buffer Size: 7282       Transition Number: 150.030 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:27:20,124][train][INFO][train.py>_log] ==> #113000     Total Loss: 3.050    [weighted Loss:3.050    Policy Loss: 6.474    Value Loss: 5.277    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 88302      Buffer Size: 7253       Transition Number: 150.055 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:34:30,626][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.281    [weighted Loss:3.281    Policy Loss: 7.147    Value Loss: 4.841    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 88948      Buffer Size: 7233       Transition Number: 150.037 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:41:42,892][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.286    [weighted Loss:3.286    Policy Loss: 6.745    Value Loss: 5.101    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 89614      Buffer Size: 7226       Transition Number: 150.082 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:48:49,909][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.768    [weighted Loss:3.768    Policy Loss: 7.041    Value Loss: 5.219    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 90230      Buffer Size: 7204       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 02:55:58,511][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 6.330    Value Loss: 4.491    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 90903      Buffer Size: 7210       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:03:05,770][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 6.393    Value Loss: 4.885    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 91582      Buffer Size: 7240       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:10:26,462][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.098    [weighted Loss:3.098    Policy Loss: 6.529    Value Loss: 5.213    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 92243      Buffer Size: 7266       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:17:42,030][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 6.107    Value Loss: 5.015    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 92879      Buffer Size: 7271       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:24:57,204][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 6.579    Value Loss: 4.851    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 93553      Buffer Size: 7241       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:32:04,799][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.617    [weighted Loss:3.617    Policy Loss: 5.875    Value Loss: 4.894    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 94213      Buffer Size: 7264       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:39:12,227][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.280    [weighted Loss:3.280    Policy Loss: 6.395    Value Loss: 5.172    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 94838      Buffer Size: 7253       Transition Number: 150.039 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:46:29,167][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 5.842    Value Loss: 4.743    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 95465      Buffer Size: 7253       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-10-30 03:53:40,798][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 6.111    Value Loss: 5.178    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 96123      Buffer Size: 7268       Transition Number: 150.045 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:00:50,539][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 6.289    Value Loss: 5.128    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 96783      Buffer Size: 7300       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:08:15,726][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 5.915    Value Loss: 5.155    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 97469      Buffer Size: 7309       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:15:43,646][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.651    [weighted Loss:2.651    Policy Loss: 6.446    Value Loss: 4.888    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 98127      Buffer Size: 7280       Transition Number: 150.007 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:22:52,737][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 6.251    Value Loss: 5.416    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 98773      Buffer Size: 7246       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:30:08,323][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 5.753    Value Loss: 5.030    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 99430      Buffer Size: 7259       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:37:17,726][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.175    [weighted Loss:3.175    Policy Loss: 6.219    Value Loss: 4.925    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 100088     Buffer Size: 7287       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:44:29,396][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 5.898    Value Loss: 5.211    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 100756     Buffer Size: 7272       Transition Number: 150.014 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:51:42,736][train][INFO][train.py>_log] ==> #133000     Total Loss: 1.673    [weighted Loss:1.673    Policy Loss: 5.788    Value Loss: 5.190    Reward Loss: 1.253    Consistency Loss: 0.000    ] Replay Episodes Collected: 101394     Buffer Size: 7261       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 04:58:54,412][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 5.930    Value Loss: 4.873    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 102039     Buffer Size: 7267       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:06:05,053][train][INFO][train.py>_log] ==> #135000     Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 5.663    Value Loss: 5.010    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 102700     Buffer Size: 7293       Transition Number: 149.974 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:13:11,309][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 5.477    Value Loss: 4.747    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 103370     Buffer Size: 7329       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:20:31,644][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 5.987    Value Loss: 5.032    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 104039     Buffer Size: 7308       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:27:39,434][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 5.814    Value Loss: 4.969    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 104689     Buffer Size: 7324       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:34:45,374][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 5.429    Value Loss: 4.973    Reward Loss: 1.152    Consistency Loss: 0.000    ] Replay Episodes Collected: 105393     Buffer Size: 7395       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:41:56,688][train][INFO][train.py>_log] ==> #140000     Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 5.254    Value Loss: 4.885    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 106038     Buffer Size: 7416       Transition Number: 150.043 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:48:52,896][train][INFO][train.py>_log] ==> #141000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 6.129    Value Loss: 5.266    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 106800     Buffer Size: 7529       Transition Number: 150.110 k Batch Size: 256        Lr: 0.100   
[2021-10-30 05:56:02,745][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.647    [weighted Loss:2.647    Policy Loss: 6.008    Value Loss: 4.825    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 107458     Buffer Size: 7534       Transition Number: 150.042 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:03:12,997][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.721    [weighted Loss:3.721    Policy Loss: 5.721    Value Loss: 5.223    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 108165     Buffer Size: 7585       Transition Number: 150.012 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:10:28,483][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.437    [weighted Loss:2.437    Policy Loss: 6.039    Value Loss: 4.900    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 108818     Buffer Size: 7584       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:17:39,199][train][INFO][train.py>_log] ==> #145000     Total Loss: 1.142    [weighted Loss:1.142    Policy Loss: 5.670    Value Loss: 4.963    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 109476     Buffer Size: 7604       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:24:49,282][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.763    [weighted Loss:2.763    Policy Loss: 5.376    Value Loss: 5.075    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 110166     Buffer Size: 7623       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:32:03,104][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 5.583    Value Loss: 5.167    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 110816     Buffer Size: 7607       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:39:05,983][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 5.679    Value Loss: 5.199    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 111434     Buffer Size: 7597       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:46:10,730][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 6.089    Value Loss: 5.102    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 112117     Buffer Size: 7627       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 06:53:10,269][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 5.392    Value Loss: 5.201    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 112766     Buffer Size: 7603       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:00:09,760][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 5.508    Value Loss: 4.862    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 113449     Buffer Size: 7625       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:07:17,881][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 5.672    Value Loss: 4.715    Reward Loss: 1.206    Consistency Loss: 0.000    ] Replay Episodes Collected: 114119     Buffer Size: 7555       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:14:23,867][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 5.693    Value Loss: 4.976    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 114738     Buffer Size: 7479       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:21:24,219][train][INFO][train.py>_log] ==> #154000     Total Loss: 1.999    [weighted Loss:1.999    Policy Loss: 5.328    Value Loss: 5.232    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 115337     Buffer Size: 7428       Transition Number: 150.087 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:28:30,727][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 5.757    Value Loss: 4.950    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 115976     Buffer Size: 7412       Transition Number: 150.064 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:35:34,960][train][INFO][train.py>_log] ==> #156000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 5.210    Value Loss: 4.894    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 116632     Buffer Size: 7411       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:42:51,307][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.508    [weighted Loss:2.508    Policy Loss: 6.453    Value Loss: 5.191    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 117347     Buffer Size: 7440       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:49:56,322][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.707    [weighted Loss:2.707    Policy Loss: 5.369    Value Loss: 5.030    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 118019     Buffer Size: 7440       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 07:56:58,791][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 6.447    Value Loss: 5.329    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 118700     Buffer Size: 7466       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:04:07,278][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 5.818    Value Loss: 5.222    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 119317     Buffer Size: 7434       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:11:30,584][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.566    [weighted Loss:2.566    Policy Loss: 6.507    Value Loss: 5.061    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 120026     Buffer Size: 7460       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:18:39,473][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 5.550    Value Loss: 5.257    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 120696     Buffer Size: 7450       Transition Number: 150.035 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:25:43,355][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 6.170    Value Loss: 4.829    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 121410     Buffer Size: 7467       Transition Number: 150.043 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:32:55,597][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 5.593    Value Loss: 4.851    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 122043     Buffer Size: 7486       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:40:20,640][train][INFO][train.py>_log] ==> #165000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 6.010    Value Loss: 5.136    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 122742     Buffer Size: 7509       Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:47:33,964][train][INFO][train.py>_log] ==> #166000     Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 5.287    Value Loss: 5.043    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 123370     Buffer Size: 7497       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-30 08:54:44,490][train][INFO][train.py>_log] ==> #167000     Total Loss: 1.079    [weighted Loss:1.079    Policy Loss: 5.276    Value Loss: 5.103    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 124044     Buffer Size: 7515       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:02:02,120][train][INFO][train.py>_log] ==> #168000     Total Loss: 1.948    [weighted Loss:1.948    Policy Loss: 4.970    Value Loss: 4.752    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 124719     Buffer Size: 7499       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:09:08,449][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 5.290    Value Loss: 5.286    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 125370     Buffer Size: 7472       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:16:08,218][train][INFO][train.py>_log] ==> #170000     Total Loss: 1.807    [weighted Loss:1.807    Policy Loss: 5.357    Value Loss: 5.223    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 126010     Buffer Size: 7447       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:23:20,502][train][INFO][train.py>_log] ==> #171000     Total Loss: 1.832    [weighted Loss:1.832    Policy Loss: 5.318    Value Loss: 5.188    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 126716     Buffer Size: 7469       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:30:22,776][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 4.925    Value Loss: 4.961    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 127299     Buffer Size: 7423       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:37:37,472][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.050    [weighted Loss:3.050    Policy Loss: 5.230    Value Loss: 5.301    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 128037     Buffer Size: 7429       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:44:43,617][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 5.301    Value Loss: 5.042    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 128684     Buffer Size: 7413       Transition Number: 150.085 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:51:55,564][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 5.470    Value Loss: 4.938    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 129353     Buffer Size: 7402       Transition Number: 150.005 k Batch Size: 256        Lr: 0.100   
[2021-10-30 09:59:17,385][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 5.100    Value Loss: 4.746    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 130010     Buffer Size: 7396       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:06:28,122][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.052    [weighted Loss:3.052    Policy Loss: 5.845    Value Loss: 4.985    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 130699     Buffer Size: 7426       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:13:55,140][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 5.709    Value Loss: 4.792    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 131383     Buffer Size: 7417       Transition Number: 150.075 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:21:05,360][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 5.252    Value Loss: 5.096    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 132029     Buffer Size: 7389       Transition Number: 149.981 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:28:29,681][train][INFO][train.py>_log] ==> #180000     Total Loss: 3.208    [weighted Loss:3.208    Policy Loss: 5.689    Value Loss: 5.095    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 132678     Buffer Size: 7383       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:35:52,005][train][INFO][train.py>_log] ==> #181000     Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 5.904    Value Loss: 4.833    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 133365     Buffer Size: 7367       Transition Number: 149.981 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:43:14,779][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 5.624    Value Loss: 5.066    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 134089     Buffer Size: 7371       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 10:50:32,694][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 5.960    Value Loss: 5.258    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 134818     Buffer Size: 7438       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
