[2021-11-02 09:24:56,648][train][INFO][train.py>_log] ==> #0          Total Loss: 50.772   [weighted Loss:50.772   Policy Loss: 7.522    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 573        Buffer Size: 573        Transition Number: 2.077   k Batch Size: 256        Lr: 0.000   
[2021-11-02 09:27:12,974][train][INFO][train.py>_log] ==> #1000       Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 7.584    Value Loss: 2.971    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225       Buffer Size: 1225       Transition Number: 4.439   k Batch Size: 256        Lr: 0.010   
[2021-11-02 09:29:44,153][train][INFO][train.py>_log] ==> #2000       Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 7.113    Value Loss: 1.940    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 1956       Buffer Size: 1956       Transition Number: 6.887   k Batch Size: 256        Lr: 0.020   
[2021-11-02 09:32:25,170][train][INFO][train.py>_log] ==> #3000       Total Loss: 1.249    [weighted Loss:1.249    Policy Loss: 6.440    Value Loss: 1.669    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 2729       Buffer Size: 2729       Transition Number: 9.376   k Batch Size: 256        Lr: 0.030   
[2021-11-02 09:35:18,145][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 6.703    Value Loss: 1.692    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 3414       Buffer Size: 3414       Transition Number: 11.984  k Batch Size: 256        Lr: 0.040   
[2021-11-02 09:38:07,138][train][INFO][train.py>_log] ==> #5000       Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 5.824    Value Loss: 1.559    Reward Loss: 0.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 4113       Buffer Size: 4113       Transition Number: 14.487  k Batch Size: 256        Lr: 0.050   
[2021-11-02 09:40:55,611][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 5.965    Value Loss: 1.620    Reward Loss: 0.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 4674       Buffer Size: 4674       Transition Number: 16.944  k Batch Size: 256        Lr: 0.060   
[2021-11-02 09:43:45,932][train][INFO][train.py>_log] ==> #7000       Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 6.068    Value Loss: 1.767    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 5218       Buffer Size: 5218       Transition Number: 19.460  k Batch Size: 256        Lr: 0.070   
[2021-11-02 09:46:39,264][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.526    [weighted Loss:2.526    Policy Loss: 6.133    Value Loss: 1.810    Reward Loss: 0.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 5749       Buffer Size: 5749       Transition Number: 21.933  k Batch Size: 256        Lr: 0.080   
[2021-11-02 09:49:34,702][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 5.700    Value Loss: 1.486    Reward Loss: 0.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 6291       Buffer Size: 6291       Transition Number: 24.496  k Batch Size: 256        Lr: 0.090   
[2021-11-02 09:52:26,863][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.581    [weighted Loss:2.581    Policy Loss: 6.040    Value Loss: 1.619    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 6783       Buffer Size: 6783       Transition Number: 26.881  k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:55:20,058][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 6.191    Value Loss: 1.643    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 7293       Buffer Size: 7293       Transition Number: 29.487  k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:58:15,238][train][INFO][train.py>_log] ==> #12000      Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 5.925    Value Loss: 1.470    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 7798       Buffer Size: 7798       Transition Number: 31.938  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:01:12,789][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 6.240    Value Loss: 1.535    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 8304       Buffer Size: 8304       Transition Number: 34.432  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:04:15,743][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 6.039    Value Loss: 1.663    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 8926       Buffer Size: 8926       Transition Number: 37.089  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:07:16,214][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 5.991    Value Loss: 1.505    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 9496       Buffer Size: 9496       Transition Number: 39.673  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:10:15,259][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.001    [weighted Loss:3.001    Policy Loss: 6.247    Value Loss: 1.641    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 10016      Buffer Size: 10016      Transition Number: 42.140  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:13:15,665][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 5.926    Value Loss: 1.646    Reward Loss: 0.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 10542      Buffer Size: 10542      Transition Number: 44.738  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:16:13,343][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 6.394    Value Loss: 1.658    Reward Loss: 0.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 11051      Buffer Size: 11051      Transition Number: 47.310  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:19:13,826][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.162    [weighted Loss:2.162    Policy Loss: 6.121    Value Loss: 1.722    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 11535      Buffer Size: 11535      Transition Number: 49.828  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:22:18,443][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 6.113    Value Loss: 1.667    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 12046      Buffer Size: 12046      Transition Number: 52.455  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:25:26,780][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 5.991    Value Loss: 1.568    Reward Loss: 0.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 12605      Buffer Size: 12605      Transition Number: 55.134  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:28:35,194][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.481    [weighted Loss:3.481    Policy Loss: 5.916    Value Loss: 1.545    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 13170      Buffer Size: 13170      Transition Number: 57.715  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:31:41,467][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 6.019    Value Loss: 1.618    Reward Loss: 0.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 13678      Buffer Size: 13678      Transition Number: 60.391  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:34:56,825][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 5.969    Value Loss: 1.590    Reward Loss: 0.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 14231      Buffer Size: 14231      Transition Number: 63.233  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:38:10,111][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 6.520    Value Loss: 1.592    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 14753      Buffer Size: 14753      Transition Number: 65.983  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:41:49,652][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 6.375    Value Loss: 1.644    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 15392      Buffer Size: 15392      Transition Number: 69.215  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:45:16,127][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 6.010    Value Loss: 1.697    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 15948      Buffer Size: 15948      Transition Number: 72.240  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:48:22,935][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.217    [weighted Loss:3.217    Policy Loss: 6.495    Value Loss: 1.815    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 16445      Buffer Size: 16445      Transition Number: 74.860  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:51:31,001][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.375    [weighted Loss:1.375    Policy Loss: 6.237    Value Loss: 1.800    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 16918      Buffer Size: 16918      Transition Number: 77.437  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:54:46,140][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.939    [weighted Loss:1.939    Policy Loss: 6.199    Value Loss: 1.817    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 17442      Buffer Size: 17442      Transition Number: 80.186  k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:58:09,453][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 6.377    Value Loss: 1.790    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 18073      Buffer Size: 18073      Transition Number: 83.144  k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:01:21,850][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 6.129    Value Loss: 1.603    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 18635      Buffer Size: 18635      Transition Number: 85.834  k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:04:31,616][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.601    [weighted Loss:2.601    Policy Loss: 6.676    Value Loss: 1.615    Reward Loss: 0.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 19158      Buffer Size: 19158      Transition Number: 88.610  k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:07:47,417][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 5.921    Value Loss: 1.304    Reward Loss: 0.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 19646      Buffer Size: 19646      Transition Number: 91.343  k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:11:05,103][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.247    [weighted Loss:2.247    Policy Loss: 6.096    Value Loss: 1.613    Reward Loss: 0.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 20161      Buffer Size: 20161      Transition Number: 94.195  k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:14:30,470][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 6.057    Value Loss: 1.455    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 20663      Buffer Size: 20663      Transition Number: 97.178  k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:17:47,026][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 6.189    Value Loss: 1.592    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 21159      Buffer Size: 21159      Transition Number: 99.956  k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:21:01,963][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 6.686    Value Loss: 1.589    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 21662      Buffer Size: 21662      Transition Number: 102.767 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:24:22,364][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.967    [weighted Loss:1.967    Policy Loss: 6.482    Value Loss: 1.496    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 22185      Buffer Size: 22185      Transition Number: 105.629 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:27:36,891][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 6.371    Value Loss: 1.560    Reward Loss: 0.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 22655      Buffer Size: 22655      Transition Number: 108.354 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:30:49,106][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 6.723    Value Loss: 1.754    Reward Loss: 0.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 23092      Buffer Size: 23092      Transition Number: 111.083 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:34:26,667][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.222    [weighted Loss:2.222    Policy Loss: 6.448    Value Loss: 1.499    Reward Loss: 0.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 23642      Buffer Size: 23642      Transition Number: 114.218 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:38:01,228][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 6.441    Value Loss: 1.674    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 24124      Buffer Size: 24124      Transition Number: 117.180 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:41:18,690][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.681    [weighted Loss:3.681    Policy Loss: 6.794    Value Loss: 1.525    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 24575      Buffer Size: 24575      Transition Number: 119.935 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:44:28,312][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 6.624    Value Loss: 1.422    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 24992      Buffer Size: 24992      Transition Number: 122.584 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:47:56,013][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 6.647    Value Loss: 1.448    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 25420      Buffer Size: 25420      Transition Number: 125.438 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:51:12,691][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 7.301    Value Loss: 1.693    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 25796      Buffer Size: 25796      Transition Number: 128.072 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:54:31,607][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 6.713    Value Loss: 1.713    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 26217      Buffer Size: 26217      Transition Number: 130.862 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:58:24,673][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 6.793    Value Loss: 1.722    Reward Loss: 0.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 26693      Buffer Size: 26693      Transition Number: 134.085 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:02:10,934][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 6.494    Value Loss: 1.609    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 27182      Buffer Size: 27182      Transition Number: 137.346 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:06:16,808][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.908    [weighted Loss:2.908    Policy Loss: 6.553    Value Loss: 1.651    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 27764      Buffer Size: 27764      Transition Number: 140.827 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:10:12,049][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.515    [weighted Loss:2.515    Policy Loss: 6.537    Value Loss: 1.495    Reward Loss: 0.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 28303      Buffer Size: 28303      Transition Number: 144.162 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:13:41,816][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 6.893    Value Loss: 1.609    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 28758      Buffer Size: 28758      Transition Number: 147.134 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:17:22,669][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 6.712    Value Loss: 1.579    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 29239      Buffer Size: 29239      Transition Number: 150.208 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:21:07,336][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.221    [weighted Loss:1.221    Policy Loss: 6.819    Value Loss: 1.608    Reward Loss: 0.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 29704      Buffer Size: 29704      Transition Number: 153.320 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:25:20,134][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.808    [weighted Loss:2.808    Policy Loss: 6.642    Value Loss: 1.664    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 30250      Buffer Size: 30250      Transition Number: 157.004 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:29:16,371][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 6.566    Value Loss: 1.619    Reward Loss: 0.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 30709      Buffer Size: 30709      Transition Number: 160.165 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:33:16,438][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 6.616    Value Loss: 1.771    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 31185      Buffer Size: 31185      Transition Number: 163.599 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:37:11,119][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 6.509    Value Loss: 1.638    Reward Loss: 0.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 31666      Buffer Size: 31666      Transition Number: 166.927 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:41:00,044][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 7.121    Value Loss: 1.812    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 32149      Buffer Size: 32149      Transition Number: 170.138 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:45:03,172][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.747    [weighted Loss:2.747    Policy Loss: 6.776    Value Loss: 1.590    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 32712      Buffer Size: 32712      Transition Number: 173.672 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:48:39,610][train][INFO][train.py>_log] ==> #62000      Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 7.158    Value Loss: 1.717    Reward Loss: 0.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 33109      Buffer Size: 33109      Transition Number: 176.517 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:52:29,995][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 6.995    Value Loss: 1.892    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 33562      Buffer Size: 33562      Transition Number: 179.795 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:56:22,290][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.129    [weighted Loss:2.129    Policy Loss: 7.259    Value Loss: 1.859    Reward Loss: 0.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 34025      Buffer Size: 34025      Transition Number: 182.825 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:00:42,467][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 6.918    Value Loss: 2.076    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 34502      Buffer Size: 34502      Transition Number: 186.339 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:05:07,320][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.754    [weighted Loss:3.754    Policy Loss: 6.784    Value Loss: 1.409    Reward Loss: 0.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 35040      Buffer Size: 35040      Transition Number: 189.930 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:09:25,848][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.054    [weighted Loss:2.054    Policy Loss: 6.531    Value Loss: 1.694    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 35517      Buffer Size: 35517      Transition Number: 193.451 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:14:05,166][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.475    [weighted Loss:2.475    Policy Loss: 6.859    Value Loss: 1.741    Reward Loss: 0.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 36059      Buffer Size: 36059      Transition Number: 197.183 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:18:34,697][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.719    [weighted Loss:2.719    Policy Loss: 6.993    Value Loss: 1.868    Reward Loss: 0.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 36548      Buffer Size: 36548      Transition Number: 200.718 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:23:01,733][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.583    [weighted Loss:2.583    Policy Loss: 6.636    Value Loss: 1.753    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 37020      Buffer Size: 37020      Transition Number: 204.369 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:28:10,010][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 7.161    Value Loss: 2.113    Reward Loss: 0.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 37551      Buffer Size: 37551      Transition Number: 208.662 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:32:49,623][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.047    [weighted Loss:3.047    Policy Loss: 7.355    Value Loss: 2.071    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 38033      Buffer Size: 38033      Transition Number: 212.360 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:38:04,271][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.350    [weighted Loss:3.350    Policy Loss: 6.696    Value Loss: 1.800    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 38529      Buffer Size: 38529      Transition Number: 216.577 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:43:09,294][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.480    [weighted Loss:3.480    Policy Loss: 7.153    Value Loss: 2.079    Reward Loss: 0.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 39028      Buffer Size: 39028      Transition Number: 220.735 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:48:31,702][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.482    [weighted Loss:2.482    Policy Loss: 6.756    Value Loss: 1.938    Reward Loss: 0.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 39562      Buffer Size: 39562      Transition Number: 224.898 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:53:56,072][train][INFO][train.py>_log] ==> #76000      Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 7.126    Value Loss: 2.098    Reward Loss: 0.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 39962      Buffer Size: 39962      Transition Number: 228.872 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:59:20,361][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.998    [weighted Loss:3.998    Policy Loss: 7.119    Value Loss: 2.264    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 40379      Buffer Size: 40379      Transition Number: 232.879 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:05:22,002][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.110    [weighted Loss:1.110    Policy Loss: 6.830    Value Loss: 2.122    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 40981      Buffer Size: 40981      Transition Number: 237.526 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:11:43,355][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.219    [weighted Loss:3.219    Policy Loss: 6.953    Value Loss: 2.092    Reward Loss: 0.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 41560      Buffer Size: 41560      Transition Number: 242.373 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:18:11,679][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 6.574    Value Loss: 2.203    Reward Loss: 0.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 42071      Buffer Size: 42071      Transition Number: 247.369 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:25:30,347][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 6.852    Value Loss: 2.147    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 42688      Buffer Size: 42688      Transition Number: 253.233 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:33:42,189][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.209    [weighted Loss:3.209    Policy Loss: 7.095    Value Loss: 2.508    Reward Loss: 0.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 43325      Buffer Size: 43325      Transition Number: 259.276 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:41:34,487][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 7.292    Value Loss: 2.281    Reward Loss: 0.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 43903      Buffer Size: 43903      Transition Number: 265.109 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:50:07,867][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.708    [weighted Loss:2.708    Policy Loss: 6.865    Value Loss: 2.652    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 44558      Buffer Size: 44558      Transition Number: 271.913 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:59:04,161][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 6.651    Value Loss: 2.623    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 45181      Buffer Size: 45181      Transition Number: 278.915 k Batch Size: 256        Lr: 0.100   
[2021-11-02 15:08:42,228][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 6.782    Value Loss: 2.753    Reward Loss: 0.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 45763      Buffer Size: 45763      Transition Number: 286.593 k Batch Size: 256        Lr: 0.100   
[2021-11-02 15:18:19,975][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 7.166    Value Loss: 2.862    Reward Loss: 0.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 46357      Buffer Size: 46357      Transition Number: 294.174 k Batch Size: 256        Lr: 0.100   
[2021-11-02 15:28:46,257][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 6.674    Value Loss: 2.511    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 47027      Buffer Size: 47027      Transition Number: 302.274 k Batch Size: 256        Lr: 0.100   
[2021-11-02 15:39:42,210][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 7.110    Value Loss: 3.251    Reward Loss: 0.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 47633      Buffer Size: 47633      Transition Number: 311.305 k Batch Size: 256        Lr: 0.100   
[2021-11-02 15:51:05,841][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 7.006    Value Loss: 2.950    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 48204      Buffer Size: 48204      Transition Number: 320.191 k Batch Size: 256        Lr: 0.100   
[2021-11-02 16:02:34,776][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 6.973    Value Loss: 2.850    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 48788      Buffer Size: 48788      Transition Number: 329.123 k Batch Size: 256        Lr: 0.100   
[2021-11-02 16:14:38,950][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 6.866    Value Loss: 3.202    Reward Loss: 0.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 49324      Buffer Size: 49324      Transition Number: 339.258 k Batch Size: 256        Lr: 0.100   
[2021-11-02 16:27:10,332][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.606    [weighted Loss:2.606    Policy Loss: 6.560    Value Loss: 3.101    Reward Loss: 0.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 49929      Buffer Size: 49929      Transition Number: 349.675 k Batch Size: 256        Lr: 0.100   
[2021-11-02 16:39:42,146][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 6.628    Value Loss: 3.441    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 50540      Buffer Size: 50540      Transition Number: 360.195 k Batch Size: 256        Lr: 0.100   
[2021-11-02 16:52:28,591][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.475    [weighted Loss:2.475    Policy Loss: 6.712    Value Loss: 3.239    Reward Loss: 0.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 51111      Buffer Size: 51111      Transition Number: 370.790 k Batch Size: 256        Lr: 0.100   
[2021-11-02 17:05:39,862][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.168    [weighted Loss:3.168    Policy Loss: 6.621    Value Loss: 3.314    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 51660      Buffer Size: 51660      Transition Number: 381.743 k Batch Size: 256        Lr: 0.100   
[2021-11-02 17:19:00,538][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.078    [weighted Loss:4.078    Policy Loss: 6.436    Value Loss: 3.187    Reward Loss: 0.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 52218      Buffer Size: 52218      Transition Number: 392.715 k Batch Size: 256        Lr: 0.100   
[2021-11-02 17:32:49,602][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 6.515    Value Loss: 3.345    Reward Loss: 0.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 52811      Buffer Size: 52811      Transition Number: 403.860 k Batch Size: 256        Lr: 0.100   
[2021-11-02 17:46:09,461][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 6.525    Value Loss: 3.497    Reward Loss: 0.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 53341      Buffer Size: 53341      Transition Number: 415.139 k Batch Size: 256        Lr: 0.100   
[2021-11-02 18:00:15,033][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.263    [weighted Loss:4.263    Policy Loss: 6.750    Value Loss: 3.417    Reward Loss: 0.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 53901      Buffer Size: 53901      Transition Number: 426.470 k Batch Size: 256        Lr: 0.100   
[2021-11-02 18:14:28,678][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 6.527    Value Loss: 3.365    Reward Loss: 0.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 54443      Buffer Size: 54443      Transition Number: 438.170 k Batch Size: 256        Lr: 0.100   
[2021-11-02 18:28:53,173][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 6.263    Value Loss: 3.765    Reward Loss: 0.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 54976      Buffer Size: 54976      Transition Number: 450.459 k Batch Size: 256        Lr: 0.100   
[2021-11-02 18:43:26,528][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.758    [weighted Loss:3.758    Policy Loss: 6.727    Value Loss: 3.888    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 55507      Buffer Size: 55507      Transition Number: 462.164 k Batch Size: 256        Lr: 0.100   
[2021-11-02 18:57:51,856][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 6.393    Value Loss: 3.533    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 56027      Buffer Size: 56027      Transition Number: 474.431 k Batch Size: 256        Lr: 0.100   
[2021-11-02 19:13:23,557][train][INFO][train.py>_log] ==> #105000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 6.236    Value Loss: 3.753    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 56572      Buffer Size: 56572      Transition Number: 487.739 k Batch Size: 256        Lr: 0.100   
[2021-11-02 19:29:26,740][train][INFO][train.py>_log] ==> #106000     Total Loss: 3.910    [weighted Loss:3.910    Policy Loss: 6.410    Value Loss: 3.823    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 57169      Buffer Size: 57169      Transition Number: 501.242 k Batch Size: 256        Lr: 0.100   
[2021-11-02 19:47:11,263][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 6.202    Value Loss: 3.852    Reward Loss: 0.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 57777      Buffer Size: 57777      Transition Number: 516.423 k Batch Size: 256        Lr: 0.100   
[2021-11-02 20:03:28,564][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.058    [weighted Loss:3.058    Policy Loss: 6.276    Value Loss: 3.841    Reward Loss: 0.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 58342      Buffer Size: 58342      Transition Number: 530.025 k Batch Size: 256        Lr: 0.100   
[2021-11-02 20:18:29,163][train][INFO][train.py>_log] ==> #109000     Total Loss: 4.119    [weighted Loss:4.119    Policy Loss: 6.235    Value Loss: 3.776    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 58872      Buffer Size: 58872      Transition Number: 542.716 k Batch Size: 256        Lr: 0.100   
[2021-11-02 20:33:50,229][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 6.108    Value Loss: 3.832    Reward Loss: 0.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 59413      Buffer Size: 59413      Transition Number: 555.645 k Batch Size: 256        Lr: 0.100   
[2021-11-02 20:49:27,876][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.919    [weighted Loss:3.919    Policy Loss: 6.319    Value Loss: 3.769    Reward Loss: 0.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 59948      Buffer Size: 59948      Transition Number: 568.690 k Batch Size: 256        Lr: 0.100   
[2021-11-02 21:04:52,196][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 6.250    Value Loss: 4.043    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 60444      Buffer Size: 60444      Transition Number: 581.318 k Batch Size: 256        Lr: 0.100   
[2021-11-02 21:20:26,938][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 6.392    Value Loss: 3.847    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 60981      Buffer Size: 60981      Transition Number: 594.296 k Batch Size: 256        Lr: 0.100   
[2021-11-02 21:36:06,295][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 5.814    Value Loss: 3.929    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 61503      Buffer Size: 61503      Transition Number: 607.212 k Batch Size: 256        Lr: 0.100   
[2021-11-02 21:52:11,823][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.255    [weighted Loss:4.255    Policy Loss: 6.357    Value Loss: 3.708    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 62047      Buffer Size: 62047      Transition Number: 620.639 k Batch Size: 256        Lr: 0.100   
[2021-11-02 22:08:18,659][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.320    [weighted Loss:3.320    Policy Loss: 6.250    Value Loss: 4.323    Reward Loss: 0.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 62603      Buffer Size: 62603      Transition Number: 634.367 k Batch Size: 256        Lr: 0.100   
[2021-11-02 22:26:07,725][train][INFO][train.py>_log] ==> #117000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 5.634    Value Loss: 4.053    Reward Loss: 0.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 63178      Buffer Size: 63178      Transition Number: 649.790 k Batch Size: 256        Lr: 0.100   
[2021-11-02 22:43:11,865][train][INFO][train.py>_log] ==> #118000     Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 5.921    Value Loss: 3.965    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 63740      Buffer Size: 63740      Transition Number: 664.187 k Batch Size: 256        Lr: 0.100   
[2021-11-02 23:00:01,835][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 6.020    Value Loss: 4.161    Reward Loss: 0.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 64284      Buffer Size: 64284      Transition Number: 678.256 k Batch Size: 256        Lr: 0.100   
[2021-11-02 23:16:39,267][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.411    [weighted Loss:3.411    Policy Loss: 6.134    Value Loss: 4.385    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 64841      Buffer Size: 64841      Transition Number: 692.077 k Batch Size: 256        Lr: 0.100   
[2021-11-02 23:33:40,061][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 5.922    Value Loss: 4.136    Reward Loss: 0.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 65380      Buffer Size: 65380      Transition Number: 706.269 k Batch Size: 256        Lr: 0.100   
[2021-11-02 23:50:50,003][train][INFO][train.py>_log] ==> #122000     Total Loss: 4.394    [weighted Loss:4.394    Policy Loss: 5.842    Value Loss: 4.324    Reward Loss: 0.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 65959      Buffer Size: 65959      Transition Number: 720.916 k Batch Size: 256        Lr: 0.100   
[2021-11-03 00:07:30,254][train][INFO][train.py>_log] ==> #123000     Total Loss: 4.684    [weighted Loss:4.684    Policy Loss: 5.899    Value Loss: 3.973    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 66513      Buffer Size: 66513      Transition Number: 735.047 k Batch Size: 256        Lr: 0.100   
[2021-11-03 00:24:22,877][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.044    [weighted Loss:4.044    Policy Loss: 5.839    Value Loss: 4.441    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 67075      Buffer Size: 67075      Transition Number: 749.022 k Batch Size: 256        Lr: 0.100   
[2021-11-03 00:41:44,460][train][INFO][train.py>_log] ==> #125000     Total Loss: 4.174    [weighted Loss:4.174    Policy Loss: 5.912    Value Loss: 4.514    Reward Loss: 0.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 67635      Buffer Size: 67635      Transition Number: 763.783 k Batch Size: 256        Lr: 0.100   
[2021-11-03 00:58:46,062][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 5.697    Value Loss: 4.161    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 68191      Buffer Size: 68191      Transition Number: 778.059 k Batch Size: 256        Lr: 0.100   
[2021-11-03 01:16:04,555][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 5.924    Value Loss: 4.704    Reward Loss: 0.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 68765      Buffer Size: 68765      Transition Number: 793.111 k Batch Size: 256        Lr: 0.100   
[2021-11-03 01:33:19,468][train][INFO][train.py>_log] ==> #128000     Total Loss: 3.677    [weighted Loss:3.677    Policy Loss: 5.928    Value Loss: 4.245    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 69305      Buffer Size: 69305      Transition Number: 808.021 k Batch Size: 256        Lr: 0.100   
