[2021-10-30 15:48:30,618][train][INFO][train.py>_log] ==> #0          Total Loss: 32.995   [weighted Loss:32.995   Policy Loss: 7.438    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 678        Buffer Size: 678        Transition Number: 2.537   k Batch Size: 256        Lr: 0.000   
[2021-10-30 15:51:38,282][train][INFO][train.py>_log] ==> #1000       Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 7.971    Value Loss: 3.739    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 5346       Buffer Size: 5346       Transition Number: 20.552  k Batch Size: 256        Lr: 0.010   
[2021-10-30 15:55:14,341][train][INFO][train.py>_log] ==> #2000       Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 8.646    Value Loss: 3.589    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 10876      Buffer Size: 10876      Transition Number: 41.578  k Batch Size: 256        Lr: 0.020   
[2021-10-30 15:59:08,448][train][INFO][train.py>_log] ==> #3000       Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 9.273    Value Loss: 3.022    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 15767      Buffer Size: 15767      Transition Number: 59.941  k Batch Size: 256        Lr: 0.030   
[2021-10-30 16:03:08,567][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.312    [weighted Loss:4.312    Policy Loss: 9.456    Value Loss: 2.758    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 20304      Buffer Size: 20304      Transition Number: 77.818  k Batch Size: 256        Lr: 0.040   
[2021-10-30 16:07:10,625][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 9.303    Value Loss: 2.710    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 25215      Buffer Size: 25215      Transition Number: 96.829  k Batch Size: 256        Lr: 0.050   
[2021-10-30 16:11:27,803][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.229    [weighted Loss:4.229    Policy Loss: 9.305    Value Loss: 2.716    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 30105      Buffer Size: 30105      Transition Number: 116.981 k Batch Size: 256        Lr: 0.060   
[2021-10-30 16:15:50,501][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.640    [weighted Loss:2.640    Policy Loss: 7.682    Value Loss: 2.471    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 34905      Buffer Size: 34905      Transition Number: 137.618 k Batch Size: 256        Lr: 0.070   
[2021-10-30 16:20:13,024][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.576    [weighted Loss:3.576    Policy Loss: 8.130    Value Loss: 2.416    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 39640      Buffer Size: 37590      Transition Number: 150.000 k Batch Size: 256        Lr: 0.080   
[2021-10-30 16:24:49,909][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 7.257    Value Loss: 2.387    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 45193      Buffer Size: 37261      Transition Number: 150.040 k Batch Size: 256        Lr: 0.090   
[2021-10-30 16:29:34,683][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 7.239    Value Loss: 2.556    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 50392      Buffer Size: 36761      Transition Number: 150.014 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:34:34,771][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.111    [weighted Loss:3.111    Policy Loss: 6.622    Value Loss: 2.440    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 56547      Buffer Size: 36483      Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:39:24,647][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 6.589    Value Loss: 2.342    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 62307      Buffer Size: 36264      Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:44:22,355][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 5.742    Value Loss: 2.361    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 66879      Buffer Size: 35156      Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:49:21,089][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.386    [weighted Loss:2.386    Policy Loss: 5.393    Value Loss: 2.376    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 70912      Buffer Size: 33717      Transition Number: 150.024 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:54:31,398][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.830    [weighted Loss:2.830    Policy Loss: 4.992    Value Loss: 2.479    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 75158      Buffer Size: 32088      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:59:50,395][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.090    [weighted Loss:2.090    Policy Loss: 5.119    Value Loss: 2.744    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 79473      Buffer Size: 30364      Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:05:12,284][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 5.989    Value Loss: 2.977    Reward Loss: 1.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 82764      Buffer Size: 27498      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:10:49,385][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.294    [weighted Loss:3.294    Policy Loss: 6.341    Value Loss: 3.487    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 85428      Buffer Size: 23624      Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:16:16,494][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 6.288    Value Loss: 3.727    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 87811      Buffer Size: 21069      Transition Number: 150.025 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:22:05,360][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.035    [weighted Loss:2.035    Policy Loss: 6.453    Value Loss: 3.977    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 90310      Buffer Size: 18871      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:28:02,646][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 6.590    Value Loss: 3.985    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 92412      Buffer Size: 16298      Transition Number: 150.007 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:34:25,665][train][INFO][train.py>_log] ==> #22000      Total Loss: 3.697    [weighted Loss:3.697    Policy Loss: 6.095    Value Loss: 4.433    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 94351      Buffer Size: 13682      Transition Number: 150.054 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:41:09,086][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.896    [weighted Loss:3.896    Policy Loss: 5.905    Value Loss: 4.436    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 96348      Buffer Size: 11995      Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:47:53,282][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.492    [weighted Loss:3.492    Policy Loss: 6.093    Value Loss: 4.844    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 98298      Buffer Size: 11016      Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:55:01,005][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 5.855    Value Loss: 4.809    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 100181     Buffer Size: 9894       Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:02:06,918][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.573    [weighted Loss:3.573    Policy Loss: 6.285    Value Loss: 5.064    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 102054     Buffer Size: 9325       Transition Number: 149.978 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:09:19,061][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.941    [weighted Loss:3.941    Policy Loss: 6.102    Value Loss: 5.195    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 103872     Buffer Size: 8970       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:16:49,257][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 5.849    Value Loss: 4.976    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 105675     Buffer Size: 8595       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:24:21,343][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 5.123    Value Loss: 4.660    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 107476     Buffer Size: 8302       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:31:47,195][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.463    [weighted Loss:3.463    Policy Loss: 5.982    Value Loss: 4.782    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 109268     Buffer Size: 8123       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:39:30,714][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.513    [weighted Loss:2.513    Policy Loss: 5.534    Value Loss: 4.871    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 111141     Buffer Size: 8018       Transition Number: 150.021 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:46:54,320][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.891    [weighted Loss:3.891    Policy Loss: 5.959    Value Loss: 5.186    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 112892     Buffer Size: 7937       Transition Number: 150.033 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:54:27,075][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 5.427    Value Loss: 4.948    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 114708     Buffer Size: 7961       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:02:01,136][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 5.878    Value Loss: 4.974    Reward Loss: 1.064    Consistency Loss: 0.000    ] Replay Episodes Collected: 116677     Buffer Size: 8052       Transition Number: 149.974 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:09:26,285][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.423    [weighted Loss:3.423    Policy Loss: 6.128    Value Loss: 5.046    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 118581     Buffer Size: 8158       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:17:02,191][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.292    [weighted Loss:3.292    Policy Loss: 6.717    Value Loss: 4.907    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 120538     Buffer Size: 8252       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:24:38,134][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 5.637    Value Loss: 5.032    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 122468     Buffer Size: 8329       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:31:54,833][train][INFO][train.py>_log] ==> #38000      Total Loss: 4.586    [weighted Loss:4.586    Policy Loss: 6.915    Value Loss: 5.181    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 124281     Buffer Size: 8329       Transition Number: 150.004 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:39:23,771][train][INFO][train.py>_log] ==> #39000      Total Loss: 4.158    [weighted Loss:4.158    Policy Loss: 5.556    Value Loss: 4.958    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 126129     Buffer Size: 8262       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:46:48,049][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.628    [weighted Loss:3.628    Policy Loss: 6.745    Value Loss: 5.033    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 127951     Buffer Size: 8227       Transition Number: 150.012 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:54:05,153][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.856    [weighted Loss:3.856    Policy Loss: 5.651    Value Loss: 5.230    Reward Loss: 1.196    Consistency Loss: 0.000    ] Replay Episodes Collected: 129805     Buffer Size: 8181       Transition Number: 150.221 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:01:41,881][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 5.565    Value Loss: 4.840    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 131806     Buffer Size: 8253       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:09:07,295][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.340    [weighted Loss:3.340    Policy Loss: 5.872    Value Loss: 5.051    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 133723     Buffer Size: 8301       Transition Number: 150.024 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:16:35,471][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 5.469    Value Loss: 5.227    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 135543     Buffer Size: 8274       Transition Number: 150.002 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:24:02,405][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 5.366    Value Loss: 4.845    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 137516     Buffer Size: 8351       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:31:30,464][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.194    [weighted Loss:4.194    Policy Loss: 5.693    Value Loss: 5.000    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 139492     Buffer Size: 8391       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:38:57,034][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.775    [weighted Loss:3.775    Policy Loss: 5.495    Value Loss: 5.481    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 141463     Buffer Size: 8421       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:46:04,145][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 5.519    Value Loss: 5.117    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 143379     Buffer Size: 8588       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:53:18,033][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 5.695    Value Loss: 5.092    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 145260     Buffer Size: 8603       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:00:42,513][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.437    [weighted Loss:2.437    Policy Loss: 5.395    Value Loss: 5.087    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 147156     Buffer Size: 8545       Transition Number: 150.099 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:08:04,731][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.540    [weighted Loss:3.540    Policy Loss: 5.085    Value Loss: 5.228    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 149115     Buffer Size: 8582       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:15:30,206][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.430    [weighted Loss:3.430    Policy Loss: 5.157    Value Loss: 5.121    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 151252     Buffer Size: 8679       Transition Number: 150.042 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:22:45,755][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 5.861    Value Loss: 5.414    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 153321     Buffer Size: 8824       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:29:56,600][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.427    [weighted Loss:3.427    Policy Loss: 5.163    Value Loss: 5.248    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 155194     Buffer Size: 8841       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:37:12,757][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.654    [weighted Loss:3.654    Policy Loss: 5.565    Value Loss: 5.464    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 157126     Buffer Size: 8856       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:44:29,898][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 5.643    Value Loss: 5.364    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 159179     Buffer Size: 8860       Transition Number: 150.001 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:51:43,250][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 5.479    Value Loss: 5.353    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 161143     Buffer Size: 8768       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:58:56,700][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.416    [weighted Loss:3.416    Policy Loss: 5.499    Value Loss: 5.473    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 163188     Buffer Size: 8845       Transition Number: 149.990 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:06:28,094][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 5.897    Value Loss: 5.452    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 165113     Buffer Size: 8740       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:13:41,167][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 5.706    Value Loss: 5.461    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 166936     Buffer Size: 8624       Transition Number: 150.033 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:21:09,733][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.709    [weighted Loss:3.709    Policy Loss: 6.036    Value Loss: 5.066    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 168816     Buffer Size: 8484       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:28:21,403][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 5.025    Value Loss: 5.005    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 170831     Buffer Size: 8524       Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:35:48,040][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 4.981    Value Loss: 5.399    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 172780     Buffer Size: 8519       Transition Number: 150.093 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:42:52,496][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.294    [weighted Loss:3.294    Policy Loss: 4.647    Value Loss: 5.253    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 174874     Buffer Size: 8804       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:50:06,455][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 5.008    Value Loss: 5.392    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 176879     Buffer Size: 8945       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:57:25,153][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.661    [weighted Loss:3.661    Policy Loss: 5.198    Value Loss: 5.331    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 178888     Buffer Size: 9045       Transition Number: 150.036 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:05:00,311][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 5.515    Value Loss: 5.722    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 180955     Buffer Size: 9017       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:12:30,044][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 5.316    Value Loss: 5.276    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 182994     Buffer Size: 8955       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:20:00,839][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 5.429    Value Loss: 5.442    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 185011     Buffer Size: 8834       Transition Number: 149.981 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:27:28,405][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.553    [weighted Loss:3.553    Policy Loss: 5.862    Value Loss: 5.264    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 186944     Buffer Size: 8704       Transition Number: 150.025 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:35:02,715][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 4.282    Value Loss: 5.143    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 189012     Buffer Size: 8646       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:42:23,737][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 4.817    Value Loss: 4.985    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 191175     Buffer Size: 8777       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:49:49,245][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 4.852    Value Loss: 5.223    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 193286     Buffer Size: 8853       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:57:14,617][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 5.458    Value Loss: 5.396    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 195427     Buffer Size: 9020       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:04:32,979][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.448    [weighted Loss:2.448    Policy Loss: 4.624    Value Loss: 5.115    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 197414     Buffer Size: 9081       Transition Number: 150.071 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:11:46,126][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 4.854    Value Loss: 5.093    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 199230     Buffer Size: 8935       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:19:11,245][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.355    [weighted Loss:2.355    Policy Loss: 4.805    Value Loss: 5.179    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 201175     Buffer Size: 8779       Transition Number: 150.020 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:26:17,535][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 4.582    Value Loss: 5.017    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 203141     Buffer Size: 8700       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:33:40,453][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.092    [weighted Loss:2.092    Policy Loss: 4.585    Value Loss: 5.216    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 205014     Buffer Size: 8557       Transition Number: 150.033 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:41:03,998][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.672    [weighted Loss:2.672    Policy Loss: 4.515    Value Loss: 5.129    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 207032     Buffer Size: 8584       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:48:20,361][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 4.486    Value Loss: 5.157    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 209413     Buffer Size: 9049       Transition Number: 150.024 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:55:37,462][train][INFO][train.py>_log] ==> #82000      Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 5.032    Value Loss: 5.003    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 211368     Buffer Size: 9062       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:03:00,089][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 4.927    Value Loss: 5.195    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 213483     Buffer Size: 9193       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:10:32,532][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 5.486    Value Loss: 5.360    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 215496     Buffer Size: 9172       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:17:53,526][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 4.698    Value Loss: 5.286    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 217945     Buffer Size: 9388       Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:25:08,380][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.095    [weighted Loss:3.095    Policy Loss: 4.706    Value Loss: 5.267    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 220250     Buffer Size: 9582       Transition Number: 150.029 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:32:22,483][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 4.646    Value Loss: 5.110    Reward Loss: 1.243    Consistency Loss: 0.000    ] Replay Episodes Collected: 222311     Buffer Size: 9620       Transition Number: 150.010 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:39:42,064][train][INFO][train.py>_log] ==> #88000      Total Loss: 0.743    [weighted Loss:0.743    Policy Loss: 4.295    Value Loss: 5.157    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 224294     Buffer Size: 9603       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:47:05,684][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.213    [weighted Loss:3.213    Policy Loss: 4.797    Value Loss: 5.038    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 226250     Buffer Size: 9287       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:54:16,232][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 4.450    Value Loss: 5.213    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 228431     Buffer Size: 9146       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:01:37,955][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 4.648    Value Loss: 5.161    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 230491     Buffer Size: 9035       Transition Number: 150.003 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:09:09,386][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 4.710    Value Loss: 5.184    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 232543     Buffer Size: 8990       Transition Number: 150.047 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:16:42,128][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 4.543    Value Loss: 5.412    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 234707     Buffer Size: 9128       Transition Number: 150.044 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:24:08,915][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.443    [weighted Loss:2.443    Policy Loss: 4.999    Value Loss: 5.502    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 236905     Buffer Size: 9139       Transition Number: 150.113 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:31:43,601][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 4.823    Value Loss: 5.267    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 239024     Buffer Size: 9105       Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:39:14,134][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 4.867    Value Loss: 5.164    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 241153     Buffer Size: 9134       Transition Number: 150.001 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:46:26,720][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 4.747    Value Loss: 5.285    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 243274     Buffer Size: 9297       Transition Number: 150.042 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:54:02,869][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 5.124    Value Loss: 5.244    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 245450     Buffer Size: 9179       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:01:26,606][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 4.453    Value Loss: 4.868    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 247654     Buffer Size: 9273       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:08:47,226][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 4.430    Value Loss: 5.000    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 249652     Buffer Size: 9208       Transition Number: 150.007 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:16:33,754][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 4.659    Value Loss: 5.383    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 251785     Buffer Size: 9034       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:24:07,558][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 4.170    Value Loss: 5.132    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 253810     Buffer Size: 8856       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:31:50,520][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.827    [weighted Loss:2.827    Policy Loss: 4.359    Value Loss: 5.148    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 255836     Buffer Size: 8607       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:39:28,170][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.940    [weighted Loss:2.940    Policy Loss: 4.525    Value Loss: 5.119    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 257971     Buffer Size: 8656       Transition Number: 150.012 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:47:10,060][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 4.411    Value Loss: 5.299    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 260539     Buffer Size: 9120       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:54:38,079][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 4.154    Value Loss: 5.014    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 262537     Buffer Size: 9098       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-31 04:01:50,607][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.105    [weighted Loss:3.105    Policy Loss: 4.098    Value Loss: 4.668    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 264937     Buffer Size: 9608       Transition Number: 150.041 k Batch Size: 256        Lr: 0.100   
[2021-10-31 04:09:22,612][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 4.582    Value Loss: 5.198    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 266948     Buffer Size: 9511       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-31 04:16:41,386][train][INFO][train.py>_log] ==> #109000     Total Loss: 1.930    [weighted Loss:1.930    Policy Loss: 4.380    Value Loss: 5.224    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 269033     Buffer Size: 9205       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
