[2021-10-30 11:01:40,626][train][INFO][train.py>_log] ==> #0          Total Loss: 33.416   [weighted Loss:33.416   Policy Loss: 7.859    Value Loss: 23.591   Reward Loss: 19.659   Consistency Loss: 0.000    ] Replay Episodes Collected: 679        Buffer Size: 679        Transition Number: 2.575   k Batch Size: 256        Lr: 0.000   
[2021-10-30 11:04:56,106][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.770    [weighted Loss:4.770    Policy Loss: 8.430    Value Loss: 4.076    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 5150       Buffer Size: 5150       Transition Number: 20.101  k Batch Size: 256        Lr: 0.010   
[2021-10-30 11:08:44,476][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.116    [weighted Loss:4.116    Policy Loss: 8.898    Value Loss: 3.360    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 10890      Buffer Size: 10890      Transition Number: 42.141  k Batch Size: 256        Lr: 0.020   
[2021-10-30 11:12:44,558][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.287    [weighted Loss:4.287    Policy Loss: 9.655    Value Loss: 3.297    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 14424      Buffer Size: 14424      Transition Number: 59.359  k Batch Size: 256        Lr: 0.030   
[2021-10-30 11:16:51,403][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 9.309    Value Loss: 2.739    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 18078      Buffer Size: 18078      Transition Number: 77.300  k Batch Size: 256        Lr: 0.040   
[2021-10-30 11:21:17,428][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 9.174    Value Loss: 2.578    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 21877      Buffer Size: 21877      Transition Number: 97.415  k Batch Size: 256        Lr: 0.050   
[2021-10-30 11:25:49,486][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 8.452    Value Loss: 2.571    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 25764      Buffer Size: 25764      Transition Number: 118.077 k Batch Size: 256        Lr: 0.060   
[2021-10-30 11:30:37,397][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 8.142    Value Loss: 2.318    Reward Loss: 0.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 29756      Buffer Size: 29756      Transition Number: 140.323 k Batch Size: 256        Lr: 0.070   
[2021-10-30 11:35:49,366][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 8.070    Value Loss: 2.560    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 34038      Buffer Size: 30271      Transition Number: 150.008 k Batch Size: 256        Lr: 0.080   
[2021-10-30 11:40:56,780][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.705    [weighted Loss:2.705    Policy Loss: 7.653    Value Loss: 2.473    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 38007      Buffer Size: 28123      Transition Number: 150.031 k Batch Size: 256        Lr: 0.090   
[2021-10-30 11:45:53,084][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.181    [weighted Loss:3.181    Policy Loss: 7.612    Value Loss: 2.524    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 42083      Buffer Size: 27113      Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-10-30 11:50:40,693][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.490    [weighted Loss:2.490    Policy Loss: 7.479    Value Loss: 2.558    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 46379      Buffer Size: 26786      Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 11:55:32,001][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 6.501    Value Loss: 2.620    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 49242      Buffer Size: 25707      Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:00:27,384][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 7.085    Value Loss: 2.512    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 53327      Buffer Size: 25398      Transition Number: 150.012 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:05:42,030][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 6.626    Value Loss: 3.028    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 56498      Buffer Size: 24245      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:11:07,304][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.171    [weighted Loss:4.171    Policy Loss: 7.393    Value Loss: 3.262    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 59542      Buffer Size: 23065      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:16:36,950][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 6.287    Value Loss: 3.089    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 62703      Buffer Size: 21891      Transition Number: 150.042 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:22:19,025][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.199    [weighted Loss:3.199    Policy Loss: 7.383    Value Loss: 3.566    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 65211      Buffer Size: 19665      Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:28:39,251][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.762    [weighted Loss:3.762    Policy Loss: 7.129    Value Loss: 3.802    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 68136      Buffer Size: 18225      Transition Number: 150.027 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:34:53,697][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.604    [weighted Loss:3.604    Policy Loss: 6.982    Value Loss: 3.912    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 70463      Buffer Size: 16164      Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:41:33,840][train][INFO][train.py>_log] ==> #20000      Total Loss: 3.713    [weighted Loss:3.713    Policy Loss: 7.427    Value Loss: 4.628    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 72601      Buffer Size: 14484      Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:48:36,574][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.790    [weighted Loss:3.790    Policy Loss: 6.969    Value Loss: 4.653    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 74930      Buffer Size: 12831      Transition Number: 150.077 k Batch Size: 256        Lr: 0.100   
[2021-10-30 12:55:40,437][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.997    [weighted Loss:2.997    Policy Loss: 6.736    Value Loss: 4.612    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 77108      Buffer Size: 11725      Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:02:46,208][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 7.367    Value Loss: 4.894    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 79252      Buffer Size: 10766      Transition Number: 150.040 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:10:06,432][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.656    [weighted Loss:3.656    Policy Loss: 6.581    Value Loss: 4.864    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 81253      Buffer Size: 10139      Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:17:55,194][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.975    [weighted Loss:3.975    Policy Loss: 7.243    Value Loss: 5.073    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 83177      Buffer Size: 9581       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:25:32,998][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.876    [weighted Loss:3.876    Policy Loss: 7.008    Value Loss: 4.992    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 85189      Buffer Size: 9219       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:33:26,585][train][INFO][train.py>_log] ==> #27000      Total Loss: 4.321    [weighted Loss:4.321    Policy Loss: 7.328    Value Loss: 4.832    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 87050      Buffer Size: 8653       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:40:54,230][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.926    [weighted Loss:3.926    Policy Loss: 6.970    Value Loss: 4.897    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 88783      Buffer Size: 8308       Transition Number: 150.043 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:48:52,194][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.995    [weighted Loss:3.995    Policy Loss: 6.289    Value Loss: 4.765    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 90623      Buffer Size: 8148       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-30 13:56:48,530][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 6.523    Value Loss: 4.767    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 92431      Buffer Size: 7927       Transition Number: 150.015 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:04:48,380][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 6.230    Value Loss: 5.010    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 94203      Buffer Size: 7805       Transition Number: 150.029 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:12:38,804][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.543    [weighted Loss:3.543    Policy Loss: 6.429    Value Loss: 4.837    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 96077      Buffer Size: 7830       Transition Number: 150.064 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:20:29,952][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.350    [weighted Loss:4.350    Policy Loss: 6.528    Value Loss: 4.873    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 97982      Buffer Size: 7860       Transition Number: 150.006 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:28:10,932][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 6.537    Value Loss: 4.834    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 99879      Buffer Size: 7986       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:35:50,210][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 6.676    Value Loss: 5.019    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 101656     Buffer Size: 7987       Transition Number: 150.072 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:43:36,605][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 6.231    Value Loss: 4.996    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 103486     Buffer Size: 8001       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:51:36,076][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.685    [weighted Loss:4.685    Policy Loss: 6.675    Value Loss: 4.696    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 105431     Buffer Size: 8018       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 14:59:27,033][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.008    [weighted Loss:3.008    Policy Loss: 6.698    Value Loss: 4.658    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 107297     Buffer Size: 7949       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:07:07,049][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.395    [weighted Loss:2.395    Policy Loss: 6.868    Value Loss: 5.102    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 109066     Buffer Size: 7960       Transition Number: 150.021 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:14:43,787][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.682    [weighted Loss:4.682    Policy Loss: 6.225    Value Loss: 5.382    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 110828     Buffer Size: 7971       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:22:21,865][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.422    [weighted Loss:4.422    Policy Loss: 6.811    Value Loss: 5.437    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 112593     Buffer Size: 7948       Transition Number: 149.973 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:30:09,016][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.662    [weighted Loss:3.662    Policy Loss: 6.503    Value Loss: 5.172    Reward Loss: 1.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 114482     Buffer Size: 7951       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:37:46,137][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 6.094    Value Loss: 4.981    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 116233     Buffer Size: 7934       Transition Number: 150.077 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:45:28,652][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.956    [weighted Loss:3.956    Policy Loss: 6.428    Value Loss: 5.064    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 118051     Buffer Size: 7923       Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-10-30 15:53:22,586][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.797    [weighted Loss:3.797    Policy Loss: 6.339    Value Loss: 5.437    Reward Loss: 1.259    Consistency Loss: 0.000    ] Replay Episodes Collected: 119963     Buffer Size: 7979       Transition Number: 150.130 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:01:13,857][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.104    [weighted Loss:3.104    Policy Loss: 6.243    Value Loss: 5.264    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 121875     Buffer Size: 7971       Transition Number: 150.041 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:09:06,911][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.887    [weighted Loss:3.887    Policy Loss: 6.073    Value Loss: 5.129    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 123773     Buffer Size: 7978       Transition Number: 150.007 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:16:59,971][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.145    [weighted Loss:3.145    Policy Loss: 6.157    Value Loss: 4.893    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 125785     Buffer Size: 8107       Transition Number: 150.120 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:24:49,445][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.610    [weighted Loss:3.610    Policy Loss: 5.775    Value Loss: 5.059    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 127721     Buffer Size: 8161       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:32:36,076][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 5.798    Value Loss: 4.885    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 129730     Buffer Size: 8260       Transition Number: 149.988 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:40:10,128][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.743    [weighted Loss:3.743    Policy Loss: 5.648    Value Loss: 5.231    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 131591     Buffer Size: 8353       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:47:48,442][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 5.156    Value Loss: 5.085    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 133418     Buffer Size: 8256       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 16:55:20,568][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 5.519    Value Loss: 5.111    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 135287     Buffer Size: 8234       Transition Number: 150.028 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:03:00,019][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.641    [weighted Loss:2.641    Policy Loss: 5.287    Value Loss: 4.804    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 137209     Buffer Size: 8201       Transition Number: 150.200 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:10:29,619][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 5.227    Value Loss: 5.100    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 139081     Buffer Size: 8169       Transition Number: 150.002 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:18:14,635][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.996    [weighted Loss:2.996    Policy Loss: 5.232    Value Loss: 4.902    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 141107     Buffer Size: 8293       Transition Number: 150.034 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:25:52,792][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.727    [weighted Loss:3.727    Policy Loss: 4.969    Value Loss: 5.044    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 143017     Buffer Size: 8333       Transition Number: 149.997 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:33:35,361][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 5.417    Value Loss: 5.192    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 144916     Buffer Size: 8328       Transition Number: 150.021 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:41:26,234][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 5.142    Value Loss: 5.202    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 146929     Buffer Size: 8365       Transition Number: 150.051 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:49:05,210][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 5.411    Value Loss: 5.397    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 148909     Buffer Size: 8350       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-30 17:56:40,152][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.458    [weighted Loss:3.458    Policy Loss: 5.048    Value Loss: 5.077    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 150792     Buffer Size: 8273       Transition Number: 150.103 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:04:15,375][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.955    [weighted Loss:2.955    Policy Loss: 5.380    Value Loss: 4.965    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 152715     Buffer Size: 8338       Transition Number: 149.975 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:11:57,042][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 5.160    Value Loss: 5.038    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 154654     Buffer Size: 8310       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:19:15,659][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 5.276    Value Loss: 5.152    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 156490     Buffer Size: 8343       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:27:01,615][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.543    [weighted Loss:3.543    Policy Loss: 4.846    Value Loss: 5.191    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 158440     Buffer Size: 8325       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:34:33,014][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.179    [weighted Loss:3.179    Policy Loss: 5.612    Value Loss: 4.985    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 160355     Buffer Size: 8369       Transition Number: 149.975 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:42:11,259][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.671    [weighted Loss:3.671    Policy Loss: 4.930    Value Loss: 5.162    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 162298     Buffer Size: 8340       Transition Number: 149.975 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:49:57,492][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 5.468    Value Loss: 5.163    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 164271     Buffer Size: 8362       Transition Number: 150.028 k Batch Size: 256        Lr: 0.100   
[2021-10-30 18:57:28,272][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 4.668    Value Loss: 5.045    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 166144     Buffer Size: 8345       Transition Number: 150.144 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:05:12,376][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 5.484    Value Loss: 4.777    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 168131     Buffer Size: 8339       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:12:49,352][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 4.792    Value Loss: 4.868    Reward Loss: 1.238    Consistency Loss: 0.000    ] Replay Episodes Collected: 170071     Buffer Size: 8377       Transition Number: 150.041 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:20:29,738][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 5.619    Value Loss: 5.258    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 171949     Buffer Size: 8275       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:28:09,964][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.758    [weighted Loss:2.758    Policy Loss: 4.681    Value Loss: 5.250    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 173868     Buffer Size: 8264       Transition Number: 149.984 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:35:53,807][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 4.703    Value Loss: 4.922    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 175811     Buffer Size: 8226       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:43:28,660][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 4.941    Value Loss: 5.235    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 177830     Buffer Size: 8247       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:50:59,675][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 5.173    Value Loss: 4.945    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 179707     Buffer Size: 8277       Transition Number: 150.022 k Batch Size: 256        Lr: 0.100   
[2021-10-30 19:58:33,309][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 5.100    Value Loss: 4.772    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 181600     Buffer Size: 8283       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:05:58,816][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 5.051    Value Loss: 5.189    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 183448     Buffer Size: 8284       Transition Number: 150.007 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:13:27,117][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 4.997    Value Loss: 4.886    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 185325     Buffer Size: 8247       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:21:11,964][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 4.861    Value Loss: 4.927    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 187448     Buffer Size: 8336       Transition Number: 149.979 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:28:46,750][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 5.146    Value Loss: 5.224    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 189329     Buffer Size: 8366       Transition Number: 150.018 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:36:21,439][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 5.204    Value Loss: 5.349    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 191187     Buffer Size: 8317       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:43:59,953][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 4.950    Value Loss: 5.045    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 193062     Buffer Size: 8289       Transition Number: 150.025 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:51:47,650][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.393    [weighted Loss:3.393    Policy Loss: 5.031    Value Loss: 4.678    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 195024     Buffer Size: 8163       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-30 20:59:25,653][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 4.710    Value Loss: 4.808    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 196855     Buffer Size: 8062       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:07:17,783][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 5.001    Value Loss: 4.919    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 198814     Buffer Size: 8067       Transition Number: 150.030 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:14:54,610][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 5.241    Value Loss: 5.138    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 200671     Buffer Size: 8064       Transition Number: 149.987 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:22:41,788][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 5.315    Value Loss: 5.259    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 202628     Buffer Size: 8073       Transition Number: 149.998 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:30:24,338][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 5.144    Value Loss: 4.985    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 204529     Buffer Size: 8119       Transition Number: 149.993 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:38:09,519][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 4.892    Value Loss: 5.272    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 206504     Buffer Size: 8189       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:45:53,448][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 5.055    Value Loss: 4.987    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 208526     Buffer Size: 8257       Transition Number: 149.983 k Batch Size: 256        Lr: 0.100   
[2021-10-30 21:53:29,975][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.492    [weighted Loss:2.492    Policy Loss: 4.973    Value Loss: 5.124    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 210532     Buffer Size: 8349       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:00:58,401][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.060    [weighted Loss:3.060    Policy Loss: 4.958    Value Loss: 4.930    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 212559     Buffer Size: 8492       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:08:32,475][train][INFO][train.py>_log] ==> #94000      Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 4.792    Value Loss: 5.403    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 214641     Buffer Size: 8638       Transition Number: 150.244 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:16:02,789][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 5.009    Value Loss: 5.384    Reward Loss: 1.147    Consistency Loss: 0.000    ] Replay Episodes Collected: 216597     Buffer Size: 8675       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:23:30,981][train][INFO][train.py>_log] ==> #96000      Total Loss: 1.776    [weighted Loss:1.776    Policy Loss: 4.304    Value Loss: 5.357    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 218572     Buffer Size: 8700       Transition Number: 149.972 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:31:04,837][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 5.297    Value Loss: 5.211    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 220541     Buffer Size: 8671       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:38:41,511][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 4.548    Value Loss: 5.074    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 222449     Buffer Size: 8546       Transition Number: 150.027 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:46:23,784][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 5.122    Value Loss: 5.116    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 224342     Buffer Size: 8423       Transition Number: 150.093 k Batch Size: 256        Lr: 0.100   
[2021-10-30 22:53:51,263][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 4.793    Value Loss: 4.993    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 226214     Buffer Size: 8367       Transition Number: 150.040 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:01:28,780][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 4.896    Value Loss: 4.964    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 228200     Buffer Size: 8333       Transition Number: 150.129 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:09:02,431][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.159    [weighted Loss:2.159    Policy Loss: 4.130    Value Loss: 4.889    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 230318     Buffer Size: 8486       Transition Number: 150.068 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:16:35,503][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.974    [weighted Loss:1.974    Policy Loss: 4.530    Value Loss: 4.958    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 232247     Buffer Size: 8528       Transition Number: 149.976 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:24:13,745][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 5.008    Value Loss: 5.248    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 234262     Buffer Size: 8595       Transition Number: 150.011 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:31:37,925][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 4.567    Value Loss: 5.277    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 236128     Buffer Size: 8579       Transition Number: 149.973 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:39:17,216][train][INFO][train.py>_log] ==> #106000     Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 4.705    Value Loss: 4.860    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 238057     Buffer Size: 8445       Transition Number: 149.982 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:46:48,901][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.621    [weighted Loss:2.621    Policy Loss: 4.287    Value Loss: 5.338    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 240100     Buffer Size: 8478       Transition Number: 149.995 k Batch Size: 256        Lr: 0.100   
[2021-10-30 23:54:27,830][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 4.722    Value Loss: 5.090    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 242050     Buffer Size: 8432       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:01:35,076][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.494    [weighted Loss:3.494    Policy Loss: 4.645    Value Loss: 5.374    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 244166     Buffer Size: 8697       Transition Number: 150.008 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:08:55,934][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 4.517    Value Loss: 5.198    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 246281     Buffer Size: 8909       Transition Number: 150.058 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:16:31,428][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.546    [weighted Loss:2.546    Policy Loss: 4.524    Value Loss: 5.244    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 248412     Buffer Size: 9002       Transition Number: 150.174 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:23:56,630][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.995    [weighted Loss:2.995    Policy Loss: 4.683    Value Loss: 5.125    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 250450     Buffer Size: 9106       Transition Number: 149.980 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:31:36,607][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 4.749    Value Loss: 5.191    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 252368     Buffer Size: 8921       Transition Number: 150.098 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:39:25,321][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.372    [weighted Loss:2.372    Policy Loss: 5.212    Value Loss: 5.347    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 254332     Buffer Size: 8658       Transition Number: 150.029 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:47:16,575][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 4.535    Value Loss: 5.137    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 256389     Buffer Size: 8529       Transition Number: 150.009 k Batch Size: 256        Lr: 0.100   
[2021-10-31 00:55:04,346][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 4.983    Value Loss: 5.122    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 258385     Buffer Size: 8390       Transition Number: 150.041 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:02:38,676][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 4.592    Value Loss: 5.072    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 260396     Buffer Size: 8474       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:10:12,548][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 5.007    Value Loss: 4.945    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 262337     Buffer Size: 8514       Transition Number: 149.996 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:17:40,065][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.142    [weighted Loss:3.142    Policy Loss: 5.587    Value Loss: 5.397    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 264199     Buffer Size: 8481       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:25:20,047][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 5.274    Value Loss: 5.330    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 266079     Buffer Size: 8462       Transition Number: 150.038 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:32:57,003][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.548    [weighted Loss:2.548    Policy Loss: 5.182    Value Loss: 5.142    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 268000     Buffer Size: 8369       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:40:20,001][train][INFO][train.py>_log] ==> #122000     Total Loss: 1.345    [weighted Loss:1.345    Policy Loss: 5.563    Value Loss: 4.956    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 270060     Buffer Size: 8485       Transition Number: 150.133 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:47:48,097][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 4.951    Value Loss: 5.219    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 271960     Buffer Size: 8493       Transition Number: 150.116 k Batch Size: 256        Lr: 0.100   
[2021-10-31 01:55:20,338][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 5.014    Value Loss: 4.996    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 273876     Buffer Size: 8511       Transition Number: 150.013 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:02:39,888][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 4.719    Value Loss: 5.006    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 275710     Buffer Size: 8501       Transition Number: 150.040 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:10:24,393][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.180    [weighted Loss:2.180    Policy Loss: 4.969    Value Loss: 4.857    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 277686     Buffer Size: 8369       Transition Number: 149.975 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:18:03,737][train][INFO][train.py>_log] ==> #127000     Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 5.021    Value Loss: 5.028    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 279699     Buffer Size: 8396       Transition Number: 149.985 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:25:38,391][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 4.890    Value Loss: 5.136    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 281705     Buffer Size: 8450       Transition Number: 150.026 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:32:58,537][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 4.929    Value Loss: 5.091    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 283942     Buffer Size: 8764       Transition Number: 150.010 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:40:29,996][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.248    [weighted Loss:3.248    Policy Loss: 5.307    Value Loss: 5.160    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 285912     Buffer Size: 8840       Transition Number: 150.066 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:48:07,852][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 4.860    Value Loss: 5.178    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 287990     Buffer Size: 8869       Transition Number: 150.056 k Batch Size: 256        Lr: 0.100   
[2021-10-31 02:55:36,766][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.238    [weighted Loss:3.238    Policy Loss: 5.827    Value Loss: 5.035    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 289899     Buffer Size: 8824       Transition Number: 149.991 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:03:14,349][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.763    [weighted Loss:2.763    Policy Loss: 5.251    Value Loss: 5.208    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 292035     Buffer Size: 8694       Transition Number: 150.080 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:10:19,516][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 5.588    Value Loss: 5.124    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 293913     Buffer Size: 8666       Transition Number: 150.146 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:18:04,144][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 5.152    Value Loss: 5.264    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 295969     Buffer Size: 8615       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:25:48,836][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 5.335    Value Loss: 5.227    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 298062     Buffer Size: 8675       Transition Number: 150.055 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:33:17,374][train][INFO][train.py>_log] ==> #137000     Total Loss: 1.409    [weighted Loss:1.409    Policy Loss: 4.453    Value Loss: 5.082    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 300022     Buffer Size: 8609       Transition Number: 149.992 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:41:04,689][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 5.523    Value Loss: 5.318    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 302056     Buffer Size: 8571       Transition Number: 149.977 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:48:45,522][train][INFO][train.py>_log] ==> #139000     Total Loss: 1.829    [weighted Loss:1.829    Policy Loss: 4.978    Value Loss: 5.081    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 304079     Buffer Size: 8561       Transition Number: 149.994 k Batch Size: 256        Lr: 0.100   
[2021-10-31 03:56:21,842][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.772    [weighted Loss:2.772    Policy Loss: 5.583    Value Loss: 5.073    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 306136     Buffer Size: 8549       Transition Number: 150.000 k Batch Size: 256        Lr: 0.100   
[2021-10-31 04:03:55,096][train][INFO][train.py>_log] ==> #141000     Total Loss: 3.002    [weighted Loss:3.002    Policy Loss: 5.110    Value Loss: 4.977    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 308115     Buffer Size: 8525       Transition Number: 149.989 k Batch Size: 256        Lr: 0.100   
[2021-10-31 04:11:43,020][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 5.760    Value Loss: 5.254    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 310211     Buffer Size: 8564       Transition Number: 149.999 k Batch Size: 256        Lr: 0.100   
[2021-10-31 04:19:09,850][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.848    [weighted Loss:3.848    Policy Loss: 4.993    Value Loss: 5.014    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 312120     Buffer Size: 8542       Transition Number: 149.986 k Batch Size: 256        Lr: 0.100   
