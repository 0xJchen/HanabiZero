[2021-11-03 08:59:43,153][train][INFO][train.py>_log] ==> #0          Total Loss: 44.836   [weighted Loss:44.836   Policy Loss: 14.839   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 44         Buffer Size: 44         Transition Number: 0.567   k Batch Size: 128        Lr: 0.000   
[2021-11-03 09:05:45,930][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.949    [weighted Loss:5.949    Policy Loss: 14.092   Value Loss: 4.764    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 437        Buffer Size: 437        Transition Number: 5.426   k Batch Size: 128        Lr: 0.010   
[2021-11-03 09:12:09,448][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.841    [weighted Loss:7.841    Policy Loss: 12.574   Value Loss: 3.357    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 881        Buffer Size: 881        Transition Number: 9.880   k Batch Size: 128        Lr: 0.020   
[2021-11-03 09:18:37,754][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.654    [weighted Loss:4.654    Policy Loss: 12.521   Value Loss: 3.431    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 1455       Buffer Size: 1455       Transition Number: 14.370  k Batch Size: 128        Lr: 0.030   
[2021-11-03 09:25:02,259][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.948    [weighted Loss:4.948    Policy Loss: 12.664   Value Loss: 2.938    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1895       Buffer Size: 1895       Transition Number: 18.759  k Batch Size: 128        Lr: 0.040   
[2021-11-03 09:31:26,713][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.511    [weighted Loss:4.511    Policy Loss: 12.520   Value Loss: 2.599    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 2268       Buffer Size: 2268       Transition Number: 23.142  k Batch Size: 128        Lr: 0.050   
[2021-11-03 09:37:55,534][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.349    [weighted Loss:4.349    Policy Loss: 12.011   Value Loss: 2.790    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 2574       Buffer Size: 2574       Transition Number: 27.479  k Batch Size: 128        Lr: 0.060   
[2021-11-03 09:44:22,627][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.966    [weighted Loss:3.966    Policy Loss: 12.076   Value Loss: 2.901    Reward Loss: 0.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 2972       Buffer Size: 2972       Transition Number: 31.593  k Batch Size: 128        Lr: 0.070   
[2021-11-03 09:50:53,231][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.845    [weighted Loss:4.845    Policy Loss: 11.627   Value Loss: 2.901    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 3358       Buffer Size: 3358       Transition Number: 35.906  k Batch Size: 128        Lr: 0.080   
[2021-11-03 09:57:21,888][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.760    [weighted Loss:5.760    Policy Loss: 11.794   Value Loss: 2.699    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 3801       Buffer Size: 3801       Transition Number: 40.451  k Batch Size: 128        Lr: 0.090   
[2021-11-03 10:03:52,405][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.177    [weighted Loss:4.177    Policy Loss: 13.433   Value Loss: 2.670    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 4129       Buffer Size: 4129       Transition Number: 44.753  k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:10:19,969][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 13.549   Value Loss: 2.740    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 4435       Buffer Size: 4435       Transition Number: 48.838  k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:16:49,103][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.448    [weighted Loss:4.448    Policy Loss: 12.342   Value Loss: 2.278    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 4775       Buffer Size: 4775       Transition Number: 53.347  k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:23:14,220][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.418    [weighted Loss:5.418    Policy Loss: 13.592   Value Loss: 2.572    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 5073       Buffer Size: 5073       Transition Number: 57.299  k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:29:41,219][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 12.789   Value Loss: 2.443    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 5462       Buffer Size: 5462       Transition Number: 61.689  k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:36:04,102][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.869    [weighted Loss:5.869    Policy Loss: 13.918   Value Loss: 2.647    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 5872       Buffer Size: 5872       Transition Number: 65.920  k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:42:30,556][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.122    [weighted Loss:3.122    Policy Loss: 12.066   Value Loss: 2.905    Reward Loss: 0.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 6283       Buffer Size: 6283       Transition Number: 70.249  k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:48:56,658][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.768    [weighted Loss:2.768    Policy Loss: 11.672   Value Loss: 2.755    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 6689       Buffer Size: 6689       Transition Number: 74.618  k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:55:23,460][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.730    [weighted Loss:4.730    Policy Loss: 12.800   Value Loss: 2.569    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 7178       Buffer Size: 7178       Transition Number: 79.118  k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:01:47,883][train][INFO][train.py>_log] ==> #19000      Total Loss: 5.571    [weighted Loss:5.571    Policy Loss: 13.086   Value Loss: 2.621    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 7674       Buffer Size: 7674       Transition Number: 83.476  k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:08:15,941][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.734    [weighted Loss:5.734    Policy Loss: 12.761   Value Loss: 2.711    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 7975       Buffer Size: 7975       Transition Number: 87.659  k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:14:42,171][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.901    [weighted Loss:4.901    Policy Loss: 13.733   Value Loss: 3.355    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 8272       Buffer Size: 8272       Transition Number: 91.681  k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:21:11,775][train][INFO][train.py>_log] ==> #22000      Total Loss: 6.372    [weighted Loss:6.372    Policy Loss: 12.658   Value Loss: 2.454    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 8615       Buffer Size: 8615       Transition Number: 96.139  k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:27:36,106][train][INFO][train.py>_log] ==> #23000      Total Loss: 5.641    [weighted Loss:5.641    Policy Loss: 13.320   Value Loss: 2.539    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 8953       Buffer Size: 8953       Transition Number: 100.248 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:34:05,511][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.375    [weighted Loss:5.375    Policy Loss: 13.185   Value Loss: 2.672    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 9285       Buffer Size: 9285       Transition Number: 104.572 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:40:35,505][train][INFO][train.py>_log] ==> #25000      Total Loss: 7.231    [weighted Loss:7.231    Policy Loss: 12.903   Value Loss: 2.793    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 9614       Buffer Size: 9614       Transition Number: 108.843 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:47:00,081][train][INFO][train.py>_log] ==> #26000      Total Loss: 6.164    [weighted Loss:6.164    Policy Loss: 12.227   Value Loss: 2.641    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 9952       Buffer Size: 9952       Transition Number: 113.089 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:53:31,558][train][INFO][train.py>_log] ==> #27000      Total Loss: 5.053    [weighted Loss:5.053    Policy Loss: 13.386   Value Loss: 2.425    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 10255      Buffer Size: 10255      Transition Number: 117.377 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:00:00,190][train][INFO][train.py>_log] ==> #28000      Total Loss: 6.072    [weighted Loss:6.072    Policy Loss: 12.898   Value Loss: 2.684    Reward Loss: 0.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 10565      Buffer Size: 10565      Transition Number: 121.507 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:06:25,898][train][INFO][train.py>_log] ==> #29000      Total Loss: 5.332    [weighted Loss:5.332    Policy Loss: 13.597   Value Loss: 2.632    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 10866      Buffer Size: 10866      Transition Number: 125.500 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:12:57,423][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 12.643   Value Loss: 2.947    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 11146      Buffer Size: 11146      Transition Number: 129.696 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:19:31,093][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.146    [weighted Loss:4.146    Policy Loss: 12.938   Value Loss: 2.741    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 11338      Buffer Size: 11338      Transition Number: 133.114 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:25:58,709][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.146    [weighted Loss:4.146    Policy Loss: 13.001   Value Loss: 2.717    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 11542      Buffer Size: 11542      Transition Number: 137.089 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:32:27,375][train][INFO][train.py>_log] ==> #33000      Total Loss: 7.539    [weighted Loss:7.539    Policy Loss: 12.919   Value Loss: 2.622    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 11647      Buffer Size: 11647      Transition Number: 139.744 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:38:59,607][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.676    [weighted Loss:4.676    Policy Loss: 11.635   Value Loss: 2.951    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 11834      Buffer Size: 11834      Transition Number: 143.813 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:45:31,196][train][INFO][train.py>_log] ==> #35000      Total Loss: 5.340    [weighted Loss:5.340    Policy Loss: 12.119   Value Loss: 2.930    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 11973      Buffer Size: 11973      Transition Number: 146.963 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:52:03,536][train][INFO][train.py>_log] ==> #36000      Total Loss: 5.033    [weighted Loss:5.033    Policy Loss: 11.622   Value Loss: 2.865    Reward Loss: 0.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 12129      Buffer Size: 12129      Transition Number: 150.160 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:58:39,319][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 11.845   Value Loss: 2.720    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 12321      Buffer Size: 12321      Transition Number: 153.727 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:05:16,391][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.705    [weighted Loss:3.705    Policy Loss: 11.979   Value Loss: 3.048    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 12545      Buffer Size: 12545      Transition Number: 157.703 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:11:54,789][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 9.091    Value Loss: 2.999    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 12709      Buffer Size: 12709      Transition Number: 161.029 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:18:42,989][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.768    [weighted Loss:2.768    Policy Loss: 9.115    Value Loss: 3.087    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 12832      Buffer Size: 12832      Transition Number: 164.445 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:25:20,293][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.994    [weighted Loss:2.994    Policy Loss: 10.383   Value Loss: 2.927    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 12986      Buffer Size: 12986      Transition Number: 167.745 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:32:01,440][train][INFO][train.py>_log] ==> #42000      Total Loss: 5.007    [weighted Loss:5.007    Policy Loss: 9.613    Value Loss: 3.227    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 13137      Buffer Size: 13137      Transition Number: 170.995 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:38:50,645][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.111    [weighted Loss:3.111    Policy Loss: 6.911    Value Loss: 3.056    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 13237      Buffer Size: 13237      Transition Number: 174.169 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:45:35,712][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.824    [weighted Loss:2.824    Policy Loss: 8.631    Value Loss: 2.986    Reward Loss: 0.952    Consistency Loss: 0.000    ] Replay Episodes Collected: 13483      Buffer Size: 13483      Transition Number: 178.423 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:52:29,044][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 9.230    Value Loss: 3.154    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 13658      Buffer Size: 13658      Transition Number: 182.232 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:01:53,316][train][INFO][train.py>_log] ==> #46000      Total Loss: 5.630    [weighted Loss:5.630    Policy Loss: 11.448   Value Loss: 3.051    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 13944      Buffer Size: 13944      Transition Number: 188.349 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:09:05,093][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.997    [weighted Loss:1.997    Policy Loss: 5.115    Value Loss: 3.657    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 14102      Buffer Size: 14102      Transition Number: 191.857 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:16:25,352][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 6.077    Value Loss: 3.260    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 14301      Buffer Size: 14301      Transition Number: 196.280 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:24:10,293][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 5.171    Value Loss: 3.443    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 14527      Buffer Size: 14494      Transition Number: 199.982 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:31:43,528][train][INFO][train.py>_log] ==> #50000      Total Loss: 4.138    [weighted Loss:4.138    Policy Loss: 7.101    Value Loss: 3.531    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 14705      Buffer Size: 14329      Transition Number: 199.993 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:39:01,519][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 6.109    Value Loss: 3.038    Reward Loss: 0.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 14884      Buffer Size: 14138      Transition Number: 200.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:46:27,680][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.843    [weighted Loss:2.843    Policy Loss: 4.467    Value Loss: 3.382    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 15032      Buffer Size: 13792      Transition Number: 199.997 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:53:46,783][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.249    [weighted Loss:1.249    Policy Loss: 4.242    Value Loss: 3.519    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 15251      Buffer Size: 13590      Transition Number: 200.006 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:01:10,790][train][INFO][train.py>_log] ==> #54000      Total Loss: 1.525    [weighted Loss:1.525    Policy Loss: 2.972    Value Loss: 3.310    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 15448      Buffer Size: 13399      Transition Number: 200.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:08:52,578][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.244    [weighted Loss:1.244    Policy Loss: 1.771    Value Loss: 3.290    Reward Loss: 0.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 15640      Buffer Size: 13269      Transition Number: 200.005 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:16:17,906][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.382    [weighted Loss:1.382    Policy Loss: 4.044    Value Loss: 3.450    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 16072      Buffer Size: 13280      Transition Number: 199.992 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:23:47,339][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 3.339    Value Loss: 3.365    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 16343      Buffer Size: 13168      Transition Number: 199.990 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:31:20,920][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.376    [weighted Loss:1.376    Policy Loss: 2.758    Value Loss: 3.552    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 16466      Buffer Size: 12905      Transition Number: 199.992 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:41:42,493][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.903    [weighted Loss:2.903    Policy Loss: 5.375    Value Loss: 3.610    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 17079      Buffer Size: 12986      Transition Number: 200.001 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:49:02,130][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.775    [weighted Loss:1.775    Policy Loss: 2.114    Value Loss: 3.617    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 17456      Buffer Size: 13073      Transition Number: 199.997 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:56:21,777][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.114    [weighted Loss:3.114    Policy Loss: 6.848    Value Loss: 3.424    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 17649      Buffer Size: 12982      Transition Number: 200.019 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:03:23,070][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 6.472    Value Loss: 3.915    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 17836      Buffer Size: 12884      Transition Number: 199.998 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:10:43,604][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.228    [weighted Loss:2.228    Policy Loss: 4.558    Value Loss: 3.751    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 18071      Buffer Size: 12827      Transition Number: 199.998 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:17:57,485][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 2.284    Value Loss: 3.490    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 18940      Buffer Size: 13173      Transition Number: 199.994 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:25:14,974][train][INFO][train.py>_log] ==> #65000      Total Loss: 1.060    [weighted Loss:1.060    Policy Loss: 3.012    Value Loss: 3.556    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 19763      Buffer Size: 13580      Transition Number: 200.009 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:32:34,238][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 2.875    Value Loss: 3.474    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 20732      Buffer Size: 14077      Transition Number: 200.007 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:39:53,756][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 2.061    Value Loss: 3.616    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 21174      Buffer Size: 14142      Transition Number: 199.995 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:47:24,288][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.908    [weighted Loss:2.908    Policy Loss: 3.958    Value Loss: 3.689    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 21720      Buffer Size: 14148      Transition Number: 199.996 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:54:47,433][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 2.349    Value Loss: 3.521    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 22427      Buffer Size: 14484      Transition Number: 199.998 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:01:54,464][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 2.519    Value Loss: 3.710    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 22972      Buffer Size: 14722      Transition Number: 199.994 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:09:10,105][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 5.348    Value Loss: 3.614    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 23411      Buffer Size: 14847      Transition Number: 199.979 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:16:34,355][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 3.879    Value Loss: 3.552    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 23700      Buffer Size: 14810      Transition Number: 199.993 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:23:46,960][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 4.012    Value Loss: 3.492    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 23986      Buffer Size: 14834      Transition Number: 199.987 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:40:10,800][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.739    [weighted Loss:3.739    Policy Loss: 7.257    Value Loss: 3.638    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 24667      Buffer Size: 14609      Transition Number: 199.999 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:47:17,989][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 7.415    Value Loss: 3.717    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 25031      Buffer Size: 14674      Transition Number: 200.001 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:57:42,914][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.146    [weighted Loss:4.146    Policy Loss: 7.278    Value Loss: 3.801    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 25587      Buffer Size: 14768      Transition Number: 200.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:04:49,801][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 3.773    Value Loss: 3.513    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 25862      Buffer Size: 14812      Transition Number: 199.993 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:12:00,805][train][INFO][train.py>_log] ==> #78000      Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 6.563    Value Loss: 3.727    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 26207      Buffer Size: 14933      Transition Number: 199.999 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:22:28,187][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.705    [weighted Loss:2.705    Policy Loss: 5.136    Value Loss: 3.866    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 27396      Buffer Size: 15740      Transition Number: 199.994 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:35:50,411][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 4.321    Value Loss: 3.907    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 28536      Buffer Size: 16432      Transition Number: 199.991 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:42:50,827][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 7.771    Value Loss: 3.912    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 28828      Buffer Size: 16511      Transition Number: 199.992 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:11:01,702][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 8.390    Value Loss: 3.870    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 31749      Buffer Size: 16418      Transition Number: 200.112 k Batch Size: 128        Lr: 0.100   
[2021-11-03 23:14:03,620][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.805    [weighted Loss:3.805    Policy Loss: 7.788    Value Loss: 3.833    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 37949      Buffer Size: 9000       Transition Number: 200.035 k Batch Size: 128        Lr: 0.100   
