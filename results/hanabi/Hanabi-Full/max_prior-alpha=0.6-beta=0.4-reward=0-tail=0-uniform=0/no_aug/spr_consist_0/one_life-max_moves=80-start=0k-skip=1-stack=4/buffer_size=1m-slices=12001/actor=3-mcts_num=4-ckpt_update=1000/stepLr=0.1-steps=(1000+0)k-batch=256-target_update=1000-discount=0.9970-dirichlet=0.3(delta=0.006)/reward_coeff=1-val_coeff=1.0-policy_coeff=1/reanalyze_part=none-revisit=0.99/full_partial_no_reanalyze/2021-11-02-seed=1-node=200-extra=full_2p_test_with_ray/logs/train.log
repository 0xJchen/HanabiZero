[2021-11-02 04:13:03,160][train][INFO][train.py>_log] ==> #0          Total Loss: 64.538   [weighted Loss:64.538   Policy Loss: 13.774   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 37         Buffer Size: 37         Transition Number: 0.388   k Batch Size: 256        Lr: 0.000   
[2021-11-02 04:15:25,316][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.843    [weighted Loss:5.843    Policy Loss: 14.326   Value Loss: 2.604    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 209        Buffer Size: 209        Transition Number: 2.515   k Batch Size: 256        Lr: 0.010   
[2021-11-02 04:19:04,543][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.722    [weighted Loss:7.722    Policy Loss: 13.991   Value Loss: 2.634    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 529        Buffer Size: 529        Transition Number: 5.865   k Batch Size: 256        Lr: 0.020   
[2021-11-02 04:23:28,558][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 13.315   Value Loss: 3.007    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 915        Buffer Size: 915        Transition Number: 9.729   k Batch Size: 256        Lr: 0.030   
[2021-11-02 04:28:15,897][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 12.091   Value Loss: 2.474    Reward Loss: 0.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 1309       Buffer Size: 1309       Transition Number: 13.806  k Batch Size: 256        Lr: 0.040   
[2021-11-02 04:33:23,410][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.861    [weighted Loss:5.861    Policy Loss: 11.202   Value Loss: 2.713    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 1801       Buffer Size: 1801       Transition Number: 18.285  k Batch Size: 256        Lr: 0.050   
[2021-11-02 04:38:35,048][train][INFO][train.py>_log] ==> #6000       Total Loss: 1.192    [weighted Loss:1.192    Policy Loss: 10.748   Value Loss: 2.603    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 2297       Buffer Size: 2297       Transition Number: 22.865  k Batch Size: 256        Lr: 0.060   
[2021-11-02 04:43:56,973][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.449    [weighted Loss:3.449    Policy Loss: 10.842   Value Loss: 2.278    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2788       Buffer Size: 2788       Transition Number: 27.615  k Batch Size: 256        Lr: 0.070   
[2021-11-02 04:49:22,638][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.418    [weighted Loss:4.418    Policy Loss: 10.296   Value Loss: 2.628    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 3287       Buffer Size: 3287       Transition Number: 32.382  k Batch Size: 256        Lr: 0.080   
[2021-11-02 04:55:08,997][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.695    [weighted Loss:2.695    Policy Loss: 9.961    Value Loss: 2.423    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 3902       Buffer Size: 3902       Transition Number: 37.608  k Batch Size: 256        Lr: 0.090   
[2021-11-02 05:00:48,582][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 10.417   Value Loss: 2.377    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 4437       Buffer Size: 4437       Transition Number: 42.496  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:06:28,838][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.547    [weighted Loss:3.547    Policy Loss: 10.993   Value Loss: 2.565    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 4837       Buffer Size: 4837       Transition Number: 47.339  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:12:15,852][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.932    [weighted Loss:4.932    Policy Loss: 11.199   Value Loss: 2.523    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 5286       Buffer Size: 5286       Transition Number: 52.178  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:18:05,002][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.119    [weighted Loss:4.119    Policy Loss: 10.870   Value Loss: 2.362    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 5772       Buffer Size: 5772       Transition Number: 57.251  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:23:54,128][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 10.440   Value Loss: 2.495    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 6292       Buffer Size: 6292       Transition Number: 62.266  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:29:48,142][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 10.349   Value Loss: 2.518    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 6840       Buffer Size: 6840       Transition Number: 67.213  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:35:53,399][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.193    [weighted Loss:4.193    Policy Loss: 11.358   Value Loss: 2.658    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 7267       Buffer Size: 7267       Transition Number: 72.310  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:42:13,840][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.031    [weighted Loss:4.031    Policy Loss: 10.381   Value Loss: 2.478    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 7807       Buffer Size: 7807       Transition Number: 77.631  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:48:13,845][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.328    [weighted Loss:4.328    Policy Loss: 10.859   Value Loss: 2.437    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 8530       Buffer Size: 8530       Transition Number: 82.858  k Batch Size: 256        Lr: 0.100   
[2021-11-02 05:54:13,809][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.683    [weighted Loss:2.683    Policy Loss: 11.089   Value Loss: 2.402    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 9082       Buffer Size: 9082       Transition Number: 87.921  k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:00:20,715][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.126    [weighted Loss:5.126    Policy Loss: 11.384   Value Loss: 2.376    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 9476       Buffer Size: 9476       Transition Number: 92.939  k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:06:27,558][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.475    [weighted Loss:4.475    Policy Loss: 10.949   Value Loss: 2.539    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 10029      Buffer Size: 10029      Transition Number: 98.333  k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:12:32,574][train][INFO][train.py>_log] ==> #22000      Total Loss: 5.549    [weighted Loss:5.549    Policy Loss: 11.181   Value Loss: 2.616    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 10511      Buffer Size: 10511      Transition Number: 103.469 k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:18:41,355][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.084    [weighted Loss:4.084    Policy Loss: 11.595   Value Loss: 2.616    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 11028      Buffer Size: 11028      Transition Number: 108.727 k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:24:45,515][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.862    [weighted Loss:4.862    Policy Loss: 11.677   Value Loss: 2.640    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 11488      Buffer Size: 11488      Transition Number: 113.821 k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:30:59,721][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 11.299   Value Loss: 2.461    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 11988      Buffer Size: 11988      Transition Number: 119.030 k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:37:10,127][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 11.022   Value Loss: 2.577    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 12623      Buffer Size: 12623      Transition Number: 124.460 k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:43:25,405][train][INFO][train.py>_log] ==> #27000      Total Loss: 4.965    [weighted Loss:4.965    Policy Loss: 11.407   Value Loss: 2.454    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 13105      Buffer Size: 13105      Transition Number: 129.802 k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:49:46,322][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.520    [weighted Loss:3.520    Policy Loss: 11.248   Value Loss: 2.429    Reward Loss: 0.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 13476      Buffer Size: 13476      Transition Number: 135.041 k Batch Size: 256        Lr: 0.100   
[2021-11-02 06:56:09,414][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.402    [weighted Loss:4.402    Policy Loss: 11.477   Value Loss: 2.681    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 13992      Buffer Size: 13992      Transition Number: 140.618 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:02:36,277][train][INFO][train.py>_log] ==> #30000      Total Loss: 6.055    [weighted Loss:6.055    Policy Loss: 11.866   Value Loss: 2.531    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 14557      Buffer Size: 14557      Transition Number: 146.178 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:08:57,594][train][INFO][train.py>_log] ==> #31000      Total Loss: 5.248    [weighted Loss:5.248    Policy Loss: 11.740   Value Loss: 2.540    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 15108      Buffer Size: 15108      Transition Number: 151.830 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:15:17,626][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 11.104   Value Loss: 2.434    Reward Loss: 0.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 15527      Buffer Size: 15527      Transition Number: 157.157 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:21:39,271][train][INFO][train.py>_log] ==> #33000      Total Loss: 5.250    [weighted Loss:5.250    Policy Loss: 11.322   Value Loss: 2.554    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 16071      Buffer Size: 16071      Transition Number: 162.689 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:28:03,238][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 10.909   Value Loss: 2.586    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 16722      Buffer Size: 16722      Transition Number: 168.304 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:34:27,156][train][INFO][train.py>_log] ==> #35000      Total Loss: 4.667    [weighted Loss:4.667    Policy Loss: 11.421   Value Loss: 2.294    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 17225      Buffer Size: 17225      Transition Number: 173.685 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:40:50,409][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 11.265   Value Loss: 2.515    Reward Loss: 0.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 17716      Buffer Size: 17716      Transition Number: 179.143 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:47:17,587][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.405    [weighted Loss:4.405    Policy Loss: 11.010   Value Loss: 2.457    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 18348      Buffer Size: 18348      Transition Number: 184.712 k Batch Size: 256        Lr: 0.100   
[2021-11-02 07:53:46,745][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 11.271   Value Loss: 2.586    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 18878      Buffer Size: 18878      Transition Number: 190.131 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:00:16,281][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.595    [weighted Loss:2.595    Policy Loss: 11.146   Value Loss: 2.448    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 19422      Buffer Size: 19422      Transition Number: 195.647 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:06:51,108][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.147    [weighted Loss:4.147    Policy Loss: 11.422   Value Loss: 2.509    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 19899      Buffer Size: 19899      Transition Number: 201.217 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:13:42,451][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.721    [weighted Loss:4.721    Policy Loss: 11.087   Value Loss: 2.544    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 20486      Buffer Size: 20486      Transition Number: 207.020 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:20:14,196][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.811    [weighted Loss:2.811    Policy Loss: 11.831   Value Loss: 2.703    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 21003      Buffer Size: 21003      Transition Number: 212.643 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:26:42,985][train][INFO][train.py>_log] ==> #43000      Total Loss: 4.463    [weighted Loss:4.463    Policy Loss: 10.937   Value Loss: 2.556    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 21553      Buffer Size: 21553      Transition Number: 218.304 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:33:03,915][train][INFO][train.py>_log] ==> #44000      Total Loss: 4.738    [weighted Loss:4.738    Policy Loss: 11.075   Value Loss: 2.527    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 22057      Buffer Size: 22057      Transition Number: 223.792 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:39:25,076][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.458    [weighted Loss:4.458    Policy Loss: 10.621   Value Loss: 2.362    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 22641      Buffer Size: 22641      Transition Number: 229.332 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:45:51,746][train][INFO][train.py>_log] ==> #46000      Total Loss: 6.005    [weighted Loss:6.005    Policy Loss: 11.371   Value Loss: 2.617    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 23115      Buffer Size: 23115      Transition Number: 234.848 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:52:15,180][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.481    [weighted Loss:4.481    Policy Loss: 11.027   Value Loss: 2.463    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 23653      Buffer Size: 23653      Transition Number: 240.462 k Batch Size: 256        Lr: 0.100   
[2021-11-02 08:58:37,523][train][INFO][train.py>_log] ==> #48000      Total Loss: 5.631    [weighted Loss:5.631    Policy Loss: 10.607   Value Loss: 2.432    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 24187      Buffer Size: 24187      Transition Number: 245.916 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:05:03,113][train][INFO][train.py>_log] ==> #49000      Total Loss: 4.658    [weighted Loss:4.658    Policy Loss: 11.358   Value Loss: 2.500    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 24643      Buffer Size: 24643      Transition Number: 251.308 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:11:32,530][train][INFO][train.py>_log] ==> #50000      Total Loss: 4.380    [weighted Loss:4.380    Policy Loss: 11.345   Value Loss: 2.493    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 25114      Buffer Size: 25114      Transition Number: 256.846 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:17:46,100][train][INFO][train.py>_log] ==> #51000      Total Loss: 4.629    [weighted Loss:4.629    Policy Loss: 10.646   Value Loss: 2.449    Reward Loss: 0.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 25651      Buffer Size: 25651      Transition Number: 262.337 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:24:08,786][train][INFO][train.py>_log] ==> #52000      Total Loss: 4.995    [weighted Loss:4.995    Policy Loss: 11.240   Value Loss: 2.474    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 26262      Buffer Size: 26262      Transition Number: 267.926 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:30:34,715][train][INFO][train.py>_log] ==> #53000      Total Loss: 6.386    [weighted Loss:6.386    Policy Loss: 11.109   Value Loss: 2.502    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 26838      Buffer Size: 26838      Transition Number: 273.426 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:37:09,085][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 11.377   Value Loss: 2.651    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 27228      Buffer Size: 27228      Transition Number: 278.864 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:43:47,823][train][INFO][train.py>_log] ==> #55000      Total Loss: 5.155    [weighted Loss:5.155    Policy Loss: 11.007   Value Loss: 2.444    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 27746      Buffer Size: 27746      Transition Number: 284.580 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:50:27,248][train][INFO][train.py>_log] ==> #56000      Total Loss: 4.924    [weighted Loss:4.924    Policy Loss: 11.695   Value Loss: 2.672    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 28291      Buffer Size: 28291      Transition Number: 290.396 k Batch Size: 256        Lr: 0.100   
[2021-11-02 09:57:05,523][train][INFO][train.py>_log] ==> #57000      Total Loss: 5.379    [weighted Loss:5.379    Policy Loss: 11.211   Value Loss: 2.605    Reward Loss: 1.026    Consistency Loss: 0.000    ] Replay Episodes Collected: 28706      Buffer Size: 28706      Transition Number: 295.959 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:03:49,471][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 10.982   Value Loss: 2.583    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 29275      Buffer Size: 29275      Transition Number: 301.769 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:10:35,327][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 10.781   Value Loss: 2.547    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 29808      Buffer Size: 29808      Transition Number: 307.605 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:17:18,781][train][INFO][train.py>_log] ==> #60000      Total Loss: 5.870    [weighted Loss:5.870    Policy Loss: 11.536   Value Loss: 2.647    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 30305      Buffer Size: 30305      Transition Number: 313.366 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:24:02,919][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.350    [weighted Loss:4.350    Policy Loss: 11.350   Value Loss: 2.404    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 30943      Buffer Size: 30943      Transition Number: 319.309 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:30:44,650][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.338    [weighted Loss:3.338    Policy Loss: 11.228   Value Loss: 2.499    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 31432      Buffer Size: 31432      Transition Number: 324.958 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:37:29,990][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 11.537   Value Loss: 2.628    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 31929      Buffer Size: 31929      Transition Number: 330.783 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:44:15,725][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.960    [weighted Loss:3.960    Policy Loss: 10.619   Value Loss: 2.479    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 32457      Buffer Size: 32457      Transition Number: 336.620 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:51:12,112][train][INFO][train.py>_log] ==> #65000      Total Loss: 5.066    [weighted Loss:5.066    Policy Loss: 12.051   Value Loss: 2.822    Reward Loss: 1.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 32985      Buffer Size: 32985      Transition Number: 342.694 k Batch Size: 256        Lr: 0.100   
[2021-11-02 10:58:01,410][train][INFO][train.py>_log] ==> #66000      Total Loss: 5.031    [weighted Loss:5.031    Policy Loss: 11.119   Value Loss: 2.792    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 33485      Buffer Size: 33485      Transition Number: 348.534 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:04:42,814][train][INFO][train.py>_log] ==> #67000      Total Loss: 5.925    [weighted Loss:5.925    Policy Loss: 12.317   Value Loss: 2.703    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 33937      Buffer Size: 33937      Transition Number: 354.127 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:11:24,574][train][INFO][train.py>_log] ==> #68000      Total Loss: 5.194    [weighted Loss:5.194    Policy Loss: 11.477   Value Loss: 2.536    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 34374      Buffer Size: 34374      Transition Number: 359.594 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:18:05,499][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 11.453   Value Loss: 2.759    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 34861      Buffer Size: 34861      Transition Number: 365.047 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:24:51,821][train][INFO][train.py>_log] ==> #70000      Total Loss: 5.230    [weighted Loss:5.230    Policy Loss: 12.091   Value Loss: 2.616    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 35391      Buffer Size: 35391      Transition Number: 370.757 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:31:39,400][train][INFO][train.py>_log] ==> #71000      Total Loss: 4.153    [weighted Loss:4.153    Policy Loss: 12.019   Value Loss: 2.623    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 35800      Buffer Size: 35800      Transition Number: 376.264 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:38:26,162][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.756    [weighted Loss:3.756    Policy Loss: 10.699   Value Loss: 2.596    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 36368      Buffer Size: 36368      Transition Number: 382.004 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:45:15,428][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.539    [weighted Loss:3.539    Policy Loss: 11.854   Value Loss: 2.588    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 36811      Buffer Size: 36811      Transition Number: 387.558 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:52:12,862][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 12.088   Value Loss: 2.801    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 37330      Buffer Size: 37330      Transition Number: 393.652 k Batch Size: 256        Lr: 0.100   
[2021-11-02 11:59:05,929][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.703    [weighted Loss:4.703    Policy Loss: 12.186   Value Loss: 2.527    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 37833      Buffer Size: 37833      Transition Number: 399.418 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:05:58,648][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.520    [weighted Loss:4.520    Policy Loss: 11.929   Value Loss: 2.722    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 38314      Buffer Size: 38314      Transition Number: 405.345 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:12:48,888][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.570    [weighted Loss:3.570    Policy Loss: 12.379   Value Loss: 2.732    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 38832      Buffer Size: 38832      Transition Number: 411.233 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:19:38,793][train][INFO][train.py>_log] ==> #78000      Total Loss: 3.641    [weighted Loss:3.641    Policy Loss: 12.303   Value Loss: 2.753    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 39573      Buffer Size: 39573      Transition Number: 417.244 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:26:29,028][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.315    [weighted Loss:4.315    Policy Loss: 12.204   Value Loss: 2.800    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 40023      Buffer Size: 40023      Transition Number: 422.944 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:33:19,737][train][INFO][train.py>_log] ==> #80000      Total Loss: 4.304    [weighted Loss:4.304    Policy Loss: 11.944   Value Loss: 2.543    Reward Loss: 0.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 40553      Buffer Size: 40553      Transition Number: 428.790 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:40:10,680][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.913    [weighted Loss:4.913    Policy Loss: 12.476   Value Loss: 2.527    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 41068      Buffer Size: 41068      Transition Number: 434.784 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:47:02,693][train][INFO][train.py>_log] ==> #82000      Total Loss: 6.127    [weighted Loss:6.127    Policy Loss: 12.131   Value Loss: 2.822    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 41648      Buffer Size: 41648      Transition Number: 440.837 k Batch Size: 256        Lr: 0.100   
[2021-11-02 12:54:02,368][train][INFO][train.py>_log] ==> #83000      Total Loss: 6.352    [weighted Loss:6.352    Policy Loss: 12.190   Value Loss: 2.808    Reward Loss: 1.000    Consistency Loss: 0.000    ] Replay Episodes Collected: 42126      Buffer Size: 42126      Transition Number: 446.586 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:00:56,886][train][INFO][train.py>_log] ==> #84000      Total Loss: 5.869    [weighted Loss:5.869    Policy Loss: 12.153   Value Loss: 2.783    Reward Loss: 0.992    Consistency Loss: 0.000    ] Replay Episodes Collected: 42552      Buffer Size: 42552      Transition Number: 452.147 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:07:57,496][train][INFO][train.py>_log] ==> #85000      Total Loss: 5.034    [weighted Loss:5.034    Policy Loss: 12.414   Value Loss: 2.851    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 42993      Buffer Size: 42993      Transition Number: 457.914 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:14:59,825][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.902    [weighted Loss:4.902    Policy Loss: 12.806   Value Loss: 2.917    Reward Loss: 1.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 43377      Buffer Size: 43377      Transition Number: 463.475 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:22:01,694][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.597    [weighted Loss:3.597    Policy Loss: 11.871   Value Loss: 2.741    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 43740      Buffer Size: 43740      Transition Number: 469.200 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:28:57,997][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.597    [weighted Loss:4.597    Policy Loss: 12.172   Value Loss: 2.693    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 44177      Buffer Size: 44177      Transition Number: 475.085 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:36:07,293][train][INFO][train.py>_log] ==> #89000      Total Loss: 6.695    [weighted Loss:6.695    Policy Loss: 11.903   Value Loss: 2.554    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 44695      Buffer Size: 44695      Transition Number: 481.099 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:43:34,857][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 12.398   Value Loss: 2.670    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 45118      Buffer Size: 45118      Transition Number: 487.253 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:50:52,898][train][INFO][train.py>_log] ==> #91000      Total Loss: 5.172    [weighted Loss:5.172    Policy Loss: 12.142   Value Loss: 2.701    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 45609      Buffer Size: 45609      Transition Number: 493.430 k Batch Size: 256        Lr: 0.100   
[2021-11-02 13:58:01,653][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.402    [weighted Loss:3.402    Policy Loss: 12.228   Value Loss: 2.650    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 46114      Buffer Size: 46114      Transition Number: 499.537 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:05:27,663][train][INFO][train.py>_log] ==> #93000      Total Loss: 4.694    [weighted Loss:4.694    Policy Loss: 11.678   Value Loss: 2.669    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 46621      Buffer Size: 46102      Transition Number: 499.993 k Batch Size: 256        Lr: 0.100   
[2021-11-02 14:12:50,490][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.541    [weighted Loss:4.541    Policy Loss: 12.484   Value Loss: 2.826    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 47091      Buffer Size: 45963      Transition Number: 499.994 k Batch Size: 256        Lr: 0.100   
