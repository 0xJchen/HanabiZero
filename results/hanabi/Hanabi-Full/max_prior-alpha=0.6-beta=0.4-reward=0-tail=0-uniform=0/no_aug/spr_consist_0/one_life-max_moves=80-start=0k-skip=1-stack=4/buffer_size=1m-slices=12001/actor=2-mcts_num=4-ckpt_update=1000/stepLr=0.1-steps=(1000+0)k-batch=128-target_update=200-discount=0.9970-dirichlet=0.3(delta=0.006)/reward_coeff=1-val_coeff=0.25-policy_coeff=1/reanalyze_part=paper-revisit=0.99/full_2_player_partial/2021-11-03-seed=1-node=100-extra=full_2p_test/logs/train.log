[2021-11-03 15:50:45,406][train][INFO][train.py>_log] ==> #0          Total Loss: 44.743   [weighted Loss:44.743   Policy Loss: 14.745   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 36         Buffer Size: 36         Transition Number: 0.439   k Batch Size: 128        Lr: 0.000   
[2021-11-03 15:54:48,307][train][INFO][train.py>_log] ==> #1000       Total Loss: 9.068    [weighted Loss:9.068    Policy Loss: 13.326   Value Loss: 4.375    Reward Loss: 1.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 325        Buffer Size: 325        Transition Number: 4.003   k Batch Size: 128        Lr: 0.010   
[2021-11-03 15:59:03,010][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.299    [weighted Loss:6.299    Policy Loss: 13.318   Value Loss: 3.309    Reward Loss: 0.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 637        Buffer Size: 637        Transition Number: 7.462   k Batch Size: 128        Lr: 0.020   
[2021-11-03 16:03:18,713][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.121    [weighted Loss:5.121    Policy Loss: 11.329   Value Loss: 2.818    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 896        Buffer Size: 896        Transition Number: 10.655  k Batch Size: 128        Lr: 0.030   
[2021-11-03 16:07:37,639][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.851    [weighted Loss:4.851    Policy Loss: 10.679   Value Loss: 2.648    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 1264       Buffer Size: 1264       Transition Number: 14.044  k Batch Size: 128        Lr: 0.040   
[2021-11-03 16:11:57,087][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.655    [weighted Loss:4.655    Policy Loss: 12.785   Value Loss: 2.676    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1602       Buffer Size: 1602       Transition Number: 17.298  k Batch Size: 128        Lr: 0.050   
[2021-11-03 16:16:15,450][train][INFO][train.py>_log] ==> #6000       Total Loss: 6.824    [weighted Loss:6.824    Policy Loss: 11.925   Value Loss: 2.329    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1908       Buffer Size: 1908       Transition Number: 20.585  k Batch Size: 128        Lr: 0.060   
[2021-11-03 16:20:36,072][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.679    [weighted Loss:4.679    Policy Loss: 12.811   Value Loss: 2.501    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 2241       Buffer Size: 2241       Transition Number: 23.895  k Batch Size: 128        Lr: 0.070   
[2021-11-03 16:24:54,728][train][INFO][train.py>_log] ==> #8000       Total Loss: 6.194    [weighted Loss:6.194    Policy Loss: 13.361   Value Loss: 2.788    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 2604       Buffer Size: 2604       Transition Number: 27.175  k Batch Size: 128        Lr: 0.080   
[2021-11-03 16:29:12,907][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.917    [weighted Loss:5.917    Policy Loss: 12.381   Value Loss: 2.978    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 2934       Buffer Size: 2934       Transition Number: 30.438  k Batch Size: 128        Lr: 0.090   
[2021-11-03 16:33:32,252][train][INFO][train.py>_log] ==> #10000      Total Loss: 6.389    [weighted Loss:6.389    Policy Loss: 13.055   Value Loss: 2.794    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 3234       Buffer Size: 3234       Transition Number: 33.714  k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:37:52,508][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.665    [weighted Loss:3.665    Policy Loss: 10.460   Value Loss: 2.584    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 3499       Buffer Size: 3499       Transition Number: 36.961  k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:42:13,475][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 12.561   Value Loss: 2.665    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 3826       Buffer Size: 3826       Transition Number: 40.317  k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:46:33,740][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.787    [weighted Loss:5.787    Policy Loss: 11.671   Value Loss: 2.903    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 4174       Buffer Size: 4174       Transition Number: 43.663  k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:50:54,289][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.110    [weighted Loss:4.110    Policy Loss: 12.564   Value Loss: 2.662    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 4508       Buffer Size: 4508       Transition Number: 46.987  k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:55:15,198][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.051    [weighted Loss:3.051    Policy Loss: 12.431   Value Loss: 2.319    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 4847       Buffer Size: 4847       Transition Number: 50.239  k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:59:41,000][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.730    [weighted Loss:4.730    Policy Loss: 13.015   Value Loss: 2.711    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 5267       Buffer Size: 5267       Transition Number: 53.694  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:04:02,918][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 12.111   Value Loss: 2.678    Reward Loss: 0.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 5669       Buffer Size: 5669       Transition Number: 57.038  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:08:20,281][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.373    [weighted Loss:4.373    Policy Loss: 12.854   Value Loss: 2.948    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 6082       Buffer Size: 6082       Transition Number: 60.373  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:12:41,513][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.665    [weighted Loss:4.665    Policy Loss: 12.113   Value Loss: 2.620    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 6435       Buffer Size: 6435       Transition Number: 63.707  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:17:04,244][train][INFO][train.py>_log] ==> #20000      Total Loss: 7.038    [weighted Loss:7.038    Policy Loss: 12.006   Value Loss: 2.536    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 6764       Buffer Size: 6764       Transition Number: 67.103  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:21:26,754][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.713    [weighted Loss:3.713    Policy Loss: 11.542   Value Loss: 2.347    Reward Loss: 0.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 7060       Buffer Size: 7060       Transition Number: 70.320  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:25:49,483][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.599    [weighted Loss:4.599    Policy Loss: 12.332   Value Loss: 2.471    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 7379       Buffer Size: 7379       Transition Number: 73.648  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:30:10,105][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.948    [weighted Loss:3.948    Policy Loss: 12.496   Value Loss: 2.250    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 7745       Buffer Size: 7745       Transition Number: 76.901  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:34:34,568][train][INFO][train.py>_log] ==> #24000      Total Loss: 6.191    [weighted Loss:6.191    Policy Loss: 12.260   Value Loss: 2.537    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 8029       Buffer Size: 8029       Transition Number: 80.250  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:38:57,466][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.921    [weighted Loss:4.921    Policy Loss: 12.659   Value Loss: 2.463    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 8325       Buffer Size: 8325       Transition Number: 83.432  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:43:15,480][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.423    [weighted Loss:3.423    Policy Loss: 12.651   Value Loss: 2.434    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 8630       Buffer Size: 8630       Transition Number: 86.709  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:47:35,682][train][INFO][train.py>_log] ==> #27000      Total Loss: 5.480    [weighted Loss:5.480    Policy Loss: 12.868   Value Loss: 2.888    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 8927       Buffer Size: 8927       Transition Number: 89.932  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:51:55,982][train][INFO][train.py>_log] ==> #28000      Total Loss: 6.967    [weighted Loss:6.967    Policy Loss: 12.587   Value Loss: 2.570    Reward Loss: 1.025    Consistency Loss: 0.000    ] Replay Episodes Collected: 9228       Buffer Size: 9228       Transition Number: 93.102  k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:56:19,775][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.059    [weighted Loss:4.059    Policy Loss: 11.462   Value Loss: 2.762    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 9502       Buffer Size: 9502       Transition Number: 96.434  k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:00:45,155][train][INFO][train.py>_log] ==> #30000      Total Loss: 6.313    [weighted Loss:6.313    Policy Loss: 12.660   Value Loss: 2.723    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 9816       Buffer Size: 9816       Transition Number: 99.796  k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:05:11,082][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.856    [weighted Loss:4.856    Policy Loss: 12.922   Value Loss: 2.827    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 10120      Buffer Size: 10120      Transition Number: 103.076 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:09:40,902][train][INFO][train.py>_log] ==> #32000      Total Loss: 5.990    [weighted Loss:5.990    Policy Loss: 12.486   Value Loss: 2.770    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 10430      Buffer Size: 10430      Transition Number: 106.555 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:14:12,019][train][INFO][train.py>_log] ==> #33000      Total Loss: 6.210    [weighted Loss:6.210    Policy Loss: 12.193   Value Loss: 2.747    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 10728      Buffer Size: 10728      Transition Number: 109.992 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:18:41,327][train][INFO][train.py>_log] ==> #34000      Total Loss: 5.493    [weighted Loss:5.493    Policy Loss: 13.420   Value Loss: 2.964    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 11015      Buffer Size: 11015      Transition Number: 113.548 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:23:05,209][train][INFO][train.py>_log] ==> #35000      Total Loss: 5.249    [weighted Loss:5.249    Policy Loss: 11.790   Value Loss: 2.658    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 11279      Buffer Size: 11279      Transition Number: 116.736 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:27:31,361][train][INFO][train.py>_log] ==> #36000      Total Loss: 4.736    [weighted Loss:4.736    Policy Loss: 11.750   Value Loss: 2.674    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 11565      Buffer Size: 11565      Transition Number: 120.024 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:31:58,899][train][INFO][train.py>_log] ==> #37000      Total Loss: 5.643    [weighted Loss:5.643    Policy Loss: 11.458   Value Loss: 2.844    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 11871      Buffer Size: 11871      Transition Number: 123.479 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:36:23,833][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.874    [weighted Loss:3.874    Policy Loss: 13.108   Value Loss: 3.086    Reward Loss: 1.252    Consistency Loss: 0.000    ] Replay Episodes Collected: 12179      Buffer Size: 12179      Transition Number: 126.873 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:40:51,755][train][INFO][train.py>_log] ==> #39000      Total Loss: 5.281    [weighted Loss:5.281    Policy Loss: 11.501   Value Loss: 3.304    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 12449      Buffer Size: 12449      Transition Number: 130.152 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:45:21,398][train][INFO][train.py>_log] ==> #40000      Total Loss: 4.403    [weighted Loss:4.403    Policy Loss: 11.453   Value Loss: 2.942    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 12765      Buffer Size: 12765      Transition Number: 133.637 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:49:49,669][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.738    [weighted Loss:4.738    Policy Loss: 11.829   Value Loss: 2.655    Reward Loss: 1.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 13068      Buffer Size: 13068      Transition Number: 137.024 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:54:21,524][train][INFO][train.py>_log] ==> #42000      Total Loss: 4.140    [weighted Loss:4.140    Policy Loss: 12.734   Value Loss: 2.822    Reward Loss: 0.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 13274      Buffer Size: 13274      Transition Number: 140.180 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:58:48,469][train][INFO][train.py>_log] ==> #43000      Total Loss: 5.092    [weighted Loss:5.092    Policy Loss: 11.210   Value Loss: 2.763    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 13453      Buffer Size: 13453      Transition Number: 143.164 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:03:16,792][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 13.134   Value Loss: 3.260    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 13710      Buffer Size: 13710      Transition Number: 146.464 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:07:47,115][train][INFO][train.py>_log] ==> #45000      Total Loss: 5.025    [weighted Loss:5.025    Policy Loss: 12.054   Value Loss: 2.804    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 13918      Buffer Size: 13918      Transition Number: 149.253 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:12:19,241][train][INFO][train.py>_log] ==> #46000      Total Loss: 5.410    [weighted Loss:5.410    Policy Loss: 12.040   Value Loss: 2.969    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 14133      Buffer Size: 13947      Transition Number: 150.017 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:16:50,599][train][INFO][train.py>_log] ==> #47000      Total Loss: 5.497    [weighted Loss:5.497    Policy Loss: 13.063   Value Loss: 3.067    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 14372      Buffer Size: 13926      Transition Number: 150.002 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:21:28,908][train][INFO][train.py>_log] ==> #48000      Total Loss: 7.150    [weighted Loss:7.150    Policy Loss: 12.521   Value Loss: 2.827    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 14601      Buffer Size: 13862      Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:25:57,884][train][INFO][train.py>_log] ==> #49000      Total Loss: 4.822    [weighted Loss:4.822    Policy Loss: 11.326   Value Loss: 2.811    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 14741      Buffer Size: 13774      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:30:30,729][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.970    [weighted Loss:3.970    Policy Loss: 12.101   Value Loss: 2.922    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 14912      Buffer Size: 13612      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:35:07,927][train][INFO][train.py>_log] ==> #51000      Total Loss: 6.318    [weighted Loss:6.318    Policy Loss: 11.775   Value Loss: 3.368    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 15092      Buffer Size: 13508      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:39:43,266][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 11.766   Value Loss: 2.831    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 15331      Buffer Size: 13437      Transition Number: 150.022 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:44:21,147][train][INFO][train.py>_log] ==> #53000      Total Loss: 5.616    [weighted Loss:5.616    Policy Loss: 12.629   Value Loss: 3.277    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 15564      Buffer Size: 13365      Transition Number: 150.020 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:48:58,917][train][INFO][train.py>_log] ==> #54000      Total Loss: 5.547    [weighted Loss:5.547    Policy Loss: 11.241   Value Loss: 3.094    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 15776      Buffer Size: 13218      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:54:51,065][train][INFO][train.py>_log] ==> #55000      Total Loss: 5.637    [weighted Loss:5.637    Policy Loss: 10.651   Value Loss: 3.035    Reward Loss: 1.313    Consistency Loss: 0.000    ] Replay Episodes Collected: 16138      Buffer Size: 13148      Transition Number: 150.006 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:00:18,051][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.675    [weighted Loss:3.675    Policy Loss: 11.843   Value Loss: 2.956    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 16487      Buffer Size: 13135      Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:09:39,982][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.382    [weighted Loss:4.382    Policy Loss: 12.283   Value Loss: 2.957    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 17124      Buffer Size: 12973      Transition Number: 150.007 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:23:00,016][train][INFO][train.py>_log] ==> #58000      Total Loss: 6.690    [weighted Loss:6.690    Policy Loss: 12.157   Value Loss: 3.044    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 18105      Buffer Size: 12599      Transition Number: 150.001 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:50:30,366][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 11.539   Value Loss: 3.330    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 19851      Buffer Size: 11809      Transition Number: 150.028 k Batch Size: 128        Lr: 0.100   
[2021-11-03 21:22:07,814][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.119    [weighted Loss:2.119    Policy Loss: 10.854   Value Loss: 3.482    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 21952      Buffer Size: 11332      Transition Number: 150.013 k Batch Size: 128        Lr: 0.100   
[2021-11-03 21:53:39,773][train][INFO][train.py>_log] ==> #61000      Total Loss: 6.207    [weighted Loss:6.207    Policy Loss: 13.050   Value Loss: 3.058    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 24327      Buffer Size: 11166      Transition Number: 150.033 k Batch Size: 128        Lr: 0.100   
[2021-11-03 22:23:08,250][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.973    [weighted Loss:4.973    Policy Loss: 12.755   Value Loss: 3.245    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 26400      Buffer Size: 11394      Transition Number: 150.002 k Batch Size: 128        Lr: 0.100   
[2021-11-03 22:49:16,720][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.497    [weighted Loss:4.497    Policy Loss: 13.587   Value Loss: 3.350    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 28034      Buffer Size: 11296      Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-03 23:35:12,125][train][INFO][train.py>_log] ==> #64000      Total Loss: 6.055    [weighted Loss:6.055    Policy Loss: 13.033   Value Loss: 3.258    Reward Loss: 1.221    Consistency Loss: 0.000    ] Replay Episodes Collected: 30599      Buffer Size: 10910      Transition Number: 150.038 k Batch Size: 128        Lr: 0.100   
[2021-11-04 00:36:41,488][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.348    [weighted Loss:3.348    Policy Loss: 13.127   Value Loss: 3.642    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 33555      Buffer Size: 10070      Transition Number: 150.121 k Batch Size: 128        Lr: 0.100   
