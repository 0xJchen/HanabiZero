[2021-10-31 17:31:25,995][train][INFO][train.py>_log] ==> #0          Total Loss: 43.713   [weighted Loss:43.713   Policy Loss: 13.715   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 39         Buffer Size: 39         Transition Number: 0.384   k Batch Size: 128        Lr: 0.000   
[2021-10-31 17:41:08,077][train][INFO][train.py>_log] ==> #1000       Total Loss: 8.174    [weighted Loss:8.174    Policy Loss: 14.347   Value Loss: 4.792    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 696        Buffer Size: 696        Transition Number: 8.363   k Batch Size: 128        Lr: 0.010   
[2021-10-31 17:50:54,107][train][INFO][train.py>_log] ==> #2000       Total Loss: 9.158    [weighted Loss:9.158    Policy Loss: 14.792   Value Loss: 3.615    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 1396       Buffer Size: 1396       Transition Number: 16.609  k Batch Size: 128        Lr: 0.020   
[2021-10-31 18:01:10,225][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.947    [weighted Loss:6.947    Policy Loss: 14.118   Value Loss: 3.704    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 2250       Buffer Size: 2250       Transition Number: 24.172  k Batch Size: 128        Lr: 0.030   
[2021-10-31 18:11:40,040][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.237    [weighted Loss:6.237    Policy Loss: 14.888   Value Loss: 3.660    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 2867       Buffer Size: 2867       Transition Number: 31.473  k Batch Size: 128        Lr: 0.040   
[2021-10-31 18:22:08,616][train][INFO][train.py>_log] ==> #5000       Total Loss: 7.053    [weighted Loss:7.053    Policy Loss: 14.507   Value Loss: 3.372    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 3466       Buffer Size: 3466       Transition Number: 38.628  k Batch Size: 128        Lr: 0.050   
[2021-10-31 18:32:35,049][train][INFO][train.py>_log] ==> #6000       Total Loss: 6.238    [weighted Loss:6.238    Policy Loss: 13.536   Value Loss: 3.354    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 4012       Buffer Size: 4012       Transition Number: 45.653  k Batch Size: 128        Lr: 0.060   
[2021-10-31 18:43:01,082][train][INFO][train.py>_log] ==> #7000       Total Loss: 7.105    [weighted Loss:7.105    Policy Loss: 14.499   Value Loss: 3.050    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 4805       Buffer Size: 4805       Transition Number: 52.849  k Batch Size: 128        Lr: 0.070   
[2021-10-31 18:53:26,979][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.350    [weighted Loss:5.350    Policy Loss: 13.956   Value Loss: 3.007    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 5643       Buffer Size: 5643       Transition Number: 60.221  k Batch Size: 128        Lr: 0.080   
[2021-10-31 19:03:56,699][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.612    [weighted Loss:5.612    Policy Loss: 14.325   Value Loss: 3.056    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 6107       Buffer Size: 6107       Transition Number: 67.052  k Batch Size: 128        Lr: 0.090   
[2021-10-31 19:14:28,035][train][INFO][train.py>_log] ==> #10000      Total Loss: 7.416    [weighted Loss:7.416    Policy Loss: 14.491   Value Loss: 2.901    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 6721       Buffer Size: 6721       Transition Number: 74.464  k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:24:59,536][train][INFO][train.py>_log] ==> #11000      Total Loss: 7.125    [weighted Loss:7.125    Policy Loss: 13.788   Value Loss: 2.757    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 7342       Buffer Size: 7342       Transition Number: 81.616  k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:35:25,692][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.027    [weighted Loss:6.027    Policy Loss: 14.059   Value Loss: 2.593    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 7864       Buffer Size: 7864       Transition Number: 88.467  k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:45:54,836][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 13.871   Value Loss: 3.012    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 8399       Buffer Size: 8399       Transition Number: 95.275  k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:56:23,858][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.205    [weighted Loss:5.205    Policy Loss: 13.565   Value Loss: 2.808    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 9117       Buffer Size: 9117       Transition Number: 102.429 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:06:59,304][train][INFO][train.py>_log] ==> #15000      Total Loss: 6.968    [weighted Loss:6.968    Policy Loss: 14.236   Value Loss: 2.853    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 9847       Buffer Size: 9847       Transition Number: 109.682 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:17:25,839][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.787    [weighted Loss:4.787    Policy Loss: 13.173   Value Loss: 2.789    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 10584      Buffer Size: 10584      Transition Number: 116.692 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:27:49,036][train][INFO][train.py>_log] ==> #17000      Total Loss: 6.151    [weighted Loss:6.151    Policy Loss: 13.756   Value Loss: 3.038    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 11298      Buffer Size: 11298      Transition Number: 123.859 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:38:15,760][train][INFO][train.py>_log] ==> #18000      Total Loss: 7.355    [weighted Loss:7.355    Policy Loss: 13.666   Value Loss: 3.026    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 11786      Buffer Size: 11786      Transition Number: 129.918 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:48:44,529][train][INFO][train.py>_log] ==> #19000      Total Loss: 7.438    [weighted Loss:7.438    Policy Loss: 14.152   Value Loss: 3.094    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 12317      Buffer Size: 12317      Transition Number: 136.377 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:59:16,431][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.873    [weighted Loss:5.873    Policy Loss: 13.309   Value Loss: 2.995    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 12741      Buffer Size: 12741      Transition Number: 142.538 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:09:46,618][train][INFO][train.py>_log] ==> #21000      Total Loss: 7.694    [weighted Loss:7.694    Policy Loss: 13.975   Value Loss: 2.891    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 13167      Buffer Size: 13167      Transition Number: 148.818 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:20:23,830][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.291    [weighted Loss:4.291    Policy Loss: 12.342   Value Loss: 2.871    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 13583      Buffer Size: 13220      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:31:08,366][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.538    [weighted Loss:4.538    Policy Loss: 13.599   Value Loss: 3.222    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 14027      Buffer Size: 13209      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:41:48,044][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.075    [weighted Loss:4.075    Policy Loss: 12.797   Value Loss: 3.066    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 14428      Buffer Size: 13137      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:52:36,061][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.039    [weighted Loss:4.039    Policy Loss: 10.725   Value Loss: 2.993    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 14761      Buffer Size: 12879      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:03:20,932][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.695    [weighted Loss:5.695    Policy Loss: 11.847   Value Loss: 3.209    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 15137      Buffer Size: 12728      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:14:19,354][train][INFO][train.py>_log] ==> #27000      Total Loss: 4.935    [weighted Loss:4.935    Policy Loss: 10.488   Value Loss: 3.470    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 15656      Buffer Size: 12776      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:25:17,740][train][INFO][train.py>_log] ==> #28000      Total Loss: 5.110    [weighted Loss:5.110    Policy Loss: 12.286   Value Loss: 3.077    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 16157      Buffer Size: 12745      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:36:16,868][train][INFO][train.py>_log] ==> #29000      Total Loss: 5.695    [weighted Loss:5.695    Policy Loss: 12.884   Value Loss: 3.065    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 16641      Buffer Size: 12824      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:47:20,532][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.859    [weighted Loss:2.859    Policy Loss: 9.826    Value Loss: 3.202    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 17022      Buffer Size: 12700      Transition Number: 150.011 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:58:23,699][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.563    [weighted Loss:3.563    Policy Loss: 9.449    Value Loss: 3.172    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 17337      Buffer Size: 12403      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:10:23,395][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.928    [weighted Loss:3.928    Policy Loss: 9.261    Value Loss: 3.200    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 17766      Buffer Size: 12154      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:21:54,251][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 5.920    Value Loss: 3.305    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 18126      Buffer Size: 12129      Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:33:25,529][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.903    [weighted Loss:2.903    Policy Loss: 6.942    Value Loss: 3.249    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 18753      Buffer Size: 12245      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:45:29,348][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 5.502    Value Loss: 3.559    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 19146      Buffer Size: 12084      Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:56:45,900][train][INFO][train.py>_log] ==> #36000      Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 9.949    Value Loss: 3.459    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 19709      Buffer Size: 12178      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:08:16,167][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.592    [weighted Loss:3.592    Policy Loss: 8.148    Value Loss: 3.068    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 20201      Buffer Size: 12211      Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:19:40,398][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.694    [weighted Loss:2.694    Policy Loss: 9.119    Value Loss: 3.423    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 20633      Buffer Size: 12193      Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:30:51,756][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 6.609    Value Loss: 3.476    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 21253      Buffer Size: 12214      Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:42:00,424][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 8.019    Value Loss: 3.583    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 21710      Buffer Size: 12120      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:53:10,222][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.221    [weighted Loss:4.221    Policy Loss: 8.557    Value Loss: 3.456    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 22506      Buffer Size: 12281      Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:04:34,676][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 6.267    Value Loss: 3.473    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 22942      Buffer Size: 12087      Transition Number: 150.005 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:15:53,886][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 7.622    Value Loss: 3.333    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 23407      Buffer Size: 11937      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:27:17,601][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.217    [weighted Loss:3.217    Policy Loss: 6.009    Value Loss: 3.669    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 23853      Buffer Size: 11838      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:38:38,560][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 7.743    Value Loss: 3.787    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 24238      Buffer Size: 11763      Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:50:06,714][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.455    [weighted Loss:3.455    Policy Loss: 6.119    Value Loss: 3.466    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 24635      Buffer Size: 11741      Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:01:29,458][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.247    [weighted Loss:4.247    Policy Loss: 5.587    Value Loss: 3.574    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 25369      Buffer Size: 12035      Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:12:57,870][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 5.795    Value Loss: 3.836    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 25783      Buffer Size: 12004      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:24:34,837][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.455    [weighted Loss:3.455    Policy Loss: 6.903    Value Loss: 3.739    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 26325      Buffer Size: 12041      Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:36:11,543][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 6.808    Value Loss: 3.782    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 26604      Buffer Size: 11939      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:48:07,252][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 6.857    Value Loss: 3.781    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 27257      Buffer Size: 12133      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:59:58,376][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 5.598    Value Loss: 3.750    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 27554      Buffer Size: 11838      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:11:43,453][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 5.168    Value Loss: 3.519    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 27887      Buffer Size: 11655      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:23:23,870][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 8.188    Value Loss: 3.743    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 28120      Buffer Size: 11342      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:35:08,004][train][INFO][train.py>_log] ==> #55000      Total Loss: 5.495    [weighted Loss:5.495    Policy Loss: 9.711    Value Loss: 3.891    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 28383      Buffer Size: 11172      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:46:49,801][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.900    [weighted Loss:2.900    Policy Loss: 7.415    Value Loss: 3.861    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 28594      Buffer Size: 10940      Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:58:30,772][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 9.063    Value Loss: 4.169    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 28821      Buffer Size: 10726      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:10:09,254][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 8.041    Value Loss: 4.002    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 29037      Buffer Size: 10305      Transition Number: 149.982 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:21:45,123][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 7.640    Value Loss: 3.943    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 29248      Buffer Size: 10146      Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:33:24,099][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.780    [weighted Loss:3.780    Policy Loss: 7.267    Value Loss: 4.021    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 29462      Buffer Size: 9774       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:45:02,522][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.825    Value Loss: 3.959    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 29719      Buffer Size: 9500       Transition Number: 150.074 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:56:37,828][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.512    [weighted Loss:3.512    Policy Loss: 7.811    Value Loss: 4.170    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 29969      Buffer Size: 9218       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:08:23,258][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.669    [weighted Loss:4.669    Policy Loss: 8.427    Value Loss: 4.052    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 30224      Buffer Size: 8857       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:20:05,315][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 8.237    Value Loss: 3.995    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 30495      Buffer Size: 8587       Transition Number: 150.020 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:31:32,936][train][INFO][train.py>_log] ==> #65000      Total Loss: 4.378    [weighted Loss:4.378    Policy Loss: 8.915    Value Loss: 4.140    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 30678      Buffer Size: 8050       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:43:03,215][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 7.945    Value Loss: 3.830    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 30874      Buffer Size: 7806       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:54:29,105][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 9.239    Value Loss: 3.994    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 31039      Buffer Size: 7536       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:06:09,267][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 8.406    Value Loss: 3.818    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 31186      Buffer Size: 7233       Transition Number: 149.931 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:17:46,768][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.656    [weighted Loss:3.656    Policy Loss: 9.028    Value Loss: 4.025    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 31324      Buffer Size: 6947       Transition Number: 149.939 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:29:26,075][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 7.869    Value Loss: 3.929    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 31516      Buffer Size: 6534       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:41:14,578][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 8.829    Value Loss: 4.076    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 31671      Buffer Size: 6049       Transition Number: 149.980 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:53:01,620][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.764    [weighted Loss:3.764    Policy Loss: 9.237    Value Loss: 4.042    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 31823      Buffer Size: 5687       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:04:44,029][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 9.877    Value Loss: 4.179    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 31964      Buffer Size: 5448       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:16:31,822][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.849    [weighted Loss:4.849    Policy Loss: 10.003   Value Loss: 4.081    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 32098      Buffer Size: 5015       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:28:18,811][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.312    [weighted Loss:4.312    Policy Loss: 9.216    Value Loss: 3.917    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 32240      Buffer Size: 4759       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:40:10,811][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.847    [weighted Loss:3.847    Policy Loss: 9.525    Value Loss: 4.126    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 32420      Buffer Size: 4606       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:52:01,968][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.880    [weighted Loss:4.880    Policy Loss: 9.828    Value Loss: 4.142    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 32580      Buffer Size: 4500       Transition Number: 149.956 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:03:59,532][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.290    [weighted Loss:5.290    Policy Loss: 9.979    Value Loss: 4.029    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 32728      Buffer Size: 4384       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:15:45,571][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 10.199   Value Loss: 3.895    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 32906      Buffer Size: 4346       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:27:34,431][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 9.313    Value Loss: 4.125    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 33077      Buffer Size: 4283       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:39:20,208][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 10.216   Value Loss: 4.245    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 33239      Buffer Size: 4246       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:51:06,980][train][INFO][train.py>_log] ==> #82000      Total Loss: 5.052    [weighted Loss:5.052    Policy Loss: 10.749   Value Loss: 4.251    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 33414      Buffer Size: 4182       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:02:58,559][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 10.057   Value Loss: 4.046    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 33569      Buffer Size: 4130       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:14:43,485][train][INFO][train.py>_log] ==> #84000      Total Loss: 5.647    [weighted Loss:5.647    Policy Loss: 9.965    Value Loss: 4.030    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 33698      Buffer Size: 3994       Transition Number: 149.968 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:26:33,008][train][INFO][train.py>_log] ==> #85000      Total Loss: 5.230    [weighted Loss:5.230    Policy Loss: 10.211   Value Loss: 4.249    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 33883      Buffer Size: 3917       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:38:27,516][train][INFO][train.py>_log] ==> #86000      Total Loss: 5.890    [weighted Loss:5.890    Policy Loss: 9.958    Value Loss: 4.089    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 34058      Buffer Size: 3818       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:50:21,060][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.013    [weighted Loss:4.013    Policy Loss: 10.865   Value Loss: 4.222    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 34260      Buffer Size: 3744       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:02:12,295][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.274    [weighted Loss:4.274    Policy Loss: 10.151   Value Loss: 4.539    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 34440      Buffer Size: 3727       Transition Number: 149.962 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:14:11,279][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.800    [weighted Loss:3.800    Policy Loss: 10.710   Value Loss: 4.169    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 34616      Buffer Size: 3713       Transition Number: 149.962 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:26:04,143][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 10.311   Value Loss: 4.396    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 34816      Buffer Size: 3732       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:37:53,206][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.529    [weighted Loss:3.529    Policy Loss: 10.285   Value Loss: 4.350    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 35014      Buffer Size: 3790       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:49:45,779][train][INFO][train.py>_log] ==> #92000      Total Loss: 5.252    [weighted Loss:5.252    Policy Loss: 11.356   Value Loss: 4.309    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 35196      Buffer Size: 3820       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:01:33,028][train][INFO][train.py>_log] ==> #93000      Total Loss: 5.720    [weighted Loss:5.720    Policy Loss: 10.840   Value Loss: 4.270    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 35355      Buffer Size: 3799       Transition Number: 149.961 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:13:19,214][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.611    [weighted Loss:3.611    Policy Loss: 10.486   Value Loss: 4.070    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 35533      Buffer Size: 3825       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:25:04,975][train][INFO][train.py>_log] ==> #95000      Total Loss: 5.095    [weighted Loss:5.095    Policy Loss: 10.225   Value Loss: 3.895    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 35676      Buffer Size: 3829       Transition Number: 150.070 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:36:56,134][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.946    [weighted Loss:5.946    Policy Loss: 11.197   Value Loss: 4.220    Reward Loss: 0.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 35926      Buffer Size: 3929       Transition Number: 149.953 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:48:43,745][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.428    [weighted Loss:4.428    Policy Loss: 10.945   Value Loss: 4.348    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 36078      Buffer Size: 3943       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:00:25,058][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.296    [weighted Loss:4.296    Policy Loss: 11.022   Value Loss: 4.117    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 36295      Buffer Size: 4010       Transition Number: 150.028 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:12:12,661][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.829    [weighted Loss:3.829    Policy Loss: 11.101   Value Loss: 4.179    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 36479      Buffer Size: 4024       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:23:55,079][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 11.108   Value Loss: 3.962    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 36673      Buffer Size: 4053       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:35:37,760][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 10.811   Value Loss: 4.001    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 36835      Buffer Size: 4085       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:47:18,274][train][INFO][train.py>_log] ==> #102000     Total Loss: 4.345    [weighted Loss:4.345    Policy Loss: 10.921   Value Loss: 4.178    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 37010      Buffer Size: 4095       Transition Number: 149.938 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:59:01,873][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 11.394   Value Loss: 4.160    Reward Loss: 0.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 37166      Buffer Size: 4078       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:10:41,129][train][INFO][train.py>_log] ==> #104000     Total Loss: 4.804    [weighted Loss:4.804    Policy Loss: 11.226   Value Loss: 4.260    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 37362      Buffer Size: 4103       Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:22:17,290][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.121    [weighted Loss:4.121    Policy Loss: 10.898   Value Loss: 4.074    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 37590      Buffer Size: 4168       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:33:54,821][train][INFO][train.py>_log] ==> #106000     Total Loss: 4.143    [weighted Loss:4.143    Policy Loss: 10.556   Value Loss: 4.111    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 37801      Buffer Size: 4221       Transition Number: 149.969 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:45:26,255][train][INFO][train.py>_log] ==> #107000     Total Loss: 4.176    [weighted Loss:4.176    Policy Loss: 11.016   Value Loss: 4.027    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 38016      Buffer Size: 4299       Transition Number: 149.968 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:56:59,027][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 9.459    Value Loss: 4.278    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 38179      Buffer Size: 4291       Transition Number: 149.928 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:08:30,965][train][INFO][train.py>_log] ==> #109000     Total Loss: 4.970    [weighted Loss:4.970    Policy Loss: 11.383   Value Loss: 4.235    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 38331      Buffer Size: 4274       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:20:10,423][train][INFO][train.py>_log] ==> #110000     Total Loss: 5.494    [weighted Loss:5.494    Policy Loss: 9.999    Value Loss: 4.288    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 38539      Buffer Size: 4279       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:31:44,691][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.366    [weighted Loss:3.366    Policy Loss: 11.327   Value Loss: 4.571    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 38726      Buffer Size: 4285       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:43:25,076][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 10.553   Value Loss: 4.320    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 38869      Buffer Size: 4252       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:55:06,160][train][INFO][train.py>_log] ==> #113000     Total Loss: 5.266    [weighted Loss:5.266    Policy Loss: 10.634   Value Loss: 4.270    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 39052      Buffer Size: 4235       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:06:50,660][train][INFO][train.py>_log] ==> #114000     Total Loss: 4.002    [weighted Loss:4.002    Policy Loss: 9.517    Value Loss: 4.093    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 39213      Buffer Size: 4204       Transition Number: 150.015 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:18:42,217][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.800    [weighted Loss:4.800    Policy Loss: 10.297   Value Loss: 4.088    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 39368      Buffer Size: 4177       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:30:30,623][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.043    [weighted Loss:4.043    Policy Loss: 10.563   Value Loss: 4.272    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 39546      Buffer Size: 4196       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:42:12,903][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.128    [weighted Loss:4.128    Policy Loss: 9.160    Value Loss: 4.343    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 39725      Buffer Size: 4187       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:53:56,786][train][INFO][train.py>_log] ==> #118000     Total Loss: 4.899    [weighted Loss:4.899    Policy Loss: 9.770    Value Loss: 4.319    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 39947      Buffer Size: 4261       Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:05:47,739][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 9.858    Value Loss: 4.259    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 40135      Buffer Size: 4191       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:17:39,635][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.454    [weighted Loss:3.454    Policy Loss: 9.251    Value Loss: 4.299    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 40326      Buffer Size: 4244       Transition Number: 149.963 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:29:14,849][train][INFO][train.py>_log] ==> #121000     Total Loss: 4.744    [weighted Loss:4.744    Policy Loss: 9.751    Value Loss: 4.350    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 40596      Buffer Size: 4292       Transition Number: 149.971 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:40:59,756][train][INFO][train.py>_log] ==> #122000     Total Loss: 0.607    [weighted Loss:0.607    Policy Loss: 8.794    Value Loss: 4.284    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 40857      Buffer Size: 4368       Transition Number: 149.957 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:52:41,907][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.948    [weighted Loss:3.948    Policy Loss: 9.522    Value Loss: 4.326    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 41134      Buffer Size: 4448       Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:04:22,514][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 8.868    Value Loss: 4.307    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 41475      Buffer Size: 4616       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:15:55,184][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 9.925    Value Loss: 4.430    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 41778      Buffer Size: 4730       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:27:24,517][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.359    [weighted Loss:4.359    Policy Loss: 9.632    Value Loss: 4.329    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 42079      Buffer Size: 4868       Transition Number: 149.959 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:38:51,820][train][INFO][train.py>_log] ==> #127000     Total Loss: 5.791    [weighted Loss:5.791    Policy Loss: 10.091   Value Loss: 4.451    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 42395      Buffer Size: 4969       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:50:21,578][train][INFO][train.py>_log] ==> #128000     Total Loss: 4.698    [weighted Loss:4.698    Policy Loss: 9.809    Value Loss: 4.371    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 42622      Buffer Size: 4973       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:01:54,452][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.956    [weighted Loss:2.956    Policy Loss: 9.336    Value Loss: 4.422    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 42853      Buffer Size: 5005       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:13:20,119][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.439    [weighted Loss:3.439    Policy Loss: 9.830    Value Loss: 4.346    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 43225      Buffer Size: 5162       Transition Number: 149.982 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:24:44,811][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 10.471   Value Loss: 4.693    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 43437      Buffer Size: 5211       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:36:11,821][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 8.966    Value Loss: 3.954    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 43679      Buffer Size: 5289       Transition Number: 149.934 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:47:36,395][train][INFO][train.py>_log] ==> #133000     Total Loss: 4.347    [weighted Loss:4.347    Policy Loss: 9.680    Value Loss: 4.338    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 43937      Buffer Size: 5323       Transition Number: 150.022 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:59:05,558][train][INFO][train.py>_log] ==> #134000     Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 9.348    Value Loss: 4.285    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 44123      Buffer Size: 5337       Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:10:36,241][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 9.182    Value Loss: 4.702    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 44334      Buffer Size: 5394       Transition Number: 149.953 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:22:11,403][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 9.384    Value Loss: 4.079    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 44506      Buffer Size: 5402       Transition Number: 150.035 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:33:46,994][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 9.345    Value Loss: 4.141    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 44665      Buffer Size: 5412       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:45:08,856][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.143    [weighted Loss:4.143    Policy Loss: 10.018   Value Loss: 4.516    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 44939      Buffer Size: 5520       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:56:28,619][train][INFO][train.py>_log] ==> #139000     Total Loss: 5.694    [weighted Loss:5.694    Policy Loss: 9.902    Value Loss: 4.377    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 45101      Buffer Size: 5508       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:07:55,360][train][INFO][train.py>_log] ==> #140000     Total Loss: 4.481    [weighted Loss:4.481    Policy Loss: 9.823    Value Loss: 4.520    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 45330      Buffer Size: 5561       Transition Number: 150.031 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:19:25,558][train][INFO][train.py>_log] ==> #141000     Total Loss: 4.012    [weighted Loss:4.012    Policy Loss: 9.553    Value Loss: 4.503    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 45558      Buffer Size: 5574       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:30:49,477][train][INFO][train.py>_log] ==> #142000     Total Loss: 4.283    [weighted Loss:4.283    Policy Loss: 10.393   Value Loss: 4.511    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 45760      Buffer Size: 5597       Transition Number: 149.944 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:42:14,160][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 9.601    Value Loss: 4.259    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 45906      Buffer Size: 5535       Transition Number: 149.948 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:53:45,599][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.791    [weighted Loss:3.791    Policy Loss: 9.256    Value Loss: 4.255    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 46077      Buffer Size: 5439       Transition Number: 149.971 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:05:18,797][train][INFO][train.py>_log] ==> #145000     Total Loss: 6.293    [weighted Loss:6.293    Policy Loss: 9.744    Value Loss: 4.231    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 46237      Buffer Size: 5359       Transition Number: 150.006 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:17:02,472][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.519    [weighted Loss:2.519    Policy Loss: 8.783    Value Loss: 4.471    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 46394      Buffer Size: 5212       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:28:43,296][train][INFO][train.py>_log] ==> #147000     Total Loss: 4.537    [weighted Loss:4.537    Policy Loss: 9.163    Value Loss: 4.406    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 46558      Buffer Size: 5058       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:40:28,506][train][INFO][train.py>_log] ==> #148000     Total Loss: 4.626    [weighted Loss:4.626    Policy Loss: 8.657    Value Loss: 4.515    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 46746      Buffer Size: 4965       Transition Number: 149.980 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:52:15,172][train][INFO][train.py>_log] ==> #149000     Total Loss: 4.583    [weighted Loss:4.583    Policy Loss: 9.732    Value Loss: 4.306    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 46926      Buffer Size: 4845       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:03:56,120][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 9.555    Value Loss: 4.450    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 47126      Buffer Size: 4740       Transition Number: 149.955 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:15:39,549][train][INFO][train.py>_log] ==> #151000     Total Loss: 4.381    [weighted Loss:4.381    Policy Loss: 9.720    Value Loss: 4.269    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 47302      Buffer Size: 4693       Transition Number: 149.952 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:27:24,154][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 10.074   Value Loss: 4.327    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 47526      Buffer Size: 4673       Transition Number: 149.963 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:39:09,452][train][INFO][train.py>_log] ==> #153000     Total Loss: 4.878    [weighted Loss:4.878    Policy Loss: 10.752   Value Loss: 4.411    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 47738      Buffer Size: 4535       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:50:53,327][train][INFO][train.py>_log] ==> #154000     Total Loss: 6.073    [weighted Loss:6.073    Policy Loss: 10.284   Value Loss: 4.576    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 47921      Buffer Size: 4499       Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:02:39,579][train][INFO][train.py>_log] ==> #155000     Total Loss: 4.218    [weighted Loss:4.218    Policy Loss: 9.798    Value Loss: 4.671    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 48093      Buffer Size: 4427       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:14:25,707][train][INFO][train.py>_log] ==> #156000     Total Loss: 4.077    [weighted Loss:4.077    Policy Loss: 9.498    Value Loss: 4.405    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 48525      Buffer Size: 4595       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:26:10,523][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 9.523    Value Loss: 4.629    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 48676      Buffer Size: 4567       Transition Number: 149.961 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:38:02,777][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 10.593   Value Loss: 4.350    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 48909      Buffer Size: 4590       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:49:46,881][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 10.051   Value Loss: 4.238    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 49145      Buffer Size: 4647       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:01:32,564][train][INFO][train.py>_log] ==> #160000     Total Loss: 4.404    [weighted Loss:4.404    Policy Loss: 10.163   Value Loss: 4.323    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 49353      Buffer Size: 4701       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:13:16,496][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.881    [weighted Loss:3.881    Policy Loss: 9.942    Value Loss: 4.446    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 49553      Buffer Size: 4622       Transition Number: 149.949 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:24:59,837][train][INFO][train.py>_log] ==> #162000     Total Loss: 3.524    [weighted Loss:3.524    Policy Loss: 10.599   Value Loss: 4.817    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 49736      Buffer Size: 4637       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:36:50,333][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 9.527    Value Loss: 4.909    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 49933      Buffer Size: 4586       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:48:35,927][train][INFO][train.py>_log] ==> #164000     Total Loss: 4.284    [weighted Loss:4.284    Policy Loss: 9.609    Value Loss: 4.446    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 50112      Buffer Size: 4539       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:00:25,647][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.826    [weighted Loss:3.826    Policy Loss: 10.529   Value Loss: 4.606    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 50329      Buffer Size: 4544       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:12:16,407][train][INFO][train.py>_log] ==> #166000     Total Loss: 4.738    [weighted Loss:4.738    Policy Loss: 10.294   Value Loss: 4.945    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 50528      Buffer Size: 4588       Transition Number: 149.959 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:24:12,025][train][INFO][train.py>_log] ==> #167000     Total Loss: 5.496    [weighted Loss:5.496    Policy Loss: 9.675    Value Loss: 4.916    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 50720      Buffer Size: 4618       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:35:57,693][train][INFO][train.py>_log] ==> #168000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 10.470   Value Loss: 4.918    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 50969      Buffer Size: 4692       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:47:46,743][train][INFO][train.py>_log] ==> #169000     Total Loss: 5.820    [weighted Loss:5.820    Policy Loss: 10.093   Value Loss: 4.884    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 51161      Buffer Size: 4723       Transition Number: 149.946 k Batch Size: 128        Lr: 0.100   
