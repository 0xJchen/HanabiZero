[2021-10-31 17:31:25,995][train][INFO][train.py>_log] ==> #0          Total Loss: 43.713   [weighted Loss:43.713   Policy Loss: 13.715   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 39         Buffer Size: 39         Transition Number: 0.384   k Batch Size: 128        Lr: 0.000   
[2021-10-31 17:41:08,077][train][INFO][train.py>_log] ==> #1000       Total Loss: 8.174    [weighted Loss:8.174    Policy Loss: 14.347   Value Loss: 4.792    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 696        Buffer Size: 696        Transition Number: 8.363   k Batch Size: 128        Lr: 0.010   
[2021-10-31 17:50:54,107][train][INFO][train.py>_log] ==> #2000       Total Loss: 9.158    [weighted Loss:9.158    Policy Loss: 14.792   Value Loss: 3.615    Reward Loss: 0.997    Consistency Loss: 0.000    ] Replay Episodes Collected: 1396       Buffer Size: 1396       Transition Number: 16.609  k Batch Size: 128        Lr: 0.020   
[2021-10-31 18:01:10,225][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.947    [weighted Loss:6.947    Policy Loss: 14.118   Value Loss: 3.704    Reward Loss: 0.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 2250       Buffer Size: 2250       Transition Number: 24.172  k Batch Size: 128        Lr: 0.030   
[2021-10-31 18:11:40,040][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.237    [weighted Loss:6.237    Policy Loss: 14.888   Value Loss: 3.660    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 2867       Buffer Size: 2867       Transition Number: 31.473  k Batch Size: 128        Lr: 0.040   
[2021-10-31 18:22:08,616][train][INFO][train.py>_log] ==> #5000       Total Loss: 7.053    [weighted Loss:7.053    Policy Loss: 14.507   Value Loss: 3.372    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 3466       Buffer Size: 3466       Transition Number: 38.628  k Batch Size: 128        Lr: 0.050   
[2021-10-31 18:32:35,049][train][INFO][train.py>_log] ==> #6000       Total Loss: 6.238    [weighted Loss:6.238    Policy Loss: 13.536   Value Loss: 3.354    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 4012       Buffer Size: 4012       Transition Number: 45.653  k Batch Size: 128        Lr: 0.060   
[2021-10-31 18:43:01,082][train][INFO][train.py>_log] ==> #7000       Total Loss: 7.105    [weighted Loss:7.105    Policy Loss: 14.499   Value Loss: 3.050    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 4805       Buffer Size: 4805       Transition Number: 52.849  k Batch Size: 128        Lr: 0.070   
[2021-10-31 18:53:26,979][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.350    [weighted Loss:5.350    Policy Loss: 13.956   Value Loss: 3.007    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 5643       Buffer Size: 5643       Transition Number: 60.221  k Batch Size: 128        Lr: 0.080   
[2021-10-31 19:03:56,699][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.612    [weighted Loss:5.612    Policy Loss: 14.325   Value Loss: 3.056    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 6107       Buffer Size: 6107       Transition Number: 67.052  k Batch Size: 128        Lr: 0.090   
[2021-10-31 19:14:28,035][train][INFO][train.py>_log] ==> #10000      Total Loss: 7.416    [weighted Loss:7.416    Policy Loss: 14.491   Value Loss: 2.901    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 6721       Buffer Size: 6721       Transition Number: 74.464  k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:24:59,536][train][INFO][train.py>_log] ==> #11000      Total Loss: 7.125    [weighted Loss:7.125    Policy Loss: 13.788   Value Loss: 2.757    Reward Loss: 0.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 7342       Buffer Size: 7342       Transition Number: 81.616  k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:35:25,692][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.027    [weighted Loss:6.027    Policy Loss: 14.059   Value Loss: 2.593    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 7864       Buffer Size: 7864       Transition Number: 88.467  k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:45:54,836][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 13.871   Value Loss: 3.012    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 8399       Buffer Size: 8399       Transition Number: 95.275  k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:56:23,858][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.205    [weighted Loss:5.205    Policy Loss: 13.565   Value Loss: 2.808    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 9117       Buffer Size: 9117       Transition Number: 102.429 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:06:59,304][train][INFO][train.py>_log] ==> #15000      Total Loss: 6.968    [weighted Loss:6.968    Policy Loss: 14.236   Value Loss: 2.853    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 9847       Buffer Size: 9847       Transition Number: 109.682 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:17:25,839][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.787    [weighted Loss:4.787    Policy Loss: 13.173   Value Loss: 2.789    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 10584      Buffer Size: 10584      Transition Number: 116.692 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:27:49,036][train][INFO][train.py>_log] ==> #17000      Total Loss: 6.151    [weighted Loss:6.151    Policy Loss: 13.756   Value Loss: 3.038    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 11298      Buffer Size: 11298      Transition Number: 123.859 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:38:15,760][train][INFO][train.py>_log] ==> #18000      Total Loss: 7.355    [weighted Loss:7.355    Policy Loss: 13.666   Value Loss: 3.026    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 11786      Buffer Size: 11786      Transition Number: 129.918 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:48:44,529][train][INFO][train.py>_log] ==> #19000      Total Loss: 7.438    [weighted Loss:7.438    Policy Loss: 14.152   Value Loss: 3.094    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 12317      Buffer Size: 12317      Transition Number: 136.377 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:59:16,431][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.873    [weighted Loss:5.873    Policy Loss: 13.309   Value Loss: 2.995    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 12741      Buffer Size: 12741      Transition Number: 142.538 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:09:46,618][train][INFO][train.py>_log] ==> #21000      Total Loss: 7.694    [weighted Loss:7.694    Policy Loss: 13.975   Value Loss: 2.891    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 13167      Buffer Size: 13167      Transition Number: 148.818 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:20:23,830][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.291    [weighted Loss:4.291    Policy Loss: 12.342   Value Loss: 2.871    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 13583      Buffer Size: 13220      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:31:08,366][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.538    [weighted Loss:4.538    Policy Loss: 13.599   Value Loss: 3.222    Reward Loss: 0.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 14027      Buffer Size: 13209      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:41:48,044][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.075    [weighted Loss:4.075    Policy Loss: 12.797   Value Loss: 3.066    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 14428      Buffer Size: 13137      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:52:36,061][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.039    [weighted Loss:4.039    Policy Loss: 10.725   Value Loss: 2.993    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 14761      Buffer Size: 12879      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:03:20,932][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.695    [weighted Loss:5.695    Policy Loss: 11.847   Value Loss: 3.209    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 15137      Buffer Size: 12728      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:14:19,354][train][INFO][train.py>_log] ==> #27000      Total Loss: 4.935    [weighted Loss:4.935    Policy Loss: 10.488   Value Loss: 3.470    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 15656      Buffer Size: 12776      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:25:17,740][train][INFO][train.py>_log] ==> #28000      Total Loss: 5.110    [weighted Loss:5.110    Policy Loss: 12.286   Value Loss: 3.077    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 16157      Buffer Size: 12745      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:36:16,868][train][INFO][train.py>_log] ==> #29000      Total Loss: 5.695    [weighted Loss:5.695    Policy Loss: 12.884   Value Loss: 3.065    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 16641      Buffer Size: 12824      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:47:20,532][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.859    [weighted Loss:2.859    Policy Loss: 9.826    Value Loss: 3.202    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 17022      Buffer Size: 12700      Transition Number: 150.011 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:58:23,699][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.563    [weighted Loss:3.563    Policy Loss: 9.449    Value Loss: 3.172    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 17337      Buffer Size: 12403      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:10:23,395][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.928    [weighted Loss:3.928    Policy Loss: 9.261    Value Loss: 3.200    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 17766      Buffer Size: 12154      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:21:54,251][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 5.920    Value Loss: 3.305    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 18126      Buffer Size: 12129      Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:33:25,529][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.903    [weighted Loss:2.903    Policy Loss: 6.942    Value Loss: 3.249    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 18753      Buffer Size: 12245      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:45:29,348][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 5.502    Value Loss: 3.559    Reward Loss: 0.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 19146      Buffer Size: 12084      Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:56:45,900][train][INFO][train.py>_log] ==> #36000      Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 9.949    Value Loss: 3.459    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 19709      Buffer Size: 12178      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:08:16,167][train][INFO][train.py>_log] ==> #37000      Total Loss: 3.592    [weighted Loss:3.592    Policy Loss: 8.148    Value Loss: 3.068    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 20201      Buffer Size: 12211      Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:19:40,398][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.694    [weighted Loss:2.694    Policy Loss: 9.119    Value Loss: 3.423    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 20633      Buffer Size: 12193      Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:30:51,756][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 6.609    Value Loss: 3.476    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 21253      Buffer Size: 12214      Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:42:00,424][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 8.019    Value Loss: 3.583    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 21710      Buffer Size: 12120      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:53:10,222][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.221    [weighted Loss:4.221    Policy Loss: 8.557    Value Loss: 3.456    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 22506      Buffer Size: 12281      Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:04:34,676][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 6.267    Value Loss: 3.473    Reward Loss: 0.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 22942      Buffer Size: 12087      Transition Number: 150.005 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:15:53,886][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.645    [weighted Loss:1.645    Policy Loss: 7.622    Value Loss: 3.333    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 23407      Buffer Size: 11937      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:27:17,601][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.217    [weighted Loss:3.217    Policy Loss: 6.009    Value Loss: 3.669    Reward Loss: 0.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 23853      Buffer Size: 11838      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:38:38,560][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 7.743    Value Loss: 3.787    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 24238      Buffer Size: 11763      Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:50:06,714][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.455    [weighted Loss:3.455    Policy Loss: 6.119    Value Loss: 3.466    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 24635      Buffer Size: 11741      Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:01:29,458][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.247    [weighted Loss:4.247    Policy Loss: 5.587    Value Loss: 3.574    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 25369      Buffer Size: 12035      Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:12:57,870][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 5.795    Value Loss: 3.836    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 25783      Buffer Size: 12004      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:24:34,837][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.455    [weighted Loss:3.455    Policy Loss: 6.903    Value Loss: 3.739    Reward Loss: 0.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 26325      Buffer Size: 12041      Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:36:11,543][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 6.808    Value Loss: 3.782    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 26604      Buffer Size: 11939      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:48:07,252][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 6.857    Value Loss: 3.781    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 27257      Buffer Size: 12133      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:59:58,376][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 5.598    Value Loss: 3.750    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 27554      Buffer Size: 11838      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:11:43,453][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 5.168    Value Loss: 3.519    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 27887      Buffer Size: 11655      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:23:23,870][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 8.188    Value Loss: 3.743    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 28120      Buffer Size: 11342      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:35:08,004][train][INFO][train.py>_log] ==> #55000      Total Loss: 5.495    [weighted Loss:5.495    Policy Loss: 9.711    Value Loss: 3.891    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 28383      Buffer Size: 11172      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:46:49,801][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.900    [weighted Loss:2.900    Policy Loss: 7.415    Value Loss: 3.861    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 28594      Buffer Size: 10940      Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:58:30,772][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 9.063    Value Loss: 4.169    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 28821      Buffer Size: 10726      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:10:09,254][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 8.041    Value Loss: 4.002    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 29037      Buffer Size: 10305      Transition Number: 149.982 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:21:45,123][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 7.640    Value Loss: 3.943    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 29248      Buffer Size: 10146      Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:33:24,099][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.780    [weighted Loss:3.780    Policy Loss: 7.267    Value Loss: 4.021    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 29462      Buffer Size: 9774       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:45:02,522][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.825    Value Loss: 3.959    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 29719      Buffer Size: 9500       Transition Number: 150.074 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:56:37,828][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.512    [weighted Loss:3.512    Policy Loss: 7.811    Value Loss: 4.170    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 29969      Buffer Size: 9218       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:08:23,258][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.669    [weighted Loss:4.669    Policy Loss: 8.427    Value Loss: 4.052    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 30224      Buffer Size: 8857       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:20:05,315][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 8.237    Value Loss: 3.995    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 30495      Buffer Size: 8587       Transition Number: 150.020 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:31:32,936][train][INFO][train.py>_log] ==> #65000      Total Loss: 4.378    [weighted Loss:4.378    Policy Loss: 8.915    Value Loss: 4.140    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 30678      Buffer Size: 8050       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:43:03,215][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 7.945    Value Loss: 3.830    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 30874      Buffer Size: 7806       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:54:29,105][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 9.239    Value Loss: 3.994    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 31039      Buffer Size: 7536       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:06:09,267][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 8.406    Value Loss: 3.818    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 31186      Buffer Size: 7233       Transition Number: 149.931 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:17:46,768][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.656    [weighted Loss:3.656    Policy Loss: 9.028    Value Loss: 4.025    Reward Loss: 0.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 31324      Buffer Size: 6947       Transition Number: 149.939 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:29:26,075][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 7.869    Value Loss: 3.929    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 31516      Buffer Size: 6534       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:41:14,578][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 8.829    Value Loss: 4.076    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 31671      Buffer Size: 6049       Transition Number: 149.980 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:53:01,620][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.764    [weighted Loss:3.764    Policy Loss: 9.237    Value Loss: 4.042    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 31823      Buffer Size: 5687       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:04:44,029][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 9.877    Value Loss: 4.179    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 31964      Buffer Size: 5448       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:16:31,822][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.849    [weighted Loss:4.849    Policy Loss: 10.003   Value Loss: 4.081    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 32098      Buffer Size: 5015       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:28:18,811][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.312    [weighted Loss:4.312    Policy Loss: 9.216    Value Loss: 3.917    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 32240      Buffer Size: 4759       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:40:10,811][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.847    [weighted Loss:3.847    Policy Loss: 9.525    Value Loss: 4.126    Reward Loss: 0.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 32420      Buffer Size: 4606       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:52:01,968][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.880    [weighted Loss:4.880    Policy Loss: 9.828    Value Loss: 4.142    Reward Loss: 0.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 32580      Buffer Size: 4500       Transition Number: 149.956 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:03:59,532][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.290    [weighted Loss:5.290    Policy Loss: 9.979    Value Loss: 4.029    Reward Loss: 0.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 32728      Buffer Size: 4384       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:15:45,571][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 10.199   Value Loss: 3.895    Reward Loss: 0.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 32906      Buffer Size: 4346       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:27:34,431][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 9.313    Value Loss: 4.125    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 33077      Buffer Size: 4283       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:39:20,208][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 10.216   Value Loss: 4.245    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 33239      Buffer Size: 4246       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:51:06,980][train][INFO][train.py>_log] ==> #82000      Total Loss: 5.052    [weighted Loss:5.052    Policy Loss: 10.749   Value Loss: 4.251    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 33414      Buffer Size: 4182       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:02:58,559][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 10.057   Value Loss: 4.046    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 33569      Buffer Size: 4130       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:14:43,485][train][INFO][train.py>_log] ==> #84000      Total Loss: 5.647    [weighted Loss:5.647    Policy Loss: 9.965    Value Loss: 4.030    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 33698      Buffer Size: 3994       Transition Number: 149.968 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:26:33,008][train][INFO][train.py>_log] ==> #85000      Total Loss: 5.230    [weighted Loss:5.230    Policy Loss: 10.211   Value Loss: 4.249    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 33883      Buffer Size: 3917       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:38:27,516][train][INFO][train.py>_log] ==> #86000      Total Loss: 5.890    [weighted Loss:5.890    Policy Loss: 9.958    Value Loss: 4.089    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 34058      Buffer Size: 3818       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:50:21,060][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.013    [weighted Loss:4.013    Policy Loss: 10.865   Value Loss: 4.222    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 34260      Buffer Size: 3744       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:02:12,295][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.274    [weighted Loss:4.274    Policy Loss: 10.151   Value Loss: 4.539    Reward Loss: 0.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 34440      Buffer Size: 3727       Transition Number: 149.962 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:14:11,279][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.800    [weighted Loss:3.800    Policy Loss: 10.710   Value Loss: 4.169    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 34616      Buffer Size: 3713       Transition Number: 149.962 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:26:04,143][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 10.311   Value Loss: 4.396    Reward Loss: 0.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 34816      Buffer Size: 3732       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:37:53,206][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.529    [weighted Loss:3.529    Policy Loss: 10.285   Value Loss: 4.350    Reward Loss: 0.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 35014      Buffer Size: 3790       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:49:45,779][train][INFO][train.py>_log] ==> #92000      Total Loss: 5.252    [weighted Loss:5.252    Policy Loss: 11.356   Value Loss: 4.309    Reward Loss: 0.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 35196      Buffer Size: 3820       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:01:33,028][train][INFO][train.py>_log] ==> #93000      Total Loss: 5.720    [weighted Loss:5.720    Policy Loss: 10.840   Value Loss: 4.270    Reward Loss: 0.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 35355      Buffer Size: 3799       Transition Number: 149.961 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:13:19,214][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.611    [weighted Loss:3.611    Policy Loss: 10.486   Value Loss: 4.070    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 35533      Buffer Size: 3825       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:25:04,975][train][INFO][train.py>_log] ==> #95000      Total Loss: 5.095    [weighted Loss:5.095    Policy Loss: 10.225   Value Loss: 3.895    Reward Loss: 0.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 35676      Buffer Size: 3829       Transition Number: 150.070 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:36:56,134][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.946    [weighted Loss:5.946    Policy Loss: 11.197   Value Loss: 4.220    Reward Loss: 0.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 35926      Buffer Size: 3929       Transition Number: 149.953 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:48:43,745][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.428    [weighted Loss:4.428    Policy Loss: 10.945   Value Loss: 4.348    Reward Loss: 0.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 36078      Buffer Size: 3943       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:00:25,058][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.296    [weighted Loss:4.296    Policy Loss: 11.022   Value Loss: 4.117    Reward Loss: 0.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 36295      Buffer Size: 4010       Transition Number: 150.028 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:12:12,661][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.829    [weighted Loss:3.829    Policy Loss: 11.101   Value Loss: 4.179    Reward Loss: 0.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 36479      Buffer Size: 4024       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:23:55,079][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 11.108   Value Loss: 3.962    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 36673      Buffer Size: 4053       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:35:37,760][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 10.811   Value Loss: 4.001    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 36835      Buffer Size: 4085       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:47:18,274][train][INFO][train.py>_log] ==> #102000     Total Loss: 4.345    [weighted Loss:4.345    Policy Loss: 10.921   Value Loss: 4.178    Reward Loss: 0.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 37010      Buffer Size: 4095       Transition Number: 149.938 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:59:01,873][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 11.394   Value Loss: 4.160    Reward Loss: 0.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 37166      Buffer Size: 4078       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:10:41,129][train][INFO][train.py>_log] ==> #104000     Total Loss: 4.804    [weighted Loss:4.804    Policy Loss: 11.226   Value Loss: 4.260    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 37362      Buffer Size: 4103       Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:22:17,290][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.121    [weighted Loss:4.121    Policy Loss: 10.898   Value Loss: 4.074    Reward Loss: 0.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 37590      Buffer Size: 4168       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:33:54,821][train][INFO][train.py>_log] ==> #106000     Total Loss: 4.143    [weighted Loss:4.143    Policy Loss: 10.556   Value Loss: 4.111    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 37801      Buffer Size: 4221       Transition Number: 149.969 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:45:26,255][train][INFO][train.py>_log] ==> #107000     Total Loss: 4.176    [weighted Loss:4.176    Policy Loss: 11.016   Value Loss: 4.027    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 38016      Buffer Size: 4299       Transition Number: 149.968 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:56:59,027][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.074    [weighted Loss:4.074    Policy Loss: 9.459    Value Loss: 4.278    Reward Loss: 0.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 38179      Buffer Size: 4291       Transition Number: 149.928 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:08:30,965][train][INFO][train.py>_log] ==> #109000     Total Loss: 4.970    [weighted Loss:4.970    Policy Loss: 11.383   Value Loss: 4.235    Reward Loss: 0.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 38331      Buffer Size: 4274       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:20:10,423][train][INFO][train.py>_log] ==> #110000     Total Loss: 5.494    [weighted Loss:5.494    Policy Loss: 9.999    Value Loss: 4.288    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 38539      Buffer Size: 4279       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:31:44,691][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.366    [weighted Loss:3.366    Policy Loss: 11.327   Value Loss: 4.571    Reward Loss: 0.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 38726      Buffer Size: 4285       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:43:25,076][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 10.553   Value Loss: 4.320    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 38869      Buffer Size: 4252       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:55:06,160][train][INFO][train.py>_log] ==> #113000     Total Loss: 5.266    [weighted Loss:5.266    Policy Loss: 10.634   Value Loss: 4.270    Reward Loss: 0.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 39052      Buffer Size: 4235       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:06:50,660][train][INFO][train.py>_log] ==> #114000     Total Loss: 4.002    [weighted Loss:4.002    Policy Loss: 9.517    Value Loss: 4.093    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 39213      Buffer Size: 4204       Transition Number: 150.015 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:18:42,217][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.800    [weighted Loss:4.800    Policy Loss: 10.297   Value Loss: 4.088    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 39368      Buffer Size: 4177       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:30:30,623][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.043    [weighted Loss:4.043    Policy Loss: 10.563   Value Loss: 4.272    Reward Loss: 0.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 39546      Buffer Size: 4196       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:42:12,903][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.128    [weighted Loss:4.128    Policy Loss: 9.160    Value Loss: 4.343    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 39725      Buffer Size: 4187       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:53:56,786][train][INFO][train.py>_log] ==> #118000     Total Loss: 4.899    [weighted Loss:4.899    Policy Loss: 9.770    Value Loss: 4.319    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 39947      Buffer Size: 4261       Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:05:47,739][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 9.858    Value Loss: 4.259    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 40135      Buffer Size: 4191       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:17:39,635][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.454    [weighted Loss:3.454    Policy Loss: 9.251    Value Loss: 4.299    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 40326      Buffer Size: 4244       Transition Number: 149.963 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:29:14,849][train][INFO][train.py>_log] ==> #121000     Total Loss: 4.744    [weighted Loss:4.744    Policy Loss: 9.751    Value Loss: 4.350    Reward Loss: 0.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 40596      Buffer Size: 4292       Transition Number: 149.971 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:40:59,756][train][INFO][train.py>_log] ==> #122000     Total Loss: 0.607    [weighted Loss:0.607    Policy Loss: 8.794    Value Loss: 4.284    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 40857      Buffer Size: 4368       Transition Number: 149.957 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:52:41,907][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.948    [weighted Loss:3.948    Policy Loss: 9.522    Value Loss: 4.326    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 41134      Buffer Size: 4448       Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:04:22,514][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 8.868    Value Loss: 4.307    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 41475      Buffer Size: 4616       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:15:55,184][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 9.925    Value Loss: 4.430    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 41778      Buffer Size: 4730       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:27:24,517][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.359    [weighted Loss:4.359    Policy Loss: 9.632    Value Loss: 4.329    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 42079      Buffer Size: 4868       Transition Number: 149.959 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:38:51,820][train][INFO][train.py>_log] ==> #127000     Total Loss: 5.791    [weighted Loss:5.791    Policy Loss: 10.091   Value Loss: 4.451    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 42395      Buffer Size: 4969       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:50:21,578][train][INFO][train.py>_log] ==> #128000     Total Loss: 4.698    [weighted Loss:4.698    Policy Loss: 9.809    Value Loss: 4.371    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 42622      Buffer Size: 4973       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:01:54,452][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.956    [weighted Loss:2.956    Policy Loss: 9.336    Value Loss: 4.422    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 42853      Buffer Size: 5005       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:13:20,119][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.439    [weighted Loss:3.439    Policy Loss: 9.830    Value Loss: 4.346    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 43225      Buffer Size: 5162       Transition Number: 149.982 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:24:44,811][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 10.471   Value Loss: 4.693    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 43437      Buffer Size: 5211       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:36:11,821][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 8.966    Value Loss: 3.954    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 43679      Buffer Size: 5289       Transition Number: 149.934 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:47:36,395][train][INFO][train.py>_log] ==> #133000     Total Loss: 4.347    [weighted Loss:4.347    Policy Loss: 9.680    Value Loss: 4.338    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 43937      Buffer Size: 5323       Transition Number: 150.022 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:59:05,558][train][INFO][train.py>_log] ==> #134000     Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 9.348    Value Loss: 4.285    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 44123      Buffer Size: 5337       Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:10:36,241][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 9.182    Value Loss: 4.702    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 44334      Buffer Size: 5394       Transition Number: 149.953 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:22:11,403][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 9.384    Value Loss: 4.079    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 44506      Buffer Size: 5402       Transition Number: 150.035 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:33:46,994][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 9.345    Value Loss: 4.141    Reward Loss: 0.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 44665      Buffer Size: 5412       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:45:08,856][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.143    [weighted Loss:4.143    Policy Loss: 10.018   Value Loss: 4.516    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 44939      Buffer Size: 5520       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:56:28,619][train][INFO][train.py>_log] ==> #139000     Total Loss: 5.694    [weighted Loss:5.694    Policy Loss: 9.902    Value Loss: 4.377    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 45101      Buffer Size: 5508       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:07:55,360][train][INFO][train.py>_log] ==> #140000     Total Loss: 4.481    [weighted Loss:4.481    Policy Loss: 9.823    Value Loss: 4.520    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 45330      Buffer Size: 5561       Transition Number: 150.031 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:19:25,558][train][INFO][train.py>_log] ==> #141000     Total Loss: 4.012    [weighted Loss:4.012    Policy Loss: 9.553    Value Loss: 4.503    Reward Loss: 0.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 45558      Buffer Size: 5574       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:30:49,477][train][INFO][train.py>_log] ==> #142000     Total Loss: 4.283    [weighted Loss:4.283    Policy Loss: 10.393   Value Loss: 4.511    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 45760      Buffer Size: 5597       Transition Number: 149.944 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:42:14,160][train][INFO][train.py>_log] ==> #143000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 9.601    Value Loss: 4.259    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 45906      Buffer Size: 5535       Transition Number: 149.948 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:53:45,599][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.791    [weighted Loss:3.791    Policy Loss: 9.256    Value Loss: 4.255    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 46077      Buffer Size: 5439       Transition Number: 149.971 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:05:18,797][train][INFO][train.py>_log] ==> #145000     Total Loss: 6.293    [weighted Loss:6.293    Policy Loss: 9.744    Value Loss: 4.231    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 46237      Buffer Size: 5359       Transition Number: 150.006 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:17:02,472][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.519    [weighted Loss:2.519    Policy Loss: 8.783    Value Loss: 4.471    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 46394      Buffer Size: 5212       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:28:43,296][train][INFO][train.py>_log] ==> #147000     Total Loss: 4.537    [weighted Loss:4.537    Policy Loss: 9.163    Value Loss: 4.406    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 46558      Buffer Size: 5058       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:40:28,506][train][INFO][train.py>_log] ==> #148000     Total Loss: 4.626    [weighted Loss:4.626    Policy Loss: 8.657    Value Loss: 4.515    Reward Loss: 0.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 46746      Buffer Size: 4965       Transition Number: 149.980 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:52:15,172][train][INFO][train.py>_log] ==> #149000     Total Loss: 4.583    [weighted Loss:4.583    Policy Loss: 9.732    Value Loss: 4.306    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 46926      Buffer Size: 4845       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:03:56,120][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 9.555    Value Loss: 4.450    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 47126      Buffer Size: 4740       Transition Number: 149.955 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:15:39,549][train][INFO][train.py>_log] ==> #151000     Total Loss: 4.381    [weighted Loss:4.381    Policy Loss: 9.720    Value Loss: 4.269    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 47302      Buffer Size: 4693       Transition Number: 149.952 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:27:24,154][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 10.074   Value Loss: 4.327    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 47526      Buffer Size: 4673       Transition Number: 149.963 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:39:09,452][train][INFO][train.py>_log] ==> #153000     Total Loss: 4.878    [weighted Loss:4.878    Policy Loss: 10.752   Value Loss: 4.411    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 47738      Buffer Size: 4535       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:50:53,327][train][INFO][train.py>_log] ==> #154000     Total Loss: 6.073    [weighted Loss:6.073    Policy Loss: 10.284   Value Loss: 4.576    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 47921      Buffer Size: 4499       Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:02:39,579][train][INFO][train.py>_log] ==> #155000     Total Loss: 4.218    [weighted Loss:4.218    Policy Loss: 9.798    Value Loss: 4.671    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 48093      Buffer Size: 4427       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:14:25,707][train][INFO][train.py>_log] ==> #156000     Total Loss: 4.077    [weighted Loss:4.077    Policy Loss: 9.498    Value Loss: 4.405    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 48525      Buffer Size: 4595       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:26:10,523][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.378    [weighted Loss:3.378    Policy Loss: 9.523    Value Loss: 4.629    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 48676      Buffer Size: 4567       Transition Number: 149.961 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:38:02,777][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 10.593   Value Loss: 4.350    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 48909      Buffer Size: 4590       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:49:46,881][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 10.051   Value Loss: 4.238    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 49145      Buffer Size: 4647       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:01:32,564][train][INFO][train.py>_log] ==> #160000     Total Loss: 4.404    [weighted Loss:4.404    Policy Loss: 10.163   Value Loss: 4.323    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 49353      Buffer Size: 4701       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:13:16,496][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.881    [weighted Loss:3.881    Policy Loss: 9.942    Value Loss: 4.446    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 49553      Buffer Size: 4622       Transition Number: 149.949 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:24:59,837][train][INFO][train.py>_log] ==> #162000     Total Loss: 3.524    [weighted Loss:3.524    Policy Loss: 10.599   Value Loss: 4.817    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 49736      Buffer Size: 4637       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:36:50,333][train][INFO][train.py>_log] ==> #163000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 9.527    Value Loss: 4.909    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 49933      Buffer Size: 4586       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:48:35,927][train][INFO][train.py>_log] ==> #164000     Total Loss: 4.284    [weighted Loss:4.284    Policy Loss: 9.609    Value Loss: 4.446    Reward Loss: 0.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 50112      Buffer Size: 4539       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:00:25,647][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.826    [weighted Loss:3.826    Policy Loss: 10.529   Value Loss: 4.606    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 50329      Buffer Size: 4544       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:12:16,407][train][INFO][train.py>_log] ==> #166000     Total Loss: 4.738    [weighted Loss:4.738    Policy Loss: 10.294   Value Loss: 4.945    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 50528      Buffer Size: 4588       Transition Number: 149.959 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:24:12,025][train][INFO][train.py>_log] ==> #167000     Total Loss: 5.496    [weighted Loss:5.496    Policy Loss: 9.675    Value Loss: 4.916    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 50720      Buffer Size: 4618       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:35:57,693][train][INFO][train.py>_log] ==> #168000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 10.470   Value Loss: 4.918    Reward Loss: 0.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 50969      Buffer Size: 4692       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:47:46,743][train][INFO][train.py>_log] ==> #169000     Total Loss: 5.820    [weighted Loss:5.820    Policy Loss: 10.093   Value Loss: 4.884    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 51161      Buffer Size: 4723       Transition Number: 149.946 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:59:32,843][train][INFO][train.py>_log] ==> #170000     Total Loss: 4.748    [weighted Loss:4.748    Policy Loss: 10.122   Value Loss: 4.841    Reward Loss: 0.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 51426      Buffer Size: 4805       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-02 02:11:20,100][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.982    [weighted Loss:3.982    Policy Loss: 9.428    Value Loss: 4.767    Reward Loss: 0.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 51629      Buffer Size: 4810       Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-02 02:22:58,999][train][INFO][train.py>_log] ==> #172000     Total Loss: 5.392    [weighted Loss:5.392    Policy Loss: 10.971   Value Loss: 4.577    Reward Loss: 0.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 51861      Buffer Size: 4848       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-02 02:34:43,145][train][INFO][train.py>_log] ==> #173000     Total Loss: 5.331    [weighted Loss:5.331    Policy Loss: 11.084   Value Loss: 5.093    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 52064      Buffer Size: 4859       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-02 02:46:25,462][train][INFO][train.py>_log] ==> #174000     Total Loss: 4.518    [weighted Loss:4.518    Policy Loss: 10.767   Value Loss: 4.605    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 52271      Buffer Size: 4870       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-02 02:58:10,147][train][INFO][train.py>_log] ==> #175000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 10.170   Value Loss: 5.185    Reward Loss: 0.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 52483      Buffer Size: 4868       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-02 03:09:45,108][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 9.980    Value Loss: 4.498    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 52689      Buffer Size: 4884       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-02 03:21:19,879][train][INFO][train.py>_log] ==> #177000     Total Loss: 1.795    [weighted Loss:1.795    Policy Loss: 9.635    Value Loss: 4.859    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 52872      Buffer Size: 4887       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-02 03:32:51,577][train][INFO][train.py>_log] ==> #178000     Total Loss: 4.062    [weighted Loss:4.062    Policy Loss: 9.395    Value Loss: 4.837    Reward Loss: 0.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 53078      Buffer Size: 4832       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-02 03:44:31,031][train][INFO][train.py>_log] ==> #179000     Total Loss: 3.400    [weighted Loss:3.400    Policy Loss: 10.591   Value Loss: 4.829    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 53246      Buffer Size: 4671       Transition Number: 149.948 k Batch Size: 128        Lr: 0.100   
[2021-11-02 03:56:15,336][train][INFO][train.py>_log] ==> #180000     Total Loss: 4.321    [weighted Loss:4.321    Policy Loss: 9.263    Value Loss: 4.470    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 53421      Buffer Size: 4657       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-02 04:08:02,891][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.985    [weighted Loss:2.985    Policy Loss: 9.482    Value Loss: 4.458    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 53573      Buffer Size: 4565       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-02 04:19:49,381][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 9.176    Value Loss: 4.538    Reward Loss: 0.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 53717      Buffer Size: 4475       Transition Number: 149.965 k Batch Size: 128        Lr: 0.100   
[2021-11-02 04:31:41,736][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 10.359   Value Loss: 4.971    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 53906      Buffer Size: 4454       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-02 04:43:23,207][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.648    [weighted Loss:3.648    Policy Loss: 9.032    Value Loss: 4.761    Reward Loss: 0.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 54148      Buffer Size: 4499       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-02 04:55:09,794][train][INFO][train.py>_log] ==> #185000     Total Loss: 3.132    [weighted Loss:3.132    Policy Loss: 9.182    Value Loss: 4.790    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 54404      Buffer Size: 4548       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-02 05:06:51,604][train][INFO][train.py>_log] ==> #186000     Total Loss: 4.546    [weighted Loss:4.546    Policy Loss: 10.242   Value Loss: 4.651    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 54575      Buffer Size: 4537       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-02 05:18:33,826][train][INFO][train.py>_log] ==> #187000     Total Loss: 4.308    [weighted Loss:4.308    Policy Loss: 9.583    Value Loss: 4.732    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 54799      Buffer Size: 4560       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-02 05:30:02,235][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 10.166   Value Loss: 4.553    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 55039      Buffer Size: 4610       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-02 05:41:36,546][train][INFO][train.py>_log] ==> #189000     Total Loss: 5.191    [weighted Loss:5.191    Policy Loss: 9.881    Value Loss: 4.630    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 55248      Buffer Size: 4626       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-02 05:53:05,461][train][INFO][train.py>_log] ==> #190000     Total Loss: 5.006    [weighted Loss:5.006    Policy Loss: 10.183   Value Loss: 4.675    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 55453      Buffer Size: 4614       Transition Number: 149.939 k Batch Size: 128        Lr: 0.100   
[2021-11-02 06:04:41,963][train][INFO][train.py>_log] ==> #191000     Total Loss: 2.384    [weighted Loss:2.384    Policy Loss: 10.034   Value Loss: 4.827    Reward Loss: 0.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 55632      Buffer Size: 4587       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-02 06:16:17,236][train][INFO][train.py>_log] ==> #192000     Total Loss: 5.113    [weighted Loss:5.113    Policy Loss: 9.903    Value Loss: 4.500    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 55826      Buffer Size: 4564       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-02 06:27:44,789][train][INFO][train.py>_log] ==> #193000     Total Loss: 4.003    [weighted Loss:4.003    Policy Loss: 9.113    Value Loss: 4.959    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 56217      Buffer Size: 4723       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-02 06:39:15,652][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 9.463    Value Loss: 4.814    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 56403      Buffer Size: 4699       Transition Number: 150.016 k Batch Size: 128        Lr: 0.100   
[2021-11-02 06:50:41,690][train][INFO][train.py>_log] ==> #195000     Total Loss: 5.256    [weighted Loss:5.256    Policy Loss: 10.935   Value Loss: 4.900    Reward Loss: 0.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 56678      Buffer Size: 4759       Transition Number: 149.965 k Batch Size: 128        Lr: 0.100   
[2021-11-02 07:02:17,687][train][INFO][train.py>_log] ==> #196000     Total Loss: 4.427    [weighted Loss:4.427    Policy Loss: 9.765    Value Loss: 4.587    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 56869      Buffer Size: 4736       Transition Number: 150.070 k Batch Size: 128        Lr: 0.100   
[2021-11-02 07:13:53,214][train][INFO][train.py>_log] ==> #197000     Total Loss: 4.382    [weighted Loss:4.382    Policy Loss: 9.654    Value Loss: 4.582    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 57058      Buffer Size: 4720       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-02 07:25:27,497][train][INFO][train.py>_log] ==> #198000     Total Loss: 4.030    [weighted Loss:4.030    Policy Loss: 9.002    Value Loss: 4.661    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 57395      Buffer Size: 4823       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-02 07:37:00,104][train][INFO][train.py>_log] ==> #199000     Total Loss: 5.088    [weighted Loss:5.088    Policy Loss: 10.192   Value Loss: 4.613    Reward Loss: 0.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 57732      Buffer Size: 4952       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-02 07:48:35,938][train][INFO][train.py>_log] ==> #200000     Total Loss: 5.156    [weighted Loss:5.156    Policy Loss: 10.695   Value Loss: 4.694    Reward Loss: 0.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 57926      Buffer Size: 4945       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-02 08:00:03,836][train][INFO][train.py>_log] ==> #201000     Total Loss: 4.677    [weighted Loss:4.677    Policy Loss: 9.986    Value Loss: 4.764    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 58114      Buffer Size: 4953       Transition Number: 150.011 k Batch Size: 128        Lr: 0.100   
[2021-11-02 08:11:33,321][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 10.823   Value Loss: 4.582    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 58295      Buffer Size: 4954       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-02 08:23:02,689][train][INFO][train.py>_log] ==> #203000     Total Loss: 3.430    [weighted Loss:3.430    Policy Loss: 10.631   Value Loss: 4.857    Reward Loss: 0.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 58474      Buffer Size: 4985       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-02 08:34:37,892][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.735    [weighted Loss:2.735    Policy Loss: 9.680    Value Loss: 4.621    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 58640      Buffer Size: 5015       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-02 08:46:14,210][train][INFO][train.py>_log] ==> #205000     Total Loss: 4.028    [weighted Loss:4.028    Policy Loss: 9.796    Value Loss: 4.631    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 58832      Buffer Size: 5054       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-02 08:57:55,309][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.146    [weighted Loss:3.146    Policy Loss: 9.409    Value Loss: 4.798    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 59049      Buffer Size: 5090       Transition Number: 149.964 k Batch Size: 128        Lr: 0.100   
[2021-11-02 09:09:25,917][train][INFO][train.py>_log] ==> #207000     Total Loss: 4.393    [weighted Loss:4.393    Policy Loss: 9.220    Value Loss: 4.711    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 59194      Buffer Size: 5025       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-02 09:20:50,061][train][INFO][train.py>_log] ==> #208000     Total Loss: 4.708    [weighted Loss:4.708    Policy Loss: 10.645   Value Loss: 4.617    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 59407      Buffer Size: 4994       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-02 09:32:18,028][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 10.204   Value Loss: 4.598    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 59587      Buffer Size: 5006       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-02 09:43:50,165][train][INFO][train.py>_log] ==> #210000     Total Loss: 4.082    [weighted Loss:4.082    Policy Loss: 10.302   Value Loss: 4.533    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 59772      Buffer Size: 4967       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-02 09:55:18,805][train][INFO][train.py>_log] ==> #211000     Total Loss: 5.549    [weighted Loss:5.549    Policy Loss: 10.877   Value Loss: 4.770    Reward Loss: 0.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 59970      Buffer Size: 4916       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-02 10:06:45,377][train][INFO][train.py>_log] ==> #212000     Total Loss: 4.636    [weighted Loss:4.636    Policy Loss: 10.381   Value Loss: 4.593    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 60136      Buffer Size: 4891       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-02 10:18:15,550][train][INFO][train.py>_log] ==> #213000     Total Loss: 3.966    [weighted Loss:3.966    Policy Loss: 11.051   Value Loss: 4.979    Reward Loss: 0.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 60331      Buffer Size: 4877       Transition Number: 150.039 k Batch Size: 128        Lr: 0.100   
[2021-11-02 10:29:47,217][train][INFO][train.py>_log] ==> #214000     Total Loss: 4.459    [weighted Loss:4.459    Policy Loss: 9.886    Value Loss: 4.522    Reward Loss: 0.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 60530      Buffer Size: 4894       Transition Number: 149.938 k Batch Size: 128        Lr: 0.100   
[2021-11-02 10:41:15,422][train][INFO][train.py>_log] ==> #215000     Total Loss: 4.434    [weighted Loss:4.434    Policy Loss: 10.071   Value Loss: 4.642    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 60712      Buffer Size: 4871       Transition Number: 149.970 k Batch Size: 128        Lr: 0.100   
[2021-11-02 10:52:44,415][train][INFO][train.py>_log] ==> #216000     Total Loss: 4.597    [weighted Loss:4.597    Policy Loss: 10.436   Value Loss: 4.483    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 60920      Buffer Size: 4702       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-02 11:04:20,279][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 8.837    Value Loss: 4.565    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 61114      Buffer Size: 4706       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-02 11:15:47,639][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.846    [weighted Loss:2.846    Policy Loss: 10.811   Value Loss: 4.480    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 61299      Buffer Size: 4612       Transition Number: 149.957 k Batch Size: 128        Lr: 0.100   
[2021-11-02 11:27:16,750][train][INFO][train.py>_log] ==> #219000     Total Loss: 5.244    [weighted Loss:5.244    Policy Loss: 10.797   Value Loss: 4.757    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 61468      Buffer Size: 4592       Transition Number: 149.966 k Batch Size: 128        Lr: 0.100   
[2021-11-02 11:38:47,233][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.738    [weighted Loss:3.738    Policy Loss: 9.622    Value Loss: 4.889    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 61648      Buffer Size: 4584       Transition Number: 149.945 k Batch Size: 128        Lr: 0.100   
[2021-11-02 11:50:21,337][train][INFO][train.py>_log] ==> #221000     Total Loss: 3.715    [weighted Loss:3.715    Policy Loss: 9.766    Value Loss: 4.567    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 61840      Buffer Size: 4469       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-02 12:01:59,953][train][INFO][train.py>_log] ==> #222000     Total Loss: 3.619    [weighted Loss:3.619    Policy Loss: 9.360    Value Loss: 4.851    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 62072      Buffer Size: 4364       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-02 12:13:29,675][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.698    [weighted Loss:3.698    Policy Loss: 10.678   Value Loss: 4.626    Reward Loss: 0.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 62226      Buffer Size: 4318       Transition Number: 149.941 k Batch Size: 128        Lr: 0.100   
[2021-11-02 12:25:07,265][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.306    [weighted Loss:2.306    Policy Loss: 9.630    Value Loss: 4.916    Reward Loss: 0.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 62383      Buffer Size: 4292       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-02 12:36:50,187][train][INFO][train.py>_log] ==> #225000     Total Loss: 3.161    [weighted Loss:3.161    Policy Loss: 9.929    Value Loss: 4.546    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 62553      Buffer Size: 4278       Transition Number: 150.034 k Batch Size: 128        Lr: 0.100   
[2021-11-02 12:48:35,493][train][INFO][train.py>_log] ==> #226000     Total Loss: 4.298    [weighted Loss:4.298    Policy Loss: 9.441    Value Loss: 4.699    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 62712      Buffer Size: 4246       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-02 13:00:21,332][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.812    [weighted Loss:3.812    Policy Loss: 10.580   Value Loss: 4.699    Reward Loss: 0.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 62883      Buffer Size: 4237       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-02 13:12:05,805][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.336    [weighted Loss:2.336    Policy Loss: 9.562    Value Loss: 4.832    Reward Loss: 0.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 63067      Buffer Size: 4210       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-02 13:23:52,393][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.510    [weighted Loss:3.510    Policy Loss: 10.312   Value Loss: 5.041    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 63276      Buffer Size: 4200       Transition Number: 149.952 k Batch Size: 128        Lr: 0.100   
[2021-11-02 13:35:36,287][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 10.262   Value Loss: 4.446    Reward Loss: 0.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 63461      Buffer Size: 4223       Transition Number: 149.935 k Batch Size: 128        Lr: 0.100   
[2021-11-02 13:47:19,376][train][INFO][train.py>_log] ==> #231000     Total Loss: 4.849    [weighted Loss:4.849    Policy Loss: 10.016   Value Loss: 4.615    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 63651      Buffer Size: 4187       Transition Number: 150.062 k Batch Size: 128        Lr: 0.100   
[2021-11-02 13:59:06,320][train][INFO][train.py>_log] ==> #232000     Total Loss: 4.981    [weighted Loss:4.981    Policy Loss: 10.476   Value Loss: 4.996    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 64020      Buffer Size: 4358       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-02 14:10:50,695][train][INFO][train.py>_log] ==> #233000     Total Loss: 3.945    [weighted Loss:3.945    Policy Loss: 10.136   Value Loss: 4.911    Reward Loss: 0.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 64209      Buffer Size: 4376       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-02 14:22:29,971][train][INFO][train.py>_log] ==> #234000     Total Loss: 4.325    [weighted Loss:4.325    Policy Loss: 10.425   Value Loss: 4.813    Reward Loss: 0.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 64394      Buffer Size: 4376       Transition Number: 149.945 k Batch Size: 128        Lr: 0.100   
[2021-11-02 14:34:12,832][train][INFO][train.py>_log] ==> #235000     Total Loss: 4.333    [weighted Loss:4.333    Policy Loss: 8.438    Value Loss: 4.835    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 64607      Buffer Size: 4416       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-02 14:45:57,093][train][INFO][train.py>_log] ==> #236000     Total Loss: 4.056    [weighted Loss:4.056    Policy Loss: 9.798    Value Loss: 4.748    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 64859      Buffer Size: 4453       Transition Number: 150.064 k Batch Size: 128        Lr: 0.100   
[2021-11-02 14:57:34,102][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.771    [weighted Loss:3.771    Policy Loss: 9.718    Value Loss: 4.711    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 65137      Buffer Size: 4538       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-02 15:09:21,617][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 9.962    Value Loss: 4.852    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 65350      Buffer Size: 4547       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-02 15:21:04,112][train][INFO][train.py>_log] ==> #239000     Total Loss: 4.728    [weighted Loss:4.728    Policy Loss: 10.752   Value Loss: 4.722    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 65643      Buffer Size: 4621       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-02 15:32:47,008][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 9.768    Value Loss: 4.668    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 65855      Buffer Size: 4648       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-02 15:44:25,742][train][INFO][train.py>_log] ==> #241000     Total Loss: 4.352    [weighted Loss:4.352    Policy Loss: 9.428    Value Loss: 4.708    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 65985      Buffer Size: 4604       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-02 15:56:00,931][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.993    [weighted Loss:3.993    Policy Loss: 9.841    Value Loss: 4.671    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 66192      Buffer Size: 4635       Transition Number: 149.946 k Batch Size: 128        Lr: 0.100   
[2021-11-02 16:07:46,645][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.991    [weighted Loss:2.991    Policy Loss: 9.733    Value Loss: 4.630    Reward Loss: 0.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 66385      Buffer Size: 4630       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-02 16:19:27,537][train][INFO][train.py>_log] ==> #244000     Total Loss: 4.214    [weighted Loss:4.214    Policy Loss: 10.064   Value Loss: 4.810    Reward Loss: 0.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 66587      Buffer Size: 4625       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-02 16:31:09,646][train][INFO][train.py>_log] ==> #245000     Total Loss: 4.535    [weighted Loss:4.535    Policy Loss: 9.819    Value Loss: 4.764    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 66762      Buffer Size: 4604       Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-02 16:42:51,289][train][INFO][train.py>_log] ==> #246000     Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 9.938    Value Loss: 4.913    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 66925      Buffer Size: 4612       Transition Number: 149.939 k Batch Size: 128        Lr: 0.100   
[2021-11-02 16:54:29,646][train][INFO][train.py>_log] ==> #247000     Total Loss: 3.561    [weighted Loss:3.561    Policy Loss: 9.656    Value Loss: 5.077    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 67138      Buffer Size: 4653       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-02 17:06:07,503][train][INFO][train.py>_log] ==> #248000     Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 9.424    Value Loss: 4.664    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 67299      Buffer Size: 4669       Transition Number: 149.971 k Batch Size: 128        Lr: 0.100   
[2021-11-02 17:17:42,788][train][INFO][train.py>_log] ==> #249000     Total Loss: 4.480    [weighted Loss:4.480    Policy Loss: 9.979    Value Loss: 4.740    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 67453      Buffer Size: 4656       Transition Number: 149.955 k Batch Size: 128        Lr: 0.100   
[2021-11-02 17:29:19,609][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 9.396    Value Loss: 4.654    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 67611      Buffer Size: 4635       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-02 17:41:07,392][train][INFO][train.py>_log] ==> #251000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 9.821    Value Loss: 4.628    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 67741      Buffer Size: 4595       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-02 17:52:54,850][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.926    [weighted Loss:2.926    Policy Loss: 10.372   Value Loss: 4.595    Reward Loss: 0.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 67874      Buffer Size: 4522       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-02 18:04:40,488][train][INFO][train.py>_log] ==> #253000     Total Loss: 4.138    [weighted Loss:4.138    Policy Loss: 9.301    Value Loss: 4.553    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 68054      Buffer Size: 4526       Transition Number: 149.953 k Batch Size: 128        Lr: 0.100   
[2021-11-02 18:16:22,460][train][INFO][train.py>_log] ==> #254000     Total Loss: 3.734    [weighted Loss:3.734    Policy Loss: 9.285    Value Loss: 4.469    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 68180      Buffer Size: 4430       Transition Number: 150.033 k Batch Size: 128        Lr: 0.100   
[2021-11-02 18:28:06,302][train][INFO][train.py>_log] ==> #255000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 9.171    Value Loss: 4.528    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 68368      Buffer Size: 4300       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-02 18:39:52,544][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.859    [weighted Loss:2.859    Policy Loss: 9.424    Value Loss: 5.000    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 68528      Buffer Size: 4274       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-02 18:51:38,335][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 9.417    Value Loss: 4.552    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 68687      Buffer Size: 4225       Transition Number: 149.979 k Batch Size: 128        Lr: 0.100   
[2021-11-02 19:03:25,257][train][INFO][train.py>_log] ==> #258000     Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 9.641    Value Loss: 5.096    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 68920      Buffer Size: 4217       Transition Number: 149.970 k Batch Size: 128        Lr: 0.100   
[2021-11-02 19:15:08,524][train][INFO][train.py>_log] ==> #259000     Total Loss: 5.300    [weighted Loss:5.300    Policy Loss: 10.402   Value Loss: 4.691    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 69112      Buffer Size: 4157       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-02 19:27:00,473][train][INFO][train.py>_log] ==> #260000     Total Loss: 4.304    [weighted Loss:4.304    Policy Loss: 9.141    Value Loss: 4.861    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 69280      Buffer Size: 4066       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-02 19:38:44,745][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 10.557   Value Loss: 4.756    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 69412      Buffer Size: 3964       Transition Number: 149.985 k Batch Size: 128        Lr: 0.100   
[2021-11-02 19:50:39,608][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.843    [weighted Loss:2.843    Policy Loss: 9.575    Value Loss: 4.964    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 69580      Buffer Size: 3872       Transition Number: 150.068 k Batch Size: 128        Lr: 0.100   
[2021-11-02 20:02:24,384][train][INFO][train.py>_log] ==> #263000     Total Loss: 3.024    [weighted Loss:3.024    Policy Loss: 10.217   Value Loss: 4.992    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 69722      Buffer Size: 3822       Transition Number: 149.965 k Batch Size: 128        Lr: 0.100   
[2021-11-02 20:14:09,986][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.296    [weighted Loss:3.296    Policy Loss: 10.561   Value Loss: 4.749    Reward Loss: 0.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 69918      Buffer Size: 3862       Transition Number: 149.969 k Batch Size: 128        Lr: 0.100   
[2021-11-02 20:25:57,238][train][INFO][train.py>_log] ==> #265000     Total Loss: 3.970    [weighted Loss:3.970    Policy Loss: 10.125   Value Loss: 4.858    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 70112      Buffer Size: 3852       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-02 20:37:44,273][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.358    [weighted Loss:1.358    Policy Loss: 9.167    Value Loss: 4.918    Reward Loss: 0.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 70285      Buffer Size: 3822       Transition Number: 149.969 k Batch Size: 128        Lr: 0.100   
[2021-11-02 20:49:36,352][train][INFO][train.py>_log] ==> #267000     Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 9.665    Value Loss: 4.748    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 70441      Buffer Size: 3792       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-02 21:01:21,755][train][INFO][train.py>_log] ==> #268000     Total Loss: 5.166    [weighted Loss:5.166    Policy Loss: 9.942    Value Loss: 5.109    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 70635      Buffer Size: 3801       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-02 21:13:20,482][train][INFO][train.py>_log] ==> #269000     Total Loss: 4.264    [weighted Loss:4.264    Policy Loss: 9.404    Value Loss: 4.567    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 70785      Buffer Size: 3769       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-02 21:25:08,659][train][INFO][train.py>_log] ==> #270000     Total Loss: 4.404    [weighted Loss:4.404    Policy Loss: 9.571    Value Loss: 4.662    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 70983      Buffer Size: 3760       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-02 21:37:05,294][train][INFO][train.py>_log] ==> #271000     Total Loss: 1.535    [weighted Loss:1.535    Policy Loss: 8.911    Value Loss: 4.638    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 71123      Buffer Size: 3731       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-02 21:48:58,343][train][INFO][train.py>_log] ==> #272000     Total Loss: 4.787    [weighted Loss:4.787    Policy Loss: 10.198   Value Loss: 4.427    Reward Loss: 0.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 71379      Buffer Size: 3828       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-02 22:00:59,025][train][INFO][train.py>_log] ==> #273000     Total Loss: 4.045    [weighted Loss:4.045    Policy Loss: 9.566    Value Loss: 4.666    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 71561      Buffer Size: 3860       Transition Number: 149.961 k Batch Size: 128        Lr: 0.100   
[2021-11-02 22:12:56,613][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.728    [weighted Loss:3.728    Policy Loss: 8.956    Value Loss: 5.105    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 71730      Buffer Size: 3884       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-02 22:24:49,796][train][INFO][train.py>_log] ==> #275000     Total Loss: 3.710    [weighted Loss:3.710    Policy Loss: 9.604    Value Loss: 4.574    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 71897      Buffer Size: 3878       Transition Number: 149.965 k Batch Size: 128        Lr: 0.100   
[2021-11-02 22:36:44,486][train][INFO][train.py>_log] ==> #276000     Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 8.993    Value Loss: 4.766    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 72140      Buffer Size: 3983       Transition Number: 149.951 k Batch Size: 128        Lr: 0.100   
[2021-11-02 22:48:45,862][train][INFO][train.py>_log] ==> #277000     Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 9.809    Value Loss: 4.709    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 72296      Buffer Size: 3966       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-02 23:00:37,853][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 10.439   Value Loss: 4.899    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 72455      Buffer Size: 3949       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-02 23:12:39,779][train][INFO][train.py>_log] ==> #279000     Total Loss: 3.888    [weighted Loss:3.888    Policy Loss: 7.942    Value Loss: 4.737    Reward Loss: 0.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 72639      Buffer Size: 3971       Transition Number: 149.985 k Batch Size: 128        Lr: 0.100   
[2021-11-02 23:24:35,734][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.206    [weighted Loss:3.206    Policy Loss: 9.234    Value Loss: 4.685    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 72833      Buffer Size: 3946       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-02 23:36:28,371][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.597    [weighted Loss:2.597    Policy Loss: 9.533    Value Loss: 4.719    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 72973      Buffer Size: 3890       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-02 23:48:23,613][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.548    [weighted Loss:2.548    Policy Loss: 9.075    Value Loss: 5.039    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 73172      Buffer Size: 3917       Transition Number: 149.944 k Batch Size: 128        Lr: 0.100   
[2021-11-03 00:00:24,728][train][INFO][train.py>_log] ==> #283000     Total Loss: 3.697    [weighted Loss:3.697    Policy Loss: 9.538    Value Loss: 4.940    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 73293      Buffer Size: 3894       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-03 00:12:18,249][train][INFO][train.py>_log] ==> #284000     Total Loss: 0.908    [weighted Loss:0.908    Policy Loss: 8.598    Value Loss: 4.876    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 73561      Buffer Size: 3985       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-03 00:24:16,236][train][INFO][train.py>_log] ==> #285000     Total Loss: 3.499    [weighted Loss:3.499    Policy Loss: 8.564    Value Loss: 5.000    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 73694      Buffer Size: 3980       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-03 00:36:17,391][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.730    [weighted Loss:3.730    Policy Loss: 8.462    Value Loss: 4.978    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 73831      Buffer Size: 3905       Transition Number: 149.960 k Batch Size: 128        Lr: 0.100   
[2021-11-03 00:48:22,384][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 8.640    Value Loss: 5.308    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 74026      Buffer Size: 3896       Transition Number: 150.003 k Batch Size: 128        Lr: 0.100   
[2021-11-03 01:00:32,963][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 7.356    Value Loss: 5.124    Reward Loss: 0.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 74163      Buffer Size: 3854       Transition Number: 149.945 k Batch Size: 128        Lr: 0.100   
[2021-11-03 01:12:38,946][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 7.703    Value Loss: 4.932    Reward Loss: 0.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 74302      Buffer Size: 3830       Transition Number: 149.971 k Batch Size: 128        Lr: 0.100   
[2021-11-03 01:24:43,668][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.764    [weighted Loss:3.764    Policy Loss: 8.664    Value Loss: 4.826    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 74438      Buffer Size: 3775       Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-03 01:36:52,011][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 7.685    Value Loss: 4.778    Reward Loss: 0.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 74570      Buffer Size: 3741       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-03 01:49:01,512][train][INFO][train.py>_log] ==> #292000     Total Loss: 1.872    [weighted Loss:1.872    Policy Loss: 8.477    Value Loss: 4.572    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 74726      Buffer Size: 3715       Transition Number: 149.979 k Batch Size: 128        Lr: 0.100   
[2021-11-03 02:01:06,561][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 7.339    Value Loss: 4.606    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 74874      Buffer Size: 3689       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-03 02:13:14,676][train][INFO][train.py>_log] ==> #294000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 8.147    Value Loss: 4.498    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 75019      Buffer Size: 3598       Transition Number: 150.020 k Batch Size: 128        Lr: 0.100   
[2021-11-03 02:25:29,109][train][INFO][train.py>_log] ==> #295000     Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 7.586    Value Loss: 4.599    Reward Loss: 0.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 75164      Buffer Size: 3544       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-03 02:37:45,658][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 7.521    Value Loss: 4.852    Reward Loss: 0.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 75307      Buffer Size: 3512       Transition Number: 149.956 k Batch Size: 128        Lr: 0.100   
[2021-11-03 02:49:54,444][train][INFO][train.py>_log] ==> #297000     Total Loss: 2.682    [weighted Loss:2.682    Policy Loss: 7.850    Value Loss: 4.972    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 75453      Buffer Size: 3457       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-03 03:01:59,146][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 8.514    Value Loss: 4.611    Reward Loss: 0.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 75605      Buffer Size: 3390       Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-03 03:14:05,935][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 7.049    Value Loss: 4.676    Reward Loss: 0.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 75795      Buffer Size: 3417       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-03 03:26:07,289][train][INFO][train.py>_log] ==> #300000     Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 7.726    Value Loss: 4.936    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 75982      Buffer Size: 3433       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-03 03:38:13,252][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.798    [weighted Loss:2.798    Policy Loss: 7.512    Value Loss: 5.017    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 76127      Buffer Size: 3397       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-03 03:50:19,283][train][INFO][train.py>_log] ==> #302000     Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 8.211    Value Loss: 4.476    Reward Loss: 0.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 76281      Buffer Size: 3366       Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-11-03 04:02:29,934][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 9.044    Value Loss: 5.302    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 76447      Buffer Size: 3359       Transition Number: 150.057 k Batch Size: 128        Lr: 0.100   
[2021-11-03 04:14:36,391][train][INFO][train.py>_log] ==> #304000     Total Loss: 4.204    [weighted Loss:4.204    Policy Loss: 8.085    Value Loss: 4.646    Reward Loss: 0.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 76601      Buffer Size: 3362       Transition Number: 150.047 k Batch Size: 128        Lr: 0.100   
[2021-11-03 04:26:44,731][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.444    [weighted Loss:2.444    Policy Loss: 7.686    Value Loss: 4.813    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 76760      Buffer Size: 3340       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-03 04:38:50,791][train][INFO][train.py>_log] ==> #306000     Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 7.517    Value Loss: 4.839    Reward Loss: 0.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 76938      Buffer Size: 3311       Transition Number: 149.966 k Batch Size: 128        Lr: 0.100   
[2021-11-03 04:50:54,749][train][INFO][train.py>_log] ==> #307000     Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 7.779    Value Loss: 4.894    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 77097      Buffer Size: 3324       Transition Number: 149.970 k Batch Size: 128        Lr: 0.100   
[2021-11-03 05:03:02,017][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 7.582    Value Loss: 4.793    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 77241      Buffer Size: 3303       Transition Number: 149.948 k Batch Size: 128        Lr: 0.100   
[2021-11-03 05:15:07,794][train][INFO][train.py>_log] ==> #309000     Total Loss: 3.900    [weighted Loss:3.900    Policy Loss: 8.887    Value Loss: 5.089    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 77744      Buffer Size: 3641       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-03 05:27:13,206][train][INFO][train.py>_log] ==> #310000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 8.114    Value Loss: 4.657    Reward Loss: 0.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 77932      Buffer Size: 3692       Transition Number: 149.972 k Batch Size: 128        Lr: 0.100   
[2021-11-03 05:39:15,702][train][INFO][train.py>_log] ==> #311000     Total Loss: 3.669    [weighted Loss:3.669    Policy Loss: 8.785    Value Loss: 4.828    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 78116      Buffer Size: 3731       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-03 05:51:15,645][train][INFO][train.py>_log] ==> #312000     Total Loss: 3.860    [weighted Loss:3.860    Policy Loss: 8.751    Value Loss: 4.948    Reward Loss: 0.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 78251      Buffer Size: 3731       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-03 06:03:25,987][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.891    [weighted Loss:3.891    Policy Loss: 8.030    Value Loss: 4.486    Reward Loss: 0.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 78372      Buffer Size: 3694       Transition Number: 149.947 k Batch Size: 128        Lr: 0.100   
[2021-11-03 06:15:32,324][train][INFO][train.py>_log] ==> #314000     Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 7.888    Value Loss: 4.685    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 78511      Buffer Size: 3675       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-03 06:27:49,186][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 7.961    Value Loss: 4.982    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 78655      Buffer Size: 3661       Transition Number: 149.930 k Batch Size: 128        Lr: 0.100   
[2021-11-03 06:40:00,854][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 7.472    Value Loss: 5.002    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 78793      Buffer Size: 3654       Transition Number: 149.933 k Batch Size: 128        Lr: 0.100   
[2021-11-03 06:52:07,278][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 8.146    Value Loss: 5.009    Reward Loss: 0.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 78937      Buffer Size: 3674       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-03 07:04:16,162][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.926    [weighted Loss:2.926    Policy Loss: 7.154    Value Loss: 4.919    Reward Loss: 0.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 79082      Buffer Size: 3666       Transition Number: 149.964 k Batch Size: 128        Lr: 0.100   
[2021-11-03 07:16:21,584][train][INFO][train.py>_log] ==> #319000     Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 7.783    Value Loss: 4.951    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 79248      Buffer Size: 3690       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-03 07:28:23,117][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 8.542    Value Loss: 4.579    Reward Loss: 0.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 79417      Buffer Size: 3692       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 07:40:27,289][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.808    [weighted Loss:2.808    Policy Loss: 7.931    Value Loss: 4.913    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 79564      Buffer Size: 3626       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-03 07:52:31,349][train][INFO][train.py>_log] ==> #322000     Total Loss: 4.017    [weighted Loss:4.017    Policy Loss: 8.372    Value Loss: 4.738    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 79709      Buffer Size: 3621       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-03 08:04:34,401][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 7.335    Value Loss: 4.757    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 79863      Buffer Size: 3630       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-03 08:16:35,731][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 8.656    Value Loss: 4.912    Reward Loss: 0.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 80024      Buffer Size: 3640       Transition Number: 149.946 k Batch Size: 128        Lr: 0.100   
[2021-11-03 08:28:39,404][train][INFO][train.py>_log] ==> #325000     Total Loss: 3.597    [weighted Loss:3.597    Policy Loss: 9.693    Value Loss: 4.841    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 80165      Buffer Size: 3610       Transition Number: 150.052 k Batch Size: 128        Lr: 0.100   
[2021-11-03 08:40:42,151][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 7.766    Value Loss: 4.885    Reward Loss: 0.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 80320      Buffer Size: 3617       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-03 08:52:46,108][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.649    [weighted Loss:2.649    Policy Loss: 8.051    Value Loss: 5.031    Reward Loss: 0.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 80460      Buffer Size: 3583       Transition Number: 149.943 k Batch Size: 128        Lr: 0.100   
[2021-11-03 09:04:59,302][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 8.079    Value Loss: 4.788    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 80609      Buffer Size: 3571       Transition Number: 149.958 k Batch Size: 128        Lr: 0.100   
[2021-11-03 09:17:04,779][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 6.933    Value Loss: 4.503    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 80755      Buffer Size: 3570       Transition Number: 149.936 k Batch Size: 128        Lr: 0.100   
[2021-11-03 09:29:12,380][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 8.157    Value Loss: 4.823    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 80907      Buffer Size: 3379       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-03 09:41:24,585][train][INFO][train.py>_log] ==> #331000     Total Loss: 3.545    [weighted Loss:3.545    Policy Loss: 8.814    Value Loss: 5.132    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 81057      Buffer Size: 3225       Transition Number: 149.964 k Batch Size: 128        Lr: 0.100   
[2021-11-03 09:53:37,087][train][INFO][train.py>_log] ==> #332000     Total Loss: 1.005    [weighted Loss:1.005    Policy Loss: 7.602    Value Loss: 4.590    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 81189      Buffer Size: 3167       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:05:47,277][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 8.749    Value Loss: 4.837    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 81338      Buffer Size: 3153       Transition Number: 150.017 k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:18:03,528][train][INFO][train.py>_log] ==> #334000     Total Loss: 4.342    [weighted Loss:4.342    Policy Loss: 9.374    Value Loss: 4.798    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 81599      Buffer Size: 3286       Transition Number: 149.971 k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:30:11,268][train][INFO][train.py>_log] ==> #335000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 9.126    Value Loss: 4.850    Reward Loss: 0.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 81735      Buffer Size: 3305       Transition Number: 149.933 k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:42:14,144][train][INFO][train.py>_log] ==> #336000     Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 8.695    Value Loss: 4.865    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 81889      Buffer Size: 3329       Transition Number: 149.958 k Batch Size: 128        Lr: 0.100   
[2021-11-03 10:54:17,140][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 9.119    Value Loss: 4.770    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 82032      Buffer Size: 3340       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:06:26,745][train][INFO][train.py>_log] ==> #338000     Total Loss: 3.111    [weighted Loss:3.111    Policy Loss: 9.008    Value Loss: 4.569    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 82175      Buffer Size: 3344       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:18:32,746][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.046    [weighted Loss:2.046    Policy Loss: 9.640    Value Loss: 4.983    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 82327      Buffer Size: 3352       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:30:36,498][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 9.318    Value Loss: 4.836    Reward Loss: 0.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 82468      Buffer Size: 3339       Transition Number: 149.979 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:42:47,825][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 9.252    Value Loss: 4.851    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 82594      Buffer Size: 3281       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-03 11:55:01,307][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 8.568    Value Loss: 4.875    Reward Loss: 0.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 82719      Buffer Size: 3234       Transition Number: 149.954 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:07:22,169][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 7.580    Value Loss: 4.786    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 82847      Buffer Size: 3191       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:19:54,679][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 8.604    Value Loss: 4.868    Reward Loss: 0.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 82986      Buffer Size: 3163       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:32:18,738][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 7.194    Value Loss: 5.172    Reward Loss: 0.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 83123      Buffer Size: 3106       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:44:42,122][train][INFO][train.py>_log] ==> #346000     Total Loss: 1.486    [weighted Loss:1.486    Policy Loss: 7.863    Value Loss: 4.672    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 83259      Buffer Size: 3093       Transition Number: 150.048 k Batch Size: 128        Lr: 0.100   
[2021-11-03 12:56:59,476][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 6.943    Value Loss: 5.041    Reward Loss: 0.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 83416      Buffer Size: 3074       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:09:25,867][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 6.428    Value Loss: 4.526    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 83541      Buffer Size: 3045       Transition Number: 149.980 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:21:46,452][train][INFO][train.py>_log] ==> #349000     Total Loss: 1.836    [weighted Loss:1.836    Policy Loss: 7.221    Value Loss: 4.848    Reward Loss: 0.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 83668      Buffer Size: 3011       Transition Number: 149.938 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:34:08,353][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 6.778    Value Loss: 4.706    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 83813      Buffer Size: 2995       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:46:39,432][train][INFO][train.py>_log] ==> #351000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 6.810    Value Loss: 4.722    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 83973      Buffer Size: 2990       Transition Number: 149.930 k Batch Size: 128        Lr: 0.100   
[2021-11-03 13:59:03,310][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 7.017    Value Loss: 4.728    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 84190      Buffer Size: 3053       Transition Number: 149.945 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:11:24,305][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 7.097    Value Loss: 4.699    Reward Loss: 0.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 84349      Buffer Size: 3062       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:23:45,359][train][INFO][train.py>_log] ==> #354000     Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 7.018    Value Loss: 4.918    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 84522      Buffer Size: 3024       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:36:06,536][train][INFO][train.py>_log] ==> #355000     Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 6.600    Value Loss: 4.649    Reward Loss: 0.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 84664      Buffer Size: 2970       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-03 14:48:27,594][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 7.031    Value Loss: 4.802    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 84797      Buffer Size: 2945       Transition Number: 149.951 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:00:46,719][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 7.420    Value Loss: 4.966    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 84943      Buffer Size: 2934       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:13:02,971][train][INFO][train.py>_log] ==> #358000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 7.021    Value Loss: 4.846    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 85093      Buffer Size: 2929       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:25:21,212][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.890    [weighted Loss:2.890    Policy Loss: 7.567    Value Loss: 4.889    Reward Loss: 0.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 85235      Buffer Size: 2904       Transition Number: 149.941 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:37:36,165][train][INFO][train.py>_log] ==> #360000     Total Loss: 3.207    [weighted Loss:3.207    Policy Loss: 7.382    Value Loss: 4.502    Reward Loss: 0.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 85378      Buffer Size: 2909       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-03 15:49:55,204][train][INFO][train.py>_log] ==> #361000     Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 6.753    Value Loss: 4.654    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 85512      Buffer Size: 2916       Transition Number: 150.028 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:02:15,209][train][INFO][train.py>_log] ==> #362000     Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 7.255    Value Loss: 5.355    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 85660      Buffer Size: 2941       Transition Number: 149.939 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:14:48,555][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 6.930    Value Loss: 4.754    Reward Loss: 0.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 85813      Buffer Size: 2971       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:26:59,953][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.812    [weighted Loss:2.812    Policy Loss: 7.458    Value Loss: 4.551    Reward Loss: 0.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 85976      Buffer Size: 3012       Transition Number: 149.948 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:39:14,272][train][INFO][train.py>_log] ==> #365000     Total Loss: 2.305    [weighted Loss:2.305    Policy Loss: 7.339    Value Loss: 5.137    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 86127      Buffer Size: 3036       Transition Number: 149.955 k Batch Size: 128        Lr: 0.100   
[2021-11-03 16:51:28,534][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 6.440    Value Loss: 4.611    Reward Loss: 0.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 86256      Buffer Size: 3043       Transition Number: 149.961 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:03:44,522][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.623    [weighted Loss:2.623    Policy Loss: 7.750    Value Loss: 4.959    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 86412      Buffer Size: 3059       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:16:01,968][train][INFO][train.py>_log] ==> #368000     Total Loss: 1.285    [weighted Loss:1.285    Policy Loss: 7.174    Value Loss: 4.805    Reward Loss: 0.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 86553      Buffer Size: 3065       Transition Number: 149.952 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:28:15,039][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 6.738    Value Loss: 4.444    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 86708      Buffer Size: 3106       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:40:32,193][train][INFO][train.py>_log] ==> #370000     Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 6.828    Value Loss: 4.813    Reward Loss: 0.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 86847      Buffer Size: 3117       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-03 17:52:42,706][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.879    [weighted Loss:2.879    Policy Loss: 7.064    Value Loss: 4.682    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 86979      Buffer Size: 3100       Transition Number: 149.960 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:04:58,052][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 7.610    Value Loss: 4.631    Reward Loss: 0.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 87117      Buffer Size: 3059       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:17:12,885][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 6.852    Value Loss: 4.744    Reward Loss: 0.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 87261      Buffer Size: 3021       Transition Number: 149.963 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:29:30,108][train][INFO][train.py>_log] ==> #374000     Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 7.617    Value Loss: 4.532    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 87401      Buffer Size: 2989       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:41:47,475][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 7.581    Value Loss: 4.668    Reward Loss: 0.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 87546      Buffer Size: 2969       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-03 18:54:05,999][train][INFO][train.py>_log] ==> #376000     Total Loss: 1.130    [weighted Loss:1.130    Policy Loss: 6.394    Value Loss: 4.730    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 87679      Buffer Size: 2963       Transition Number: 149.944 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:06:24,892][train][INFO][train.py>_log] ==> #377000     Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 6.672    Value Loss: 5.071    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 87833      Buffer Size: 2977       Transition Number: 149.979 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:18:52,605][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 5.931    Value Loss: 4.890    Reward Loss: 0.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 87986      Buffer Size: 2985       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:31:18,374][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.090    [weighted Loss:2.090    Policy Loss: 6.818    Value Loss: 4.499    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 88119      Buffer Size: 2974       Transition Number: 149.953 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:43:38,021][train][INFO][train.py>_log] ==> #380000     Total Loss: 3.501    [weighted Loss:3.501    Policy Loss: 7.573    Value Loss: 4.667    Reward Loss: 0.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 88285      Buffer Size: 2992       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-03 19:56:00,306][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.085    [weighted Loss:2.085    Policy Loss: 6.303    Value Loss: 4.855    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 88424      Buffer Size: 2993       Transition Number: 149.965 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:08:23,888][train][INFO][train.py>_log] ==> #382000     Total Loss: 3.153    [weighted Loss:3.153    Policy Loss: 6.488    Value Loss: 4.557    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 88580      Buffer Size: 3024       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:20:48,426][train][INFO][train.py>_log] ==> #383000     Total Loss: 1.504    [weighted Loss:1.504    Policy Loss: 5.674    Value Loss: 5.120    Reward Loss: 0.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 88772      Buffer Size: 3078       Transition Number: 150.022 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:33:06,756][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 8.152    Value Loss: 4.816    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 88923      Buffer Size: 3074       Transition Number: 149.963 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:45:45,719][train][INFO][train.py>_log] ==> #385000     Total Loss: 2.009    [weighted Loss:2.009    Policy Loss: 5.224    Value Loss: 4.328    Reward Loss: 0.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 89072      Buffer Size: 3046       Transition Number: 149.934 k Batch Size: 128        Lr: 0.100   
[2021-11-03 20:58:07,252][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.715    [weighted Loss:1.715    Policy Loss: 5.733    Value Loss: 4.689    Reward Loss: 0.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 89220      Buffer Size: 3042       Transition Number: 149.980 k Batch Size: 128        Lr: 0.100   
[2021-11-03 21:10:45,733][train][INFO][train.py>_log] ==> #387000     Total Loss: 1.247    [weighted Loss:1.247    Policy Loss: 5.554    Value Loss: 4.704    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 89395      Buffer Size: 3072       Transition Number: 149.980 k Batch Size: 128        Lr: 0.100   
[2021-11-03 21:23:14,327][train][INFO][train.py>_log] ==> #388000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 5.468    Value Loss: 4.702    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 89548      Buffer Size: 3081       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-03 21:35:53,204][train][INFO][train.py>_log] ==> #389000     Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 4.957    Value Loss: 4.965    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 89710      Buffer Size: 3079       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-03 21:48:24,277][train][INFO][train.py>_log] ==> #390000     Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 5.592    Value Loss: 4.912    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 89886      Buffer Size: 3109       Transition Number: 149.961 k Batch Size: 128        Lr: 0.100   
[2021-11-03 22:01:00,769][train][INFO][train.py>_log] ==> #391000     Total Loss: 1.131    [weighted Loss:1.131    Policy Loss: 5.162    Value Loss: 4.832    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 90038      Buffer Size: 3117       Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-11-03 22:13:41,030][train][INFO][train.py>_log] ==> #392000     Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 4.621    Value Loss: 4.916    Reward Loss: 0.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 90184      Buffer Size: 3120       Transition Number: 149.968 k Batch Size: 128        Lr: 0.100   
[2021-11-03 22:26:08,694][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.507    [weighted Loss:2.507    Policy Loss: 6.975    Value Loss: 4.702    Reward Loss: 0.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 90350      Buffer Size: 3153       Transition Number: 149.971 k Batch Size: 128        Lr: 0.100   
[2021-11-03 22:38:49,835][train][INFO][train.py>_log] ==> #394000     Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 6.706    Value Loss: 4.729    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 90488      Buffer Size: 3160       Transition Number: 149.963 k Batch Size: 128        Lr: 0.100   
[2021-11-03 22:51:08,086][train][INFO][train.py>_log] ==> #395000     Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 5.568    Value Loss: 4.989    Reward Loss: 0.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 90651      Buffer Size: 3187       Transition Number: 149.949 k Batch Size: 128        Lr: 0.100   
[2021-11-03 23:03:25,955][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 6.891    Value Loss: 4.612    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 90792      Buffer Size: 3192       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-03 23:15:49,965][train][INFO][train.py>_log] ==> #397000     Total Loss: 2.137    [weighted Loss:2.137    Policy Loss: 6.649    Value Loss: 5.304    Reward Loss: 0.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 90955      Buffer Size: 3221       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-03 23:28:08,415][train][INFO][train.py>_log] ==> #398000     Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 6.603    Value Loss: 4.909    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 91099      Buffer Size: 3216       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-03 23:40:31,024][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 8.496    Value Loss: 4.790    Reward Loss: 0.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 91263      Buffer Size: 3238       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-03 23:52:58,327][train][INFO][train.py>_log] ==> #400000     Total Loss: 1.822    [weighted Loss:1.822    Policy Loss: 6.504    Value Loss: 5.068    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 91406      Buffer Size: 3238       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-04 00:05:14,861][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 7.654    Value Loss: 4.749    Reward Loss: 0.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 91546      Buffer Size: 3224       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-04 00:17:25,760][train][INFO][train.py>_log] ==> #402000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 8.598    Value Loss: 4.929    Reward Loss: 0.891    Consistency Loss: 0.000    ] Replay Episodes Collected: 91692      Buffer Size: 3232       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-04 00:29:37,814][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 7.307    Value Loss: 4.905    Reward Loss: 0.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 91862      Buffer Size: 3247       Transition Number: 149.950 k Batch Size: 128        Lr: 0.100   
[2021-11-04 00:41:57,749][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 6.473    Value Loss: 4.730    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 91997      Buffer Size: 3190       Transition Number: 149.979 k Batch Size: 128        Lr: 0.100   
[2021-11-04 00:54:10,547][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.527    [weighted Loss:2.527    Policy Loss: 6.875    Value Loss: 4.921    Reward Loss: 0.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 92141      Buffer Size: 3184       Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-11-04 01:06:25,229][train][INFO][train.py>_log] ==> #406000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 8.573    Value Loss: 4.837    Reward Loss: 0.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 92309      Buffer Size: 3224       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-04 01:18:38,609][train][INFO][train.py>_log] ==> #407000     Total Loss: 3.849    [weighted Loss:3.849    Policy Loss: 8.084    Value Loss: 4.951    Reward Loss: 0.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 92473      Buffer Size: 3251       Transition Number: 150.061 k Batch Size: 128        Lr: 0.100   
[2021-11-04 01:30:53,528][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.230    [weighted Loss:1.230    Policy Loss: 7.574    Value Loss: 4.903    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 92617      Buffer Size: 3225       Transition Number: 150.015 k Batch Size: 128        Lr: 0.100   
[2021-11-04 01:43:04,794][train][INFO][train.py>_log] ==> #409000     Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 6.755    Value Loss: 4.963    Reward Loss: 0.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 92767      Buffer Size: 3218       Transition Number: 149.953 k Batch Size: 128        Lr: 0.100   
[2021-11-04 01:55:23,785][train][INFO][train.py>_log] ==> #410000     Total Loss: 3.360    [weighted Loss:3.360    Policy Loss: 7.014    Value Loss: 4.886    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 92917      Buffer Size: 3212       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-04 02:07:46,097][train][INFO][train.py>_log] ==> #411000     Total Loss: 0.943    [weighted Loss:0.943    Policy Loss: 6.552    Value Loss: 4.790    Reward Loss: 0.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 93066      Buffer Size: 3180       Transition Number: 149.982 k Batch Size: 128        Lr: 0.100   
[2021-11-04 02:20:18,710][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.110    [weighted Loss:3.110    Policy Loss: 7.248    Value Loss: 4.696    Reward Loss: 0.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 93206      Buffer Size: 3166       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-04 02:32:47,084][train][INFO][train.py>_log] ==> #413000     Total Loss: 1.341    [weighted Loss:1.341    Policy Loss: 7.231    Value Loss: 4.821    Reward Loss: 0.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 93340      Buffer Size: 3143       Transition Number: 149.982 k Batch Size: 128        Lr: 0.100   
[2021-11-04 02:45:05,450][train][INFO][train.py>_log] ==> #414000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 7.667    Value Loss: 4.685    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 93473      Buffer Size: 3103       Transition Number: 149.970 k Batch Size: 128        Lr: 0.100   
[2021-11-04 02:57:44,862][train][INFO][train.py>_log] ==> #415000     Total Loss: 3.575    [weighted Loss:3.575    Policy Loss: 8.000    Value Loss: 4.628    Reward Loss: 0.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 93605      Buffer Size: 3068       Transition Number: 149.955 k Batch Size: 128        Lr: 0.100   
[2021-11-04 03:10:10,893][train][INFO][train.py>_log] ==> #416000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 7.219    Value Loss: 4.675    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 93737      Buffer Size: 3029       Transition Number: 149.936 k Batch Size: 128        Lr: 0.100   
[2021-11-04 03:22:36,636][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 7.207    Value Loss: 4.576    Reward Loss: 0.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 93881      Buffer Size: 3019       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-04 03:35:05,335][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 6.053    Value Loss: 4.556    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 94014      Buffer Size: 2990       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-04 03:47:40,717][train][INFO][train.py>_log] ==> #419000     Total Loss: 3.881    [weighted Loss:3.881    Policy Loss: 6.976    Value Loss: 4.610    Reward Loss: 0.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 94160      Buffer Size: 2969       Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-11-04 04:00:10,159][train][INFO][train.py>_log] ==> #420000     Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 6.785    Value Loss: 4.698    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 94295      Buffer Size: 2951       Transition Number: 149.963 k Batch Size: 128        Lr: 0.100   
[2021-11-04 04:12:40,427][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 7.757    Value Loss: 4.553    Reward Loss: 0.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 94441      Buffer Size: 2954       Transition Number: 149.939 k Batch Size: 128        Lr: 0.100   
[2021-11-04 04:25:04,698][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 6.974    Value Loss: 4.547    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 94613      Buffer Size: 2977       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-04 04:37:28,267][train][INFO][train.py>_log] ==> #423000     Total Loss: 1.741    [weighted Loss:1.741    Policy Loss: 7.537    Value Loss: 4.406    Reward Loss: 0.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 94770      Buffer Size: 2963       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-04 04:50:01,360][train][INFO][train.py>_log] ==> #424000     Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 6.698    Value Loss: 4.662    Reward Loss: 0.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 94912      Buffer Size: 2958       Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-11-04 05:02:22,564][train][INFO][train.py>_log] ==> #425000     Total Loss: 3.437    [weighted Loss:3.437    Policy Loss: 6.507    Value Loss: 5.025    Reward Loss: 0.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 95092      Buffer Size: 3001       Transition Number: 149.944 k Batch Size: 128        Lr: 0.100   
[2021-11-04 05:14:49,564][train][INFO][train.py>_log] ==> #426000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 7.882    Value Loss: 4.874    Reward Loss: 0.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 95230      Buffer Size: 2961       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-04 05:27:15,808][train][INFO][train.py>_log] ==> #427000     Total Loss: 2.034    [weighted Loss:2.034    Policy Loss: 5.998    Value Loss: 4.473    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 95370      Buffer Size: 2932       Transition Number: 149.932 k Batch Size: 128        Lr: 0.100   
[2021-11-04 05:39:42,000][train][INFO][train.py>_log] ==> #428000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 5.997    Value Loss: 4.706    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 95511      Buffer Size: 2916       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-04 05:52:12,045][train][INFO][train.py>_log] ==> #429000     Total Loss: 1.865    [weighted Loss:1.865    Policy Loss: 6.141    Value Loss: 4.796    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 95655      Buffer Size: 2915       Transition Number: 149.979 k Batch Size: 128        Lr: 0.100   
[2021-11-04 06:04:38,542][train][INFO][train.py>_log] ==> #430000     Total Loss: 3.649    [weighted Loss:3.649    Policy Loss: 6.794    Value Loss: 4.437    Reward Loss: 0.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 95797      Buffer Size: 2906       Transition Number: 149.974 k Batch Size: 128        Lr: 0.100   
[2021-11-04 06:17:02,810][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 7.107    Value Loss: 4.720    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 96070      Buffer Size: 3039       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-04 06:29:20,238][train][INFO][train.py>_log] ==> #432000     Total Loss: 3.660    [weighted Loss:3.660    Policy Loss: 7.504    Value Loss: 4.506    Reward Loss: 0.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 96317      Buffer Size: 3155       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-04 06:41:38,347][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 6.926    Value Loss: 4.576    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 96474      Buffer Size: 3198       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-04 06:53:57,165][train][INFO][train.py>_log] ==> #434000     Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 7.245    Value Loss: 4.787    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 96624      Buffer Size: 3225       Transition Number: 150.045 k Batch Size: 128        Lr: 0.100   
[2021-11-04 07:06:16,738][train][INFO][train.py>_log] ==> #435000     Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 6.407    Value Loss: 4.689    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 96771      Buffer Size: 3244       Transition Number: 149.957 k Batch Size: 128        Lr: 0.100   
[2021-11-04 07:18:32,193][train][INFO][train.py>_log] ==> #436000     Total Loss: 1.347    [weighted Loss:1.347    Policy Loss: 7.061    Value Loss: 4.572    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 96933      Buffer Size: 3291       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-04 07:30:48,633][train][INFO][train.py>_log] ==> #437000     Total Loss: 1.771    [weighted Loss:1.771    Policy Loss: 6.586    Value Loss: 4.642    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 97088      Buffer Size: 3318       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-04 07:43:03,041][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 6.693    Value Loss: 4.981    Reward Loss: 0.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 97234      Buffer Size: 3328       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-04 07:55:20,946][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 6.577    Value Loss: 4.939    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 97376      Buffer Size: 3341       Transition Number: 149.968 k Batch Size: 128        Lr: 0.100   
[2021-11-04 08:07:41,301][train][INFO][train.py>_log] ==> #440000     Total Loss: 1.340    [weighted Loss:1.340    Policy Loss: 7.558    Value Loss: 4.944    Reward Loss: 0.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 97522      Buffer Size: 3334       Transition Number: 149.965 k Batch Size: 128        Lr: 0.100   
[2021-11-04 08:19:59,237][train][INFO][train.py>_log] ==> #441000     Total Loss: 2.240    [weighted Loss:2.240    Policy Loss: 6.551    Value Loss: 4.813    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 97669      Buffer Size: 3347       Transition Number: 150.031 k Batch Size: 128        Lr: 0.100   
[2021-11-04 08:32:19,836][train][INFO][train.py>_log] ==> #442000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 7.435    Value Loss: 4.957    Reward Loss: 0.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 97852      Buffer Size: 3384       Transition Number: 149.975 k Batch Size: 128        Lr: 0.100   
[2021-11-04 08:44:49,356][train][INFO][train.py>_log] ==> #443000     Total Loss: 2.425    [weighted Loss:2.425    Policy Loss: 7.476    Value Loss: 5.042    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 98016      Buffer Size: 3372       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-04 08:57:03,969][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.517    [weighted Loss:2.517    Policy Loss: 7.400    Value Loss: 5.310    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 98157      Buffer Size: 3360       Transition Number: 149.952 k Batch Size: 128        Lr: 0.100   
[2021-11-04 09:09:22,301][train][INFO][train.py>_log] ==> #445000     Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 6.727    Value Loss: 4.472    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 98297      Buffer Size: 3354       Transition Number: 149.929 k Batch Size: 128        Lr: 0.100   
[2021-11-04 09:21:44,830][train][INFO][train.py>_log] ==> #446000     Total Loss: 0.862    [weighted Loss:0.862    Policy Loss: 6.544    Value Loss: 4.978    Reward Loss: 0.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 98431      Buffer Size: 3306       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
