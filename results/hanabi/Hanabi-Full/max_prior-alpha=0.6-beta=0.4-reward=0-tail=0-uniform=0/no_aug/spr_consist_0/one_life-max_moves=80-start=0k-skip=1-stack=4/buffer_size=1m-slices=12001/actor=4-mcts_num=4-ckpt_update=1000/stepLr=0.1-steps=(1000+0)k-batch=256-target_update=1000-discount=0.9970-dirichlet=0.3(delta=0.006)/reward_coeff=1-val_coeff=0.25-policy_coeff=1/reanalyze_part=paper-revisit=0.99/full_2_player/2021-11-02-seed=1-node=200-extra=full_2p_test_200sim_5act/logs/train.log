[2021-11-02 16:30:17,714][train][INFO][train.py>_log] ==> #0          Total Loss: 44.427   [weighted Loss:44.427   Policy Loss: 14.429   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 43         Buffer Size: 43         Transition Number: 0.539   k Batch Size: 256        Lr: 0.000   
[2021-11-02 16:36:59,885][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.509    [weighted Loss:5.509    Policy Loss: 14.616   Value Loss: 4.487    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 288        Buffer Size: 288        Transition Number: 3.566   k Batch Size: 256        Lr: 0.010   
[2021-11-02 16:43:55,539][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.146    [weighted Loss:7.146    Policy Loss: 14.347   Value Loss: 2.969    Reward Loss: 0.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 568        Buffer Size: 568        Transition Number: 6.712   k Batch Size: 256        Lr: 0.020   
[2021-11-02 16:51:14,936][train][INFO][train.py>_log] ==> #3000       Total Loss: 7.097    [weighted Loss:7.097    Policy Loss: 13.866   Value Loss: 2.779    Reward Loss: 0.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 790        Buffer Size: 790        Transition Number: 9.301   k Batch Size: 256        Lr: 0.030   
[2021-11-02 16:58:34,291][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.501    [weighted Loss:3.501    Policy Loss: 14.940   Value Loss: 3.376    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1068       Buffer Size: 1068       Transition Number: 12.069  k Batch Size: 256        Lr: 0.040   
[2021-11-02 17:29:23,084][train][INFO][train.py>_log] ==> #5000       Total Loss: 6.134    [weighted Loss:6.134    Policy Loss: 13.494   Value Loss: 3.198    Reward Loss: 0.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 2669       Buffer Size: 2669       Transition Number: 28.472  k Batch Size: 256        Lr: 0.050   
[2021-11-02 17:42:38,069][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.236    [weighted Loss:5.236    Policy Loss: 14.456   Value Loss: 3.218    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 3242       Buffer Size: 3242       Transition Number: 35.015  k Batch Size: 256        Lr: 0.060   
[2021-11-02 19:17:16,194][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.310    [weighted Loss:5.310    Policy Loss: 14.121   Value Loss: 3.207    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 8075       Buffer Size: 8075       Transition Number: 88.953  k Batch Size: 256        Lr: 0.070   
[2021-11-02 23:56:21,957][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.955    [weighted Loss:4.955    Policy Loss: 14.411   Value Loss: 3.262    Reward Loss: 0.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 20578      Buffer Size: 20578      Transition Number: 251.117 k Batch Size: 256        Lr: 0.080   
