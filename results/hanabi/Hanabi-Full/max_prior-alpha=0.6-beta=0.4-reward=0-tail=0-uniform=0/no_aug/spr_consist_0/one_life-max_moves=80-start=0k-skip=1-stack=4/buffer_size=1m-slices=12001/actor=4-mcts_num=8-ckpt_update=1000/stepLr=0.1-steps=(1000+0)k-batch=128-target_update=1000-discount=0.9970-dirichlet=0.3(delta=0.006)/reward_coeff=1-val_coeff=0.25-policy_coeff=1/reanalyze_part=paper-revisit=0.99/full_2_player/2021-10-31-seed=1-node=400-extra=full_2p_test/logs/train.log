[2021-10-31 04:50:05,636][train][INFO][train.py>_log] ==> #0          Total Loss: 43.526   [weighted Loss:43.526   Policy Loss: 13.528   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 52         Buffer Size: 52         Transition Number: 0.533   k Batch Size: 128        Lr: 0.000   
[2021-10-31 05:00:16,116][train][INFO][train.py>_log] ==> #1000       Total Loss: 3.958    [weighted Loss:3.958    Policy Loss: 13.294   Value Loss: 4.427    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 466        Buffer Size: 466        Transition Number: 5.714   k Batch Size: 128        Lr: 0.010   
[2021-10-31 05:10:35,170][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.549    [weighted Loss:6.549    Policy Loss: 14.066   Value Loss: 3.397    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 900        Buffer Size: 900        Transition Number: 10.078  k Batch Size: 128        Lr: 0.020   
[2021-10-31 05:21:13,672][train][INFO][train.py>_log] ==> #3000       Total Loss: 7.310    [weighted Loss:7.310    Policy Loss: 14.508   Value Loss: 3.114    Reward Loss: 0.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 1224       Buffer Size: 1224       Transition Number: 14.183  k Batch Size: 128        Lr: 0.030   
[2021-10-31 05:31:53,009][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.097    [weighted Loss:4.097    Policy Loss: 13.779   Value Loss: 3.367    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 1750       Buffer Size: 1750       Transition Number: 18.552  k Batch Size: 128        Lr: 0.040   
[2021-10-31 05:42:31,538][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.280    [weighted Loss:3.280    Policy Loss: 13.573   Value Loss: 3.351    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 2174       Buffer Size: 2174       Transition Number: 22.670  k Batch Size: 128        Lr: 0.050   
[2021-10-31 05:53:15,165][train][INFO][train.py>_log] ==> #6000       Total Loss: 6.348    [weighted Loss:6.348    Policy Loss: 13.180   Value Loss: 2.892    Reward Loss: 0.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2698       Buffer Size: 2698       Transition Number: 26.899  k Batch Size: 128        Lr: 0.060   
[2021-10-31 06:03:58,711][train][INFO][train.py>_log] ==> #7000       Total Loss: 7.197    [weighted Loss:7.197    Policy Loss: 12.686   Value Loss: 2.683    Reward Loss: 0.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 3116       Buffer Size: 3116       Transition Number: 31.153  k Batch Size: 128        Lr: 0.070   
[2021-10-31 06:14:38,460][train][INFO][train.py>_log] ==> #8000       Total Loss: 7.482    [weighted Loss:7.482    Policy Loss: 13.087   Value Loss: 3.174    Reward Loss: 0.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 3705       Buffer Size: 3705       Transition Number: 35.252  k Batch Size: 128        Lr: 0.080   
[2021-10-31 06:25:16,872][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.418    [weighted Loss:4.418    Policy Loss: 12.625   Value Loss: 2.894    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 4223       Buffer Size: 4223       Transition Number: 39.436  k Batch Size: 128        Lr: 0.090   
[2021-10-31 06:36:01,070][train][INFO][train.py>_log] ==> #10000      Total Loss: 8.199    [weighted Loss:8.199    Policy Loss: 13.325   Value Loss: 2.833    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 4676       Buffer Size: 4676       Transition Number: 43.747  k Batch Size: 128        Lr: 0.100   
[2021-10-31 06:46:43,024][train][INFO][train.py>_log] ==> #11000      Total Loss: 6.226    [weighted Loss:6.226    Policy Loss: 12.962   Value Loss: 2.592    Reward Loss: 0.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 5079       Buffer Size: 5079       Transition Number: 47.909  k Batch Size: 128        Lr: 0.100   
[2021-10-31 06:57:20,486][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.271    [weighted Loss:4.271    Policy Loss: 13.801   Value Loss: 2.986    Reward Loss: 0.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 5453       Buffer Size: 5453       Transition Number: 51.786  k Batch Size: 128        Lr: 0.100   
[2021-10-31 07:08:05,007][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.215    [weighted Loss:4.215    Policy Loss: 13.547   Value Loss: 3.002    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 5996       Buffer Size: 5996       Transition Number: 56.069  k Batch Size: 128        Lr: 0.100   
[2021-10-31 07:18:48,248][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.307    [weighted Loss:4.307    Policy Loss: 12.761   Value Loss: 2.968    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 6205       Buffer Size: 6205       Transition Number: 59.730  k Batch Size: 128        Lr: 0.100   
[2021-10-31 07:29:27,893][train][INFO][train.py>_log] ==> #15000      Total Loss: 7.163    [weighted Loss:7.163    Policy Loss: 13.809   Value Loss: 3.033    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 6724       Buffer Size: 6724       Transition Number: 64.067  k Batch Size: 128        Lr: 0.100   
[2021-10-31 07:40:14,474][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.614    [weighted Loss:5.614    Policy Loss: 12.981   Value Loss: 3.012    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 7217       Buffer Size: 7217       Transition Number: 68.186  k Batch Size: 128        Lr: 0.100   
[2021-10-31 07:50:59,288][train][INFO][train.py>_log] ==> #17000      Total Loss: 5.858    [weighted Loss:5.858    Policy Loss: 12.314   Value Loss: 2.662    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 7692       Buffer Size: 7692       Transition Number: 72.313  k Batch Size: 128        Lr: 0.100   
[2021-10-31 08:01:49,376][train][INFO][train.py>_log] ==> #18000      Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 10.962   Value Loss: 2.978    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 8085       Buffer Size: 8085       Transition Number: 76.308  k Batch Size: 128        Lr: 0.100   
[2021-10-31 08:12:32,542][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.422    [weighted Loss:4.422    Policy Loss: 12.331   Value Loss: 2.612    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 8617       Buffer Size: 8617       Transition Number: 80.641  k Batch Size: 128        Lr: 0.100   
[2021-10-31 08:23:19,594][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.198    [weighted Loss:5.198    Policy Loss: 12.570   Value Loss: 2.943    Reward Loss: 1.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 9103       Buffer Size: 9103       Transition Number: 84.875  k Batch Size: 128        Lr: 0.100   
[2021-10-31 08:34:04,523][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.928    [weighted Loss:4.928    Policy Loss: 12.535   Value Loss: 2.806    Reward Loss: 1.041    Consistency Loss: 0.000    ] Replay Episodes Collected: 9631       Buffer Size: 9631       Transition Number: 89.084  k Batch Size: 128        Lr: 0.100   
[2021-10-31 08:44:52,823][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.302    [weighted Loss:4.302    Policy Loss: 11.274   Value Loss: 3.134    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 10276      Buffer Size: 10276      Transition Number: 93.563  k Batch Size: 128        Lr: 0.100   
[2021-10-31 08:55:41,892][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.778    [weighted Loss:3.778    Policy Loss: 10.793   Value Loss: 2.959    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 10963      Buffer Size: 10963      Transition Number: 98.044  k Batch Size: 128        Lr: 0.100   
[2021-10-31 09:06:31,603][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.991    [weighted Loss:5.991    Policy Loss: 12.670   Value Loss: 2.797    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 11567      Buffer Size: 11567      Transition Number: 102.220 k Batch Size: 128        Lr: 0.100   
[2021-10-31 09:17:20,581][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.416    [weighted Loss:4.416    Policy Loss: 9.371    Value Loss: 3.057    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 12226      Buffer Size: 12226      Transition Number: 106.678 k Batch Size: 128        Lr: 0.100   
[2021-10-31 09:28:14,186][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.861    [weighted Loss:2.861    Policy Loss: 10.130   Value Loss: 2.954    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 12914      Buffer Size: 12914      Transition Number: 111.199 k Batch Size: 128        Lr: 0.100   
[2021-10-31 09:39:08,386][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 8.247    Value Loss: 2.818    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 13621      Buffer Size: 13621      Transition Number: 115.708 k Batch Size: 128        Lr: 0.100   
[2021-10-31 09:50:01,339][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.177    [weighted Loss:4.177    Policy Loss: 9.448    Value Loss: 2.962    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 14298      Buffer Size: 14298      Transition Number: 120.174 k Batch Size: 128        Lr: 0.100   
[2021-10-31 10:00:48,242][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.324    [weighted Loss:4.324    Policy Loss: 9.831    Value Loss: 3.012    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 15041      Buffer Size: 15041      Transition Number: 124.667 k Batch Size: 128        Lr: 0.100   
[2021-10-31 10:11:40,356][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.299    [weighted Loss:3.299    Policy Loss: 8.370    Value Loss: 3.018    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 15700      Buffer Size: 15700      Transition Number: 129.128 k Batch Size: 128        Lr: 0.100   
[2021-10-31 10:22:28,039][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 9.462    Value Loss: 3.136    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 16393      Buffer Size: 16393      Transition Number: 133.573 k Batch Size: 128        Lr: 0.100   
[2021-10-31 10:33:20,658][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.899    [weighted Loss:2.899    Policy Loss: 7.897    Value Loss: 3.024    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 17103      Buffer Size: 17103      Transition Number: 138.044 k Batch Size: 128        Lr: 0.100   
[2021-10-31 10:44:06,720][train][INFO][train.py>_log] ==> #33000      Total Loss: 5.138    [weighted Loss:5.138    Policy Loss: 9.163    Value Loss: 2.903    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 17754      Buffer Size: 17754      Transition Number: 142.432 k Batch Size: 128        Lr: 0.100   
[2021-10-31 10:55:08,421][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.282    [weighted Loss:4.282    Policy Loss: 7.517    Value Loss: 3.177    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 18494      Buffer Size: 18494      Transition Number: 147.046 k Batch Size: 128        Lr: 0.100   
[2021-10-31 11:05:57,952][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 7.444    Value Loss: 3.064    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 19292      Buffer Size: 19160      Transition Number: 150.004 k Batch Size: 128        Lr: 0.100   
[2021-10-31 11:17:01,709][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.773    [weighted Loss:2.773    Policy Loss: 4.948    Value Loss: 2.944    Reward Loss: 1.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 20144      Buffer Size: 19622      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-10-31 11:27:54,408][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 5.049    Value Loss: 2.748    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 20907      Buffer Size: 19948      Transition Number: 150.002 k Batch Size: 128        Lr: 0.100   
[2021-10-31 11:38:55,075][train][INFO][train.py>_log] ==> #38000      Total Loss: 0.955    [weighted Loss:0.955    Policy Loss: 4.700    Value Loss: 2.896    Reward Loss: 1.974    Consistency Loss: 0.000    ] Replay Episodes Collected: 21634      Buffer Size: 20272      Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-10-31 11:49:48,387][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.395    [weighted Loss:2.395    Policy Loss: 5.191    Value Loss: 2.729    Reward Loss: 1.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 22250      Buffer Size: 20374      Transition Number: 150.038 k Batch Size: 128        Lr: 0.100   
[2021-10-31 12:00:35,120][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.692    [weighted Loss:1.692    Policy Loss: 6.227    Value Loss: 2.676    Reward Loss: 1.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 22860      Buffer Size: 20514      Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-10-31 12:11:28,829][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.704    [weighted Loss:2.704    Policy Loss: 5.410    Value Loss: 3.090    Reward Loss: 2.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 23189      Buffer Size: 20400      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 12:22:40,934][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 5.417    Value Loss: 3.048    Reward Loss: 1.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 23640      Buffer Size: 20420      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-10-31 12:33:54,700][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 5.714    Value Loss: 3.063    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 24208      Buffer Size: 20319      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 12:45:09,792][train][INFO][train.py>_log] ==> #44000      Total Loss: 1.653    [weighted Loss:1.653    Policy Loss: 3.930    Value Loss: 2.725    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 24923      Buffer Size: 20490      Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-10-31 12:56:19,691][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 4.475    Value Loss: 2.794    Reward Loss: 1.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 25672      Buffer Size: 20746      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-10-31 13:07:34,711][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 2.839    Value Loss: 2.805    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 26396      Buffer Size: 21033      Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-10-31 13:18:54,076][train][INFO][train.py>_log] ==> #47000      Total Loss: 1.914    [weighted Loss:1.914    Policy Loss: 4.194    Value Loss: 2.908    Reward Loss: 1.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 27083      Buffer Size: 21229      Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-10-31 13:31:09,729][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 6.705    Value Loss: 2.888    Reward Loss: 1.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 27876      Buffer Size: 21670      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 13:42:23,732][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.483    [weighted Loss:1.483    Policy Loss: 3.922    Value Loss: 2.916    Reward Loss: 2.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 28528      Buffer Size: 21803      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 13:54:42,079][train][INFO][train.py>_log] ==> #50000      Total Loss: 1.616    [weighted Loss:1.616    Policy Loss: 3.520    Value Loss: 2.538    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 29324      Buffer Size: 21967      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-10-31 14:06:08,323][train][INFO][train.py>_log] ==> #51000      Total Loss: 1.479    [weighted Loss:1.479    Policy Loss: 3.607    Value Loss: 2.895    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 29804      Buffer Size: 21963      Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-10-31 14:17:16,619][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 3.897    Value Loss: 2.692    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 30627      Buffer Size: 22296      Transition Number: 149.985 k Batch Size: 128        Lr: 0.100   
[2021-10-31 14:28:35,873][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 3.332    Value Loss: 2.954    Reward Loss: 1.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 31262      Buffer Size: 22399      Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-10-31 14:39:52,894][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.871    [weighted Loss:2.871    Policy Loss: 9.465    Value Loss: 3.120    Reward Loss: 1.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 31960      Buffer Size: 22540      Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-10-31 14:51:14,497][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 3.880    Value Loss: 3.188    Reward Loss: 1.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 32562      Buffer Size: 22578      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 15:04:29,944][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 4.206    Value Loss: 3.076    Reward Loss: 2.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 33119      Buffer Size: 22450      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-10-31 15:15:36,182][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 4.383    Value Loss: 2.945    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 33542      Buffer Size: 22304      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 15:26:54,208][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.566    [weighted Loss:2.566    Policy Loss: 3.866    Value Loss: 2.893    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 34012      Buffer Size: 22227      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 15:38:15,200][train][INFO][train.py>_log] ==> #59000      Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 3.794    Value Loss: 2.752    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 34464      Buffer Size: 22023      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 15:49:21,952][train][INFO][train.py>_log] ==> #60000      Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 3.537    Value Loss: 2.778    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 34996      Buffer Size: 21894      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-10-31 16:00:36,588][train][INFO][train.py>_log] ==> #61000      Total Loss: 5.906    [weighted Loss:5.906    Policy Loss: 3.348    Value Loss: 2.929    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 35550      Buffer Size: 21761      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 16:12:02,784][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.584    [weighted Loss:2.584    Policy Loss: 3.242    Value Loss: 2.954    Reward Loss: 1.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 36244      Buffer Size: 21744      Transition Number: 150.005 k Batch Size: 128        Lr: 0.100   
[2021-10-31 16:23:18,857][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 6.828    Value Loss: 3.193    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 36918      Buffer Size: 21709      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 16:34:53,266][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.645    [weighted Loss:2.645    Policy Loss: 4.767    Value Loss: 2.894    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 37505      Buffer Size: 21656      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 16:46:16,207][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 4.122    Value Loss: 3.011    Reward Loss: 1.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 38084      Buffer Size: 21516      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 16:59:07,936][train][INFO][train.py>_log] ==> #66000      Total Loss: 6.864    [weighted Loss:6.864    Policy Loss: 4.091    Value Loss: 3.133    Reward Loss: 1.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 39000      Buffer Size: 21526      Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-10-31 17:10:14,580][train][INFO][train.py>_log] ==> #67000      Total Loss: 7.561    [weighted Loss:7.561    Policy Loss: 5.072    Value Loss: 2.842    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 39775      Buffer Size: 21548      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 17:22:02,184][train][INFO][train.py>_log] ==> #68000      Total Loss: 6.006    [weighted Loss:6.006    Policy Loss: 3.436    Value Loss: 3.008    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 40434      Buffer Size: 21376      Transition Number: 150.012 k Batch Size: 128        Lr: 0.100   
[2021-10-31 17:33:07,615][train][INFO][train.py>_log] ==> #69000      Total Loss: 7.386    [weighted Loss:7.386    Policy Loss: 4.617    Value Loss: 3.106    Reward Loss: 1.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 40959      Buffer Size: 21194      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 17:44:43,934][train][INFO][train.py>_log] ==> #70000      Total Loss: 6.426    [weighted Loss:6.426    Policy Loss: 3.866    Value Loss: 2.828    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 41684      Buffer Size: 21113      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 17:55:56,444][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 3.332    Value Loss: 3.145    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 42218      Buffer Size: 20951      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-10-31 18:07:09,466][train][INFO][train.py>_log] ==> #72000      Total Loss: 6.348    [weighted Loss:6.348    Policy Loss: 3.793    Value Loss: 3.045    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 42773      Buffer Size: 20795      Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-10-31 18:18:08,325][train][INFO][train.py>_log] ==> #73000      Total Loss: 7.701    [weighted Loss:7.701    Policy Loss: 5.180    Value Loss: 3.275    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 43362      Buffer Size: 20766      Transition Number: 150.018 k Batch Size: 128        Lr: 0.100   
[2021-10-31 18:29:02,323][train][INFO][train.py>_log] ==> #74000      Total Loss: 6.485    [weighted Loss:6.485    Policy Loss: 3.705    Value Loss: 3.106    Reward Loss: 2.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 43920      Buffer Size: 20847      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 18:39:56,427][train][INFO][train.py>_log] ==> #75000      Total Loss: 8.426    [weighted Loss:8.426    Policy Loss: 5.868    Value Loss: 3.163    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 44503      Buffer Size: 20996      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 18:51:38,333][train][INFO][train.py>_log] ==> #76000      Total Loss: 7.563    [weighted Loss:7.563    Policy Loss: 4.701    Value Loss: 3.458    Reward Loss: 1.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 44990      Buffer Size: 20977      Transition Number: 150.005 k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:02:39,569][train][INFO][train.py>_log] ==> #77000      Total Loss: 8.813    [weighted Loss:8.813    Policy Loss: 6.098    Value Loss: 3.213    Reward Loss: 1.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 45156      Buffer Size: 20798      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:13:51,775][train][INFO][train.py>_log] ==> #78000      Total Loss: 8.080    [weighted Loss:8.080    Policy Loss: 5.388    Value Loss: 3.245    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 45750      Buffer Size: 20678      Transition Number: 149.970 k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:24:39,778][train][INFO][train.py>_log] ==> #79000      Total Loss: 8.562    [weighted Loss:8.562    Policy Loss: 5.861    Value Loss: 3.439    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 45971      Buffer Size: 20505      Transition Number: 149.964 k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:35:44,659][train][INFO][train.py>_log] ==> #80000      Total Loss: 8.165    [weighted Loss:8.165    Policy Loss: 5.174    Value Loss: 3.496    Reward Loss: 2.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 46359      Buffer Size: 20289      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:46:37,540][train][INFO][train.py>_log] ==> #81000      Total Loss: 9.199    [weighted Loss:9.199    Policy Loss: 6.456    Value Loss: 3.371    Reward Loss: 1.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 46662      Buffer Size: 20072      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 19:57:49,709][train][INFO][train.py>_log] ==> #82000      Total Loss: 8.477    [weighted Loss:8.477    Policy Loss: 5.978    Value Loss: 3.268    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 47257      Buffer Size: 19916      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:08:53,331][train][INFO][train.py>_log] ==> #83000      Total Loss: 8.357    [weighted Loss:8.357    Policy Loss: 5.717    Value Loss: 3.265    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 47385      Buffer Size: 19651      Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:20:01,772][train][INFO][train.py>_log] ==> #84000      Total Loss: 8.113    [weighted Loss:8.113    Policy Loss: 5.767    Value Loss: 3.032    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 47701      Buffer Size: 19419      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:30:55,432][train][INFO][train.py>_log] ==> #85000      Total Loss: 4.471    [weighted Loss:4.471    Policy Loss: 5.148    Value Loss: 3.174    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 48012      Buffer Size: 19182      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:41:56,782][train][INFO][train.py>_log] ==> #86000      Total Loss: 9.482    [weighted Loss:9.482    Policy Loss: 6.955    Value Loss: 3.531    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 48262      Buffer Size: 18901      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-10-31 20:52:56,123][train][INFO][train.py>_log] ==> #87000      Total Loss: 10.135   [weighted Loss:10.135   Policy Loss: 7.731    Value Loss: 3.119    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 48413      Buffer Size: 18777      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:04:06,297][train][INFO][train.py>_log] ==> #88000      Total Loss: 9.780    [weighted Loss:9.780    Policy Loss: 7.182    Value Loss: 3.633    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 48595      Buffer Size: 18446      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:15:03,396][train][INFO][train.py>_log] ==> #89000      Total Loss: 11.749   [weighted Loss:11.749   Policy Loss: 9.015    Value Loss: 3.576    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 48839      Buffer Size: 18006      Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:26:10,806][train][INFO][train.py>_log] ==> #90000      Total Loss: 8.781    [weighted Loss:8.781    Policy Loss: 6.320    Value Loss: 3.334    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 49065      Buffer Size: 17735      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:37:18,976][train][INFO][train.py>_log] ==> #91000      Total Loss: 6.037    [weighted Loss:6.037    Policy Loss: 7.673    Value Loss: 3.649    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 49333      Buffer Size: 17484      Transition Number: 150.012 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:48:21,557][train][INFO][train.py>_log] ==> #92000      Total Loss: 9.035    [weighted Loss:9.035    Policy Loss: 6.175    Value Loss: 3.855    Reward Loss: 1.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 49602      Buffer Size: 17247      Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-10-31 21:59:34,169][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.745    [weighted Loss:3.745    Policy Loss: 6.637    Value Loss: 3.272    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 49683      Buffer Size: 16974      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:10:43,360][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.131    [weighted Loss:4.131    Policy Loss: 6.800    Value Loss: 3.393    Reward Loss: 1.893    Consistency Loss: 0.000    ] Replay Episodes Collected: 49891      Buffer Size: 16738      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:21:40,597][train][INFO][train.py>_log] ==> #95000      Total Loss: 4.691    [weighted Loss:4.691    Policy Loss: 11.400   Value Loss: 3.602    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 50002      Buffer Size: 16536      Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:32:36,061][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.175    [weighted Loss:5.175    Policy Loss: 8.160    Value Loss: 3.572    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 50126      Buffer Size: 16216      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:43:34,365][train][INFO][train.py>_log] ==> #97000      Total Loss: 5.441    [weighted Loss:5.441    Policy Loss: 8.547    Value Loss: 3.828    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 50225      Buffer Size: 15994      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-10-31 22:54:41,328][train][INFO][train.py>_log] ==> #98000      Total Loss: 6.105    [weighted Loss:6.105    Policy Loss: 8.020    Value Loss: 3.860    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 50365      Buffer Size: 15714      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:05:49,724][train][INFO][train.py>_log] ==> #99000      Total Loss: 5.568    [weighted Loss:5.568    Policy Loss: 6.485    Value Loss: 3.507    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 50508      Buffer Size: 15474      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:16:55,577][train][INFO][train.py>_log] ==> #100000     Total Loss: 5.007    [weighted Loss:5.007    Policy Loss: 7.458    Value Loss: 3.697    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 50631      Buffer Size: 15144      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:28:11,879][train][INFO][train.py>_log] ==> #101000     Total Loss: 4.716    [weighted Loss:4.716    Policy Loss: 6.257    Value Loss: 3.892    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 50741      Buffer Size: 14753      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:39:16,308][train][INFO][train.py>_log] ==> #102000     Total Loss: 6.995    [weighted Loss:6.995    Policy Loss: 10.706   Value Loss: 3.674    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 50835      Buffer Size: 14386      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-10-31 23:50:25,198][train][INFO][train.py>_log] ==> #103000     Total Loss: 4.322    [weighted Loss:4.322    Policy Loss: 6.989    Value Loss: 3.700    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 50999      Buffer Size: 14016      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:01:40,753][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 7.335    Value Loss: 4.463    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 51116      Buffer Size: 13689      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:12:55,641][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.968    [weighted Loss:4.968    Policy Loss: 7.174    Value Loss: 4.138    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 51275      Buffer Size: 13405      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:24:02,746][train][INFO][train.py>_log] ==> #106000     Total Loss: 3.560    [weighted Loss:3.560    Policy Loss: 7.124    Value Loss: 4.139    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 51408      Buffer Size: 13086      Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:35:22,499][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 6.150    Value Loss: 3.784    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 51528      Buffer Size: 12614      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:46:31,191][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.379    [weighted Loss:4.379    Policy Loss: 7.812    Value Loss: 4.522    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 51632      Buffer Size: 12242      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 00:57:41,207][train][INFO][train.py>_log] ==> #109000     Total Loss: 4.126    [weighted Loss:4.126    Policy Loss: 7.662    Value Loss: 3.927    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 51732      Buffer Size: 11813      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:08:52,143][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.931    [weighted Loss:3.931    Policy Loss: 7.541    Value Loss: 4.150    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 51828      Buffer Size: 11484      Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:20:36,876][train][INFO][train.py>_log] ==> #111000     Total Loss: 6.141    [weighted Loss:6.141    Policy Loss: 7.130    Value Loss: 4.593    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 51928      Buffer Size: 11201      Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:31:49,267][train][INFO][train.py>_log] ==> #112000     Total Loss: 6.395    [weighted Loss:6.395    Policy Loss: 8.528    Value Loss: 4.162    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 52048      Buffer Size: 10824      Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:43:23,533][train][INFO][train.py>_log] ==> #113000     Total Loss: 4.651    [weighted Loss:4.651    Policy Loss: 8.607    Value Loss: 4.332    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 52228      Buffer Size: 10446      Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 01:54:34,513][train][INFO][train.py>_log] ==> #114000     Total Loss: 4.566    [weighted Loss:4.566    Policy Loss: 8.172    Value Loss: 4.200    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 52354      Buffer Size: 10157      Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:05:41,318][train][INFO][train.py>_log] ==> #115000     Total Loss: 6.220    [weighted Loss:6.220    Policy Loss: 8.656    Value Loss: 4.379    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 52548      Buffer Size: 9960       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:17:03,319][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 7.429    Value Loss: 4.266    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 52668      Buffer Size: 9720       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:28:10,520][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.538    [weighted Loss:4.538    Policy Loss: 9.270    Value Loss: 4.612    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 52800      Buffer Size: 9398       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:39:22,720][train][INFO][train.py>_log] ==> #118000     Total Loss: 5.023    [weighted Loss:5.023    Policy Loss: 9.082    Value Loss: 4.724    Reward Loss: 0.951    Consistency Loss: 0.000    ] Replay Episodes Collected: 52922      Buffer Size: 9125       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 02:50:39,125][train][INFO][train.py>_log] ==> #119000     Total Loss: 5.261    [weighted Loss:5.261    Policy Loss: 9.699    Value Loss: 4.348    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 53028      Buffer Size: 8818       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:02:07,209][train][INFO][train.py>_log] ==> #120000     Total Loss: 5.760    [weighted Loss:5.760    Policy Loss: 9.787    Value Loss: 4.976    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 53145      Buffer Size: 8514       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:13:26,518][train][INFO][train.py>_log] ==> #121000     Total Loss: 5.987    [weighted Loss:5.987    Policy Loss: 10.975   Value Loss: 5.441    Reward Loss: 0.969    Consistency Loss: 0.000    ] Replay Episodes Collected: 53333      Buffer Size: 8322       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:24:55,114][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.419    [weighted Loss:3.419    Policy Loss: 9.086    Value Loss: 4.692    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 53451      Buffer Size: 8238       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:36:32,588][train][INFO][train.py>_log] ==> #123000     Total Loss: 5.385    [weighted Loss:5.385    Policy Loss: 12.007   Value Loss: 4.986    Reward Loss: 0.938    Consistency Loss: 0.000    ] Replay Episodes Collected: 53605      Buffer Size: 7890       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:47:58,192][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 13.395   Value Loss: 4.859    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 53780      Buffer Size: 7714       Transition Number: 150.007 k Batch Size: 128        Lr: 0.100   
[2021-11-01 03:59:16,975][train][INFO][train.py>_log] ==> #125000     Total Loss: 4.198    [weighted Loss:4.198    Policy Loss: 9.986    Value Loss: 5.225    Reward Loss: 0.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 53918      Buffer Size: 7499       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:10:34,819][train][INFO][train.py>_log] ==> #126000     Total Loss: 6.760    [weighted Loss:6.760    Policy Loss: 10.941   Value Loss: 5.069    Reward Loss: 1.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 54086      Buffer Size: 7303       Transition Number: 150.014 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:21:49,563][train][INFO][train.py>_log] ==> #127000     Total Loss: 4.985    [weighted Loss:4.985    Policy Loss: 10.132   Value Loss: 5.191    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 54229      Buffer Size: 6979       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:33:26,955][train][INFO][train.py>_log] ==> #128000     Total Loss: 5.379    [weighted Loss:5.379    Policy Loss: 10.697   Value Loss: 5.098    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 54346      Buffer Size: 6908       Transition Number: 149.977 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:45:06,934][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.414    [weighted Loss:3.414    Policy Loss: 9.980    Value Loss: 5.279    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 54448      Buffer Size: 6675       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 04:56:43,968][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.702    [weighted Loss:3.702    Policy Loss: 10.284   Value Loss: 4.744    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 54536      Buffer Size: 6453       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:08:20,362][train][INFO][train.py>_log] ==> #131000     Total Loss: 4.660    [weighted Loss:4.660    Policy Loss: 8.301    Value Loss: 5.009    Reward Loss: 0.939    Consistency Loss: 0.000    ] Replay Episodes Collected: 54647      Buffer Size: 6333       Transition Number: 149.985 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:20:39,085][train][INFO][train.py>_log] ==> #132000     Total Loss: 4.779    [weighted Loss:4.779    Policy Loss: 10.035   Value Loss: 4.817    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 54766      Buffer Size: 6255       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:32:09,975][train][INFO][train.py>_log] ==> #133000     Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 9.401    Value Loss: 4.943    Reward Loss: 0.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 54888      Buffer Size: 6162       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:44:15,135][train][INFO][train.py>_log] ==> #134000     Total Loss: 5.069    [weighted Loss:5.069    Policy Loss: 10.377   Value Loss: 5.212    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 54988      Buffer Size: 6030       Transition Number: 149.982 k Batch Size: 128        Lr: 0.100   
[2021-11-01 05:55:42,007][train][INFO][train.py>_log] ==> #135000     Total Loss: 4.430    [weighted Loss:4.430    Policy Loss: 9.636    Value Loss: 4.867    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 55081      Buffer Size: 5878       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:07:58,549][train][INFO][train.py>_log] ==> #136000     Total Loss: 5.557    [weighted Loss:5.557    Policy Loss: 10.049   Value Loss: 5.043    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 55228      Buffer Size: 5719       Transition Number: 150.016 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:20:08,553][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.982    [weighted Loss:3.982    Policy Loss: 10.473   Value Loss: 5.199    Reward Loss: 0.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 55376      Buffer Size: 5691       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:31:51,162][train][INFO][train.py>_log] ==> #138000     Total Loss: 6.248    [weighted Loss:6.248    Policy Loss: 11.083   Value Loss: 4.865    Reward Loss: 0.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 55493      Buffer Size: 5602       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:44:19,101][train][INFO][train.py>_log] ==> #139000     Total Loss: 5.246    [weighted Loss:5.246    Policy Loss: 10.699   Value Loss: 5.459    Reward Loss: 1.007    Consistency Loss: 0.000    ] Replay Episodes Collected: 55637      Buffer Size: 5602       Transition Number: 149.931 k Batch Size: 128        Lr: 0.100   
[2021-11-01 06:55:44,019][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.784    [weighted Loss:3.784    Policy Loss: 11.261   Value Loss: 5.403    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 55805      Buffer Size: 5628       Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:08:11,548][train][INFO][train.py>_log] ==> #141000     Total Loss: 4.273    [weighted Loss:4.273    Policy Loss: 10.119   Value Loss: 4.975    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 55994      Buffer Size: 5668       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:19:58,857][train][INFO][train.py>_log] ==> #142000     Total Loss: 5.076    [weighted Loss:5.076    Policy Loss: 11.406   Value Loss: 4.927    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 56141      Buffer Size: 5652       Transition Number: 149.996 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:31:28,253][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 10.822   Value Loss: 5.245    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 56242      Buffer Size: 5646       Transition Number: 149.962 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:43:11,567][train][INFO][train.py>_log] ==> #144000     Total Loss: 6.980    [weighted Loss:6.980    Policy Loss: 11.918   Value Loss: 4.850    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 56373      Buffer Size: 5640       Transition Number: 149.957 k Batch Size: 128        Lr: 0.100   
[2021-11-01 07:54:33,203][train][INFO][train.py>_log] ==> #145000     Total Loss: 5.198    [weighted Loss:5.198    Policy Loss: 11.673   Value Loss: 5.328    Reward Loss: 0.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 56453      Buffer Size: 5622       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:05:52,200][train][INFO][train.py>_log] ==> #146000     Total Loss: 4.808    [weighted Loss:4.808    Policy Loss: 11.488   Value Loss: 5.386    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 56540      Buffer Size: 5538       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:17:15,583][train][INFO][train.py>_log] ==> #147000     Total Loss: 5.237    [weighted Loss:5.237    Policy Loss: 10.825   Value Loss: 5.440    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 56617      Buffer Size: 5496       Transition Number: 149.997 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:29:15,169][train][INFO][train.py>_log] ==> #148000     Total Loss: 4.209    [weighted Loss:4.209    Policy Loss: 10.741   Value Loss: 4.932    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 56743      Buffer Size: 5441       Transition Number: 149.983 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:40:54,845][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.456    [weighted Loss:3.456    Policy Loss: 10.836   Value Loss: 5.558    Reward Loss: 0.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 56858      Buffer Size: 5414       Transition Number: 149.955 k Batch Size: 128        Lr: 0.100   
[2021-11-01 08:52:40,460][train][INFO][train.py>_log] ==> #150000     Total Loss: 4.785    [weighted Loss:4.785    Policy Loss: 10.470   Value Loss: 5.247    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 56958      Buffer Size: 5391       Transition Number: 150.031 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:04:21,159][train][INFO][train.py>_log] ==> #151000     Total Loss: 5.643    [weighted Loss:5.643    Policy Loss: 11.222   Value Loss: 5.388    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 57049      Buffer Size: 5370       Transition Number: 149.955 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:15:43,837][train][INFO][train.py>_log] ==> #152000     Total Loss: 5.498    [weighted Loss:5.498    Policy Loss: 11.721   Value Loss: 4.895    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 57149      Buffer Size: 5363       Transition Number: 149.941 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:27:49,370][train][INFO][train.py>_log] ==> #153000     Total Loss: 5.638    [weighted Loss:5.638    Policy Loss: 11.168   Value Loss: 5.085    Reward Loss: 0.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 57258      Buffer Size: 5359       Transition Number: 150.009 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:39:20,665][train][INFO][train.py>_log] ==> #154000     Total Loss: 5.810    [weighted Loss:5.810    Policy Loss: 11.262   Value Loss: 5.246    Reward Loss: 0.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 57377      Buffer Size: 5343       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-01 09:52:04,908][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.512    [weighted Loss:3.512    Policy Loss: 11.054   Value Loss: 5.182    Reward Loss: 0.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 57501      Buffer Size: 5285       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:04:16,348][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.541    [weighted Loss:3.541    Policy Loss: 11.358   Value Loss: 4.759    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 57641      Buffer Size: 5270       Transition Number: 149.993 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:16:38,187][train][INFO][train.py>_log] ==> #157000     Total Loss: 4.424    [weighted Loss:4.424    Policy Loss: 10.921   Value Loss: 5.303    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 57808      Buffer Size: 5218       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:28:22,159][train][INFO][train.py>_log] ==> #158000     Total Loss: 4.628    [weighted Loss:4.628    Policy Loss: 10.557   Value Loss: 5.012    Reward Loss: 0.952    Consistency Loss: 0.000    ] Replay Episodes Collected: 57927      Buffer Size: 5196       Transition Number: 149.985 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:40:21,934][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 12.016   Value Loss: 5.008    Reward Loss: 0.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 58070      Buffer Size: 5190       Transition Number: 149.985 k Batch Size: 128        Lr: 0.100   
[2021-11-01 10:51:51,662][train][INFO][train.py>_log] ==> #160000     Total Loss: 4.128    [weighted Loss:4.128    Policy Loss: 10.637   Value Loss: 5.041    Reward Loss: 0.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 58190      Buffer Size: 5184       Transition Number: 149.962 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:04:17,610][train][INFO][train.py>_log] ==> #161000     Total Loss: 4.161    [weighted Loss:4.161    Policy Loss: 12.335   Value Loss: 4.999    Reward Loss: 0.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 58307      Buffer Size: 5171       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:15:53,609][train][INFO][train.py>_log] ==> #162000     Total Loss: 4.042    [weighted Loss:4.042    Policy Loss: 11.251   Value Loss: 5.194    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 58427      Buffer Size: 5110       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:28:22,728][train][INFO][train.py>_log] ==> #163000     Total Loss: 5.862    [weighted Loss:5.862    Policy Loss: 10.853   Value Loss: 5.137    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 58543      Buffer Size: 5079       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:40:18,812][train][INFO][train.py>_log] ==> #164000     Total Loss: 3.467    [weighted Loss:3.467    Policy Loss: 11.253   Value Loss: 5.499    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 58661      Buffer Size: 5026       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 11:52:24,001][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.747    [weighted Loss:3.747    Policy Loss: 10.636   Value Loss: 5.038    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 58812      Buffer Size: 4989       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:04:11,802][train][INFO][train.py>_log] ==> #166000     Total Loss: 4.954    [weighted Loss:4.954    Policy Loss: 10.739   Value Loss: 5.167    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 58935      Buffer Size: 4979       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:16:27,054][train][INFO][train.py>_log] ==> #167000     Total Loss: 4.445    [weighted Loss:4.445    Policy Loss: 11.515   Value Loss: 5.083    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 59041      Buffer Size: 4921       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:28:18,424][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 11.098   Value Loss: 5.035    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 59180      Buffer Size: 4915       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:40:02,901][train][INFO][train.py>_log] ==> #169000     Total Loss: 4.839    [weighted Loss:4.839    Policy Loss: 11.320   Value Loss: 4.772    Reward Loss: 0.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 59315      Buffer Size: 4941       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-01 12:51:58,680][train][INFO][train.py>_log] ==> #170000     Total Loss: 4.177    [weighted Loss:4.177    Policy Loss: 10.771   Value Loss: 5.052    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 59436      Buffer Size: 4961       Transition Number: 149.960 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:04:01,638][train][INFO][train.py>_log] ==> #171000     Total Loss: 5.745    [weighted Loss:5.745    Policy Loss: 11.113   Value Loss: 5.188    Reward Loss: 0.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 59546      Buffer Size: 4966       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:15:57,812][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 10.631   Value Loss: 4.783    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 59658      Buffer Size: 4969       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:28:05,733][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 11.800   Value Loss: 5.077    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 59768      Buffer Size: 4955       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:39:35,899][train][INFO][train.py>_log] ==> #174000     Total Loss: 5.543    [weighted Loss:5.543    Policy Loss: 12.410   Value Loss: 4.954    Reward Loss: 0.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 59942      Buffer Size: 5022       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-01 13:51:39,279][train][INFO][train.py>_log] ==> #175000     Total Loss: 4.564    [weighted Loss:4.564    Policy Loss: 12.043   Value Loss: 5.000    Reward Loss: 0.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 60045      Buffer Size: 5040       Transition Number: 150.018 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:03:10,235][train][INFO][train.py>_log] ==> #176000     Total Loss: 5.772    [weighted Loss:5.772    Policy Loss: 11.500   Value Loss: 4.890    Reward Loss: 0.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 60219      Buffer Size: 5103       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:16:18,493][train][INFO][train.py>_log] ==> #177000     Total Loss: 4.100    [weighted Loss:4.100    Policy Loss: 11.213   Value Loss: 5.070    Reward Loss: 0.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 60400      Buffer Size: 5142       Transition Number: 149.991 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:28:21,494][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 11.060   Value Loss: 4.566    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 60602      Buffer Size: 5200       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:39:55,307][train][INFO][train.py>_log] ==> #179000     Total Loss: 4.044    [weighted Loss:4.044    Policy Loss: 10.972   Value Loss: 4.711    Reward Loss: 0.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 60700      Buffer Size: 5193       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 14:51:48,530][train][INFO][train.py>_log] ==> #180000     Total Loss: 4.109    [weighted Loss:4.109    Policy Loss: 10.668   Value Loss: 4.567    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 60901      Buffer Size: 5252       Transition Number: 149.981 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:03:48,675][train][INFO][train.py>_log] ==> #181000     Total Loss: 7.382    [weighted Loss:7.382    Policy Loss: 12.348   Value Loss: 4.807    Reward Loss: 0.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 60999      Buffer Size: 5193       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:15:58,578][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 10.971   Value Loss: 5.190    Reward Loss: 0.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 61116      Buffer Size: 5138       Transition Number: 150.020 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:27:39,853][train][INFO][train.py>_log] ==> #183000     Total Loss: 4.885    [weighted Loss:4.885    Policy Loss: 12.889   Value Loss: 4.992    Reward Loss: 0.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 61339      Buffer Size: 5195       Transition Number: 149.955 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:39:39,485][train][INFO][train.py>_log] ==> #184000     Total Loss: 4.209    [weighted Loss:4.209    Policy Loss: 10.872   Value Loss: 5.245    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 61469      Buffer Size: 5215       Transition Number: 149.941 k Batch Size: 128        Lr: 0.100   
[2021-11-01 15:51:27,182][train][INFO][train.py>_log] ==> #185000     Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 11.717   Value Loss: 5.065    Reward Loss: 0.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 61594      Buffer Size: 5211       Transition Number: 149.962 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:03:02,193][train][INFO][train.py>_log] ==> #186000     Total Loss: 4.972    [weighted Loss:4.972    Policy Loss: 11.226   Value Loss: 5.195    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 61711      Buffer Size: 5244       Transition Number: 149.967 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:14:36,264][train][INFO][train.py>_log] ==> #187000     Total Loss: 0.991    [weighted Loss:0.991    Policy Loss: 11.378   Value Loss: 5.107    Reward Loss: 0.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 61824      Buffer Size: 5274       Transition Number: 149.968 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:26:17,879][train][INFO][train.py>_log] ==> #188000     Total Loss: 4.499    [weighted Loss:4.499    Policy Loss: 10.893   Value Loss: 4.894    Reward Loss: 0.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 61931      Buffer Size: 5302       Transition Number: 149.958 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:38:20,062][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.715    [weighted Loss:3.715    Policy Loss: 10.791   Value Loss: 4.792    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 62050      Buffer Size: 5299       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 16:49:47,927][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.988    [weighted Loss:3.988    Policy Loss: 10.839   Value Loss: 5.162    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 62173      Buffer Size: 5314       Transition Number: 149.960 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:01:47,974][train][INFO][train.py>_log] ==> #191000     Total Loss: 5.178    [weighted Loss:5.178    Policy Loss: 10.610   Value Loss: 4.892    Reward Loss: 0.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 62325      Buffer Size: 5361       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:13:18,113][train][INFO][train.py>_log] ==> #192000     Total Loss: 4.069    [weighted Loss:4.069    Policy Loss: 11.602   Value Loss: 4.753    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 62561      Buffer Size: 5494       Transition Number: 149.951 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:24:58,986][train][INFO][train.py>_log] ==> #193000     Total Loss: 1.173    [weighted Loss:1.173    Policy Loss: 9.975    Value Loss: 4.778    Reward Loss: 0.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 62671      Buffer Size: 5500       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:36:30,769][train][INFO][train.py>_log] ==> #194000     Total Loss: 4.727    [weighted Loss:4.727    Policy Loss: 11.278   Value Loss: 4.544    Reward Loss: 0.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 62765      Buffer Size: 5502       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:48:06,620][train][INFO][train.py>_log] ==> #195000     Total Loss: 4.586    [weighted Loss:4.586    Policy Loss: 12.410   Value Loss: 4.849    Reward Loss: 0.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 62836      Buffer Size: 5465       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-01 17:59:53,180][train][INFO][train.py>_log] ==> #196000     Total Loss: 4.107    [weighted Loss:4.107    Policy Loss: 10.972   Value Loss: 4.654    Reward Loss: 0.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 62946      Buffer Size: 5458       Transition Number: 149.978 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:11:29,735][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.803    [weighted Loss:3.803    Policy Loss: 11.494   Value Loss: 4.890    Reward Loss: 0.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 63032      Buffer Size: 5424       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:23:15,174][train][INFO][train.py>_log] ==> #198000     Total Loss: 4.133    [weighted Loss:4.133    Policy Loss: 11.729   Value Loss: 5.250    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 63138      Buffer Size: 5386       Transition Number: 149.969 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:35:15,582][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 10.821   Value Loss: 4.718    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 63248      Buffer Size: 5359       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:47:46,111][train][INFO][train.py>_log] ==> #200000     Total Loss: 5.210    [weighted Loss:5.210    Policy Loss: 10.664   Value Loss: 4.672    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 63397      Buffer Size: 5367       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-01 18:59:25,871][train][INFO][train.py>_log] ==> #201000     Total Loss: 1.428    [weighted Loss:1.428    Policy Loss: 10.974   Value Loss: 5.125    Reward Loss: 0.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 63526      Buffer Size: 5350       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:12:46,242][train][INFO][train.py>_log] ==> #202000     Total Loss: 4.848    [weighted Loss:4.848    Policy Loss: 10.858   Value Loss: 4.873    Reward Loss: 0.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 63625      Buffer Size: 5337       Transition Number: 149.979 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:24:24,290][train][INFO][train.py>_log] ==> #203000     Total Loss: 4.248    [weighted Loss:4.248    Policy Loss: 10.993   Value Loss: 4.641    Reward Loss: 0.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 63741      Buffer Size: 5325       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:35:56,004][train][INFO][train.py>_log] ==> #204000     Total Loss: 4.490    [weighted Loss:4.490    Policy Loss: 9.554    Value Loss: 5.061    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 63830      Buffer Size: 5304       Transition Number: 149.937 k Batch Size: 128        Lr: 0.100   
[2021-11-01 19:49:12,046][train][INFO][train.py>_log] ==> #205000     Total Loss: 4.219    [weighted Loss:4.219    Policy Loss: 10.611   Value Loss: 5.051    Reward Loss: 0.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 64057      Buffer Size: 5389       Transition Number: 150.002 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:02:14,991][train][INFO][train.py>_log] ==> #206000     Total Loss: 4.589    [weighted Loss:4.589    Policy Loss: 9.728    Value Loss: 5.070    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 64235      Buffer Size: 5439       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:14:18,324][train][INFO][train.py>_log] ==> #207000     Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 9.459    Value Loss: 4.782    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 64343      Buffer Size: 5395       Transition Number: 149.986 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:26:44,310][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 10.167   Value Loss: 5.094    Reward Loss: 0.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 64440      Buffer Size: 5399       Transition Number: 149.969 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:39:16,442][train][INFO][train.py>_log] ==> #209000     Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 9.352    Value Loss: 5.102    Reward Loss: 0.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 64529      Buffer Size: 5338       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-01 20:51:56,968][train][INFO][train.py>_log] ==> #210000     Total Loss: 4.221    [weighted Loss:4.221    Policy Loss: 9.458    Value Loss: 5.287    Reward Loss: 0.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 64683      Buffer Size: 5329       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:05:22,552][train][INFO][train.py>_log] ==> #211000     Total Loss: 4.213    [weighted Loss:4.213    Policy Loss: 10.713   Value Loss: 5.161    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 64784      Buffer Size: 5279       Transition Number: 149.979 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:18:27,607][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 10.440   Value Loss: 5.537    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 64876      Buffer Size: 5266       Transition Number: 149.987 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:32:07,460][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 10.550   Value Loss: 4.968    Reward Loss: 0.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 64962      Buffer Size: 5231       Transition Number: 149.969 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:44:37,914][train][INFO][train.py>_log] ==> #214000     Total Loss: 4.416    [weighted Loss:4.416    Policy Loss: 9.846    Value Loss: 5.145    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 65044      Buffer Size: 5151       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 21:57:05,351][train][INFO][train.py>_log] ==> #215000     Total Loss: 3.136    [weighted Loss:3.136    Policy Loss: 9.399    Value Loss: 5.240    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 65115      Buffer Size: 5073       Transition Number: 149.985 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:09:22,682][train][INFO][train.py>_log] ==> #216000     Total Loss: 4.410    [weighted Loss:4.410    Policy Loss: 9.414    Value Loss: 5.220    Reward Loss: 0.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 65183      Buffer Size: 4965       Transition Number: 149.989 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:22:25,997][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.821    [weighted Loss:3.821    Policy Loss: 9.576    Value Loss: 4.914    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 65265      Buffer Size: 4804       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:36:20,186][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 9.462    Value Loss: 4.874    Reward Loss: 0.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 65350      Buffer Size: 4686       Transition Number: 149.992 k Batch Size: 128        Lr: 0.100   
[2021-11-01 22:50:11,389][train][INFO][train.py>_log] ==> #219000     Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 8.341    Value Loss: 5.094    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 65432      Buffer Size: 4548       Transition Number: 149.954 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:03:41,328][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.387    [weighted Loss:3.387    Policy Loss: 9.143    Value Loss: 5.167    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 65533      Buffer Size: 4511       Transition Number: 149.953 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:16:21,528][train][INFO][train.py>_log] ==> #221000     Total Loss: 4.781    [weighted Loss:4.781    Policy Loss: 7.628    Value Loss: 4.678    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 65612      Buffer Size: 4475       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:30:34,244][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 7.919    Value Loss: 5.027    Reward Loss: 0.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 65705      Buffer Size: 4327       Transition Number: 150.000 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:43:50,198][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.910    [weighted Loss:3.910    Policy Loss: 7.189    Value Loss: 5.012    Reward Loss: 0.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 65792      Buffer Size: 4269       Transition Number: 149.998 k Batch Size: 128        Lr: 0.100   
[2021-11-01 23:57:06,756][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.727    [weighted Loss:2.727    Policy Loss: 8.284    Value Loss: 5.197    Reward Loss: 0.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 65878      Buffer Size: 4196       Transition Number: 149.999 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:10:28,837][train][INFO][train.py>_log] ==> #225000     Total Loss: 3.721    [weighted Loss:3.721    Policy Loss: 7.516    Value Loss: 5.061    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 65969      Buffer Size: 4142       Transition Number: 149.942 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:24:22,244][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.453    [weighted Loss:3.453    Policy Loss: 7.442    Value Loss: 4.605    Reward Loss: 0.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 66066      Buffer Size: 4104       Transition Number: 149.988 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:37:11,722][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.372    [weighted Loss:2.372    Policy Loss: 8.051    Value Loss: 4.767    Reward Loss: 0.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 66141      Buffer Size: 4047       Transition Number: 149.990 k Batch Size: 128        Lr: 0.100   
[2021-11-02 00:51:21,450][train][INFO][train.py>_log] ==> #228000     Total Loss: 4.056    [weighted Loss:4.056    Policy Loss: 7.708    Value Loss: 5.361    Reward Loss: 0.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 66219      Buffer Size: 3961       Transition Number: 149.994 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:05:36,068][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 7.797    Value Loss: 5.037    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 66318      Buffer Size: 3776       Transition Number: 149.995 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:19:29,954][train][INFO][train.py>_log] ==> #230000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 7.810    Value Loss: 4.852    Reward Loss: 0.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 66428      Buffer Size: 3737       Transition Number: 149.976 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:33:48,203][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 7.090    Value Loss: 4.601    Reward Loss: 0.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 66540      Buffer Size: 3727       Transition Number: 149.984 k Batch Size: 128        Lr: 0.100   
[2021-11-02 01:47:41,840][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.216    [weighted Loss:2.216    Policy Loss: 8.126    Value Loss: 4.906    Reward Loss: 0.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 66669      Buffer Size: 3723       Transition Number: 149.973 k Batch Size: 128        Lr: 0.100   
