[2021-11-03 07:16:34,214][train][INFO][train.py>_log] ==> #0          Total Loss: 44.146   [weighted Loss:44.146   Policy Loss: 14.148   Value Loss: 27.689   Reward Loss: 23.076   Consistency Loss: 0.000    ] Replay Episodes Collected: 61         Buffer Size: 61         Transition Number: 0.701   k Batch Size: 256        Lr: 0.000   
[2021-11-03 07:25:32,073][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.665    [weighted Loss:5.665    Policy Loss: 13.916   Value Loss: 4.906    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 774        Buffer Size: 774        Transition Number: 9.469   k Batch Size: 256        Lr: 0.010   
[2021-11-03 07:34:45,592][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.253    [weighted Loss:6.253    Policy Loss: 13.649   Value Loss: 3.461    Reward Loss: 0.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1528       Buffer Size: 1528       Transition Number: 18.265  k Batch Size: 256        Lr: 0.020   
[2021-11-03 07:43:58,760][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.070    [weighted Loss:6.070    Policy Loss: 11.997   Value Loss: 3.036    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2366       Buffer Size: 2366       Transition Number: 26.587  k Batch Size: 256        Lr: 0.030   
[2021-11-03 07:53:18,269][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.971    [weighted Loss:5.971    Policy Loss: 12.344   Value Loss: 2.815    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 3151       Buffer Size: 3151       Transition Number: 35.117  k Batch Size: 256        Lr: 0.040   
[2021-11-03 08:02:45,194][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.136    [weighted Loss:5.136    Policy Loss: 12.770   Value Loss: 2.737    Reward Loss: 0.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 3920       Buffer Size: 3920       Transition Number: 43.641  k Batch Size: 256        Lr: 0.050   
[2021-11-03 08:12:22,792][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.547    [weighted Loss:5.547    Policy Loss: 12.814   Value Loss: 2.635    Reward Loss: 0.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 4706       Buffer Size: 4706       Transition Number: 52.562  k Batch Size: 256        Lr: 0.060   
[2021-11-03 08:22:04,104][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.657    [weighted Loss:4.657    Policy Loss: 13.021   Value Loss: 2.698    Reward Loss: 0.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 5446       Buffer Size: 5446       Transition Number: 60.880  k Batch Size: 256        Lr: 0.070   
[2021-11-03 08:31:55,686][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 12.878   Value Loss: 2.539    Reward Loss: 0.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 6040       Buffer Size: 6040       Transition Number: 69.164  k Batch Size: 256        Lr: 0.080   
