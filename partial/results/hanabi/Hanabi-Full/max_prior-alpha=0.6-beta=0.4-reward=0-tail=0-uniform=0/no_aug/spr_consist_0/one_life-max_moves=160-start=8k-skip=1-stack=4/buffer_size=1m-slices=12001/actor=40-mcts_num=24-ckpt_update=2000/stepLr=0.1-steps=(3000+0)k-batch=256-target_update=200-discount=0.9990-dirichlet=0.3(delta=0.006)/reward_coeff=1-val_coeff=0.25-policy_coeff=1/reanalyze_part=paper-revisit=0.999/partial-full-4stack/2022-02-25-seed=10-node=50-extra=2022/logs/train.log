[2022-02-25 03:09:48,134][train][INFO][train.py>_log] ==> #0          Total Loss: 47.801   [weighted Loss:47.801   Policy Loss: 13.329   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1448       Buffer Size: 1448       Transition Number: 15.340  k Batch Size: 256        Lr: 0.00000 
[2022-02-25 03:12:33,615][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.156    [weighted Loss:7.156    Policy Loss: 13.957   Value Loss: 4.497    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 12061      Buffer Size: 12061      Transition Number: 150.852 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:15:22,948][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.869    [weighted Loss:4.869    Policy Loss: 13.729   Value Loss: 4.380    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 22675      Buffer Size: 22675      Transition Number: 282.566 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:18:13,395][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.290    [weighted Loss:6.290    Policy Loss: 12.790   Value Loss: 4.075    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 39376      Buffer Size: 39376      Transition Number: 420.323 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:21:06,082][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.522    [weighted Loss:5.522    Policy Loss: 11.832   Value Loss: 4.300    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 56345      Buffer Size: 56345      Transition Number: 557.612 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:23:59,687][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.805    [weighted Loss:4.805    Policy Loss: 10.262   Value Loss: 4.064    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 73965      Buffer Size: 73965      Transition Number: 697.845 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:27:00,935][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.621    [weighted Loss:4.621    Policy Loss: 9.927    Value Loss: 3.830    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 92376      Buffer Size: 92376      Transition Number: 843.936 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:29:59,814][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.429    [weighted Loss:5.429    Policy Loss: 10.884   Value Loss: 4.050    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 106789     Buffer Size: 106789     Transition Number: 983.516 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:33:02,387][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.957    [weighted Loss:4.957    Policy Loss: 9.992    Value Loss: 4.148    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 121574     Buffer Size: 111374     Transition Number: 1000.347k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:36:07,898][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.039    [weighted Loss:5.039    Policy Loss: 8.718    Value Loss: 4.384    Reward Loss: 1.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 138241     Buffer Size: 115984     Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:39:14,385][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.591    [weighted Loss:3.591    Policy Loss: 7.149    Value Loss: 3.997    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 154733     Buffer Size: 114866     Transition Number: 1000.141k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:42:24,016][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 7.388    Value Loss: 4.169    Reward Loss: 2.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 173130     Buffer Size: 114386     Transition Number: 1000.131k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:45:36,571][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.146    [weighted Loss:4.146    Policy Loss: 8.204    Value Loss: 3.960    Reward Loss: 2.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 192004     Buffer Size: 113766     Transition Number: 1000.304k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:48:44,246][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 8.462    Value Loss: 4.224    Reward Loss: 2.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 207099     Buffer Size: 110687     Transition Number: 1000.023k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:51:48,492][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 8.741    Value Loss: 4.235    Reward Loss: 2.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 221954     Buffer Size: 110527     Transition Number: 1000.172k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:54:51,041][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.946    [weighted Loss:3.946    Policy Loss: 8.163    Value Loss: 4.119    Reward Loss: 2.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 236446     Buffer Size: 109639     Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:57:57,023][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.233    [weighted Loss:5.233    Policy Loss: 9.937    Value Loss: 4.328    Reward Loss: 2.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 250936     Buffer Size: 107736     Transition Number: 1000.174k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:01:02,250][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.001    [weighted Loss:4.001    Policy Loss: 9.634    Value Loss: 4.145    Reward Loss: 2.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 264748     Buffer Size: 104696     Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:04:11,568][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.963    [weighted Loss:5.963    Policy Loss: 8.370    Value Loss: 4.564    Reward Loss: 2.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 278925     Buffer Size: 100472     Transition Number: 1000.135k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:07:13,732][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 9.427    Value Loss: 4.549    Reward Loss: 2.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 289949     Buffer Size: 94507      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:10:18,311][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.271    [weighted Loss:5.271    Policy Loss: 8.889    Value Loss: 4.482    Reward Loss: 2.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 301056     Buffer Size: 90969      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:13:17,380][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.315    [weighted Loss:5.315    Policy Loss: 8.919    Value Loss: 4.531    Reward Loss: 2.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 308088     Buffer Size: 84433      Transition Number: 1000.199k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:16:20,363][train][INFO][train.py>_log] ==> #22000      Total Loss: 5.528    [weighted Loss:5.528    Policy Loss: 9.286    Value Loss: 4.564    Reward Loss: 2.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 315158     Buffer Size: 77782      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:19:21,780][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.449    [weighted Loss:4.449    Policy Loss: 7.647    Value Loss: 4.814    Reward Loss: 2.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 320731     Buffer Size: 70119      Transition Number: 1000.207k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:22:21,354][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.470    [weighted Loss:3.470    Policy Loss: 7.243    Value Loss: 4.983    Reward Loss: 2.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 326202     Buffer Size: 62888      Transition Number: 1000.273k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:25:22,484][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.799    [weighted Loss:4.799    Policy Loss: 6.291    Value Loss: 4.926    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 329043     Buffer Size: 55399      Transition Number: 1000.149k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:28:22,965][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 5.459    Value Loss: 4.579    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 332051     Buffer Size: 47310      Transition Number: 1000.262k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:31:23,772][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 7.274    Value Loss: 4.934    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 333991     Buffer Size: 40294      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:34:25,197][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 4.296    Value Loss: 4.333    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 336079     Buffer Size: 33100      Transition Number: 1000.180k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:37:28,297][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 4.355    Value Loss: 4.589    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 337961     Buffer Size: 28249      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:40:28,829][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.755    [weighted Loss:1.755    Policy Loss: 4.041    Value Loss: 4.547    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 339951     Buffer Size: 23245      Transition Number: 1000.276k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:43:28,601][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 4.378    Value Loss: 4.618    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 341891     Buffer Size: 19700      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:46:31,553][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 3.971    Value Loss: 4.283    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 343937     Buffer Size: 16490      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:49:31,063][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.857    [weighted Loss:1.857    Policy Loss: 4.644    Value Loss: 4.284    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 345774     Buffer Size: 15323      Transition Number: 1000.132k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:52:29,666][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 4.297    Value Loss: 4.344    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 347666     Buffer Size: 14556      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:55:33,571][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 4.448    Value Loss: 4.518    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 349700     Buffer Size: 14430      Transition Number: 1000.061k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:58:33,017][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 4.402    Value Loss: 4.628    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 351685     Buffer Size: 14482      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:01:35,308][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 4.325    Value Loss: 4.763    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 353761     Buffer Size: 14707      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:04:35,220][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 4.269    Value Loss: 5.348    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 355823     Buffer Size: 14917      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:07:34,646][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 4.727    Value Loss: 5.331    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 357800     Buffer Size: 15006      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:10:36,564][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 4.394    Value Loss: 5.022    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 359788     Buffer Size: 15108      Transition Number: 1000.316k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:13:38,659][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 3.926    Value Loss: 5.003    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 361721     Buffer Size: 15104      Transition Number: 1000.247k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:16:39,161][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.368    [weighted Loss:2.368    Policy Loss: 4.023    Value Loss: 4.767    Reward Loss: 0.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 363624     Buffer Size: 15065      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:19:39,629][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.865    [weighted Loss:1.865    Policy Loss: 4.241    Value Loss: 4.986    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 365591     Buffer Size: 14865      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:22:41,193][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 4.111    Value Loss: 4.679    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 367560     Buffer Size: 14596      Transition Number: 1000.264k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:25:39,837][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 4.270    Value Loss: 4.971    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 369609     Buffer Size: 14378      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:28:40,705][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 4.809    Value Loss: 4.865    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 371578     Buffer Size: 14260      Transition Number: 1000.336k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:31:42,664][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 4.751    Value Loss: 4.905    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 373588     Buffer Size: 14199      Transition Number: 1000.654k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:34:41,271][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 5.495    Value Loss: 4.256    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 375530     Buffer Size: 14225      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:37:43,374][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 5.294    Value Loss: 4.677    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 377547     Buffer Size: 14294      Transition Number: 1000.205k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:40:43,681][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.693    [weighted Loss:2.693    Policy Loss: 5.646    Value Loss: 4.454    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 379549     Buffer Size: 14423      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:43:44,060][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 5.747    Value Loss: 4.903    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 381590     Buffer Size: 14519      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:46:47,553][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 5.669    Value Loss: 4.593    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 383635     Buffer Size: 14543      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:49:49,467][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 5.685    Value Loss: 4.795    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 385622     Buffer Size: 14535      Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:52:48,253][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 5.788    Value Loss: 4.628    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 387624     Buffer Size: 14497      Transition Number: 1000.136k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:55:49,642][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.417    [weighted Loss:1.417    Policy Loss: 5.726    Value Loss: 4.822    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 389799     Buffer Size: 14666      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:58:51,587][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 6.074    Value Loss: 4.921    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 391981     Buffer Size: 14872      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:01:51,729][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 5.898    Value Loss: 4.682    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 393894     Buffer Size: 14854      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:04:51,422][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 6.944    Value Loss: 4.775    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 395890     Buffer Size: 14867      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:07:51,812][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 6.531    Value Loss: 4.916    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 397878     Buffer Size: 14868      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:10:51,120][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.579    [weighted Loss:3.579    Policy Loss: 6.634    Value Loss: 4.526    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 399849     Buffer Size: 14912      Transition Number: 1000.542k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:13:50,651][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 6.738    Value Loss: 5.018    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 401829     Buffer Size: 14941      Transition Number: 1000.047k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:16:52,776][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.703    [weighted Loss:3.703    Policy Loss: 6.931    Value Loss: 4.481    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 403863     Buffer Size: 14865      Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:19:53,228][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 7.511    Value Loss: 4.603    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 405996     Buffer Size: 14796      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:22:52,188][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 7.873    Value Loss: 4.924    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 408103     Buffer Size: 14796      Transition Number: 1000.578k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:25:51,591][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.244    [weighted Loss:3.244    Policy Loss: 7.978    Value Loss: 5.154    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 409929     Buffer Size: 14877      Transition Number: 1000.317k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:28:51,571][train][INFO][train.py>_log] ==> #66000      Total Loss: 4.069    [weighted Loss:4.069    Policy Loss: 8.017    Value Loss: 4.914    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 411934     Buffer Size: 14927      Transition Number: 1000.316k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:31:54,423][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.571    [weighted Loss:1.571    Policy Loss: 7.919    Value Loss: 4.687    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 413992     Buffer Size: 14993      Transition Number: 999.939 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:34:54,981][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.157    [weighted Loss:4.157    Policy Loss: 8.583    Value Loss: 4.539    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 416072     Buffer Size: 15094      Transition Number: 1000.151k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:37:54,158][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.575    [weighted Loss:3.575    Policy Loss: 7.837    Value Loss: 5.426    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 418349     Buffer Size: 15422      Transition Number: 1000.007k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:40:58,707][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 7.964    Value Loss: 5.125    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 420644     Buffer Size: 15731      Transition Number: 1000.117k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:43:58,238][train][INFO][train.py>_log] ==> #71000      Total Loss: 5.411    [weighted Loss:5.411    Policy Loss: 9.006    Value Loss: 4.846    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 422764     Buffer Size: 15861      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:46:53,478][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.472    [weighted Loss:1.472    Policy Loss: 10.282   Value Loss: 5.233    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 424838     Buffer Size: 16029      Transition Number: 1000.452k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:49:55,932][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 9.813    Value Loss: 5.215    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 426838     Buffer Size: 16127      Transition Number: 1000.405k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:52:56,459][train][INFO][train.py>_log] ==> #74000      Total Loss: 5.663    [weighted Loss:5.663    Policy Loss: 10.063   Value Loss: 5.085    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 428864     Buffer Size: 16177      Transition Number: 1000.349k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:55:58,772][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.049    [weighted Loss:4.049    Policy Loss: 9.951    Value Loss: 5.170    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 430875     Buffer Size: 16209      Transition Number: 1000.234k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:59:00,121][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.411    [weighted Loss:4.411    Policy Loss: 10.127   Value Loss: 5.252    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 432898     Buffer Size: 16158      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:02:03,159][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.256    [weighted Loss:4.256    Policy Loss: 10.677   Value Loss: 5.398    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 435085     Buffer Size: 15919      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:05:03,940][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.823    [weighted Loss:4.823    Policy Loss: 10.434   Value Loss: 5.010    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 437153     Buffer Size: 15722      Transition Number: 1000.488k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:08:08,990][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 10.947   Value Loss: 5.209    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 439325     Buffer Size: 15587      Transition Number: 1000.320k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:11:11,733][train][INFO][train.py>_log] ==> #80000      Total Loss: 5.060    [weighted Loss:5.060    Policy Loss: 11.106   Value Loss: 5.365    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 441459     Buffer Size: 15505      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:14:13,950][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.581    [weighted Loss:4.581    Policy Loss: 10.422   Value Loss: 5.141    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 443594     Buffer Size: 15599      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:17:17,686][train][INFO][train.py>_log] ==> #82000      Total Loss: 4.787    [weighted Loss:4.787    Policy Loss: 9.939    Value Loss: 5.154    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 445763     Buffer Size: 15724      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:20:20,922][train][INFO][train.py>_log] ==> #83000      Total Loss: 5.466    [weighted Loss:5.466    Policy Loss: 9.672    Value Loss: 4.771    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 447909     Buffer Size: 15800      Transition Number: 1000.235k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:23:19,611][train][INFO][train.py>_log] ==> #84000      Total Loss: 5.156    [weighted Loss:5.156    Policy Loss: 9.615    Value Loss: 5.237    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 449968     Buffer Size: 15862      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:26:19,084][train][INFO][train.py>_log] ==> #85000      Total Loss: 4.105    [weighted Loss:4.105    Policy Loss: 9.474    Value Loss: 5.195    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 451922     Buffer Size: 15763      Transition Number: 1000.564k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:29:19,870][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.072    [weighted Loss:4.072    Policy Loss: 9.444    Value Loss: 4.932    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 453925     Buffer Size: 15702      Transition Number: 1000.220k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:32:18,057][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.564    [weighted Loss:4.564    Policy Loss: 8.920    Value Loss: 5.362    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 455930     Buffer Size: 15636      Transition Number: 1000.160k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:35:20,193][train][INFO][train.py>_log] ==> #88000      Total Loss: 3.674    [weighted Loss:3.674    Policy Loss: 9.342    Value Loss: 5.130    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 457958     Buffer Size: 15580      Transition Number: 1000.141k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:38:22,963][train][INFO][train.py>_log] ==> #89000      Total Loss: 5.010    [weighted Loss:5.010    Policy Loss: 8.931    Value Loss: 4.863    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 459970     Buffer Size: 15399      Transition Number: 1000.326k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:41:22,933][train][INFO][train.py>_log] ==> #90000      Total Loss: 4.242    [weighted Loss:4.242    Policy Loss: 9.606    Value Loss: 4.991    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 462009     Buffer Size: 15228      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:44:23,623][train][INFO][train.py>_log] ==> #91000      Total Loss: 4.498    [weighted Loss:4.498    Policy Loss: 8.849    Value Loss: 5.004    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 464001     Buffer Size: 15052      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:47:26,759][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 9.023    Value Loss: 4.839    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 466024     Buffer Size: 14982      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:50:24,603][train][INFO][train.py>_log] ==> #93000      Total Loss: 4.021    [weighted Loss:4.021    Policy Loss: 9.057    Value Loss: 4.750    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 468011     Buffer Size: 14969      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:53:24,577][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.372    [weighted Loss:4.372    Policy Loss: 9.384    Value Loss: 4.858    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 470019     Buffer Size: 14957      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:56:27,041][train][INFO][train.py>_log] ==> #95000      Total Loss: 4.444    [weighted Loss:4.444    Policy Loss: 9.103    Value Loss: 4.779    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 472089     Buffer Size: 14883      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:59:26,989][train][INFO][train.py>_log] ==> #96000      Total Loss: 4.894    [weighted Loss:4.894    Policy Loss: 9.430    Value Loss: 4.460    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 474136     Buffer Size: 14845      Transition Number: 1000.218k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:02:27,697][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.867    [weighted Loss:2.867    Policy Loss: 9.011    Value Loss: 4.817    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 476210     Buffer Size: 14829      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:05:31,345][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.846    [weighted Loss:3.846    Policy Loss: 9.427    Value Loss: 4.650    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 478325     Buffer Size: 14841      Transition Number: 1000.171k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:08:30,551][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.449    [weighted Loss:3.449    Policy Loss: 9.459    Value Loss: 4.757    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 480466     Buffer Size: 14891      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:11:30,542][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 9.597    Value Loss: 4.800    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 482531     Buffer Size: 14909      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:14:33,547][train][INFO][train.py>_log] ==> #101000     Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 8.884    Value Loss: 4.663    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 484599     Buffer Size: 14908      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:17:34,972][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.623    [weighted Loss:3.623    Policy Loss: 9.810    Value Loss: 5.162    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 486707     Buffer Size: 14939      Transition Number: 1000.214k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:20:39,320][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.927    [weighted Loss:2.927    Policy Loss: 9.166    Value Loss: 4.995    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 488865     Buffer Size: 15029      Transition Number: 1000.143k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:23:40,489][train][INFO][train.py>_log] ==> #104000     Total Loss: 5.357    [weighted Loss:5.357    Policy Loss: 9.317    Value Loss: 5.227    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 490905     Buffer Size: 15130      Transition Number: 1000.393k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:26:40,277][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.957    [weighted Loss:4.957    Policy Loss: 9.298    Value Loss: 4.885    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 492967     Buffer Size: 15189      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:29:43,987][train][INFO][train.py>_log] ==> #106000     Total Loss: 4.902    [weighted Loss:4.902    Policy Loss: 9.720    Value Loss: 4.841    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 495018     Buffer Size: 15220      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:32:45,970][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 9.488    Value Loss: 5.157    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 497068     Buffer Size: 15189      Transition Number: 1000.027k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:35:47,082][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.282    [weighted Loss:4.282    Policy Loss: 9.350    Value Loss: 4.971    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 499156     Buffer Size: 15184      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:38:50,459][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 8.932    Value Loss: 5.073    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 501328     Buffer Size: 15314      Transition Number: 1000.224k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:41:49,688][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 9.425    Value Loss: 5.227    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 503458     Buffer Size: 15402      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:44:49,890][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.719    [weighted Loss:3.719    Policy Loss: 9.105    Value Loss: 5.120    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 505544     Buffer Size: 15395      Transition Number: 1000.571k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:47:52,048][train][INFO][train.py>_log] ==> #112000     Total Loss: 4.780    [weighted Loss:4.780    Policy Loss: 9.544    Value Loss: 5.153    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 507634     Buffer Size: 15400      Transition Number: 1000.137k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:50:52,455][train][INFO][train.py>_log] ==> #113000     Total Loss: 5.488    [weighted Loss:5.488    Policy Loss: 9.505    Value Loss: 5.144    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 509734     Buffer Size: 15407      Transition Number: 1000.192k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:53:53,208][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.645    [weighted Loss:3.645    Policy Loss: 9.412    Value Loss: 5.256    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 511791     Buffer Size: 15497      Transition Number: 1000.511k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:56:54,928][train][INFO][train.py>_log] ==> #115000     Total Loss: 5.125    [weighted Loss:5.125    Policy Loss: 9.577    Value Loss: 4.969    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 513875     Buffer Size: 15540      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:59:57,770][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 9.542    Value Loss: 5.289    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 515972     Buffer Size: 15510      Transition Number: 1000.128k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:02:58,318][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 9.595    Value Loss: 5.175    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 518046     Buffer Size: 15352      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:06:00,184][train][INFO][train.py>_log] ==> #118000     Total Loss: 5.190    [weighted Loss:5.190    Policy Loss: 9.109    Value Loss: 5.311    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 520056     Buffer Size: 15278      Transition Number: 1000.394k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:09:02,695][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.340    [weighted Loss:4.340    Policy Loss: 9.331    Value Loss: 5.143    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 522092     Buffer Size: 15178      Transition Number: 1000.251k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:12:01,269][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.778    [weighted Loss:3.778    Policy Loss: 9.667    Value Loss: 5.179    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 524120     Buffer Size: 15075      Transition Number: 1000.589k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:15:04,235][train][INFO][train.py>_log] ==> #121000     Total Loss: 5.083    [weighted Loss:5.083    Policy Loss: 9.813    Value Loss: 4.854    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 526201     Buffer Size: 14960      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:18:03,815][train][INFO][train.py>_log] ==> #122000     Total Loss: 4.300    [weighted Loss:4.300    Policy Loss: 9.605    Value Loss: 5.065    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 528298     Buffer Size: 14886      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:21:04,128][train][INFO][train.py>_log] ==> #123000     Total Loss: 4.543    [weighted Loss:4.543    Policy Loss: 9.796    Value Loss: 5.125    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 530391     Buffer Size: 14901      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:24:06,368][train][INFO][train.py>_log] ==> #124000     Total Loss: 5.084    [weighted Loss:5.084    Policy Loss: 9.886    Value Loss: 4.992    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 532440     Buffer Size: 14916      Transition Number: 1000.364k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:27:08,492][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 9.263    Value Loss: 5.033    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 534530     Buffer Size: 14918      Transition Number: 1000.162k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:30:08,132][train][INFO][train.py>_log] ==> #126000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 8.880    Value Loss: 4.897    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 536566     Buffer Size: 14945      Transition Number: 1000.120k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:33:09,618][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 8.576    Value Loss: 4.676    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 538718     Buffer Size: 15013      Transition Number: 1000.271k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:36:14,478][train][INFO][train.py>_log] ==> #128000     Total Loss: 3.077    [weighted Loss:3.077    Policy Loss: 8.899    Value Loss: 5.103    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 540815     Buffer Size: 15058      Transition Number: 1000.298k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:39:15,155][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 8.181    Value Loss: 4.723    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 542816     Buffer Size: 15096      Transition Number: 1000.328k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:42:16,195][train][INFO][train.py>_log] ==> #130000     Total Loss: 4.131    [weighted Loss:4.131    Policy Loss: 8.158    Value Loss: 5.002    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 544878     Buffer Size: 15074      Transition Number: 1000.020k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:45:18,834][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.950    [weighted Loss:3.950    Policy Loss: 8.837    Value Loss: 4.921    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 546891     Buffer Size: 15040      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:48:20,340][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.787    [weighted Loss:3.787    Policy Loss: 8.674    Value Loss: 4.867    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 548991     Buffer Size: 15021      Transition Number: 1000.231k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:51:23,166][train][INFO][train.py>_log] ==> #133000     Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.736    Value Loss: 4.904    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 551082     Buffer Size: 15043      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:54:25,896][train][INFO][train.py>_log] ==> #134000     Total Loss: 3.630    [weighted Loss:3.630    Policy Loss: 7.777    Value Loss: 4.935    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 553112     Buffer Size: 15072      Transition Number: 1000.303k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:57:25,375][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 7.539    Value Loss: 5.095    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 555124     Buffer Size: 15133      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:00:26,896][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 7.519    Value Loss: 4.935    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 557221     Buffer Size: 15228      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:03:30,662][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.961    [weighted Loss:3.961    Policy Loss: 8.399    Value Loss: 4.874    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 559278     Buffer Size: 15277      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:06:31,952][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.171    [weighted Loss:4.171    Policy Loss: 8.107    Value Loss: 5.115    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 561410     Buffer Size: 15340      Transition Number: 1000.173k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:09:35,493][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.699    [weighted Loss:3.699    Policy Loss: 8.495    Value Loss: 5.223    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 563482     Buffer Size: 15390      Transition Number: 1000.457k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:12:40,971][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.614    [weighted Loss:3.614    Policy Loss: 8.339    Value Loss: 5.000    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 565550     Buffer Size: 15384      Transition Number: 1000.444k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:15:41,895][train][INFO][train.py>_log] ==> #141000     Total Loss: 4.017    [weighted Loss:4.017    Policy Loss: 8.016    Value Loss: 4.926    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 567639     Buffer Size: 15410      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:18:44,302][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.636    [weighted Loss:3.636    Policy Loss: 8.106    Value Loss: 4.885    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 569695     Buffer Size: 15411      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:21:44,352][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 8.501    Value Loss: 4.999    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 571826     Buffer Size: 15379      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:24:43,663][train][INFO][train.py>_log] ==> #144000     Total Loss: 4.225    [weighted Loss:4.225    Policy Loss: 8.627    Value Loss: 4.927    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 573835     Buffer Size: 15384      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:27:45,996][train][INFO][train.py>_log] ==> #145000     Total Loss: 4.348    [weighted Loss:4.348    Policy Loss: 9.094    Value Loss: 5.093    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 575987     Buffer Size: 15403      Transition Number: 1000.125k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:30:47,779][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 8.392    Value Loss: 5.037    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 578042     Buffer Size: 15447      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:33:48,094][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 8.355    Value Loss: 5.740    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 581966     Buffer Size: 17282      Transition Number: 1000.192k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:36:51,371][train][INFO][train.py>_log] ==> #148000     Total Loss: 4.986    [weighted Loss:4.986    Policy Loss: 8.613    Value Loss: 5.462    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 585844     Buffer Size: 19174      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:39:51,490][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 8.374    Value Loss: 5.573    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 588960     Buffer Size: 20240      Transition Number: 1000.480k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:42:51,666][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.852    [weighted Loss:3.852    Policy Loss: 8.524    Value Loss: 5.822    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 592008     Buffer Size: 21251      Transition Number: 1000.200k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:45:55,596][train][INFO][train.py>_log] ==> #151000     Total Loss: 3.919    [weighted Loss:3.919    Policy Loss: 7.766    Value Loss: 5.905    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 594047     Buffer Size: 21243      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:48:55,885][train][INFO][train.py>_log] ==> #152000     Total Loss: 3.447    [weighted Loss:3.447    Policy Loss: 7.012    Value Loss: 5.592    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 595963     Buffer Size: 21206      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:51:57,317][train][INFO][train.py>_log] ==> #153000     Total Loss: 3.810    [weighted Loss:3.810    Policy Loss: 7.071    Value Loss: 5.550    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 598034     Buffer Size: 21177      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:54:59,749][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.519    [weighted Loss:3.519    Policy Loss: 7.236    Value Loss: 5.156    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 600099     Buffer Size: 20544      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:58:00,406][train][INFO][train.py>_log] ==> #155000     Total Loss: 4.403    [weighted Loss:4.403    Policy Loss: 6.833    Value Loss: 5.351    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 602178     Buffer Size: 18523      Transition Number: 1000.071k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:00:59,513][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 7.014    Value Loss: 5.327    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 604175     Buffer Size: 16999      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:04:02,275][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.177    [weighted Loss:3.177    Policy Loss: 7.552    Value Loss: 4.878    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 606198     Buffer Size: 15999      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:07:08,104][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.988    [weighted Loss:3.988    Policy Loss: 7.302    Value Loss: 5.046    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 608283     Buffer Size: 15403      Transition Number: 1000.114k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:10:12,364][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 7.378    Value Loss: 5.095    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 610408     Buffer Size: 15414      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:13:18,655][train][INFO][train.py>_log] ==> #160000     Total Loss: 3.108    [weighted Loss:3.108    Policy Loss: 8.418    Value Loss: 5.006    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 612499     Buffer Size: 15421      Transition Number: 1000.095k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:16:24,206][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 7.467    Value Loss: 5.098    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 614592     Buffer Size: 15406      Transition Number: 1000.114k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:19:28,399][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 8.185    Value Loss: 5.253    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 616667     Buffer Size: 15407      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:22:34,765][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.676    [weighted Loss:3.676    Policy Loss: 8.289    Value Loss: 4.870    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 618767     Buffer Size: 15412      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:25:38,926][train][INFO][train.py>_log] ==> #164000     Total Loss: 4.444    [weighted Loss:4.444    Policy Loss: 8.570    Value Loss: 4.707    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 620848     Buffer Size: 15384      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:28:43,031][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.961    [weighted Loss:2.961    Policy Loss: 8.166    Value Loss: 4.778    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 623023     Buffer Size: 15427      Transition Number: 1000.250k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:31:49,769][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.017    [weighted Loss:3.017    Policy Loss: 8.138    Value Loss: 5.098    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 625228     Buffer Size: 15467      Transition Number: 1000.178k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:34:54,671][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.639    [weighted Loss:3.639    Policy Loss: 7.913    Value Loss: 5.046    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 627319     Buffer Size: 15508      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:37:59,911][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 7.473    Value Loss: 5.097    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 629492     Buffer Size: 15575      Transition Number: 1000.113k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:41:06,063][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 7.939    Value Loss: 5.304    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 631722     Buffer Size: 15708      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:44:10,139][train][INFO][train.py>_log] ==> #170000     Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 8.238    Value Loss: 5.339    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 633921     Buffer Size: 15858      Transition Number: 1000.270k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:47:12,374][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 8.470    Value Loss: 6.041    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 636115     Buffer Size: 16031      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:50:18,569][train][INFO][train.py>_log] ==> #172000     Total Loss: 3.636    [weighted Loss:3.636    Policy Loss: 7.982    Value Loss: 5.623    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 638361     Buffer Size: 16151      Transition Number: 1000.095k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:53:23,766][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.906    [weighted Loss:3.906    Policy Loss: 8.376    Value Loss: 5.817    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 640474     Buffer Size: 16138      Transition Number: 1000.201k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:56:28,772][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.910    [weighted Loss:3.910    Policy Loss: 8.731    Value Loss: 5.351    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 642542     Buffer Size: 16181      Transition Number: 1000.406k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:59:34,705][train][INFO][train.py>_log] ==> #175000     Total Loss: 4.099    [weighted Loss:4.099    Policy Loss: 8.944    Value Loss: 5.061    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 644628     Buffer Size: 16136      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:02:38,676][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.674    [weighted Loss:3.674    Policy Loss: 8.920    Value Loss: 5.366    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 646739     Buffer Size: 16038      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:05:42,506][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.465    [weighted Loss:3.465    Policy Loss: 9.112    Value Loss: 5.645    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 648851     Buffer Size: 15953      Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:08:49,560][train][INFO][train.py>_log] ==> #178000     Total Loss: 4.011    [weighted Loss:4.011    Policy Loss: 9.279    Value Loss: 5.373    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 650972     Buffer Size: 15800      Transition Number: 1000.124k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:11:56,085][train][INFO][train.py>_log] ==> #179000     Total Loss: 4.637    [weighted Loss:4.637    Policy Loss: 9.637    Value Loss: 5.451    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 653101     Buffer Size: 15744      Transition Number: 1000.191k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:14:59,696][train][INFO][train.py>_log] ==> #180000     Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 8.772    Value Loss: 5.465    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 655290     Buffer Size: 15789      Transition Number: 1000.474k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:18:06,015][train][INFO][train.py>_log] ==> #181000     Total Loss: 4.026    [weighted Loss:4.026    Policy Loss: 8.216    Value Loss: 5.088    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 657469     Buffer Size: 15837      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:21:12,245][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 7.782    Value Loss: 5.488    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 659642     Buffer Size: 15913      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:24:15,614][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.512    Value Loss: 5.333    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 661701     Buffer Size: 15938      Transition Number: 1000.316k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:27:19,084][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.292    [weighted Loss:3.292    Policy Loss: 7.222    Value Loss: 4.871    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 663696     Buffer Size: 15923      Transition Number: 1000.289k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:30:23,786][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 8.034    Value Loss: 5.503    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 665902     Buffer Size: 15970      Transition Number: 1000.398k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:33:27,904][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 7.303    Value Loss: 4.999    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 667986     Buffer Size: 15998      Transition Number: 1000.424k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:36:34,661][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.917    [weighted Loss:3.917    Policy Loss: 7.237    Value Loss: 5.343    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 670119     Buffer Size: 15917      Transition Number: 1000.220k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:39:40,924][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.400    [weighted Loss:3.400    Policy Loss: 7.065    Value Loss: 5.176    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 672303     Buffer Size: 15856      Transition Number: 1000.498k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:42:45,169][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 6.945    Value Loss: 4.886    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 674407     Buffer Size: 15773      Transition Number: 1000.704k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:45:46,689][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.546    [weighted Loss:3.546    Policy Loss: 6.801    Value Loss: 5.273    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 676459     Buffer Size: 15706      Transition Number: 1000.107k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:48:50,590][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.107    [weighted Loss:3.107    Policy Loss: 6.396    Value Loss: 4.953    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 678461     Buffer Size: 15661      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:51:53,046][train][INFO][train.py>_log] ==> #192000     Total Loss: 3.479    [weighted Loss:3.479    Policy Loss: 6.639    Value Loss: 5.023    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 680571     Buffer Size: 15589      Transition Number: 1000.235k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:54:56,951][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 6.427    Value Loss: 4.910    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 682746     Buffer Size: 15520      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:58:02,833][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.368    Value Loss: 4.803    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 684813     Buffer Size: 15454      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:01:06,006][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 6.394    Value Loss: 4.824    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 686915     Buffer Size: 15410      Transition Number: 1000.121k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:04:07,896][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.996    [weighted Loss:3.996    Policy Loss: 6.820    Value Loss: 4.844    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 688999     Buffer Size: 15391      Transition Number: 1000.229k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:07:12,787][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 6.453    Value Loss: 4.893    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 691138     Buffer Size: 15430      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:10:12,379][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.467    [weighted Loss:3.467    Policy Loss: 6.606    Value Loss: 4.776    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 693216     Buffer Size: 15492      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:13:15,353][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.830    [weighted Loss:3.830    Policy Loss: 7.166    Value Loss: 4.932    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 695288     Buffer Size: 15560      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:16:34,548][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 6.856    Value Loss: 5.326    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 697361     Buffer Size: 15619      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:19:35,411][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 6.427    Value Loss: 4.903    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 699643     Buffer Size: 15629      Transition Number: 1000.191k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:22:37,587][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 6.601    Value Loss: 5.008    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 701732     Buffer Size: 15627      Transition Number: 1000.037k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:25:44,051][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.645    [weighted Loss:2.645    Policy Loss: 6.298    Value Loss: 4.747    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 703815     Buffer Size: 15547      Transition Number: 1000.192k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:28:46,842][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 6.119    Value Loss: 4.776    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 705925     Buffer Size: 15450      Transition Number: 1000.157k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:31:51,050][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 6.181    Value Loss: 4.953    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 708011     Buffer Size: 15297      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:34:57,859][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 6.180    Value Loss: 4.651    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 710117     Buffer Size: 15152      Transition Number: 1000.027k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:38:00,685][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 6.604    Value Loss: 4.525    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 712207     Buffer Size: 15017      Transition Number: 1000.467k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:41:02,725][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 6.444    Value Loss: 4.722    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 714237     Buffer Size: 14909      Transition Number: 999.995 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:44:08,174][train][INFO][train.py>_log] ==> #209000     Total Loss: 3.292    [weighted Loss:3.292    Policy Loss: 6.653    Value Loss: 4.403    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 716346     Buffer Size: 14788      Transition Number: 1000.133k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:47:12,570][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 6.551    Value Loss: 4.020    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 718382     Buffer Size: 14742      Transition Number: 999.985 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:50:16,845][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.728    [weighted Loss:2.728    Policy Loss: 6.573    Value Loss: 4.536    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 720450     Buffer Size: 14713      Transition Number: 1000.166k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:53:23,631][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 6.821    Value Loss: 4.308    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 722550     Buffer Size: 14708      Transition Number: 1000.780k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:56:27,363][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 7.207    Value Loss: 4.311    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 724628     Buffer Size: 14692      Transition Number: 1000.282k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:59:29,735][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 6.770    Value Loss: 4.022    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 726667     Buffer Size: 14707      Transition Number: 1000.583k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:02:35,482][train][INFO][train.py>_log] ==> #215000     Total Loss: 3.573    [weighted Loss:3.573    Policy Loss: 7.191    Value Loss: 4.273    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 728788     Buffer Size: 14685      Transition Number: 1000.033k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:05:38,412][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 7.116    Value Loss: 4.592    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 730915     Buffer Size: 14718      Transition Number: 1000.363k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:08:41,506][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 7.249    Value Loss: 4.672    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 733056     Buffer Size: 14732      Transition Number: 1000.003k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:11:49,013][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 7.141    Value Loss: 4.337    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 735187     Buffer Size: 14758      Transition Number: 1000.126k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:14:51,610][train][INFO][train.py>_log] ==> #219000     Total Loss: 3.621    [weighted Loss:3.621    Policy Loss: 7.212    Value Loss: 4.631    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 737334     Buffer Size: 14788      Transition Number: 999.997 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:17:55,601][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 7.386    Value Loss: 4.422    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 739472     Buffer Size: 14826      Transition Number: 999.936 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:21:01,592][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.561    [weighted Loss:2.561    Policy Loss: 7.008    Value Loss: 4.286    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 741612     Buffer Size: 14881      Transition Number: 999.953 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:24:05,397][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.876    [weighted Loss:2.876    Policy Loss: 7.007    Value Loss: 4.471    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 743738     Buffer Size: 14931      Transition Number: 1000.055k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:27:09,284][train][INFO][train.py>_log] ==> #223000     Total Loss: 4.298    [weighted Loss:4.298    Policy Loss: 7.468    Value Loss: 4.981    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 747730     Buffer Size: 16743      Transition Number: 1000.792k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:30:17,581][train][INFO][train.py>_log] ==> #224000     Total Loss: 4.055    [weighted Loss:4.055    Policy Loss: 7.382    Value Loss: 5.511    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 751775     Buffer Size: 18681      Transition Number: 1000.266k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:33:22,254][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 7.009    Value Loss: 4.996    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 754442     Buffer Size: 19323      Transition Number: 1000.527k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:36:27,443][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 7.166    Value Loss: 5.057    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 757286     Buffer Size: 19959      Transition Number: 1000.149k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:39:34,881][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 7.097    Value Loss: 5.103    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 759442     Buffer Size: 20033      Transition Number: 1000.161k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:42:37,031][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 6.951    Value Loss: 5.298    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 761566     Buffer Size: 20060      Transition Number: 1000.111k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:45:37,043][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 7.204    Value Loss: 5.205    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 763661     Buffer Size: 20095      Transition Number: 1000.415k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:48:43,845][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.805    [weighted Loss:2.805    Policy Loss: 7.427    Value Loss: 4.854    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 765786     Buffer Size: 18640      Transition Number: 1000.126k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:51:46,709][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 7.540    Value Loss: 5.217    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 767921     Buffer Size: 16795      Transition Number: 1000.257k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:54:49,599][train][INFO][train.py>_log] ==> #232000     Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 7.465    Value Loss: 4.693    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 769979     Buffer Size: 16021      Transition Number: 1000.019k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:57:55,163][train][INFO][train.py>_log] ==> #233000     Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 7.700    Value Loss: 4.589    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 772027     Buffer Size: 15519      Transition Number: 1000.211k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:00:58,877][train][INFO][train.py>_log] ==> #234000     Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 7.671    Value Loss: 4.391    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 774100     Buffer Size: 15328      Transition Number: 1000.158k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:04:03,241][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.906    [weighted Loss:3.906    Policy Loss: 7.841    Value Loss: 4.619    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 776273     Buffer Size: 15355      Transition Number: 1000.518k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:07:09,741][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.979    [weighted Loss:3.979    Policy Loss: 7.875    Value Loss: 4.799    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 778409     Buffer Size: 15370      Transition Number: 1000.275k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:10:14,616][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 7.511    Value Loss: 4.682    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 780553     Buffer Size: 15407      Transition Number: 1000.043k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:13:18,936][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 7.839    Value Loss: 4.763    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 782714     Buffer Size: 15452      Transition Number: 1000.269k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:16:27,236][train][INFO][train.py>_log] ==> #239000     Total Loss: 4.151    [weighted Loss:4.151    Policy Loss: 8.009    Value Loss: 4.578    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 784859     Buffer Size: 15496      Transition Number: 1000.290k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:19:29,240][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.826    [weighted Loss:3.826    Policy Loss: 8.199    Value Loss: 4.923    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 787013     Buffer Size: 15547      Transition Number: 1000.135k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:22:32,098][train][INFO][train.py>_log] ==> #241000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 8.007    Value Loss: 4.643    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 789134     Buffer Size: 15598      Transition Number: 1000.433k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:25:38,942][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.826    [weighted Loss:3.826    Policy Loss: 7.955    Value Loss: 4.727    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 791327     Buffer Size: 15617      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:28:42,518][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.548    [weighted Loss:3.548    Policy Loss: 8.402    Value Loss: 4.471    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 793438     Buffer Size: 15621      Transition Number: 999.991 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:31:45,814][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 8.355    Value Loss: 5.250    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 795583     Buffer Size: 15619      Transition Number: 1000.012k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:34:53,714][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 8.272    Value Loss: 4.457    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 797806     Buffer Size: 15602      Transition Number: 1000.065k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:37:56,963][train][INFO][train.py>_log] ==> #246000     Total Loss: 3.700    [weighted Loss:3.700    Policy Loss: 8.141    Value Loss: 4.674    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 799967     Buffer Size: 15597      Transition Number: 1000.579k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:40:59,975][train][INFO][train.py>_log] ==> #247000     Total Loss: 3.266    [weighted Loss:3.266    Policy Loss: 8.577    Value Loss: 4.652    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 802087     Buffer Size: 15589      Transition Number: 1000.163k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:44:06,660][train][INFO][train.py>_log] ==> #248000     Total Loss: 4.356    [weighted Loss:4.356    Policy Loss: 8.396    Value Loss: 4.497    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 804268     Buffer Size: 15591      Transition Number: 1000.326k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:47:11,308][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 8.648    Value Loss: 4.627    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 806405     Buffer Size: 15624      Transition Number: 1000.188k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:50:15,878][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 8.437    Value Loss: 4.588    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 808601     Buffer Size: 15661      Transition Number: 1000.209k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:53:24,054][train][INFO][train.py>_log] ==> #251000     Total Loss: 4.104    [weighted Loss:4.104    Policy Loss: 8.703    Value Loss: 4.839    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 810773     Buffer Size: 15680      Transition Number: 1000.175k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:56:27,452][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 8.481    Value Loss: 4.821    Reward Loss: 1.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 812894     Buffer Size: 15689      Transition Number: 999.947 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:59:31,787][train][INFO][train.py>_log] ==> #253000     Total Loss: 3.326    [weighted Loss:3.326    Policy Loss: 7.673    Value Loss: 4.650    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 815085     Buffer Size: 15717      Transition Number: 1000.454k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:02:36,288][train][INFO][train.py>_log] ==> #254000     Total Loss: 4.066    [weighted Loss:4.066    Policy Loss: 7.916    Value Loss: 5.058    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 817240     Buffer Size: 15710      Transition Number: 999.988 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:05:37,982][train][INFO][train.py>_log] ==> #255000     Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 8.089    Value Loss: 4.893    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 819387     Buffer Size: 15710      Transition Number: 999.943 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:08:40,396][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 7.744    Value Loss: 4.970    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 821552     Buffer Size: 15683      Transition Number: 1000.312k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:11:45,519][train][INFO][train.py>_log] ==> #257000     Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 7.327    Value Loss: 4.562    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 823724     Buffer Size: 15632      Transition Number: 1000.277k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:14:48,522][train][INFO][train.py>_log] ==> #258000     Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 7.278    Value Loss: 4.639    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 825861     Buffer Size: 15613      Transition Number: 1000.173k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:17:50,983][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 7.363    Value Loss: 4.664    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 827979     Buffer Size: 15628      Transition Number: 1000.103k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:20:55,300][train][INFO][train.py>_log] ==> #260000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 7.347    Value Loss: 4.907    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 830177     Buffer Size: 15639      Transition Number: 1000.261k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:23:56,900][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.597    [weighted Loss:2.597    Policy Loss: 6.832    Value Loss: 4.706    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 832304     Buffer Size: 15644      Transition Number: 1000.084k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:27:00,553][train][INFO][train.py>_log] ==> #262000     Total Loss: 3.733    [weighted Loss:3.733    Policy Loss: 7.309    Value Loss: 4.619    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 834429     Buffer Size: 15662      Transition Number: 1000.265k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:30:05,924][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 7.094    Value Loss: 4.541    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 836642     Buffer Size: 15657      Transition Number: 1000.198k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:33:08,111][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 6.936    Value Loss: 4.833    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 838831     Buffer Size: 15668      Transition Number: 1000.267k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:36:12,720][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 6.375    Value Loss: 4.525    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 841025     Buffer Size: 15667      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:39:17,548][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 6.588    Value Loss: 4.675    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 843191     Buffer Size: 15654      Transition Number: 1000.139k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:42:20,143][train][INFO][train.py>_log] ==> #267000     Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 6.794    Value Loss: 4.597    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 845344     Buffer Size: 15659      Transition Number: 1000.083k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:45:22,833][train][INFO][train.py>_log] ==> #268000     Total Loss: 3.940    [weighted Loss:3.940    Policy Loss: 7.008    Value Loss: 4.757    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 847456     Buffer Size: 15657      Transition Number: 1000.136k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:48:27,772][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 6.606    Value Loss: 4.435    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 849564     Buffer Size: 15649      Transition Number: 1000.047k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:51:31,174][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 6.724    Value Loss: 4.394    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 851768     Buffer Size: 15672      Transition Number: 1000.442k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:54:35,027][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 6.360    Value Loss: 4.774    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 853918     Buffer Size: 15670      Transition Number: 1000.204k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:57:39,877][train][INFO][train.py>_log] ==> #272000     Total Loss: 3.529    [weighted Loss:3.529    Policy Loss: 6.470    Value Loss: 4.521    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 856096     Buffer Size: 15673      Transition Number: 1000.192k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:00:41,170][train][INFO][train.py>_log] ==> #273000     Total Loss: 3.095    [weighted Loss:3.095    Policy Loss: 6.358    Value Loss: 4.404    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 858272     Buffer Size: 15671      Transition Number: 1000.502k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:03:44,537][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 6.419    Value Loss: 4.521    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 860418     Buffer Size: 15644      Transition Number: 1000.240k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:06:51,831][train][INFO][train.py>_log] ==> #275000     Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 6.376    Value Loss: 4.847    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 862608     Buffer Size: 15618      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:09:56,141][train][INFO][train.py>_log] ==> #276000     Total Loss: 0.937    [weighted Loss:0.937    Policy Loss: 6.621    Value Loss: 4.911    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 864829     Buffer Size: 15595      Transition Number: 999.960 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:12:59,045][train][INFO][train.py>_log] ==> #277000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 6.277    Value Loss: 4.472    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 867007     Buffer Size: 15592      Transition Number: 1000.708k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:16:03,696][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.509    [weighted Loss:2.509    Policy Loss: 6.481    Value Loss: 4.699    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 869223     Buffer Size: 15586      Transition Number: 999.955 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:19:08,076][train][INFO][train.py>_log] ==> #279000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 6.920    Value Loss: 4.373    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 871471     Buffer Size: 15614      Transition Number: 999.949 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:22:10,169][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 6.430    Value Loss: 4.316    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 873713     Buffer Size: 15654      Transition Number: 1000.249k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:25:16,460][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 6.647    Value Loss: 4.590    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 875910     Buffer Size: 15683      Transition Number: 1000.243k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:28:17,793][train][INFO][train.py>_log] ==> #282000     Total Loss: 3.240    [weighted Loss:3.240    Policy Loss: 6.959    Value Loss: 4.479    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 878109     Buffer Size: 15715      Transition Number: 1000.207k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:31:18,573][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 6.810    Value Loss: 4.695    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 880295     Buffer Size: 15752      Transition Number: 1000.104k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:34:23,893][train][INFO][train.py>_log] ==> #284000     Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 7.054    Value Loss: 4.916    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 882493     Buffer Size: 15778      Transition Number: 1000.219k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:37:27,757][train][INFO][train.py>_log] ==> #285000     Total Loss: 3.358    [weighted Loss:3.358    Policy Loss: 6.603    Value Loss: 4.383    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 884734     Buffer Size: 15814      Transition Number: 1000.164k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:40:31,143][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 6.618    Value Loss: 4.957    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 886886     Buffer Size: 15850      Transition Number: 1000.797k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:43:36,469][train][INFO][train.py>_log] ==> #287000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 6.843    Value Loss: 4.487    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 889072     Buffer Size: 15872      Transition Number: 1000.413k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:46:39,998][train][INFO][train.py>_log] ==> #288000     Total Loss: 3.747    [weighted Loss:3.747    Policy Loss: 6.731    Value Loss: 4.668    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 891298     Buffer Size: 15885      Transition Number: 1000.411k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:49:43,326][train][INFO][train.py>_log] ==> #289000     Total Loss: 4.089    [weighted Loss:4.089    Policy Loss: 6.749    Value Loss: 4.931    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 893471     Buffer Size: 15911      Transition Number: 1000.404k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:52:49,108][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 7.053    Value Loss: 4.634    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 895689     Buffer Size: 15919      Transition Number: 1000.105k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:55:52,387][train][INFO][train.py>_log] ==> #291000     Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 6.567    Value Loss: 4.695    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 897928     Buffer Size: 15936      Transition Number: 999.997 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:58:58,072][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.071    [weighted Loss:2.071    Policy Loss: 6.677    Value Loss: 4.883    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 900119     Buffer Size: 15942      Transition Number: 1000.046k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:02:05,238][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 6.905    Value Loss: 4.995    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 902367     Buffer Size: 15942      Transition Number: 1000.152k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:05:08,757][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.435    [weighted Loss:1.435    Policy Loss: 6.986    Value Loss: 4.611    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 904607     Buffer Size: 15923      Transition Number: 1000.383k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:08:13,862][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.838    [weighted Loss:2.838    Policy Loss: 6.756    Value Loss: 4.567    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 906777     Buffer Size: 15908      Transition Number: 1000.164k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:11:18,392][train][INFO][train.py>_log] ==> #296000     Total Loss: 4.049    [weighted Loss:4.049    Policy Loss: 6.735    Value Loss: 4.820    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 908962     Buffer Size: 15889      Transition Number: 1000.142k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:14:20,640][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 7.125    Value Loss: 4.652    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 911151     Buffer Size: 15884      Transition Number: 1000.066k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:17:25,323][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.932    Value Loss: 4.967    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 913360     Buffer Size: 15866      Transition Number: 1000.243k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:20:30,970][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 7.218    Value Loss: 4.697    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 915555     Buffer Size: 15834      Transition Number: 1000.155k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:23:33,068][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 7.026    Value Loss: 4.745    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 917729     Buffer Size: 15812      Transition Number: 1000.240k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:26:39,458][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 6.898    Value Loss: 4.552    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 920024     Buffer Size: 15794      Transition Number: 1000.641k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:29:44,672][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 6.840    Value Loss: 4.710    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 922188     Buffer Size: 15772      Transition Number: 1000.150k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:32:47,113][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 6.619    Value Loss: 4.629    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 924440     Buffer Size: 15771      Transition Number: 1000.490k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:35:52,158][train][INFO][train.py>_log] ==> #304000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 6.765    Value Loss: 4.624    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 926688     Buffer Size: 15748      Transition Number: 1000.106k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:38:57,275][train][INFO][train.py>_log] ==> #305000     Total Loss: 3.554    [weighted Loss:3.554    Policy Loss: 6.772    Value Loss: 4.733    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 928911     Buffer Size: 15734      Transition Number: 999.972 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:42:03,928][train][INFO][train.py>_log] ==> #306000     Total Loss: 3.948    [weighted Loss:3.948    Policy Loss: 6.854    Value Loss: 4.497    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 931117     Buffer Size: 15737      Transition Number: 1000.216k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:45:06,803][train][INFO][train.py>_log] ==> #307000     Total Loss: 1.736    [weighted Loss:1.736    Policy Loss: 6.644    Value Loss: 4.577    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 933322     Buffer Size: 15757      Transition Number: 1000.312k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:48:13,525][train][INFO][train.py>_log] ==> #308000     Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 6.709    Value Loss: 4.639    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 935558     Buffer Size: 15782      Transition Number: 999.997 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:51:15,751][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 6.955    Value Loss: 4.738    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 937767     Buffer Size: 15810      Transition Number: 1000.192k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:54:20,089][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.226    [weighted Loss:3.226    Policy Loss: 6.811    Value Loss: 4.633    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 939953     Buffer Size: 15810      Transition Number: 1000.121k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:57:24,709][train][INFO][train.py>_log] ==> #311000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 7.210    Value Loss: 4.729    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 942189     Buffer Size: 15823      Transition Number: 1000.033k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:00:26,373][train][INFO][train.py>_log] ==> #312000     Total Loss: 3.158    [weighted Loss:3.158    Policy Loss: 6.881    Value Loss: 4.549    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 944364     Buffer Size: 15850      Transition Number: 1000.154k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:03:29,658][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.438    [weighted Loss:3.438    Policy Loss: 7.062    Value Loss: 4.922    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 946602     Buffer Size: 15848      Transition Number: 999.939 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:06:32,713][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 7.160    Value Loss: 4.863    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 948774     Buffer Size: 15859      Transition Number: 1000.049k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:09:35,607][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 7.099    Value Loss: 4.592    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 951117     Buffer Size: 15882      Transition Number: 1000.129k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:12:39,224][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 7.380    Value Loss: 4.792    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 953351     Buffer Size: 15906      Transition Number: 1000.108k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:15:43,752][train][INFO][train.py>_log] ==> #317000     Total Loss: 3.675    [weighted Loss:3.675    Policy Loss: 7.578    Value Loss: 4.798    Reward Loss: 1.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 955552     Buffer Size: 15925      Transition Number: 999.980 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:18:47,814][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.577    [weighted Loss:2.577    Policy Loss: 7.644    Value Loss: 4.991    Reward Loss: 1.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 957818     Buffer Size: 15945      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:21:52,580][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 7.310    Value Loss: 4.418    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 960077     Buffer Size: 15976      Transition Number: 999.963 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:24:56,375][train][INFO][train.py>_log] ==> #320000     Total Loss: 3.105    [weighted Loss:3.105    Policy Loss: 7.319    Value Loss: 4.970    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 962311     Buffer Size: 16003      Transition Number: 1000.006k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:27:59,767][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.975    [weighted Loss:2.975    Policy Loss: 7.492    Value Loss: 4.750    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 964550     Buffer Size: 16016      Transition Number: 999.934 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:31:05,548][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 7.849    Value Loss: 4.608    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 966808     Buffer Size: 16017      Transition Number: 1000.029k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:34:10,954][train][INFO][train.py>_log] ==> #323000     Total Loss: 3.469    [weighted Loss:3.469    Policy Loss: 7.189    Value Loss: 4.672    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 969038     Buffer Size: 16002      Transition Number: 1000.171k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:37:15,035][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 7.976    Value Loss: 4.748    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 971251     Buffer Size: 16012      Transition Number: 1000.231k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:40:21,038][train][INFO][train.py>_log] ==> #325000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 7.897    Value Loss: 4.713    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 973501     Buffer Size: 16032      Transition Number: 1000.029k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:43:24,428][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 7.093    Value Loss: 4.267    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 975757     Buffer Size: 16033      Transition Number: 1000.367k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:46:26,280][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.644    [weighted Loss:2.644    Policy Loss: 7.768    Value Loss: 4.522    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 977935     Buffer Size: 16041      Transition Number: 1000.085k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:49:29,600][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.540    [weighted Loss:3.540    Policy Loss: 7.467    Value Loss: 4.986    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 980146     Buffer Size: 16057      Transition Number: 999.971 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:52:33,485][train][INFO][train.py>_log] ==> #329000     Total Loss: 4.036    [weighted Loss:4.036    Policy Loss: 7.489    Value Loss: 4.913    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 982376     Buffer Size: 16061      Transition Number: 1000.020k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:55:35,950][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 7.834    Value Loss: 4.373    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 984557     Buffer Size: 16056      Transition Number: 1000.125k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:58:40,888][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.677    [weighted Loss:2.677    Policy Loss: 7.303    Value Loss: 4.708    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 986922     Buffer Size: 16226      Transition Number: 1000.261k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:01:46,319][train][INFO][train.py>_log] ==> #332000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 7.094    Value Loss: 4.765    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 989309     Buffer Size: 16368      Transition Number: 1000.134k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:04:48,121][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 7.508    Value Loss: 4.731    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 991548     Buffer Size: 16438      Transition Number: 1000.091k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:07:54,469][train][INFO][train.py>_log] ==> #334000     Total Loss: 4.485    [weighted Loss:4.485    Policy Loss: 7.069    Value Loss: 5.036    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 993819     Buffer Size: 16491      Transition Number: 1000.236k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:10:59,713][train][INFO][train.py>_log] ==> #335000     Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 7.032    Value Loss: 5.039    Reward Loss: 1.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 996095     Buffer Size: 16514      Transition Number: 1000.426k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:14:03,424][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 7.431    Value Loss: 4.600    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 998323     Buffer Size: 16535      Transition Number: 1000.126k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:17:07,547][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.867    [weighted Loss:2.867    Policy Loss: 7.250    Value Loss: 4.652    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000611    Buffer Size: 16554      Transition Number: 1000.067k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:20:13,068][train][INFO][train.py>_log] ==> #338000     Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 7.347    Value Loss: 4.697    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002869    Buffer Size: 16470      Transition Number: 1000.175k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:23:15,946][train][INFO][train.py>_log] ==> #339000     Total Loss: 3.331    [weighted Loss:3.331    Policy Loss: 7.736    Value Loss: 4.703    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1005031    Buffer Size: 16286      Transition Number: 1000.244k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:26:22,257][train][INFO][train.py>_log] ==> #340000     Total Loss: 4.317    [weighted Loss:4.317    Policy Loss: 7.617    Value Loss: 4.601    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1007284    Buffer Size: 16184      Transition Number: 1000.293k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:29:27,088][train][INFO][train.py>_log] ==> #341000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 7.885    Value Loss: 4.763    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1009457    Buffer Size: 16125      Transition Number: 1000.292k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:32:32,201][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 8.225    Value Loss: 4.802    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1011759    Buffer Size: 16098      Transition Number: 1000.050k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:35:36,162][train][INFO][train.py>_log] ==> #343000     Total Loss: 3.625    [weighted Loss:3.625    Policy Loss: 8.162    Value Loss: 4.662    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013973    Buffer Size: 16114      Transition Number: 1000.357k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:38:40,163][train][INFO][train.py>_log] ==> #344000     Total Loss: 3.048    [weighted Loss:3.048    Policy Loss: 7.893    Value Loss: 4.519    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1016281    Buffer Size: 16121      Transition Number: 1000.198k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:41:43,503][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.413    [weighted Loss:3.413    Policy Loss: 8.302    Value Loss: 4.699    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1018453    Buffer Size: 16134      Transition Number: 1000.411k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:44:48,863][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 8.037    Value Loss: 4.587    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1020717    Buffer Size: 16185      Transition Number: 1000.105k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:47:53,523][train][INFO][train.py>_log] ==> #347000     Total Loss: 0.977    [weighted Loss:0.977    Policy Loss: 8.434    Value Loss: 4.721    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1023000    Buffer Size: 16252      Transition Number: 1000.045k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:50:57,107][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 8.340    Value Loss: 4.856    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025213    Buffer Size: 16310      Transition Number: 1000.015k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:54:02,745][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 8.386    Value Loss: 4.666    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1027502    Buffer Size: 16371      Transition Number: 999.962 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:57:07,768][train][INFO][train.py>_log] ==> #350000     Total Loss: 4.321    [weighted Loss:4.321    Policy Loss: 8.859    Value Loss: 5.012    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 1029773    Buffer Size: 16425      Transition Number: 1000.166k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:00:12,434][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.991    [weighted Loss:3.991    Policy Loss: 8.049    Value Loss: 4.947    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032062    Buffer Size: 16443      Transition Number: 1000.187k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:03:19,755][train][INFO][train.py>_log] ==> #352000     Total Loss: 3.699    [weighted Loss:3.699    Policy Loss: 8.482    Value Loss: 4.709    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1034287    Buffer Size: 16465      Transition Number: 1000.010k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:06:22,948][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 8.184    Value Loss: 4.925    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1036561    Buffer Size: 16484      Transition Number: 1000.089k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:09:26,939][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 8.437    Value Loss: 4.966    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1038781    Buffer Size: 16512      Transition Number: 1000.017k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:12:31,522][train][INFO][train.py>_log] ==> #355000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 8.245    Value Loss: 4.687    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1040982    Buffer Size: 16523      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:15:35,570][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 8.445    Value Loss: 4.945    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043270    Buffer Size: 16552      Transition Number: 1000.174k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:18:38,622][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 8.229    Value Loss: 5.380    Reward Loss: 2.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 1045849    Buffer Size: 16921      Transition Number: 1000.031k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:21:44,665][train][INFO][train.py>_log] ==> #358000     Total Loss: 4.164    [weighted Loss:4.164    Policy Loss: 7.956    Value Loss: 5.171    Reward Loss: 1.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048546    Buffer Size: 17386      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:24:48,573][train][INFO][train.py>_log] ==> #359000     Total Loss: 3.502    [weighted Loss:3.502    Policy Loss: 8.102    Value Loss: 5.065    Reward Loss: 1.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 1051088    Buffer Size: 17651      Transition Number: 1000.171k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:27:50,803][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 7.997    Value Loss: 5.134    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 1053564    Buffer Size: 17896      Transition Number: 1000.188k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:30:56,716][train][INFO][train.py>_log] ==> #361000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 8.445    Value Loss: 4.953    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 1055796    Buffer Size: 17968      Transition Number: 1000.074k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:34:01,005][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 8.031    Value Loss: 5.467    Reward Loss: 1.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 1058101    Buffer Size: 18036      Transition Number: 1000.002k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:37:02,300][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.785    [weighted Loss:2.785    Policy Loss: 8.071    Value Loss: 5.210    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1060346    Buffer Size: 18113      Transition Number: 1000.023k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:40:10,473][train][INFO][train.py>_log] ==> #364000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 8.147    Value Loss: 5.686    Reward Loss: 1.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 1062694    Buffer Size: 18033      Transition Number: 1000.323k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:43:14,751][train][INFO][train.py>_log] ==> #365000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 7.965    Value Loss: 5.183    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1065003    Buffer Size: 17699      Transition Number: 1000.080k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:46:21,370][train][INFO][train.py>_log] ==> #366000     Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 7.940    Value Loss: 5.211    Reward Loss: 1.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 1067366    Buffer Size: 17439      Transition Number: 1000.042k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:49:26,567][train][INFO][train.py>_log] ==> #367000     Total Loss: 4.079    [weighted Loss:4.079    Policy Loss: 8.105    Value Loss: 4.995    Reward Loss: 1.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069577    Buffer Size: 17277      Transition Number: 1000.087k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:52:29,362][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.104    [weighted Loss:3.104    Policy Loss: 8.396    Value Loss: 5.036    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 1071776    Buffer Size: 17185      Transition Number: 1000.138k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:55:31,661][train][INFO][train.py>_log] ==> #369000     Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 8.242    Value Loss: 4.957    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1073999    Buffer Size: 17164      Transition Number: 1000.118k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:58:40,308][train][INFO][train.py>_log] ==> #370000     Total Loss: 3.319    [weighted Loss:3.319    Policy Loss: 8.199    Value Loss: 4.826    Reward Loss: 1.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076286    Buffer Size: 17121      Transition Number: 999.982 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:01:46,692][train][INFO][train.py>_log] ==> #371000     Total Loss: 4.124    [weighted Loss:4.124    Policy Loss: 8.783    Value Loss: 4.810    Reward Loss: 1.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 1078541    Buffer Size: 17073      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:04:50,125][train][INFO][train.py>_log] ==> #372000     Total Loss: 3.780    [weighted Loss:3.780    Policy Loss: 8.353    Value Loss: 4.920    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1080823    Buffer Size: 17014      Transition Number: 1000.404k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:07:55,335][train][INFO][train.py>_log] ==> #373000     Total Loss: 4.288    [weighted Loss:4.288    Policy Loss: 9.507    Value Loss: 4.570    Reward Loss: 1.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 1083069    Buffer Size: 16982      Transition Number: 1000.305k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:11:00,123][train][INFO][train.py>_log] ==> #374000     Total Loss: 4.170    [weighted Loss:4.170    Policy Loss: 8.936    Value Loss: 4.914    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 1085300    Buffer Size: 16956      Transition Number: 1000.053k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:14:05,200][train][INFO][train.py>_log] ==> #375000     Total Loss: 3.499    [weighted Loss:3.499    Policy Loss: 9.027    Value Loss: 5.013    Reward Loss: 1.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 1087580    Buffer Size: 16963      Transition Number: 1000.391k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:17:09,056][train][INFO][train.py>_log] ==> #376000     Total Loss: 3.877    [weighted Loss:3.877    Policy Loss: 8.993    Value Loss: 4.680    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089851    Buffer Size: 16985      Transition Number: 1000.588k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:20:15,223][train][INFO][train.py>_log] ==> #377000     Total Loss: 4.162    [weighted Loss:4.162    Policy Loss: 9.186    Value Loss: 5.519    Reward Loss: 1.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092146    Buffer Size: 16986      Transition Number: 1000.185k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:23:19,198][train][INFO][train.py>_log] ==> #378000     Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 9.093    Value Loss: 5.006    Reward Loss: 1.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 1094392    Buffer Size: 16984      Transition Number: 1000.173k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:26:23,582][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 9.547    Value Loss: 5.239    Reward Loss: 1.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 1096720    Buffer Size: 16976      Transition Number: 1000.178k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:29:29,171][train][INFO][train.py>_log] ==> #380000     Total Loss: 3.162    [weighted Loss:3.162    Policy Loss: 9.230    Value Loss: 4.989    Reward Loss: 2.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098957    Buffer Size: 16947      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:32:32,234][train][INFO][train.py>_log] ==> #381000     Total Loss: 3.162    [weighted Loss:3.162    Policy Loss: 9.335    Value Loss: 4.772    Reward Loss: 1.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 1101197    Buffer Size: 16945      Transition Number: 1000.154k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:35:38,572][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 9.141    Value Loss: 4.854    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103495    Buffer Size: 16925      Transition Number: 1000.088k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:38:43,501][train][INFO][train.py>_log] ==> #383000     Total Loss: 3.185    [weighted Loss:3.185    Policy Loss: 9.166    Value Loss: 5.066    Reward Loss: 1.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 1105735    Buffer Size: 16916      Transition Number: 1000.250k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:41:47,091][train][INFO][train.py>_log] ==> #384000     Total Loss: 4.587    [weighted Loss:4.587    Policy Loss: 9.357    Value Loss: 4.853    Reward Loss: 1.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 1107988    Buffer Size: 16904      Transition Number: 1000.057k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:44:52,356][train][INFO][train.py>_log] ==> #385000     Total Loss: 4.143    [weighted Loss:4.143    Policy Loss: 9.206    Value Loss: 4.978    Reward Loss: 1.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 1110297    Buffer Size: 16900      Transition Number: 1000.152k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:47:57,900][train][INFO][train.py>_log] ==> #386000     Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 9.320    Value Loss: 4.831    Reward Loss: 1.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 1112524    Buffer Size: 16887      Transition Number: 1000.002k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:51:00,572][train][INFO][train.py>_log] ==> #387000     Total Loss: 4.287    [weighted Loss:4.287    Policy Loss: 9.248    Value Loss: 4.816    Reward Loss: 1.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 1114782    Buffer Size: 16906      Transition Number: 1000.107k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:54:04,589][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 9.370    Value Loss: 4.797    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117066    Buffer Size: 16908      Transition Number: 1000.030k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:57:08,612][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 9.520    Value Loss: 4.502    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1119301    Buffer Size: 16925      Transition Number: 1000.308k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:00:12,668][train][INFO][train.py>_log] ==> #390000     Total Loss: 4.449    [weighted Loss:4.449    Policy Loss: 9.488    Value Loss: 5.084    Reward Loss: 1.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 1121545    Buffer Size: 16959      Transition Number: 1000.060k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:03:18,645][train][INFO][train.py>_log] ==> #391000     Total Loss: 4.442    [weighted Loss:4.442    Policy Loss: 9.333    Value Loss: 5.133    Reward Loss: 1.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 1123913    Buffer Size: 17042      Transition Number: 1000.261k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:06:24,107][train][INFO][train.py>_log] ==> #392000     Total Loss: 3.732    [weighted Loss:3.732    Policy Loss: 8.820    Value Loss: 5.009    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126258    Buffer Size: 17102      Transition Number: 1000.178k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:09:31,871][train][INFO][train.py>_log] ==> #393000     Total Loss: 4.402    [weighted Loss:4.402    Policy Loss: 9.865    Value Loss: 5.258    Reward Loss: 2.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128587    Buffer Size: 17182      Transition Number: 1000.009k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:12:38,448][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.967    [weighted Loss:3.967    Policy Loss: 9.511    Value Loss: 5.249    Reward Loss: 1.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 1130944    Buffer Size: 17220      Transition Number: 1000.001k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:15:43,947][train][INFO][train.py>_log] ==> #395000     Total Loss: 4.179    [weighted Loss:4.179    Policy Loss: 9.561    Value Loss: 4.976    Reward Loss: 2.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133266    Buffer Size: 17267      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:18:47,219][train][INFO][train.py>_log] ==> #396000     Total Loss: 4.083    [weighted Loss:4.083    Policy Loss: 9.179    Value Loss: 5.125    Reward Loss: 1.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135582    Buffer Size: 17296      Transition Number: 999.961 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:21:52,713][train][INFO][train.py>_log] ==> #397000     Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 9.330    Value Loss: 5.027    Reward Loss: 1.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 1137939    Buffer Size: 17320      Transition Number: 1000.022k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:24:56,552][train][INFO][train.py>_log] ==> #398000     Total Loss: 3.588    [weighted Loss:3.588    Policy Loss: 9.388    Value Loss: 4.941    Reward Loss: 1.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 1140228    Buffer Size: 17305      Transition Number: 999.959 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:28:05,356][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 9.646    Value Loss: 4.860    Reward Loss: 1.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 1142552    Buffer Size: 17288      Transition Number: 1000.352k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:31:29,008][train][INFO][train.py>_log] ==> #400000     Total Loss: 4.257    [weighted Loss:4.257    Policy Loss: 9.366    Value Loss: 4.879    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144897    Buffer Size: 17265      Transition Number: 1000.025k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:34:38,900][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 8.845    Value Loss: 5.162    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147449    Buffer Size: 17249      Transition Number: 1000.395k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:37:41,419][train][INFO][train.py>_log] ==> #402000     Total Loss: 3.986    [weighted Loss:3.986    Policy Loss: 9.025    Value Loss: 4.664    Reward Loss: 2.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 1149647    Buffer Size: 17243      Transition Number: 1000.386k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:40:45,065][train][INFO][train.py>_log] ==> #403000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 9.152    Value Loss: 5.153    Reward Loss: 2.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 1151885    Buffer Size: 17180      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:43:47,531][train][INFO][train.py>_log] ==> #404000     Total Loss: 4.287    [weighted Loss:4.287    Policy Loss: 8.755    Value Loss: 4.852    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 1154078    Buffer Size: 17137      Transition Number: 1000.358k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:46:49,348][train][INFO][train.py>_log] ==> #405000     Total Loss: 3.235    [weighted Loss:3.235    Policy Loss: 8.447    Value Loss: 4.653    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1156256    Buffer Size: 17068      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:49:56,705][train][INFO][train.py>_log] ==> #406000     Total Loss: 3.310    [weighted Loss:3.310    Policy Loss: 8.772    Value Loss: 4.927    Reward Loss: 2.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 1158542    Buffer Size: 16990      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:52:56,682][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 8.362    Value Loss: 5.175    Reward Loss: 1.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 1160656    Buffer Size: 16911      Transition Number: 1000.160k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:56:00,269][train][INFO][train.py>_log] ==> #408000     Total Loss: 3.952    [weighted Loss:3.952    Policy Loss: 8.181    Value Loss: 4.457    Reward Loss: 1.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 1162853    Buffer Size: 16835      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:59:03,107][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 7.824    Value Loss: 4.484    Reward Loss: 1.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 1165023    Buffer Size: 16742      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:02:08,950][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 8.309    Value Loss: 4.530    Reward Loss: 2.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 1167180    Buffer Size: 16696      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:05:12,843][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 7.822    Value Loss: 4.612    Reward Loss: 1.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 1169329    Buffer Size: 16673      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:08:15,763][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.196    [weighted Loss:3.196    Policy Loss: 8.066    Value Loss: 4.536    Reward Loss: 1.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 1171533    Buffer Size: 16660      Transition Number: 1000.280k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:11:20,208][train][INFO][train.py>_log] ==> #413000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 8.152    Value Loss: 4.709    Reward Loss: 1.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 1173687    Buffer Size: 16645      Transition Number: 1000.462k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:14:23,007][train][INFO][train.py>_log] ==> #414000     Total Loss: 1.200    [weighted Loss:1.200    Policy Loss: 8.190    Value Loss: 4.481    Reward Loss: 1.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 1175930    Buffer Size: 16643      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:17:26,736][train][INFO][train.py>_log] ==> #415000     Total Loss: 4.095    [weighted Loss:4.095    Policy Loss: 8.271    Value Loss: 4.351    Reward Loss: 2.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 1178136    Buffer Size: 16653      Transition Number: 1000.395k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:20:33,569][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 8.692    Value Loss: 4.286    Reward Loss: 1.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 1180309    Buffer Size: 16651      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:23:36,171][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 8.754    Value Loss: 4.270    Reward Loss: 1.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 1182504    Buffer Size: 16648      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:26:39,502][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 8.757    Value Loss: 4.478    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 1184744    Buffer Size: 16661      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:29:42,714][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 8.778    Value Loss: 4.795    Reward Loss: 2.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 1186933    Buffer Size: 16662      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:32:48,948][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 8.547    Value Loss: 4.457    Reward Loss: 1.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 1189189    Buffer Size: 16678      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:35:54,846][train][INFO][train.py>_log] ==> #421000     Total Loss: 3.441    [weighted Loss:3.441    Policy Loss: 8.700    Value Loss: 4.578    Reward Loss: 1.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 1191435    Buffer Size: 16655      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:39:01,930][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 8.558    Value Loss: 4.925    Reward Loss: 1.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 1193695    Buffer Size: 16639      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:42:07,550][train][INFO][train.py>_log] ==> #423000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 8.709    Value Loss: 4.351    Reward Loss: 1.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 1195916    Buffer Size: 16608      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:45:11,620][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 9.169    Value Loss: 4.761    Reward Loss: 2.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 1198174    Buffer Size: 16603      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:48:15,441][train][INFO][train.py>_log] ==> #425000     Total Loss: 3.570    [weighted Loss:3.570    Policy Loss: 8.589    Value Loss: 4.622    Reward Loss: 1.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 1200393    Buffer Size: 16573      Transition Number: 1000.279k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:51:27,297][train][INFO][train.py>_log] ==> #426000     Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 8.831    Value Loss: 4.424    Reward Loss: 1.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 1202758    Buffer Size: 16513      Transition Number: 1000.073k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:54:34,146][train][INFO][train.py>_log] ==> #427000     Total Loss: 3.334    [weighted Loss:3.334    Policy Loss: 8.986    Value Loss: 4.270    Reward Loss: 1.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 1205027    Buffer Size: 16487      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:57:46,022][train][INFO][train.py>_log] ==> #428000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 8.892    Value Loss: 4.371    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 1207357    Buffer Size: 16466      Transition Number: 1000.290k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:00:48,593][train][INFO][train.py>_log] ==> #429000     Total Loss: 3.940    [weighted Loss:3.940    Policy Loss: 8.833    Value Loss: 4.577    Reward Loss: 1.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 1209594    Buffer Size: 16443      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:03:52,715][train][INFO][train.py>_log] ==> #430000     Total Loss: 3.930    [weighted Loss:3.930    Policy Loss: 8.985    Value Loss: 4.700    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1211751    Buffer Size: 16427      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:06:56,686][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 9.156    Value Loss: 4.464    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1214086    Buffer Size: 16402      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:10:00,290][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 8.943    Value Loss: 4.589    Reward Loss: 1.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216337    Buffer Size: 16403      Transition Number: 1000.418k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:13:07,550][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 9.217    Value Loss: 4.610    Reward Loss: 1.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218643    Buffer Size: 16387      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:16:12,326][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.846    [weighted Loss:3.846    Policy Loss: 9.336    Value Loss: 4.261    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1220910    Buffer Size: 16362      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:19:21,357][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.431    [weighted Loss:2.431    Policy Loss: 8.902    Value Loss: 4.482    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223242    Buffer Size: 16339      Transition Number: 1000.145k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:22:27,628][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 8.716    Value Loss: 4.415    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225517    Buffer Size: 16315      Transition Number: 1000.217k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:25:32,960][train][INFO][train.py>_log] ==> #437000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 8.766    Value Loss: 4.426    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 1227758    Buffer Size: 16283      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:28:38,453][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 8.502    Value Loss: 4.640    Reward Loss: 1.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 1229966    Buffer Size: 16258      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:31:43,246][train][INFO][train.py>_log] ==> #439000     Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 8.615    Value Loss: 4.579    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1232231    Buffer Size: 16207      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:34:49,529][train][INFO][train.py>_log] ==> #440000     Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 8.227    Value Loss: 4.586    Reward Loss: 1.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 1234487    Buffer Size: 16172      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:37:55,947][train][INFO][train.py>_log] ==> #441000     Total Loss: 2.702    [weighted Loss:2.702    Policy Loss: 8.623    Value Loss: 4.811    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236745    Buffer Size: 16154      Transition Number: 1000.615k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:41:06,944][train][INFO][train.py>_log] ==> #442000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 8.414    Value Loss: 4.795    Reward Loss: 1.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 1239054    Buffer Size: 16124      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:44:16,966][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.168    [weighted Loss:3.168    Policy Loss: 8.910    Value Loss: 4.415    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241362    Buffer Size: 16129      Transition Number: 1000.641k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:47:27,349][train][INFO][train.py>_log] ==> #444000     Total Loss: 4.448    [weighted Loss:4.448    Policy Loss: 8.881    Value Loss: 4.614    Reward Loss: 1.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 1243708    Buffer Size: 16110      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:50:34,476][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.420    [weighted Loss:3.420    Policy Loss: 8.519    Value Loss: 4.357    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1245967    Buffer Size: 16097      Transition Number: 1000.368k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:53:42,964][train][INFO][train.py>_log] ==> #446000     Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 8.834    Value Loss: 4.685    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1248275    Buffer Size: 16112      Transition Number: 1000.594k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:56:50,617][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.486    [weighted Loss:3.486    Policy Loss: 9.226    Value Loss: 4.422    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1250595    Buffer Size: 16102      Transition Number: 1000.217k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:59:59,857][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 9.088    Value Loss: 4.338    Reward Loss: 1.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252901    Buffer Size: 16100      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:03:04,628][train][INFO][train.py>_log] ==> #449000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 8.845    Value Loss: 4.538    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1255186    Buffer Size: 16100      Transition Number: 1000.196k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:06:11,725][train][INFO][train.py>_log] ==> #450000     Total Loss: 3.279    [weighted Loss:3.279    Policy Loss: 9.277    Value Loss: 4.442    Reward Loss: 2.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 1257452    Buffer Size: 16114      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:09:16,394][train][INFO][train.py>_log] ==> #451000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 9.504    Value Loss: 4.276    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1259781    Buffer Size: 16120      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:12:24,790][train][INFO][train.py>_log] ==> #452000     Total Loss: 4.139    [weighted Loss:4.139    Policy Loss: 9.588    Value Loss: 4.583    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1262063    Buffer Size: 16136      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:15:28,842][train][INFO][train.py>_log] ==> #453000     Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 9.868    Value Loss: 4.683    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1264348    Buffer Size: 16127      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:18:36,432][train][INFO][train.py>_log] ==> #454000     Total Loss: 4.438    [weighted Loss:4.438    Policy Loss: 9.725    Value Loss: 4.668    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266609    Buffer Size: 16129      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:21:42,049][train][INFO][train.py>_log] ==> #455000     Total Loss: 3.859    [weighted Loss:3.859    Policy Loss: 9.973    Value Loss: 4.602    Reward Loss: 1.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 1268938    Buffer Size: 16121      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:24:47,594][train][INFO][train.py>_log] ==> #456000     Total Loss: 4.076    [weighted Loss:4.076    Policy Loss: 10.064   Value Loss: 4.286    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1271196    Buffer Size: 16101      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:27:55,633][train][INFO][train.py>_log] ==> #457000     Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 9.782    Value Loss: 4.339    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 1273451    Buffer Size: 16071      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:31:04,064][train][INFO][train.py>_log] ==> #458000     Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 10.030   Value Loss: 4.117    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1275791    Buffer Size: 16040      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:34:14,385][train][INFO][train.py>_log] ==> #459000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 9.949    Value Loss: 4.539    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 1278095    Buffer Size: 16019      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:37:25,942][train][INFO][train.py>_log] ==> #460000     Total Loss: 3.965    [weighted Loss:3.965    Policy Loss: 10.309   Value Loss: 4.569    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 1280452    Buffer Size: 16015      Transition Number: 1000.310k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:40:36,051][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.628    [weighted Loss:3.628    Policy Loss: 9.582    Value Loss: 4.664    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 1282775    Buffer Size: 16010      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:43:46,473][train][INFO][train.py>_log] ==> #462000     Total Loss: 3.148    [weighted Loss:3.148    Policy Loss: 9.699    Value Loss: 4.345    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1285174    Buffer Size: 16003      Transition Number: 1000.427k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:46:55,747][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 9.889    Value Loss: 4.894    Reward Loss: 1.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 1287547    Buffer Size: 16016      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:50:06,205][train][INFO][train.py>_log] ==> #464000     Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 9.615    Value Loss: 4.260    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1289861    Buffer Size: 16058      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:53:13,685][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.593    [weighted Loss:3.593    Policy Loss: 9.957    Value Loss: 4.203    Reward Loss: 1.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 1292206    Buffer Size: 16099      Transition Number: 1000.382k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:56:21,942][train][INFO][train.py>_log] ==> #466000     Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 10.134   Value Loss: 4.644    Reward Loss: 1.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 1294561    Buffer Size: 16114      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:59:25,299][train][INFO][train.py>_log] ==> #467000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 9.900    Value Loss: 4.359    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1296876    Buffer Size: 16132      Transition Number: 1000.076k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:02:29,448][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 10.044   Value Loss: 4.573    Reward Loss: 1.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299150    Buffer Size: 16161      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:05:37,190][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 9.973    Value Loss: 4.253    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 1301408    Buffer Size: 16202      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:08:43,647][train][INFO][train.py>_log] ==> #470000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 10.248   Value Loss: 4.552    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 1303825    Buffer Size: 16225      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:11:52,876][train][INFO][train.py>_log] ==> #471000     Total Loss: 4.099    [weighted Loss:4.099    Policy Loss: 10.045   Value Loss: 4.846    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1306165    Buffer Size: 16233      Transition Number: 1000.209k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:15:06,112][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 9.977    Value Loss: 4.122    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1308502    Buffer Size: 16226      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:18:13,447][train][INFO][train.py>_log] ==> #473000     Total Loss: 4.597    [weighted Loss:4.597    Policy Loss: 9.890    Value Loss: 4.623    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 1310853    Buffer Size: 16232      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:21:30,030][train][INFO][train.py>_log] ==> #474000     Total Loss: 4.622    [weighted Loss:4.622    Policy Loss: 10.075   Value Loss: 4.250    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 1313288    Buffer Size: 16245      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:24:46,312][train][INFO][train.py>_log] ==> #475000     Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 10.157   Value Loss: 4.295    Reward Loss: 1.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 1315723    Buffer Size: 16246      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:27:55,487][train][INFO][train.py>_log] ==> #476000     Total Loss: 4.139    [weighted Loss:4.139    Policy Loss: 9.898    Value Loss: 4.364    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1318093    Buffer Size: 16243      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:31:05,725][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 10.204   Value Loss: 4.224    Reward Loss: 1.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 1320490    Buffer Size: 16214      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:34:14,662][train][INFO][train.py>_log] ==> #478000     Total Loss: 3.146    [weighted Loss:3.146    Policy Loss: 9.801    Value Loss: 4.316    Reward Loss: 1.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 1322815    Buffer Size: 16199      Transition Number: 1000.364k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:37:19,161][train][INFO][train.py>_log] ==> #479000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 9.828    Value Loss: 4.344    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1325215    Buffer Size: 16185      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:40:28,271][train][INFO][train.py>_log] ==> #480000     Total Loss: 4.091    [weighted Loss:4.091    Policy Loss: 9.969    Value Loss: 4.616    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 1327595    Buffer Size: 16168      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:43:36,546][train][INFO][train.py>_log] ==> #481000     Total Loss: 3.344    [weighted Loss:3.344    Policy Loss: 10.030   Value Loss: 4.515    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1329923    Buffer Size: 16150      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:46:41,711][train][INFO][train.py>_log] ==> #482000     Total Loss: 4.095    [weighted Loss:4.095    Policy Loss: 10.091   Value Loss: 4.104    Reward Loss: 1.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332302    Buffer Size: 16122      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:49:57,036][train][INFO][train.py>_log] ==> #483000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 9.373    Value Loss: 4.376    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1334744    Buffer Size: 16090      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:53:05,586][train][INFO][train.py>_log] ==> #484000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 9.510    Value Loss: 4.519    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1337077    Buffer Size: 16083      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:56:15,923][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 10.279   Value Loss: 4.724    Reward Loss: 1.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 1339506    Buffer Size: 16067      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:59:24,233][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 10.007   Value Loss: 4.840    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1341904    Buffer Size: 16069      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:02:36,065][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 10.251   Value Loss: 4.272    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1344303    Buffer Size: 16064      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:05:50,488][train][INFO][train.py>_log] ==> #488000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 10.098   Value Loss: 4.341    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1346772    Buffer Size: 16061      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:08:57,581][train][INFO][train.py>_log] ==> #489000     Total Loss: 3.951    [weighted Loss:3.951    Policy Loss: 10.364   Value Loss: 4.480    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1349142    Buffer Size: 16062      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:12:09,879][train][INFO][train.py>_log] ==> #490000     Total Loss: 3.968    [weighted Loss:3.968    Policy Loss: 10.351   Value Loss: 4.461    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1351481    Buffer Size: 16060      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:15:21,427][train][INFO][train.py>_log] ==> #491000     Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 10.303   Value Loss: 4.389    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1353971    Buffer Size: 16071      Transition Number: 1000.343k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:18:30,017][train][INFO][train.py>_log] ==> #492000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 10.712   Value Loss: 4.357    Reward Loss: 1.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 1356421    Buffer Size: 16074      Transition Number: 1000.206k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:21:38,974][train][INFO][train.py>_log] ==> #493000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 10.902   Value Loss: 4.278    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1358793    Buffer Size: 16056      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:24:48,804][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 10.449   Value Loss: 4.080    Reward Loss: 1.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 1361185    Buffer Size: 16052      Transition Number: 1000.234k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:27:59,975][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 10.602   Value Loss: 4.300    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1363586    Buffer Size: 16042      Transition Number: 1000.716k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:31:08,846][train][INFO][train.py>_log] ==> #496000     Total Loss: 3.415    [weighted Loss:3.415    Policy Loss: 10.263   Value Loss: 4.252    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1365992    Buffer Size: 16013      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:34:18,845][train][INFO][train.py>_log] ==> #497000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 10.580   Value Loss: 4.419    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1368395    Buffer Size: 15993      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:37:30,563][train][INFO][train.py>_log] ==> #498000     Total Loss: 4.461    [weighted Loss:4.461    Policy Loss: 10.442   Value Loss: 4.599    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370772    Buffer Size: 15988      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:40:40,398][train][INFO][train.py>_log] ==> #499000     Total Loss: 3.371    [weighted Loss:3.371    Policy Loss: 10.585   Value Loss: 4.457    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373145    Buffer Size: 15975      Transition Number: 1000.081k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:43:48,492][train][INFO][train.py>_log] ==> #500000     Total Loss: 3.042    [weighted Loss:3.042    Policy Loss: 10.202   Value Loss: 4.641    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375565    Buffer Size: 15976      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:46:54,763][train][INFO][train.py>_log] ==> #501000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 10.157   Value Loss: 4.301    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1377893    Buffer Size: 15949      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:50:03,892][train][INFO][train.py>_log] ==> #502000     Total Loss: 3.289    [weighted Loss:3.289    Policy Loss: 10.284   Value Loss: 4.499    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1380298    Buffer Size: 15942      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:53:15,951][train][INFO][train.py>_log] ==> #503000     Total Loss: 2.539    [weighted Loss:2.539    Policy Loss: 9.860    Value Loss: 4.274    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1382771    Buffer Size: 15936      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:56:23,798][train][INFO][train.py>_log] ==> #504000     Total Loss: 3.921    [weighted Loss:3.921    Policy Loss: 9.980    Value Loss: 4.648    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1385197    Buffer Size: 15924      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:59:33,009][train][INFO][train.py>_log] ==> #505000     Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 10.054   Value Loss: 4.537    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1387565    Buffer Size: 15923      Transition Number: 1000.257k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:02:38,225][train][INFO][train.py>_log] ==> #506000     Total Loss: 3.238    [weighted Loss:3.238    Policy Loss: 10.443   Value Loss: 4.279    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1389864    Buffer Size: 15913      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:05:41,905][train][INFO][train.py>_log] ==> #507000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 10.463   Value Loss: 4.193    Reward Loss: 1.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 1392171    Buffer Size: 15889      Transition Number: 1000.331k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:08:50,954][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 10.353   Value Loss: 4.358    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1394593    Buffer Size: 15886      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:11:58,624][train][INFO][train.py>_log] ==> #509000     Total Loss: 3.082    [weighted Loss:3.082    Policy Loss: 10.512   Value Loss: 4.207    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1396985    Buffer Size: 15893      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:15:08,502][train][INFO][train.py>_log] ==> #510000     Total Loss: 3.483    [weighted Loss:3.483    Policy Loss: 10.438   Value Loss: 4.266    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1399384    Buffer Size: 15900      Transition Number: 1000.304k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:18:19,454][train][INFO][train.py>_log] ==> #511000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 10.629   Value Loss: 4.311    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1401871    Buffer Size: 15904      Transition Number: 1000.375k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:21:28,908][train][INFO][train.py>_log] ==> #512000     Total Loss: 3.395    [weighted Loss:3.395    Policy Loss: 10.828   Value Loss: 4.178    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 1404246    Buffer Size: 15921      Transition Number: 1000.330k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:24:38,341][train][INFO][train.py>_log] ==> #513000     Total Loss: 3.577    [weighted Loss:3.577    Policy Loss: 10.946   Value Loss: 4.209    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406639    Buffer Size: 15921      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:27:44,646][train][INFO][train.py>_log] ==> #514000     Total Loss: 4.011    [weighted Loss:4.011    Policy Loss: 10.788   Value Loss: 4.450    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1409027    Buffer Size: 15949      Transition Number: 1000.238k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:30:53,124][train][INFO][train.py>_log] ==> #515000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 10.608   Value Loss: 4.298    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411422    Buffer Size: 15951      Transition Number: 1000.577k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:33:58,755][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 10.214   Value Loss: 4.340    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1413836    Buffer Size: 15927      Transition Number: 1000.328k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:37:06,088][train][INFO][train.py>_log] ==> #517000     Total Loss: 4.209    [weighted Loss:4.209    Policy Loss: 10.744   Value Loss: 4.495    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1416144    Buffer Size: 15908      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:40:12,613][train][INFO][train.py>_log] ==> #518000     Total Loss: 4.696    [weighted Loss:4.696    Policy Loss: 10.310   Value Loss: 4.322    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1418472    Buffer Size: 15877      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:43:21,896][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 10.336   Value Loss: 4.477    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1420883    Buffer Size: 15840      Transition Number: 1000.289k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:46:32,810][train][INFO][train.py>_log] ==> #520000     Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 10.652   Value Loss: 4.372    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1423269    Buffer Size: 15819      Transition Number: 1000.384k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:49:45,683][train][INFO][train.py>_log] ==> #521000     Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 10.782   Value Loss: 4.496    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1425692    Buffer Size: 15764      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:52:52,634][train][INFO][train.py>_log] ==> #522000     Total Loss: 3.966    [weighted Loss:3.966    Policy Loss: 10.249   Value Loss: 4.452    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1428088    Buffer Size: 15745      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:55:58,550][train][INFO][train.py>_log] ==> #523000     Total Loss: 4.460    [weighted Loss:4.460    Policy Loss: 10.438   Value Loss: 4.449    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1430417    Buffer Size: 15750      Transition Number: 1000.468k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:59:03,482][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 10.049   Value Loss: 4.582    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1432763    Buffer Size: 15771      Transition Number: 1000.571k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:02:12,712][train][INFO][train.py>_log] ==> #525000     Total Loss: 4.185    [weighted Loss:4.185    Policy Loss: 9.777    Value Loss: 4.773    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435221    Buffer Size: 15803      Transition Number: 1000.358k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:05:24,351][train][INFO][train.py>_log] ==> #526000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 9.831    Value Loss: 4.543    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1437664    Buffer Size: 15835      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:08:35,744][train][INFO][train.py>_log] ==> #527000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 9.818    Value Loss: 4.488    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440061    Buffer Size: 15869      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:11:48,645][train][INFO][train.py>_log] ==> #528000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 9.652    Value Loss: 4.666    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 1442504    Buffer Size: 15897      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:14:56,541][train][INFO][train.py>_log] ==> #529000     Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 9.886    Value Loss: 4.390    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1444896    Buffer Size: 15921      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:18:04,170][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 9.373    Value Loss: 4.605    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1447280    Buffer Size: 15908      Transition Number: 1000.244k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:21:13,210][train][INFO][train.py>_log] ==> #531000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 9.516    Value Loss: 4.458    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1449685    Buffer Size: 15859      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:24:17,130][train][INFO][train.py>_log] ==> #532000     Total Loss: 3.988    [weighted Loss:3.988    Policy Loss: 10.051   Value Loss: 4.655    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451984    Buffer Size: 15828      Transition Number: 1000.239k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:27:22,298][train][INFO][train.py>_log] ==> #533000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 9.789    Value Loss: 4.397    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1454330    Buffer Size: 15819      Transition Number: 1000.611k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:30:31,429][train][INFO][train.py>_log] ==> #534000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 10.090   Value Loss: 4.633    Reward Loss: 1.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 1456745    Buffer Size: 15810      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:33:43,484][train][INFO][train.py>_log] ==> #535000     Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 9.535    Value Loss: 4.536    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 1459181    Buffer Size: 15798      Transition Number: 1000.586k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:36:52,989][train][INFO][train.py>_log] ==> #536000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 9.697    Value Loss: 4.782    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1461599    Buffer Size: 15794      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:40:03,208][train][INFO][train.py>_log] ==> #537000     Total Loss: 3.780    [weighted Loss:3.780    Policy Loss: 10.169   Value Loss: 4.418    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 1463977    Buffer Size: 15802      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:43:14,484][train][INFO][train.py>_log] ==> #538000     Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 9.835    Value Loss: 4.521    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1466372    Buffer Size: 15824      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:46:23,058][train][INFO][train.py>_log] ==> #539000     Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 10.324   Value Loss: 4.583    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1468796    Buffer Size: 15847      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:49:36,504][train][INFO][train.py>_log] ==> #540000     Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 10.226   Value Loss: 4.566    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1471223    Buffer Size: 15863      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:52:43,927][train][INFO][train.py>_log] ==> #541000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 9.799    Value Loss: 4.075    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1473610    Buffer Size: 15896      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:55:54,793][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 9.447    Value Loss: 4.498    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1476072    Buffer Size: 15941      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:59:02,924][train][INFO][train.py>_log] ==> #543000     Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 9.789    Value Loss: 4.316    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1478483    Buffer Size: 16005      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:02:08,354][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 9.952    Value Loss: 4.417    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 1480856    Buffer Size: 16083      Transition Number: 1000.308k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:05:22,522][train][INFO][train.py>_log] ==> #545000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 10.008   Value Loss: 4.464    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1483334    Buffer Size: 16172      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:08:31,084][train][INFO][train.py>_log] ==> #546000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 9.838    Value Loss: 4.718    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485802    Buffer Size: 16271      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:11:39,687][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 10.101   Value Loss: 4.490    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1488242    Buffer Size: 16364      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:14:47,944][train][INFO][train.py>_log] ==> #548000     Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 10.134   Value Loss: 4.367    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1490652    Buffer Size: 16438      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:17:58,773][train][INFO][train.py>_log] ==> #549000     Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 10.323   Value Loss: 4.887    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1493055    Buffer Size: 16502      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:21:08,429][train][INFO][train.py>_log] ==> #550000     Total Loss: 3.298    [weighted Loss:3.298    Policy Loss: 10.103   Value Loss: 4.482    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 1495481    Buffer Size: 16517      Transition Number: 1000.436k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:24:14,811][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.586    [weighted Loss:3.586    Policy Loss: 10.411   Value Loss: 4.602    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1497915    Buffer Size: 16511      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:27:23,454][train][INFO][train.py>_log] ==> #552000     Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 10.195   Value Loss: 4.471    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1500374    Buffer Size: 16488      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:30:33,391][train][INFO][train.py>_log] ==> #553000     Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 10.232   Value Loss: 4.729    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1502731    Buffer Size: 16474      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:33:43,266][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 10.348   Value Loss: 4.554    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1505208    Buffer Size: 16444      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:36:51,796][train][INFO][train.py>_log] ==> #555000     Total Loss: 3.501    [weighted Loss:3.501    Policy Loss: 10.099   Value Loss: 4.670    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 1507658    Buffer Size: 16434      Transition Number: 1000.214k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:39:57,420][train][INFO][train.py>_log] ==> #556000     Total Loss: 3.341    [weighted Loss:3.341    Policy Loss: 10.105   Value Loss: 4.503    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1510077    Buffer Size: 16436      Transition Number: 1000.178k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:43:04,874][train][INFO][train.py>_log] ==> #557000     Total Loss: 3.994    [weighted Loss:3.994    Policy Loss: 10.466   Value Loss: 4.871    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1512548    Buffer Size: 16471      Transition Number: 1000.168k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:46:13,502][train][INFO][train.py>_log] ==> #558000     Total Loss: 3.957    [weighted Loss:3.957    Policy Loss: 10.354   Value Loss: 4.349    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1514996    Buffer Size: 16517      Transition Number: 1000.600k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:49:21,512][train][INFO][train.py>_log] ==> #559000     Total Loss: 3.947    [weighted Loss:3.947    Policy Loss: 10.183   Value Loss: 4.614    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1517403    Buffer Size: 16512      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:52:28,246][train][INFO][train.py>_log] ==> #560000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 9.887    Value Loss: 4.654    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1519739    Buffer Size: 16549      Transition Number: 1000.234k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:55:41,282][train][INFO][train.py>_log] ==> #561000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 10.320   Value Loss: 4.670    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1522239    Buffer Size: 16562      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:58:52,312][train][INFO][train.py>_log] ==> #562000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 10.219   Value Loss: 4.598    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524745    Buffer Size: 16591      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:01:59,474][train][INFO][train.py>_log] ==> #563000     Total Loss: 3.262    [weighted Loss:3.262    Policy Loss: 10.065   Value Loss: 4.645    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 1527118    Buffer Size: 16592      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:05:10,533][train][INFO][train.py>_log] ==> #564000     Total Loss: 3.439    [weighted Loss:3.439    Policy Loss: 10.250   Value Loss: 4.483    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1529620    Buffer Size: 16567      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:08:24,053][train][INFO][train.py>_log] ==> #565000     Total Loss: 3.687    [weighted Loss:3.687    Policy Loss: 10.556   Value Loss: 4.416    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1532086    Buffer Size: 16565      Transition Number: 1000.372k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:11:35,601][train][INFO][train.py>_log] ==> #566000     Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 10.449   Value Loss: 4.924    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1534581    Buffer Size: 16531      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:14:45,109][train][INFO][train.py>_log] ==> #567000     Total Loss: 4.348    [weighted Loss:4.348    Policy Loss: 10.644   Value Loss: 4.555    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1537022    Buffer Size: 16518      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:17:54,059][train][INFO][train.py>_log] ==> #568000     Total Loss: 4.215    [weighted Loss:4.215    Policy Loss: 10.871   Value Loss: 4.485    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1539400    Buffer Size: 16477      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:21:05,487][train][INFO][train.py>_log] ==> #569000     Total Loss: 3.945    [weighted Loss:3.945    Policy Loss: 11.320   Value Loss: 4.748    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1541864    Buffer Size: 16417      Transition Number: 1000.273k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:24:14,818][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 10.834   Value Loss: 4.180    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 1544200    Buffer Size: 16370      Transition Number: 1000.378k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:27:28,085][train][INFO][train.py>_log] ==> #571000     Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 10.873   Value Loss: 4.337    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1546754    Buffer Size: 16320      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:30:38,029][train][INFO][train.py>_log] ==> #572000     Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 10.615   Value Loss: 4.595    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1549214    Buffer Size: 16264      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:33:49,294][train][INFO][train.py>_log] ==> #573000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 10.765   Value Loss: 4.656    Reward Loss: 1.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 1551591    Buffer Size: 16246      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:37:00,425][train][INFO][train.py>_log] ==> #574000     Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 10.919   Value Loss: 4.670    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1554130    Buffer Size: 16220      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:40:13,507][train][INFO][train.py>_log] ==> #575000     Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 10.870   Value Loss: 4.570    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 1556623    Buffer Size: 16217      Transition Number: 1000.557k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:43:21,299][train][INFO][train.py>_log] ==> #576000     Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 10.662   Value Loss: 4.460    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1559012    Buffer Size: 16203      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:46:35,414][train][INFO][train.py>_log] ==> #577000     Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 11.047   Value Loss: 4.628    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1561482    Buffer Size: 16196      Transition Number: 1000.294k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:49:52,045][train][INFO][train.py>_log] ==> #578000     Total Loss: 2.853    [weighted Loss:2.853    Policy Loss: 10.153   Value Loss: 4.577    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 1563924    Buffer Size: 16199      Transition Number: 1000.245k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:53:03,441][train][INFO][train.py>_log] ==> #579000     Total Loss: 4.823    [weighted Loss:4.823    Policy Loss: 10.803   Value Loss: 4.481    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1566304    Buffer Size: 16187      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:56:14,338][train][INFO][train.py>_log] ==> #580000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 10.916   Value Loss: 4.443    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 1568831    Buffer Size: 16167      Transition Number: 1000.337k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:59:23,151][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.683    [weighted Loss:3.683    Policy Loss: 10.551   Value Loss: 4.828    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1571197    Buffer Size: 16135      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:02:33,676][train][INFO][train.py>_log] ==> #582000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 10.762   Value Loss: 4.863    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1573620    Buffer Size: 16101      Transition Number: 1000.245k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:05:43,884][train][INFO][train.py>_log] ==> #583000     Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 10.555   Value Loss: 4.741    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1576005    Buffer Size: 16090      Transition Number: 1000.271k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:08:57,158][train][INFO][train.py>_log] ==> #584000     Total Loss: 4.000    [weighted Loss:4.000    Policy Loss: 10.367   Value Loss: 4.780    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1578482    Buffer Size: 16050      Transition Number: 1000.148k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:12:09,635][train][INFO][train.py>_log] ==> #585000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 10.591   Value Loss: 4.681    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1580993    Buffer Size: 16051      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:15:25,751][train][INFO][train.py>_log] ==> #586000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 10.269   Value Loss: 4.578    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 1583510    Buffer Size: 16057      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:18:34,370][train][INFO][train.py>_log] ==> #587000     Total Loss: 3.739    [weighted Loss:3.739    Policy Loss: 10.480   Value Loss: 4.442    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 1585886    Buffer Size: 16041      Transition Number: 1000.360k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:21:43,946][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 10.423   Value Loss: 4.596    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1588292    Buffer Size: 16054      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:24:55,848][train][INFO][train.py>_log] ==> #589000     Total Loss: 4.723    [weighted Loss:4.723    Policy Loss: 10.605   Value Loss: 4.462    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 1590777    Buffer Size: 16070      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:28:07,861][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 10.735   Value Loss: 4.634    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 1593290    Buffer Size: 16092      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:31:23,060][train][INFO][train.py>_log] ==> #591000     Total Loss: 3.424    [weighted Loss:3.424    Policy Loss: 10.892   Value Loss: 4.615    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1595847    Buffer Size: 16127      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:34:38,067][train][INFO][train.py>_log] ==> #592000     Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 10.400   Value Loss: 4.557    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1598300    Buffer Size: 16136      Transition Number: 1000.266k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:37:50,437][train][INFO][train.py>_log] ==> #593000     Total Loss: 3.871    [weighted Loss:3.871    Policy Loss: 10.602   Value Loss: 4.129    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1600776    Buffer Size: 16167      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:41:02,732][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 10.802   Value Loss: 4.673    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 1603278    Buffer Size: 16213      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:44:18,213][train][INFO][train.py>_log] ==> #595000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 10.876   Value Loss: 4.521    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1605730    Buffer Size: 16269      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:47:32,356][train][INFO][train.py>_log] ==> #596000     Total Loss: 3.961    [weighted Loss:3.961    Policy Loss: 10.543   Value Loss: 4.461    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1608239    Buffer Size: 16310      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:50:44,245][train][INFO][train.py>_log] ==> #597000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 10.597   Value Loss: 4.933    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1610745    Buffer Size: 16330      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:53:58,600][train][INFO][train.py>_log] ==> #598000     Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 10.734   Value Loss: 4.441    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1613181    Buffer Size: 16355      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:57:13,081][train][INFO][train.py>_log] ==> #599000     Total Loss: 4.320    [weighted Loss:4.320    Policy Loss: 10.516   Value Loss: 4.389    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1615775    Buffer Size: 16381      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 10:00:22,687][train][INFO][train.py>_log] ==> #600000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 10.691   Value Loss: 4.188    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1618224    Buffer Size: 16395      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00400 
[2022-02-26 10:03:37,855][train][INFO][train.py>_log] ==> #601000     Total Loss: 4.372    [weighted Loss:4.372    Policy Loss: 10.341   Value Loss: 4.460    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 1620652    Buffer Size: 16410      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:06:50,732][train][INFO][train.py>_log] ==> #602000     Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 10.169   Value Loss: 4.632    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 1623090    Buffer Size: 16408      Transition Number: 1000.544k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:10:02,561][train][INFO][train.py>_log] ==> #603000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 10.598   Value Loss: 4.499    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1625649    Buffer Size: 16392      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:13:14,102][train][INFO][train.py>_log] ==> #604000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 10.280   Value Loss: 4.423    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1628057    Buffer Size: 16398      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:16:30,356][train][INFO][train.py>_log] ==> #605000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 10.382   Value Loss: 4.591    Reward Loss: 1.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 1630546    Buffer Size: 16375      Transition Number: 1000.302k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:19:45,304][train][INFO][train.py>_log] ==> #606000     Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 10.064   Value Loss: 4.389    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1633034    Buffer Size: 16332      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:23:04,706][train][INFO][train.py>_log] ==> #607000     Total Loss: 2.025    [weighted Loss:2.025    Policy Loss: 10.091   Value Loss: 4.704    Reward Loss: 1.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 1635569    Buffer Size: 16333      Transition Number: 1000.512k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:26:22,385][train][INFO][train.py>_log] ==> #608000     Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 10.115   Value Loss: 4.656    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1638142    Buffer Size: 16300      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:29:36,454][train][INFO][train.py>_log] ==> #609000     Total Loss: 3.042    [weighted Loss:3.042    Policy Loss: 9.900    Value Loss: 4.622    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 1640568    Buffer Size: 16277      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:32:49,682][train][INFO][train.py>_log] ==> #610000     Total Loss: 2.843    [weighted Loss:2.843    Policy Loss: 10.270   Value Loss: 4.501    Reward Loss: 1.937    Consistency Loss: 0.000    ] Replay Episodes Collected: 1643027    Buffer Size: 16283      Transition Number: 1000.296k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:36:03,828][train][INFO][train.py>_log] ==> #611000     Total Loss: 4.005    [weighted Loss:4.005    Policy Loss: 10.114   Value Loss: 4.235    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 1645416    Buffer Size: 16256      Transition Number: 1000.153k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:39:22,308][train][INFO][train.py>_log] ==> #612000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 10.169   Value Loss: 4.406    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 1648132    Buffer Size: 16268      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:42:38,685][train][INFO][train.py>_log] ==> #613000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 10.089   Value Loss: 4.455    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1650596    Buffer Size: 16287      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:45:55,619][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 10.466   Value Loss: 4.576    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1653092    Buffer Size: 16315      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:49:06,694][train][INFO][train.py>_log] ==> #615000     Total Loss: 1.795    [weighted Loss:1.795    Policy Loss: 10.158   Value Loss: 4.447    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1655470    Buffer Size: 16319      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:52:18,783][train][INFO][train.py>_log] ==> #616000     Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 9.978    Value Loss: 4.781    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1657920    Buffer Size: 16299      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:55:32,936][train][INFO][train.py>_log] ==> #617000     Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 10.322   Value Loss: 4.105    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1660462    Buffer Size: 16285      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:58:47,131][train][INFO][train.py>_log] ==> #618000     Total Loss: 3.967    [weighted Loss:3.967    Policy Loss: 10.243   Value Loss: 4.499    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1662916    Buffer Size: 16290      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:02:04,588][train][INFO][train.py>_log] ==> #619000     Total Loss: 4.517    [weighted Loss:4.517    Policy Loss: 9.964    Value Loss: 4.484    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 1665459    Buffer Size: 16279      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:05:21,568][train][INFO][train.py>_log] ==> #620000     Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 10.177   Value Loss: 4.488    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 1668036    Buffer Size: 16286      Transition Number: 1000.540k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:08:34,316][train][INFO][train.py>_log] ==> #621000     Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 10.127   Value Loss: 5.062    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1670520    Buffer Size: 16248      Transition Number: 1000.393k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:11:47,749][train][INFO][train.py>_log] ==> #622000     Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 10.203   Value Loss: 4.550    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1672943    Buffer Size: 16270      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:14:59,112][train][INFO][train.py>_log] ==> #623000     Total Loss: 3.761    [weighted Loss:3.761    Policy Loss: 10.012   Value Loss: 4.179    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 1675375    Buffer Size: 16280      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:18:12,038][train][INFO][train.py>_log] ==> #624000     Total Loss: 3.632    [weighted Loss:3.632    Policy Loss: 10.410   Value Loss: 4.438    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1677847    Buffer Size: 16308      Transition Number: 1000.277k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:21:20,862][train][INFO][train.py>_log] ==> #625000     Total Loss: 3.401    [weighted Loss:3.401    Policy Loss: 10.450   Value Loss: 4.213    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1680257    Buffer Size: 16302      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:24:35,488][train][INFO][train.py>_log] ==> #626000     Total Loss: 4.208    [weighted Loss:4.208    Policy Loss: 10.167   Value Loss: 4.354    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1682817    Buffer Size: 16296      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:27:46,667][train][INFO][train.py>_log] ==> #627000     Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 10.692   Value Loss: 4.568    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1685230    Buffer Size: 16301      Transition Number: 1000.149k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:30:59,827][train][INFO][train.py>_log] ==> #628000     Total Loss: 4.241    [weighted Loss:4.241    Policy Loss: 10.466   Value Loss: 4.607    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1687688    Buffer Size: 16284      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:34:13,249][train][INFO][train.py>_log] ==> #629000     Total Loss: 4.584    [weighted Loss:4.584    Policy Loss: 10.390   Value Loss: 4.370    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1690195    Buffer Size: 16289      Transition Number: 1000.403k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:37:22,941][train][INFO][train.py>_log] ==> #630000     Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 10.346   Value Loss: 4.133    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1692626    Buffer Size: 16268      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:40:36,794][train][INFO][train.py>_log] ==> #631000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 10.621   Value Loss: 4.765    Reward Loss: 1.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 1695078    Buffer Size: 16234      Transition Number: 1000.167k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:43:50,696][train][INFO][train.py>_log] ==> #632000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 10.468   Value Loss: 4.547    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 1697573    Buffer Size: 16230      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:47:02,604][train][INFO][train.py>_log] ==> #633000     Total Loss: 4.049    [weighted Loss:4.049    Policy Loss: 10.347   Value Loss: 4.509    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1699946    Buffer Size: 16202      Transition Number: 1000.419k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:50:19,219][train][INFO][train.py>_log] ==> #634000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 10.950   Value Loss: 4.293    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1702438    Buffer Size: 16175      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:53:35,600][train][INFO][train.py>_log] ==> #635000     Total Loss: 4.317    [weighted Loss:4.317    Policy Loss: 10.691   Value Loss: 4.238    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1705043    Buffer Size: 16152      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00080 
[2022-02-26 11:56:48,819][train][INFO][train.py>_log] ==> #636000     Total Loss: 3.570    [weighted Loss:3.570    Policy Loss: 10.694   Value Loss: 4.518    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1707538    Buffer Size: 16123      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:00:00,171][train][INFO][train.py>_log] ==> #637000     Total Loss: 3.148    [weighted Loss:3.148    Policy Loss: 10.440   Value Loss: 4.412    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1709888    Buffer Size: 16105      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:03:12,818][train][INFO][train.py>_log] ==> #638000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 10.307   Value Loss: 4.437    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 1712321    Buffer Size: 16093      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:06:28,386][train][INFO][train.py>_log] ==> #639000     Total Loss: 3.954    [weighted Loss:3.954    Policy Loss: 10.208   Value Loss: 4.309    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1714864    Buffer Size: 16055      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:09:38,669][train][INFO][train.py>_log] ==> #640000     Total Loss: 3.979    [weighted Loss:3.979    Policy Loss: 10.299   Value Loss: 4.651    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1717296    Buffer Size: 16041      Transition Number: 1000.732k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:12:52,933][train][INFO][train.py>_log] ==> #641000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 10.370   Value Loss: 4.294    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1719735    Buffer Size: 16030      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:16:08,218][train][INFO][train.py>_log] ==> #642000     Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 10.501   Value Loss: 4.288    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1722192    Buffer Size: 16029      Transition Number: 1000.038k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:19:24,318][train][INFO][train.py>_log] ==> #643000     Total Loss: 1.942    [weighted Loss:1.942    Policy Loss: 10.248   Value Loss: 4.739    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 1724759    Buffer Size: 16025      Transition Number: 1000.413k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:22:40,694][train][INFO][train.py>_log] ==> #644000     Total Loss: 3.883    [weighted Loss:3.883    Policy Loss: 10.275   Value Loss: 4.266    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1727240    Buffer Size: 16003      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:25:52,226][train][INFO][train.py>_log] ==> #645000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 10.340   Value Loss: 4.261    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1729735    Buffer Size: 16003      Transition Number: 1000.330k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:29:10,660][train][INFO][train.py>_log] ==> #646000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 9.895    Value Loss: 4.390    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 1732284    Buffer Size: 16029      Transition Number: 1000.198k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:32:28,051][train][INFO][train.py>_log] ==> #647000     Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 10.551   Value Loss: 4.222    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 1734806    Buffer Size: 16040      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:35:40,333][train][INFO][train.py>_log] ==> #648000     Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 10.239   Value Loss: 4.163    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1737266    Buffer Size: 16062      Transition Number: 1000.279k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:38:59,942][train][INFO][train.py>_log] ==> #649000     Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 10.531   Value Loss: 4.484    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1739757    Buffer Size: 16056      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:42:17,829][train][INFO][train.py>_log] ==> #650000     Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 10.336   Value Loss: 4.416    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 1742331    Buffer Size: 16080      Transition Number: 1000.068k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:45:36,179][train][INFO][train.py>_log] ==> #651000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 10.587   Value Loss: 4.584    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1744815    Buffer Size: 16075      Transition Number: 1000.203k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:48:49,074][train][INFO][train.py>_log] ==> #652000     Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 10.055   Value Loss: 4.465    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 1747284    Buffer Size: 16071      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:52:03,936][train][INFO][train.py>_log] ==> #653000     Total Loss: 2.808    [weighted Loss:2.808    Policy Loss: 9.968    Value Loss: 4.337    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1749860    Buffer Size: 16062      Transition Number: 1000.632k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:55:15,989][train][INFO][train.py>_log] ==> #654000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 10.345   Value Loss: 4.359    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1752279    Buffer Size: 16048      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 12:58:27,194][train][INFO][train.py>_log] ==> #655000     Total Loss: 3.879    [weighted Loss:3.879    Policy Loss: 10.516   Value Loss: 4.146    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1754651    Buffer Size: 16040      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:01:39,884][train][INFO][train.py>_log] ==> #656000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 10.360   Value Loss: 4.240    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1757101    Buffer Size: 16024      Transition Number: 1000.285k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:04:51,588][train][INFO][train.py>_log] ==> #657000     Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 10.712   Value Loss: 4.486    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1759599    Buffer Size: 16006      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:08:06,108][train][INFO][train.py>_log] ==> #658000     Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 10.216   Value Loss: 4.036    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 1761992    Buffer Size: 15989      Transition Number: 1000.256k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:11:18,098][train][INFO][train.py>_log] ==> #659000     Total Loss: 3.418    [weighted Loss:3.418    Policy Loss: 10.482   Value Loss: 4.298    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1764439    Buffer Size: 15965      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:14:26,575][train][INFO][train.py>_log] ==> #660000     Total Loss: 3.415    [weighted Loss:3.415    Policy Loss: 10.855   Value Loss: 4.560    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 1766835    Buffer Size: 15941      Transition Number: 1000.569k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:17:40,881][train][INFO][train.py>_log] ==> #661000     Total Loss: 3.653    [weighted Loss:3.653    Policy Loss: 10.478   Value Loss: 4.383    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1769305    Buffer Size: 15916      Transition Number: 1000.244k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:21:01,153][train][INFO][train.py>_log] ==> #662000     Total Loss: 3.632    [weighted Loss:3.632    Policy Loss: 10.262   Value Loss: 4.476    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 1771892    Buffer Size: 15881      Transition Number: 1000.068k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:24:18,756][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 10.145   Value Loss: 4.305    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1774379    Buffer Size: 15888      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:27:35,080][train][INFO][train.py>_log] ==> #664000     Total Loss: 3.023    [weighted Loss:3.023    Policy Loss: 10.338   Value Loss: 4.181    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1776898    Buffer Size: 15888      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:30:47,557][train][INFO][train.py>_log] ==> #665000     Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 10.506   Value Loss: 4.319    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1779301    Buffer Size: 15883      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:34:03,930][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.950    [weighted Loss:2.950    Policy Loss: 10.749   Value Loss: 4.302    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1781743    Buffer Size: 15894      Transition Number: 1000.213k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:37:21,895][train][INFO][train.py>_log] ==> #667000     Total Loss: 2.975    [weighted Loss:2.975    Policy Loss: 10.784   Value Loss: 4.272    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 1784402    Buffer Size: 15911      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:40:31,581][train][INFO][train.py>_log] ==> #668000     Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 10.581   Value Loss: 4.172    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1786791    Buffer Size: 15921      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:43:47,317][train][INFO][train.py>_log] ==> #669000     Total Loss: 3.502    [weighted Loss:3.502    Policy Loss: 10.549   Value Loss: 4.554    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 1789226    Buffer Size: 15928      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:47:03,283][train][INFO][train.py>_log] ==> #670000     Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 10.394   Value Loss: 4.221    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1791677    Buffer Size: 15938      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:50:16,038][train][INFO][train.py>_log] ==> #671000     Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 10.460   Value Loss: 4.590    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1794230    Buffer Size: 15923      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:53:30,908][train][INFO][train.py>_log] ==> #672000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 10.402   Value Loss: 4.276    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1796730    Buffer Size: 15904      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 13:56:44,564][train][INFO][train.py>_log] ==> #673000     Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 10.707   Value Loss: 4.294    Reward Loss: 1.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 1799139    Buffer Size: 15897      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:00:01,776][train][INFO][train.py>_log] ==> #674000     Total Loss: 3.289    [weighted Loss:3.289    Policy Loss: 10.501   Value Loss: 4.301    Reward Loss: 1.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 1801771    Buffer Size: 15906      Transition Number: 1000.439k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:03:18,368][train][INFO][train.py>_log] ==> #675000     Total Loss: 3.859    [weighted Loss:3.859    Policy Loss: 10.365   Value Loss: 4.589    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1804240    Buffer Size: 15889      Transition Number: 1000.242k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:06:35,390][train][INFO][train.py>_log] ==> #676000     Total Loss: 3.805    [weighted Loss:3.805    Policy Loss: 11.115   Value Loss: 4.459    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1806663    Buffer Size: 15871      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:09:49,608][train][INFO][train.py>_log] ==> #677000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 10.613   Value Loss: 4.506    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1809184    Buffer Size: 15866      Transition Number: 1000.193k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:13:07,132][train][INFO][train.py>_log] ==> #678000     Total Loss: 2.539    [weighted Loss:2.539    Policy Loss: 11.088   Value Loss: 4.257    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1811741    Buffer Size: 15875      Transition Number: 1000.283k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:16:22,801][train][INFO][train.py>_log] ==> #679000     Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 10.813   Value Loss: 4.775    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1814185    Buffer Size: 15859      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:19:35,609][train][INFO][train.py>_log] ==> #680000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 10.966   Value Loss: 4.410    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 1816630    Buffer Size: 15851      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:22:52,762][train][INFO][train.py>_log] ==> #681000     Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 11.044   Value Loss: 4.102    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1819197    Buffer Size: 15848      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:26:08,663][train][INFO][train.py>_log] ==> #682000     Total Loss: 4.488    [weighted Loss:4.488    Policy Loss: 10.815   Value Loss: 4.449    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1821670    Buffer Size: 15848      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:29:21,395][train][INFO][train.py>_log] ==> #683000     Total Loss: 3.612    [weighted Loss:3.612    Policy Loss: 11.091   Value Loss: 4.116    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1824174    Buffer Size: 15874      Transition Number: 1000.271k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:32:37,892][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 10.843   Value Loss: 4.236    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1826720    Buffer Size: 15878      Transition Number: 1000.542k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:35:52,732][train][INFO][train.py>_log] ==> #685000     Total Loss: 3.678    [weighted Loss:3.678    Policy Loss: 10.548   Value Loss: 3.984    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1829212    Buffer Size: 15892      Transition Number: 1000.131k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:39:07,743][train][INFO][train.py>_log] ==> #686000     Total Loss: 3.572    [weighted Loss:3.572    Policy Loss: 10.565   Value Loss: 4.214    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1831709    Buffer Size: 15891      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:42:17,419][train][INFO][train.py>_log] ==> #687000     Total Loss: 4.007    [weighted Loss:4.007    Policy Loss: 10.435   Value Loss: 4.483    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1834101    Buffer Size: 15906      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:45:32,709][train][INFO][train.py>_log] ==> #688000     Total Loss: 1.870    [weighted Loss:1.870    Policy Loss: 10.414   Value Loss: 4.365    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 1836555    Buffer Size: 15910      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:48:46,916][train][INFO][train.py>_log] ==> #689000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 10.460   Value Loss: 4.324    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 1839031    Buffer Size: 15912      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:51:56,976][train][INFO][train.py>_log] ==> #690000     Total Loss: 3.629    [weighted Loss:3.629    Policy Loss: 10.785   Value Loss: 4.313    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1841544    Buffer Size: 15911      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:55:08,807][train][INFO][train.py>_log] ==> #691000     Total Loss: 3.167    [weighted Loss:3.167    Policy Loss: 10.339   Value Loss: 4.334    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1844011    Buffer Size: 15918      Transition Number: 1000.476k Batch Size: 256        Lr: 0.00080 
[2022-02-26 14:58:21,241][train][INFO][train.py>_log] ==> #692000     Total Loss: 1.640    [weighted Loss:1.640    Policy Loss: 10.340   Value Loss: 4.430    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1846423    Buffer Size: 15945      Transition Number: 1000.399k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:01:33,253][train][INFO][train.py>_log] ==> #693000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 10.346   Value Loss: 4.251    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1848934    Buffer Size: 15962      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:04:46,918][train][INFO][train.py>_log] ==> #694000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 10.094   Value Loss: 4.306    Reward Loss: 1.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 1851367    Buffer Size: 15968      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:08:00,524][train][INFO][train.py>_log] ==> #695000     Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 10.317   Value Loss: 4.449    Reward Loss: 1.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 1853841    Buffer Size: 16017      Transition Number: 1000.121k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:11:12,458][train][INFO][train.py>_log] ==> #696000     Total Loss: 3.301    [weighted Loss:3.301    Policy Loss: 10.354   Value Loss: 4.099    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1856253    Buffer Size: 16047      Transition Number: 1000.354k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:14:26,739][train][INFO][train.py>_log] ==> #697000     Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 10.597   Value Loss: 4.270    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1858849    Buffer Size: 16063      Transition Number: 1000.200k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:17:41,577][train][INFO][train.py>_log] ==> #698000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 10.588   Value Loss: 4.269    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1861321    Buffer Size: 16067      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:21:00,054][train][INFO][train.py>_log] ==> #699000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 10.830   Value Loss: 4.515    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1863879    Buffer Size: 16095      Transition Number: 1000.371k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:24:14,927][train][INFO][train.py>_log] ==> #700000     Total Loss: 3.935    [weighted Loss:3.935    Policy Loss: 10.673   Value Loss: 4.371    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 1866391    Buffer Size: 16127      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:27:31,107][train][INFO][train.py>_log] ==> #701000     Total Loss: 3.492    [weighted Loss:3.492    Policy Loss: 10.574   Value Loss: 4.253    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1868906    Buffer Size: 16139      Transition Number: 1000.565k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:30:48,039][train][INFO][train.py>_log] ==> #702000     Total Loss: 4.319    [weighted Loss:4.319    Policy Loss: 10.562   Value Loss: 4.449    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1871448    Buffer Size: 16148      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:34:03,247][train][INFO][train.py>_log] ==> #703000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 10.218   Value Loss: 4.043    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1873971    Buffer Size: 16175      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:37:15,806][train][INFO][train.py>_log] ==> #704000     Total Loss: 2.800    [weighted Loss:2.800    Policy Loss: 10.278   Value Loss: 4.280    Reward Loss: 1.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 1876405    Buffer Size: 16199      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:40:32,235][train][INFO][train.py>_log] ==> #705000     Total Loss: 4.256    [weighted Loss:4.256    Policy Loss: 10.845   Value Loss: 4.564    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1878869    Buffer Size: 16222      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:43:45,339][train][INFO][train.py>_log] ==> #706000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 10.533   Value Loss: 4.444    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1881452    Buffer Size: 16238      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:47:00,462][train][INFO][train.py>_log] ==> #707000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 10.275   Value Loss: 4.434    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 1883956    Buffer Size: 16245      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:50:13,465][train][INFO][train.py>_log] ==> #708000     Total Loss: 4.209    [weighted Loss:4.209    Policy Loss: 10.429   Value Loss: 4.440    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 1886470    Buffer Size: 16250      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:53:30,393][train][INFO][train.py>_log] ==> #709000     Total Loss: 1.171    [weighted Loss:1.171    Policy Loss: 10.630   Value Loss: 4.429    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 1889048    Buffer Size: 16275      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:56:47,533][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 10.037   Value Loss: 4.232    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1891533    Buffer Size: 16294      Transition Number: 1000.152k Batch Size: 256        Lr: 0.00080 
[2022-02-26 15:59:59,417][train][INFO][train.py>_log] ==> #711000     Total Loss: 2.929    [weighted Loss:2.929    Policy Loss: 10.457   Value Loss: 4.666    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 1894018    Buffer Size: 16295      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:03:11,848][train][INFO][train.py>_log] ==> #712000     Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 10.626   Value Loss: 4.349    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1896476    Buffer Size: 16319      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:06:24,086][train][INFO][train.py>_log] ==> #713000     Total Loss: 3.994    [weighted Loss:3.994    Policy Loss: 10.739   Value Loss: 4.424    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1898964    Buffer Size: 16316      Transition Number: 1000.241k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:09:39,566][train][INFO][train.py>_log] ==> #714000     Total Loss: 3.673    [weighted Loss:3.673    Policy Loss: 10.885   Value Loss: 4.573    Reward Loss: 1.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 1901507    Buffer Size: 16295      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:12:55,659][train][INFO][train.py>_log] ==> #715000     Total Loss: 4.409    [weighted Loss:4.409    Policy Loss: 10.555   Value Loss: 4.697    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1903984    Buffer Size: 16265      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:16:11,261][train][INFO][train.py>_log] ==> #716000     Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 10.779   Value Loss: 4.634    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1906522    Buffer Size: 16255      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:19:27,670][train][INFO][train.py>_log] ==> #717000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 11.096   Value Loss: 4.485    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1909097    Buffer Size: 16234      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:22:43,457][train][INFO][train.py>_log] ==> #718000     Total Loss: 2.527    [weighted Loss:2.527    Policy Loss: 10.815   Value Loss: 4.622    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1911584    Buffer Size: 16232      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:25:57,053][train][INFO][train.py>_log] ==> #719000     Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 10.542   Value Loss: 4.513    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1914052    Buffer Size: 16200      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:29:13,756][train][INFO][train.py>_log] ==> #720000     Total Loss: 3.261    [weighted Loss:3.261    Policy Loss: 10.848   Value Loss: 4.116    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1916584    Buffer Size: 16179      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:32:30,090][train][INFO][train.py>_log] ==> #721000     Total Loss: 3.623    [weighted Loss:3.623    Policy Loss: 10.759   Value Loss: 4.576    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1919111    Buffer Size: 16176      Transition Number: 1000.183k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:35:42,975][train][INFO][train.py>_log] ==> #722000     Total Loss: 3.812    [weighted Loss:3.812    Policy Loss: 10.655   Value Loss: 4.265    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1921567    Buffer Size: 16166      Transition Number: 1000.374k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:38:58,529][train][INFO][train.py>_log] ==> #723000     Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 10.692   Value Loss: 4.190    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1924077    Buffer Size: 16152      Transition Number: 1000.120k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:42:15,505][train][INFO][train.py>_log] ==> #724000     Total Loss: 4.344    [weighted Loss:4.344    Policy Loss: 10.343   Value Loss: 4.576    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1926619    Buffer Size: 16131      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:45:33,701][train][INFO][train.py>_log] ==> #725000     Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 10.373   Value Loss: 4.287    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1929198    Buffer Size: 16114      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:48:50,373][train][INFO][train.py>_log] ==> #726000     Total Loss: 2.891    [weighted Loss:2.891    Policy Loss: 10.353   Value Loss: 4.459    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1931669    Buffer Size: 16129      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:52:07,373][train][INFO][train.py>_log] ==> #727000     Total Loss: 3.361    [weighted Loss:3.361    Policy Loss: 10.266   Value Loss: 4.629    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 1934164    Buffer Size: 16132      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:55:23,453][train][INFO][train.py>_log] ==> #728000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 10.350   Value Loss: 4.370    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1936734    Buffer Size: 16134      Transition Number: 1000.515k Batch Size: 256        Lr: 0.00080 
[2022-02-26 16:58:48,215][train][INFO][train.py>_log] ==> #729000     Total Loss: 2.902    [weighted Loss:2.902    Policy Loss: 10.685   Value Loss: 4.396    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 1939392    Buffer Size: 16153      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:02:04,453][train][INFO][train.py>_log] ==> #730000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 10.952   Value Loss: 4.499    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 1941832    Buffer Size: 16164      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:05:22,814][train][INFO][train.py>_log] ==> #731000     Total Loss: 4.494    [weighted Loss:4.494    Policy Loss: 10.903   Value Loss: 4.463    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1944524    Buffer Size: 16158      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:08:36,695][train][INFO][train.py>_log] ==> #732000     Total Loss: 3.927    [weighted Loss:3.927    Policy Loss: 11.123   Value Loss: 4.513    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 1946992    Buffer Size: 16161      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:11:57,104][train][INFO][train.py>_log] ==> #733000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 11.014   Value Loss: 4.657    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1949509    Buffer Size: 16150      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:15:13,155][train][INFO][train.py>_log] ==> #734000     Total Loss: 3.709    [weighted Loss:3.709    Policy Loss: 10.962   Value Loss: 4.501    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1951938    Buffer Size: 16147      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:18:30,866][train][INFO][train.py>_log] ==> #735000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 11.212   Value Loss: 4.474    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 1954629    Buffer Size: 16094      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:21:47,649][train][INFO][train.py>_log] ==> #736000     Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 10.631   Value Loss: 4.733    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1957067    Buffer Size: 16065      Transition Number: 1000.281k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:25:03,807][train][INFO][train.py>_log] ==> #737000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 10.633   Value Loss: 4.440    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 1959667    Buffer Size: 16051      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:28:22,109][train][INFO][train.py>_log] ==> #738000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 10.632   Value Loss: 4.317    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1962209    Buffer Size: 16017      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:31:39,773][train][INFO][train.py>_log] ==> #739000     Total Loss: 3.448    [weighted Loss:3.448    Policy Loss: 10.771   Value Loss: 4.217    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1964702    Buffer Size: 16017      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:34:53,101][train][INFO][train.py>_log] ==> #740000     Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 10.673   Value Loss: 4.248    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1967230    Buffer Size: 16026      Transition Number: 1000.491k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:38:10,242][train][INFO][train.py>_log] ==> #741000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 10.458   Value Loss: 4.313    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1969747    Buffer Size: 16040      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:41:32,074][train][INFO][train.py>_log] ==> #742000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 10.519   Value Loss: 4.385    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1972384    Buffer Size: 16049      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:44:48,218][train][INFO][train.py>_log] ==> #743000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 10.944   Value Loss: 4.330    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1974810    Buffer Size: 16056      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:48:05,270][train][INFO][train.py>_log] ==> #744000     Total Loss: 3.136    [weighted Loss:3.136    Policy Loss: 10.802   Value Loss: 4.532    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1977308    Buffer Size: 16065      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:51:29,099][train][INFO][train.py>_log] ==> #745000     Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 10.630   Value Loss: 4.482    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 1980043    Buffer Size: 16067      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:54:50,901][train][INFO][train.py>_log] ==> #746000     Total Loss: 3.770    [weighted Loss:3.770    Policy Loss: 10.602   Value Loss: 4.335    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1982584    Buffer Size: 16067      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 17:58:10,324][train][INFO][train.py>_log] ==> #747000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 10.845   Value Loss: 4.249    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1985145    Buffer Size: 16046      Transition Number: 1000.382k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:01:27,204][train][INFO][train.py>_log] ==> #748000     Total Loss: 3.524    [weighted Loss:3.524    Policy Loss: 10.984   Value Loss: 4.396    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1987645    Buffer Size: 16041      Transition Number: 1000.417k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:04:46,490][train][INFO][train.py>_log] ==> #749000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 11.223   Value Loss: 4.705    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1990217    Buffer Size: 16001      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:08:05,315][train][INFO][train.py>_log] ==> #750000     Total Loss: 3.112    [weighted Loss:3.112    Policy Loss: 10.761   Value Loss: 4.210    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1992705    Buffer Size: 15996      Transition Number: 1000.355k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:11:25,731][train][INFO][train.py>_log] ==> #751000     Total Loss: 3.672    [weighted Loss:3.672    Policy Loss: 10.844   Value Loss: 4.001    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1995389    Buffer Size: 15942      Transition Number: 1000.181k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:14:40,601][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.714    [weighted Loss:1.714    Policy Loss: 10.807   Value Loss: 4.465    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 1997818    Buffer Size: 15914      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:17:58,433][train][INFO][train.py>_log] ==> #753000     Total Loss: 3.356    [weighted Loss:3.356    Policy Loss: 11.021   Value Loss: 4.216    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 2000354    Buffer Size: 15898      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:21:22,964][train][INFO][train.py>_log] ==> #754000     Total Loss: 3.416    [weighted Loss:3.416    Policy Loss: 11.278   Value Loss: 4.369    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2002958    Buffer Size: 15864      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:24:43,623][train][INFO][train.py>_log] ==> #755000     Total Loss: 1.674    [weighted Loss:1.674    Policy Loss: 11.398   Value Loss: 4.442    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 2005560    Buffer Size: 15849      Transition Number: 1000.341k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:28:01,732][train][INFO][train.py>_log] ==> #756000     Total Loss: 3.926    [weighted Loss:3.926    Policy Loss: 11.289   Value Loss: 4.479    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2008150    Buffer Size: 15819      Transition Number: 1000.226k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:31:17,556][train][INFO][train.py>_log] ==> #757000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 11.153   Value Loss: 4.197    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2010662    Buffer Size: 15791      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:34:32,024][train][INFO][train.py>_log] ==> #758000     Total Loss: 3.007    [weighted Loss:3.007    Policy Loss: 11.199   Value Loss: 4.506    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2013186    Buffer Size: 15780      Transition Number: 1000.183k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:37:44,872][train][INFO][train.py>_log] ==> #759000     Total Loss: 4.083    [weighted Loss:4.083    Policy Loss: 11.145   Value Loss: 4.257    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2015632    Buffer Size: 15746      Transition Number: 1000.096k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:41:06,239][train][INFO][train.py>_log] ==> #760000     Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 10.769   Value Loss: 4.204    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2018111    Buffer Size: 15733      Transition Number: 1000.239k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:44:22,593][train][INFO][train.py>_log] ==> #761000     Total Loss: 4.286    [weighted Loss:4.286    Policy Loss: 11.083   Value Loss: 4.398    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 2020635    Buffer Size: 15714      Transition Number: 1000.328k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:47:41,846][train][INFO][train.py>_log] ==> #762000     Total Loss: 4.089    [weighted Loss:4.089    Policy Loss: 11.070   Value Loss: 4.757    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2023238    Buffer Size: 15675      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:50:55,206][train][INFO][train.py>_log] ==> #763000     Total Loss: 4.156    [weighted Loss:4.156    Policy Loss: 10.926   Value Loss: 4.362    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 2025644    Buffer Size: 15679      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:54:14,067][train][INFO][train.py>_log] ==> #764000     Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 10.728   Value Loss: 4.448    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2028200    Buffer Size: 15656      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00080 
[2022-02-26 18:57:30,510][train][INFO][train.py>_log] ==> #765000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 10.599   Value Loss: 4.304    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2030721    Buffer Size: 15674      Transition Number: 1000.325k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:00:45,165][train][INFO][train.py>_log] ==> #766000     Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 11.155   Value Loss: 4.323    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2033251    Buffer Size: 15666      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:04:07,156][train][INFO][train.py>_log] ==> #767000     Total Loss: 3.402    [weighted Loss:3.402    Policy Loss: 10.838   Value Loss: 4.472    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2035772    Buffer Size: 15665      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:07:25,315][train][INFO][train.py>_log] ==> #768000     Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 10.978   Value Loss: 4.277    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2038304    Buffer Size: 15655      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:10:42,186][train][INFO][train.py>_log] ==> #769000     Total Loss: 3.325    [weighted Loss:3.325    Policy Loss: 11.111   Value Loss: 4.434    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2040820    Buffer Size: 15646      Transition Number: 1000.584k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:14:05,963][train][INFO][train.py>_log] ==> #770000     Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 11.179   Value Loss: 4.402    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2043422    Buffer Size: 15639      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:17:26,754][train][INFO][train.py>_log] ==> #771000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 10.753   Value Loss: 4.361    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2046021    Buffer Size: 15627      Transition Number: 1000.536k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:20:46,995][train][INFO][train.py>_log] ==> #772000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 11.117   Value Loss: 4.087    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 2048661    Buffer Size: 15599      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:24:01,749][train][INFO][train.py>_log] ==> #773000     Total Loss: 3.032    [weighted Loss:3.032    Policy Loss: 11.005   Value Loss: 4.424    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 2051022    Buffer Size: 15591      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:27:21,384][train][INFO][train.py>_log] ==> #774000     Total Loss: 3.695    [weighted Loss:3.695    Policy Loss: 10.621   Value Loss: 4.447    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2053549    Buffer Size: 15585      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:30:46,074][train][INFO][train.py>_log] ==> #775000     Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 10.887   Value Loss: 4.074    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2056233    Buffer Size: 15562      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:34:02,777][train][INFO][train.py>_log] ==> #776000     Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 11.095   Value Loss: 4.360    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2058726    Buffer Size: 15541      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:37:22,078][train][INFO][train.py>_log] ==> #777000     Total Loss: 4.068    [weighted Loss:4.068    Policy Loss: 11.049   Value Loss: 4.195    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 2061208    Buffer Size: 15522      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:40:33,498][train][INFO][train.py>_log] ==> #778000     Total Loss: 4.043    [weighted Loss:4.043    Policy Loss: 10.854   Value Loss: 4.216    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2063687    Buffer Size: 15488      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:43:51,120][train][INFO][train.py>_log] ==> #779000     Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 11.168   Value Loss: 4.133    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2066212    Buffer Size: 15474      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:47:11,136][train][INFO][train.py>_log] ==> #780000     Total Loss: 4.962    [weighted Loss:4.962    Policy Loss: 10.945   Value Loss: 4.240    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2068733    Buffer Size: 15441      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:50:30,298][train][INFO][train.py>_log] ==> #781000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 10.920   Value Loss: 4.155    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2071219    Buffer Size: 15428      Transition Number: 1000.234k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:53:50,909][train][INFO][train.py>_log] ==> #782000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 10.920   Value Loss: 4.683    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 2073787    Buffer Size: 15392      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00080 
[2022-02-26 19:57:07,580][train][INFO][train.py>_log] ==> #783000     Total Loss: 1.244    [weighted Loss:1.244    Policy Loss: 10.512   Value Loss: 4.302    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2076273    Buffer Size: 15382      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:00:23,134][train][INFO][train.py>_log] ==> #784000     Total Loss: 3.687    [weighted Loss:3.687    Policy Loss: 11.325   Value Loss: 4.343    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2078776    Buffer Size: 15377      Transition Number: 1000.491k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:03:40,173][train][INFO][train.py>_log] ==> #785000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 10.450   Value Loss: 4.165    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 2081246    Buffer Size: 15381      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:06:54,235][train][INFO][train.py>_log] ==> #786000     Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 10.431   Value Loss: 4.376    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 2083767    Buffer Size: 15381      Transition Number: 1000.231k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:10:11,159][train][INFO][train.py>_log] ==> #787000     Total Loss: 3.177    [weighted Loss:3.177    Policy Loss: 10.579   Value Loss: 4.389    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 2086288    Buffer Size: 15384      Transition Number: 1000.420k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:13:29,103][train][INFO][train.py>_log] ==> #788000     Total Loss: 2.293    [weighted Loss:2.293    Policy Loss: 10.677   Value Loss: 4.950    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 2088775    Buffer Size: 15385      Transition Number: 1000.081k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:16:40,999][train][INFO][train.py>_log] ==> #789000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 11.102   Value Loss: 4.589    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 2091181    Buffer Size: 15393      Transition Number: 1000.106k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:19:56,448][train][INFO][train.py>_log] ==> #790000     Total Loss: 3.520    [weighted Loss:3.520    Policy Loss: 11.072   Value Loss: 4.381    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2093672    Buffer Size: 15372      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:23:11,302][train][INFO][train.py>_log] ==> #791000     Total Loss: 2.929    [weighted Loss:2.929    Policy Loss: 10.752   Value Loss: 4.138    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 2096096    Buffer Size: 15356      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:26:21,033][train][INFO][train.py>_log] ==> #792000     Total Loss: 2.997    [weighted Loss:2.997    Policy Loss: 10.567   Value Loss: 4.208    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 2098549    Buffer Size: 15334      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:29:37,566][train][INFO][train.py>_log] ==> #793000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 10.236   Value Loss: 4.290    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 2101020    Buffer Size: 15317      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:32:51,968][train][INFO][train.py>_log] ==> #794000     Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 10.730   Value Loss: 4.507    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 2103444    Buffer Size: 15310      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:36:08,534][train][INFO][train.py>_log] ==> #795000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 10.957   Value Loss: 4.427    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2106009    Buffer Size: 15283      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:39:29,728][train][INFO][train.py>_log] ==> #796000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 10.182   Value Loss: 4.451    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2108525    Buffer Size: 15281      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:42:47,690][train][INFO][train.py>_log] ==> #797000     Total Loss: 4.096    [weighted Loss:4.096    Policy Loss: 10.525   Value Loss: 4.241    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2111003    Buffer Size: 15281      Transition Number: 1000.231k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:46:05,658][train][INFO][train.py>_log] ==> #798000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 10.793   Value Loss: 4.177    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2113455    Buffer Size: 15264      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:49:23,575][train][INFO][train.py>_log] ==> #799000     Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 10.325   Value Loss: 4.547    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 2116049    Buffer Size: 15226      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:52:46,289][train][INFO][train.py>_log] ==> #800000     Total Loss: 3.017    [weighted Loss:3.017    Policy Loss: 10.669   Value Loss: 4.356    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 2118535    Buffer Size: 15212      Transition Number: 1000.340k Batch Size: 256        Lr: 0.00080 
[2022-02-26 20:56:04,658][train][INFO][train.py>_log] ==> #801000     Total Loss: 3.734    [weighted Loss:3.734    Policy Loss: 10.696   Value Loss: 4.357    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 2121099    Buffer Size: 15192      Transition Number: 1000.445k Batch Size: 256        Lr: 0.00016 
[2022-02-26 20:59:22,851][train][INFO][train.py>_log] ==> #802000     Total Loss: 2.440    [weighted Loss:2.440    Policy Loss: 10.215   Value Loss: 4.138    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 2123637    Buffer Size: 15151      Transition Number: 1000.233k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:02:38,318][train][INFO][train.py>_log] ==> #803000     Total Loss: 1.881    [weighted Loss:1.881    Policy Loss: 10.336   Value Loss: 4.436    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2125997    Buffer Size: 15132      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:05:54,273][train][INFO][train.py>_log] ==> #804000     Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 10.468   Value Loss: 4.235    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2128402    Buffer Size: 15117      Transition Number: 1000.251k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:09:13,500][train][INFO][train.py>_log] ==> #805000     Total Loss: 0.829    [weighted Loss:0.829    Policy Loss: 10.317   Value Loss: 4.452    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2131019    Buffer Size: 15108      Transition Number: 1000.095k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:12:32,054][train][INFO][train.py>_log] ==> #806000     Total Loss: 3.602    [weighted Loss:3.602    Policy Loss: 10.391   Value Loss: 4.197    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2133540    Buffer Size: 15081      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:15:47,160][train][INFO][train.py>_log] ==> #807000     Total Loss: 2.719    [weighted Loss:2.719    Policy Loss: 9.980    Value Loss: 4.581    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 2135898    Buffer Size: 15088      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:19:02,501][train][INFO][train.py>_log] ==> #808000     Total Loss: 3.175    [weighted Loss:3.175    Policy Loss: 9.880    Value Loss: 4.243    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2138450    Buffer Size: 15080      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:22:12,439][train][INFO][train.py>_log] ==> #809000     Total Loss: 2.513    [weighted Loss:2.513    Policy Loss: 10.261   Value Loss: 4.218    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 2140803    Buffer Size: 15057      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:25:31,760][train][INFO][train.py>_log] ==> #810000     Total Loss: 1.082    [weighted Loss:1.082    Policy Loss: 10.272   Value Loss: 4.359    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2143319    Buffer Size: 15056      Transition Number: 1000.231k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:28:50,982][train][INFO][train.py>_log] ==> #811000     Total Loss: 4.349    [weighted Loss:4.349    Policy Loss: 10.038   Value Loss: 4.263    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2145828    Buffer Size: 15051      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:32:07,138][train][INFO][train.py>_log] ==> #812000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 10.436   Value Loss: 4.401    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 2148274    Buffer Size: 15048      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:35:24,576][train][INFO][train.py>_log] ==> #813000     Total Loss: 3.447    [weighted Loss:3.447    Policy Loss: 10.397   Value Loss: 4.204    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2150786    Buffer Size: 15043      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:38:39,457][train][INFO][train.py>_log] ==> #814000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 10.104   Value Loss: 4.408    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2153207    Buffer Size: 15028      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:41:53,422][train][INFO][train.py>_log] ==> #815000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 9.840    Value Loss: 4.518    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2155706    Buffer Size: 15051      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:45:10,812][train][INFO][train.py>_log] ==> #816000     Total Loss: 2.733    [weighted Loss:2.733    Policy Loss: 9.904    Value Loss: 4.019    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2158166    Buffer Size: 15052      Transition Number: 1000.236k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:48:25,932][train][INFO][train.py>_log] ==> #817000     Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 10.184   Value Loss: 4.307    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2160665    Buffer Size: 15054      Transition Number: 1000.300k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:51:41,096][train][INFO][train.py>_log] ==> #818000     Total Loss: 2.316    [weighted Loss:2.316    Policy Loss: 10.079   Value Loss: 4.151    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 2163036    Buffer Size: 15055      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:54:57,378][train][INFO][train.py>_log] ==> #819000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 9.908    Value Loss: 4.368    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2165557    Buffer Size: 15076      Transition Number: 1000.546k Batch Size: 256        Lr: 0.00016 
[2022-02-26 21:58:16,365][train][INFO][train.py>_log] ==> #820000     Total Loss: 3.216    [weighted Loss:3.216    Policy Loss: 9.815    Value Loss: 4.224    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 2168046    Buffer Size: 15071      Transition Number: 1000.369k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:01:33,019][train][INFO][train.py>_log] ==> #821000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 9.883    Value Loss: 4.041    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 2170583    Buffer Size: 15077      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:04:49,642][train][INFO][train.py>_log] ==> #822000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 9.941    Value Loss: 4.293    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 2173000    Buffer Size: 15092      Transition Number: 1000.357k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:08:06,138][train][INFO][train.py>_log] ==> #823000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 10.069   Value Loss: 4.595    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 2175525    Buffer Size: 15093      Transition Number: 1000.335k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:11:23,266][train][INFO][train.py>_log] ==> #824000     Total Loss: 3.377    [weighted Loss:3.377    Policy Loss: 10.208   Value Loss: 4.675    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 2177993    Buffer Size: 15097      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:14:40,178][train][INFO][train.py>_log] ==> #825000     Total Loss: 3.114    [weighted Loss:3.114    Policy Loss: 9.860    Value Loss: 4.281    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2180512    Buffer Size: 15112      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:17:58,401][train][INFO][train.py>_log] ==> #826000     Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 9.773    Value Loss: 4.497    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 2183050    Buffer Size: 15134      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:21:15,135][train][INFO][train.py>_log] ==> #827000     Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 9.625    Value Loss: 4.120    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 2185454    Buffer Size: 15140      Transition Number: 1000.150k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:24:32,143][train][INFO][train.py>_log] ==> #828000     Total Loss: 3.379    [weighted Loss:3.379    Policy Loss: 9.981    Value Loss: 4.224    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 2188001    Buffer Size: 15169      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:27:52,876][train][INFO][train.py>_log] ==> #829000     Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 9.749    Value Loss: 4.218    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 2190484    Buffer Size: 15176      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:31:12,447][train][INFO][train.py>_log] ==> #830000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 10.336   Value Loss: 4.195    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2193031    Buffer Size: 15195      Transition Number: 1000.262k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:34:29,229][train][INFO][train.py>_log] ==> #831000     Total Loss: 2.886    [weighted Loss:2.886    Policy Loss: 9.689    Value Loss: 4.330    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 2195520    Buffer Size: 15202      Transition Number: 1000.358k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:37:46,806][train][INFO][train.py>_log] ==> #832000     Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 9.880    Value Loss: 4.183    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2198007    Buffer Size: 15207      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:41:05,054][train][INFO][train.py>_log] ==> #833000     Total Loss: 3.533    [weighted Loss:3.533    Policy Loss: 10.105   Value Loss: 4.445    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2200466    Buffer Size: 15227      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:44:27,677][train][INFO][train.py>_log] ==> #834000     Total Loss: 2.175    [weighted Loss:2.175    Policy Loss: 9.956    Value Loss: 4.120    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2203100    Buffer Size: 15198      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:47:46,520][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 10.242   Value Loss: 4.040    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 2205570    Buffer Size: 15213      Transition Number: 1000.073k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:51:06,349][train][INFO][train.py>_log] ==> #836000     Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 10.004   Value Loss: 4.477    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2208179    Buffer Size: 15218      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:54:21,970][train][INFO][train.py>_log] ==> #837000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 9.909    Value Loss: 4.416    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2210598    Buffer Size: 15227      Transition Number: 1000.153k Batch Size: 256        Lr: 0.00016 
[2022-02-26 22:57:39,483][train][INFO][train.py>_log] ==> #838000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 9.883    Value Loss: 4.231    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 2213097    Buffer Size: 15238      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:00:59,116][train][INFO][train.py>_log] ==> #839000     Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 9.966    Value Loss: 4.015    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2215680    Buffer Size: 15249      Transition Number: 1000.282k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:04:18,619][train][INFO][train.py>_log] ==> #840000     Total Loss: 3.209    [weighted Loss:3.209    Policy Loss: 10.414   Value Loss: 4.073    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2218221    Buffer Size: 15288      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:07:35,983][train][INFO][train.py>_log] ==> #841000     Total Loss: 2.485    [weighted Loss:2.485    Policy Loss: 10.543   Value Loss: 4.293    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2220721    Buffer Size: 15328      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:10:51,563][train][INFO][train.py>_log] ==> #842000     Total Loss: 2.058    [weighted Loss:2.058    Policy Loss: 10.110   Value Loss: 4.164    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 2223133    Buffer Size: 15337      Transition Number: 1000.096k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:14:12,103][train][INFO][train.py>_log] ==> #843000     Total Loss: 1.409    [weighted Loss:1.409    Policy Loss: 10.357   Value Loss: 4.326    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2225791    Buffer Size: 15362      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:17:30,016][train][INFO][train.py>_log] ==> #844000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 9.960    Value Loss: 4.359    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 2228261    Buffer Size: 15386      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:20:44,508][train][INFO][train.py>_log] ==> #845000     Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 10.469   Value Loss: 4.063    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2230717    Buffer Size: 15411      Transition Number: 1000.289k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:24:02,328][train][INFO][train.py>_log] ==> #846000     Total Loss: 2.838    [weighted Loss:2.838    Policy Loss: 10.667   Value Loss: 4.655    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2233240    Buffer Size: 15440      Transition Number: 1000.397k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:27:23,577][train][INFO][train.py>_log] ==> #847000     Total Loss: 1.211    [weighted Loss:1.211    Policy Loss: 10.283   Value Loss: 4.198    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 2235830    Buffer Size: 15442      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:30:42,688][train][INFO][train.py>_log] ==> #848000     Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 10.631   Value Loss: 4.671    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 2238293    Buffer Size: 15491      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:33:59,212][train][INFO][train.py>_log] ==> #849000     Total Loss: 2.903    [weighted Loss:2.903    Policy Loss: 10.037   Value Loss: 4.159    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2240914    Buffer Size: 15525      Transition Number: 1000.651k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:37:19,125][train][INFO][train.py>_log] ==> #850000     Total Loss: 2.918    [weighted Loss:2.918    Policy Loss: 10.482   Value Loss: 4.397    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 2243453    Buffer Size: 15555      Transition Number: 1000.275k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:40:33,780][train][INFO][train.py>_log] ==> #851000     Total Loss: 1.712    [weighted Loss:1.712    Policy Loss: 10.520   Value Loss: 4.268    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 2245872    Buffer Size: 15593      Transition Number: 1000.586k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:43:52,835][train][INFO][train.py>_log] ==> #852000     Total Loss: 3.395    [weighted Loss:3.395    Policy Loss: 10.474   Value Loss: 4.196    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2248389    Buffer Size: 15597      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:47:12,495][train][INFO][train.py>_log] ==> #853000     Total Loss: 2.034    [weighted Loss:2.034    Policy Loss: 10.652   Value Loss: 4.256    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2251017    Buffer Size: 15629      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:50:30,961][train][INFO][train.py>_log] ==> #854000     Total Loss: 3.853    [weighted Loss:3.853    Policy Loss: 10.646   Value Loss: 4.409    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2253520    Buffer Size: 15654      Transition Number: 1000.281k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:53:48,380][train][INFO][train.py>_log] ==> #855000     Total Loss: 3.695    [weighted Loss:3.695    Policy Loss: 10.687   Value Loss: 4.405    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2256089    Buffer Size: 15703      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00016 
[2022-02-26 23:57:11,486][train][INFO][train.py>_log] ==> #856000     Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 10.337   Value Loss: 4.252    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2258657    Buffer Size: 15736      Transition Number: 1000.489k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:00:30,381][train][INFO][train.py>_log] ==> #857000     Total Loss: 2.496    [weighted Loss:2.496    Policy Loss: 10.563   Value Loss: 4.353    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2261273    Buffer Size: 15782      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:03:47,095][train][INFO][train.py>_log] ==> #858000     Total Loss: 3.663    [weighted Loss:3.663    Policy Loss: 10.306   Value Loss: 4.541    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 2263773    Buffer Size: 15830      Transition Number: 1000.516k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:07:06,827][train][INFO][train.py>_log] ==> #859000     Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 10.233   Value Loss: 4.424    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 2266331    Buffer Size: 15876      Transition Number: 1000.458k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:10:28,577][train][INFO][train.py>_log] ==> #860000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 10.692   Value Loss: 4.508    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 2268896    Buffer Size: 15926      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:13:48,902][train][INFO][train.py>_log] ==> #861000     Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 10.482   Value Loss: 4.219    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 2271536    Buffer Size: 15957      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:17:05,299][train][INFO][train.py>_log] ==> #862000     Total Loss: 2.522    [weighted Loss:2.522    Policy Loss: 10.841   Value Loss: 4.571    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2274089    Buffer Size: 16005      Transition Number: 1000.121k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:20:25,608][train][INFO][train.py>_log] ==> #863000     Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 10.659   Value Loss: 4.488    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2276641    Buffer Size: 16034      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:23:39,075][train][INFO][train.py>_log] ==> #864000     Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 10.596   Value Loss: 4.853    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2279143    Buffer Size: 16063      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:26:59,462][train][INFO][train.py>_log] ==> #865000     Total Loss: 3.205    [weighted Loss:3.205    Policy Loss: 10.680   Value Loss: 4.509    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2281715    Buffer Size: 16074      Transition Number: 1000.193k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:30:16,296][train][INFO][train.py>_log] ==> #866000     Total Loss: 3.625    [weighted Loss:3.625    Policy Loss: 10.665   Value Loss: 4.660    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 2284265    Buffer Size: 16104      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:33:38,790][train][INFO][train.py>_log] ==> #867000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 10.548   Value Loss: 4.328    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 2286797    Buffer Size: 16117      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:36:53,353][train][INFO][train.py>_log] ==> #868000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 11.149   Value Loss: 4.676    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2289285    Buffer Size: 16120      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:40:12,185][train][INFO][train.py>_log] ==> #869000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 10.660   Value Loss: 4.371    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 2291931    Buffer Size: 16110      Transition Number: 1000.609k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:43:30,896][train][INFO][train.py>_log] ==> #870000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 10.868   Value Loss: 4.859    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 2294504    Buffer Size: 16084      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:46:46,668][train][INFO][train.py>_log] ==> #871000     Total Loss: 1.811    [weighted Loss:1.811    Policy Loss: 10.559   Value Loss: 4.679    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 2296946    Buffer Size: 16099      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:50:05,302][train][INFO][train.py>_log] ==> #872000     Total Loss: 2.744    [weighted Loss:2.744    Policy Loss: 10.681   Value Loss: 4.549    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 2299553    Buffer Size: 16077      Transition Number: 1000.202k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:53:19,076][train][INFO][train.py>_log] ==> #873000     Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 10.557   Value Loss: 4.610    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 2302032    Buffer Size: 16066      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:56:37,958][train][INFO][train.py>_log] ==> #874000     Total Loss: 1.226    [weighted Loss:1.226    Policy Loss: 10.514   Value Loss: 4.460    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 2304440    Buffer Size: 16043      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00016 
[2022-02-27 00:59:52,443][train][INFO][train.py>_log] ==> #875000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 10.485   Value Loss: 4.562    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 2306987    Buffer Size: 16014      Transition Number: 1000.275k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:03:11,798][train][INFO][train.py>_log] ==> #876000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 10.467   Value Loss: 4.647    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2309679    Buffer Size: 15970      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:06:25,479][train][INFO][train.py>_log] ==> #877000     Total Loss: 3.625    [weighted Loss:3.625    Policy Loss: 10.084   Value Loss: 4.381    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 2312076    Buffer Size: 15941      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:09:42,658][train][INFO][train.py>_log] ==> #878000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 10.558   Value Loss: 4.815    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 2314626    Buffer Size: 15926      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:12:56,000][train][INFO][train.py>_log] ==> #879000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 10.491   Value Loss: 4.344    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 2317127    Buffer Size: 15910      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:16:15,464][train][INFO][train.py>_log] ==> #880000     Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 10.586   Value Loss: 4.381    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 2319630    Buffer Size: 15910      Transition Number: 1000.682k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:19:36,496][train][INFO][train.py>_log] ==> #881000     Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 9.902    Value Loss: 4.201    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 2322148    Buffer Size: 15913      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:22:55,983][train][INFO][train.py>_log] ==> #882000     Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 10.512   Value Loss: 4.502    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 2324780    Buffer Size: 15916      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:26:11,554][train][INFO][train.py>_log] ==> #883000     Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 10.220   Value Loss: 4.307    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 2327316    Buffer Size: 15914      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:29:33,407][train][INFO][train.py>_log] ==> #884000     Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 10.623   Value Loss: 4.147    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 2329916    Buffer Size: 15924      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:32:50,307][train][INFO][train.py>_log] ==> #885000     Total Loss: 3.350    [weighted Loss:3.350    Policy Loss: 10.573   Value Loss: 4.343    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 2332416    Buffer Size: 15925      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:36:06,537][train][INFO][train.py>_log] ==> #886000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 10.296   Value Loss: 4.089    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2334944    Buffer Size: 15917      Transition Number: 1000.345k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:39:19,841][train][INFO][train.py>_log] ==> #887000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 10.195   Value Loss: 4.198    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 2337405    Buffer Size: 15908      Transition Number: 1000.308k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:42:43,454][train][INFO][train.py>_log] ==> #888000     Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 10.493   Value Loss: 4.626    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 2339956    Buffer Size: 15891      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:46:01,471][train][INFO][train.py>_log] ==> #889000     Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 10.793   Value Loss: 4.365    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2342521    Buffer Size: 15905      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:49:19,536][train][INFO][train.py>_log] ==> #890000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 10.407   Value Loss: 4.385    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 2345141    Buffer Size: 15893      Transition Number: 1000.251k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:52:39,912][train][INFO][train.py>_log] ==> #891000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 10.288   Value Loss: 4.437    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 2347746    Buffer Size: 15902      Transition Number: 1000.461k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:55:58,124][train][INFO][train.py>_log] ==> #892000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 10.709   Value Loss: 4.528    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 2350209    Buffer Size: 15915      Transition Number: 1000.217k Batch Size: 256        Lr: 0.00016 
[2022-02-27 01:59:13,167][train][INFO][train.py>_log] ==> #893000     Total Loss: 3.335    [weighted Loss:3.335    Policy Loss: 10.115   Value Loss: 4.337    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2352808    Buffer Size: 15905      Transition Number: 1000.248k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:02:30,898][train][INFO][train.py>_log] ==> #894000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 10.912   Value Loss: 4.239    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 2355286    Buffer Size: 15913      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:05:48,265][train][INFO][train.py>_log] ==> #895000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 10.544   Value Loss: 4.483    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 2357810    Buffer Size: 15914      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:09:07,450][train][INFO][train.py>_log] ==> #896000     Total Loss: 3.123    [weighted Loss:3.123    Policy Loss: 10.216   Value Loss: 4.257    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 2360341    Buffer Size: 15907      Transition Number: 1000.247k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:12:28,893][train][INFO][train.py>_log] ==> #897000     Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 10.591   Value Loss: 4.362    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2362917    Buffer Size: 15907      Transition Number: 1000.196k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:15:49,279][train][INFO][train.py>_log] ==> #898000     Total Loss: 3.707    [weighted Loss:3.707    Policy Loss: 10.167   Value Loss: 4.186    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2365517    Buffer Size: 15901      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:19:11,748][train][INFO][train.py>_log] ==> #899000     Total Loss: 2.896    [weighted Loss:2.896    Policy Loss: 10.162   Value Loss: 4.160    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 2368079    Buffer Size: 15912      Transition Number: 1000.211k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:22:27,989][train][INFO][train.py>_log] ==> #900000     Total Loss: 2.800    [weighted Loss:2.800    Policy Loss: 10.419   Value Loss: 4.223    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2370685    Buffer Size: 15909      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:25:57,687][train][INFO][train.py>_log] ==> #901000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 10.715   Value Loss: 4.193    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 2373322    Buffer Size: 15882      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:29:21,411][train][INFO][train.py>_log] ==> #902000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 10.745   Value Loss: 4.420    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 2375928    Buffer Size: 15890      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:32:40,728][train][INFO][train.py>_log] ==> #903000     Total Loss: 3.894    [weighted Loss:3.894    Policy Loss: 11.048   Value Loss: 4.542    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 2378568    Buffer Size: 15884      Transition Number: 1000.274k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:36:00,640][train][INFO][train.py>_log] ==> #904000     Total Loss: 1.629    [weighted Loss:1.629    Policy Loss: 10.962   Value Loss: 4.447    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 2381106    Buffer Size: 15858      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:39:25,776][train][INFO][train.py>_log] ==> #905000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 10.790   Value Loss: 4.163    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 2383733    Buffer Size: 15835      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:42:42,495][train][INFO][train.py>_log] ==> #906000     Total Loss: 3.291    [weighted Loss:3.291    Policy Loss: 10.868   Value Loss: 4.387    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 2386235    Buffer Size: 15813      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:46:03,768][train][INFO][train.py>_log] ==> #907000     Total Loss: 3.746    [weighted Loss:3.746    Policy Loss: 10.966   Value Loss: 4.446    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2388728    Buffer Size: 15817      Transition Number: 1000.346k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:49:25,019][train][INFO][train.py>_log] ==> #908000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 10.912   Value Loss: 4.340    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2391395    Buffer Size: 15799      Transition Number: 1000.193k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:52:43,298][train][INFO][train.py>_log] ==> #909000     Total Loss: 1.537    [weighted Loss:1.537    Policy Loss: 10.800   Value Loss: 4.347    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 2393950    Buffer Size: 15780      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:56:01,111][train][INFO][train.py>_log] ==> #910000     Total Loss: 3.370    [weighted Loss:3.370    Policy Loss: 10.827   Value Loss: 4.271    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2396484    Buffer Size: 15784      Transition Number: 1000.210k Batch Size: 256        Lr: 0.00016 
[2022-02-27 02:59:25,376][train][INFO][train.py>_log] ==> #911000     Total Loss: 3.563    [weighted Loss:3.563    Policy Loss: 10.820   Value Loss: 4.491    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 2399155    Buffer Size: 15796      Transition Number: 1000.215k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:02:43,752][train][INFO][train.py>_log] ==> #912000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 10.737   Value Loss: 4.568    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2401621    Buffer Size: 15791      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:06:04,987][train][INFO][train.py>_log] ==> #913000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 10.566   Value Loss: 4.270    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2404116    Buffer Size: 15796      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:09:23,919][train][INFO][train.py>_log] ==> #914000     Total Loss: 3.157    [weighted Loss:3.157    Policy Loss: 10.975   Value Loss: 4.509    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2406675    Buffer Size: 15791      Transition Number: 1000.619k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:12:43,020][train][INFO][train.py>_log] ==> #915000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 10.753   Value Loss: 4.214    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 2409255    Buffer Size: 15785      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:15:58,476][train][INFO][train.py>_log] ==> #916000     Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 10.619   Value Loss: 4.316    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 2411757    Buffer Size: 15781      Transition Number: 1000.427k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:19:18,394][train][INFO][train.py>_log] ==> #917000     Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 10.854   Value Loss: 4.349    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2414364    Buffer Size: 15755      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:22:34,090][train][INFO][train.py>_log] ==> #918000     Total Loss: 3.047    [weighted Loss:3.047    Policy Loss: 10.776   Value Loss: 4.281    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2416798    Buffer Size: 15751      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:25:56,922][train][INFO][train.py>_log] ==> #919000     Total Loss: 3.087    [weighted Loss:3.087    Policy Loss: 11.082   Value Loss: 4.327    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 2419350    Buffer Size: 15757      Transition Number: 1000.276k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:29:20,694][train][INFO][train.py>_log] ==> #920000     Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 11.185   Value Loss: 4.234    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2421955    Buffer Size: 15761      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:32:40,997][train][INFO][train.py>_log] ==> #921000     Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 10.877   Value Loss: 4.221    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 2424556    Buffer Size: 15748      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:36:03,923][train][INFO][train.py>_log] ==> #922000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 10.984   Value Loss: 4.373    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2427175    Buffer Size: 15750      Transition Number: 1000.399k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:39:24,812][train][INFO][train.py>_log] ==> #923000     Total Loss: 3.082    [weighted Loss:3.082    Policy Loss: 11.028   Value Loss: 4.714    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 2429702    Buffer Size: 15735      Transition Number: 1000.326k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:42:46,914][train][INFO][train.py>_log] ==> #924000     Total Loss: 2.507    [weighted Loss:2.507    Policy Loss: 10.546   Value Loss: 4.440    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 2432330    Buffer Size: 15740      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:46:09,779][train][INFO][train.py>_log] ==> #925000     Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 10.833   Value Loss: 4.328    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2434864    Buffer Size: 15740      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:49:27,230][train][INFO][train.py>_log] ==> #926000     Total Loss: 2.226    [weighted Loss:2.226    Policy Loss: 11.040   Value Loss: 4.494    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2437386    Buffer Size: 15729      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:52:46,875][train][INFO][train.py>_log] ==> #927000     Total Loss: 3.811    [weighted Loss:3.811    Policy Loss: 10.775   Value Loss: 4.007    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2439994    Buffer Size: 15714      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:56:03,848][train][INFO][train.py>_log] ==> #928000     Total Loss: 3.133    [weighted Loss:3.133    Policy Loss: 10.695   Value Loss: 4.115    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 2442502    Buffer Size: 15728      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00016 
[2022-02-27 03:59:19,608][train][INFO][train.py>_log] ==> #929000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 10.625   Value Loss: 4.195    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 2444974    Buffer Size: 15730      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:02:42,882][train][INFO][train.py>_log] ==> #930000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 11.354   Value Loss: 4.351    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 2447561    Buffer Size: 15752      Transition Number: 1000.403k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:06:03,752][train][INFO][train.py>_log] ==> #931000     Total Loss: 3.162    [weighted Loss:3.162    Policy Loss: 11.381   Value Loss: 4.446    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 2450077    Buffer Size: 15759      Transition Number: 1000.441k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:09:26,878][train][INFO][train.py>_log] ==> #932000     Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 10.749   Value Loss: 4.124    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 2452656    Buffer Size: 15752      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:12:49,758][train][INFO][train.py>_log] ==> #933000     Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 10.801   Value Loss: 4.308    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 2455362    Buffer Size: 15731      Transition Number: 1000.202k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:16:10,543][train][INFO][train.py>_log] ==> #934000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 10.938   Value Loss: 4.398    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2457905    Buffer Size: 15738      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:19:31,686][train][INFO][train.py>_log] ==> #935000     Total Loss: 2.660    [weighted Loss:2.660    Policy Loss: 11.031   Value Loss: 4.312    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 2460454    Buffer Size: 15728      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:22:55,436][train][INFO][train.py>_log] ==> #936000     Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 11.167   Value Loss: 4.282    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2463065    Buffer Size: 15707      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:26:17,163][train][INFO][train.py>_log] ==> #937000     Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 10.870   Value Loss: 4.023    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 2465628    Buffer Size: 15698      Transition Number: 1000.165k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:29:42,423][train][INFO][train.py>_log] ==> #938000     Total Loss: 2.890    [weighted Loss:2.890    Policy Loss: 11.283   Value Loss: 4.261    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2468214    Buffer Size: 15672      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:33:05,335][train][INFO][train.py>_log] ==> #939000     Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 10.968   Value Loss: 4.313    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 2470846    Buffer Size: 15680      Transition Number: 1000.608k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:36:31,323][train][INFO][train.py>_log] ==> #940000     Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 10.632   Value Loss: 4.201    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2473356    Buffer Size: 15661      Transition Number: 1000.316k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:39:57,588][train][INFO][train.py>_log] ==> #941000     Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 11.225   Value Loss: 4.229    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2476029    Buffer Size: 15646      Transition Number: 1000.323k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:43:23,748][train][INFO][train.py>_log] ==> #942000     Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 10.863   Value Loss: 4.260    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2478717    Buffer Size: 15624      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:46:43,811][train][INFO][train.py>_log] ==> #943000     Total Loss: 3.537    [weighted Loss:3.537    Policy Loss: 10.833   Value Loss: 4.550    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 2481196    Buffer Size: 15617      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:50:09,114][train][INFO][train.py>_log] ==> #944000     Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 10.886   Value Loss: 4.341    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 2483856    Buffer Size: 15622      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:53:32,781][train][INFO][train.py>_log] ==> #945000     Total Loss: 1.070    [weighted Loss:1.070    Policy Loss: 10.895   Value Loss: 4.313    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 2486485    Buffer Size: 15616      Transition Number: 1000.116k Batch Size: 256        Lr: 0.00016 
[2022-02-27 04:57:00,183][train][INFO][train.py>_log] ==> #946000     Total Loss: 2.038    [weighted Loss:2.038    Policy Loss: 10.893   Value Loss: 4.202    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 2488982    Buffer Size: 15611      Transition Number: 1000.670k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:00:27,055][train][INFO][train.py>_log] ==> #947000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 10.708   Value Loss: 4.134    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2491692    Buffer Size: 15590      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:03:53,828][train][INFO][train.py>_log] ==> #948000     Total Loss: 2.458    [weighted Loss:2.458    Policy Loss: 10.643   Value Loss: 4.496    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2494298    Buffer Size: 15582      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:07:24,268][train][INFO][train.py>_log] ==> #949000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 11.382   Value Loss: 4.598    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 2496968    Buffer Size: 15572      Transition Number: 1000.414k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:10:52,238][train][INFO][train.py>_log] ==> #950000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 10.947   Value Loss: 4.401    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 2499654    Buffer Size: 15555      Transition Number: 1000.242k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:14:17,770][train][INFO][train.py>_log] ==> #951000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 10.802   Value Loss: 4.147    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 2502268    Buffer Size: 15528      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:17:47,229][train][INFO][train.py>_log] ==> #952000     Total Loss: 4.010    [weighted Loss:4.010    Policy Loss: 11.136   Value Loss: 4.347    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2504945    Buffer Size: 15511      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:21:13,865][train][INFO][train.py>_log] ==> #953000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 11.115   Value Loss: 4.277    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2507590    Buffer Size: 15494      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:24:43,969][train][INFO][train.py>_log] ==> #954000     Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 10.895   Value Loss: 4.431    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2510259    Buffer Size: 15474      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:28:11,312][train][INFO][train.py>_log] ==> #955000     Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 10.904   Value Loss: 4.185    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 2512913    Buffer Size: 15465      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:31:37,733][train][INFO][train.py>_log] ==> #956000     Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 11.028   Value Loss: 4.407    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 2515504    Buffer Size: 15443      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:35:07,361][train][INFO][train.py>_log] ==> #957000     Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 10.727   Value Loss: 4.226    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2518278    Buffer Size: 15418      Transition Number: 1000.142k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:38:34,810][train][INFO][train.py>_log] ==> #958000     Total Loss: 2.758    [weighted Loss:2.758    Policy Loss: 10.959   Value Loss: 4.126    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2520822    Buffer Size: 15412      Transition Number: 1000.298k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:42:04,442][train][INFO][train.py>_log] ==> #959000     Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 10.906   Value Loss: 4.306    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2523574    Buffer Size: 15396      Transition Number: 1000.260k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:45:27,737][train][INFO][train.py>_log] ==> #960000     Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 10.850   Value Loss: 4.076    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2526135    Buffer Size: 15386      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:48:51,743][train][INFO][train.py>_log] ==> #961000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 11.120   Value Loss: 4.406    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2528686    Buffer Size: 15390      Transition Number: 1000.879k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:52:17,303][train][INFO][train.py>_log] ==> #962000     Total Loss: 3.337    [weighted Loss:3.337    Policy Loss: 10.915   Value Loss: 4.398    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2531383    Buffer Size: 15353      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:55:40,774][train][INFO][train.py>_log] ==> #963000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 10.552   Value Loss: 4.462    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 2533856    Buffer Size: 15346      Transition Number: 1000.648k Batch Size: 256        Lr: 0.00016 
[2022-02-27 05:59:09,200][train][INFO][train.py>_log] ==> #964000     Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 11.043   Value Loss: 3.900    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 2536546    Buffer Size: 15333      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:02:39,777][train][INFO][train.py>_log] ==> #965000     Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 10.672   Value Loss: 4.491    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 2539228    Buffer Size: 15325      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:06:07,122][train][INFO][train.py>_log] ==> #966000     Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 10.805   Value Loss: 3.964    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 2541892    Buffer Size: 15308      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:09:38,452][train][INFO][train.py>_log] ==> #967000     Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 10.701   Value Loss: 4.056    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2544524    Buffer Size: 15289      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:13:01,547][train][INFO][train.py>_log] ==> #968000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 10.521   Value Loss: 4.182    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 2547106    Buffer Size: 15284      Transition Number: 1000.260k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:16:28,964][train][INFO][train.py>_log] ==> #969000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 10.582   Value Loss: 4.426    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2549837    Buffer Size: 15269      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:19:57,665][train][INFO][train.py>_log] ==> #970000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 10.817   Value Loss: 4.395    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2552424    Buffer Size: 15245      Transition Number: 1000.215k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:23:31,329][train][INFO][train.py>_log] ==> #971000     Total Loss: 1.789    [weighted Loss:1.789    Policy Loss: 10.721   Value Loss: 3.995    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2555228    Buffer Size: 15228      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:26:57,089][train][INFO][train.py>_log] ==> #972000     Total Loss: 2.527    [weighted Loss:2.527    Policy Loss: 10.817   Value Loss: 4.317    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2557740    Buffer Size: 15214      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:30:22,819][train][INFO][train.py>_log] ==> #973000     Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 10.987   Value Loss: 4.342    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 2560347    Buffer Size: 15219      Transition Number: 1000.473k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:33:49,537][train][INFO][train.py>_log] ==> #974000     Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 10.553   Value Loss: 4.253    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 2563066    Buffer Size: 15186      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:37:16,865][train][INFO][train.py>_log] ==> #975000     Total Loss: 2.549    [weighted Loss:2.549    Policy Loss: 10.471   Value Loss: 4.320    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2565713    Buffer Size: 15170      Transition Number: 1000.384k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:40:43,518][train][INFO][train.py>_log] ==> #976000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 10.441   Value Loss: 4.296    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 2568348    Buffer Size: 15147      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:44:08,795][train][INFO][train.py>_log] ==> #977000     Total Loss: 1.966    [weighted Loss:1.966    Policy Loss: 10.825   Value Loss: 3.930    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 2570871    Buffer Size: 15130      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:47:37,803][train][INFO][train.py>_log] ==> #978000     Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 10.472   Value Loss: 3.863    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 2573603    Buffer Size: 15128      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:51:04,695][train][INFO][train.py>_log] ==> #979000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 10.316   Value Loss: 4.057    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 2576206    Buffer Size: 15111      Transition Number: 1000.263k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:54:27,324][train][INFO][train.py>_log] ==> #980000     Total Loss: 3.493    [weighted Loss:3.493    Policy Loss: 10.728   Value Loss: 4.205    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2578779    Buffer Size: 15092      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00016 
[2022-02-27 06:57:56,866][train][INFO][train.py>_log] ==> #981000     Total Loss: 3.128    [weighted Loss:3.128    Policy Loss: 10.230   Value Loss: 4.406    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 2581461    Buffer Size: 15088      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:01:25,596][train][INFO][train.py>_log] ==> #982000     Total Loss: 3.196    [weighted Loss:3.196    Policy Loss: 10.531   Value Loss: 4.370    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 2584125    Buffer Size: 15089      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:04:56,507][train][INFO][train.py>_log] ==> #983000     Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 10.541   Value Loss: 4.117    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 2586722    Buffer Size: 15092      Transition Number: 1000.275k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:08:26,462][train][INFO][train.py>_log] ==> #984000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 10.653   Value Loss: 4.468    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 2589445    Buffer Size: 15083      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:11:51,990][train][INFO][train.py>_log] ==> #985000     Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 10.151   Value Loss: 4.391    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 2592050    Buffer Size: 15083      Transition Number: 1000.130k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:15:20,145][train][INFO][train.py>_log] ==> #986000     Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 10.481   Value Loss: 3.946    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 2594672    Buffer Size: 15064      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:18:45,213][train][INFO][train.py>_log] ==> #987000     Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 10.358   Value Loss: 4.136    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 2597291    Buffer Size: 15071      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:22:14,810][train][INFO][train.py>_log] ==> #988000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 9.989    Value Loss: 4.145    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2599866    Buffer Size: 15093      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:25:43,918][train][INFO][train.py>_log] ==> #989000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 10.312   Value Loss: 4.064    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2602635    Buffer Size: 15109      Transition Number: 1000.213k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:29:11,423][train][INFO][train.py>_log] ==> #990000     Total Loss: 1.024    [weighted Loss:1.024    Policy Loss: 10.604   Value Loss: 4.243    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 2605192    Buffer Size: 15130      Transition Number: 1000.870k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:32:34,861][train][INFO][train.py>_log] ==> #991000     Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 10.540   Value Loss: 4.167    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 2607867    Buffer Size: 15135      Transition Number: 1000.138k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:36:12,445][train][INFO][train.py>_log] ==> #992000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 10.559   Value Loss: 4.645    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2610601    Buffer Size: 15145      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:39:41,470][train][INFO][train.py>_log] ==> #993000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 10.356   Value Loss: 4.052    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 2613185    Buffer Size: 15151      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:43:10,385][train][INFO][train.py>_log] ==> #994000     Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 10.152   Value Loss: 4.018    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2615850    Buffer Size: 15137      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:46:34,545][train][INFO][train.py>_log] ==> #995000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 10.326   Value Loss: 4.211    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 2618481    Buffer Size: 15154      Transition Number: 1000.197k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:49:58,317][train][INFO][train.py>_log] ==> #996000     Total Loss: 3.965    [weighted Loss:3.965    Policy Loss: 10.569   Value Loss: 3.918    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2621059    Buffer Size: 15165      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:53:30,633][train][INFO][train.py>_log] ==> #997000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 10.334   Value Loss: 4.091    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 2623746    Buffer Size: 15181      Transition Number: 1000.253k Batch Size: 256        Lr: 0.00016 
[2022-02-27 07:57:00,050][train][INFO][train.py>_log] ==> #998000     Total Loss: 2.386    [weighted Loss:2.386    Policy Loss: 10.647   Value Loss: 4.345    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 2626415    Buffer Size: 15194      Transition Number: 1000.312k Batch Size: 256        Lr: 0.00016 
[2022-02-27 08:00:29,204][train][INFO][train.py>_log] ==> #999000     Total Loss: 2.279    [weighted Loss:2.279    Policy Loss: 10.176   Value Loss: 4.127    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 2629067    Buffer Size: 15200      Transition Number: 1000.256k Batch Size: 256        Lr: 0.00016 
[2022-02-27 08:04:10,238][train][INFO][train.py>_log] ==> #1000000    Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 10.616   Value Loss: 4.208    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 2631682    Buffer Size: 15209      Transition Number: 1000.279k Batch Size: 256        Lr: 0.00016 
[2022-02-27 08:07:47,734][train][INFO][train.py>_log] ==> #1001000    Total Loss: 2.469    [weighted Loss:2.469    Policy Loss: 10.378   Value Loss: 4.145    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 2634677    Buffer Size: 15198      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:11:13,438][train][INFO][train.py>_log] ==> #1002000    Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 10.228   Value Loss: 4.130    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 2637200    Buffer Size: 15214      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:14:34,648][train][INFO][train.py>_log] ==> #1003000    Total Loss: 1.786    [weighted Loss:1.786    Policy Loss: 10.271   Value Loss: 4.320    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 2639843    Buffer Size: 15217      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:18:02,703][train][INFO][train.py>_log] ==> #1004000    Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 10.344   Value Loss: 4.198    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 2642449    Buffer Size: 15231      Transition Number: 1000.853k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:21:30,664][train][INFO][train.py>_log] ==> #1005000    Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 10.538   Value Loss: 4.184    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2645105    Buffer Size: 15239      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:24:57,810][train][INFO][train.py>_log] ==> #1006000    Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 10.082   Value Loss: 4.037    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 2647731    Buffer Size: 15236      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:28:21,949][train][INFO][train.py>_log] ==> #1007000    Total Loss: 3.620    [weighted Loss:3.620    Policy Loss: 10.009   Value Loss: 4.251    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 2650244    Buffer Size: 15272      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:31:50,487][train][INFO][train.py>_log] ==> #1008000    Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 10.197   Value Loss: 4.280    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 2652965    Buffer Size: 15261      Transition Number: 1000.016k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:35:19,380][train][INFO][train.py>_log] ==> #1009000    Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 10.397   Value Loss: 4.336    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2655610    Buffer Size: 15288      Transition Number: 1000.296k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:38:53,660][train][INFO][train.py>_log] ==> #1010000    Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 10.381   Value Loss: 4.214    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 2658397    Buffer Size: 15312      Transition Number: 1000.243k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:42:21,308][train][INFO][train.py>_log] ==> #1011000    Total Loss: 1.673    [weighted Loss:1.673    Policy Loss: 10.406   Value Loss: 4.588    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2660873    Buffer Size: 15345      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:45:50,137][train][INFO][train.py>_log] ==> #1012000    Total Loss: 3.895    [weighted Loss:3.895    Policy Loss: 10.477   Value Loss: 4.216    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 2663578    Buffer Size: 15351      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:49:16,994][train][INFO][train.py>_log] ==> #1013000    Total Loss: 3.052    [weighted Loss:3.052    Policy Loss: 10.386   Value Loss: 4.077    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 2666256    Buffer Size: 15357      Transition Number: 1000.521k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:52:48,664][train][INFO][train.py>_log] ==> #1014000    Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 10.415   Value Loss: 4.158    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 2669001    Buffer Size: 15366      Transition Number: 1000.210k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:56:12,544][train][INFO][train.py>_log] ==> #1015000    Total Loss: 2.270    [weighted Loss:2.270    Policy Loss: 10.359   Value Loss: 3.990    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 2671547    Buffer Size: 15373      Transition Number: 1000.214k Batch Size: 256        Lr: 0.00010 
[2022-02-27 08:59:45,844][train][INFO][train.py>_log] ==> #1016000    Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 10.582   Value Loss: 4.536    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2674179    Buffer Size: 15385      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:03:13,826][train][INFO][train.py>_log] ==> #1017000    Total Loss: 2.935    [weighted Loss:2.935    Policy Loss: 10.620   Value Loss: 4.188    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2676904    Buffer Size: 15387      Transition Number: 1000.452k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:06:39,102][train][INFO][train.py>_log] ==> #1018000    Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 10.264   Value Loss: 4.155    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 2679528    Buffer Size: 15413      Transition Number: 1000.355k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:10:07,451][train][INFO][train.py>_log] ==> #1019000    Total Loss: 2.105    [weighted Loss:2.105    Policy Loss: 9.991    Value Loss: 4.312    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2682156    Buffer Size: 15432      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:13:34,405][train][INFO][train.py>_log] ==> #1020000    Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 10.323   Value Loss: 4.381    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2684815    Buffer Size: 15474      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:17:04,856][train][INFO][train.py>_log] ==> #1021000    Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 10.335   Value Loss: 4.066    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 2687492    Buffer Size: 15476      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:20:33,235][train][INFO][train.py>_log] ==> #1022000    Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 10.386   Value Loss: 4.570    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 2690048    Buffer Size: 15494      Transition Number: 1000.153k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:24:01,860][train][INFO][train.py>_log] ==> #1023000    Total Loss: 2.644    [weighted Loss:2.644    Policy Loss: 10.251   Value Loss: 4.279    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 2692805    Buffer Size: 15498      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:27:32,016][train][INFO][train.py>_log] ==> #1024000    Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 10.842   Value Loss: 4.222    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2695498    Buffer Size: 15505      Transition Number: 1000.293k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:31:02,721][train][INFO][train.py>_log] ==> #1025000    Total Loss: 1.596    [weighted Loss:1.596    Policy Loss: 10.125   Value Loss: 4.073    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 2698185    Buffer Size: 15486      Transition Number: 1000.076k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:34:34,700][train][INFO][train.py>_log] ==> #1026000    Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 10.014   Value Loss: 4.256    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2700860    Buffer Size: 15485      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:37:58,306][train][INFO][train.py>_log] ==> #1027000    Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 10.287   Value Loss: 4.258    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 2703449    Buffer Size: 15493      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:41:25,694][train][INFO][train.py>_log] ==> #1028000    Total Loss: 3.170    [weighted Loss:3.170    Policy Loss: 10.045   Value Loss: 4.375    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2706195    Buffer Size: 15480      Transition Number: 1000.246k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:44:48,983][train][INFO][train.py>_log] ==> #1029000    Total Loss: 1.544    [weighted Loss:1.544    Policy Loss: 10.641   Value Loss: 4.325    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 2708684    Buffer Size: 15484      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:48:18,136][train][INFO][train.py>_log] ==> #1030000    Total Loss: 2.433    [weighted Loss:2.433    Policy Loss: 10.316   Value Loss: 4.206    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 2711357    Buffer Size: 15478      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:51:50,595][train][INFO][train.py>_log] ==> #1031000    Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 10.466   Value Loss: 4.257    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2714099    Buffer Size: 15524      Transition Number: 1000.474k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:55:19,564][train][INFO][train.py>_log] ==> #1032000    Total Loss: 2.344    [weighted Loss:2.344    Policy Loss: 10.457   Value Loss: 4.574    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2716698    Buffer Size: 15526      Transition Number: 1000.121k Batch Size: 256        Lr: 0.00010 
[2022-02-27 09:58:48,088][train][INFO][train.py>_log] ==> #1033000    Total Loss: 3.033    [weighted Loss:3.033    Policy Loss: 10.520   Value Loss: 4.430    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2719447    Buffer Size: 15525      Transition Number: 1000.500k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:02:16,731][train][INFO][train.py>_log] ==> #1034000    Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 9.904    Value Loss: 4.311    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 2722165    Buffer Size: 15506      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:05:36,915][train][INFO][train.py>_log] ==> #1035000    Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 10.627   Value Loss: 4.524    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 2724687    Buffer Size: 15525      Transition Number: 1000.611k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:09:07,005][train][INFO][train.py>_log] ==> #1036000    Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 10.513   Value Loss: 4.085    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2727410    Buffer Size: 15504      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:12:30,724][train][INFO][train.py>_log] ==> #1037000    Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 10.432   Value Loss: 4.435    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2729973    Buffer Size: 15487      Transition Number: 1000.305k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:15:57,224][train][INFO][train.py>_log] ==> #1038000    Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 10.268   Value Loss: 4.279    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2732598    Buffer Size: 15468      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:19:23,733][train][INFO][train.py>_log] ==> #1039000    Total Loss: 1.941    [weighted Loss:1.941    Policy Loss: 10.525   Value Loss: 4.106    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 2735253    Buffer Size: 15477      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:22:46,894][train][INFO][train.py>_log] ==> #1040000    Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 10.397   Value Loss: 4.426    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 2737814    Buffer Size: 15478      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:26:14,148][train][INFO][train.py>_log] ==> #1041000    Total Loss: 2.017    [weighted Loss:2.017    Policy Loss: 10.044   Value Loss: 4.408    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 2740434    Buffer Size: 15485      Transition Number: 1000.251k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:29:41,906][train][INFO][train.py>_log] ==> #1042000    Total Loss: 2.960    [weighted Loss:2.960    Policy Loss: 9.898    Value Loss: 4.520    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 2743140    Buffer Size: 15486      Transition Number: 1000.206k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:33:11,078][train][INFO][train.py>_log] ==> #1043000    Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 10.499   Value Loss: 4.035    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 2745782    Buffer Size: 15491      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:36:34,628][train][INFO][train.py>_log] ==> #1044000    Total Loss: 2.149    [weighted Loss:2.149    Policy Loss: 10.589   Value Loss: 4.373    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 2748393    Buffer Size: 15497      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:40:02,125][train][INFO][train.py>_log] ==> #1045000    Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 10.882   Value Loss: 4.310    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 2751037    Buffer Size: 15498      Transition Number: 1000.227k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:43:28,987][train][INFO][train.py>_log] ==> #1046000    Total Loss: 3.285    [weighted Loss:3.285    Policy Loss: 10.144   Value Loss: 4.312    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2753604    Buffer Size: 15508      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:46:52,337][train][INFO][train.py>_log] ==> #1047000    Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 10.402   Value Loss: 4.568    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 2756306    Buffer Size: 15522      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:50:17,921][train][INFO][train.py>_log] ==> #1048000    Total Loss: 1.026    [weighted Loss:1.026    Policy Loss: 10.256   Value Loss: 4.288    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2758882    Buffer Size: 15523      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:53:42,993][train][INFO][train.py>_log] ==> #1049000    Total Loss: 2.443    [weighted Loss:2.443    Policy Loss: 10.533   Value Loss: 4.251    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2761510    Buffer Size: 15514      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00010 
[2022-02-27 10:57:12,589][train][INFO][train.py>_log] ==> #1050000    Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 10.220   Value Loss: 4.293    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 2764148    Buffer Size: 15512      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:00:38,501][train][INFO][train.py>_log] ==> #1051000    Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 10.245   Value Loss: 4.199    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 2766751    Buffer Size: 15503      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:04:06,063][train][INFO][train.py>_log] ==> #1052000    Total Loss: 1.218    [weighted Loss:1.218    Policy Loss: 10.419   Value Loss: 4.098    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2769387    Buffer Size: 15475      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:07:29,521][train][INFO][train.py>_log] ==> #1053000    Total Loss: 3.500    [weighted Loss:3.500    Policy Loss: 10.579   Value Loss: 4.159    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 2771982    Buffer Size: 15461      Transition Number: 1000.513k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:10:56,843][train][INFO][train.py>_log] ==> #1054000    Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 10.406   Value Loss: 4.305    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2774726    Buffer Size: 15452      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:14:20,039][train][INFO][train.py>_log] ==> #1055000    Total Loss: 1.455    [weighted Loss:1.455    Policy Loss: 10.487   Value Loss: 4.083    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2777211    Buffer Size: 15468      Transition Number: 1000.210k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:17:44,002][train][INFO][train.py>_log] ==> #1056000    Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 10.009   Value Loss: 4.534    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2779869    Buffer Size: 15474      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:21:12,437][train][INFO][train.py>_log] ==> #1057000    Total Loss: 3.368    [weighted Loss:3.368    Policy Loss: 10.723   Value Loss: 4.317    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2782579    Buffer Size: 15492      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:24:40,221][train][INFO][train.py>_log] ==> #1058000    Total Loss: 3.567    [weighted Loss:3.567    Policy Loss: 10.500   Value Loss: 4.113    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2785203    Buffer Size: 15490      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:28:06,049][train][INFO][train.py>_log] ==> #1059000    Total Loss: 3.556    [weighted Loss:3.556    Policy Loss: 10.253   Value Loss: 4.189    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 2787785    Buffer Size: 15514      Transition Number: 1000.399k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:31:29,906][train][INFO][train.py>_log] ==> #1060000    Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 10.391   Value Loss: 4.221    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2790362    Buffer Size: 15516      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:34:57,884][train][INFO][train.py>_log] ==> #1061000    Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 10.505   Value Loss: 4.250    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2793093    Buffer Size: 15526      Transition Number: 1000.205k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:38:28,678][train][INFO][train.py>_log] ==> #1062000    Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 10.390   Value Loss: 4.339    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2795721    Buffer Size: 15507      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:41:52,550][train][INFO][train.py>_log] ==> #1063000    Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 10.349   Value Loss: 4.407    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 2798339    Buffer Size: 15501      Transition Number: 1000.283k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:45:20,964][train][INFO][train.py>_log] ==> #1064000    Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 10.442   Value Loss: 4.319    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2801044    Buffer Size: 15512      Transition Number: 1000.224k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:48:49,559][train][INFO][train.py>_log] ==> #1065000    Total Loss: 3.486    [weighted Loss:3.486    Policy Loss: 10.482   Value Loss: 4.113    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 2803672    Buffer Size: 15528      Transition Number: 1000.194k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:52:20,216][train][INFO][train.py>_log] ==> #1066000    Total Loss: 2.875    [weighted Loss:2.875    Policy Loss: 10.248   Value Loss: 4.201    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2806408    Buffer Size: 15538      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:55:46,811][train][INFO][train.py>_log] ==> #1067000    Total Loss: 1.533    [weighted Loss:1.533    Policy Loss: 10.647   Value Loss: 4.252    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2809062    Buffer Size: 15532      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 11:59:18,638][train][INFO][train.py>_log] ==> #1068000    Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 10.384   Value Loss: 4.087    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 2811796    Buffer Size: 15546      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:02:47,933][train][INFO][train.py>_log] ==> #1069000    Total Loss: 1.024    [weighted Loss:1.024    Policy Loss: 10.547   Value Loss: 4.104    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2814427    Buffer Size: 15561      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:06:14,930][train][INFO][train.py>_log] ==> #1070000    Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 10.267   Value Loss: 4.360    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2817041    Buffer Size: 15536      Transition Number: 1000.264k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:09:43,363][train][INFO][train.py>_log] ==> #1071000    Total Loss: 2.185    [weighted Loss:2.185    Policy Loss: 10.458   Value Loss: 4.393    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2819814    Buffer Size: 15526      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:13:11,114][train][INFO][train.py>_log] ==> #1072000    Total Loss: 1.241    [weighted Loss:1.241    Policy Loss: 10.013   Value Loss: 4.555    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 2822354    Buffer Size: 15525      Transition Number: 1000.418k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:16:42,062][train][INFO][train.py>_log] ==> #1073000    Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 10.448   Value Loss: 4.177    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2825097    Buffer Size: 15524      Transition Number: 1000.273k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:20:13,697][train][INFO][train.py>_log] ==> #1074000    Total Loss: 2.546    [weighted Loss:2.546    Policy Loss: 10.295   Value Loss: 4.490    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2827739    Buffer Size: 15540      Transition Number: 1000.275k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:23:45,865][train][INFO][train.py>_log] ==> #1075000    Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 10.338   Value Loss: 3.998    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 2830537    Buffer Size: 15534      Transition Number: 1000.329k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:27:11,540][train][INFO][train.py>_log] ==> #1076000    Total Loss: 2.318    [weighted Loss:2.318    Policy Loss: 10.594   Value Loss: 4.228    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 2833112    Buffer Size: 15555      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:30:40,149][train][INFO][train.py>_log] ==> #1077000    Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 10.258   Value Loss: 4.086    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 2835834    Buffer Size: 15549      Transition Number: 1000.276k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:34:15,253][train][INFO][train.py>_log] ==> #1078000    Total Loss: 2.890    [weighted Loss:2.890    Policy Loss: 10.447   Value Loss: 4.205    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2838429    Buffer Size: 15574      Transition Number: 1000.338k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:37:43,753][train][INFO][train.py>_log] ==> #1079000    Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 10.127   Value Loss: 4.260    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 2841255    Buffer Size: 15534      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:41:13,238][train][INFO][train.py>_log] ==> #1080000    Total Loss: 3.048    [weighted Loss:3.048    Policy Loss: 10.645   Value Loss: 4.301    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 2843866    Buffer Size: 15547      Transition Number: 1000.531k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:44:37,946][train][INFO][train.py>_log] ==> #1081000    Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 10.358   Value Loss: 4.416    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2846556    Buffer Size: 15554      Transition Number: 1000.378k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:48:05,346][train][INFO][train.py>_log] ==> #1082000    Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 10.009   Value Loss: 3.951    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2849124    Buffer Size: 15564      Transition Number: 1000.428k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:51:36,124][train][INFO][train.py>_log] ==> #1083000    Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 10.559   Value Loss: 3.979    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2851882    Buffer Size: 15559      Transition Number: 1000.201k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:55:05,387][train][INFO][train.py>_log] ==> #1084000    Total Loss: 3.046    [weighted Loss:3.046    Policy Loss: 10.241   Value Loss: 4.185    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2854463    Buffer Size: 15557      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 12:58:34,782][train][INFO][train.py>_log] ==> #1085000    Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 10.628   Value Loss: 4.154    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 2857161    Buffer Size: 15570      Transition Number: 1000.736k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:02:03,490][train][INFO][train.py>_log] ==> #1086000    Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 10.543   Value Loss: 4.489    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 2859811    Buffer Size: 15544      Transition Number: 1000.142k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:05:31,289][train][INFO][train.py>_log] ==> #1087000    Total Loss: 3.000    [weighted Loss:3.000    Policy Loss: 10.551   Value Loss: 4.211    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2862521    Buffer Size: 15520      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:08:59,793][train][INFO][train.py>_log] ==> #1088000    Total Loss: 1.353    [weighted Loss:1.353    Policy Loss: 10.652   Value Loss: 4.350    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2865063    Buffer Size: 15497      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:12:25,711][train][INFO][train.py>_log] ==> #1089000    Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 10.808   Value Loss: 4.364    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2867697    Buffer Size: 15491      Transition Number: 1000.346k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:15:54,975][train][INFO][train.py>_log] ==> #1090000    Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 10.629   Value Loss: 4.420    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 2870412    Buffer Size: 15477      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:19:24,355][train][INFO][train.py>_log] ==> #1091000    Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 10.197   Value Loss: 4.276    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 2873089    Buffer Size: 15492      Transition Number: 1000.522k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:22:55,434][train][INFO][train.py>_log] ==> #1092000    Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 10.257   Value Loss: 4.228    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2875897    Buffer Size: 15491      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:26:25,112][train][INFO][train.py>_log] ==> #1093000    Total Loss: 1.913    [weighted Loss:1.913    Policy Loss: 10.538   Value Loss: 4.326    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2878451    Buffer Size: 15481      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:29:53,717][train][INFO][train.py>_log] ==> #1094000    Total Loss: 2.242    [weighted Loss:2.242    Policy Loss: 10.470   Value Loss: 4.333    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2881130    Buffer Size: 15479      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:33:21,026][train][INFO][train.py>_log] ==> #1095000    Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 10.228   Value Loss: 4.585    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 2883825    Buffer Size: 15491      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:36:48,913][train][INFO][train.py>_log] ==> #1096000    Total Loss: 2.501    [weighted Loss:2.501    Policy Loss: 10.333   Value Loss: 4.196    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 2886455    Buffer Size: 15479      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:40:15,569][train][INFO][train.py>_log] ==> #1097000    Total Loss: 1.860    [weighted Loss:1.860    Policy Loss: 10.614   Value Loss: 4.204    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 2889095    Buffer Size: 15478      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:43:46,282][train][INFO][train.py>_log] ==> #1098000    Total Loss: 2.741    [weighted Loss:2.741    Policy Loss: 10.504   Value Loss: 4.153    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 2891812    Buffer Size: 15475      Transition Number: 1000.406k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:47:13,028][train][INFO][train.py>_log] ==> #1099000    Total Loss: 2.566    [weighted Loss:2.566    Policy Loss: 10.632   Value Loss: 4.641    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 2894405    Buffer Size: 15496      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:50:41,690][train][INFO][train.py>_log] ==> #1100000    Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 10.314   Value Loss: 4.098    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 2897119    Buffer Size: 15497      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:54:10,620][train][INFO][train.py>_log] ==> #1101000    Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 10.464   Value Loss: 4.431    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 2899804    Buffer Size: 15498      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00010 
[2022-02-27 13:57:40,837][train][INFO][train.py>_log] ==> #1102000    Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 10.445   Value Loss: 4.179    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2902441    Buffer Size: 15523      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:01:10,304][train][INFO][train.py>_log] ==> #1103000    Total Loss: 2.200    [weighted Loss:2.200    Policy Loss: 10.647   Value Loss: 4.191    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 2905178    Buffer Size: 15517      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:04:41,382][train][INFO][train.py>_log] ==> #1104000    Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 10.396   Value Loss: 4.168    Reward Loss: 1.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 2907832    Buffer Size: 15508      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:08:09,828][train][INFO][train.py>_log] ==> #1105000    Total Loss: 3.141    [weighted Loss:3.141    Policy Loss: 10.494   Value Loss: 4.041    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 2910484    Buffer Size: 15490      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:11:37,297][train][INFO][train.py>_log] ==> #1106000    Total Loss: 1.476    [weighted Loss:1.476    Policy Loss: 10.555   Value Loss: 4.252    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2913157    Buffer Size: 15486      Transition Number: 1000.327k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:15:04,439][train][INFO][train.py>_log] ==> #1107000    Total Loss: 3.296    [weighted Loss:3.296    Policy Loss: 10.449   Value Loss: 4.277    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2915771    Buffer Size: 15453      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:18:36,342][train][INFO][train.py>_log] ==> #1108000    Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 10.959   Value Loss: 3.974    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2918574    Buffer Size: 15435      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:22:06,123][train][INFO][train.py>_log] ==> #1109000    Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 10.587   Value Loss: 4.233    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2921168    Buffer Size: 15434      Transition Number: 1000.380k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:25:34,413][train][INFO][train.py>_log] ==> #1110000    Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 10.903   Value Loss: 4.327    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2923849    Buffer Size: 15433      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:29:05,219][train][INFO][train.py>_log] ==> #1111000    Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 10.821   Value Loss: 4.151    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 2926482    Buffer Size: 15453      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:32:34,468][train][INFO][train.py>_log] ==> #1112000    Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 10.623   Value Loss: 4.125    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 2929287    Buffer Size: 15458      Transition Number: 1000.349k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:36:00,996][train][INFO][train.py>_log] ==> #1113000    Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 10.494   Value Loss: 4.308    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 2931873    Buffer Size: 15473      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:39:30,803][train][INFO][train.py>_log] ==> #1114000    Total Loss: 2.582    [weighted Loss:2.582    Policy Loss: 10.358   Value Loss: 4.307    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2934587    Buffer Size: 15475      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:43:04,019][train][INFO][train.py>_log] ==> #1115000    Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 10.304   Value Loss: 4.657    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2937254    Buffer Size: 15507      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:46:31,164][train][INFO][train.py>_log] ==> #1116000    Total Loss: 3.034    [weighted Loss:3.034    Policy Loss: 10.050   Value Loss: 4.227    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2940044    Buffer Size: 15506      Transition Number: 1000.451k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:50:02,490][train][INFO][train.py>_log] ==> #1117000    Total Loss: 1.937    [weighted Loss:1.937    Policy Loss: 10.493   Value Loss: 3.967    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 2942685    Buffer Size: 15520      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:53:30,884][train][INFO][train.py>_log] ==> #1118000    Total Loss: 2.666    [weighted Loss:2.666    Policy Loss: 10.063   Value Loss: 4.160    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 2945330    Buffer Size: 15521      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00010 
[2022-02-27 14:57:04,077][train][INFO][train.py>_log] ==> #1119000    Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 10.277   Value Loss: 4.206    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 2948006    Buffer Size: 15547      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:00:32,637][train][INFO][train.py>_log] ==> #1120000    Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 10.536   Value Loss: 4.120    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 2950707    Buffer Size: 15557      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:04:00,678][train][INFO][train.py>_log] ==> #1121000    Total Loss: 3.110    [weighted Loss:3.110    Policy Loss: 10.406   Value Loss: 4.445    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2953417    Buffer Size: 15567      Transition Number: 1000.193k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:07:27,679][train][INFO][train.py>_log] ==> #1122000    Total Loss: 2.495    [weighted Loss:2.495    Policy Loss: 10.549   Value Loss: 4.479    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2956091    Buffer Size: 15581      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:10:52,135][train][INFO][train.py>_log] ==> #1123000    Total Loss: 1.872    [weighted Loss:1.872    Policy Loss: 10.934   Value Loss: 4.347    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2958722    Buffer Size: 15583      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:14:20,525][train][INFO][train.py>_log] ==> #1124000    Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 10.357   Value Loss: 4.338    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 2961312    Buffer Size: 15613      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:17:52,349][train][INFO][train.py>_log] ==> #1125000    Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 10.417   Value Loss: 4.205    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 2964160    Buffer Size: 15615      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:21:26,791][train][INFO][train.py>_log] ==> #1126000    Total Loss: 3.496    [weighted Loss:3.496    Policy Loss: 10.404   Value Loss: 4.380    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2966813    Buffer Size: 15622      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:24:55,306][train][INFO][train.py>_log] ==> #1127000    Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 10.635   Value Loss: 4.397    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 2969547    Buffer Size: 15640      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:28:25,426][train][INFO][train.py>_log] ==> #1128000    Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 10.436   Value Loss: 4.000    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 2972171    Buffer Size: 15654      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:31:53,941][train][INFO][train.py>_log] ==> #1129000    Total Loss: 3.450    [weighted Loss:3.450    Policy Loss: 10.239   Value Loss: 4.171    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 2974913    Buffer Size: 15685      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:35:24,480][train][INFO][train.py>_log] ==> #1130000    Total Loss: 1.843    [weighted Loss:1.843    Policy Loss: 10.440   Value Loss: 4.051    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 2977613    Buffer Size: 15698      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:38:52,139][train][INFO][train.py>_log] ==> #1131000    Total Loss: 0.721    [weighted Loss:0.721    Policy Loss: 10.044   Value Loss: 4.116    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2980255    Buffer Size: 15715      Transition Number: 1000.176k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:42:22,116][train][INFO][train.py>_log] ==> #1132000    Total Loss: 3.589    [weighted Loss:3.589    Policy Loss: 10.303   Value Loss: 4.319    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 2982976    Buffer Size: 15733      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:45:50,731][train][INFO][train.py>_log] ==> #1133000    Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 10.693   Value Loss: 4.197    Reward Loss: 1.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 2985611    Buffer Size: 15742      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:49:18,698][train][INFO][train.py>_log] ==> #1134000    Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 10.637   Value Loss: 4.017    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 2988350    Buffer Size: 15735      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:52:53,565][train][INFO][train.py>_log] ==> #1135000    Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 10.541   Value Loss: 4.490    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2991048    Buffer Size: 15724      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:56:25,744][train][INFO][train.py>_log] ==> #1136000    Total Loss: 3.703    [weighted Loss:3.703    Policy Loss: 10.923   Value Loss: 4.286    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 2993753    Buffer Size: 15709      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00010 
[2022-02-27 15:59:57,406][train][INFO][train.py>_log] ==> #1137000    Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 10.538   Value Loss: 4.342    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 2996553    Buffer Size: 15705      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:03:26,559][train][INFO][train.py>_log] ==> #1138000    Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 10.864   Value Loss: 4.289    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2999186    Buffer Size: 15723      Transition Number: 1000.230k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:06:57,809][train][INFO][train.py>_log] ==> #1139000    Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 10.742   Value Loss: 4.299    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 3001902    Buffer Size: 15741      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:10:28,020][train][INFO][train.py>_log] ==> #1140000    Total Loss: 1.529    [weighted Loss:1.529    Policy Loss: 10.250   Value Loss: 4.288    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 3004649    Buffer Size: 15758      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:14:00,997][train][INFO][train.py>_log] ==> #1141000    Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 10.245   Value Loss: 4.383    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 3007373    Buffer Size: 15783      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:17:34,849][train][INFO][train.py>_log] ==> #1142000    Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 10.450   Value Loss: 4.357    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 3010112    Buffer Size: 15804      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:21:08,486][train][INFO][train.py>_log] ==> #1143000    Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 10.430   Value Loss: 4.160    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 3012893    Buffer Size: 15801      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:24:41,588][train][INFO][train.py>_log] ==> #1144000    Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 10.262   Value Loss: 4.422    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 3015595    Buffer Size: 15807      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:28:14,936][train][INFO][train.py>_log] ==> #1145000    Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 10.313   Value Loss: 4.106    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 3018369    Buffer Size: 15780      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:31:46,251][train][INFO][train.py>_log] ==> #1146000    Total Loss: 2.645    [weighted Loss:2.645    Policy Loss: 10.523   Value Loss: 4.498    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 3021009    Buffer Size: 15777      Transition Number: 1000.523k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:35:15,350][train][INFO][train.py>_log] ==> #1147000    Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 10.490   Value Loss: 4.181    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 3023737    Buffer Size: 15748      Transition Number: 1000.148k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:38:51,704][train][INFO][train.py>_log] ==> #1148000    Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 10.488   Value Loss: 3.984    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 3026471    Buffer Size: 15727      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:42:23,885][train][INFO][train.py>_log] ==> #1149000    Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 10.372   Value Loss: 4.349    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 3029249    Buffer Size: 15698      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:45:55,660][train][INFO][train.py>_log] ==> #1150000    Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 10.294   Value Loss: 4.046    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 3031875    Buffer Size: 15690      Transition Number: 1000.230k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:49:29,198][train][INFO][train.py>_log] ==> #1151000    Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 11.065   Value Loss: 4.387    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 3034630    Buffer Size: 15682      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:53:03,994][train][INFO][train.py>_log] ==> #1152000    Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 9.856    Value Loss: 4.201    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 3037517    Buffer Size: 15661      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00010 
[2022-02-27 16:56:40,517][train][INFO][train.py>_log] ==> #1153000    Total Loss: 2.380    [weighted Loss:2.380    Policy Loss: 10.116   Value Loss: 4.143    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 3040216    Buffer Size: 15657      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:00:20,759][train][INFO][train.py>_log] ==> #1154000    Total Loss: 2.886    [weighted Loss:2.886    Policy Loss: 10.628   Value Loss: 4.125    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 3043036    Buffer Size: 15655      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:03:44,815][train][INFO][train.py>_log] ==> #1155000    Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 11.016   Value Loss: 4.253    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 3045646    Buffer Size: 15642      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:07:13,410][train][INFO][train.py>_log] ==> #1156000    Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 10.843   Value Loss: 4.392    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 3048409    Buffer Size: 15641      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:10:41,385][train][INFO][train.py>_log] ==> #1157000    Total Loss: 1.408    [weighted Loss:1.408    Policy Loss: 10.495   Value Loss: 4.509    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 3050988    Buffer Size: 15625      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:14:14,436][train][INFO][train.py>_log] ==> #1158000    Total Loss: 1.808    [weighted Loss:1.808    Policy Loss: 10.694   Value Loss: 4.250    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 3053672    Buffer Size: 15603      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:17:47,255][train][INFO][train.py>_log] ==> #1159000    Total Loss: 2.524    [weighted Loss:2.524    Policy Loss: 10.408   Value Loss: 4.322    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 3056368    Buffer Size: 15574      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:21:21,835][train][INFO][train.py>_log] ==> #1160000    Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 10.429   Value Loss: 4.229    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 3059200    Buffer Size: 15556      Transition Number: 1000.408k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:24:52,168][train][INFO][train.py>_log] ==> #1161000    Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 10.875   Value Loss: 4.141    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 3061860    Buffer Size: 15548      Transition Number: 1000.392k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:28:26,868][train][INFO][train.py>_log] ==> #1162000    Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 10.745   Value Loss: 4.188    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 3064533    Buffer Size: 15537      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:31:59,689][train][INFO][train.py>_log] ==> #1163000    Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 10.652   Value Loss: 4.124    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 3067293    Buffer Size: 15532      Transition Number: 1000.225k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:35:31,141][train][INFO][train.py>_log] ==> #1164000    Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 10.463   Value Loss: 4.004    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 3070016    Buffer Size: 15538      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:39:04,401][train][INFO][train.py>_log] ==> #1165000    Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 10.476   Value Loss: 4.629    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 3072714    Buffer Size: 15581      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:42:35,957][train][INFO][train.py>_log] ==> #1166000    Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 10.381   Value Loss: 4.455    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 3075436    Buffer Size: 15593      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:46:06,724][train][INFO][train.py>_log] ==> #1167000    Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 10.124   Value Loss: 4.060    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 3078196    Buffer Size: 15611      Transition Number: 1000.291k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:49:39,654][train][INFO][train.py>_log] ==> #1168000    Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 10.347   Value Loss: 4.665    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 3080892    Buffer Size: 15619      Transition Number: 1000.369k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:53:13,346][train][INFO][train.py>_log] ==> #1169000    Total Loss: 0.517    [weighted Loss:0.517    Policy Loss: 10.169   Value Loss: 4.434    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 3083659    Buffer Size: 15611      Transition Number: 1000.242k Batch Size: 256        Lr: 0.00010 
[2022-02-27 17:56:42,020][train][INFO][train.py>_log] ==> #1170000    Total Loss: 3.334    [weighted Loss:3.334    Policy Loss: 10.583   Value Loss: 4.202    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 3086335    Buffer Size: 15600      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:00:15,295][train][INFO][train.py>_log] ==> #1171000    Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 10.648   Value Loss: 4.312    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 3089039    Buffer Size: 15621      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:03:49,977][train][INFO][train.py>_log] ==> #1172000    Total Loss: 2.465    [weighted Loss:2.465    Policy Loss: 10.381   Value Loss: 4.142    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 3091825    Buffer Size: 15626      Transition Number: 1000.291k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:07:23,865][train][INFO][train.py>_log] ==> #1173000    Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 10.587   Value Loss: 4.220    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 3094526    Buffer Size: 15617      Transition Number: 1000.294k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:10:57,563][train][INFO][train.py>_log] ==> #1174000    Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 10.402   Value Loss: 4.244    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 3097225    Buffer Size: 15606      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:14:30,315][train][INFO][train.py>_log] ==> #1175000    Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 10.710   Value Loss: 4.190    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 3099975    Buffer Size: 15627      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:18:07,314][train][INFO][train.py>_log] ==> #1176000    Total Loss: 1.299    [weighted Loss:1.299    Policy Loss: 10.874   Value Loss: 4.541    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 3102764    Buffer Size: 15630      Transition Number: 1000.389k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:21:43,533][train][INFO][train.py>_log] ==> #1177000    Total Loss: 3.209    [weighted Loss:3.209    Policy Loss: 10.592   Value Loss: 4.528    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 3105552    Buffer Size: 15618      Transition Number: 1000.321k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:25:16,446][train][INFO][train.py>_log] ==> #1178000    Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 10.628   Value Loss: 4.335    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 3108287    Buffer Size: 15615      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:28:46,536][train][INFO][train.py>_log] ==> #1179000    Total Loss: 1.355    [weighted Loss:1.355    Policy Loss: 10.032   Value Loss: 4.637    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 3111021    Buffer Size: 15616      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:32:22,083][train][INFO][train.py>_log] ==> #1180000    Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 10.458   Value Loss: 4.298    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 3113712    Buffer Size: 15608      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:35:56,647][train][INFO][train.py>_log] ==> #1181000    Total Loss: 1.543    [weighted Loss:1.543    Policy Loss: 10.657   Value Loss: 4.210    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 3116550    Buffer Size: 15624      Transition Number: 1000.388k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:39:31,513][train][INFO][train.py>_log] ==> #1182000    Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 10.793   Value Loss: 4.306    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 3119281    Buffer Size: 15623      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:43:08,547][train][INFO][train.py>_log] ==> #1183000    Total Loss: 2.119    [weighted Loss:2.119    Policy Loss: 10.440   Value Loss: 4.235    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 3122095    Buffer Size: 15628      Transition Number: 1000.241k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:46:38,370][train][INFO][train.py>_log] ==> #1184000    Total Loss: 2.380    [weighted Loss:2.380    Policy Loss: 10.565   Value Loss: 4.340    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 3124757    Buffer Size: 15641      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:50:08,877][train][INFO][train.py>_log] ==> #1185000    Total Loss: 3.531    [weighted Loss:3.531    Policy Loss: 10.805   Value Loss: 4.393    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 3127447    Buffer Size: 15631      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:53:40,329][train][INFO][train.py>_log] ==> #1186000    Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 10.829   Value Loss: 4.323    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 3130176    Buffer Size: 15652      Transition Number: 1000.439k Batch Size: 256        Lr: 0.00010 
[2022-02-27 18:57:17,769][train][INFO][train.py>_log] ==> #1187000    Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 10.138   Value Loss: 4.211    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 3132961    Buffer Size: 15661      Transition Number: 1000.380k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:00:54,818][train][INFO][train.py>_log] ==> #1188000    Total Loss: 1.454    [weighted Loss:1.454    Policy Loss: 10.572   Value Loss: 4.163    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 3135765    Buffer Size: 15661      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:04:34,282][train][INFO][train.py>_log] ==> #1189000    Total Loss: 2.352    [weighted Loss:2.352    Policy Loss: 10.462   Value Loss: 4.577    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 3138523    Buffer Size: 15685      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:08:11,544][train][INFO][train.py>_log] ==> #1190000    Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 10.427   Value Loss: 4.269    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 3141384    Buffer Size: 15671      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:11:44,913][train][INFO][train.py>_log] ==> #1191000    Total Loss: 2.017    [weighted Loss:2.017    Policy Loss: 10.735   Value Loss: 4.205    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 3144066    Buffer Size: 15707      Transition Number: 1000.426k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:15:15,634][train][INFO][train.py>_log] ==> #1192000    Total Loss: 3.400    [weighted Loss:3.400    Policy Loss: 10.753   Value Loss: 4.348    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 3146844    Buffer Size: 15699      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:18:48,902][train][INFO][train.py>_log] ==> #1193000    Total Loss: 2.728    [weighted Loss:2.728    Policy Loss: 10.609   Value Loss: 4.175    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 3149585    Buffer Size: 15692      Transition Number: 1000.423k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:22:21,711][train][INFO][train.py>_log] ==> #1194000    Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 10.596   Value Loss: 4.050    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 3152281    Buffer Size: 15676      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:25:50,635][train][INFO][train.py>_log] ==> #1195000    Total Loss: 3.343    [weighted Loss:3.343    Policy Loss: 11.055   Value Loss: 4.588    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 3154953    Buffer Size: 15652      Transition Number: 1000.180k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:29:27,659][train][INFO][train.py>_log] ==> #1196000    Total Loss: 0.563    [weighted Loss:0.563    Policy Loss: 10.926   Value Loss: 4.203    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 3157766    Buffer Size: 15628      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:33:04,368][train][INFO][train.py>_log] ==> #1197000    Total Loss: 1.943    [weighted Loss:1.943    Policy Loss: 10.282   Value Loss: 4.568    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 3160568    Buffer Size: 15602      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:36:34,467][train][INFO][train.py>_log] ==> #1198000    Total Loss: 1.101    [weighted Loss:1.101    Policy Loss: 10.656   Value Loss: 4.278    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 3163213    Buffer Size: 15581      Transition Number: 1000.214k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:40:05,775][train][INFO][train.py>_log] ==> #1199000    Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 10.804   Value Loss: 4.075    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 3165863    Buffer Size: 15578      Transition Number: 1000.182k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:43:34,878][train][INFO][train.py>_log] ==> #1200000    Total Loss: 1.984    [weighted Loss:1.984    Policy Loss: 10.643   Value Loss: 4.395    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 3168544    Buffer Size: 15570      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:47:04,641][train][INFO][train.py>_log] ==> #1201000    Total Loss: 3.317    [weighted Loss:3.317    Policy Loss: 10.637   Value Loss: 4.452    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 3171266    Buffer Size: 15575      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:50:34,159][train][INFO][train.py>_log] ==> #1202000    Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 10.746   Value Loss: 4.277    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 3174027    Buffer Size: 15565      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:54:07,917][train][INFO][train.py>_log] ==> #1203000    Total Loss: 3.337    [weighted Loss:3.337    Policy Loss: 10.410   Value Loss: 4.124    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 3176678    Buffer Size: 15568      Transition Number: 1000.465k Batch Size: 256        Lr: 0.00010 
[2022-02-27 19:57:36,452][train][INFO][train.py>_log] ==> #1204000    Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 10.419   Value Loss: 4.419    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 3179404    Buffer Size: 15565      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:01:04,605][train][INFO][train.py>_log] ==> #1205000    Total Loss: 2.431    [weighted Loss:2.431    Policy Loss: 10.377   Value Loss: 4.220    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 3182021    Buffer Size: 15559      Transition Number: 1000.283k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:04:40,732][train][INFO][train.py>_log] ==> #1206000    Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 10.477   Value Loss: 4.284    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 3184758    Buffer Size: 15541      Transition Number: 1000.310k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:08:11,881][train][INFO][train.py>_log] ==> #1207000    Total Loss: 3.882    [weighted Loss:3.882    Policy Loss: 10.823   Value Loss: 4.178    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 3187439    Buffer Size: 15535      Transition Number: 1000.381k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:11:47,343][train][INFO][train.py>_log] ==> #1208000    Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 10.515   Value Loss: 4.394    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 3190271    Buffer Size: 15522      Transition Number: 1000.241k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:15:19,672][train][INFO][train.py>_log] ==> #1209000    Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 10.193   Value Loss: 4.309    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 3193033    Buffer Size: 15522      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:18:57,314][train][INFO][train.py>_log] ==> #1210000    Total Loss: 2.950    [weighted Loss:2.950    Policy Loss: 10.605   Value Loss: 4.120    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 3195773    Buffer Size: 15512      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:22:31,881][train][INFO][train.py>_log] ==> #1211000    Total Loss: 1.193    [weighted Loss:1.193    Policy Loss: 10.325   Value Loss: 3.964    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 3198461    Buffer Size: 15514      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:26:09,238][train][INFO][train.py>_log] ==> #1212000    Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 10.286   Value Loss: 4.083    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 3201342    Buffer Size: 15521      Transition Number: 1000.247k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:29:50,124][train][INFO][train.py>_log] ==> #1213000    Total Loss: 2.407    [weighted Loss:2.407    Policy Loss: 10.257   Value Loss: 4.246    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 3204205    Buffer Size: 15499      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:33:22,585][train][INFO][train.py>_log] ==> #1214000    Total Loss: 3.270    [weighted Loss:3.270    Policy Loss: 10.588   Value Loss: 4.483    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 3206853    Buffer Size: 15506      Transition Number: 1000.081k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:36:57,162][train][INFO][train.py>_log] ==> #1215000    Total Loss: 1.845    [weighted Loss:1.845    Policy Loss: 10.519   Value Loss: 4.426    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 3209611    Buffer Size: 15510      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:40:34,839][train][INFO][train.py>_log] ==> #1216000    Total Loss: 2.164    [weighted Loss:2.164    Policy Loss: 10.513   Value Loss: 4.206    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 3212348    Buffer Size: 15539      Transition Number: 1000.384k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:44:09,464][train][INFO][train.py>_log] ==> #1217000    Total Loss: 1.696    [weighted Loss:1.696    Policy Loss: 10.852   Value Loss: 4.238    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 3215154    Buffer Size: 15544      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:47:38,299][train][INFO][train.py>_log] ==> #1218000    Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 10.664   Value Loss: 4.003    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 3217847    Buffer Size: 15549      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:51:12,270][train][INFO][train.py>_log] ==> #1219000    Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 10.398   Value Loss: 4.225    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 3220584    Buffer Size: 15577      Transition Number: 1000.344k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:54:42,112][train][INFO][train.py>_log] ==> #1220000    Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 10.566   Value Loss: 4.275    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 3223210    Buffer Size: 15577      Transition Number: 1000.238k Batch Size: 256        Lr: 0.00010 
[2022-02-27 20:58:15,134][train][INFO][train.py>_log] ==> #1221000    Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 10.294   Value Loss: 4.288    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 3226008    Buffer Size: 15571      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:01:48,070][train][INFO][train.py>_log] ==> #1222000    Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 10.611   Value Loss: 4.467    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 3228715    Buffer Size: 15570      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:05:18,796][train][INFO][train.py>_log] ==> #1223000    Total Loss: 1.861    [weighted Loss:1.861    Policy Loss: 10.561   Value Loss: 4.191    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 3231369    Buffer Size: 15567      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:08:51,292][train][INFO][train.py>_log] ==> #1224000    Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 10.070   Value Loss: 4.392    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 3234138    Buffer Size: 15556      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:12:23,095][train][INFO][train.py>_log] ==> #1225000    Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 10.053   Value Loss: 4.239    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 3236827    Buffer Size: 15542      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:15:56,431][train][INFO][train.py>_log] ==> #1226000    Total Loss: 2.966    [weighted Loss:2.966    Policy Loss: 10.507   Value Loss: 4.672    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 3239521    Buffer Size: 15546      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:19:28,654][train][INFO][train.py>_log] ==> #1227000    Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 10.179   Value Loss: 4.347    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 3242231    Buffer Size: 15534      Transition Number: 1000.321k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:23:04,841][train][INFO][train.py>_log] ==> #1228000    Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 10.681   Value Loss: 4.169    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 3245019    Buffer Size: 15530      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:26:35,443][train][INFO][train.py>_log] ==> #1229000    Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 10.348   Value Loss: 4.196    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 3247684    Buffer Size: 15531      Transition Number: 1000.674k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:30:07,706][train][INFO][train.py>_log] ==> #1230000    Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 10.186   Value Loss: 4.266    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 3250440    Buffer Size: 15513      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:33:39,118][train][INFO][train.py>_log] ==> #1231000    Total Loss: 3.270    [weighted Loss:3.270    Policy Loss: 10.617   Value Loss: 4.194    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 3253120    Buffer Size: 15500      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:37:09,385][train][INFO][train.py>_log] ==> #1232000    Total Loss: 2.030    [weighted Loss:2.030    Policy Loss: 10.370   Value Loss: 4.696    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 3255880    Buffer Size: 15481      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:40:43,036][train][INFO][train.py>_log] ==> #1233000    Total Loss: 1.643    [weighted Loss:1.643    Policy Loss: 10.730   Value Loss: 4.264    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 3258583    Buffer Size: 15461      Transition Number: 1000.218k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:44:14,562][train][INFO][train.py>_log] ==> #1234000    Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 10.163   Value Loss: 4.342    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 3261276    Buffer Size: 15461      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:47:45,085][train][INFO][train.py>_log] ==> #1235000    Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 10.394   Value Loss: 4.516    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 3263915    Buffer Size: 15446      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:51:18,618][train][INFO][train.py>_log] ==> #1236000    Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 10.318   Value Loss: 4.220    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 3266747    Buffer Size: 15442      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:54:48,064][train][INFO][train.py>_log] ==> #1237000    Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 10.324   Value Loss: 4.347    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 3269386    Buffer Size: 15483      Transition Number: 1000.203k Batch Size: 256        Lr: 0.00010 
[2022-02-27 21:58:18,441][train][INFO][train.py>_log] ==> #1238000    Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 10.248   Value Loss: 4.140    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 3272100    Buffer Size: 15488      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:01:46,847][train][INFO][train.py>_log] ==> #1239000    Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 10.999   Value Loss: 4.423    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 3274715    Buffer Size: 15477      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:05:17,680][train][INFO][train.py>_log] ==> #1240000    Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 10.366   Value Loss: 4.397    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 3277362    Buffer Size: 15472      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:08:50,557][train][INFO][train.py>_log] ==> #1241000    Total Loss: 2.561    [weighted Loss:2.561    Policy Loss: 10.139   Value Loss: 4.269    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 3280103    Buffer Size: 15474      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:12:23,290][train][INFO][train.py>_log] ==> #1242000    Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 10.357   Value Loss: 4.537    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 3282871    Buffer Size: 15446      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:15:54,586][train][INFO][train.py>_log] ==> #1243000    Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 10.721   Value Loss: 4.446    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 3285528    Buffer Size: 15427      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:19:30,687][train][INFO][train.py>_log] ==> #1244000    Total Loss: 2.606    [weighted Loss:2.606    Policy Loss: 10.539   Value Loss: 4.134    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 3288335    Buffer Size: 15417      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:23:04,225][train][INFO][train.py>_log] ==> #1245000    Total Loss: 2.330    [weighted Loss:2.330    Policy Loss: 10.325   Value Loss: 4.353    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 3291012    Buffer Size: 15411      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:26:34,975][train][INFO][train.py>_log] ==> #1246000    Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 10.251   Value Loss: 4.320    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 3293680    Buffer Size: 15399      Transition Number: 1000.197k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:30:07,463][train][INFO][train.py>_log] ==> #1247000    Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 10.592   Value Loss: 4.535    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 3296438    Buffer Size: 15400      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:33:38,021][train][INFO][train.py>_log] ==> #1248000    Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 10.319   Value Loss: 4.389    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 3299118    Buffer Size: 15380      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:37:14,264][train][INFO][train.py>_log] ==> #1249000    Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 10.237   Value Loss: 4.035    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 3301897    Buffer Size: 15377      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:40:46,864][train][INFO][train.py>_log] ==> #1250000    Total Loss: 1.751    [weighted Loss:1.751    Policy Loss: 10.352   Value Loss: 4.285    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 3304605    Buffer Size: 15399      Transition Number: 1000.077k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:44:18,624][train][INFO][train.py>_log] ==> #1251000    Total Loss: 0.975    [weighted Loss:0.975    Policy Loss: 10.108   Value Loss: 4.416    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 3307334    Buffer Size: 15423      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:47:50,753][train][INFO][train.py>_log] ==> #1252000    Total Loss: 3.500    [weighted Loss:3.500    Policy Loss: 10.536   Value Loss: 4.137    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 3309959    Buffer Size: 15435      Transition Number: 1000.163k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:51:23,236][train][INFO][train.py>_log] ==> #1253000    Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 10.226   Value Loss: 4.221    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 3312800    Buffer Size: 15440      Transition Number: 1000.381k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:54:53,153][train][INFO][train.py>_log] ==> #1254000    Total Loss: 4.099    [weighted Loss:4.099    Policy Loss: 10.758   Value Loss: 4.362    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 3315390    Buffer Size: 15454      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 22:58:21,584][train][INFO][train.py>_log] ==> #1255000    Total Loss: 3.295    [weighted Loss:3.295    Policy Loss: 10.206   Value Loss: 4.158    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 3318079    Buffer Size: 15445      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:01:50,320][train][INFO][train.py>_log] ==> #1256000    Total Loss: 1.551    [weighted Loss:1.551    Policy Loss: 10.168   Value Loss: 4.139    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 3320697    Buffer Size: 15439      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:05:22,476][train][INFO][train.py>_log] ==> #1257000    Total Loss: 3.050    [weighted Loss:3.050    Policy Loss: 10.825   Value Loss: 4.449    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 3323463    Buffer Size: 15432      Transition Number: 1000.352k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:08:55,557][train][INFO][train.py>_log] ==> #1258000    Total Loss: 1.130    [weighted Loss:1.130    Policy Loss: 10.244   Value Loss: 4.203    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 3326193    Buffer Size: 15442      Transition Number: 1000.205k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:12:32,431][train][INFO][train.py>_log] ==> #1259000    Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 10.357   Value Loss: 4.086    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 3328898    Buffer Size: 15469      Transition Number: 1000.096k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:16:05,252][train][INFO][train.py>_log] ==> #1260000    Total Loss: 0.959    [weighted Loss:0.959    Policy Loss: 10.578   Value Loss: 4.262    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 3331719    Buffer Size: 15464      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:19:36,429][train][INFO][train.py>_log] ==> #1261000    Total Loss: 2.298    [weighted Loss:2.298    Policy Loss: 10.495   Value Loss: 4.178    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 3334391    Buffer Size: 15507      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:23:07,681][train][INFO][train.py>_log] ==> #1262000    Total Loss: 2.942    [weighted Loss:2.942    Policy Loss: 10.494   Value Loss: 4.405    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 3337066    Buffer Size: 15524      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:26:38,591][train][INFO][train.py>_log] ==> #1263000    Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 10.752   Value Loss: 4.162    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 3339821    Buffer Size: 15538      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:30:08,161][train][INFO][train.py>_log] ==> #1264000    Total Loss: 2.772    [weighted Loss:2.772    Policy Loss: 10.180   Value Loss: 4.225    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 3342435    Buffer Size: 15548      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:33:42,098][train][INFO][train.py>_log] ==> #1265000    Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 10.399   Value Loss: 4.014    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 3345169    Buffer Size: 15545      Transition Number: 1000.249k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:37:13,733][train][INFO][train.py>_log] ==> #1266000    Total Loss: 3.131    [weighted Loss:3.131    Policy Loss: 10.295   Value Loss: 4.191    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 3347928    Buffer Size: 15563      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:40:43,824][train][INFO][train.py>_log] ==> #1267000    Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 10.382   Value Loss: 4.670    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 3350625    Buffer Size: 15551      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:44:14,212][train][INFO][train.py>_log] ==> #1268000    Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 10.322   Value Loss: 4.424    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 3353286    Buffer Size: 15548      Transition Number: 1000.208k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:47:45,724][train][INFO][train.py>_log] ==> #1269000    Total Loss: 3.002    [weighted Loss:3.002    Policy Loss: 10.362   Value Loss: 4.805    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 3356003    Buffer Size: 15521      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:51:17,520][train][INFO][train.py>_log] ==> #1270000    Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 10.572   Value Loss: 4.413    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 3358690    Buffer Size: 15537      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:54:48,949][train][INFO][train.py>_log] ==> #1271000    Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 10.803   Value Loss: 4.220    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 3361430    Buffer Size: 15550      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00010 
[2022-02-27 23:58:17,487][train][INFO][train.py>_log] ==> #1272000    Total Loss: 1.330    [weighted Loss:1.330    Policy Loss: 10.490   Value Loss: 4.253    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 3364134    Buffer Size: 15563      Transition Number: 1000.328k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:01:48,324][train][INFO][train.py>_log] ==> #1273000    Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 10.190   Value Loss: 4.595    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 3366816    Buffer Size: 15541      Transition Number: 1000.280k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:05:17,141][train][INFO][train.py>_log] ==> #1274000    Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 10.713   Value Loss: 4.058    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 3369496    Buffer Size: 15536      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:08:53,571][train][INFO][train.py>_log] ==> #1275000    Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 10.518   Value Loss: 4.250    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 3372206    Buffer Size: 15542      Transition Number: 1000.386k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:12:27,507][train][INFO][train.py>_log] ==> #1276000    Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 10.501   Value Loss: 4.292    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 3374951    Buffer Size: 15527      Transition Number: 1000.334k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:15:58,053][train][INFO][train.py>_log] ==> #1277000    Total Loss: 2.092    [weighted Loss:2.092    Policy Loss: 10.460   Value Loss: 4.138    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 3377551    Buffer Size: 15508      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:19:27,571][train][INFO][train.py>_log] ==> #1278000    Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 10.494   Value Loss: 4.158    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 3380381    Buffer Size: 15494      Transition Number: 1000.214k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:22:56,097][train][INFO][train.py>_log] ==> #1279000    Total Loss: 1.502    [weighted Loss:1.502    Policy Loss: 10.851   Value Loss: 4.078    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 3383047    Buffer Size: 15530      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:26:27,644][train][INFO][train.py>_log] ==> #1280000    Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 10.943   Value Loss: 4.109    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 3385720    Buffer Size: 15536      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:29:55,055][train][INFO][train.py>_log] ==> #1281000    Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 10.626   Value Loss: 4.088    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 3388296    Buffer Size: 15537      Transition Number: 1000.275k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:33:27,963][train][INFO][train.py>_log] ==> #1282000    Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 10.494   Value Loss: 4.182    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 3391146    Buffer Size: 15539      Transition Number: 1000.422k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:36:57,770][train][INFO][train.py>_log] ==> #1283000    Total Loss: 2.088    [weighted Loss:2.088    Policy Loss: 10.787   Value Loss: 4.475    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 3393737    Buffer Size: 15542      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:40:25,539][train][INFO][train.py>_log] ==> #1284000    Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 10.501   Value Loss: 4.230    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 3396471    Buffer Size: 15551      Transition Number: 1000.634k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:43:56,797][train][INFO][train.py>_log] ==> #1285000    Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 10.746   Value Loss: 4.478    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 3399133    Buffer Size: 15534      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:47:26,497][train][INFO][train.py>_log] ==> #1286000    Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 10.321   Value Loss: 4.217    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 3401792    Buffer Size: 15554      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:50:56,112][train][INFO][train.py>_log] ==> #1287000    Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 10.357   Value Loss: 4.199    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 3404604    Buffer Size: 15577      Transition Number: 1000.413k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:54:27,672][train][INFO][train.py>_log] ==> #1288000    Total Loss: 3.246    [weighted Loss:3.246    Policy Loss: 10.626   Value Loss: 4.134    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 3407327    Buffer Size: 15586      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00010 
[2022-02-28 00:57:59,075][train][INFO][train.py>_log] ==> #1289000    Total Loss: 2.862    [weighted Loss:2.862    Policy Loss: 10.350   Value Loss: 4.257    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 3409992    Buffer Size: 15618      Transition Number: 1000.499k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:01:32,602][train][INFO][train.py>_log] ==> #1290000    Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 10.313   Value Loss: 4.412    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 3412684    Buffer Size: 15610      Transition Number: 1000.668k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:05:12,614][train][INFO][train.py>_log] ==> #1291000    Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 10.652   Value Loss: 4.429    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 3415553    Buffer Size: 15609      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:08:45,585][train][INFO][train.py>_log] ==> #1292000    Total Loss: 1.999    [weighted Loss:1.999    Policy Loss: 10.398   Value Loss: 4.270    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 3418211    Buffer Size: 15593      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:12:12,893][train][INFO][train.py>_log] ==> #1293000    Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 10.552   Value Loss: 4.416    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 3420947    Buffer Size: 15618      Transition Number: 1000.431k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:15:47,352][train][INFO][train.py>_log] ==> #1294000    Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 10.499   Value Loss: 4.555    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 3423691    Buffer Size: 15601      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:19:18,925][train][INFO][train.py>_log] ==> #1295000    Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 10.633   Value Loss: 4.204    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 3426390    Buffer Size: 15623      Transition Number: 1000.262k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:22:44,024][train][INFO][train.py>_log] ==> #1296000    Total Loss: 2.416    [weighted Loss:2.416    Policy Loss: 10.610   Value Loss: 4.116    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 3429014    Buffer Size: 15632      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:26:12,892][train][INFO][train.py>_log] ==> #1297000    Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 10.704   Value Loss: 4.219    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 3431721    Buffer Size: 15642      Transition Number: 1000.256k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:29:42,572][train][INFO][train.py>_log] ==> #1298000    Total Loss: 1.236    [weighted Loss:1.236    Policy Loss: 10.991   Value Loss: 4.120    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 3434405    Buffer Size: 15652      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:33:12,618][train][INFO][train.py>_log] ==> #1299000    Total Loss: 2.817    [weighted Loss:2.817    Policy Loss: 10.850   Value Loss: 4.349    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 3437134    Buffer Size: 15640      Transition Number: 1000.323k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:36:45,119][train][INFO][train.py>_log] ==> #1300000    Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 10.779   Value Loss: 4.172    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 3439880    Buffer Size: 15614      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:40:17,335][train][INFO][train.py>_log] ==> #1301000    Total Loss: 2.694    [weighted Loss:2.694    Policy Loss: 10.584   Value Loss: 4.346    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 3442493    Buffer Size: 15600      Transition Number: 1000.133k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:43:46,542][train][INFO][train.py>_log] ==> #1302000    Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 10.819   Value Loss: 4.309    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 3445233    Buffer Size: 15606      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:47:19,211][train][INFO][train.py>_log] ==> #1303000    Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 10.562   Value Loss: 4.118    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 3447938    Buffer Size: 15621      Transition Number: 1000.526k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:50:54,623][train][INFO][train.py>_log] ==> #1304000    Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 10.814   Value Loss: 4.066    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 3450730    Buffer Size: 15625      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:54:27,124][train][INFO][train.py>_log] ==> #1305000    Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 10.846   Value Loss: 4.258    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 3453494    Buffer Size: 15641      Transition Number: 1000.417k Batch Size: 256        Lr: 0.00010 
[2022-02-28 01:57:56,930][train][INFO][train.py>_log] ==> #1306000    Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 10.155   Value Loss: 4.547    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 3456143    Buffer Size: 15672      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:01:25,827][train][INFO][train.py>_log] ==> #1307000    Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 10.629   Value Loss: 4.185    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 3458834    Buffer Size: 15676      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:04:53,028][train][INFO][train.py>_log] ==> #1308000    Total Loss: 0.950    [weighted Loss:0.950    Policy Loss: 10.593   Value Loss: 4.253    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 3461445    Buffer Size: 15662      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:08:24,689][train][INFO][train.py>_log] ==> #1309000    Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 10.353   Value Loss: 4.172    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 3464151    Buffer Size: 15670      Transition Number: 1000.215k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:11:55,136][train][INFO][train.py>_log] ==> #1310000    Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 10.603   Value Loss: 4.454    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 3466865    Buffer Size: 15653      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:15:26,804][train][INFO][train.py>_log] ==> #1311000    Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 10.213   Value Loss: 4.743    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 3469638    Buffer Size: 15640      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:18:56,117][train][INFO][train.py>_log] ==> #1312000    Total Loss: 0.998    [weighted Loss:0.998    Policy Loss: 10.251   Value Loss: 4.506    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 3472278    Buffer Size: 15642      Transition Number: 1000.092k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:22:28,882][train][INFO][train.py>_log] ==> #1313000    Total Loss: 2.666    [weighted Loss:2.666    Policy Loss: 10.484   Value Loss: 4.077    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 3475003    Buffer Size: 15661      Transition Number: 1000.356k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:25:59,522][train][INFO][train.py>_log] ==> #1314000    Total Loss: 3.145    [weighted Loss:3.145    Policy Loss: 10.392   Value Loss: 4.741    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 3477704    Buffer Size: 15667      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:29:32,677][train][INFO][train.py>_log] ==> #1315000    Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 10.297   Value Loss: 4.371    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 3480454    Buffer Size: 15675      Transition Number: 1000.193k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:33:03,262][train][INFO][train.py>_log] ==> #1316000    Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 10.642   Value Loss: 4.169    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 3483108    Buffer Size: 15672      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:36:33,963][train][INFO][train.py>_log] ==> #1317000    Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 10.628   Value Loss: 4.129    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 3485756    Buffer Size: 15683      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:40:03,752][train][INFO][train.py>_log] ==> #1318000    Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 10.271   Value Loss: 4.302    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 3488468    Buffer Size: 15682      Transition Number: 1000.095k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:43:33,175][train][INFO][train.py>_log] ==> #1319000    Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 10.307   Value Loss: 4.164    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 3491152    Buffer Size: 15682      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:47:05,675][train][INFO][train.py>_log] ==> #1320000    Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 10.612   Value Loss: 4.396    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 3493936    Buffer Size: 15680      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:50:37,122][train][INFO][train.py>_log] ==> #1321000    Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 10.341   Value Loss: 4.371    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 3496538    Buffer Size: 15704      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:54:14,298][train][INFO][train.py>_log] ==> #1322000    Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 10.925   Value Loss: 4.442    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 3499388    Buffer Size: 15729      Transition Number: 1000.972k Batch Size: 256        Lr: 0.00010 
[2022-02-28 02:57:46,084][train][INFO][train.py>_log] ==> #1323000    Total Loss: 2.608    [weighted Loss:2.608    Policy Loss: 10.821   Value Loss: 4.088    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 3502134    Buffer Size: 15726      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:01:18,398][train][INFO][train.py>_log] ==> #1324000    Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 10.594   Value Loss: 4.207    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 3504848    Buffer Size: 15726      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:04:53,046][train][INFO][train.py>_log] ==> #1325000    Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 10.486   Value Loss: 4.401    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 3507607    Buffer Size: 15712      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:08:26,980][train][INFO][train.py>_log] ==> #1326000    Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 10.971   Value Loss: 4.224    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 3510267    Buffer Size: 15713      Transition Number: 1000.217k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:11:57,927][train][INFO][train.py>_log] ==> #1327000    Total Loss: 3.087    [weighted Loss:3.087    Policy Loss: 10.681   Value Loss: 4.373    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 3513016    Buffer Size: 15716      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:15:28,468][train][INFO][train.py>_log] ==> #1328000    Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 10.240   Value Loss: 4.371    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 3515692    Buffer Size: 15721      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:19:01,105][train][INFO][train.py>_log] ==> #1329000    Total Loss: 3.647    [weighted Loss:3.647    Policy Loss: 10.466   Value Loss: 4.122    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 3518517    Buffer Size: 15711      Transition Number: 1000.106k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:22:33,287][train][INFO][train.py>_log] ==> #1330000    Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 10.857   Value Loss: 4.280    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 3521117    Buffer Size: 15749      Transition Number: 1000.271k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:26:04,724][train][INFO][train.py>_log] ==> #1331000    Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 10.352   Value Loss: 4.068    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 3523865    Buffer Size: 15747      Transition Number: 1000.165k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:29:36,604][train][INFO][train.py>_log] ==> #1332000    Total Loss: 1.547    [weighted Loss:1.547    Policy Loss: 10.439   Value Loss: 4.329    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 3526567    Buffer Size: 15763      Transition Number: 1000.133k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:33:10,153][train][INFO][train.py>_log] ==> #1333000    Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 10.826   Value Loss: 4.246    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 3529329    Buffer Size: 15743      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:36:41,577][train][INFO][train.py>_log] ==> #1334000    Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 10.380   Value Loss: 4.525    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 3532025    Buffer Size: 15716      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:40:09,960][train][INFO][train.py>_log] ==> #1335000    Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 10.317   Value Loss: 4.392    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 3534663    Buffer Size: 15697      Transition Number: 1000.201k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:43:42,524][train][INFO][train.py>_log] ==> #1336000    Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 10.751   Value Loss: 4.394    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 3537359    Buffer Size: 15682      Transition Number: 1000.689k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:47:16,004][train][INFO][train.py>_log] ==> #1337000    Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 10.856   Value Loss: 4.397    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 3540163    Buffer Size: 15664      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:50:47,075][train][INFO][train.py>_log] ==> #1338000    Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 10.761   Value Loss: 4.175    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 3542881    Buffer Size: 15641      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:54:22,239][train][INFO][train.py>_log] ==> #1339000    Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 10.531   Value Loss: 4.061    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 3545597    Buffer Size: 15657      Transition Number: 1000.038k Batch Size: 256        Lr: 0.00010 
[2022-02-28 03:57:48,608][train][INFO][train.py>_log] ==> #1340000    Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 10.290   Value Loss: 4.251    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 3548165    Buffer Size: 15666      Transition Number: 1000.208k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:01:23,323][train][INFO][train.py>_log] ==> #1341000    Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 10.539   Value Loss: 4.494    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 3550965    Buffer Size: 15682      Transition Number: 1000.427k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:04:53,234][train][INFO][train.py>_log] ==> #1342000    Total Loss: 1.552    [weighted Loss:1.552    Policy Loss: 10.387   Value Loss: 4.397    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 3553737    Buffer Size: 15680      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:08:20,770][train][INFO][train.py>_log] ==> #1343000    Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 10.465   Value Loss: 4.471    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 3556348    Buffer Size: 15686      Transition Number: 1000.286k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:11:49,681][train][INFO][train.py>_log] ==> #1344000    Total Loss: 1.325    [weighted Loss:1.325    Policy Loss: 10.494   Value Loss: 4.407    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 3559074    Buffer Size: 15690      Transition Number: 1000.300k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:15:24,125][train][INFO][train.py>_log] ==> #1345000    Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 10.457   Value Loss: 4.149    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 3561743    Buffer Size: 15690      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:18:54,797][train][INFO][train.py>_log] ==> #1346000    Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 10.521   Value Loss: 4.310    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 3564468    Buffer Size: 15682      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:22:26,724][train][INFO][train.py>_log] ==> #1347000    Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 10.373   Value Loss: 4.203    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 3567171    Buffer Size: 15692      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:25:56,563][train][INFO][train.py>_log] ==> #1348000    Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 10.539   Value Loss: 4.060    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 3569875    Buffer Size: 15702      Transition Number: 1000.121k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:29:28,938][train][INFO][train.py>_log] ==> #1349000    Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 10.481   Value Loss: 4.281    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 3572571    Buffer Size: 15702      Transition Number: 1000.153k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:33:04,274][train][INFO][train.py>_log] ==> #1350000    Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 10.510   Value Loss: 4.301    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 3575429    Buffer Size: 15688      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:36:30,237][train][INFO][train.py>_log] ==> #1351000    Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 10.548   Value Loss: 4.100    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 3577962    Buffer Size: 15676      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:40:01,705][train][INFO][train.py>_log] ==> #1352000    Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 10.758   Value Loss: 4.196    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 3580687    Buffer Size: 15663      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:43:31,115][train][INFO][train.py>_log] ==> #1353000    Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 10.527   Value Loss: 4.659    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 3583373    Buffer Size: 15673      Transition Number: 1000.641k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:47:00,662][train][INFO][train.py>_log] ==> #1354000    Total Loss: 2.154    [weighted Loss:2.154    Policy Loss: 10.566   Value Loss: 4.382    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 3586047    Buffer Size: 15635      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:50:31,090][train][INFO][train.py>_log] ==> #1355000    Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 10.479   Value Loss: 4.157    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 3588765    Buffer Size: 15653      Transition Number: 1000.285k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:54:00,004][train][INFO][train.py>_log] ==> #1356000    Total Loss: 3.067    [weighted Loss:3.067    Policy Loss: 10.649   Value Loss: 4.094    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 3591386    Buffer Size: 15663      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00010 
[2022-02-28 04:57:31,983][train][INFO][train.py>_log] ==> #1357000    Total Loss: 2.385    [weighted Loss:2.385    Policy Loss: 10.438   Value Loss: 4.315    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 3594111    Buffer Size: 15665      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:01:08,249][train][INFO][train.py>_log] ==> #1358000    Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 10.361   Value Loss: 4.328    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 3596860    Buffer Size: 15676      Transition Number: 1000.116k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:04:36,508][train][INFO][train.py>_log] ==> #1359000    Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 10.299   Value Loss: 4.510    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 3599570    Buffer Size: 15670      Transition Number: 1000.451k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:08:12,608][train][INFO][train.py>_log] ==> #1360000    Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 10.798   Value Loss: 4.338    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 3602257    Buffer Size: 15679      Transition Number: 1000.350k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:11:46,893][train][INFO][train.py>_log] ==> #1361000    Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 10.523   Value Loss: 4.163    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 3605093    Buffer Size: 15658      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:15:20,204][train][INFO][train.py>_log] ==> #1362000    Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 10.436   Value Loss: 4.344    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 3607766    Buffer Size: 15659      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:18:52,289][train][INFO][train.py>_log] ==> #1363000    Total Loss: 2.769    [weighted Loss:2.769    Policy Loss: 10.533   Value Loss: 4.256    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 3610516    Buffer Size: 15677      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:22:22,816][train][INFO][train.py>_log] ==> #1364000    Total Loss: 2.871    [weighted Loss:2.871    Policy Loss: 10.201   Value Loss: 4.044    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 3613187    Buffer Size: 15686      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:25:52,864][train][INFO][train.py>_log] ==> #1365000    Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 10.470   Value Loss: 4.406    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 3615940    Buffer Size: 15696      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:29:25,013][train][INFO][train.py>_log] ==> #1366000    Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 10.350   Value Loss: 4.355    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 3618673    Buffer Size: 15712      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:32:55,689][train][INFO][train.py>_log] ==> #1367000    Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 10.906   Value Loss: 4.282    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 3621311    Buffer Size: 15700      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:36:25,336][train][INFO][train.py>_log] ==> #1368000    Total Loss: 2.860    [weighted Loss:2.860    Policy Loss: 10.421   Value Loss: 4.380    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 3624008    Buffer Size: 15697      Transition Number: 1000.304k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:39:57,306][train][INFO][train.py>_log] ==> #1369000    Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 10.620   Value Loss: 4.413    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 3626722    Buffer Size: 15697      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:43:29,223][train][INFO][train.py>_log] ==> #1370000    Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 10.334   Value Loss: 4.351    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 3629473    Buffer Size: 15692      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:47:01,751][train][INFO][train.py>_log] ==> #1371000    Total Loss: 2.335    [weighted Loss:2.335    Policy Loss: 10.411   Value Loss: 4.601    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 3632194    Buffer Size: 15707      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:50:36,445][train][INFO][train.py>_log] ==> #1372000    Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 10.205   Value Loss: 4.430    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 3634996    Buffer Size: 15695      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:54:12,070][train][INFO][train.py>_log] ==> #1373000    Total Loss: 2.324    [weighted Loss:2.324    Policy Loss: 10.631   Value Loss: 4.314    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 3637712    Buffer Size: 15692      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00010 
[2022-02-28 05:57:43,159][train][INFO][train.py>_log] ==> #1374000    Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 10.544   Value Loss: 4.356    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 3640399    Buffer Size: 15697      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00010 
