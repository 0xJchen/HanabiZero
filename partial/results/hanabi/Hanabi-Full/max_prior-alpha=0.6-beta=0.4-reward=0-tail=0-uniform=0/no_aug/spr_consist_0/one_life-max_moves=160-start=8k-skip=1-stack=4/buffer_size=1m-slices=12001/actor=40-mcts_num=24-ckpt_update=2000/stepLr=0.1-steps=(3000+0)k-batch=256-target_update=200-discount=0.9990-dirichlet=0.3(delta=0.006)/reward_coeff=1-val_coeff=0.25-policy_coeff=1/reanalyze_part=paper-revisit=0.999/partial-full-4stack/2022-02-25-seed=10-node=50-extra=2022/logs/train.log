[2022-02-25 03:09:48,134][train][INFO][train.py>_log] ==> #0          Total Loss: 47.801   [weighted Loss:47.801   Policy Loss: 13.329   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1448       Buffer Size: 1448       Transition Number: 15.340  k Batch Size: 256        Lr: 0.00000 
[2022-02-25 03:12:33,615][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.156    [weighted Loss:7.156    Policy Loss: 13.957   Value Loss: 4.497    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 12061      Buffer Size: 12061      Transition Number: 150.852 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:15:22,948][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.869    [weighted Loss:4.869    Policy Loss: 13.729   Value Loss: 4.380    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 22675      Buffer Size: 22675      Transition Number: 282.566 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:18:13,395][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.290    [weighted Loss:6.290    Policy Loss: 12.790   Value Loss: 4.075    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 39376      Buffer Size: 39376      Transition Number: 420.323 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:21:06,082][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.522    [weighted Loss:5.522    Policy Loss: 11.832   Value Loss: 4.300    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 56345      Buffer Size: 56345      Transition Number: 557.612 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:23:59,687][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.805    [weighted Loss:4.805    Policy Loss: 10.262   Value Loss: 4.064    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 73965      Buffer Size: 73965      Transition Number: 697.845 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:27:00,935][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.621    [weighted Loss:4.621    Policy Loss: 9.927    Value Loss: 3.830    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 92376      Buffer Size: 92376      Transition Number: 843.936 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:29:59,814][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.429    [weighted Loss:5.429    Policy Loss: 10.884   Value Loss: 4.050    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 106789     Buffer Size: 106789     Transition Number: 983.516 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:33:02,387][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.957    [weighted Loss:4.957    Policy Loss: 9.992    Value Loss: 4.148    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 121574     Buffer Size: 111374     Transition Number: 1000.347k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:36:07,898][train][INFO][train.py>_log] ==> #9000       Total Loss: 5.039    [weighted Loss:5.039    Policy Loss: 8.718    Value Loss: 4.384    Reward Loss: 1.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 138241     Buffer Size: 115984     Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:39:14,385][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.591    [weighted Loss:3.591    Policy Loss: 7.149    Value Loss: 3.997    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 154733     Buffer Size: 114866     Transition Number: 1000.141k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:42:24,016][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 7.388    Value Loss: 4.169    Reward Loss: 2.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 173130     Buffer Size: 114386     Transition Number: 1000.131k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:45:36,571][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.146    [weighted Loss:4.146    Policy Loss: 8.204    Value Loss: 3.960    Reward Loss: 2.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 192004     Buffer Size: 113766     Transition Number: 1000.304k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:48:44,246][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 8.462    Value Loss: 4.224    Reward Loss: 2.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 207099     Buffer Size: 110687     Transition Number: 1000.023k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:51:48,492][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 8.741    Value Loss: 4.235    Reward Loss: 2.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 221954     Buffer Size: 110527     Transition Number: 1000.172k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:54:51,041][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.946    [weighted Loss:3.946    Policy Loss: 8.163    Value Loss: 4.119    Reward Loss: 2.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 236446     Buffer Size: 109639     Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-25 03:57:57,023][train][INFO][train.py>_log] ==> #16000      Total Loss: 5.233    [weighted Loss:5.233    Policy Loss: 9.937    Value Loss: 4.328    Reward Loss: 2.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 250936     Buffer Size: 107736     Transition Number: 1000.174k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:01:02,250][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.001    [weighted Loss:4.001    Policy Loss: 9.634    Value Loss: 4.145    Reward Loss: 2.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 264748     Buffer Size: 104696     Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:04:11,568][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.963    [weighted Loss:5.963    Policy Loss: 8.370    Value Loss: 4.564    Reward Loss: 2.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 278925     Buffer Size: 100472     Transition Number: 1000.135k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:07:13,732][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 9.427    Value Loss: 4.549    Reward Loss: 2.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 289949     Buffer Size: 94507      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:10:18,311][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.271    [weighted Loss:5.271    Policy Loss: 8.889    Value Loss: 4.482    Reward Loss: 2.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 301056     Buffer Size: 90969      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:13:17,380][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.315    [weighted Loss:5.315    Policy Loss: 8.919    Value Loss: 4.531    Reward Loss: 2.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 308088     Buffer Size: 84433      Transition Number: 1000.199k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:16:20,363][train][INFO][train.py>_log] ==> #22000      Total Loss: 5.528    [weighted Loss:5.528    Policy Loss: 9.286    Value Loss: 4.564    Reward Loss: 2.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 315158     Buffer Size: 77782      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:19:21,780][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.449    [weighted Loss:4.449    Policy Loss: 7.647    Value Loss: 4.814    Reward Loss: 2.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 320731     Buffer Size: 70119      Transition Number: 1000.207k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:22:21,354][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.470    [weighted Loss:3.470    Policy Loss: 7.243    Value Loss: 4.983    Reward Loss: 2.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 326202     Buffer Size: 62888      Transition Number: 1000.273k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:25:22,484][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.799    [weighted Loss:4.799    Policy Loss: 6.291    Value Loss: 4.926    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 329043     Buffer Size: 55399      Transition Number: 1000.149k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:28:22,965][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 5.459    Value Loss: 4.579    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 332051     Buffer Size: 47310      Transition Number: 1000.262k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:31:23,772][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 7.274    Value Loss: 4.934    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 333991     Buffer Size: 40294      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:34:25,197][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 4.296    Value Loss: 4.333    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 336079     Buffer Size: 33100      Transition Number: 1000.180k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:37:28,297][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 4.355    Value Loss: 4.589    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 337961     Buffer Size: 28249      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:40:28,829][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.755    [weighted Loss:1.755    Policy Loss: 4.041    Value Loss: 4.547    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 339951     Buffer Size: 23245      Transition Number: 1000.276k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:43:28,601][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 4.378    Value Loss: 4.618    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 341891     Buffer Size: 19700      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:46:31,553][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 3.971    Value Loss: 4.283    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 343937     Buffer Size: 16490      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:49:31,063][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.857    [weighted Loss:1.857    Policy Loss: 4.644    Value Loss: 4.284    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 345774     Buffer Size: 15323      Transition Number: 1000.132k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:52:29,666][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.388    [weighted Loss:2.388    Policy Loss: 4.297    Value Loss: 4.344    Reward Loss: 0.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 347666     Buffer Size: 14556      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:55:33,571][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 4.448    Value Loss: 4.518    Reward Loss: 0.971    Consistency Loss: 0.000    ] Replay Episodes Collected: 349700     Buffer Size: 14430      Transition Number: 1000.061k Batch Size: 256        Lr: 0.10000 
[2022-02-25 04:58:33,017][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.650    [weighted Loss:1.650    Policy Loss: 4.402    Value Loss: 4.628    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 351685     Buffer Size: 14482      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:01:35,308][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 4.325    Value Loss: 4.763    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 353761     Buffer Size: 14707      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:04:35,220][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 4.269    Value Loss: 5.348    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 355823     Buffer Size: 14917      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:07:34,646][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 4.727    Value Loss: 5.331    Reward Loss: 1.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 357800     Buffer Size: 15006      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:10:36,564][train][INFO][train.py>_log] ==> #40000      Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 4.394    Value Loss: 5.022    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 359788     Buffer Size: 15108      Transition Number: 1000.316k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:13:38,659][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 3.926    Value Loss: 5.003    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 361721     Buffer Size: 15104      Transition Number: 1000.247k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:16:39,161][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.368    [weighted Loss:2.368    Policy Loss: 4.023    Value Loss: 4.767    Reward Loss: 0.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 363624     Buffer Size: 15065      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:19:39,629][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.865    [weighted Loss:1.865    Policy Loss: 4.241    Value Loss: 4.986    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 365591     Buffer Size: 14865      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:22:41,193][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.077    [weighted Loss:2.077    Policy Loss: 4.111    Value Loss: 4.679    Reward Loss: 0.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 367560     Buffer Size: 14596      Transition Number: 1000.264k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:25:39,837][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 4.270    Value Loss: 4.971    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 369609     Buffer Size: 14378      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:28:40,705][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 4.809    Value Loss: 4.865    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 371578     Buffer Size: 14260      Transition Number: 1000.336k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:31:42,664][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 4.751    Value Loss: 4.905    Reward Loss: 0.948    Consistency Loss: 0.000    ] Replay Episodes Collected: 373588     Buffer Size: 14199      Transition Number: 1000.654k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:34:41,271][train][INFO][train.py>_log] ==> #48000      Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 5.495    Value Loss: 4.256    Reward Loss: 0.981    Consistency Loss: 0.000    ] Replay Episodes Collected: 375530     Buffer Size: 14225      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:37:43,374][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 5.294    Value Loss: 4.677    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 377547     Buffer Size: 14294      Transition Number: 1000.205k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:40:43,681][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.693    [weighted Loss:2.693    Policy Loss: 5.646    Value Loss: 4.454    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 379549     Buffer Size: 14423      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:43:44,060][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.780    [weighted Loss:2.780    Policy Loss: 5.747    Value Loss: 4.903    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 381590     Buffer Size: 14519      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:46:47,553][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 5.669    Value Loss: 4.593    Reward Loss: 1.002    Consistency Loss: 0.000    ] Replay Episodes Collected: 383635     Buffer Size: 14543      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:49:49,467][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 5.685    Value Loss: 4.795    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 385622     Buffer Size: 14535      Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:52:48,253][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 5.788    Value Loss: 4.628    Reward Loss: 1.005    Consistency Loss: 0.000    ] Replay Episodes Collected: 387624     Buffer Size: 14497      Transition Number: 1000.136k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:55:49,642][train][INFO][train.py>_log] ==> #55000      Total Loss: 1.417    [weighted Loss:1.417    Policy Loss: 5.726    Value Loss: 4.822    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 389799     Buffer Size: 14666      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-25 05:58:51,587][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 6.074    Value Loss: 4.921    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 391981     Buffer Size: 14872      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:01:51,729][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 5.898    Value Loss: 4.682    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 393894     Buffer Size: 14854      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:04:51,422][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 6.944    Value Loss: 4.775    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 395890     Buffer Size: 14867      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:07:51,812][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 6.531    Value Loss: 4.916    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 397878     Buffer Size: 14868      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:10:51,120][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.579    [weighted Loss:3.579    Policy Loss: 6.634    Value Loss: 4.526    Reward Loss: 0.980    Consistency Loss: 0.000    ] Replay Episodes Collected: 399849     Buffer Size: 14912      Transition Number: 1000.542k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:13:50,651][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 6.738    Value Loss: 5.018    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 401829     Buffer Size: 14941      Transition Number: 1000.047k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:16:52,776][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.703    [weighted Loss:3.703    Policy Loss: 6.931    Value Loss: 4.481    Reward Loss: 0.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 403863     Buffer Size: 14865      Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:19:53,228][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 7.511    Value Loss: 4.603    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 405996     Buffer Size: 14796      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:22:52,188][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 7.873    Value Loss: 4.924    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 408103     Buffer Size: 14796      Transition Number: 1000.578k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:25:51,591][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.244    [weighted Loss:3.244    Policy Loss: 7.978    Value Loss: 5.154    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 409929     Buffer Size: 14877      Transition Number: 1000.317k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:28:51,571][train][INFO][train.py>_log] ==> #66000      Total Loss: 4.069    [weighted Loss:4.069    Policy Loss: 8.017    Value Loss: 4.914    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 411934     Buffer Size: 14927      Transition Number: 1000.316k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:31:54,423][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.571    [weighted Loss:1.571    Policy Loss: 7.919    Value Loss: 4.687    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 413992     Buffer Size: 14993      Transition Number: 999.939 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:34:54,981][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.157    [weighted Loss:4.157    Policy Loss: 8.583    Value Loss: 4.539    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 416072     Buffer Size: 15094      Transition Number: 1000.151k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:37:54,158][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.575    [weighted Loss:3.575    Policy Loss: 7.837    Value Loss: 5.426    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 418349     Buffer Size: 15422      Transition Number: 1000.007k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:40:58,707][train][INFO][train.py>_log] ==> #70000      Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 7.964    Value Loss: 5.125    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 420644     Buffer Size: 15731      Transition Number: 1000.117k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:43:58,238][train][INFO][train.py>_log] ==> #71000      Total Loss: 5.411    [weighted Loss:5.411    Policy Loss: 9.006    Value Loss: 4.846    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 422764     Buffer Size: 15861      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:46:53,478][train][INFO][train.py>_log] ==> #72000      Total Loss: 1.472    [weighted Loss:1.472    Policy Loss: 10.282   Value Loss: 5.233    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 424838     Buffer Size: 16029      Transition Number: 1000.452k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:49:55,932][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 9.813    Value Loss: 5.215    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 426838     Buffer Size: 16127      Transition Number: 1000.405k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:52:56,459][train][INFO][train.py>_log] ==> #74000      Total Loss: 5.663    [weighted Loss:5.663    Policy Loss: 10.063   Value Loss: 5.085    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 428864     Buffer Size: 16177      Transition Number: 1000.349k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:55:58,772][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.049    [weighted Loss:4.049    Policy Loss: 9.951    Value Loss: 5.170    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 430875     Buffer Size: 16209      Transition Number: 1000.234k Batch Size: 256        Lr: 0.10000 
[2022-02-25 06:59:00,121][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.411    [weighted Loss:4.411    Policy Loss: 10.127   Value Loss: 5.252    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 432898     Buffer Size: 16158      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:02:03,159][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.256    [weighted Loss:4.256    Policy Loss: 10.677   Value Loss: 5.398    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 435085     Buffer Size: 15919      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:05:03,940][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.823    [weighted Loss:4.823    Policy Loss: 10.434   Value Loss: 5.010    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 437153     Buffer Size: 15722      Transition Number: 1000.488k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:08:08,990][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 10.947   Value Loss: 5.209    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 439325     Buffer Size: 15587      Transition Number: 1000.320k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:11:11,733][train][INFO][train.py>_log] ==> #80000      Total Loss: 5.060    [weighted Loss:5.060    Policy Loss: 11.106   Value Loss: 5.365    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 441459     Buffer Size: 15505      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:14:13,950][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.581    [weighted Loss:4.581    Policy Loss: 10.422   Value Loss: 5.141    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 443594     Buffer Size: 15599      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:17:17,686][train][INFO][train.py>_log] ==> #82000      Total Loss: 4.787    [weighted Loss:4.787    Policy Loss: 9.939    Value Loss: 5.154    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 445763     Buffer Size: 15724      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:20:20,922][train][INFO][train.py>_log] ==> #83000      Total Loss: 5.466    [weighted Loss:5.466    Policy Loss: 9.672    Value Loss: 4.771    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 447909     Buffer Size: 15800      Transition Number: 1000.235k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:23:19,611][train][INFO][train.py>_log] ==> #84000      Total Loss: 5.156    [weighted Loss:5.156    Policy Loss: 9.615    Value Loss: 5.237    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 449968     Buffer Size: 15862      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:26:19,084][train][INFO][train.py>_log] ==> #85000      Total Loss: 4.105    [weighted Loss:4.105    Policy Loss: 9.474    Value Loss: 5.195    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 451922     Buffer Size: 15763      Transition Number: 1000.564k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:29:19,870][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.072    [weighted Loss:4.072    Policy Loss: 9.444    Value Loss: 4.932    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 453925     Buffer Size: 15702      Transition Number: 1000.220k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:32:18,057][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.564    [weighted Loss:4.564    Policy Loss: 8.920    Value Loss: 5.362    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 455930     Buffer Size: 15636      Transition Number: 1000.160k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:35:20,193][train][INFO][train.py>_log] ==> #88000      Total Loss: 3.674    [weighted Loss:3.674    Policy Loss: 9.342    Value Loss: 5.130    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 457958     Buffer Size: 15580      Transition Number: 1000.141k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:38:22,963][train][INFO][train.py>_log] ==> #89000      Total Loss: 5.010    [weighted Loss:5.010    Policy Loss: 8.931    Value Loss: 4.863    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 459970     Buffer Size: 15399      Transition Number: 1000.326k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:41:22,933][train][INFO][train.py>_log] ==> #90000      Total Loss: 4.242    [weighted Loss:4.242    Policy Loss: 9.606    Value Loss: 4.991    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 462009     Buffer Size: 15228      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:44:23,623][train][INFO][train.py>_log] ==> #91000      Total Loss: 4.498    [weighted Loss:4.498    Policy Loss: 8.849    Value Loss: 5.004    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 464001     Buffer Size: 15052      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:47:26,759][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.167    [weighted Loss:4.167    Policy Loss: 9.023    Value Loss: 4.839    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 466024     Buffer Size: 14982      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:50:24,603][train][INFO][train.py>_log] ==> #93000      Total Loss: 4.021    [weighted Loss:4.021    Policy Loss: 9.057    Value Loss: 4.750    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 468011     Buffer Size: 14969      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:53:24,577][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.372    [weighted Loss:4.372    Policy Loss: 9.384    Value Loss: 4.858    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 470019     Buffer Size: 14957      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:56:27,041][train][INFO][train.py>_log] ==> #95000      Total Loss: 4.444    [weighted Loss:4.444    Policy Loss: 9.103    Value Loss: 4.779    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 472089     Buffer Size: 14883      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-02-25 07:59:26,989][train][INFO][train.py>_log] ==> #96000      Total Loss: 4.894    [weighted Loss:4.894    Policy Loss: 9.430    Value Loss: 4.460    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 474136     Buffer Size: 14845      Transition Number: 1000.218k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:02:27,697][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.867    [weighted Loss:2.867    Policy Loss: 9.011    Value Loss: 4.817    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 476210     Buffer Size: 14829      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:05:31,345][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.846    [weighted Loss:3.846    Policy Loss: 9.427    Value Loss: 4.650    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 478325     Buffer Size: 14841      Transition Number: 1000.171k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:08:30,551][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.449    [weighted Loss:3.449    Policy Loss: 9.459    Value Loss: 4.757    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 480466     Buffer Size: 14891      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:11:30,542][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 9.597    Value Loss: 4.800    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 482531     Buffer Size: 14909      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:14:33,547][train][INFO][train.py>_log] ==> #101000     Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 8.884    Value Loss: 4.663    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 484599     Buffer Size: 14908      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:17:34,972][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.623    [weighted Loss:3.623    Policy Loss: 9.810    Value Loss: 5.162    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 486707     Buffer Size: 14939      Transition Number: 1000.214k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:20:39,320][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.927    [weighted Loss:2.927    Policy Loss: 9.166    Value Loss: 4.995    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 488865     Buffer Size: 15029      Transition Number: 1000.143k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:23:40,489][train][INFO][train.py>_log] ==> #104000     Total Loss: 5.357    [weighted Loss:5.357    Policy Loss: 9.317    Value Loss: 5.227    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 490905     Buffer Size: 15130      Transition Number: 1000.393k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:26:40,277][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.957    [weighted Loss:4.957    Policy Loss: 9.298    Value Loss: 4.885    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 492967     Buffer Size: 15189      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:29:43,987][train][INFO][train.py>_log] ==> #106000     Total Loss: 4.902    [weighted Loss:4.902    Policy Loss: 9.720    Value Loss: 4.841    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 495018     Buffer Size: 15220      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:32:45,970][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 9.488    Value Loss: 5.157    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 497068     Buffer Size: 15189      Transition Number: 1000.027k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:35:47,082][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.282    [weighted Loss:4.282    Policy Loss: 9.350    Value Loss: 4.971    Reward Loss: 1.325    Consistency Loss: 0.000    ] Replay Episodes Collected: 499156     Buffer Size: 15184      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:38:50,459][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 8.932    Value Loss: 5.073    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 501328     Buffer Size: 15314      Transition Number: 1000.224k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:41:49,688][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 9.425    Value Loss: 5.227    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 503458     Buffer Size: 15402      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:44:49,890][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.719    [weighted Loss:3.719    Policy Loss: 9.105    Value Loss: 5.120    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 505544     Buffer Size: 15395      Transition Number: 1000.571k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:47:52,048][train][INFO][train.py>_log] ==> #112000     Total Loss: 4.780    [weighted Loss:4.780    Policy Loss: 9.544    Value Loss: 5.153    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 507634     Buffer Size: 15400      Transition Number: 1000.137k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:50:52,455][train][INFO][train.py>_log] ==> #113000     Total Loss: 5.488    [weighted Loss:5.488    Policy Loss: 9.505    Value Loss: 5.144    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 509734     Buffer Size: 15407      Transition Number: 1000.192k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:53:53,208][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.645    [weighted Loss:3.645    Policy Loss: 9.412    Value Loss: 5.256    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 511791     Buffer Size: 15497      Transition Number: 1000.511k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:56:54,928][train][INFO][train.py>_log] ==> #115000     Total Loss: 5.125    [weighted Loss:5.125    Policy Loss: 9.577    Value Loss: 4.969    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 513875     Buffer Size: 15540      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-02-25 08:59:57,770][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 9.542    Value Loss: 5.289    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 515972     Buffer Size: 15510      Transition Number: 1000.128k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:02:58,318][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.480    [weighted Loss:2.480    Policy Loss: 9.595    Value Loss: 5.175    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 518046     Buffer Size: 15352      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:06:00,184][train][INFO][train.py>_log] ==> #118000     Total Loss: 5.190    [weighted Loss:5.190    Policy Loss: 9.109    Value Loss: 5.311    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 520056     Buffer Size: 15278      Transition Number: 1000.394k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:09:02,695][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.340    [weighted Loss:4.340    Policy Loss: 9.331    Value Loss: 5.143    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 522092     Buffer Size: 15178      Transition Number: 1000.251k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:12:01,269][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.778    [weighted Loss:3.778    Policy Loss: 9.667    Value Loss: 5.179    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 524120     Buffer Size: 15075      Transition Number: 1000.589k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:15:04,235][train][INFO][train.py>_log] ==> #121000     Total Loss: 5.083    [weighted Loss:5.083    Policy Loss: 9.813    Value Loss: 4.854    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 526201     Buffer Size: 14960      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:18:03,815][train][INFO][train.py>_log] ==> #122000     Total Loss: 4.300    [weighted Loss:4.300    Policy Loss: 9.605    Value Loss: 5.065    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 528298     Buffer Size: 14886      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:21:04,128][train][INFO][train.py>_log] ==> #123000     Total Loss: 4.543    [weighted Loss:4.543    Policy Loss: 9.796    Value Loss: 5.125    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 530391     Buffer Size: 14901      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:24:06,368][train][INFO][train.py>_log] ==> #124000     Total Loss: 5.084    [weighted Loss:5.084    Policy Loss: 9.886    Value Loss: 4.992    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 532440     Buffer Size: 14916      Transition Number: 1000.364k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:27:08,492][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 9.263    Value Loss: 5.033    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 534530     Buffer Size: 14918      Transition Number: 1000.162k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:30:08,132][train][INFO][train.py>_log] ==> #126000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 8.880    Value Loss: 4.897    Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 536566     Buffer Size: 14945      Transition Number: 1000.120k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:33:09,618][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 8.576    Value Loss: 4.676    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 538718     Buffer Size: 15013      Transition Number: 1000.271k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:36:14,478][train][INFO][train.py>_log] ==> #128000     Total Loss: 3.077    [weighted Loss:3.077    Policy Loss: 8.899    Value Loss: 5.103    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 540815     Buffer Size: 15058      Transition Number: 1000.298k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:39:15,155][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.558    [weighted Loss:3.558    Policy Loss: 8.181    Value Loss: 4.723    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 542816     Buffer Size: 15096      Transition Number: 1000.328k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:42:16,195][train][INFO][train.py>_log] ==> #130000     Total Loss: 4.131    [weighted Loss:4.131    Policy Loss: 8.158    Value Loss: 5.002    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 544878     Buffer Size: 15074      Transition Number: 1000.020k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:45:18,834][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.950    [weighted Loss:3.950    Policy Loss: 8.837    Value Loss: 4.921    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 546891     Buffer Size: 15040      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:48:20,340][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.787    [weighted Loss:3.787    Policy Loss: 8.674    Value Loss: 4.867    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 548991     Buffer Size: 15021      Transition Number: 1000.231k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:51:23,166][train][INFO][train.py>_log] ==> #133000     Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.736    Value Loss: 4.904    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 551082     Buffer Size: 15043      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:54:25,896][train][INFO][train.py>_log] ==> #134000     Total Loss: 3.630    [weighted Loss:3.630    Policy Loss: 7.777    Value Loss: 4.935    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 553112     Buffer Size: 15072      Transition Number: 1000.303k Batch Size: 256        Lr: 0.10000 
[2022-02-25 09:57:25,375][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 7.539    Value Loss: 5.095    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 555124     Buffer Size: 15133      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:00:26,896][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 7.519    Value Loss: 4.935    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 557221     Buffer Size: 15228      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:03:30,662][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.961    [weighted Loss:3.961    Policy Loss: 8.399    Value Loss: 4.874    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 559278     Buffer Size: 15277      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:06:31,952][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.171    [weighted Loss:4.171    Policy Loss: 8.107    Value Loss: 5.115    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 561410     Buffer Size: 15340      Transition Number: 1000.173k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:09:35,493][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.699    [weighted Loss:3.699    Policy Loss: 8.495    Value Loss: 5.223    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 563482     Buffer Size: 15390      Transition Number: 1000.457k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:12:40,971][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.614    [weighted Loss:3.614    Policy Loss: 8.339    Value Loss: 5.000    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 565550     Buffer Size: 15384      Transition Number: 1000.444k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:15:41,895][train][INFO][train.py>_log] ==> #141000     Total Loss: 4.017    [weighted Loss:4.017    Policy Loss: 8.016    Value Loss: 4.926    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 567639     Buffer Size: 15410      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:18:44,302][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.636    [weighted Loss:3.636    Policy Loss: 8.106    Value Loss: 4.885    Reward Loss: 1.327    Consistency Loss: 0.000    ] Replay Episodes Collected: 569695     Buffer Size: 15411      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:21:44,352][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 8.501    Value Loss: 4.999    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 571826     Buffer Size: 15379      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:24:43,663][train][INFO][train.py>_log] ==> #144000     Total Loss: 4.225    [weighted Loss:4.225    Policy Loss: 8.627    Value Loss: 4.927    Reward Loss: 1.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 573835     Buffer Size: 15384      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:27:45,996][train][INFO][train.py>_log] ==> #145000     Total Loss: 4.348    [weighted Loss:4.348    Policy Loss: 9.094    Value Loss: 5.093    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 575987     Buffer Size: 15403      Transition Number: 1000.125k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:30:47,779][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 8.392    Value Loss: 5.037    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 578042     Buffer Size: 15447      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:33:48,094][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 8.355    Value Loss: 5.740    Reward Loss: 1.346    Consistency Loss: 0.000    ] Replay Episodes Collected: 581966     Buffer Size: 17282      Transition Number: 1000.192k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:36:51,371][train][INFO][train.py>_log] ==> #148000     Total Loss: 4.986    [weighted Loss:4.986    Policy Loss: 8.613    Value Loss: 5.462    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 585844     Buffer Size: 19174      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:39:51,490][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 8.374    Value Loss: 5.573    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 588960     Buffer Size: 20240      Transition Number: 1000.480k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:42:51,666][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.852    [weighted Loss:3.852    Policy Loss: 8.524    Value Loss: 5.822    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 592008     Buffer Size: 21251      Transition Number: 1000.200k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:45:55,596][train][INFO][train.py>_log] ==> #151000     Total Loss: 3.919    [weighted Loss:3.919    Policy Loss: 7.766    Value Loss: 5.905    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 594047     Buffer Size: 21243      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:48:55,885][train][INFO][train.py>_log] ==> #152000     Total Loss: 3.447    [weighted Loss:3.447    Policy Loss: 7.012    Value Loss: 5.592    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 595963     Buffer Size: 21206      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:51:57,317][train][INFO][train.py>_log] ==> #153000     Total Loss: 3.810    [weighted Loss:3.810    Policy Loss: 7.071    Value Loss: 5.550    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 598034     Buffer Size: 21177      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:54:59,749][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.519    [weighted Loss:3.519    Policy Loss: 7.236    Value Loss: 5.156    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 600099     Buffer Size: 20544      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 10:58:00,406][train][INFO][train.py>_log] ==> #155000     Total Loss: 4.403    [weighted Loss:4.403    Policy Loss: 6.833    Value Loss: 5.351    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 602178     Buffer Size: 18523      Transition Number: 1000.071k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:00:59,513][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 7.014    Value Loss: 5.327    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 604175     Buffer Size: 16999      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:04:02,275][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.177    [weighted Loss:3.177    Policy Loss: 7.552    Value Loss: 4.878    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 606198     Buffer Size: 15999      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:07:08,104][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.988    [weighted Loss:3.988    Policy Loss: 7.302    Value Loss: 5.046    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 608283     Buffer Size: 15403      Transition Number: 1000.114k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:10:12,364][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 7.378    Value Loss: 5.095    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 610408     Buffer Size: 15414      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:13:18,655][train][INFO][train.py>_log] ==> #160000     Total Loss: 3.108    [weighted Loss:3.108    Policy Loss: 8.418    Value Loss: 5.006    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 612499     Buffer Size: 15421      Transition Number: 1000.095k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:16:24,206][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 7.467    Value Loss: 5.098    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 614592     Buffer Size: 15406      Transition Number: 1000.114k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:19:28,399][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 8.185    Value Loss: 5.253    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 616667     Buffer Size: 15407      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:22:34,765][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.676    [weighted Loss:3.676    Policy Loss: 8.289    Value Loss: 4.870    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 618767     Buffer Size: 15412      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:25:38,926][train][INFO][train.py>_log] ==> #164000     Total Loss: 4.444    [weighted Loss:4.444    Policy Loss: 8.570    Value Loss: 4.707    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 620848     Buffer Size: 15384      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:28:43,031][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.961    [weighted Loss:2.961    Policy Loss: 8.166    Value Loss: 4.778    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 623023     Buffer Size: 15427      Transition Number: 1000.250k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:31:49,769][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.017    [weighted Loss:3.017    Policy Loss: 8.138    Value Loss: 5.098    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 625228     Buffer Size: 15467      Transition Number: 1000.178k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:34:54,671][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.639    [weighted Loss:3.639    Policy Loss: 7.913    Value Loss: 5.046    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 627319     Buffer Size: 15508      Transition Number: 999.965 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:37:59,911][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 7.473    Value Loss: 5.097    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 629492     Buffer Size: 15575      Transition Number: 1000.113k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:41:06,063][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 7.939    Value Loss: 5.304    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 631722     Buffer Size: 15708      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:44:10,139][train][INFO][train.py>_log] ==> #170000     Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 8.238    Value Loss: 5.339    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 633921     Buffer Size: 15858      Transition Number: 1000.270k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:47:12,374][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 8.470    Value Loss: 6.041    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 636115     Buffer Size: 16031      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:50:18,569][train][INFO][train.py>_log] ==> #172000     Total Loss: 3.636    [weighted Loss:3.636    Policy Loss: 7.982    Value Loss: 5.623    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 638361     Buffer Size: 16151      Transition Number: 1000.095k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:53:23,766][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.906    [weighted Loss:3.906    Policy Loss: 8.376    Value Loss: 5.817    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 640474     Buffer Size: 16138      Transition Number: 1000.201k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:56:28,772][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.910    [weighted Loss:3.910    Policy Loss: 8.731    Value Loss: 5.351    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 642542     Buffer Size: 16181      Transition Number: 1000.406k Batch Size: 256        Lr: 0.10000 
[2022-02-25 11:59:34,705][train][INFO][train.py>_log] ==> #175000     Total Loss: 4.099    [weighted Loss:4.099    Policy Loss: 8.944    Value Loss: 5.061    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 644628     Buffer Size: 16136      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:02:38,676][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.674    [weighted Loss:3.674    Policy Loss: 8.920    Value Loss: 5.366    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 646739     Buffer Size: 16038      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:05:42,506][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.465    [weighted Loss:3.465    Policy Loss: 9.112    Value Loss: 5.645    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 648851     Buffer Size: 15953      Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:08:49,560][train][INFO][train.py>_log] ==> #178000     Total Loss: 4.011    [weighted Loss:4.011    Policy Loss: 9.279    Value Loss: 5.373    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 650972     Buffer Size: 15800      Transition Number: 1000.124k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:11:56,085][train][INFO][train.py>_log] ==> #179000     Total Loss: 4.637    [weighted Loss:4.637    Policy Loss: 9.637    Value Loss: 5.451    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 653101     Buffer Size: 15744      Transition Number: 1000.191k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:14:59,696][train][INFO][train.py>_log] ==> #180000     Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 8.772    Value Loss: 5.465    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 655290     Buffer Size: 15789      Transition Number: 1000.474k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:18:06,015][train][INFO][train.py>_log] ==> #181000     Total Loss: 4.026    [weighted Loss:4.026    Policy Loss: 8.216    Value Loss: 5.088    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 657469     Buffer Size: 15837      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:21:12,245][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 7.782    Value Loss: 5.488    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 659642     Buffer Size: 15913      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:24:15,614][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.512    Value Loss: 5.333    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 661701     Buffer Size: 15938      Transition Number: 1000.316k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:27:19,084][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.292    [weighted Loss:3.292    Policy Loss: 7.222    Value Loss: 4.871    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 663696     Buffer Size: 15923      Transition Number: 1000.289k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:30:23,786][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 8.034    Value Loss: 5.503    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 665902     Buffer Size: 15970      Transition Number: 1000.398k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:33:27,904][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 7.303    Value Loss: 4.999    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 667986     Buffer Size: 15998      Transition Number: 1000.424k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:36:34,661][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.917    [weighted Loss:3.917    Policy Loss: 7.237    Value Loss: 5.343    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 670119     Buffer Size: 15917      Transition Number: 1000.220k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:39:40,924][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.400    [weighted Loss:3.400    Policy Loss: 7.065    Value Loss: 5.176    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 672303     Buffer Size: 15856      Transition Number: 1000.498k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:42:45,169][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 6.945    Value Loss: 4.886    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 674407     Buffer Size: 15773      Transition Number: 1000.704k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:45:46,689][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.546    [weighted Loss:3.546    Policy Loss: 6.801    Value Loss: 5.273    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 676459     Buffer Size: 15706      Transition Number: 1000.107k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:48:50,590][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.107    [weighted Loss:3.107    Policy Loss: 6.396    Value Loss: 4.953    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 678461     Buffer Size: 15661      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:51:53,046][train][INFO][train.py>_log] ==> #192000     Total Loss: 3.479    [weighted Loss:3.479    Policy Loss: 6.639    Value Loss: 5.023    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 680571     Buffer Size: 15589      Transition Number: 1000.235k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:54:56,951][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 6.427    Value Loss: 4.910    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 682746     Buffer Size: 15520      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-25 12:58:02,833][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.368    Value Loss: 4.803    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 684813     Buffer Size: 15454      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:01:06,006][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 6.394    Value Loss: 4.824    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 686915     Buffer Size: 15410      Transition Number: 1000.121k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:04:07,896][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.996    [weighted Loss:3.996    Policy Loss: 6.820    Value Loss: 4.844    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 688999     Buffer Size: 15391      Transition Number: 1000.229k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:07:12,787][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 6.453    Value Loss: 4.893    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 691138     Buffer Size: 15430      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:10:12,379][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.467    [weighted Loss:3.467    Policy Loss: 6.606    Value Loss: 4.776    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 693216     Buffer Size: 15492      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:13:15,353][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.830    [weighted Loss:3.830    Policy Loss: 7.166    Value Loss: 4.932    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 695288     Buffer Size: 15560      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:16:34,548][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 6.856    Value Loss: 5.326    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 697361     Buffer Size: 15619      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-02-25 13:19:35,411][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 6.427    Value Loss: 4.903    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 699643     Buffer Size: 15629      Transition Number: 1000.191k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:22:37,587][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 6.601    Value Loss: 5.008    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 701732     Buffer Size: 15627      Transition Number: 1000.037k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:25:44,051][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.645    [weighted Loss:2.645    Policy Loss: 6.298    Value Loss: 4.747    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 703815     Buffer Size: 15547      Transition Number: 1000.192k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:28:46,842][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 6.119    Value Loss: 4.776    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 705925     Buffer Size: 15450      Transition Number: 1000.157k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:31:51,050][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 6.181    Value Loss: 4.953    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 708011     Buffer Size: 15297      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:34:57,859][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 6.180    Value Loss: 4.651    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 710117     Buffer Size: 15152      Transition Number: 1000.027k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:38:00,685][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 6.604    Value Loss: 4.525    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 712207     Buffer Size: 15017      Transition Number: 1000.467k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:41:02,725][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 6.444    Value Loss: 4.722    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 714237     Buffer Size: 14909      Transition Number: 999.995 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:44:08,174][train][INFO][train.py>_log] ==> #209000     Total Loss: 3.292    [weighted Loss:3.292    Policy Loss: 6.653    Value Loss: 4.403    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 716346     Buffer Size: 14788      Transition Number: 1000.133k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:47:12,570][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 6.551    Value Loss: 4.020    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 718382     Buffer Size: 14742      Transition Number: 999.985 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:50:16,845][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.728    [weighted Loss:2.728    Policy Loss: 6.573    Value Loss: 4.536    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 720450     Buffer Size: 14713      Transition Number: 1000.166k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:53:23,631][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 6.821    Value Loss: 4.308    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 722550     Buffer Size: 14708      Transition Number: 1000.780k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:56:27,363][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 7.207    Value Loss: 4.311    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 724628     Buffer Size: 14692      Transition Number: 1000.282k Batch Size: 256        Lr: 0.02000 
[2022-02-25 13:59:29,735][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 6.770    Value Loss: 4.022    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 726667     Buffer Size: 14707      Transition Number: 1000.583k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:02:35,482][train][INFO][train.py>_log] ==> #215000     Total Loss: 3.573    [weighted Loss:3.573    Policy Loss: 7.191    Value Loss: 4.273    Reward Loss: 1.481    Consistency Loss: 0.000    ] Replay Episodes Collected: 728788     Buffer Size: 14685      Transition Number: 1000.033k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:05:38,412][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.650    [weighted Loss:2.650    Policy Loss: 7.116    Value Loss: 4.592    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 730915     Buffer Size: 14718      Transition Number: 1000.363k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:08:41,506][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 7.249    Value Loss: 4.672    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 733056     Buffer Size: 14732      Transition Number: 1000.003k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:11:49,013][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 7.141    Value Loss: 4.337    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 735187     Buffer Size: 14758      Transition Number: 1000.126k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:14:51,610][train][INFO][train.py>_log] ==> #219000     Total Loss: 3.621    [weighted Loss:3.621    Policy Loss: 7.212    Value Loss: 4.631    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 737334     Buffer Size: 14788      Transition Number: 999.997 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:17:55,601][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 7.386    Value Loss: 4.422    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 739472     Buffer Size: 14826      Transition Number: 999.936 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:21:01,592][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.561    [weighted Loss:2.561    Policy Loss: 7.008    Value Loss: 4.286    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 741612     Buffer Size: 14881      Transition Number: 999.953 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:24:05,397][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.876    [weighted Loss:2.876    Policy Loss: 7.007    Value Loss: 4.471    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 743738     Buffer Size: 14931      Transition Number: 1000.055k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:27:09,284][train][INFO][train.py>_log] ==> #223000     Total Loss: 4.298    [weighted Loss:4.298    Policy Loss: 7.468    Value Loss: 4.981    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 747730     Buffer Size: 16743      Transition Number: 1000.792k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:30:17,581][train][INFO][train.py>_log] ==> #224000     Total Loss: 4.055    [weighted Loss:4.055    Policy Loss: 7.382    Value Loss: 5.511    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 751775     Buffer Size: 18681      Transition Number: 1000.266k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:33:22,254][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 7.009    Value Loss: 4.996    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 754442     Buffer Size: 19323      Transition Number: 1000.527k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:36:27,443][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 7.166    Value Loss: 5.057    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 757286     Buffer Size: 19959      Transition Number: 1000.149k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:39:34,881][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 7.097    Value Loss: 5.103    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 759442     Buffer Size: 20033      Transition Number: 1000.161k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:42:37,031][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.114    [weighted Loss:2.114    Policy Loss: 6.951    Value Loss: 5.298    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 761566     Buffer Size: 20060      Transition Number: 1000.111k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:45:37,043][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 7.204    Value Loss: 5.205    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 763661     Buffer Size: 20095      Transition Number: 1000.415k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:48:43,845][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.805    [weighted Loss:2.805    Policy Loss: 7.427    Value Loss: 4.854    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 765786     Buffer Size: 18640      Transition Number: 1000.126k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:51:46,709][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 7.540    Value Loss: 5.217    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 767921     Buffer Size: 16795      Transition Number: 1000.257k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:54:49,599][train][INFO][train.py>_log] ==> #232000     Total Loss: 3.038    [weighted Loss:3.038    Policy Loss: 7.465    Value Loss: 4.693    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 769979     Buffer Size: 16021      Transition Number: 1000.019k Batch Size: 256        Lr: 0.02000 
[2022-02-25 14:57:55,163][train][INFO][train.py>_log] ==> #233000     Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 7.700    Value Loss: 4.589    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 772027     Buffer Size: 15519      Transition Number: 1000.211k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:00:58,877][train][INFO][train.py>_log] ==> #234000     Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 7.671    Value Loss: 4.391    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 774100     Buffer Size: 15328      Transition Number: 1000.158k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:04:03,241][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.906    [weighted Loss:3.906    Policy Loss: 7.841    Value Loss: 4.619    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 776273     Buffer Size: 15355      Transition Number: 1000.518k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:07:09,741][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.979    [weighted Loss:3.979    Policy Loss: 7.875    Value Loss: 4.799    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 778409     Buffer Size: 15370      Transition Number: 1000.275k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:10:14,616][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 7.511    Value Loss: 4.682    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 780553     Buffer Size: 15407      Transition Number: 1000.043k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:13:18,936][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 7.839    Value Loss: 4.763    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 782714     Buffer Size: 15452      Transition Number: 1000.269k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:16:27,236][train][INFO][train.py>_log] ==> #239000     Total Loss: 4.151    [weighted Loss:4.151    Policy Loss: 8.009    Value Loss: 4.578    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 784859     Buffer Size: 15496      Transition Number: 1000.290k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:19:29,240][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.826    [weighted Loss:3.826    Policy Loss: 8.199    Value Loss: 4.923    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 787013     Buffer Size: 15547      Transition Number: 1000.135k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:22:32,098][train][INFO][train.py>_log] ==> #241000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 8.007    Value Loss: 4.643    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 789134     Buffer Size: 15598      Transition Number: 1000.433k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:25:38,942][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.826    [weighted Loss:3.826    Policy Loss: 7.955    Value Loss: 4.727    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 791327     Buffer Size: 15617      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:28:42,518][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.548    [weighted Loss:3.548    Policy Loss: 8.402    Value Loss: 4.471    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 793438     Buffer Size: 15621      Transition Number: 999.991 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:31:45,814][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 8.355    Value Loss: 5.250    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 795583     Buffer Size: 15619      Transition Number: 1000.012k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:34:53,714][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 8.272    Value Loss: 4.457    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 797806     Buffer Size: 15602      Transition Number: 1000.065k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:37:56,963][train][INFO][train.py>_log] ==> #246000     Total Loss: 3.700    [weighted Loss:3.700    Policy Loss: 8.141    Value Loss: 4.674    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 799967     Buffer Size: 15597      Transition Number: 1000.579k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:40:59,975][train][INFO][train.py>_log] ==> #247000     Total Loss: 3.266    [weighted Loss:3.266    Policy Loss: 8.577    Value Loss: 4.652    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 802087     Buffer Size: 15589      Transition Number: 1000.163k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:44:06,660][train][INFO][train.py>_log] ==> #248000     Total Loss: 4.356    [weighted Loss:4.356    Policy Loss: 8.396    Value Loss: 4.497    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 804268     Buffer Size: 15591      Transition Number: 1000.326k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:47:11,308][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 8.648    Value Loss: 4.627    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 806405     Buffer Size: 15624      Transition Number: 1000.188k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:50:15,878][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 8.437    Value Loss: 4.588    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 808601     Buffer Size: 15661      Transition Number: 1000.209k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:53:24,054][train][INFO][train.py>_log] ==> #251000     Total Loss: 4.104    [weighted Loss:4.104    Policy Loss: 8.703    Value Loss: 4.839    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 810773     Buffer Size: 15680      Transition Number: 1000.175k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:56:27,452][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 8.481    Value Loss: 4.821    Reward Loss: 1.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 812894     Buffer Size: 15689      Transition Number: 999.947 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 15:59:31,787][train][INFO][train.py>_log] ==> #253000     Total Loss: 3.326    [weighted Loss:3.326    Policy Loss: 7.673    Value Loss: 4.650    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 815085     Buffer Size: 15717      Transition Number: 1000.454k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:02:36,288][train][INFO][train.py>_log] ==> #254000     Total Loss: 4.066    [weighted Loss:4.066    Policy Loss: 7.916    Value Loss: 5.058    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 817240     Buffer Size: 15710      Transition Number: 999.988 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:05:37,982][train][INFO][train.py>_log] ==> #255000     Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 8.089    Value Loss: 4.893    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 819387     Buffer Size: 15710      Transition Number: 999.943 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:08:40,396][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 7.744    Value Loss: 4.970    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 821552     Buffer Size: 15683      Transition Number: 1000.312k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:11:45,519][train][INFO][train.py>_log] ==> #257000     Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 7.327    Value Loss: 4.562    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 823724     Buffer Size: 15632      Transition Number: 1000.277k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:14:48,522][train][INFO][train.py>_log] ==> #258000     Total Loss: 3.542    [weighted Loss:3.542    Policy Loss: 7.278    Value Loss: 4.639    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 825861     Buffer Size: 15613      Transition Number: 1000.173k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:17:50,983][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 7.363    Value Loss: 4.664    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 827979     Buffer Size: 15628      Transition Number: 1000.103k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:20:55,300][train][INFO][train.py>_log] ==> #260000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 7.347    Value Loss: 4.907    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 830177     Buffer Size: 15639      Transition Number: 1000.261k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:23:56,900][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.597    [weighted Loss:2.597    Policy Loss: 6.832    Value Loss: 4.706    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 832304     Buffer Size: 15644      Transition Number: 1000.084k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:27:00,553][train][INFO][train.py>_log] ==> #262000     Total Loss: 3.733    [weighted Loss:3.733    Policy Loss: 7.309    Value Loss: 4.619    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 834429     Buffer Size: 15662      Transition Number: 1000.265k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:30:05,924][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 7.094    Value Loss: 4.541    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 836642     Buffer Size: 15657      Transition Number: 1000.198k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:33:08,111][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 6.936    Value Loss: 4.833    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 838831     Buffer Size: 15668      Transition Number: 1000.267k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:36:12,720][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 6.375    Value Loss: 4.525    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 841025     Buffer Size: 15667      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:39:17,548][train][INFO][train.py>_log] ==> #266000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 6.588    Value Loss: 4.675    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 843191     Buffer Size: 15654      Transition Number: 1000.139k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:42:20,143][train][INFO][train.py>_log] ==> #267000     Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 6.794    Value Loss: 4.597    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 845344     Buffer Size: 15659      Transition Number: 1000.083k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:45:22,833][train][INFO][train.py>_log] ==> #268000     Total Loss: 3.940    [weighted Loss:3.940    Policy Loss: 7.008    Value Loss: 4.757    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 847456     Buffer Size: 15657      Transition Number: 1000.136k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:48:27,772][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 6.606    Value Loss: 4.435    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 849564     Buffer Size: 15649      Transition Number: 1000.047k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:51:31,174][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 6.724    Value Loss: 4.394    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 851768     Buffer Size: 15672      Transition Number: 1000.442k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:54:35,027][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 6.360    Value Loss: 4.774    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 853918     Buffer Size: 15670      Transition Number: 1000.204k Batch Size: 256        Lr: 0.02000 
[2022-02-25 16:57:39,877][train][INFO][train.py>_log] ==> #272000     Total Loss: 3.529    [weighted Loss:3.529    Policy Loss: 6.470    Value Loss: 4.521    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 856096     Buffer Size: 15673      Transition Number: 1000.192k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:00:41,170][train][INFO][train.py>_log] ==> #273000     Total Loss: 3.095    [weighted Loss:3.095    Policy Loss: 6.358    Value Loss: 4.404    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 858272     Buffer Size: 15671      Transition Number: 1000.502k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:03:44,537][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 6.419    Value Loss: 4.521    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 860418     Buffer Size: 15644      Transition Number: 1000.240k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:06:51,831][train][INFO][train.py>_log] ==> #275000     Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 6.376    Value Loss: 4.847    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 862608     Buffer Size: 15618      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:09:56,141][train][INFO][train.py>_log] ==> #276000     Total Loss: 0.937    [weighted Loss:0.937    Policy Loss: 6.621    Value Loss: 4.911    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 864829     Buffer Size: 15595      Transition Number: 999.960 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:12:59,045][train][INFO][train.py>_log] ==> #277000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 6.277    Value Loss: 4.472    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 867007     Buffer Size: 15592      Transition Number: 1000.708k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:16:03,696][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.509    [weighted Loss:2.509    Policy Loss: 6.481    Value Loss: 4.699    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 869223     Buffer Size: 15586      Transition Number: 999.955 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:19:08,076][train][INFO][train.py>_log] ==> #279000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 6.920    Value Loss: 4.373    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 871471     Buffer Size: 15614      Transition Number: 999.949 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:22:10,169][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 6.430    Value Loss: 4.316    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 873713     Buffer Size: 15654      Transition Number: 1000.249k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:25:16,460][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 6.647    Value Loss: 4.590    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 875910     Buffer Size: 15683      Transition Number: 1000.243k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:28:17,793][train][INFO][train.py>_log] ==> #282000     Total Loss: 3.240    [weighted Loss:3.240    Policy Loss: 6.959    Value Loss: 4.479    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 878109     Buffer Size: 15715      Transition Number: 1000.207k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:31:18,573][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 6.810    Value Loss: 4.695    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 880295     Buffer Size: 15752      Transition Number: 1000.104k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:34:23,893][train][INFO][train.py>_log] ==> #284000     Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 7.054    Value Loss: 4.916    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 882493     Buffer Size: 15778      Transition Number: 1000.219k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:37:27,757][train][INFO][train.py>_log] ==> #285000     Total Loss: 3.358    [weighted Loss:3.358    Policy Loss: 6.603    Value Loss: 4.383    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 884734     Buffer Size: 15814      Transition Number: 1000.164k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:40:31,143][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.784    [weighted Loss:2.784    Policy Loss: 6.618    Value Loss: 4.957    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 886886     Buffer Size: 15850      Transition Number: 1000.797k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:43:36,469][train][INFO][train.py>_log] ==> #287000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 6.843    Value Loss: 4.487    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 889072     Buffer Size: 15872      Transition Number: 1000.413k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:46:39,998][train][INFO][train.py>_log] ==> #288000     Total Loss: 3.747    [weighted Loss:3.747    Policy Loss: 6.731    Value Loss: 4.668    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 891298     Buffer Size: 15885      Transition Number: 1000.411k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:49:43,326][train][INFO][train.py>_log] ==> #289000     Total Loss: 4.089    [weighted Loss:4.089    Policy Loss: 6.749    Value Loss: 4.931    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 893471     Buffer Size: 15911      Transition Number: 1000.404k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:52:49,108][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 7.053    Value Loss: 4.634    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 895689     Buffer Size: 15919      Transition Number: 1000.105k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:55:52,387][train][INFO][train.py>_log] ==> #291000     Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 6.567    Value Loss: 4.695    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 897928     Buffer Size: 15936      Transition Number: 999.997 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 17:58:58,072][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.071    [weighted Loss:2.071    Policy Loss: 6.677    Value Loss: 4.883    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 900119     Buffer Size: 15942      Transition Number: 1000.046k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:02:05,238][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 6.905    Value Loss: 4.995    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 902367     Buffer Size: 15942      Transition Number: 1000.152k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:05:08,757][train][INFO][train.py>_log] ==> #294000     Total Loss: 1.435    [weighted Loss:1.435    Policy Loss: 6.986    Value Loss: 4.611    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 904607     Buffer Size: 15923      Transition Number: 1000.383k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:08:13,862][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.838    [weighted Loss:2.838    Policy Loss: 6.756    Value Loss: 4.567    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 906777     Buffer Size: 15908      Transition Number: 1000.164k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:11:18,392][train][INFO][train.py>_log] ==> #296000     Total Loss: 4.049    [weighted Loss:4.049    Policy Loss: 6.735    Value Loss: 4.820    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 908962     Buffer Size: 15889      Transition Number: 1000.142k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:14:20,640][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 7.125    Value Loss: 4.652    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 911151     Buffer Size: 15884      Transition Number: 1000.066k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:17:25,323][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.932    Value Loss: 4.967    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 913360     Buffer Size: 15866      Transition Number: 1000.243k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:20:30,970][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.329    [weighted Loss:2.329    Policy Loss: 7.218    Value Loss: 4.697    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 915555     Buffer Size: 15834      Transition Number: 1000.155k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:23:33,068][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 7.026    Value Loss: 4.745    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 917729     Buffer Size: 15812      Transition Number: 1000.240k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:26:39,458][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.163    [weighted Loss:3.163    Policy Loss: 6.898    Value Loss: 4.552    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 920024     Buffer Size: 15794      Transition Number: 1000.641k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:29:44,672][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 6.840    Value Loss: 4.710    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 922188     Buffer Size: 15772      Transition Number: 1000.150k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:32:47,113][train][INFO][train.py>_log] ==> #303000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 6.619    Value Loss: 4.629    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 924440     Buffer Size: 15771      Transition Number: 1000.490k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:35:52,158][train][INFO][train.py>_log] ==> #304000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 6.765    Value Loss: 4.624    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 926688     Buffer Size: 15748      Transition Number: 1000.106k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:38:57,275][train][INFO][train.py>_log] ==> #305000     Total Loss: 3.554    [weighted Loss:3.554    Policy Loss: 6.772    Value Loss: 4.733    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 928911     Buffer Size: 15734      Transition Number: 999.972 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:42:03,928][train][INFO][train.py>_log] ==> #306000     Total Loss: 3.948    [weighted Loss:3.948    Policy Loss: 6.854    Value Loss: 4.497    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 931117     Buffer Size: 15737      Transition Number: 1000.216k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:45:06,803][train][INFO][train.py>_log] ==> #307000     Total Loss: 1.736    [weighted Loss:1.736    Policy Loss: 6.644    Value Loss: 4.577    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 933322     Buffer Size: 15757      Transition Number: 1000.312k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:48:13,525][train][INFO][train.py>_log] ==> #308000     Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 6.709    Value Loss: 4.639    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 935558     Buffer Size: 15782      Transition Number: 999.997 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:51:15,751][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 6.955    Value Loss: 4.738    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 937767     Buffer Size: 15810      Transition Number: 1000.192k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:54:20,089][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.226    [weighted Loss:3.226    Policy Loss: 6.811    Value Loss: 4.633    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 939953     Buffer Size: 15810      Transition Number: 1000.121k Batch Size: 256        Lr: 0.02000 
[2022-02-25 18:57:24,709][train][INFO][train.py>_log] ==> #311000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 7.210    Value Loss: 4.729    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 942189     Buffer Size: 15823      Transition Number: 1000.033k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:00:26,373][train][INFO][train.py>_log] ==> #312000     Total Loss: 3.158    [weighted Loss:3.158    Policy Loss: 6.881    Value Loss: 4.549    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 944364     Buffer Size: 15850      Transition Number: 1000.154k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:03:29,658][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.438    [weighted Loss:3.438    Policy Loss: 7.062    Value Loss: 4.922    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 946602     Buffer Size: 15848      Transition Number: 999.939 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:06:32,713][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 7.160    Value Loss: 4.863    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 948774     Buffer Size: 15859      Transition Number: 1000.049k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:09:35,607][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 7.099    Value Loss: 4.592    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 951117     Buffer Size: 15882      Transition Number: 1000.129k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:12:39,224][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 7.380    Value Loss: 4.792    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 953351     Buffer Size: 15906      Transition Number: 1000.108k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:15:43,752][train][INFO][train.py>_log] ==> #317000     Total Loss: 3.675    [weighted Loss:3.675    Policy Loss: 7.578    Value Loss: 4.798    Reward Loss: 1.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 955552     Buffer Size: 15925      Transition Number: 999.980 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:18:47,814][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.577    [weighted Loss:2.577    Policy Loss: 7.644    Value Loss: 4.991    Reward Loss: 1.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 957818     Buffer Size: 15945      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:21:52,580][train][INFO][train.py>_log] ==> #319000     Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 7.310    Value Loss: 4.418    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 960077     Buffer Size: 15976      Transition Number: 999.963 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:24:56,375][train][INFO][train.py>_log] ==> #320000     Total Loss: 3.105    [weighted Loss:3.105    Policy Loss: 7.319    Value Loss: 4.970    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 962311     Buffer Size: 16003      Transition Number: 1000.006k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:27:59,767][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.975    [weighted Loss:2.975    Policy Loss: 7.492    Value Loss: 4.750    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 964550     Buffer Size: 16016      Transition Number: 999.934 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:31:05,548][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.096    [weighted Loss:2.096    Policy Loss: 7.849    Value Loss: 4.608    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 966808     Buffer Size: 16017      Transition Number: 1000.029k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:34:10,954][train][INFO][train.py>_log] ==> #323000     Total Loss: 3.469    [weighted Loss:3.469    Policy Loss: 7.189    Value Loss: 4.672    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 969038     Buffer Size: 16002      Transition Number: 1000.171k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:37:15,035][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 7.976    Value Loss: 4.748    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 971251     Buffer Size: 16012      Transition Number: 1000.231k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:40:21,038][train][INFO][train.py>_log] ==> #325000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 7.897    Value Loss: 4.713    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 973501     Buffer Size: 16032      Transition Number: 1000.029k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:43:24,428][train][INFO][train.py>_log] ==> #326000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 7.093    Value Loss: 4.267    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 975757     Buffer Size: 16033      Transition Number: 1000.367k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:46:26,280][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.644    [weighted Loss:2.644    Policy Loss: 7.768    Value Loss: 4.522    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 977935     Buffer Size: 16041      Transition Number: 1000.085k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:49:29,600][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.540    [weighted Loss:3.540    Policy Loss: 7.467    Value Loss: 4.986    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 980146     Buffer Size: 16057      Transition Number: 999.971 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:52:33,485][train][INFO][train.py>_log] ==> #329000     Total Loss: 4.036    [weighted Loss:4.036    Policy Loss: 7.489    Value Loss: 4.913    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 982376     Buffer Size: 16061      Transition Number: 1000.020k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:55:35,950][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 7.834    Value Loss: 4.373    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 984557     Buffer Size: 16056      Transition Number: 1000.125k Batch Size: 256        Lr: 0.02000 
[2022-02-25 19:58:40,888][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.677    [weighted Loss:2.677    Policy Loss: 7.303    Value Loss: 4.708    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 986922     Buffer Size: 16226      Transition Number: 1000.261k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:01:46,319][train][INFO][train.py>_log] ==> #332000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 7.094    Value Loss: 4.765    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 989309     Buffer Size: 16368      Transition Number: 1000.134k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:04:48,121][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 7.508    Value Loss: 4.731    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 991548     Buffer Size: 16438      Transition Number: 1000.091k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:07:54,469][train][INFO][train.py>_log] ==> #334000     Total Loss: 4.485    [weighted Loss:4.485    Policy Loss: 7.069    Value Loss: 5.036    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 993819     Buffer Size: 16491      Transition Number: 1000.236k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:10:59,713][train][INFO][train.py>_log] ==> #335000     Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 7.032    Value Loss: 5.039    Reward Loss: 1.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 996095     Buffer Size: 16514      Transition Number: 1000.426k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:14:03,424][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 7.431    Value Loss: 4.600    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 998323     Buffer Size: 16535      Transition Number: 1000.126k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:17:07,547][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.867    [weighted Loss:2.867    Policy Loss: 7.250    Value Loss: 4.652    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000611    Buffer Size: 16554      Transition Number: 1000.067k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:20:13,068][train][INFO][train.py>_log] ==> #338000     Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 7.347    Value Loss: 4.697    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002869    Buffer Size: 16470      Transition Number: 1000.175k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:23:15,946][train][INFO][train.py>_log] ==> #339000     Total Loss: 3.331    [weighted Loss:3.331    Policy Loss: 7.736    Value Loss: 4.703    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1005031    Buffer Size: 16286      Transition Number: 1000.244k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:26:22,257][train][INFO][train.py>_log] ==> #340000     Total Loss: 4.317    [weighted Loss:4.317    Policy Loss: 7.617    Value Loss: 4.601    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1007284    Buffer Size: 16184      Transition Number: 1000.293k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:29:27,088][train][INFO][train.py>_log] ==> #341000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 7.885    Value Loss: 4.763    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1009457    Buffer Size: 16125      Transition Number: 1000.292k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:32:32,201][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 8.225    Value Loss: 4.802    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1011759    Buffer Size: 16098      Transition Number: 1000.050k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:35:36,162][train][INFO][train.py>_log] ==> #343000     Total Loss: 3.625    [weighted Loss:3.625    Policy Loss: 8.162    Value Loss: 4.662    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013973    Buffer Size: 16114      Transition Number: 1000.357k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:38:40,163][train][INFO][train.py>_log] ==> #344000     Total Loss: 3.048    [weighted Loss:3.048    Policy Loss: 7.893    Value Loss: 4.519    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1016281    Buffer Size: 16121      Transition Number: 1000.198k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:41:43,503][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.413    [weighted Loss:3.413    Policy Loss: 8.302    Value Loss: 4.699    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1018453    Buffer Size: 16134      Transition Number: 1000.411k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:44:48,863][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.761    [weighted Loss:2.761    Policy Loss: 8.037    Value Loss: 4.587    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1020717    Buffer Size: 16185      Transition Number: 1000.105k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:47:53,523][train][INFO][train.py>_log] ==> #347000     Total Loss: 0.977    [weighted Loss:0.977    Policy Loss: 8.434    Value Loss: 4.721    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1023000    Buffer Size: 16252      Transition Number: 1000.045k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:50:57,107][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 8.340    Value Loss: 4.856    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025213    Buffer Size: 16310      Transition Number: 1000.015k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:54:02,745][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 8.386    Value Loss: 4.666    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1027502    Buffer Size: 16371      Transition Number: 999.962 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 20:57:07,768][train][INFO][train.py>_log] ==> #350000     Total Loss: 4.321    [weighted Loss:4.321    Policy Loss: 8.859    Value Loss: 5.012    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 1029773    Buffer Size: 16425      Transition Number: 1000.166k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:00:12,434][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.991    [weighted Loss:3.991    Policy Loss: 8.049    Value Loss: 4.947    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032062    Buffer Size: 16443      Transition Number: 1000.187k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:03:19,755][train][INFO][train.py>_log] ==> #352000     Total Loss: 3.699    [weighted Loss:3.699    Policy Loss: 8.482    Value Loss: 4.709    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1034287    Buffer Size: 16465      Transition Number: 1000.010k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:06:22,948][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 8.184    Value Loss: 4.925    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1036561    Buffer Size: 16484      Transition Number: 1000.089k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:09:26,939][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 8.437    Value Loss: 4.966    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1038781    Buffer Size: 16512      Transition Number: 1000.017k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:12:31,522][train][INFO][train.py>_log] ==> #355000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 8.245    Value Loss: 4.687    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1040982    Buffer Size: 16523      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:15:35,570][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 8.445    Value Loss: 4.945    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043270    Buffer Size: 16552      Transition Number: 1000.174k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:18:38,622][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 8.229    Value Loss: 5.380    Reward Loss: 2.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 1045849    Buffer Size: 16921      Transition Number: 1000.031k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:21:44,665][train][INFO][train.py>_log] ==> #358000     Total Loss: 4.164    [weighted Loss:4.164    Policy Loss: 7.956    Value Loss: 5.171    Reward Loss: 1.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048546    Buffer Size: 17386      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:24:48,573][train][INFO][train.py>_log] ==> #359000     Total Loss: 3.502    [weighted Loss:3.502    Policy Loss: 8.102    Value Loss: 5.065    Reward Loss: 1.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 1051088    Buffer Size: 17651      Transition Number: 1000.171k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:27:50,803][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 7.997    Value Loss: 5.134    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 1053564    Buffer Size: 17896      Transition Number: 1000.188k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:30:56,716][train][INFO][train.py>_log] ==> #361000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 8.445    Value Loss: 4.953    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 1055796    Buffer Size: 17968      Transition Number: 1000.074k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:34:01,005][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 8.031    Value Loss: 5.467    Reward Loss: 1.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 1058101    Buffer Size: 18036      Transition Number: 1000.002k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:37:02,300][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.785    [weighted Loss:2.785    Policy Loss: 8.071    Value Loss: 5.210    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1060346    Buffer Size: 18113      Transition Number: 1000.023k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:40:10,473][train][INFO][train.py>_log] ==> #364000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 8.147    Value Loss: 5.686    Reward Loss: 1.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 1062694    Buffer Size: 18033      Transition Number: 1000.323k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:43:14,751][train][INFO][train.py>_log] ==> #365000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 7.965    Value Loss: 5.183    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1065003    Buffer Size: 17699      Transition Number: 1000.080k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:46:21,370][train][INFO][train.py>_log] ==> #366000     Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 7.940    Value Loss: 5.211    Reward Loss: 1.900    Consistency Loss: 0.000    ] Replay Episodes Collected: 1067366    Buffer Size: 17439      Transition Number: 1000.042k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:49:26,567][train][INFO][train.py>_log] ==> #367000     Total Loss: 4.079    [weighted Loss:4.079    Policy Loss: 8.105    Value Loss: 4.995    Reward Loss: 1.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069577    Buffer Size: 17277      Transition Number: 1000.087k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:52:29,362][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.104    [weighted Loss:3.104    Policy Loss: 8.396    Value Loss: 5.036    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 1071776    Buffer Size: 17185      Transition Number: 1000.138k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:55:31,661][train][INFO][train.py>_log] ==> #369000     Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 8.242    Value Loss: 4.957    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1073999    Buffer Size: 17164      Transition Number: 1000.118k Batch Size: 256        Lr: 0.02000 
[2022-02-25 21:58:40,308][train][INFO][train.py>_log] ==> #370000     Total Loss: 3.319    [weighted Loss:3.319    Policy Loss: 8.199    Value Loss: 4.826    Reward Loss: 1.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076286    Buffer Size: 17121      Transition Number: 999.982 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:01:46,692][train][INFO][train.py>_log] ==> #371000     Total Loss: 4.124    [weighted Loss:4.124    Policy Loss: 8.783    Value Loss: 4.810    Reward Loss: 1.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 1078541    Buffer Size: 17073      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:04:50,125][train][INFO][train.py>_log] ==> #372000     Total Loss: 3.780    [weighted Loss:3.780    Policy Loss: 8.353    Value Loss: 4.920    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1080823    Buffer Size: 17014      Transition Number: 1000.404k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:07:55,335][train][INFO][train.py>_log] ==> #373000     Total Loss: 4.288    [weighted Loss:4.288    Policy Loss: 9.507    Value Loss: 4.570    Reward Loss: 1.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 1083069    Buffer Size: 16982      Transition Number: 1000.305k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:11:00,123][train][INFO][train.py>_log] ==> #374000     Total Loss: 4.170    [weighted Loss:4.170    Policy Loss: 8.936    Value Loss: 4.914    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 1085300    Buffer Size: 16956      Transition Number: 1000.053k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:14:05,200][train][INFO][train.py>_log] ==> #375000     Total Loss: 3.499    [weighted Loss:3.499    Policy Loss: 9.027    Value Loss: 5.013    Reward Loss: 1.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 1087580    Buffer Size: 16963      Transition Number: 1000.391k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:17:09,056][train][INFO][train.py>_log] ==> #376000     Total Loss: 3.877    [weighted Loss:3.877    Policy Loss: 8.993    Value Loss: 4.680    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089851    Buffer Size: 16985      Transition Number: 1000.588k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:20:15,223][train][INFO][train.py>_log] ==> #377000     Total Loss: 4.162    [weighted Loss:4.162    Policy Loss: 9.186    Value Loss: 5.519    Reward Loss: 1.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092146    Buffer Size: 16986      Transition Number: 1000.185k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:23:19,198][train][INFO][train.py>_log] ==> #378000     Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 9.093    Value Loss: 5.006    Reward Loss: 1.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 1094392    Buffer Size: 16984      Transition Number: 1000.173k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:26:23,582][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 9.547    Value Loss: 5.239    Reward Loss: 1.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 1096720    Buffer Size: 16976      Transition Number: 1000.178k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:29:29,171][train][INFO][train.py>_log] ==> #380000     Total Loss: 3.162    [weighted Loss:3.162    Policy Loss: 9.230    Value Loss: 4.989    Reward Loss: 2.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098957    Buffer Size: 16947      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:32:32,234][train][INFO][train.py>_log] ==> #381000     Total Loss: 3.162    [weighted Loss:3.162    Policy Loss: 9.335    Value Loss: 4.772    Reward Loss: 1.946    Consistency Loss: 0.000    ] Replay Episodes Collected: 1101197    Buffer Size: 16945      Transition Number: 1000.154k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:35:38,572][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 9.141    Value Loss: 4.854    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103495    Buffer Size: 16925      Transition Number: 1000.088k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:38:43,501][train][INFO][train.py>_log] ==> #383000     Total Loss: 3.185    [weighted Loss:3.185    Policy Loss: 9.166    Value Loss: 5.066    Reward Loss: 1.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 1105735    Buffer Size: 16916      Transition Number: 1000.250k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:41:47,091][train][INFO][train.py>_log] ==> #384000     Total Loss: 4.587    [weighted Loss:4.587    Policy Loss: 9.357    Value Loss: 4.853    Reward Loss: 1.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 1107988    Buffer Size: 16904      Transition Number: 1000.057k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:44:52,356][train][INFO][train.py>_log] ==> #385000     Total Loss: 4.143    [weighted Loss:4.143    Policy Loss: 9.206    Value Loss: 4.978    Reward Loss: 1.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 1110297    Buffer Size: 16900      Transition Number: 1000.152k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:47:57,900][train][INFO][train.py>_log] ==> #386000     Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 9.320    Value Loss: 4.831    Reward Loss: 1.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 1112524    Buffer Size: 16887      Transition Number: 1000.002k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:51:00,572][train][INFO][train.py>_log] ==> #387000     Total Loss: 4.287    [weighted Loss:4.287    Policy Loss: 9.248    Value Loss: 4.816    Reward Loss: 1.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 1114782    Buffer Size: 16906      Transition Number: 1000.107k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:54:04,589][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 9.370    Value Loss: 4.797    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117066    Buffer Size: 16908      Transition Number: 1000.030k Batch Size: 256        Lr: 0.02000 
[2022-02-25 22:57:08,612][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.301    [weighted Loss:2.301    Policy Loss: 9.520    Value Loss: 4.502    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1119301    Buffer Size: 16925      Transition Number: 1000.308k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:00:12,668][train][INFO][train.py>_log] ==> #390000     Total Loss: 4.449    [weighted Loss:4.449    Policy Loss: 9.488    Value Loss: 5.084    Reward Loss: 1.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 1121545    Buffer Size: 16959      Transition Number: 1000.060k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:03:18,645][train][INFO][train.py>_log] ==> #391000     Total Loss: 4.442    [weighted Loss:4.442    Policy Loss: 9.333    Value Loss: 5.133    Reward Loss: 1.933    Consistency Loss: 0.000    ] Replay Episodes Collected: 1123913    Buffer Size: 17042      Transition Number: 1000.261k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:06:24,107][train][INFO][train.py>_log] ==> #392000     Total Loss: 3.732    [weighted Loss:3.732    Policy Loss: 8.820    Value Loss: 5.009    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126258    Buffer Size: 17102      Transition Number: 1000.178k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:09:31,871][train][INFO][train.py>_log] ==> #393000     Total Loss: 4.402    [weighted Loss:4.402    Policy Loss: 9.865    Value Loss: 5.258    Reward Loss: 2.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128587    Buffer Size: 17182      Transition Number: 1000.009k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:12:38,448][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.967    [weighted Loss:3.967    Policy Loss: 9.511    Value Loss: 5.249    Reward Loss: 1.908    Consistency Loss: 0.000    ] Replay Episodes Collected: 1130944    Buffer Size: 17220      Transition Number: 1000.001k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:15:43,947][train][INFO][train.py>_log] ==> #395000     Total Loss: 4.179    [weighted Loss:4.179    Policy Loss: 9.561    Value Loss: 4.976    Reward Loss: 2.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133266    Buffer Size: 17267      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:18:47,219][train][INFO][train.py>_log] ==> #396000     Total Loss: 4.083    [weighted Loss:4.083    Policy Loss: 9.179    Value Loss: 5.125    Reward Loss: 1.944    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135582    Buffer Size: 17296      Transition Number: 999.961 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:21:52,713][train][INFO][train.py>_log] ==> #397000     Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 9.330    Value Loss: 5.027    Reward Loss: 1.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 1137939    Buffer Size: 17320      Transition Number: 1000.022k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:24:56,552][train][INFO][train.py>_log] ==> #398000     Total Loss: 3.588    [weighted Loss:3.588    Policy Loss: 9.388    Value Loss: 4.941    Reward Loss: 1.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 1140228    Buffer Size: 17305      Transition Number: 999.959 k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:28:05,356][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 9.646    Value Loss: 4.860    Reward Loss: 1.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 1142552    Buffer Size: 17288      Transition Number: 1000.352k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:31:29,008][train][INFO][train.py>_log] ==> #400000     Total Loss: 4.257    [weighted Loss:4.257    Policy Loss: 9.366    Value Loss: 4.879    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144897    Buffer Size: 17265      Transition Number: 1000.025k Batch Size: 256        Lr: 0.02000 
[2022-02-25 23:34:38,900][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 8.845    Value Loss: 5.162    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147449    Buffer Size: 17249      Transition Number: 1000.395k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:37:41,419][train][INFO][train.py>_log] ==> #402000     Total Loss: 3.986    [weighted Loss:3.986    Policy Loss: 9.025    Value Loss: 4.664    Reward Loss: 2.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 1149647    Buffer Size: 17243      Transition Number: 1000.386k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:40:45,065][train][INFO][train.py>_log] ==> #403000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 9.152    Value Loss: 5.153    Reward Loss: 2.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 1151885    Buffer Size: 17180      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:43:47,531][train][INFO][train.py>_log] ==> #404000     Total Loss: 4.287    [weighted Loss:4.287    Policy Loss: 8.755    Value Loss: 4.852    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 1154078    Buffer Size: 17137      Transition Number: 1000.358k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:46:49,348][train][INFO][train.py>_log] ==> #405000     Total Loss: 3.235    [weighted Loss:3.235    Policy Loss: 8.447    Value Loss: 4.653    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1156256    Buffer Size: 17068      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:49:56,705][train][INFO][train.py>_log] ==> #406000     Total Loss: 3.310    [weighted Loss:3.310    Policy Loss: 8.772    Value Loss: 4.927    Reward Loss: 2.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 1158542    Buffer Size: 16990      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:52:56,682][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 8.362    Value Loss: 5.175    Reward Loss: 1.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 1160656    Buffer Size: 16911      Transition Number: 1000.160k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:56:00,269][train][INFO][train.py>_log] ==> #408000     Total Loss: 3.952    [weighted Loss:3.952    Policy Loss: 8.181    Value Loss: 4.457    Reward Loss: 1.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 1162853    Buffer Size: 16835      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00400 
[2022-02-25 23:59:03,107][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 7.824    Value Loss: 4.484    Reward Loss: 1.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 1165023    Buffer Size: 16742      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:02:08,950][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 8.309    Value Loss: 4.530    Reward Loss: 2.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 1167180    Buffer Size: 16696      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:05:12,843][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 7.822    Value Loss: 4.612    Reward Loss: 1.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 1169329    Buffer Size: 16673      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:08:15,763][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.196    [weighted Loss:3.196    Policy Loss: 8.066    Value Loss: 4.536    Reward Loss: 1.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 1171533    Buffer Size: 16660      Transition Number: 1000.280k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:11:20,208][train][INFO][train.py>_log] ==> #413000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 8.152    Value Loss: 4.709    Reward Loss: 1.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 1173687    Buffer Size: 16645      Transition Number: 1000.462k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:14:23,007][train][INFO][train.py>_log] ==> #414000     Total Loss: 1.200    [weighted Loss:1.200    Policy Loss: 8.190    Value Loss: 4.481    Reward Loss: 1.984    Consistency Loss: 0.000    ] Replay Episodes Collected: 1175930    Buffer Size: 16643      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:17:26,736][train][INFO][train.py>_log] ==> #415000     Total Loss: 4.095    [weighted Loss:4.095    Policy Loss: 8.271    Value Loss: 4.351    Reward Loss: 2.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 1178136    Buffer Size: 16653      Transition Number: 1000.395k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:20:33,569][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 8.692    Value Loss: 4.286    Reward Loss: 1.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 1180309    Buffer Size: 16651      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:23:36,171][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 8.754    Value Loss: 4.270    Reward Loss: 1.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 1182504    Buffer Size: 16648      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:26:39,502][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 8.757    Value Loss: 4.478    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 1184744    Buffer Size: 16661      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:29:42,714][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 8.778    Value Loss: 4.795    Reward Loss: 2.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 1186933    Buffer Size: 16662      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:32:48,948][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 8.547    Value Loss: 4.457    Reward Loss: 1.975    Consistency Loss: 0.000    ] Replay Episodes Collected: 1189189    Buffer Size: 16678      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:35:54,846][train][INFO][train.py>_log] ==> #421000     Total Loss: 3.441    [weighted Loss:3.441    Policy Loss: 8.700    Value Loss: 4.578    Reward Loss: 1.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 1191435    Buffer Size: 16655      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:39:01,930][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 8.558    Value Loss: 4.925    Reward Loss: 1.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 1193695    Buffer Size: 16639      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:42:07,550][train][INFO][train.py>_log] ==> #423000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 8.709    Value Loss: 4.351    Reward Loss: 1.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 1195916    Buffer Size: 16608      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:45:11,620][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 9.169    Value Loss: 4.761    Reward Loss: 2.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 1198174    Buffer Size: 16603      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:48:15,441][train][INFO][train.py>_log] ==> #425000     Total Loss: 3.570    [weighted Loss:3.570    Policy Loss: 8.589    Value Loss: 4.622    Reward Loss: 1.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 1200393    Buffer Size: 16573      Transition Number: 1000.279k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:51:27,297][train][INFO][train.py>_log] ==> #426000     Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 8.831    Value Loss: 4.424    Reward Loss: 1.898    Consistency Loss: 0.000    ] Replay Episodes Collected: 1202758    Buffer Size: 16513      Transition Number: 1000.073k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:54:34,146][train][INFO][train.py>_log] ==> #427000     Total Loss: 3.334    [weighted Loss:3.334    Policy Loss: 8.986    Value Loss: 4.270    Reward Loss: 1.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 1205027    Buffer Size: 16487      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00400 
[2022-02-26 00:57:46,022][train][INFO][train.py>_log] ==> #428000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 8.892    Value Loss: 4.371    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 1207357    Buffer Size: 16466      Transition Number: 1000.290k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:00:48,593][train][INFO][train.py>_log] ==> #429000     Total Loss: 3.940    [weighted Loss:3.940    Policy Loss: 8.833    Value Loss: 4.577    Reward Loss: 1.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 1209594    Buffer Size: 16443      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:03:52,715][train][INFO][train.py>_log] ==> #430000     Total Loss: 3.930    [weighted Loss:3.930    Policy Loss: 8.985    Value Loss: 4.700    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1211751    Buffer Size: 16427      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:06:56,686][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 9.156    Value Loss: 4.464    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1214086    Buffer Size: 16402      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:10:00,290][train][INFO][train.py>_log] ==> #432000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 8.943    Value Loss: 4.589    Reward Loss: 1.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216337    Buffer Size: 16403      Transition Number: 1000.418k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:13:07,550][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 9.217    Value Loss: 4.610    Reward Loss: 1.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218643    Buffer Size: 16387      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:16:12,326][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.846    [weighted Loss:3.846    Policy Loss: 9.336    Value Loss: 4.261    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1220910    Buffer Size: 16362      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:19:21,357][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.431    [weighted Loss:2.431    Policy Loss: 8.902    Value Loss: 4.482    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223242    Buffer Size: 16339      Transition Number: 1000.145k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:22:27,628][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 8.716    Value Loss: 4.415    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225517    Buffer Size: 16315      Transition Number: 1000.217k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:25:32,960][train][INFO][train.py>_log] ==> #437000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 8.766    Value Loss: 4.426    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 1227758    Buffer Size: 16283      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:28:38,453][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 8.502    Value Loss: 4.640    Reward Loss: 1.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 1229966    Buffer Size: 16258      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:31:43,246][train][INFO][train.py>_log] ==> #439000     Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 8.615    Value Loss: 4.579    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1232231    Buffer Size: 16207      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:34:49,529][train][INFO][train.py>_log] ==> #440000     Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 8.227    Value Loss: 4.586    Reward Loss: 1.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 1234487    Buffer Size: 16172      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:37:55,947][train][INFO][train.py>_log] ==> #441000     Total Loss: 2.702    [weighted Loss:2.702    Policy Loss: 8.623    Value Loss: 4.811    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236745    Buffer Size: 16154      Transition Number: 1000.615k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:41:06,944][train][INFO][train.py>_log] ==> #442000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 8.414    Value Loss: 4.795    Reward Loss: 1.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 1239054    Buffer Size: 16124      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:44:16,966][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.168    [weighted Loss:3.168    Policy Loss: 8.910    Value Loss: 4.415    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241362    Buffer Size: 16129      Transition Number: 1000.641k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:47:27,349][train][INFO][train.py>_log] ==> #444000     Total Loss: 4.448    [weighted Loss:4.448    Policy Loss: 8.881    Value Loss: 4.614    Reward Loss: 1.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 1243708    Buffer Size: 16110      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:50:34,476][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.420    [weighted Loss:3.420    Policy Loss: 8.519    Value Loss: 4.357    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1245967    Buffer Size: 16097      Transition Number: 1000.368k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:53:42,964][train][INFO][train.py>_log] ==> #446000     Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 8.834    Value Loss: 4.685    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1248275    Buffer Size: 16112      Transition Number: 1000.594k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:56:50,617][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.486    [weighted Loss:3.486    Policy Loss: 9.226    Value Loss: 4.422    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1250595    Buffer Size: 16102      Transition Number: 1000.217k Batch Size: 256        Lr: 0.00400 
[2022-02-26 01:59:59,857][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 9.088    Value Loss: 4.338    Reward Loss: 1.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252901    Buffer Size: 16100      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:03:04,628][train][INFO][train.py>_log] ==> #449000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 8.845    Value Loss: 4.538    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1255186    Buffer Size: 16100      Transition Number: 1000.196k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:06:11,725][train][INFO][train.py>_log] ==> #450000     Total Loss: 3.279    [weighted Loss:3.279    Policy Loss: 9.277    Value Loss: 4.442    Reward Loss: 2.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 1257452    Buffer Size: 16114      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:09:16,394][train][INFO][train.py>_log] ==> #451000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 9.504    Value Loss: 4.276    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1259781    Buffer Size: 16120      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:12:24,790][train][INFO][train.py>_log] ==> #452000     Total Loss: 4.139    [weighted Loss:4.139    Policy Loss: 9.588    Value Loss: 4.583    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1262063    Buffer Size: 16136      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:15:28,842][train][INFO][train.py>_log] ==> #453000     Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 9.868    Value Loss: 4.683    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1264348    Buffer Size: 16127      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:18:36,432][train][INFO][train.py>_log] ==> #454000     Total Loss: 4.438    [weighted Loss:4.438    Policy Loss: 9.725    Value Loss: 4.668    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266609    Buffer Size: 16129      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:21:42,049][train][INFO][train.py>_log] ==> #455000     Total Loss: 3.859    [weighted Loss:3.859    Policy Loss: 9.973    Value Loss: 4.602    Reward Loss: 1.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 1268938    Buffer Size: 16121      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:24:47,594][train][INFO][train.py>_log] ==> #456000     Total Loss: 4.076    [weighted Loss:4.076    Policy Loss: 10.064   Value Loss: 4.286    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1271196    Buffer Size: 16101      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:27:55,633][train][INFO][train.py>_log] ==> #457000     Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 9.782    Value Loss: 4.339    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 1273451    Buffer Size: 16071      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:31:04,064][train][INFO][train.py>_log] ==> #458000     Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 10.030   Value Loss: 4.117    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1275791    Buffer Size: 16040      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:34:14,385][train][INFO][train.py>_log] ==> #459000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 9.949    Value Loss: 4.539    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 1278095    Buffer Size: 16019      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:37:25,942][train][INFO][train.py>_log] ==> #460000     Total Loss: 3.965    [weighted Loss:3.965    Policy Loss: 10.309   Value Loss: 4.569    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 1280452    Buffer Size: 16015      Transition Number: 1000.310k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:40:36,051][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.628    [weighted Loss:3.628    Policy Loss: 9.582    Value Loss: 4.664    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 1282775    Buffer Size: 16010      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:43:46,473][train][INFO][train.py>_log] ==> #462000     Total Loss: 3.148    [weighted Loss:3.148    Policy Loss: 9.699    Value Loss: 4.345    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1285174    Buffer Size: 16003      Transition Number: 1000.427k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:46:55,747][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 9.889    Value Loss: 4.894    Reward Loss: 1.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 1287547    Buffer Size: 16016      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:50:06,205][train][INFO][train.py>_log] ==> #464000     Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 9.615    Value Loss: 4.260    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1289861    Buffer Size: 16058      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:53:13,685][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.593    [weighted Loss:3.593    Policy Loss: 9.957    Value Loss: 4.203    Reward Loss: 1.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 1292206    Buffer Size: 16099      Transition Number: 1000.382k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:56:21,942][train][INFO][train.py>_log] ==> #466000     Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 10.134   Value Loss: 4.644    Reward Loss: 1.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 1294561    Buffer Size: 16114      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 02:59:25,299][train][INFO][train.py>_log] ==> #467000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 9.900    Value Loss: 4.359    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1296876    Buffer Size: 16132      Transition Number: 1000.076k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:02:29,448][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 10.044   Value Loss: 4.573    Reward Loss: 1.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299150    Buffer Size: 16161      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:05:37,190][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 9.973    Value Loss: 4.253    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 1301408    Buffer Size: 16202      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:08:43,647][train][INFO][train.py>_log] ==> #470000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 10.248   Value Loss: 4.552    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 1303825    Buffer Size: 16225      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:11:52,876][train][INFO][train.py>_log] ==> #471000     Total Loss: 4.099    [weighted Loss:4.099    Policy Loss: 10.045   Value Loss: 4.846    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1306165    Buffer Size: 16233      Transition Number: 1000.209k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:15:06,112][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 9.977    Value Loss: 4.122    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1308502    Buffer Size: 16226      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:18:13,447][train][INFO][train.py>_log] ==> #473000     Total Loss: 4.597    [weighted Loss:4.597    Policy Loss: 9.890    Value Loss: 4.623    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 1310853    Buffer Size: 16232      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:21:30,030][train][INFO][train.py>_log] ==> #474000     Total Loss: 4.622    [weighted Loss:4.622    Policy Loss: 10.075   Value Loss: 4.250    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 1313288    Buffer Size: 16245      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:24:46,312][train][INFO][train.py>_log] ==> #475000     Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 10.157   Value Loss: 4.295    Reward Loss: 1.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 1315723    Buffer Size: 16246      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:27:55,487][train][INFO][train.py>_log] ==> #476000     Total Loss: 4.139    [weighted Loss:4.139    Policy Loss: 9.898    Value Loss: 4.364    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1318093    Buffer Size: 16243      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:31:05,725][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 10.204   Value Loss: 4.224    Reward Loss: 1.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 1320490    Buffer Size: 16214      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:34:14,662][train][INFO][train.py>_log] ==> #478000     Total Loss: 3.146    [weighted Loss:3.146    Policy Loss: 9.801    Value Loss: 4.316    Reward Loss: 1.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 1322815    Buffer Size: 16199      Transition Number: 1000.364k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:37:19,161][train][INFO][train.py>_log] ==> #479000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 9.828    Value Loss: 4.344    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1325215    Buffer Size: 16185      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:40:28,271][train][INFO][train.py>_log] ==> #480000     Total Loss: 4.091    [weighted Loss:4.091    Policy Loss: 9.969    Value Loss: 4.616    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 1327595    Buffer Size: 16168      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:43:36,546][train][INFO][train.py>_log] ==> #481000     Total Loss: 3.344    [weighted Loss:3.344    Policy Loss: 10.030   Value Loss: 4.515    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1329923    Buffer Size: 16150      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:46:41,711][train][INFO][train.py>_log] ==> #482000     Total Loss: 4.095    [weighted Loss:4.095    Policy Loss: 10.091   Value Loss: 4.104    Reward Loss: 1.932    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332302    Buffer Size: 16122      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:49:57,036][train][INFO][train.py>_log] ==> #483000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 9.373    Value Loss: 4.376    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1334744    Buffer Size: 16090      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:53:05,586][train][INFO][train.py>_log] ==> #484000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 9.510    Value Loss: 4.519    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1337077    Buffer Size: 16083      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:56:15,923][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 10.279   Value Loss: 4.724    Reward Loss: 1.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 1339506    Buffer Size: 16067      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00400 
[2022-02-26 03:59:24,233][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 10.007   Value Loss: 4.840    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1341904    Buffer Size: 16069      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:02:36,065][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 10.251   Value Loss: 4.272    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1344303    Buffer Size: 16064      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:05:50,488][train][INFO][train.py>_log] ==> #488000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 10.098   Value Loss: 4.341    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1346772    Buffer Size: 16061      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:08:57,581][train][INFO][train.py>_log] ==> #489000     Total Loss: 3.951    [weighted Loss:3.951    Policy Loss: 10.364   Value Loss: 4.480    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1349142    Buffer Size: 16062      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:12:09,879][train][INFO][train.py>_log] ==> #490000     Total Loss: 3.968    [weighted Loss:3.968    Policy Loss: 10.351   Value Loss: 4.461    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1351481    Buffer Size: 16060      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:15:21,427][train][INFO][train.py>_log] ==> #491000     Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 10.303   Value Loss: 4.389    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1353971    Buffer Size: 16071      Transition Number: 1000.343k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:18:30,017][train][INFO][train.py>_log] ==> #492000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 10.712   Value Loss: 4.357    Reward Loss: 1.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 1356421    Buffer Size: 16074      Transition Number: 1000.206k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:21:38,974][train][INFO][train.py>_log] ==> #493000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 10.902   Value Loss: 4.278    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1358793    Buffer Size: 16056      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:24:48,804][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.804    [weighted Loss:3.804    Policy Loss: 10.449   Value Loss: 4.080    Reward Loss: 1.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 1361185    Buffer Size: 16052      Transition Number: 1000.234k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:27:59,975][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 10.602   Value Loss: 4.300    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1363586    Buffer Size: 16042      Transition Number: 1000.716k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:31:08,846][train][INFO][train.py>_log] ==> #496000     Total Loss: 3.415    [weighted Loss:3.415    Policy Loss: 10.263   Value Loss: 4.252    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1365992    Buffer Size: 16013      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:34:18,845][train][INFO][train.py>_log] ==> #497000     Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 10.580   Value Loss: 4.419    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1368395    Buffer Size: 15993      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:37:30,563][train][INFO][train.py>_log] ==> #498000     Total Loss: 4.461    [weighted Loss:4.461    Policy Loss: 10.442   Value Loss: 4.599    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370772    Buffer Size: 15988      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:40:40,398][train][INFO][train.py>_log] ==> #499000     Total Loss: 3.371    [weighted Loss:3.371    Policy Loss: 10.585   Value Loss: 4.457    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373145    Buffer Size: 15975      Transition Number: 1000.081k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:43:48,492][train][INFO][train.py>_log] ==> #500000     Total Loss: 3.042    [weighted Loss:3.042    Policy Loss: 10.202   Value Loss: 4.641    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375565    Buffer Size: 15976      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:46:54,763][train][INFO][train.py>_log] ==> #501000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 10.157   Value Loss: 4.301    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1377893    Buffer Size: 15949      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:50:03,892][train][INFO][train.py>_log] ==> #502000     Total Loss: 3.289    [weighted Loss:3.289    Policy Loss: 10.284   Value Loss: 4.499    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1380298    Buffer Size: 15942      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:53:15,951][train][INFO][train.py>_log] ==> #503000     Total Loss: 2.539    [weighted Loss:2.539    Policy Loss: 9.860    Value Loss: 4.274    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1382771    Buffer Size: 15936      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:56:23,798][train][INFO][train.py>_log] ==> #504000     Total Loss: 3.921    [weighted Loss:3.921    Policy Loss: 9.980    Value Loss: 4.648    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1385197    Buffer Size: 15924      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00400 
[2022-02-26 04:59:33,009][train][INFO][train.py>_log] ==> #505000     Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 10.054   Value Loss: 4.537    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1387565    Buffer Size: 15923      Transition Number: 1000.257k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:02:38,225][train][INFO][train.py>_log] ==> #506000     Total Loss: 3.238    [weighted Loss:3.238    Policy Loss: 10.443   Value Loss: 4.279    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1389864    Buffer Size: 15913      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:05:41,905][train][INFO][train.py>_log] ==> #507000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 10.463   Value Loss: 4.193    Reward Loss: 1.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 1392171    Buffer Size: 15889      Transition Number: 1000.331k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:08:50,954][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.663    [weighted Loss:2.663    Policy Loss: 10.353   Value Loss: 4.358    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1394593    Buffer Size: 15886      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:11:58,624][train][INFO][train.py>_log] ==> #509000     Total Loss: 3.082    [weighted Loss:3.082    Policy Loss: 10.512   Value Loss: 4.207    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1396985    Buffer Size: 15893      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:15:08,502][train][INFO][train.py>_log] ==> #510000     Total Loss: 3.483    [weighted Loss:3.483    Policy Loss: 10.438   Value Loss: 4.266    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1399384    Buffer Size: 15900      Transition Number: 1000.304k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:18:19,454][train][INFO][train.py>_log] ==> #511000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 10.629   Value Loss: 4.311    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1401871    Buffer Size: 15904      Transition Number: 1000.375k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:21:28,908][train][INFO][train.py>_log] ==> #512000     Total Loss: 3.395    [weighted Loss:3.395    Policy Loss: 10.828   Value Loss: 4.178    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 1404246    Buffer Size: 15921      Transition Number: 1000.330k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:24:38,341][train][INFO][train.py>_log] ==> #513000     Total Loss: 3.577    [weighted Loss:3.577    Policy Loss: 10.946   Value Loss: 4.209    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406639    Buffer Size: 15921      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:27:44,646][train][INFO][train.py>_log] ==> #514000     Total Loss: 4.011    [weighted Loss:4.011    Policy Loss: 10.788   Value Loss: 4.450    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1409027    Buffer Size: 15949      Transition Number: 1000.238k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:30:53,124][train][INFO][train.py>_log] ==> #515000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 10.608   Value Loss: 4.298    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411422    Buffer Size: 15951      Transition Number: 1000.577k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:33:58,755][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 10.214   Value Loss: 4.340    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1413836    Buffer Size: 15927      Transition Number: 1000.328k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:37:06,088][train][INFO][train.py>_log] ==> #517000     Total Loss: 4.209    [weighted Loss:4.209    Policy Loss: 10.744   Value Loss: 4.495    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1416144    Buffer Size: 15908      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:40:12,613][train][INFO][train.py>_log] ==> #518000     Total Loss: 4.696    [weighted Loss:4.696    Policy Loss: 10.310   Value Loss: 4.322    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1418472    Buffer Size: 15877      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:43:21,896][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 10.336   Value Loss: 4.477    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1420883    Buffer Size: 15840      Transition Number: 1000.289k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:46:32,810][train][INFO][train.py>_log] ==> #520000     Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 10.652   Value Loss: 4.372    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1423269    Buffer Size: 15819      Transition Number: 1000.384k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:49:45,683][train][INFO][train.py>_log] ==> #521000     Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 10.782   Value Loss: 4.496    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1425692    Buffer Size: 15764      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:52:52,634][train][INFO][train.py>_log] ==> #522000     Total Loss: 3.966    [weighted Loss:3.966    Policy Loss: 10.249   Value Loss: 4.452    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1428088    Buffer Size: 15745      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:55:58,550][train][INFO][train.py>_log] ==> #523000     Total Loss: 4.460    [weighted Loss:4.460    Policy Loss: 10.438   Value Loss: 4.449    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1430417    Buffer Size: 15750      Transition Number: 1000.468k Batch Size: 256        Lr: 0.00400 
[2022-02-26 05:59:03,482][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 10.049   Value Loss: 4.582    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1432763    Buffer Size: 15771      Transition Number: 1000.571k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:02:12,712][train][INFO][train.py>_log] ==> #525000     Total Loss: 4.185    [weighted Loss:4.185    Policy Loss: 9.777    Value Loss: 4.773    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435221    Buffer Size: 15803      Transition Number: 1000.358k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:05:24,351][train][INFO][train.py>_log] ==> #526000     Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 9.831    Value Loss: 4.543    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1437664    Buffer Size: 15835      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:08:35,744][train][INFO][train.py>_log] ==> #527000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 9.818    Value Loss: 4.488    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440061    Buffer Size: 15869      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:11:48,645][train][INFO][train.py>_log] ==> #528000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 9.652    Value Loss: 4.666    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 1442504    Buffer Size: 15897      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:14:56,541][train][INFO][train.py>_log] ==> #529000     Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 9.886    Value Loss: 4.390    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1444896    Buffer Size: 15921      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:18:04,170][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.451    [weighted Loss:1.451    Policy Loss: 9.373    Value Loss: 4.605    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1447280    Buffer Size: 15908      Transition Number: 1000.244k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:21:13,210][train][INFO][train.py>_log] ==> #531000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 9.516    Value Loss: 4.458    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1449685    Buffer Size: 15859      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:24:17,130][train][INFO][train.py>_log] ==> #532000     Total Loss: 3.988    [weighted Loss:3.988    Policy Loss: 10.051   Value Loss: 4.655    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451984    Buffer Size: 15828      Transition Number: 1000.239k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:27:22,298][train][INFO][train.py>_log] ==> #533000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 9.789    Value Loss: 4.397    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1454330    Buffer Size: 15819      Transition Number: 1000.611k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:30:31,429][train][INFO][train.py>_log] ==> #534000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 10.090   Value Loss: 4.633    Reward Loss: 1.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 1456745    Buffer Size: 15810      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:33:43,484][train][INFO][train.py>_log] ==> #535000     Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 9.535    Value Loss: 4.536    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 1459181    Buffer Size: 15798      Transition Number: 1000.586k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:36:52,989][train][INFO][train.py>_log] ==> #536000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 9.697    Value Loss: 4.782    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1461599    Buffer Size: 15794      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:40:03,208][train][INFO][train.py>_log] ==> #537000     Total Loss: 3.780    [weighted Loss:3.780    Policy Loss: 10.169   Value Loss: 4.418    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 1463977    Buffer Size: 15802      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:43:14,484][train][INFO][train.py>_log] ==> #538000     Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 9.835    Value Loss: 4.521    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1466372    Buffer Size: 15824      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:46:23,058][train][INFO][train.py>_log] ==> #539000     Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 10.324   Value Loss: 4.583    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1468796    Buffer Size: 15847      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:49:36,504][train][INFO][train.py>_log] ==> #540000     Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 10.226   Value Loss: 4.566    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1471223    Buffer Size: 15863      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:52:43,927][train][INFO][train.py>_log] ==> #541000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 9.799    Value Loss: 4.075    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1473610    Buffer Size: 15896      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:55:54,793][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 9.447    Value Loss: 4.498    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1476072    Buffer Size: 15941      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00400 
[2022-02-26 06:59:02,924][train][INFO][train.py>_log] ==> #543000     Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 9.789    Value Loss: 4.316    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1478483    Buffer Size: 16005      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:02:08,354][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.927    [weighted Loss:1.927    Policy Loss: 9.952    Value Loss: 4.417    Reward Loss: 1.557    Consistency Loss: 0.000    ] Replay Episodes Collected: 1480856    Buffer Size: 16083      Transition Number: 1000.308k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:05:22,522][train][INFO][train.py>_log] ==> #545000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 10.008   Value Loss: 4.464    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1483334    Buffer Size: 16172      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:08:31,084][train][INFO][train.py>_log] ==> #546000     Total Loss: 2.477    [weighted Loss:2.477    Policy Loss: 9.838    Value Loss: 4.718    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485802    Buffer Size: 16271      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:11:39,687][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 10.101   Value Loss: 4.490    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1488242    Buffer Size: 16364      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:14:47,944][train][INFO][train.py>_log] ==> #548000     Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 10.134   Value Loss: 4.367    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1490652    Buffer Size: 16438      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:17:58,773][train][INFO][train.py>_log] ==> #549000     Total Loss: 1.611    [weighted Loss:1.611    Policy Loss: 10.323   Value Loss: 4.887    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1493055    Buffer Size: 16502      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:21:08,429][train][INFO][train.py>_log] ==> #550000     Total Loss: 3.298    [weighted Loss:3.298    Policy Loss: 10.103   Value Loss: 4.482    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 1495481    Buffer Size: 16517      Transition Number: 1000.436k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:24:14,811][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.586    [weighted Loss:3.586    Policy Loss: 10.411   Value Loss: 4.602    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1497915    Buffer Size: 16511      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:27:23,454][train][INFO][train.py>_log] ==> #552000     Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 10.195   Value Loss: 4.471    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1500374    Buffer Size: 16488      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:30:33,391][train][INFO][train.py>_log] ==> #553000     Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 10.232   Value Loss: 4.729    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1502731    Buffer Size: 16474      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:33:43,266][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 10.348   Value Loss: 4.554    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1505208    Buffer Size: 16444      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:36:51,796][train][INFO][train.py>_log] ==> #555000     Total Loss: 3.501    [weighted Loss:3.501    Policy Loss: 10.099   Value Loss: 4.670    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 1507658    Buffer Size: 16434      Transition Number: 1000.214k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:39:57,420][train][INFO][train.py>_log] ==> #556000     Total Loss: 3.341    [weighted Loss:3.341    Policy Loss: 10.105   Value Loss: 4.503    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1510077    Buffer Size: 16436      Transition Number: 1000.178k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:43:04,874][train][INFO][train.py>_log] ==> #557000     Total Loss: 3.994    [weighted Loss:3.994    Policy Loss: 10.466   Value Loss: 4.871    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1512548    Buffer Size: 16471      Transition Number: 1000.168k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:46:13,502][train][INFO][train.py>_log] ==> #558000     Total Loss: 3.957    [weighted Loss:3.957    Policy Loss: 10.354   Value Loss: 4.349    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1514996    Buffer Size: 16517      Transition Number: 1000.600k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:49:21,512][train][INFO][train.py>_log] ==> #559000     Total Loss: 3.947    [weighted Loss:3.947    Policy Loss: 10.183   Value Loss: 4.614    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1517403    Buffer Size: 16512      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:52:28,246][train][INFO][train.py>_log] ==> #560000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 9.887    Value Loss: 4.654    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1519739    Buffer Size: 16549      Transition Number: 1000.234k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:55:41,282][train][INFO][train.py>_log] ==> #561000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 10.320   Value Loss: 4.670    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1522239    Buffer Size: 16562      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00400 
[2022-02-26 07:58:52,312][train][INFO][train.py>_log] ==> #562000     Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 10.219   Value Loss: 4.598    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524745    Buffer Size: 16591      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:01:59,474][train][INFO][train.py>_log] ==> #563000     Total Loss: 3.262    [weighted Loss:3.262    Policy Loss: 10.065   Value Loss: 4.645    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 1527118    Buffer Size: 16592      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:05:10,533][train][INFO][train.py>_log] ==> #564000     Total Loss: 3.439    [weighted Loss:3.439    Policy Loss: 10.250   Value Loss: 4.483    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1529620    Buffer Size: 16567      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:08:24,053][train][INFO][train.py>_log] ==> #565000     Total Loss: 3.687    [weighted Loss:3.687    Policy Loss: 10.556   Value Loss: 4.416    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1532086    Buffer Size: 16565      Transition Number: 1000.372k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:11:35,601][train][INFO][train.py>_log] ==> #566000     Total Loss: 3.275    [weighted Loss:3.275    Policy Loss: 10.449   Value Loss: 4.924    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1534581    Buffer Size: 16531      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:14:45,109][train][INFO][train.py>_log] ==> #567000     Total Loss: 4.348    [weighted Loss:4.348    Policy Loss: 10.644   Value Loss: 4.555    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1537022    Buffer Size: 16518      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:17:54,059][train][INFO][train.py>_log] ==> #568000     Total Loss: 4.215    [weighted Loss:4.215    Policy Loss: 10.871   Value Loss: 4.485    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1539400    Buffer Size: 16477      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:21:05,487][train][INFO][train.py>_log] ==> #569000     Total Loss: 3.945    [weighted Loss:3.945    Policy Loss: 11.320   Value Loss: 4.748    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1541864    Buffer Size: 16417      Transition Number: 1000.273k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:24:14,818][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 10.834   Value Loss: 4.180    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 1544200    Buffer Size: 16370      Transition Number: 1000.378k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:27:28,085][train][INFO][train.py>_log] ==> #571000     Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 10.873   Value Loss: 4.337    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1546754    Buffer Size: 16320      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:30:38,029][train][INFO][train.py>_log] ==> #572000     Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 10.615   Value Loss: 4.595    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1549214    Buffer Size: 16264      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:33:49,294][train][INFO][train.py>_log] ==> #573000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 10.765   Value Loss: 4.656    Reward Loss: 1.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 1551591    Buffer Size: 16246      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:37:00,425][train][INFO][train.py>_log] ==> #574000     Total Loss: 1.523    [weighted Loss:1.523    Policy Loss: 10.919   Value Loss: 4.670    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1554130    Buffer Size: 16220      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:40:13,507][train][INFO][train.py>_log] ==> #575000     Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 10.870   Value Loss: 4.570    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 1556623    Buffer Size: 16217      Transition Number: 1000.557k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:43:21,299][train][INFO][train.py>_log] ==> #576000     Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 10.662   Value Loss: 4.460    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1559012    Buffer Size: 16203      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:46:35,414][train][INFO][train.py>_log] ==> #577000     Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 11.047   Value Loss: 4.628    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1561482    Buffer Size: 16196      Transition Number: 1000.294k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:49:52,045][train][INFO][train.py>_log] ==> #578000     Total Loss: 2.853    [weighted Loss:2.853    Policy Loss: 10.153   Value Loss: 4.577    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 1563924    Buffer Size: 16199      Transition Number: 1000.245k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:53:03,441][train][INFO][train.py>_log] ==> #579000     Total Loss: 4.823    [weighted Loss:4.823    Policy Loss: 10.803   Value Loss: 4.481    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1566304    Buffer Size: 16187      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:56:14,338][train][INFO][train.py>_log] ==> #580000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 10.916   Value Loss: 4.443    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 1568831    Buffer Size: 16167      Transition Number: 1000.337k Batch Size: 256        Lr: 0.00400 
[2022-02-26 08:59:23,151][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.683    [weighted Loss:3.683    Policy Loss: 10.551   Value Loss: 4.828    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1571197    Buffer Size: 16135      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:02:33,676][train][INFO][train.py>_log] ==> #582000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 10.762   Value Loss: 4.863    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1573620    Buffer Size: 16101      Transition Number: 1000.245k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:05:43,884][train][INFO][train.py>_log] ==> #583000     Total Loss: 2.892    [weighted Loss:2.892    Policy Loss: 10.555   Value Loss: 4.741    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 1576005    Buffer Size: 16090      Transition Number: 1000.271k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:08:57,158][train][INFO][train.py>_log] ==> #584000     Total Loss: 4.000    [weighted Loss:4.000    Policy Loss: 10.367   Value Loss: 4.780    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1578482    Buffer Size: 16050      Transition Number: 1000.148k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:12:09,635][train][INFO][train.py>_log] ==> #585000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 10.591   Value Loss: 4.681    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1580993    Buffer Size: 16051      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:15:25,751][train][INFO][train.py>_log] ==> #586000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 10.269   Value Loss: 4.578    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 1583510    Buffer Size: 16057      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:18:34,370][train][INFO][train.py>_log] ==> #587000     Total Loss: 3.739    [weighted Loss:3.739    Policy Loss: 10.480   Value Loss: 4.442    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 1585886    Buffer Size: 16041      Transition Number: 1000.360k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:21:43,946][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 10.423   Value Loss: 4.596    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1588292    Buffer Size: 16054      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:24:55,848][train][INFO][train.py>_log] ==> #589000     Total Loss: 4.723    [weighted Loss:4.723    Policy Loss: 10.605   Value Loss: 4.462    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 1590777    Buffer Size: 16070      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:28:07,861][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 10.735   Value Loss: 4.634    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 1593290    Buffer Size: 16092      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:31:23,060][train][INFO][train.py>_log] ==> #591000     Total Loss: 3.424    [weighted Loss:3.424    Policy Loss: 10.892   Value Loss: 4.615    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1595847    Buffer Size: 16127      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:34:38,067][train][INFO][train.py>_log] ==> #592000     Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 10.400   Value Loss: 4.557    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1598300    Buffer Size: 16136      Transition Number: 1000.266k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:37:50,437][train][INFO][train.py>_log] ==> #593000     Total Loss: 3.871    [weighted Loss:3.871    Policy Loss: 10.602   Value Loss: 4.129    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1600776    Buffer Size: 16167      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:41:02,732][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 10.802   Value Loss: 4.673    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 1603278    Buffer Size: 16213      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:44:18,213][train][INFO][train.py>_log] ==> #595000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 10.876   Value Loss: 4.521    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1605730    Buffer Size: 16269      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:47:32,356][train][INFO][train.py>_log] ==> #596000     Total Loss: 3.961    [weighted Loss:3.961    Policy Loss: 10.543   Value Loss: 4.461    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1608239    Buffer Size: 16310      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:50:44,245][train][INFO][train.py>_log] ==> #597000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 10.597   Value Loss: 4.933    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1610745    Buffer Size: 16330      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:53:58,600][train][INFO][train.py>_log] ==> #598000     Total Loss: 1.956    [weighted Loss:1.956    Policy Loss: 10.734   Value Loss: 4.441    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1613181    Buffer Size: 16355      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00400 
[2022-02-26 09:57:13,081][train][INFO][train.py>_log] ==> #599000     Total Loss: 4.320    [weighted Loss:4.320    Policy Loss: 10.516   Value Loss: 4.389    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1615775    Buffer Size: 16381      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00400 
[2022-02-26 10:00:22,687][train][INFO][train.py>_log] ==> #600000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 10.691   Value Loss: 4.188    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1618224    Buffer Size: 16395      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00400 
[2022-02-26 10:03:37,855][train][INFO][train.py>_log] ==> #601000     Total Loss: 4.372    [weighted Loss:4.372    Policy Loss: 10.341   Value Loss: 4.460    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 1620652    Buffer Size: 16410      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:06:50,732][train][INFO][train.py>_log] ==> #602000     Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 10.169   Value Loss: 4.632    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 1623090    Buffer Size: 16408      Transition Number: 1000.544k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:10:02,561][train][INFO][train.py>_log] ==> #603000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 10.598   Value Loss: 4.499    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1625649    Buffer Size: 16392      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00080 
[2022-02-26 10:13:14,102][train][INFO][train.py>_log] ==> #604000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 10.280   Value Loss: 4.423    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1628057    Buffer Size: 16398      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00080 
