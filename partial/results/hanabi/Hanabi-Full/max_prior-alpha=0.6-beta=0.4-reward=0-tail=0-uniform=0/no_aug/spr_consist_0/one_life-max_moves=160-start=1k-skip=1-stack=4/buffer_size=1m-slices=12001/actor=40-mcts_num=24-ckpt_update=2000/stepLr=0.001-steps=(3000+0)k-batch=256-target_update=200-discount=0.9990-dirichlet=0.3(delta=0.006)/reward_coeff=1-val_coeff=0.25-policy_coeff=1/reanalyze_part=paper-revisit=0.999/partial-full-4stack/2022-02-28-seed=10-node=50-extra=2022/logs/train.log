[2022-02-28 11:24:19,190][train][INFO][train.py>_log] ==> #0          Total Loss: 34.784   [weighted Loss:34.784   Policy Loss: 23.218   Value Loss: 39.556   Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 60         Buffer Size: 15258      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00000 
[2022-02-28 11:27:00,916][train][INFO][train.py>_log] ==> #1000       Total Loss: 9.297    [weighted Loss:9.297    Policy Loss: 11.225   Value Loss: 7.126    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 10277      Buffer Size: 23551      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:29:43,713][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.987    [weighted Loss:4.987    Policy Loss: 6.506    Value Loss: 5.779    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 20463      Buffer Size: 31815      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:32:32,848][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.184    [weighted Loss:4.184    Policy Loss: 6.091    Value Loss: 5.851    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 22693      Buffer Size: 32133      Transition Number: 1000.142k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:35:22,497][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.823    [weighted Loss:4.823    Policy Loss: 10.639   Value Loss: 6.600    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 24910      Buffer Size: 32295      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:38:10,747][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 5.973    Value Loss: 5.169    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 27041      Buffer Size: 32400      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:40:58,837][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.552    [weighted Loss:3.552    Policy Loss: 6.331    Value Loss: 5.035    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 29137      Buffer Size: 32498      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:43:48,296][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 5.775    Value Loss: 4.883    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 31302      Buffer Size: 32594      Transition Number: 1000.182k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:46:38,031][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 6.187    Value Loss: 5.124    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 33387      Buffer Size: 29426      Transition Number: 1000.180k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:49:35,035][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 6.441    Value Loss: 4.562    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 35579      Buffer Size: 20396      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:52:26,878][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.707    [weighted Loss:4.707    Policy Loss: 7.283    Value Loss: 4.241    Reward Loss: 2.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 37744      Buffer Size: 15898      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:55:18,888][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.258    [weighted Loss:4.258    Policy Loss: 7.253    Value Loss: 4.745    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 39773      Buffer Size: 15796      Transition Number: 1000.092k Batch Size: 256        Lr: 0.00100 
[2022-02-28 11:58:08,787][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 7.898    Value Loss: 4.468    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 41891      Buffer Size: 15698      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:00:57,076][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.895    [weighted Loss:3.895    Policy Loss: 8.196    Value Loss: 4.073    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 43954      Buffer Size: 15639      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:03:47,293][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.363    [weighted Loss:4.363    Policy Loss: 8.464    Value Loss: 4.254    Reward Loss: 1.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 46021      Buffer Size: 15559      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:06:35,021][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.562    [weighted Loss:3.562    Policy Loss: 8.596    Value Loss: 4.418    Reward Loss: 1.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 48111      Buffer Size: 15485      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:09:28,730][train][INFO][train.py>_log] ==> #16000      Total Loss: 4.066    [weighted Loss:4.066    Policy Loss: 8.959    Value Loss: 4.264    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 50281      Buffer Size: 15435      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:12:23,551][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 8.504    Value Loss: 4.142    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 52475      Buffer Size: 15391      Transition Number: 1000.495k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:15:18,885][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.196    [weighted Loss:4.196    Policy Loss: 9.086    Value Loss: 4.114    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 54673      Buffer Size: 15384      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:18:08,563][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.650    [weighted Loss:4.650    Policy Loss: 8.981    Value Loss: 4.080    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 56753      Buffer Size: 15391      Transition Number: 1000.130k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:21:05,193][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.197    [weighted Loss:4.197    Policy Loss: 9.364    Value Loss: 4.384    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 59021      Buffer Size: 15397      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:23:59,862][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.983    [weighted Loss:3.983    Policy Loss: 9.248    Value Loss: 4.473    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 61193      Buffer Size: 15433      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:26:51,531][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 9.231    Value Loss: 4.558    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 63318      Buffer Size: 15471      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:29:44,954][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.533    [weighted Loss:3.533    Policy Loss: 9.201    Value Loss: 4.355    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 65528      Buffer Size: 15491      Transition Number: 1000.149k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:32:44,929][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.666    [weighted Loss:3.666    Policy Loss: 10.104   Value Loss: 4.383    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 67857      Buffer Size: 15493      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:35:39,545][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.738    [weighted Loss:4.738    Policy Loss: 9.811    Value Loss: 4.200    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 70070      Buffer Size: 15501      Transition Number: 1000.275k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:38:32,279][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.765    [weighted Loss:3.765    Policy Loss: 9.821    Value Loss: 4.394    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 72256      Buffer Size: 15499      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:41:26,365][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.350    [weighted Loss:2.350    Policy Loss: 9.873    Value Loss: 4.511    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 74532      Buffer Size: 15506      Transition Number: 1000.073k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:44:27,230][train][INFO][train.py>_log] ==> #28000      Total Loss: 5.570    [weighted Loss:5.570    Policy Loss: 10.168   Value Loss: 4.180    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 76782      Buffer Size: 15515      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:47:23,220][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.013    [weighted Loss:4.013    Policy Loss: 10.294   Value Loss: 4.177    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 78985      Buffer Size: 15535      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:50:22,325][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.594    [weighted Loss:4.594    Policy Loss: 10.456   Value Loss: 4.238    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 81269      Buffer Size: 15563      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:53:21,013][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.570    [weighted Loss:4.570    Policy Loss: 10.611   Value Loss: 4.387    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 83584      Buffer Size: 15618      Transition Number: 1000.243k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:56:19,308][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.178    [weighted Loss:4.178    Policy Loss: 10.306   Value Loss: 4.616    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 85815      Buffer Size: 15640      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 12:59:18,453][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.577    [weighted Loss:4.577    Policy Loss: 10.633   Value Loss: 4.199    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 88065      Buffer Size: 15691      Transition Number: 1000.472k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:02:15,988][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 10.139   Value Loss: 4.667    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 90351      Buffer Size: 15716      Transition Number: 1000.300k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:05:15,055][train][INFO][train.py>_log] ==> #35000      Total Loss: 4.424    [weighted Loss:4.424    Policy Loss: 10.520   Value Loss: 4.230    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 92678      Buffer Size: 15720      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:08:11,761][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.888    [weighted Loss:3.888    Policy Loss: 10.545   Value Loss: 4.276    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 94966      Buffer Size: 15728      Transition Number: 1000.417k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:11:12,252][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.557    [weighted Loss:4.557    Policy Loss: 10.793   Value Loss: 4.210    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 97280      Buffer Size: 15735      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:14:14,717][train][INFO][train.py>_log] ==> #38000      Total Loss: 4.188    [weighted Loss:4.188    Policy Loss: 10.728   Value Loss: 4.346    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 99667      Buffer Size: 15744      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:17:14,902][train][INFO][train.py>_log] ==> #39000      Total Loss: 4.833    [weighted Loss:4.833    Policy Loss: 10.711   Value Loss: 4.455    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 101988     Buffer Size: 15743      Transition Number: 1000.144k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:20:20,960][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 10.837   Value Loss: 4.094    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 104361     Buffer Size: 15763      Transition Number: 1000.326k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:23:19,690][train][INFO][train.py>_log] ==> #41000      Total Loss: 4.120    [weighted Loss:4.120    Policy Loss: 10.404   Value Loss: 4.145    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 106661     Buffer Size: 15774      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:26:22,467][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 10.490   Value Loss: 4.379    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 108976     Buffer Size: 15800      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:29:27,700][train][INFO][train.py>_log] ==> #43000      Total Loss: 4.334    [weighted Loss:4.334    Policy Loss: 10.490   Value Loss: 4.409    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 111367     Buffer Size: 15828      Transition Number: 1000.316k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:32:57,599][train][INFO][train.py>_log] ==> #44000      Total Loss: 4.884    [weighted Loss:4.884    Policy Loss: 10.727   Value Loss: 4.746    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 114068     Buffer Size: 15843      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:36:33,746][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.551    [weighted Loss:3.551    Policy Loss: 10.730   Value Loss: 4.822    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 116706     Buffer Size: 15872      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:40:07,571][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.800    [weighted Loss:3.800    Policy Loss: 10.475   Value Loss: 4.342    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 119466     Buffer Size: 15922      Transition Number: 1000.904k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:43:40,397][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.196    [weighted Loss:4.196    Policy Loss: 10.408   Value Loss: 4.203    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 122309     Buffer Size: 15929      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:47:10,892][train][INFO][train.py>_log] ==> #48000      Total Loss: 4.677    [weighted Loss:4.677    Policy Loss: 10.398   Value Loss: 4.076    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 125070     Buffer Size: 15949      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:50:28,039][train][INFO][train.py>_log] ==> #49000      Total Loss: 4.804    [weighted Loss:4.804    Policy Loss: 10.581   Value Loss: 4.431    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 127660     Buffer Size: 15989      Transition Number: 1000.363k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:53:29,179][train][INFO][train.py>_log] ==> #50000      Total Loss: 4.111    [weighted Loss:4.111    Policy Loss: 10.491   Value Loss: 4.396    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 129929     Buffer Size: 16030      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:56:21,652][train][INFO][train.py>_log] ==> #51000      Total Loss: 4.197    [weighted Loss:4.197    Policy Loss: 11.140   Value Loss: 4.341    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 132179     Buffer Size: 16064      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 13:59:15,711][train][INFO][train.py>_log] ==> #52000      Total Loss: 6.152    [weighted Loss:6.152    Policy Loss: 10.893   Value Loss: 4.480    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 134380     Buffer Size: 16097      Transition Number: 1000.341k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:02:12,222][train][INFO][train.py>_log] ==> #53000      Total Loss: 4.394    [weighted Loss:4.394    Policy Loss: 10.227   Value Loss: 4.194    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 136656     Buffer Size: 16127      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:05:04,237][train][INFO][train.py>_log] ==> #54000      Total Loss: 5.195    [weighted Loss:5.195    Policy Loss: 10.627   Value Loss: 4.306    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 138905     Buffer Size: 16165      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:08:00,049][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 10.737   Value Loss: 4.264    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 141181     Buffer Size: 16199      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:10:52,300][train][INFO][train.py>_log] ==> #56000      Total Loss: 4.374    [weighted Loss:4.374    Policy Loss: 11.077   Value Loss: 4.161    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 143401     Buffer Size: 16230      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:13:42,823][train][INFO][train.py>_log] ==> #57000      Total Loss: 5.244    [weighted Loss:5.244    Policy Loss: 10.334   Value Loss: 4.579    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 145574     Buffer Size: 16238      Transition Number: 1000.349k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:16:37,032][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.460    [weighted Loss:3.460    Policy Loss: 10.433   Value Loss: 4.305    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 147830     Buffer Size: 16227      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:19:32,673][train][INFO][train.py>_log] ==> #59000      Total Loss: 4.331    [weighted Loss:4.331    Policy Loss: 10.262   Value Loss: 4.295    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 150072     Buffer Size: 16217      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:22:29,186][train][INFO][train.py>_log] ==> #60000      Total Loss: 5.060    [weighted Loss:5.060    Policy Loss: 10.389   Value Loss: 4.472    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 152301     Buffer Size: 16200      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:25:24,466][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.631    [weighted Loss:4.631    Policy Loss: 10.666   Value Loss: 4.542    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 154570     Buffer Size: 16191      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:28:19,155][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.353    [weighted Loss:4.353    Policy Loss: 10.598   Value Loss: 4.189    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 156770     Buffer Size: 16185      Transition Number: 1000.369k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:31:13,408][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 10.236   Value Loss: 4.269    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 159093     Buffer Size: 16144      Transition Number: 1000.255k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:34:08,745][train][INFO][train.py>_log] ==> #64000      Total Loss: 4.351    [weighted Loss:4.351    Policy Loss: 10.429   Value Loss: 4.484    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 161258     Buffer Size: 16140      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:37:05,633][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 10.109   Value Loss: 4.545    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 163569     Buffer Size: 16134      Transition Number: 1000.246k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:39:57,040][train][INFO][train.py>_log] ==> #66000      Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 10.212   Value Loss: 4.252    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 165737     Buffer Size: 16133      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:42:54,177][train][INFO][train.py>_log] ==> #67000      Total Loss: 5.323    [weighted Loss:5.323    Policy Loss: 10.074   Value Loss: 4.603    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 167936     Buffer Size: 16136      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:45:50,270][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.862    [weighted Loss:3.862    Policy Loss: 10.210   Value Loss: 4.199    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 170221     Buffer Size: 16145      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:48:48,847][train][INFO][train.py>_log] ==> #69000      Total Loss: 5.473    [weighted Loss:5.473    Policy Loss: 10.460   Value Loss: 4.634    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 172495     Buffer Size: 16166      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:51:45,422][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 9.935    Value Loss: 4.245    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 174777     Buffer Size: 16192      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:54:45,350][train][INFO][train.py>_log] ==> #71000      Total Loss: 4.824    [weighted Loss:4.824    Policy Loss: 10.460   Value Loss: 4.444    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 177006     Buffer Size: 16200      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00100 
[2022-02-28 14:57:41,789][train][INFO][train.py>_log] ==> #72000      Total Loss: 4.318    [weighted Loss:4.318    Policy Loss: 10.367   Value Loss: 4.492    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 179263     Buffer Size: 16210      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:00:35,253][train][INFO][train.py>_log] ==> #73000      Total Loss: 5.440    [weighted Loss:5.440    Policy Loss: 10.456   Value Loss: 4.437    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 181473     Buffer Size: 16209      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:03:31,151][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.875    [weighted Loss:2.875    Policy Loss: 9.818    Value Loss: 4.464    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 183696     Buffer Size: 16213      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:06:25,793][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.607    [weighted Loss:4.607    Policy Loss: 10.325   Value Loss: 4.146    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 185991     Buffer Size: 16237      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:09:22,793][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.926    [weighted Loss:4.926    Policy Loss: 10.305   Value Loss: 4.798    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 188323     Buffer Size: 16239      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:12:20,858][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.493    [weighted Loss:3.493    Policy Loss: 10.279   Value Loss: 4.333    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 190606     Buffer Size: 16259      Transition Number: 1000.229k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:15:18,823][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.122    [weighted Loss:4.122    Policy Loss: 10.314   Value Loss: 4.518    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 192854     Buffer Size: 16271      Transition Number: 1000.159k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:18:16,680][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.524    [weighted Loss:3.524    Policy Loss: 9.818    Value Loss: 4.389    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 195137     Buffer Size: 16281      Transition Number: 1000.256k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:21:15,144][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.770    [weighted Loss:3.770    Policy Loss: 9.912    Value Loss: 4.551    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 197410     Buffer Size: 16299      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:24:14,867][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.660    [weighted Loss:3.660    Policy Loss: 10.230   Value Loss: 4.270    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 199716     Buffer Size: 16316      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:27:15,487][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.564    [weighted Loss:3.564    Policy Loss: 9.598    Value Loss: 4.462    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 202005     Buffer Size: 16299      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:30:14,693][train][INFO][train.py>_log] ==> #83000      Total Loss: 4.620    [weighted Loss:4.620    Policy Loss: 9.869    Value Loss: 4.339    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 204331     Buffer Size: 16297      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:33:14,654][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 9.617    Value Loss: 4.390    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 206669     Buffer Size: 16298      Transition Number: 1000.550k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:36:14,069][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 9.780    Value Loss: 4.107    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 208927     Buffer Size: 16275      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:39:13,741][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.274    [weighted Loss:4.274    Policy Loss: 9.653    Value Loss: 4.554    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 211153     Buffer Size: 16273      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:42:15,595][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.261    [weighted Loss:4.261    Policy Loss: 9.857    Value Loss: 4.182    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 213502     Buffer Size: 16267      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:45:15,070][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.325    [weighted Loss:4.325    Policy Loss: 9.762    Value Loss: 4.457    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 215772     Buffer Size: 16255      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:48:14,309][train][INFO][train.py>_log] ==> #89000      Total Loss: 4.609    [weighted Loss:4.609    Policy Loss: 9.510    Value Loss: 4.460    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 218007     Buffer Size: 16263      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:51:16,019][train][INFO][train.py>_log] ==> #90000      Total Loss: 4.651    [weighted Loss:4.651    Policy Loss: 9.885    Value Loss: 4.402    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 220280     Buffer Size: 16245      Transition Number: 1000.290k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:54:19,905][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.655    [weighted Loss:3.655    Policy Loss: 9.723    Value Loss: 4.431    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 222713     Buffer Size: 16228      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00100 
[2022-02-28 15:57:16,740][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.262    [weighted Loss:4.262    Policy Loss: 9.703    Value Loss: 4.314    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 224957     Buffer Size: 16200      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:00:16,177][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.206    [weighted Loss:3.206    Policy Loss: 10.041   Value Loss: 4.500    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 227216     Buffer Size: 16194      Transition Number: 1000.566k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:03:18,001][train][INFO][train.py>_log] ==> #94000      Total Loss: 5.038    [weighted Loss:5.038    Policy Loss: 9.769    Value Loss: 4.343    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 229560     Buffer Size: 16164      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:06:18,581][train][INFO][train.py>_log] ==> #95000      Total Loss: 4.457    [weighted Loss:4.457    Policy Loss: 10.049   Value Loss: 4.613    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 231895     Buffer Size: 16143      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:09:17,921][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.287    [weighted Loss:5.287    Policy Loss: 10.006   Value Loss: 4.284    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 234161     Buffer Size: 16121      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:12:18,542][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.875    [weighted Loss:4.875    Policy Loss: 9.842    Value Loss: 4.493    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 236508     Buffer Size: 16124      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:15:15,425][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.628    [weighted Loss:4.628    Policy Loss: 9.587    Value Loss: 4.290    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 238725     Buffer Size: 16122      Transition Number: 1000.146k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:18:14,191][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.567    [weighted Loss:3.567    Policy Loss: 9.309    Value Loss: 3.973    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 240993     Buffer Size: 16127      Transition Number: 1000.076k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:21:11,911][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.230    [weighted Loss:4.230    Policy Loss: 9.499    Value Loss: 4.202    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 243216     Buffer Size: 16145      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00100 
[2022-02-28 16:24:05,214][train][INFO][train.py>_log] ==> #101000     Total Loss: 4.308    [weighted Loss:4.308    Policy Loss: 9.817    Value Loss: 4.191    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 245442     Buffer Size: 16172      Transition Number: 1000.289k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:27:02,441][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 9.665    Value Loss: 4.274    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 247699     Buffer Size: 16203      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:29:58,636][train][INFO][train.py>_log] ==> #103000     Total Loss: 4.156    [weighted Loss:4.156    Policy Loss: 9.319    Value Loss: 4.158    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 249971     Buffer Size: 16234      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:32:55,116][train][INFO][train.py>_log] ==> #104000     Total Loss: 4.016    [weighted Loss:4.016    Policy Loss: 9.879    Value Loss: 4.234    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 252162     Buffer Size: 16258      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:35:53,186][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.685    [weighted Loss:3.685    Policy Loss: 9.617    Value Loss: 4.447    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 254444     Buffer Size: 16265      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:38:49,485][train][INFO][train.py>_log] ==> #106000     Total Loss: 5.038    [weighted Loss:5.038    Policy Loss: 9.466    Value Loss: 4.379    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 256697     Buffer Size: 16283      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:41:47,919][train][INFO][train.py>_log] ==> #107000     Total Loss: 1.823    [weighted Loss:1.823    Policy Loss: 9.285    Value Loss: 4.363    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 258990     Buffer Size: 16286      Transition Number: 1000.261k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:44:44,927][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 9.356    Value Loss: 4.489    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 261233     Buffer Size: 16276      Transition Number: 1000.079k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:47:39,323][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 9.096    Value Loss: 4.596    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 263477     Buffer Size: 16282      Transition Number: 1000.430k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:50:42,330][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 9.109    Value Loss: 4.039    Reward Loss: 1.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 265804     Buffer Size: 16263      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:53:41,552][train][INFO][train.py>_log] ==> #111000     Total Loss: 4.702    [weighted Loss:4.702    Policy Loss: 9.669    Value Loss: 4.536    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 268075     Buffer Size: 16249      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:56:41,151][train][INFO][train.py>_log] ==> #112000     Total Loss: 4.387    [weighted Loss:4.387    Policy Loss: 9.173    Value Loss: 4.331    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 270374     Buffer Size: 16242      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00010 
[2022-02-28 16:59:39,990][train][INFO][train.py>_log] ==> #113000     Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 9.248    Value Loss: 4.174    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 272623     Buffer Size: 16226      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:02:41,470][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.959    [weighted Loss:3.959    Policy Loss: 9.324    Value Loss: 4.103    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 274960     Buffer Size: 16221      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:05:39,070][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.834    [weighted Loss:3.834    Policy Loss: 9.848    Value Loss: 4.203    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 277156     Buffer Size: 16202      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:08:37,409][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.986    [weighted Loss:3.986    Policy Loss: 9.528    Value Loss: 4.312    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 279466     Buffer Size: 16175      Transition Number: 1000.341k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:11:38,447][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.570    [weighted Loss:3.570    Policy Loss: 9.739    Value Loss: 4.392    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 281808     Buffer Size: 16144      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:14:37,673][train][INFO][train.py>_log] ==> #118000     Total Loss: 4.182    [weighted Loss:4.182    Policy Loss: 9.720    Value Loss: 4.393    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 284072     Buffer Size: 16110      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:17:35,462][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.519    [weighted Loss:4.519    Policy Loss: 9.420    Value Loss: 4.181    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 286305     Buffer Size: 16083      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:20:35,879][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.373    [weighted Loss:3.373    Policy Loss: 9.450    Value Loss: 4.258    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 288594     Buffer Size: 16062      Transition Number: 1000.211k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:23:36,374][train][INFO][train.py>_log] ==> #121000     Total Loss: 5.107    [weighted Loss:5.107    Policy Loss: 9.492    Value Loss: 4.439    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 290874     Buffer Size: 16017      Transition Number: 1000.106k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:26:40,847][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.993    [weighted Loss:3.993    Policy Loss: 9.524    Value Loss: 4.411    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 293189     Buffer Size: 16005      Transition Number: 1000.160k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:29:41,862][train][INFO][train.py>_log] ==> #123000     Total Loss: 4.728    [weighted Loss:4.728    Policy Loss: 9.878    Value Loss: 4.076    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 295470     Buffer Size: 15986      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:32:45,803][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 9.602    Value Loss: 4.170    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 297828     Buffer Size: 15979      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:35:48,473][train][INFO][train.py>_log] ==> #125000     Total Loss: 4.719    [weighted Loss:4.719    Policy Loss: 10.160   Value Loss: 4.358    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 300173     Buffer Size: 15982      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:38:48,436][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.263    [weighted Loss:4.263    Policy Loss: 9.647    Value Loss: 4.196    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 302455     Buffer Size: 15985      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:41:54,908][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 9.306    Value Loss: 4.334    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 304891     Buffer Size: 15972      Transition Number: 1000.152k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:44:58,583][train][INFO][train.py>_log] ==> #128000     Total Loss: 4.356    [weighted Loss:4.356    Policy Loss: 9.636    Value Loss: 4.214    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 307217     Buffer Size: 15976      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:47:58,268][train][INFO][train.py>_log] ==> #129000     Total Loss: 5.232    [weighted Loss:5.232    Policy Loss: 10.115   Value Loss: 4.918    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 309552     Buffer Size: 15966      Transition Number: 1000.290k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:51:00,865][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.071    [weighted Loss:2.071    Policy Loss: 9.501    Value Loss: 4.174    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 311891     Buffer Size: 15943      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:54:03,449][train][INFO][train.py>_log] ==> #131000     Total Loss: 4.166    [weighted Loss:4.166    Policy Loss: 9.435    Value Loss: 4.075    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 314153     Buffer Size: 15904      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 17:57:01,210][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.837    [weighted Loss:2.837    Policy Loss: 9.450    Value Loss: 4.242    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 316385     Buffer Size: 15875      Transition Number: 1000.253k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:00:07,027][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 9.717    Value Loss: 4.323    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 318727     Buffer Size: 15829      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:03:09,498][train][INFO][train.py>_log] ==> #134000     Total Loss: 4.323    [weighted Loss:4.323    Policy Loss: 9.961    Value Loss: 4.244    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 320986     Buffer Size: 15796      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:06:12,652][train][INFO][train.py>_log] ==> #135000     Total Loss: 4.368    [weighted Loss:4.368    Policy Loss: 9.554    Value Loss: 4.335    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 323287     Buffer Size: 15730      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:09:11,785][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 9.449    Value Loss: 4.265    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 325556     Buffer Size: 15702      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:12:15,243][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.253    [weighted Loss:3.253    Policy Loss: 9.860    Value Loss: 4.182    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 327932     Buffer Size: 15645      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:15:17,362][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.845    [weighted Loss:3.845    Policy Loss: 9.949    Value Loss: 4.185    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 330227     Buffer Size: 15614      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:18:17,836][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 9.678    Value Loss: 4.156    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 332541     Buffer Size: 15573      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:21:15,408][train][INFO][train.py>_log] ==> #140000     Total Loss: 2.581    [weighted Loss:2.581    Policy Loss: 9.450    Value Loss: 4.177    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 334746     Buffer Size: 15536      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:24:18,285][train][INFO][train.py>_log] ==> #141000     Total Loss: 4.444    [weighted Loss:4.444    Policy Loss: 9.354    Value Loss: 4.211    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 337137     Buffer Size: 15487      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:27:22,861][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 9.043    Value Loss: 4.062    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 339485     Buffer Size: 15452      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:30:25,832][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 9.850    Value Loss: 3.978    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 341778     Buffer Size: 15404      Transition Number: 1000.491k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:33:26,612][train][INFO][train.py>_log] ==> #144000     Total Loss: 4.425    [weighted Loss:4.425    Policy Loss: 9.879    Value Loss: 4.136    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 344082     Buffer Size: 15370      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:36:28,734][train][INFO][train.py>_log] ==> #145000     Total Loss: 3.226    [weighted Loss:3.226    Policy Loss: 9.850    Value Loss: 4.014    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 346294     Buffer Size: 15335      Transition Number: 1000.477k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:39:33,556][train][INFO][train.py>_log] ==> #146000     Total Loss: 4.154    [weighted Loss:4.154    Policy Loss: 9.924    Value Loss: 4.175    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 348644     Buffer Size: 15281      Transition Number: 1000.335k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:42:37,107][train][INFO][train.py>_log] ==> #147000     Total Loss: 4.271    [weighted Loss:4.271    Policy Loss: 9.369    Value Loss: 4.301    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 350964     Buffer Size: 15238      Transition Number: 1000.290k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:45:39,120][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 9.357    Value Loss: 4.176    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 353239     Buffer Size: 15201      Transition Number: 1000.333k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:48:36,826][train][INFO][train.py>_log] ==> #149000     Total Loss: 4.287    [weighted Loss:4.287    Policy Loss: 9.385    Value Loss: 4.232    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 355584     Buffer Size: 15180      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:51:38,068][train][INFO][train.py>_log] ==> #150000     Total Loss: 4.434    [weighted Loss:4.434    Policy Loss: 9.178    Value Loss: 4.256    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 357900     Buffer Size: 15162      Transition Number: 1000.142k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:54:39,897][train][INFO][train.py>_log] ==> #151000     Total Loss: 3.534    [weighted Loss:3.534    Policy Loss: 9.331    Value Loss: 4.165    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 360211     Buffer Size: 15148      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00010 
[2022-02-28 18:57:37,072][train][INFO][train.py>_log] ==> #152000     Total Loss: 4.506    [weighted Loss:4.506    Policy Loss: 9.306    Value Loss: 4.366    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 362427     Buffer Size: 15148      Transition Number: 1000.125k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:00:43,764][train][INFO][train.py>_log] ==> #153000     Total Loss: 3.570    [weighted Loss:3.570    Policy Loss: 9.237    Value Loss: 4.488    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 364776     Buffer Size: 15130      Transition Number: 1000.068k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:03:48,531][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 9.375    Value Loss: 4.468    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 367101     Buffer Size: 15111      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:06:52,681][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 9.514    Value Loss: 4.222    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 369396     Buffer Size: 15087      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:10:00,414][train][INFO][train.py>_log] ==> #156000     Total Loss: 4.206    [weighted Loss:4.206    Policy Loss: 9.585    Value Loss: 4.247    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 371723     Buffer Size: 15052      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:13:03,027][train][INFO][train.py>_log] ==> #157000     Total Loss: 4.640    [weighted Loss:4.640    Policy Loss: 9.168    Value Loss: 4.333    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 374022     Buffer Size: 15022      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:16:05,245][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.998    [weighted Loss:3.998    Policy Loss: 9.257    Value Loss: 4.014    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 376321     Buffer Size: 14997      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:19:07,658][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 9.183    Value Loss: 4.078    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 378651     Buffer Size: 14992      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:22:12,611][train][INFO][train.py>_log] ==> #160000     Total Loss: 4.149    [weighted Loss:4.149    Policy Loss: 8.982    Value Loss: 4.625    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 381048     Buffer Size: 14975      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:25:11,633][train][INFO][train.py>_log] ==> #161000     Total Loss: 4.043    [weighted Loss:4.043    Policy Loss: 9.511    Value Loss: 4.004    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 383296     Buffer Size: 14970      Transition Number: 1000.348k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:28:13,473][train][INFO][train.py>_log] ==> #162000     Total Loss: 3.958    [weighted Loss:3.958    Policy Loss: 9.096    Value Loss: 4.088    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 385611     Buffer Size: 14951      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:31:14,120][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 8.901    Value Loss: 4.361    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 387825     Buffer Size: 14943      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:34:14,654][train][INFO][train.py>_log] ==> #164000     Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 8.912    Value Loss: 4.226    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 390095     Buffer Size: 14932      Transition Number: 1000.242k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:37:21,412][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.868    [weighted Loss:3.868    Policy Loss: 9.012    Value Loss: 4.355    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 392495     Buffer Size: 14908      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:40:25,601][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.312    [weighted Loss:3.312    Policy Loss: 8.670    Value Loss: 4.098    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 394729     Buffer Size: 14898      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:43:31,012][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.054    [weighted Loss:3.054    Policy Loss: 9.041    Value Loss: 4.196    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 397120     Buffer Size: 14897      Transition Number: 1000.499k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:46:34,097][train][INFO][train.py>_log] ==> #168000     Total Loss: 4.547    [weighted Loss:4.547    Policy Loss: 8.792    Value Loss: 4.294    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 399408     Buffer Size: 14898      Transition Number: 1000.901k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:49:37,356][train][INFO][train.py>_log] ==> #169000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 8.464    Value Loss: 4.339    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 401687     Buffer Size: 14880      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:52:40,813][train][INFO][train.py>_log] ==> #170000     Total Loss: 4.479    [weighted Loss:4.479    Policy Loss: 8.733    Value Loss: 4.505    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 404067     Buffer Size: 14899      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:55:41,740][train][INFO][train.py>_log] ==> #171000     Total Loss: 4.805    [weighted Loss:4.805    Policy Loss: 8.803    Value Loss: 4.271    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 406307     Buffer Size: 14894      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00010 
[2022-02-28 19:58:47,138][train][INFO][train.py>_log] ==> #172000     Total Loss: 3.637    [weighted Loss:3.637    Policy Loss: 8.689    Value Loss: 4.048    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 408630     Buffer Size: 14871      Transition Number: 1000.298k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:01:49,249][train][INFO][train.py>_log] ==> #173000     Total Loss: 4.284    [weighted Loss:4.284    Policy Loss: 8.814    Value Loss: 4.545    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 410916     Buffer Size: 14858      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:04:50,781][train][INFO][train.py>_log] ==> #174000     Total Loss: 1.699    [weighted Loss:1.699    Policy Loss: 8.584    Value Loss: 4.326    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 413207     Buffer Size: 14845      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:07:55,532][train][INFO][train.py>_log] ==> #175000     Total Loss: 3.523    [weighted Loss:3.523    Policy Loss: 8.512    Value Loss: 4.499    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 415504     Buffer Size: 14826      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:10:58,621][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 8.933    Value Loss: 4.312    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 417858     Buffer Size: 14813      Transition Number: 1000.669k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:14:01,049][train][INFO][train.py>_log] ==> #177000     Total Loss: 4.347    [weighted Loss:4.347    Policy Loss: 8.702    Value Loss: 4.148    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 420130     Buffer Size: 14792      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:17:02,016][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.779    [weighted Loss:3.779    Policy Loss: 8.242    Value Loss: 4.312    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 422409     Buffer Size: 14785      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:20:01,540][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.480    [weighted Loss:1.480    Policy Loss: 8.112    Value Loss: 4.141    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 424648     Buffer Size: 14786      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:23:03,394][train][INFO][train.py>_log] ==> #180000     Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 8.314    Value Loss: 4.320    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 426939     Buffer Size: 14776      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:26:05,078][train][INFO][train.py>_log] ==> #181000     Total Loss: 3.238    [weighted Loss:3.238    Policy Loss: 8.600    Value Loss: 4.034    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 429164     Buffer Size: 14761      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:29:05,018][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.599    [weighted Loss:3.599    Policy Loss: 8.594    Value Loss: 4.587    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 431470     Buffer Size: 14762      Transition Number: 1000.482k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:32:07,684][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.223    [weighted Loss:3.223    Policy Loss: 8.654    Value Loss: 4.139    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 433825     Buffer Size: 14740      Transition Number: 1000.361k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:35:11,764][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 8.864    Value Loss: 4.532    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 436184     Buffer Size: 14733      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:38:14,236][train][INFO][train.py>_log] ==> #185000     Total Loss: 3.459    [weighted Loss:3.459    Policy Loss: 8.858    Value Loss: 4.244    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 438472     Buffer Size: 14734      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:41:13,831][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.756    [weighted Loss:3.756    Policy Loss: 8.610    Value Loss: 4.457    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 440753     Buffer Size: 14739      Transition Number: 1000.206k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:44:15,156][train][INFO][train.py>_log] ==> #187000     Total Loss: 4.043    [weighted Loss:4.043    Policy Loss: 8.450    Value Loss: 4.267    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 443028     Buffer Size: 14743      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:47:15,332][train][INFO][train.py>_log] ==> #188000     Total Loss: 4.182    [weighted Loss:4.182    Policy Loss: 8.451    Value Loss: 4.120    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 445299     Buffer Size: 14743      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:50:14,086][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.957    [weighted Loss:3.957    Policy Loss: 8.829    Value Loss: 4.302    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 447552     Buffer Size: 14755      Transition Number: 1000.456k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:53:14,486][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.574    [weighted Loss:3.574    Policy Loss: 8.674    Value Loss: 4.415    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 449837     Buffer Size: 14750      Transition Number: 1000.281k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:56:19,784][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.548    [weighted Loss:3.548    Policy Loss: 8.862    Value Loss: 4.280    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 452131     Buffer Size: 14726      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 20:59:22,330][train][INFO][train.py>_log] ==> #192000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 8.758    Value Loss: 4.337    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 454397     Buffer Size: 14725      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:02:23,012][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 8.550    Value Loss: 4.227    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 456719     Buffer Size: 14735      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:05:26,585][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.864    [weighted Loss:2.864    Policy Loss: 8.219    Value Loss: 4.418    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 458990     Buffer Size: 14730      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:08:27,404][train][INFO][train.py>_log] ==> #195000     Total Loss: 3.020    [weighted Loss:3.020    Policy Loss: 8.521    Value Loss: 4.331    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 461295     Buffer Size: 14729      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:11:25,955][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.791    [weighted Loss:3.791    Policy Loss: 8.910    Value Loss: 4.334    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 463542     Buffer Size: 14737      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:14:26,377][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.825    [weighted Loss:2.825    Policy Loss: 8.898    Value Loss: 4.434    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 465812     Buffer Size: 14745      Transition Number: 1000.272k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:17:26,080][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 8.943    Value Loss: 4.178    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 468086     Buffer Size: 14755      Transition Number: 1000.670k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:20:29,869][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.813    [weighted Loss:3.813    Policy Loss: 8.828    Value Loss: 4.275    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 470411     Buffer Size: 14756      Transition Number: 1000.447k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:23:31,147][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 8.786    Value Loss: 4.396    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 472700     Buffer Size: 14752      Transition Number: 1000.249k Batch Size: 256        Lr: 0.00010 
[2022-02-28 21:26:34,043][train][INFO][train.py>_log] ==> #201000     Total Loss: 3.796    [weighted Loss:3.796    Policy Loss: 8.475    Value Loss: 4.046    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 475028     Buffer Size: 14767      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:29:33,282][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.641    [weighted Loss:3.641    Policy Loss: 8.585    Value Loss: 4.627    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 477220     Buffer Size: 14766      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:32:35,620][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 8.991    Value Loss: 4.613    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 479529     Buffer Size: 14773      Transition Number: 1000.089k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:35:39,256][train][INFO][train.py>_log] ==> #204000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 8.573    Value Loss: 4.191    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 481892     Buffer Size: 14782      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:38:38,738][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.921    [weighted Loss:2.921    Policy Loss: 8.275    Value Loss: 4.428    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 484113     Buffer Size: 14787      Transition Number: 1000.445k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:41:37,715][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 8.909    Value Loss: 4.027    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 486353     Buffer Size: 14782      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:44:40,089][train][INFO][train.py>_log] ==> #207000     Total Loss: 3.895    [weighted Loss:3.895    Policy Loss: 9.060    Value Loss: 3.995    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 488636     Buffer Size: 14802      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:47:41,876][train][INFO][train.py>_log] ==> #208000     Total Loss: 3.427    [weighted Loss:3.427    Policy Loss: 8.509    Value Loss: 4.252    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 490938     Buffer Size: 14806      Transition Number: 1000.074k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:50:41,136][train][INFO][train.py>_log] ==> #209000     Total Loss: 4.828    [weighted Loss:4.828    Policy Loss: 8.912    Value Loss: 4.373    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 493223     Buffer Size: 14822      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:53:44,497][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.766    [weighted Loss:3.766    Policy Loss: 8.602    Value Loss: 4.313    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 495590     Buffer Size: 14828      Transition Number: 1000.323k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:56:47,200][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 8.622    Value Loss: 4.099    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 497853     Buffer Size: 14834      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00001 
[2022-02-28 21:59:50,250][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.764    [weighted Loss:3.764    Policy Loss: 8.750    Value Loss: 4.238    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 500210     Buffer Size: 14858      Transition Number: 1000.142k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:02:51,936][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 9.049    Value Loss: 4.268    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 502473     Buffer Size: 14876      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:05:52,044][train][INFO][train.py>_log] ==> #214000     Total Loss: 3.662    [weighted Loss:3.662    Policy Loss: 8.669    Value Loss: 4.097    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 504737     Buffer Size: 14888      Transition Number: 1000.198k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:08:56,904][train][INFO][train.py>_log] ==> #215000     Total Loss: 4.335    [weighted Loss:4.335    Policy Loss: 9.390    Value Loss: 4.479    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 507079     Buffer Size: 14911      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:12:01,085][train][INFO][train.py>_log] ==> #216000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 8.591    Value Loss: 3.915    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 509357     Buffer Size: 14935      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:15:05,683][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.608    [weighted Loss:3.608    Policy Loss: 8.407    Value Loss: 4.092    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 511712     Buffer Size: 14954      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:18:06,106][train][INFO][train.py>_log] ==> #218000     Total Loss: 4.275    [weighted Loss:4.275    Policy Loss: 8.572    Value Loss: 4.137    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 513941     Buffer Size: 14958      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:21:10,158][train][INFO][train.py>_log] ==> #219000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 8.480    Value Loss: 4.238    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 516370     Buffer Size: 14980      Transition Number: 1000.557k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:24:13,948][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.683    [weighted Loss:3.683    Policy Loss: 8.483    Value Loss: 4.023    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 518636     Buffer Size: 14976      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:27:16,245][train][INFO][train.py>_log] ==> #221000     Total Loss: 3.680    [weighted Loss:3.680    Policy Loss: 8.820    Value Loss: 3.984    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 520941     Buffer Size: 14980      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:30:19,435][train][INFO][train.py>_log] ==> #222000     Total Loss: 3.575    [weighted Loss:3.575    Policy Loss: 9.060    Value Loss: 3.868    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 523262     Buffer Size: 14990      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:33:22,564][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.661    [weighted Loss:3.661    Policy Loss: 8.939    Value Loss: 4.330    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 525605     Buffer Size: 14995      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:36:23,669][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.738    [weighted Loss:2.738    Policy Loss: 8.873    Value Loss: 4.019    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 527836     Buffer Size: 15010      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:39:25,150][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.768    [weighted Loss:2.768    Policy Loss: 8.618    Value Loss: 4.157    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 530108     Buffer Size: 15026      Transition Number: 1000.262k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:42:25,379][train][INFO][train.py>_log] ==> #226000     Total Loss: 4.482    [weighted Loss:4.482    Policy Loss: 9.001    Value Loss: 4.567    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 532385     Buffer Size: 15050      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:45:28,709][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 8.765    Value Loss: 4.063    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 534673     Buffer Size: 15064      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:48:33,022][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.726    [weighted Loss:2.726    Policy Loss: 8.340    Value Loss: 4.113    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 537049     Buffer Size: 15079      Transition Number: 1000.281k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:51:33,225][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.253    [weighted Loss:3.253    Policy Loss: 8.987    Value Loss: 4.259    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 539338     Buffer Size: 15087      Transition Number: 1000.411k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:54:35,929][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.508    [weighted Loss:2.508    Policy Loss: 8.579    Value Loss: 4.373    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 541623     Buffer Size: 15094      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00001 
[2022-02-28 22:57:40,275][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.463    [weighted Loss:3.463    Policy Loss: 9.109    Value Loss: 4.420    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 543940     Buffer Size: 15123      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:00:44,196][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 9.136    Value Loss: 4.239    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 546172     Buffer Size: 15124      Transition Number: 1000.362k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:03:47,540][train][INFO][train.py>_log] ==> #233000     Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 8.793    Value Loss: 4.245    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 548551     Buffer Size: 15114      Transition Number: 1000.387k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:06:46,314][train][INFO][train.py>_log] ==> #234000     Total Loss: 3.768    [weighted Loss:3.768    Policy Loss: 8.803    Value Loss: 4.151    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 550834     Buffer Size: 15119      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:09:48,895][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 8.711    Value Loss: 4.382    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 553179     Buffer Size: 15127      Transition Number: 1000.131k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:12:54,824][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.948    [weighted Loss:3.948    Policy Loss: 9.073    Value Loss: 4.228    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 555562     Buffer Size: 15136      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:15:53,257][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 8.549    Value Loss: 4.229    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 557764     Buffer Size: 15136      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:18:59,857][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.796    [weighted Loss:3.796    Policy Loss: 8.906    Value Loss: 4.594    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 560062     Buffer Size: 15139      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:22:03,210][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 8.914    Value Loss: 4.143    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 562435     Buffer Size: 15154      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:25:04,013][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 8.313    Value Loss: 4.103    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 564723     Buffer Size: 15161      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:28:07,941][train][INFO][train.py>_log] ==> #241000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 8.631    Value Loss: 4.330    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 567093     Buffer Size: 15151      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:31:11,761][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 8.539    Value Loss: 4.187    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 569408     Buffer Size: 15157      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:34:11,863][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 8.852    Value Loss: 4.395    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 571671     Buffer Size: 15146      Transition Number: 999.930 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:37:18,103][train][INFO][train.py>_log] ==> #244000     Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 9.118    Value Loss: 4.287    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 574081     Buffer Size: 15147      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:40:19,508][train][INFO][train.py>_log] ==> #245000     Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 8.926    Value Loss: 4.286    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 576332     Buffer Size: 15154      Transition Number: 1000.577k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:43:21,799][train][INFO][train.py>_log] ==> #246000     Total Loss: 4.133    [weighted Loss:4.133    Policy Loss: 8.605    Value Loss: 4.374    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 578709     Buffer Size: 15147      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:46:22,502][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 8.545    Value Loss: 4.256    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 580995     Buffer Size: 15152      Transition Number: 1000.355k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:49:24,318][train][INFO][train.py>_log] ==> #248000     Total Loss: 3.432    [weighted Loss:3.432    Policy Loss: 8.970    Value Loss: 4.483    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 583289     Buffer Size: 15141      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:52:21,905][train][INFO][train.py>_log] ==> #249000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 8.452    Value Loss: 4.111    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 585539     Buffer Size: 15134      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:55:24,503][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 8.769    Value Loss: 4.154    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 587721     Buffer Size: 15153      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00001 
[2022-02-28 23:58:23,504][train][INFO][train.py>_log] ==> #251000     Total Loss: 4.125    [weighted Loss:4.125    Policy Loss: 8.954    Value Loss: 4.345    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 590016     Buffer Size: 15146      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:01:27,809][train][INFO][train.py>_log] ==> #252000     Total Loss: 4.177    [weighted Loss:4.177    Policy Loss: 8.333    Value Loss: 4.078    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 592318     Buffer Size: 15157      Transition Number: 1000.016k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:04:32,033][train][INFO][train.py>_log] ==> #253000     Total Loss: 3.980    [weighted Loss:3.980    Policy Loss: 8.699    Value Loss: 4.382    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 594712     Buffer Size: 15172      Transition Number: 1000.229k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:07:33,047][train][INFO][train.py>_log] ==> #254000     Total Loss: 3.936    [weighted Loss:3.936    Policy Loss: 8.626    Value Loss: 4.170    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 597040     Buffer Size: 15167      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:10:36,255][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 8.510    Value Loss: 4.026    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 599378     Buffer Size: 15174      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:13:41,192][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.364    [weighted Loss:3.364    Policy Loss: 9.007    Value Loss: 4.186    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 601729     Buffer Size: 15167      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:16:43,332][train][INFO][train.py>_log] ==> #257000     Total Loss: 4.402    [weighted Loss:4.402    Policy Loss: 8.988    Value Loss: 4.249    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 603932     Buffer Size: 15170      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:19:48,149][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.800    [weighted Loss:2.800    Policy Loss: 8.847    Value Loss: 4.502    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 606324     Buffer Size: 15171      Transition Number: 1001.083k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:22:49,151][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 9.002    Value Loss: 4.628    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 608646     Buffer Size: 15155      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:25:53,030][train][INFO][train.py>_log] ==> #260000     Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 9.000    Value Loss: 4.258    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 610913     Buffer Size: 15148      Transition Number: 1000.338k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:28:55,715][train][INFO][train.py>_log] ==> #261000     Total Loss: 4.060    [weighted Loss:4.060    Policy Loss: 8.654    Value Loss: 4.383    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 613213     Buffer Size: 15151      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:31:58,473][train][INFO][train.py>_log] ==> #262000     Total Loss: 3.997    [weighted Loss:3.997    Policy Loss: 8.970    Value Loss: 4.243    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 615518     Buffer Size: 15154      Transition Number: 1000.232k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:34:59,133][train][INFO][train.py>_log] ==> #263000     Total Loss: 3.453    [weighted Loss:3.453    Policy Loss: 8.718    Value Loss: 4.301    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 617793     Buffer Size: 15160      Transition Number: 1000.194k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:38:01,770][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 8.709    Value Loss: 4.002    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 620199     Buffer Size: 15160      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:41:10,201][train][INFO][train.py>_log] ==> #265000     Total Loss: 4.106    [weighted Loss:4.106    Policy Loss: 8.842    Value Loss: 4.330    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 622621     Buffer Size: 15171      Transition Number: 1000.209k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:44:18,050][train][INFO][train.py>_log] ==> #266000     Total Loss: 3.905    [weighted Loss:3.905    Policy Loss: 8.676    Value Loss: 4.112    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 624879     Buffer Size: 15178      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:47:19,189][train][INFO][train.py>_log] ==> #267000     Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 9.050    Value Loss: 4.299    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 627196     Buffer Size: 15194      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:50:21,901][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 9.012    Value Loss: 4.434    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 629441     Buffer Size: 15211      Transition Number: 1000.089k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:53:26,039][train][INFO][train.py>_log] ==> #269000     Total Loss: 4.589    [weighted Loss:4.589    Policy Loss: 9.065    Value Loss: 4.261    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 631843     Buffer Size: 15220      Transition Number: 1000.210k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:56:29,153][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 8.830    Value Loss: 4.409    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 634264     Buffer Size: 15230      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00001 
[2022-03-01 00:59:30,954][train][INFO][train.py>_log] ==> #271000     Total Loss: 4.156    [weighted Loss:4.156    Policy Loss: 8.972    Value Loss: 4.348    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 636528     Buffer Size: 15241      Transition Number: 1000.301k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:02:37,565][train][INFO][train.py>_log] ==> #272000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 8.749    Value Loss: 4.578    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 638881     Buffer Size: 15239      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:05:41,929][train][INFO][train.py>_log] ==> #273000     Total Loss: 4.433    [weighted Loss:4.433    Policy Loss: 8.991    Value Loss: 4.422    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 641214     Buffer Size: 15246      Transition Number: 1000.459k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:08:45,680][train][INFO][train.py>_log] ==> #274000     Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 8.769    Value Loss: 4.260    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 643475     Buffer Size: 15236      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:11:48,348][train][INFO][train.py>_log] ==> #275000     Total Loss: 3.962    [weighted Loss:3.962    Policy Loss: 8.802    Value Loss: 4.046    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 645837     Buffer Size: 15229      Transition Number: 1000.405k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:14:53,856][train][INFO][train.py>_log] ==> #276000     Total Loss: 3.458    [weighted Loss:3.458    Policy Loss: 8.831    Value Loss: 4.432    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 648142     Buffer Size: 15218      Transition Number: 1000.077k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:17:58,329][train][INFO][train.py>_log] ==> #277000     Total Loss: 3.067    [weighted Loss:3.067    Policy Loss: 8.693    Value Loss: 4.388    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 650446     Buffer Size: 15221      Transition Number: 1000.328k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:21:06,628][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 8.771    Value Loss: 4.371    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 652806     Buffer Size: 15225      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:24:09,467][train][INFO][train.py>_log] ==> #279000     Total Loss: 2.703    [weighted Loss:2.703    Policy Loss: 8.836    Value Loss: 4.285    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 655116     Buffer Size: 15239      Transition Number: 1000.146k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:27:13,677][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.738    [weighted Loss:3.738    Policy Loss: 9.270    Value Loss: 4.142    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 657535     Buffer Size: 15241      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:30:14,808][train][INFO][train.py>_log] ==> #281000     Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 9.200    Value Loss: 4.251    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 659835     Buffer Size: 15231      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:33:16,253][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 8.793    Value Loss: 4.675    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 662070     Buffer Size: 15220      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:36:20,365][train][INFO][train.py>_log] ==> #283000     Total Loss: 3.862    [weighted Loss:3.862    Policy Loss: 8.765    Value Loss: 4.515    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 664455     Buffer Size: 15226      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:39:21,208][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 8.845    Value Loss: 4.153    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 666698     Buffer Size: 15221      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:42:25,743][train][INFO][train.py>_log] ==> #285000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 9.333    Value Loss: 4.333    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 669028     Buffer Size: 15202      Transition Number: 1000.147k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:45:30,103][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.404    [weighted Loss:3.404    Policy Loss: 9.080    Value Loss: 4.316    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 671396     Buffer Size: 15199      Transition Number: 1000.260k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:48:36,959][train][INFO][train.py>_log] ==> #287000     Total Loss: 3.563    [weighted Loss:3.563    Policy Loss: 8.863    Value Loss: 4.761    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 673814     Buffer Size: 15214      Transition Number: 1000.335k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:51:42,060][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 8.711    Value Loss: 4.446    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 676140     Buffer Size: 15226      Transition Number: 1000.289k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:54:42,592][train][INFO][train.py>_log] ==> #289000     Total Loss: 3.088    [weighted Loss:3.088    Policy Loss: 8.701    Value Loss: 4.339    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 678389     Buffer Size: 15236      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 01:57:46,593][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.560    [weighted Loss:3.560    Policy Loss: 8.749    Value Loss: 4.500    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 680673     Buffer Size: 15232      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:00:51,140][train][INFO][train.py>_log] ==> #291000     Total Loss: 3.438    [weighted Loss:3.438    Policy Loss: 9.214    Value Loss: 4.335    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 683103     Buffer Size: 15228      Transition Number: 1000.271k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:03:54,439][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 8.787    Value Loss: 4.619    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 685434     Buffer Size: 15226      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:06:59,448][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 9.155    Value Loss: 4.125    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 687701     Buffer Size: 15235      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:10:06,040][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 8.979    Value Loss: 4.575    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 690085     Buffer Size: 15235      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:13:12,275][train][INFO][train.py>_log] ==> #295000     Total Loss: 3.820    [weighted Loss:3.820    Policy Loss: 8.482    Value Loss: 4.331    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 692510     Buffer Size: 15230      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:16:14,553][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 8.686    Value Loss: 4.478    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 694778     Buffer Size: 15237      Transition Number: 1000.522k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:19:19,492][train][INFO][train.py>_log] ==> #297000     Total Loss: 2.854    [weighted Loss:2.854    Policy Loss: 8.547    Value Loss: 4.139    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 697142     Buffer Size: 15234      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:22:26,354][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 8.572    Value Loss: 4.068    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 699434     Buffer Size: 15237      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:25:31,883][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 9.288    Value Loss: 4.195    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 701799     Buffer Size: 15238      Transition Number: 1000.411k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:28:37,632][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 8.484    Value Loss: 4.285    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 704097     Buffer Size: 15236      Transition Number: 1000.603k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:31:45,222][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.480    [weighted Loss:3.480    Policy Loss: 9.277    Value Loss: 4.359    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 706587     Buffer Size: 15228      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:34:50,837][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 8.688    Value Loss: 3.975    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 709012     Buffer Size: 15238      Transition Number: 1000.453k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:37:52,078][train][INFO][train.py>_log] ==> #303000     Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 8.626    Value Loss: 4.202    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 711316     Buffer Size: 15249      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:41:00,485][train][INFO][train.py>_log] ==> #304000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 9.162    Value Loss: 4.169    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 713647     Buffer Size: 15225      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:44:08,601][train][INFO][train.py>_log] ==> #305000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 9.137    Value Loss: 4.199    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 716029     Buffer Size: 15234      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:47:15,403][train][INFO][train.py>_log] ==> #306000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 8.796    Value Loss: 4.216    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 718398     Buffer Size: 15241      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:50:18,319][train][INFO][train.py>_log] ==> #307000     Total Loss: 4.228    [weighted Loss:4.228    Policy Loss: 8.860    Value Loss: 4.290    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 720672     Buffer Size: 15249      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:53:23,451][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.514    [weighted Loss:2.514    Policy Loss: 8.980    Value Loss: 4.376    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 723054     Buffer Size: 15250      Transition Number: 1000.201k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:56:24,403][train][INFO][train.py>_log] ==> #309000     Total Loss: 3.327    [weighted Loss:3.327    Policy Loss: 9.234    Value Loss: 4.347    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 725373     Buffer Size: 15259      Transition Number: 1000.592k Batch Size: 256        Lr: 0.00001 
[2022-03-01 02:59:29,523][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.823    [weighted Loss:3.823    Policy Loss: 8.767    Value Loss: 4.043    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 727643     Buffer Size: 15246      Transition Number: 1000.336k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:02:33,698][train][INFO][train.py>_log] ==> #311000     Total Loss: 3.579    [weighted Loss:3.579    Policy Loss: 8.782    Value Loss: 4.279    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 730084     Buffer Size: 15232      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:05:34,690][train][INFO][train.py>_log] ==> #312000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 8.876    Value Loss: 4.333    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 732282     Buffer Size: 15238      Transition Number: 1000.432k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:08:37,735][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.112    [weighted Loss:3.112    Policy Loss: 9.015    Value Loss: 4.272    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 734620     Buffer Size: 15227      Transition Number: 1000.150k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:11:39,971][train][INFO][train.py>_log] ==> #314000     Total Loss: 3.421    [weighted Loss:3.421    Policy Loss: 8.794    Value Loss: 3.959    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 736926     Buffer Size: 15233      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:14:41,448][train][INFO][train.py>_log] ==> #315000     Total Loss: 3.651    [weighted Loss:3.651    Policy Loss: 8.870    Value Loss: 4.509    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 739225     Buffer Size: 15228      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:17:47,197][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.078    [weighted Loss:3.078    Policy Loss: 8.850    Value Loss: 4.192    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 741579     Buffer Size: 15223      Transition Number: 1000.401k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:20:52,742][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.742    [weighted Loss:2.742    Policy Loss: 9.106    Value Loss: 4.073    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 743939     Buffer Size: 15234      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:23:58,739][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 8.527    Value Loss: 4.365    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 746270     Buffer Size: 15231      Transition Number: 1000.202k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:27:03,937][train][INFO][train.py>_log] ==> #319000     Total Loss: 3.971    [weighted Loss:3.971    Policy Loss: 8.823    Value Loss: 4.231    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 748659     Buffer Size: 15242      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:30:11,028][train][INFO][train.py>_log] ==> #320000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 8.711    Value Loss: 4.064    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 751011     Buffer Size: 15243      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:33:16,868][train][INFO][train.py>_log] ==> #321000     Total Loss: 3.406    [weighted Loss:3.406    Policy Loss: 9.068    Value Loss: 4.157    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 753409     Buffer Size: 15239      Transition Number: 1000.229k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:36:27,171][train][INFO][train.py>_log] ==> #322000     Total Loss: 3.857    [weighted Loss:3.857    Policy Loss: 8.842    Value Loss: 4.332    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 755859     Buffer Size: 15251      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:39:38,995][train][INFO][train.py>_log] ==> #323000     Total Loss: 3.548    [weighted Loss:3.548    Policy Loss: 8.894    Value Loss: 4.291    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 758316     Buffer Size: 15253      Transition Number: 1000.243k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:42:50,444][train][INFO][train.py>_log] ==> #324000     Total Loss: 3.961    [weighted Loss:3.961    Policy Loss: 8.762    Value Loss: 4.079    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 760752     Buffer Size: 15245      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:46:00,349][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 9.024    Value Loss: 4.263    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 763137     Buffer Size: 15235      Transition Number: 1000.118k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:49:06,548][train][INFO][train.py>_log] ==> #326000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 8.907    Value Loss: 4.125    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 765475     Buffer Size: 15227      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:52:18,037][train][INFO][train.py>_log] ==> #327000     Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 8.868    Value Loss: 4.281    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 767940     Buffer Size: 15221      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:55:26,235][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 9.191    Value Loss: 4.180    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 770303     Buffer Size: 15223      Transition Number: 1000.266k Batch Size: 256        Lr: 0.00001 
[2022-03-01 03:58:32,022][train][INFO][train.py>_log] ==> #329000     Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 8.576    Value Loss: 4.536    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 772726     Buffer Size: 15228      Transition Number: 1000.454k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:01:37,662][train][INFO][train.py>_log] ==> #330000     Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 8.847    Value Loss: 4.109    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 775085     Buffer Size: 15232      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:04:39,838][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.885    [weighted Loss:2.885    Policy Loss: 9.019    Value Loss: 4.188    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 777354     Buffer Size: 15231      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:07:46,097][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 9.227    Value Loss: 4.042    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 779654     Buffer Size: 15233      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:10:50,359][train][INFO][train.py>_log] ==> #333000     Total Loss: 2.861    [weighted Loss:2.861    Policy Loss: 9.345    Value Loss: 4.359    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 782060     Buffer Size: 15225      Transition Number: 1000.178k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:13:52,773][train][INFO][train.py>_log] ==> #334000     Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 8.831    Value Loss: 4.183    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 784422     Buffer Size: 15206      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:16:58,558][train][INFO][train.py>_log] ==> #335000     Total Loss: 4.338    [weighted Loss:4.338    Policy Loss: 8.880    Value Loss: 4.339    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 786711     Buffer Size: 15206      Transition Number: 1000.152k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:20:04,509][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.585    [weighted Loss:3.585    Policy Loss: 9.018    Value Loss: 4.622    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 789063     Buffer Size: 15203      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:23:09,799][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 8.964    Value Loss: 4.243    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 791417     Buffer Size: 15200      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:26:13,851][train][INFO][train.py>_log] ==> #338000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 9.190    Value Loss: 4.457    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 793741     Buffer Size: 15208      Transition Number: 1000.366k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:29:24,705][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 8.729    Value Loss: 4.288    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 796146     Buffer Size: 15207      Transition Number: 1000.231k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:32:27,858][train][INFO][train.py>_log] ==> #340000     Total Loss: 1.914    [weighted Loss:1.914    Policy Loss: 8.942    Value Loss: 4.533    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 798493     Buffer Size: 15200      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:35:32,540][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.501    [weighted Loss:2.501    Policy Loss: 9.261    Value Loss: 4.346    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 800758     Buffer Size: 15208      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:38:43,988][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 8.623    Value Loss: 4.098    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 803240     Buffer Size: 15211      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:41:47,777][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.938    [weighted Loss:2.938    Policy Loss: 8.880    Value Loss: 4.411    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 805627     Buffer Size: 15216      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:44:57,587][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 9.040    Value Loss: 4.324    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 808029     Buffer Size: 15220      Transition Number: 1000.267k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:48:05,917][train][INFO][train.py>_log] ==> #345000     Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 9.309    Value Loss: 4.427    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 810364     Buffer Size: 15215      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:51:11,499][train][INFO][train.py>_log] ==> #346000     Total Loss: 3.544    [weighted Loss:3.544    Policy Loss: 9.050    Value Loss: 4.356    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 812681     Buffer Size: 15219      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:54:19,340][train][INFO][train.py>_log] ==> #347000     Total Loss: 3.861    [weighted Loss:3.861    Policy Loss: 8.845    Value Loss: 4.518    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 815145     Buffer Size: 15224      Transition Number: 1000.164k Batch Size: 256        Lr: 0.00001 
[2022-03-01 04:57:29,323][train][INFO][train.py>_log] ==> #348000     Total Loss: 4.176    [weighted Loss:4.176    Policy Loss: 8.847    Value Loss: 4.207    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 817567     Buffer Size: 15231      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:00:34,743][train][INFO][train.py>_log] ==> #349000     Total Loss: 4.003    [weighted Loss:4.003    Policy Loss: 9.393    Value Loss: 4.311    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 819954     Buffer Size: 15229      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:03:38,772][train][INFO][train.py>_log] ==> #350000     Total Loss: 3.098    [weighted Loss:3.098    Policy Loss: 9.626    Value Loss: 4.142    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 822246     Buffer Size: 15232      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:06:43,714][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.284    [weighted Loss:3.284    Policy Loss: 8.882    Value Loss: 3.874    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 824635     Buffer Size: 15227      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:09:52,026][train][INFO][train.py>_log] ==> #352000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 8.861    Value Loss: 4.221    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 827008     Buffer Size: 15217      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:13:01,318][train][INFO][train.py>_log] ==> #353000     Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 9.354    Value Loss: 4.550    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 829379     Buffer Size: 15212      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:16:09,876][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 8.975    Value Loss: 4.599    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 831735     Buffer Size: 15211      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:19:14,124][train][INFO][train.py>_log] ==> #355000     Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 8.903    Value Loss: 4.626    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 834055     Buffer Size: 15206      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:22:22,226][train][INFO][train.py>_log] ==> #356000     Total Loss: 3.430    [weighted Loss:3.430    Policy Loss: 8.979    Value Loss: 4.133    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 836465     Buffer Size: 15186      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:25:26,720][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 9.111    Value Loss: 4.447    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 838833     Buffer Size: 15187      Transition Number: 1000.197k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:28:38,723][train][INFO][train.py>_log] ==> #358000     Total Loss: 4.485    [weighted Loss:4.485    Policy Loss: 9.381    Value Loss: 4.277    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 841262     Buffer Size: 15192      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:31:44,926][train][INFO][train.py>_log] ==> #359000     Total Loss: 3.494    [weighted Loss:3.494    Policy Loss: 8.961    Value Loss: 4.480    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 843606     Buffer Size: 15191      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:34:52,705][train][INFO][train.py>_log] ==> #360000     Total Loss: 3.309    [weighted Loss:3.309    Policy Loss: 8.875    Value Loss: 4.154    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 845975     Buffer Size: 15180      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:38:01,155][train][INFO][train.py>_log] ==> #361000     Total Loss: 4.027    [weighted Loss:4.027    Policy Loss: 8.884    Value Loss: 4.214    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 848411     Buffer Size: 15183      Transition Number: 1000.074k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:41:13,412][train][INFO][train.py>_log] ==> #362000     Total Loss: 3.211    [weighted Loss:3.211    Policy Loss: 9.206    Value Loss: 4.201    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 850837     Buffer Size: 15172      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:44:23,526][train][INFO][train.py>_log] ==> #363000     Total Loss: 4.424    [weighted Loss:4.424    Policy Loss: 9.497    Value Loss: 4.014    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 853219     Buffer Size: 15164      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:47:33,635][train][INFO][train.py>_log] ==> #364000     Total Loss: 3.566    [weighted Loss:3.566    Policy Loss: 9.338    Value Loss: 4.096    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 855607     Buffer Size: 15168      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:50:41,404][train][INFO][train.py>_log] ==> #365000     Total Loss: 3.238    [weighted Loss:3.238    Policy Loss: 9.223    Value Loss: 4.353    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 857975     Buffer Size: 15177      Transition Number: 1000.149k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:53:50,598][train][INFO][train.py>_log] ==> #366000     Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 9.024    Value Loss: 4.003    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 860410     Buffer Size: 15180      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 05:56:53,944][train][INFO][train.py>_log] ==> #367000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 8.656    Value Loss: 4.444    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 862720     Buffer Size: 15198      Transition Number: 1000.301k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:00:01,736][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.534    [weighted Loss:3.534    Policy Loss: 9.438    Value Loss: 4.229    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 865053     Buffer Size: 15201      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:03:10,354][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 8.770    Value Loss: 4.549    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 867470     Buffer Size: 15229      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:06:11,823][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 8.844    Value Loss: 4.151    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 869762     Buffer Size: 15242      Transition Number: 1000.393k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:09:16,013][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.651    [weighted Loss:2.651    Policy Loss: 9.362    Value Loss: 4.015    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 872110     Buffer Size: 15238      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:12:23,334][train][INFO][train.py>_log] ==> #372000     Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 9.328    Value Loss: 4.249    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 874500     Buffer Size: 15247      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:15:32,632][train][INFO][train.py>_log] ==> #373000     Total Loss: 3.689    [weighted Loss:3.689    Policy Loss: 9.249    Value Loss: 4.388    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 876961     Buffer Size: 15241      Transition Number: 1000.122k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:18:35,910][train][INFO][train.py>_log] ==> #374000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 9.002    Value Loss: 4.346    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 879329     Buffer Size: 15247      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:21:40,609][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.648    [weighted Loss:2.648    Policy Loss: 9.297    Value Loss: 4.132    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 881612     Buffer Size: 15246      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:24:46,808][train][INFO][train.py>_log] ==> #376000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 9.139    Value Loss: 4.116    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 883950     Buffer Size: 15240      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:27:52,713][train][INFO][train.py>_log] ==> #377000     Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 9.010    Value Loss: 3.906    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 886270     Buffer Size: 15224      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:30:59,296][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 9.001    Value Loss: 4.130    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 888607     Buffer Size: 15239      Transition Number: 1000.497k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:34:08,791][train][INFO][train.py>_log] ==> #379000     Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 8.806    Value Loss: 4.173    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 891069     Buffer Size: 15221      Transition Number: 1000.278k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:37:13,688][train][INFO][train.py>_log] ==> #380000     Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 9.060    Value Loss: 4.247    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 893419     Buffer Size: 15223      Transition Number: 1000.211k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:40:18,862][train][INFO][train.py>_log] ==> #381000     Total Loss: 3.655    [weighted Loss:3.655    Policy Loss: 9.387    Value Loss: 4.168    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 895820     Buffer Size: 15212      Transition Number: 1000.096k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:43:22,177][train][INFO][train.py>_log] ==> #382000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 9.316    Value Loss: 4.400    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 898088     Buffer Size: 15209      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:46:27,765][train][INFO][train.py>_log] ==> #383000     Total Loss: 3.660    [weighted Loss:3.660    Policy Loss: 8.936    Value Loss: 4.446    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 900420     Buffer Size: 15208      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:49:30,140][train][INFO][train.py>_log] ==> #384000     Total Loss: 4.390    [weighted Loss:4.390    Policy Loss: 8.854    Value Loss: 4.062    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 902739     Buffer Size: 15208      Transition Number: 1000.415k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:52:36,202][train][INFO][train.py>_log] ==> #385000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 8.915    Value Loss: 4.152    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 905105     Buffer Size: 15195      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:55:39,011][train][INFO][train.py>_log] ==> #386000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 9.404    Value Loss: 4.448    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 907433     Buffer Size: 15196      Transition Number: 1000.182k Batch Size: 256        Lr: 0.00001 
[2022-03-01 06:58:43,857][train][INFO][train.py>_log] ==> #387000     Total Loss: 3.797    [weighted Loss:3.797    Policy Loss: 9.076    Value Loss: 4.167    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 909801     Buffer Size: 15197      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:01:49,591][train][INFO][train.py>_log] ==> #388000     Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 8.954    Value Loss: 4.051    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 912090     Buffer Size: 15212      Transition Number: 1000.519k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:05:00,005][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.736    [weighted Loss:2.736    Policy Loss: 8.727    Value Loss: 4.444    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 914506     Buffer Size: 15201      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:08:10,502][train][INFO][train.py>_log] ==> #390000     Total Loss: 3.740    [weighted Loss:3.740    Policy Loss: 9.269    Value Loss: 4.015    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 916973     Buffer Size: 15211      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:11:17,230][train][INFO][train.py>_log] ==> #391000     Total Loss: 3.866    [weighted Loss:3.866    Policy Loss: 9.425    Value Loss: 4.054    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 919377     Buffer Size: 15211      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:14:24,541][train][INFO][train.py>_log] ==> #392000     Total Loss: 3.099    [weighted Loss:3.099    Policy Loss: 9.283    Value Loss: 4.039    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 921687     Buffer Size: 15217      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:17:29,864][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.882    [weighted Loss:2.882    Policy Loss: 9.313    Value Loss: 4.225    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 924046     Buffer Size: 15219      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:20:40,857][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.192    [weighted Loss:3.192    Policy Loss: 9.554    Value Loss: 4.281    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 926511     Buffer Size: 15223      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:23:46,485][train][INFO][train.py>_log] ==> #395000     Total Loss: 3.519    [weighted Loss:3.519    Policy Loss: 9.147    Value Loss: 4.334    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 928877     Buffer Size: 15241      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:26:52,163][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.437    [weighted Loss:2.437    Policy Loss: 8.971    Value Loss: 4.161    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 931184     Buffer Size: 15245      Transition Number: 1000.310k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:30:01,582][train][INFO][train.py>_log] ==> #397000     Total Loss: 2.935    [weighted Loss:2.935    Policy Loss: 9.099    Value Loss: 3.979    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 933650     Buffer Size: 15246      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:33:07,677][train][INFO][train.py>_log] ==> #398000     Total Loss: 3.734    [weighted Loss:3.734    Policy Loss: 9.252    Value Loss: 3.957    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 936046     Buffer Size: 15255      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:36:16,803][train][INFO][train.py>_log] ==> #399000     Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 9.503    Value Loss: 4.470    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 938451     Buffer Size: 15260      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:39:39,662][train][INFO][train.py>_log] ==> #400000     Total Loss: 3.092    [weighted Loss:3.092    Policy Loss: 9.535    Value Loss: 4.328    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 940760     Buffer Size: 15279      Transition Number: 1000.289k Batch Size: 256        Lr: 0.00001 
[2022-03-01 07:43:01,594][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 8.770    Value Loss: 4.144    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 943509     Buffer Size: 15273      Transition Number: 1000.247k Batch Size: 256        Lr: 0.00001 
