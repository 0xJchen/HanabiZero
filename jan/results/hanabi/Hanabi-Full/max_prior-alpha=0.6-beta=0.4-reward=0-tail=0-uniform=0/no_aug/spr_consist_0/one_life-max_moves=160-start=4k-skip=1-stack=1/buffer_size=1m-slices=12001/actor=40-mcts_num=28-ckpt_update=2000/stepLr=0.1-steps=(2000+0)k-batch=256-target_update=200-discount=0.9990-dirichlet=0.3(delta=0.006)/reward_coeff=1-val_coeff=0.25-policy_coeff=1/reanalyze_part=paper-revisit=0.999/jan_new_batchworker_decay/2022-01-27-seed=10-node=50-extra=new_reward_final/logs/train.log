[2022-01-27 08:30:45,564][train][INFO][train.py>_log] ==> #0          Total Loss: 47.368   [weighted Loss:47.368   Policy Loss: 12.896   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1190       Buffer Size: 1190       Transition Number: 11.580  k Batch Size: 256        Lr: 0.00000 
[2022-01-27 08:33:30,212][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.869    [weighted Loss:7.869    Policy Loss: 14.340   Value Loss: 4.588    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 13944      Buffer Size: 13944      Transition Number: 172.896 k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:36:13,880][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.228    [weighted Loss:5.228    Policy Loss: 12.836   Value Loss: 4.148    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 26324      Buffer Size: 26324      Transition Number: 326.509 k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:38:57,460][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.372    [weighted Loss:5.372    Policy Loss: 12.602   Value Loss: 4.336    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 41850      Buffer Size: 41850      Transition Number: 484.805 k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:41:40,567][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.023    [weighted Loss:4.023    Policy Loss: 9.286    Value Loss: 4.018    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 57236      Buffer Size: 57236      Transition Number: 639.992 k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:44:28,498][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.182    [weighted Loss:3.182    Policy Loss: 7.627    Value Loss: 3.867    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 66225      Buffer Size: 66225      Transition Number: 789.637 k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:47:11,056][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.089    [weighted Loss:4.089    Policy Loss: 6.514    Value Loss: 3.837    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 75084      Buffer Size: 75084      Transition Number: 942.599 k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:49:54,725][train][INFO][train.py>_log] ==> #7000       Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 5.280    Value Loss: 3.865    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 81649      Buffer Size: 81649      Transition Number: 1087.191k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:52:38,237][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.368    [weighted Loss:2.368    Policy Loss: 4.640    Value Loss: 4.118    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 88212      Buffer Size: 88212      Transition Number: 1233.947k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:55:25,655][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 4.637    Value Loss: 4.100    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 92114      Buffer Size: 86831      Transition Number: 1300.093k Batch Size: 256        Lr: 0.10000 
[2022-01-27 08:58:11,434][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 4.595    Value Loss: 3.851    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 96103      Buffer Size: 79466      Transition Number: 1300.196k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:00:54,678][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.069    [weighted Loss:2.069    Policy Loss: 4.057    Value Loss: 3.928    Reward Loss: 0.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 99163      Buffer Size: 72129      Transition Number: 1300.043k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:03:38,955][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 4.149    Value Loss: 4.029    Reward Loss: 0.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 102298     Buffer Size: 61716      Transition Number: 1300.126k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:06:23,451][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 4.368    Value Loss: 4.044    Reward Loss: 0.936    Consistency Loss: 0.000    ] Replay Episodes Collected: 105122     Buffer Size: 51236      Transition Number: 1300.163k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:09:10,584][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 4.105    Value Loss: 3.988    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 107955     Buffer Size: 44669      Transition Number: 1300.066k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:11:54,324][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.412    [weighted Loss:2.412    Policy Loss: 4.258    Value Loss: 4.031    Reward Loss: 0.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 110318     Buffer Size: 39509      Transition Number: 1300.042k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:14:37,998][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 3.913    Value Loss: 4.191    Reward Loss: 0.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 112713     Buffer Size: 34711      Transition Number: 1300.034k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:17:22,535][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.758    [weighted Loss:1.758    Policy Loss: 4.756    Value Loss: 3.866    Reward Loss: 0.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 115058     Buffer Size: 30983      Transition Number: 1300.067k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:20:07,466][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 4.465    Value Loss: 3.876    Reward Loss: 0.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 117494     Buffer Size: 27757      Transition Number: 1299.973k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:22:49,387][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 5.437    Value Loss: 4.268    Reward Loss: 0.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 120068     Buffer Size: 26440      Transition Number: 1300.001k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:25:32,446][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 5.410    Value Loss: 4.162    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 122608     Buffer Size: 25357      Transition Number: 1299.961k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:28:20,237][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 5.199    Value Loss: 4.222    Reward Loss: 0.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 125131     Buffer Size: 24813      Transition Number: 1300.295k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:31:03,735][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 4.353    Value Loss: 4.285    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 127649     Buffer Size: 24265      Transition Number: 1300.415k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:33:46,432][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 4.892    Value Loss: 4.346    Reward Loss: 0.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 130135     Buffer Size: 23953      Transition Number: 1300.225k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:36:28,895][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 5.548    Value Loss: 4.551    Reward Loss: 0.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 132605     Buffer Size: 23646      Transition Number: 1299.979k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:39:15,999][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 4.771    Value Loss: 4.570    Reward Loss: 0.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 135182     Buffer Size: 23807      Transition Number: 1300.005k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:41:59,256][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.567    [weighted Loss:1.567    Policy Loss: 5.119    Value Loss: 4.790    Reward Loss: 0.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 137683     Buffer Size: 23942      Transition Number: 1300.017k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:44:42,535][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 5.026    Value Loss: 4.889    Reward Loss: 0.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 140513     Buffer Size: 24425      Transition Number: 1300.002k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:47:24,642][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.360    [weighted Loss:2.360    Policy Loss: 4.526    Value Loss: 4.975    Reward Loss: 0.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 143335     Buffer Size: 24777      Transition Number: 1300.065k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:50:11,612][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 4.807    Value Loss: 5.109    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 146272     Buffer Size: 25118      Transition Number: 1300.094k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:52:53,762][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 4.686    Value Loss: 5.044    Reward Loss: 0.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 149118     Buffer Size: 25471      Transition Number: 1300.157k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:55:36,589][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 4.631    Value Loss: 5.396    Reward Loss: 0.972    Consistency Loss: 0.000    ] Replay Episodes Collected: 152165     Buffer Size: 25987      Transition Number: 1299.998k Batch Size: 256        Lr: 0.10000 
[2022-01-27 09:58:18,899][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.299    [weighted Loss:1.299    Policy Loss: 5.268    Value Loss: 4.880    Reward Loss: 0.966    Consistency Loss: 0.000    ] Replay Episodes Collected: 155184     Buffer Size: 26542      Transition Number: 1300.196k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:01:02,690][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.847    [weighted Loss:2.847    Policy Loss: 5.275    Value Loss: 5.215    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 158287     Buffer Size: 27142      Transition Number: 1300.223k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:03:49,804][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 5.804    Value Loss: 5.281    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 161442     Buffer Size: 27766      Transition Number: 1300.126k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:06:32,539][train][INFO][train.py>_log] ==> #35000      Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 6.382    Value Loss: 5.384    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 164309     Buffer Size: 28102      Transition Number: 1300.212k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:09:15,395][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 5.258    Value Loss: 5.202    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 167220     Buffer Size: 28318      Transition Number: 1300.022k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:12:01,193][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.825    [weighted Loss:2.825    Policy Loss: 5.357    Value Loss: 5.645    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 170740     Buffer Size: 28817      Transition Number: 1300.121k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:14:46,921][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 5.154    Value Loss: 5.694    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 174189     Buffer Size: 29233      Transition Number: 1300.289k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:17:29,367][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 5.290    Value Loss: 5.770    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 177226     Buffer Size: 29335      Transition Number: 1300.106k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:20:12,807][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 5.231    Value Loss: 5.906    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 180191     Buffer Size: 29400      Transition Number: 1299.943k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:22:59,183][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 4.516    Value Loss: 5.807    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 182672     Buffer Size: 28912      Transition Number: 1300.126k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:25:42,961][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 4.748    Value Loss: 5.674    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 185202     Buffer Size: 28316      Transition Number: 1300.031k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:28:26,010][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.768    [weighted Loss:2.768    Policy Loss: 4.269    Value Loss: 5.461    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 187693     Buffer Size: 27625      Transition Number: 1299.950k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:31:09,150][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 5.036    Value Loss: 5.520    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 190039     Buffer Size: 27097      Transition Number: 1299.957k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:33:56,915][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 3.882    Value Loss: 5.575    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 192440     Buffer Size: 26452      Transition Number: 1300.372k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:36:40,235][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.703    [weighted Loss:1.703    Policy Loss: 3.834    Value Loss: 5.328    Reward Loss: 1.232    Consistency Loss: 0.000    ] Replay Episodes Collected: 194789     Buffer Size: 25523      Transition Number: 1299.983k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:39:24,270][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.074    [weighted Loss:2.074    Policy Loss: 4.148    Value Loss: 5.129    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 197219     Buffer Size: 24338      Transition Number: 1300.143k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:42:07,436][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 3.616    Value Loss: 4.753    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 199631     Buffer Size: 23386      Transition Number: 1300.233k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:44:55,148][train][INFO][train.py>_log] ==> #49000      Total Loss: 1.754    [weighted Loss:1.754    Policy Loss: 4.031    Value Loss: 4.735    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 201966     Buffer Size: 22465      Transition Number: 1299.967k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:47:38,736][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 4.205    Value Loss: 4.972    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 204357     Buffer Size: 21908      Transition Number: 1299.969k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:50:24,164][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 3.829    Value Loss: 4.613    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 206664     Buffer Size: 21469      Transition Number: 1299.998k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:53:08,578][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.262    [weighted Loss:2.262    Policy Loss: 4.126    Value Loss: 4.435    Reward Loss: 1.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 209063     Buffer Size: 21087      Transition Number: 1299.969k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:55:54,830][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 4.362    Value Loss: 4.485    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 211572     Buffer Size: 20825      Transition Number: 1300.080k Batch Size: 256        Lr: 0.10000 
[2022-01-27 10:58:41,945][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.192    [weighted Loss:3.192    Policy Loss: 4.834    Value Loss: 4.794    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 213964     Buffer Size: 20740      Transition Number: 1300.119k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:01:26,215][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.085    [weighted Loss:2.085    Policy Loss: 4.604    Value Loss: 4.594    Reward Loss: 1.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 216397     Buffer Size: 20759      Transition Number: 1300.012k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:04:11,402][train][INFO][train.py>_log] ==> #56000      Total Loss: 1.839    [weighted Loss:1.839    Policy Loss: 4.909    Value Loss: 4.726    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 218876     Buffer Size: 20814      Transition Number: 1300.029k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:06:59,639][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 5.567    Value Loss: 4.801    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 221640     Buffer Size: 21197      Transition Number: 1300.149k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:09:43,710][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 4.875    Value Loss: 5.005    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 224377     Buffer Size: 21660      Transition Number: 1300.083k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:12:28,458][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.249    [weighted Loss:2.249    Policy Loss: 4.452    Value Loss: 5.333    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 226933     Buffer Size: 22004      Transition Number: 1300.019k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:15:12,700][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 4.484    Value Loss: 5.600    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 229532     Buffer Size: 22362      Transition Number: 1300.049k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:18:00,466][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 4.372    Value Loss: 5.391    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 231923     Buffer Size: 22565      Transition Number: 1299.967k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:20:45,158][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 4.395    Value Loss: 5.152    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 234287     Buffer Size: 22702      Transition Number: 1300.103k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:23:29,676][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 4.742    Value Loss: 5.355    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 236712     Buffer Size: 22875      Transition Number: 1299.943k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:26:15,164][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 4.501    Value Loss: 4.967    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 239182     Buffer Size: 22926      Transition Number: 1300.020k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:28:59,316][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 4.241    Value Loss: 5.684    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 241668     Buffer Size: 22956      Transition Number: 1299.985k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:31:47,069][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 4.581    Value Loss: 5.423    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 244153     Buffer Size: 22735      Transition Number: 1300.554k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:34:31,058][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.670    [weighted Loss:1.670    Policy Loss: 4.114    Value Loss: 4.999    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 246520     Buffer Size: 22396      Transition Number: 1299.984k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:37:15,509][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.245    [weighted Loss:2.245    Policy Loss: 4.244    Value Loss: 5.362    Reward Loss: 1.169    Consistency Loss: 0.000    ] Replay Episodes Collected: 248895     Buffer Size: 22239      Transition Number: 1300.146k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:40:01,884][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 4.393    Value Loss: 5.526    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 251685     Buffer Size: 22468      Transition Number: 1300.076k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:42:48,035][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 4.183    Value Loss: 5.241    Reward Loss: 1.246    Consistency Loss: 0.000    ] Replay Episodes Collected: 254525     Buffer Size: 22900      Transition Number: 1300.199k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:45:32,244][train][INFO][train.py>_log] ==> #71000      Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 4.142    Value Loss: 5.322    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 257125     Buffer Size: 23126      Transition Number: 1300.193k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:48:17,412][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 4.133    Value Loss: 5.358    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 259725     Buffer Size: 23299      Transition Number: 1300.103k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:51:06,349][train][INFO][train.py>_log] ==> #73000      Total Loss: 1.661    [weighted Loss:1.661    Policy Loss: 4.472    Value Loss: 5.383    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 262684     Buffer Size: 23835      Transition Number: 1300.235k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:53:50,911][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 4.041    Value Loss: 5.629    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 265556     Buffer Size: 24266      Transition Number: 1300.165k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:56:34,972][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 3.976    Value Loss: 5.485    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 268042     Buffer Size: 24271      Transition Number: 1300.464k Batch Size: 256        Lr: 0.10000 
[2022-01-27 11:59:18,775][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 3.944    Value Loss: 5.784    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 270458     Buffer Size: 24324      Transition Number: 1299.954k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:02:07,076][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.102    [weighted Loss:2.102    Policy Loss: 4.184    Value Loss: 5.546    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 272881     Buffer Size: 24199      Transition Number: 1299.959k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:04:51,025][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.016    [weighted Loss:2.016    Policy Loss: 4.218    Value Loss: 5.213    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 275337     Buffer Size: 23701      Transition Number: 1300.112k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:07:36,200][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 3.744    Value Loss: 5.168    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 277677     Buffer Size: 23044      Transition Number: 1300.310k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:10:23,384][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 4.026    Value Loss: 5.287    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 280049     Buffer Size: 22577      Transition Number: 1300.001k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:13:09,708][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.616    [weighted Loss:2.616    Policy Loss: 4.154    Value Loss: 5.196    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 282382     Buffer Size: 22091      Transition Number: 1299.973k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:15:57,918][train][INFO][train.py>_log] ==> #82000      Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 3.889    Value Loss: 4.942    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 284800     Buffer Size: 21311      Transition Number: 1300.188k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:18:42,808][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.244    [weighted Loss:1.244    Policy Loss: 4.117    Value Loss: 5.190    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 287169     Buffer Size: 20715      Transition Number: 1300.007k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:21:27,763][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 4.368    Value Loss: 4.981    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 289525     Buffer Size: 20456      Transition Number: 1300.135k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:24:15,946][train][INFO][train.py>_log] ==> #85000      Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 4.062    Value Loss: 4.818    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 291879     Buffer Size: 20285      Transition Number: 1300.020k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:27:00,342][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.741    [weighted Loss:2.741    Policy Loss: 3.999    Value Loss: 4.487    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 294244     Buffer Size: 20219      Transition Number: 1299.972k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:29:44,976][train][INFO][train.py>_log] ==> #87000      Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 4.518    Value Loss: 4.701    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 297952     Buffer Size: 21482      Transition Number: 1300.027k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:32:30,261][train][INFO][train.py>_log] ==> #88000      Total Loss: 2.034    [weighted Loss:2.034    Policy Loss: 4.061    Value Loss: 5.252    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 301601     Buffer Size: 22805      Transition Number: 1300.216k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:35:19,918][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.122    [weighted Loss:2.122    Policy Loss: 4.067    Value Loss: 5.156    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 304503     Buffer Size: 23302      Transition Number: 1299.976k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:38:04,265][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 4.470    Value Loss: 5.238    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 307295     Buffer Size: 23760      Transition Number: 1300.115k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:40:50,396][train][INFO][train.py>_log] ==> #91000      Total Loss: 2.448    [weighted Loss:2.448    Policy Loss: 4.419    Value Loss: 5.232    Reward Loss: 1.297    Consistency Loss: 0.000    ] Replay Episodes Collected: 309793     Buffer Size: 23908      Transition Number: 1300.012k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:43:35,851][train][INFO][train.py>_log] ==> #92000      Total Loss: 2.678    [weighted Loss:2.678    Policy Loss: 4.495    Value Loss: 5.200    Reward Loss: 1.298    Consistency Loss: 0.000    ] Replay Episodes Collected: 312260     Buffer Size: 24011      Transition Number: 1300.089k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:46:21,239][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 4.115    Value Loss: 5.163    Reward Loss: 1.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 314594     Buffer Size: 24080      Transition Number: 1300.181k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:49:09,358][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 4.114    Value Loss: 5.099    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 317044     Buffer Size: 24110      Transition Number: 1300.036k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:51:54,211][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 4.255    Value Loss: 5.383    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 319490     Buffer Size: 23738      Transition Number: 1300.070k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:54:40,071][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 4.157    Value Loss: 4.935    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 321962     Buffer Size: 22520      Transition Number: 1300.384k Batch Size: 256        Lr: 0.10000 
[2022-01-27 12:57:29,287][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.297    [weighted Loss:2.297    Policy Loss: 3.755    Value Loss: 5.060    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 324701     Buffer Size: 21794      Transition Number: 1300.361k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:00:15,542][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 4.069    Value Loss: 5.491    Reward Loss: 1.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 327364     Buffer Size: 21697      Transition Number: 1300.049k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:03:01,462][train][INFO][train.py>_log] ==> #99000      Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 4.322    Value Loss: 5.077    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 329738     Buffer Size: 21466      Transition Number: 1299.967k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:05:47,128][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 4.263    Value Loss: 5.054    Reward Loss: 1.195    Consistency Loss: 0.000    ] Replay Episodes Collected: 332234     Buffer Size: 21457      Transition Number: 1299.977k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:08:35,588][train][INFO][train.py>_log] ==> #101000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 4.036    Value Loss: 5.214    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 334642     Buffer Size: 21355      Transition Number: 1299.937k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:11:21,410][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 4.091    Value Loss: 4.807    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 337056     Buffer Size: 21273      Transition Number: 1299.963k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:14:06,126][train][INFO][train.py>_log] ==> #103000     Total Loss: 1.302    [weighted Loss:1.302    Policy Loss: 4.580    Value Loss: 5.106    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 339436     Buffer Size: 21182      Transition Number: 1300.368k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:16:51,679][train][INFO][train.py>_log] ==> #104000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 3.900    Value Loss: 4.837    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 341729     Buffer Size: 21054      Transition Number: 1299.994k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:19:35,798][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 4.274    Value Loss: 4.887    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 344082     Buffer Size: 20848      Transition Number: 1299.955k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:22:24,079][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 4.509    Value Loss: 4.730    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 346462     Buffer Size: 20600      Transition Number: 1300.078k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:25:09,615][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 4.241    Value Loss: 4.822    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 348961     Buffer Size: 20480      Transition Number: 1300.052k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:27:54,212][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 5.212    Value Loss: 4.851    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 351357     Buffer Size: 20512      Transition Number: 1300.207k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:30:42,737][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 4.358    Value Loss: 4.604    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 353811     Buffer Size: 20506      Transition Number: 1300.496k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:33:30,587][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.581    [weighted Loss:2.581    Policy Loss: 4.555    Value Loss: 4.955    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 356290     Buffer Size: 20559      Transition Number: 1299.948k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:36:15,720][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 4.678    Value Loss: 4.834    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 358880     Buffer Size: 20624      Transition Number: 1300.632k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:39:02,148][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.559    [weighted Loss:2.559    Policy Loss: 4.695    Value Loss: 4.830    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 361277     Buffer Size: 20674      Transition Number: 1299.960k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:41:51,694][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 4.434    Value Loss: 4.833    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 363763     Buffer Size: 20695      Transition Number: 1300.045k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:44:36,800][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 4.546    Value Loss: 4.670    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 366146     Buffer Size: 20652      Transition Number: 1300.079k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:47:22,306][train][INFO][train.py>_log] ==> #115000     Total Loss: 2.173    [weighted Loss:2.173    Policy Loss: 4.320    Value Loss: 4.459    Reward Loss: 1.233    Consistency Loss: 0.000    ] Replay Episodes Collected: 368653     Buffer Size: 20562      Transition Number: 1299.948k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:50:07,668][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 4.639    Value Loss: 4.941    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 371067     Buffer Size: 20479      Transition Number: 1300.225k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:52:56,670][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.599    [weighted Loss:2.599    Policy Loss: 4.241    Value Loss: 4.548    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 373568     Buffer Size: 20420      Transition Number: 1300.279k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:55:41,841][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.753    [weighted Loss:2.753    Policy Loss: 4.542    Value Loss: 4.555    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 375961     Buffer Size: 20399      Transition Number: 1300.287k Batch Size: 256        Lr: 0.10000 
[2022-01-27 13:58:27,329][train][INFO][train.py>_log] ==> #119000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 5.047    Value Loss: 4.726    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 378394     Buffer Size: 20335      Transition Number: 1299.951k Batch Size: 256        Lr: 0.10000 
[2022-01-27 14:01:13,257][train][INFO][train.py>_log] ==> #120000     Total Loss: 1.182    [weighted Loss:1.182    Policy Loss: 4.697    Value Loss: 4.832    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 380903     Buffer Size: 20281      Transition Number: 1299.981k Batch Size: 256        Lr: 0.10000 
[2022-01-27 14:04:00,462][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 4.506    Value Loss: 4.425    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 383269     Buffer Size: 20287      Transition Number: 1300.237k Batch Size: 256        Lr: 0.10000 
[2022-01-27 14:06:46,689][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 4.930    Value Loss: 4.729    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 385659     Buffer Size: 20287      Transition Number: 1300.008k Batch Size: 256        Lr: 0.10000 
[2022-01-27 14:09:31,788][train][INFO][train.py>_log] ==> #123000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 5.182    Value Loss: 4.781    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 388134     Buffer Size: 20362      Transition Number: 1300.638k Batch Size: 256        Lr: 0.10000 
[2022-01-27 14:12:15,955][train][INFO][train.py>_log] ==> #124000     Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 4.975    Value Loss: 4.674    Reward Loss: 1.227    Consistency Loss: 0.000    ] Replay Episodes Collected: 390566     Buffer Size: 20423      Transition Number: 1300.023k Batch Size: 256        Lr: 0.10000 
