[2022-02-15 09:06:37,792][train][INFO][train.py>_log] ==> #0          Total Loss: 48.152   [weighted Loss:48.152   Policy Loss: 13.680   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1160       Buffer Size: 1160       Transition Number: 11.717  k Batch Size: 256        Lr: 0.00000 
[2022-02-15 09:09:06,538][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.851    [weighted Loss:7.851    Policy Loss: 14.476   Value Loss: 4.736    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 11030      Buffer Size: 11030      Transition Number: 136.914 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:11:36,963][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.644    [weighted Loss:5.644    Policy Loss: 13.549   Value Loss: 4.475    Reward Loss: 1.412    Consistency Loss: 0.000    ] Replay Episodes Collected: 20852      Buffer Size: 20852      Transition Number: 258.356 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:14:09,057][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.072    [weighted Loss:5.072    Policy Loss: 11.936   Value Loss: 4.085    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 37414      Buffer Size: 37414      Transition Number: 384.018 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:16:41,113][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.654    [weighted Loss:6.654    Policy Loss: 11.677   Value Loss: 4.192    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 53703      Buffer Size: 53703      Transition Number: 507.496 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:19:09,943][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.847    [weighted Loss:3.847    Policy Loss: 9.852    Value Loss: 3.976    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 66551      Buffer Size: 66551      Transition Number: 631.722 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:21:37,595][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.839    [weighted Loss:3.839    Policy Loss: 11.277   Value Loss: 3.927    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 79029      Buffer Size: 79029      Transition Number: 751.439 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:24:18,173][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.266    [weighted Loss:4.266    Policy Loss: 8.691    Value Loss: 4.087    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 92901      Buffer Size: 92901      Transition Number: 883.544 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:27:07,044][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.899    [weighted Loss:2.899    Policy Loss: 8.889    Value Loss: 4.159    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 107612     Buffer Size: 105544     Transition Number: 1000.192k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:30:03,745][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 10.310   Value Loss: 4.228    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 120422     Buffer Size: 106826     Transition Number: 1000.118k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:33:38,837][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.707    [weighted Loss:4.707    Policy Loss: 8.228    Value Loss: 4.024    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 133000     Buffer Size: 105321     Transition Number: 1000.186k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:36:43,730][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.823    [weighted Loss:4.823    Policy Loss: 9.799    Value Loss: 4.329    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 146381     Buffer Size: 94584      Transition Number: 1000.036k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:39:37,569][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.256    [weighted Loss:4.256    Policy Loss: 7.808    Value Loss: 4.124    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 156731     Buffer Size: 89694      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:42:30,182][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.361    [weighted Loss:3.361    Policy Loss: 7.105    Value Loss: 4.204    Reward Loss: 1.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 167165     Buffer Size: 85873      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:45:23,571][train][INFO][train.py>_log] ==> #14000      Total Loss: 3.205    [weighted Loss:3.205    Policy Loss: 7.053    Value Loss: 4.698    Reward Loss: 2.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 177647     Buffer Size: 81591      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:48:17,826][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.017    [weighted Loss:5.017    Policy Loss: 6.855    Value Loss: 4.989    Reward Loss: 2.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 190119     Buffer Size: 79241      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:51:16,104][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.496    [weighted Loss:3.496    Policy Loss: 8.750    Value Loss: 4.825    Reward Loss: 2.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 202630     Buffer Size: 79041      Transition Number: 1000.141k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:54:06,546][train][INFO][train.py>_log] ==> #17000      Total Loss: 5.204    [weighted Loss:5.204    Policy Loss: 7.687    Value Loss: 4.559    Reward Loss: 2.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 213042     Buffer Size: 77627      Transition Number: 1000.173k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:57:00,722][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.928    [weighted Loss:2.928    Policy Loss: 7.769    Value Loss: 4.844    Reward Loss: 2.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 223721     Buffer Size: 77987      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-15 09:59:54,952][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.280    [weighted Loss:4.280    Policy Loss: 7.671    Value Loss: 4.427    Reward Loss: 2.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 234294     Buffer Size: 78234      Transition Number: 1000.117k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:02:47,326][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.202    [weighted Loss:5.202    Policy Loss: 8.040    Value Loss: 4.792    Reward Loss: 2.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 244864     Buffer Size: 78101      Transition Number: 1000.205k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:05:39,788][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.841    [weighted Loss:4.841    Policy Loss: 8.477    Value Loss: 4.825    Reward Loss: 2.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 254041     Buffer Size: 76801      Transition Number: 1000.072k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:08:30,709][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.893    [weighted Loss:4.893    Policy Loss: 8.420    Value Loss: 4.721    Reward Loss: 2.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 263227     Buffer Size: 74203      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:11:21,087][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.831    [weighted Loss:4.831    Policy Loss: 8.660    Value Loss: 5.144    Reward Loss: 2.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 271059     Buffer Size: 70389      Transition Number: 1000.095k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:14:11,544][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.411    [weighted Loss:5.411    Policy Loss: 8.795    Value Loss: 4.683    Reward Loss: 2.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 278945     Buffer Size: 67608      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:17:00,039][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.030    [weighted Loss:5.030    Policy Loss: 8.931    Value Loss: 4.491    Reward Loss: 2.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 284866     Buffer Size: 63760      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:19:50,929][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.210    [weighted Loss:5.210    Policy Loss: 8.045    Value Loss: 4.947    Reward Loss: 2.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 290810     Buffer Size: 59831      Transition Number: 1000.073k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:22:38,453][train][INFO][train.py>_log] ==> #27000      Total Loss: 5.373    [weighted Loss:5.373    Policy Loss: 8.115    Value Loss: 5.436    Reward Loss: 2.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 294976     Buffer Size: 54922      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:25:25,554][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.675    [weighted Loss:4.675    Policy Loss: 7.121    Value Loss: 4.943    Reward Loss: 1.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 298982     Buffer Size: 50186      Transition Number: 1000.106k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:28:12,695][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 6.349    Value Loss: 4.894    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 301795     Buffer Size: 45603      Transition Number: 1000.071k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:30:58,278][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.829    [weighted Loss:3.829    Policy Loss: 6.572    Value Loss: 4.701    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 304612     Buffer Size: 40457      Transition Number: 1000.055k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:33:41,215][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 5.443    Value Loss: 5.116    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 306621     Buffer Size: 36384      Transition Number: 1000.070k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:36:29,001][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 5.105    Value Loss: 4.885    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 308798     Buffer Size: 31634      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:39:09,753][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.695    [weighted Loss:2.695    Policy Loss: 5.043    Value Loss: 5.081    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 310617     Buffer Size: 27850      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:41:54,303][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 4.782    Value Loss: 5.175    Reward Loss: 1.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 312512     Buffer Size: 24419      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:44:39,137][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 4.517    Value Loss: 5.288    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 314439     Buffer Size: 21474      Transition Number: 1000.287k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:47:20,601][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 4.405    Value Loss: 5.049    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 316336     Buffer Size: 19485      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:50:02,540][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 4.232    Value Loss: 5.028    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 318091     Buffer Size: 17690      Transition Number: 1000.128k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:52:43,734][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 4.449    Value Loss: 5.038    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 319871     Buffer Size: 16538      Transition Number: 1000.035k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:55:25,751][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 4.117    Value Loss: 4.657    Reward Loss: 1.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 321827     Buffer Size: 15773      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-02-15 10:58:04,823][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.767    [weighted Loss:2.767    Policy Loss: 4.186    Value Loss: 4.709    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 323592     Buffer Size: 15358      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:00:47,814][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 4.680    Value Loss: 4.791    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 325521     Buffer Size: 15190      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:03:28,023][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.994    [weighted Loss:1.994    Policy Loss: 4.580    Value Loss: 5.216    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 327430     Buffer Size: 15076      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:06:09,590][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 5.485    Value Loss: 5.194    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 329276     Buffer Size: 14955      Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:08:50,649][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.902    [weighted Loss:2.902    Policy Loss: 5.429    Value Loss: 5.169    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 331126     Buffer Size: 14776      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:11:32,417][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 5.416    Value Loss: 5.611    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 333092     Buffer Size: 14895      Transition Number: 1000.489k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:14:14,493][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.702    [weighted Loss:2.702    Policy Loss: 6.362    Value Loss: 5.196    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 335070     Buffer Size: 14996      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:16:54,284][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.187    [weighted Loss:4.187    Policy Loss: 7.351    Value Loss: 5.279    Reward Loss: 1.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 336916     Buffer Size: 15052      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:19:37,419][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.181    [weighted Loss:3.181    Policy Loss: 6.798    Value Loss: 4.876    Reward Loss: 1.174    Consistency Loss: 0.000    ] Replay Episodes Collected: 338764     Buffer Size: 15082      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:22:18,060][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.605    [weighted Loss:3.605    Policy Loss: 8.110    Value Loss: 5.069    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 340633     Buffer Size: 15040      Transition Number: 1000.173k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:25:11,620][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 8.811    Value Loss: 4.866    Reward Loss: 1.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 342449     Buffer Size: 14988      Transition Number: 1000.419k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:27:54,406][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 8.991    Value Loss: 5.037    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 344446     Buffer Size: 14984      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:30:36,518][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.566    [weighted Loss:3.566    Policy Loss: 10.117   Value Loss: 4.704    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 346379     Buffer Size: 14988      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:33:17,167][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.379    [weighted Loss:3.379    Policy Loss: 9.665    Value Loss: 4.387    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 348319     Buffer Size: 14929      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:35:55,206][train][INFO][train.py>_log] ==> #54000      Total Loss: 4.493    [weighted Loss:4.493    Policy Loss: 9.858    Value Loss: 4.765    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 350266     Buffer Size: 14876      Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:38:36,279][train][INFO][train.py>_log] ==> #55000      Total Loss: 5.484    [weighted Loss:5.484    Policy Loss: 10.271   Value Loss: 4.690    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 352143     Buffer Size: 14926      Transition Number: 1000.377k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:41:19,593][train][INFO][train.py>_log] ==> #56000      Total Loss: 4.101    [weighted Loss:4.101    Policy Loss: 9.894    Value Loss: 4.633    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 354071     Buffer Size: 15007      Transition Number: 1000.153k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:44:02,347][train][INFO][train.py>_log] ==> #57000      Total Loss: 5.565    [weighted Loss:5.565    Policy Loss: 9.929    Value Loss: 5.076    Reward Loss: 1.214    Consistency Loss: 0.000    ] Replay Episodes Collected: 356118     Buffer Size: 15123      Transition Number: 1000.471k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:46:43,817][train][INFO][train.py>_log] ==> #58000      Total Loss: 4.773    [weighted Loss:4.773    Policy Loss: 9.856    Value Loss: 5.232    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 358047     Buffer Size: 15248      Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:49:24,580][train][INFO][train.py>_log] ==> #59000      Total Loss: 4.562    [weighted Loss:4.562    Policy Loss: 10.565   Value Loss: 5.123    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 359882     Buffer Size: 15382      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:52:09,096][train][INFO][train.py>_log] ==> #60000      Total Loss: 4.850    [weighted Loss:4.850    Policy Loss: 10.001   Value Loss: 4.850    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 361882     Buffer Size: 15504      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:54:48,210][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 9.600    Value Loss: 5.132    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 363826     Buffer Size: 15625      Transition Number: 1000.305k Batch Size: 256        Lr: 0.10000 
[2022-02-15 11:57:30,906][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.061    [weighted Loss:4.061    Policy Loss: 9.604    Value Loss: 5.037    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 365814     Buffer Size: 15702      Transition Number: 1000.285k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:00:11,703][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 9.058    Value Loss: 5.266    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 367656     Buffer Size: 15736      Transition Number: 1000.173k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:02:54,068][train][INFO][train.py>_log] ==> #64000      Total Loss: 4.205    [weighted Loss:4.205    Policy Loss: 9.217    Value Loss: 4.927    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 369603     Buffer Size: 15746      Transition Number: 1000.047k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:05:34,658][train][INFO][train.py>_log] ==> #65000      Total Loss: 4.788    [weighted Loss:4.788    Policy Loss: 8.804    Value Loss: 5.237    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 371567     Buffer Size: 15795      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:08:15,474][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 9.315    Value Loss: 5.433    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 373512     Buffer Size: 15806      Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:10:56,286][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.475    [weighted Loss:3.475    Policy Loss: 9.185    Value Loss: 5.299    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 375376     Buffer Size: 15773      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:13:37,650][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.553    [weighted Loss:3.553    Policy Loss: 9.243    Value Loss: 5.020    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 377313     Buffer Size: 15747      Transition Number: 1000.344k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:16:19,398][train][INFO][train.py>_log] ==> #69000      Total Loss: 4.884    [weighted Loss:4.884    Policy Loss: 9.376    Value Loss: 5.255    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 379240     Buffer Size: 15701      Transition Number: 1000.209k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:19:01,952][train][INFO][train.py>_log] ==> #70000      Total Loss: 4.257    [weighted Loss:4.257    Policy Loss: 9.492    Value Loss: 5.222    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 381162     Buffer Size: 15657      Transition Number: 1000.235k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:21:44,791][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.845    [weighted Loss:3.845    Policy Loss: 9.163    Value Loss: 4.901    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 383081     Buffer Size: 15681      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:24:27,605][train][INFO][train.py>_log] ==> #72000      Total Loss: 4.755    [weighted Loss:4.755    Policy Loss: 9.170    Value Loss: 5.047    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 385092     Buffer Size: 15691      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:27:09,064][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.943    [weighted Loss:3.943    Policy Loss: 8.641    Value Loss: 5.159    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 387031     Buffer Size: 15675      Transition Number: 1000.025k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:29:48,653][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.052    [weighted Loss:4.052    Policy Loss: 8.392    Value Loss: 5.330    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 388956     Buffer Size: 15676      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:32:29,689][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 8.522    Value Loss: 5.130    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 390820     Buffer Size: 15684      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:35:10,975][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 8.697    Value Loss: 4.916    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 392778     Buffer Size: 15698      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:37:52,779][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 8.605    Value Loss: 5.352    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 394647     Buffer Size: 15725      Transition Number: 1000.207k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:40:33,561][train][INFO][train.py>_log] ==> #78000      Total Loss: 3.965    [weighted Loss:3.965    Policy Loss: 8.772    Value Loss: 5.456    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 396591     Buffer Size: 15753      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:43:14,123][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.423    [weighted Loss:4.423    Policy Loss: 9.226    Value Loss: 4.809    Reward Loss: 1.328    Consistency Loss: 0.000    ] Replay Episodes Collected: 398492     Buffer Size: 15747      Transition Number: 1000.328k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:45:54,049][train][INFO][train.py>_log] ==> #80000      Total Loss: 4.739    [weighted Loss:4.739    Policy Loss: 8.990    Value Loss: 4.834    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 400355     Buffer Size: 15722      Transition Number: 1000.175k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:48:35,790][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.453    [weighted Loss:4.453    Policy Loss: 9.082    Value Loss: 4.919    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 402282     Buffer Size: 15637      Transition Number: 1000.165k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:51:16,874][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.883    [weighted Loss:3.883    Policy Loss: 9.313    Value Loss: 4.789    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 404272     Buffer Size: 15568      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:54:01,095][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 9.063    Value Loss: 4.752    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 406224     Buffer Size: 15623      Transition Number: 1000.542k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:56:42,030][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.872    [weighted Loss:4.872    Policy Loss: 9.205    Value Loss: 4.627    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 408187     Buffer Size: 15662      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 12:59:21,347][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 9.639    Value Loss: 5.389    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 410227     Buffer Size: 15807      Transition Number: 1000.076k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:02:01,448][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 9.514    Value Loss: 5.002    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 412358     Buffer Size: 15953      Transition Number: 1000.017k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:04:42,578][train][INFO][train.py>_log] ==> #87000      Total Loss: 5.040    [weighted Loss:5.040    Policy Loss: 9.908    Value Loss: 5.110    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 414431     Buffer Size: 16104      Transition Number: 1000.183k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:07:23,809][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.333    [weighted Loss:4.333    Policy Loss: 9.704    Value Loss: 5.380    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 416461     Buffer Size: 16283      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:10:06,955][train][INFO][train.py>_log] ==> #89000      Total Loss: 4.068    [weighted Loss:4.068    Policy Loss: 9.908    Value Loss: 5.146    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 418498     Buffer Size: 16439      Transition Number: 1000.085k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:12:48,422][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.941    [weighted Loss:3.941    Policy Loss: 10.063   Value Loss: 5.422    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 420495     Buffer Size: 16560      Transition Number: 1000.025k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:15:30,104][train][INFO][train.py>_log] ==> #91000      Total Loss: 5.195    [weighted Loss:5.195    Policy Loss: 9.963    Value Loss: 5.627    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 422441     Buffer Size: 16632      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:18:12,138][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.071    [weighted Loss:4.071    Policy Loss: 10.113   Value Loss: 5.546    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 424486     Buffer Size: 16678      Transition Number: 1000.159k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:20:57,520][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.069    [weighted Loss:3.069    Policy Loss: 9.609    Value Loss: 5.097    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 426458     Buffer Size: 16557      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:23:39,444][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.709    [weighted Loss:4.709    Policy Loss: 9.981    Value Loss: 5.552    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 428382     Buffer Size: 16426      Transition Number: 1000.197k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:26:20,992][train][INFO][train.py>_log] ==> #95000      Total Loss: 4.384    [weighted Loss:4.384    Policy Loss: 9.760    Value Loss: 5.148    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 430474     Buffer Size: 16298      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:29:02,356][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.541    [weighted Loss:5.541    Policy Loss: 9.434    Value Loss: 5.433    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 432394     Buffer Size: 16195      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:31:44,892][train][INFO][train.py>_log] ==> #97000      Total Loss: 5.346    [weighted Loss:5.346    Policy Loss: 9.478    Value Loss: 5.057    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 434320     Buffer Size: 16119      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:34:26,691][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.954    [weighted Loss:3.954    Policy Loss: 9.298    Value Loss: 5.332    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 436292     Buffer Size: 16058      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:37:10,012][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.574    [weighted Loss:3.574    Policy Loss: 9.313    Value Loss: 5.280    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 438196     Buffer Size: 16065      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:39:53,831][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.344    [weighted Loss:4.344    Policy Loss: 9.024    Value Loss: 4.959    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 440262     Buffer Size: 16093      Transition Number: 1000.510k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:42:37,331][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.101    [weighted Loss:3.101    Policy Loss: 8.473    Value Loss: 5.457    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 442282     Buffer Size: 16187      Transition Number: 1000.033k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:45:20,101][train][INFO][train.py>_log] ==> #102000     Total Loss: 4.145    [weighted Loss:4.145    Policy Loss: 8.536    Value Loss: 5.266    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 444238     Buffer Size: 16304      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:48:04,644][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.256    [weighted Loss:3.256    Policy Loss: 8.456    Value Loss: 5.299    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 446243     Buffer Size: 16344      Transition Number: 1000.099k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:50:47,508][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.651    [weighted Loss:3.651    Policy Loss: 8.750    Value Loss: 4.980    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 448132     Buffer Size: 16366      Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:53:29,116][train][INFO][train.py>_log] ==> #105000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 8.582    Value Loss: 5.856    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 450129     Buffer Size: 16471      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:56:13,088][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.744    [weighted Loss:2.744    Policy Loss: 8.275    Value Loss: 5.118    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 452098     Buffer Size: 16610      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-02-15 13:58:55,907][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.215    [weighted Loss:2.215    Policy Loss: 7.829    Value Loss: 5.805    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 454194     Buffer Size: 16721      Transition Number: 1000.156k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:01:36,145][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.967    [weighted Loss:3.967    Policy Loss: 8.083    Value Loss: 5.918    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 456225     Buffer Size: 16810      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:04:18,617][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.657    [weighted Loss:3.657    Policy Loss: 7.635    Value Loss: 5.508    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 458168     Buffer Size: 16891      Transition Number: 1000.233k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:06:58,905][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.955    [weighted Loss:2.955    Policy Loss: 8.367    Value Loss: 6.348    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 460103     Buffer Size: 16914      Transition Number: 1000.330k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:09:40,951][train][INFO][train.py>_log] ==> #111000     Total Loss: 4.032    [weighted Loss:4.032    Policy Loss: 7.677    Value Loss: 6.091    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 462130     Buffer Size: 16997      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:12:22,619][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.640    [weighted Loss:2.640    Policy Loss: 7.587    Value Loss: 5.626    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 464057     Buffer Size: 17080      Transition Number: 1000.251k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:15:04,351][train][INFO][train.py>_log] ==> #113000     Total Loss: 2.824    [weighted Loss:2.824    Policy Loss: 7.498    Value Loss: 5.835    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 466056     Buffer Size: 17189      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:17:47,399][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.874    [weighted Loss:3.874    Policy Loss: 7.560    Value Loss: 5.672    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 468153     Buffer Size: 17207      Transition Number: 1000.065k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:20:31,870][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 7.163    Value Loss: 5.625    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 470078     Buffer Size: 17182      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:23:16,186][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.192    [weighted Loss:3.192    Policy Loss: 7.207    Value Loss: 5.638    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 472150     Buffer Size: 17115      Transition Number: 1000.002k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:25:59,883][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 7.860    Value Loss: 5.611    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 474271     Buffer Size: 17171      Transition Number: 1000.107k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:28:44,244][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 7.848    Value Loss: 6.037    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 476362     Buffer Size: 17284      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:31:28,922][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.849    [weighted Loss:3.849    Policy Loss: 7.853    Value Loss: 5.790    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 478460     Buffer Size: 17380      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:34:13,059][train][INFO][train.py>_log] ==> #120000     Total Loss: 4.306    [weighted Loss:4.306    Policy Loss: 7.980    Value Loss: 5.644    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 480582     Buffer Size: 17469      Transition Number: 1000.281k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:36:56,435][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.979    [weighted Loss:3.979    Policy Loss: 8.431    Value Loss: 5.838    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 482698     Buffer Size: 17482      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:39:39,026][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.650    [weighted Loss:3.650    Policy Loss: 8.011    Value Loss: 6.083    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 484851     Buffer Size: 17465      Transition Number: 1000.035k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:42:21,415][train][INFO][train.py>_log] ==> #123000     Total Loss: 5.211    [weighted Loss:5.211    Policy Loss: 7.719    Value Loss: 5.965    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 486785     Buffer Size: 17432      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:45:04,618][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 8.445    Value Loss: 5.598    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 488759     Buffer Size: 17400      Transition Number: 1000.112k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:47:45,671][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 8.460    Value Loss: 5.646    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 490697     Buffer Size: 17241      Transition Number: 1000.348k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:50:30,743][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.619    [weighted Loss:4.619    Policy Loss: 8.592    Value Loss: 5.749    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 492701     Buffer Size: 16992      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:53:14,457][train][INFO][train.py>_log] ==> #127000     Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 8.544    Value Loss: 5.864    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 495037     Buffer Size: 17073      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:56:00,338][train][INFO][train.py>_log] ==> #128000     Total Loss: 3.337    [weighted Loss:3.337    Policy Loss: 8.603    Value Loss: 5.773    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 497376     Buffer Size: 17133      Transition Number: 1000.180k Batch Size: 256        Lr: 0.10000 
[2022-02-15 14:58:43,705][train][INFO][train.py>_log] ==> #129000     Total Loss: 4.323    [weighted Loss:4.323    Policy Loss: 8.082    Value Loss: 5.770    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 499485     Buffer Size: 17061      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
