[2022-01-25 04:45:51,040][train][INFO][train.py>_log] ==> #0          Total Loss: 47.204   [weighted Loss:47.204   Policy Loss: 12.732   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1108       Buffer Size: 1108       Transition Number: 10.927  k Batch Size: 256        Lr: 0.00000 
[2022-01-25 04:48:36,648][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.049    [weighted Loss:6.049    Policy Loss: 13.326   Value Loss: 4.729    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 14007      Buffer Size: 14007      Transition Number: 174.519 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:51:21,182][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.597    [weighted Loss:4.597    Policy Loss: 12.496   Value Loss: 3.968    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 26493      Buffer Size: 26493      Transition Number: 329.809 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:54:06,026][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.328    [weighted Loss:4.328    Policy Loss: 9.958    Value Loss: 3.834    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 47667      Buffer Size: 47667      Transition Number: 492.254 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:56:49,333][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 8.898    Value Loss: 3.720    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 68809      Buffer Size: 68809      Transition Number: 650.435 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:59:37,365][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.961    [weighted Loss:2.961    Policy Loss: 8.795    Value Loss: 3.667    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 84711      Buffer Size: 84711      Transition Number: 809.891 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:02:22,209][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 9.601    Value Loss: 4.033    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 100550     Buffer Size: 100550     Transition Number: 969.864 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:05:07,050][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.374    [weighted Loss:4.374    Policy Loss: 7.879    Value Loss: 4.057    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 111861     Buffer Size: 111861     Transition Number: 1126.889k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:08:07,823][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 7.953    Value Loss: 4.168    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 124131     Buffer Size: 116126     Transition Number: 1200.483k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:11:07,193][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.484    [weighted Loss:3.484    Policy Loss: 7.981    Value Loss: 4.332    Reward Loss: 1.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 134481     Buffer Size: 112779     Transition Number: 1200.178k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:14:04,775][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.367    [weighted Loss:4.367    Policy Loss: 7.729    Value Loss: 4.268    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 144712     Buffer Size: 104415     Transition Number: 1200.306k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:17:06,085][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.651    [weighted Loss:4.651    Policy Loss: 8.303    Value Loss: 4.388    Reward Loss: 1.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 155112     Buffer Size: 91726      Transition Number: 1200.128k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:20:06,363][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.779    [weighted Loss:2.779    Policy Loss: 7.079    Value Loss: 4.023    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 165365     Buffer Size: 83458      Transition Number: 1200.227k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:23:05,463][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.568    [weighted Loss:3.568    Policy Loss: 8.627    Value Loss: 4.182    Reward Loss: 1.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 175258     Buffer Size: 76717      Transition Number: 1200.182k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:25:58,859][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.301    [weighted Loss:4.301    Policy Loss: 8.681    Value Loss: 4.029    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 184946     Buffer Size: 73919      Transition Number: 1200.079k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:28:55,992][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.802    [weighted Loss:4.802    Policy Loss: 9.770    Value Loss: 4.108    Reward Loss: 2.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 195134     Buffer Size: 72195      Transition Number: 1200.281k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:31:51,692][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.721    [weighted Loss:3.721    Policy Loss: 9.215    Value Loss: 4.046    Reward Loss: 1.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 205245     Buffer Size: 71858      Transition Number: 1200.129k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:34:45,129][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.898    [weighted Loss:4.898    Policy Loss: 9.673    Value Loss: 4.480    Reward Loss: 1.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 214087     Buffer Size: 70713      Transition Number: 1200.057k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:37:35,982][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.202    [weighted Loss:5.202    Policy Loss: 10.254   Value Loss: 4.210    Reward Loss: 1.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 222639     Buffer Size: 69664      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:40:27,291][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.236    [weighted Loss:4.236    Policy Loss: 9.758    Value Loss: 4.162    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 230390     Buffer Size: 67869      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:43:17,854][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.418    [weighted Loss:5.418    Policy Loss: 10.312   Value Loss: 4.484    Reward Loss: 1.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 238122     Buffer Size: 66192      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:46:12,103][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.869    [weighted Loss:4.869    Policy Loss: 9.958    Value Loss: 4.648    Reward Loss: 2.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 246474     Buffer Size: 64958      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:49:07,318][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.130    [weighted Loss:4.130    Policy Loss: 8.943    Value Loss: 4.694    Reward Loss: 2.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 255007     Buffer Size: 63591      Transition Number: 1200.129k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:52:00,136][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.483    [weighted Loss:4.483    Policy Loss: 9.094    Value Loss: 4.666    Reward Loss: 1.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 262298     Buffer Size: 61166      Transition Number: 1200.201k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:54:49,557][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.063    [weighted Loss:5.063    Policy Loss: 9.268    Value Loss: 4.961    Reward Loss: 2.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 269418     Buffer Size: 59347      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:57:37,720][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.004    [weighted Loss:5.004    Policy Loss: 8.992    Value Loss: 5.110    Reward Loss: 2.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 275722     Buffer Size: 57407      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:00:23,822][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.418    [weighted Loss:5.418    Policy Loss: 8.774    Value Loss: 5.193    Reward Loss: 2.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 281847     Buffer Size: 55757      Transition Number: 1200.193k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:03:08,635][train][INFO][train.py>_log] ==> #27000      Total Loss: 5.720    [weighted Loss:5.720    Policy Loss: 9.510    Value Loss: 4.940    Reward Loss: 2.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 286497     Buffer Size: 53668      Transition Number: 1200.201k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:05:53,583][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.158    [weighted Loss:4.158    Policy Loss: 8.222    Value Loss: 5.079    Reward Loss: 1.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 291078     Buffer Size: 51059      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:08:38,978][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.112    [weighted Loss:4.112    Policy Loss: 7.910    Value Loss: 5.265    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 294037     Buffer Size: 47327      Transition Number: 1200.239k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:11:28,314][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.499    [weighted Loss:4.499    Policy Loss: 7.401    Value Loss: 5.102    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 297072     Buffer Size: 43002      Transition Number: 1200.085k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:14:13,554][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 6.445    Value Loss: 5.137    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 299375     Buffer Size: 39087      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:16:57,978][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 5.876    Value Loss: 5.264    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 301722     Buffer Size: 35241      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:19:45,221][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 5.430    Value Loss: 5.646    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 304014     Buffer Size: 31391      Transition Number: 1200.156k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:22:31,203][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.498    [weighted Loss:3.498    Policy Loss: 5.413    Value Loss: 5.174    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 306309     Buffer Size: 27930      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:25:16,356][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.359    [weighted Loss:3.359    Policy Loss: 5.452    Value Loss: 5.246    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 308495     Buffer Size: 24673      Transition Number: 1200.040k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:28:01,154][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 4.751    Value Loss: 5.229    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 310600     Buffer Size: 22510      Transition Number: 1200.450k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:30:49,375][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 4.427    Value Loss: 5.102    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 312780     Buffer Size: 20436      Transition Number: 1200.064k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:33:33,275][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 5.844    Value Loss: 5.195    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 314954     Buffer Size: 19555      Transition Number: 1200.118k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:36:17,247][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 5.239    Value Loss: 5.190    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 317331     Buffer Size: 19046      Transition Number: 1200.043k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:39:01,164][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 5.548    Value Loss: 5.006    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 319539     Buffer Size: 18937      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:41:49,379][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 5.637    Value Loss: 4.914    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 321860     Buffer Size: 18820      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:44:33,787][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 5.963    Value Loss: 4.897    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 324161     Buffer Size: 18781      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:47:18,620][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 6.422    Value Loss: 5.234    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 326624     Buffer Size: 19067      Transition Number: 1200.212k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:50:03,113][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 6.559    Value Loss: 5.076    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 329142     Buffer Size: 19430      Transition Number: 1200.132k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:52:48,572][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 6.563    Value Loss: 5.202    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 331427     Buffer Size: 19577      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:55:37,896][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 6.291    Value Loss: 5.254    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 333823     Buffer Size: 19780      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:58:22,143][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.738    [weighted Loss:2.738    Policy Loss: 6.753    Value Loss: 5.235    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 336086     Buffer Size: 19865      Transition Number: 1200.340k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:01:06,666][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 5.553    Value Loss: 5.056    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 338455     Buffer Size: 19818      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:03:53,786][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 5.855    Value Loss: 5.381    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 342057     Buffer Size: 21106      Transition Number: 1200.423k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:06:40,977][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 5.587    Value Loss: 4.818    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 345549     Buffer Size: 22332      Transition Number: 1200.004k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:09:26,838][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 5.115    Value Loss: 5.141    Reward Loss: 1.274    Consistency Loss: 0.000    ] Replay Episodes Collected: 347987     Buffer Size: 22234      Transition Number: 1200.411k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:12:12,974][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.132    [weighted Loss:3.132    Policy Loss: 5.046    Value Loss: 5.075    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 350449     Buffer Size: 21927      Transition Number: 1200.102k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:15:02,915][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 5.046    Value Loss: 4.632    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 352774     Buffer Size: 21555      Transition Number: 1200.479k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:17:48,827][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 5.418    Value Loss: 4.443    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 355102     Buffer Size: 21193      Transition Number: 1200.178k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:20:35,118][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 5.421    Value Loss: 4.472    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 357550     Buffer Size: 21056      Transition Number: 1200.210k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:23:20,779][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 6.049    Value Loss: 4.747    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 359918     Buffer Size: 20641      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:26:10,482][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.819    [weighted Loss:2.819    Policy Loss: 5.793    Value Loss: 4.406    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 362239     Buffer Size: 19070      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:28:55,853][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 5.561    Value Loss: 4.441    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 364577     Buffer Size: 17992      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:31:41,818][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.997    [weighted Loss:2.997    Policy Loss: 6.538    Value Loss: 4.940    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 366956     Buffer Size: 17806      Transition Number: 1199.950k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:34:27,929][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 6.178    Value Loss: 4.525    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 369245     Buffer Size: 17725      Transition Number: 1200.154k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:37:13,366][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 6.556    Value Loss: 4.696    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 371701     Buffer Size: 17978      Transition Number: 1200.165k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:40:01,365][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 6.857    Value Loss: 5.018    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 374170     Buffer Size: 18222      Transition Number: 1200.206k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:42:47,519][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 7.031    Value Loss: 4.892    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 376620     Buffer Size: 18331      Transition Number: 1200.073k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:45:32,648][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.216    [weighted Loss:3.216    Policy Loss: 7.440    Value Loss: 5.107    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 379130     Buffer Size: 18478      Transition Number: 1200.318k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:48:22,580][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.076    [weighted Loss:3.076    Policy Loss: 7.097    Value Loss: 5.134    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 381548     Buffer Size: 18732      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:51:08,466][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 7.425    Value Loss: 4.892    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 383944     Buffer Size: 19002      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:53:53,926][train][INFO][train.py>_log] ==> #67000      Total Loss: 4.324    [weighted Loss:4.324    Policy Loss: 7.270    Value Loss: 5.281    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 386439     Buffer Size: 19294      Transition Number: 1200.182k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:56:39,264][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.188    [weighted Loss:3.188    Policy Loss: 7.366    Value Loss: 4.865    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 388981     Buffer Size: 19615      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:59:28,877][train][INFO][train.py>_log] ==> #69000      Total Loss: 4.599    [weighted Loss:4.599    Policy Loss: 7.764    Value Loss: 5.456    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 391385     Buffer Size: 19699      Transition Number: 1200.863k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:02:13,802][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 7.436    Value Loss: 4.855    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 393866     Buffer Size: 19741      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:05:00,021][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.554    [weighted Loss:3.554    Policy Loss: 8.150    Value Loss: 4.949    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 396229     Buffer Size: 19773      Transition Number: 1200.340k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:07:44,925][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 7.923    Value Loss: 5.309    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 398675     Buffer Size: 19730      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:10:30,483][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.239    [weighted Loss:2.239    Policy Loss: 7.486    Value Loss: 5.223    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 401178     Buffer Size: 19694      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:13:21,129][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 7.562    Value Loss: 4.774    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 403727     Buffer Size: 19645      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:16:07,403][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.434    [weighted Loss:4.434    Policy Loss: 8.431    Value Loss: 5.248    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 406295     Buffer Size: 19550      Transition Number: 1200.296k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:18:53,759][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 7.881    Value Loss: 4.868    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 408758     Buffer Size: 19441      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:21:43,390][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.831    [weighted Loss:3.831    Policy Loss: 7.035    Value Loss: 5.001    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 411292     Buffer Size: 19371      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:24:29,682][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.161    [weighted Loss:4.161    Policy Loss: 7.231    Value Loss: 5.176    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 413797     Buffer Size: 19349      Transition Number: 1200.118k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:27:15,914][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 7.359    Value Loss: 4.967    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 416186     Buffer Size: 19363      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:30:02,479][train][INFO][train.py>_log] ==> #80000      Total Loss: 4.507    [weighted Loss:4.507    Policy Loss: 7.478    Value Loss: 4.992    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 418597     Buffer Size: 19371      Transition Number: 1200.151k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:32:52,183][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 6.914    Value Loss: 5.256    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 421182     Buffer Size: 19407      Transition Number: 1200.044k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:35:36,720][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.781    [weighted Loss:3.781    Policy Loss: 7.105    Value Loss: 5.055    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 423626     Buffer Size: 19417      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:38:21,976][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.719    [weighted Loss:2.719    Policy Loss: 7.786    Value Loss: 5.262    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 426202     Buffer Size: 19573      Transition Number: 1200.195k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:41:07,200][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.645    [weighted Loss:4.645    Policy Loss: 7.560    Value Loss: 5.465    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 428696     Buffer Size: 19767      Transition Number: 1200.117k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:43:53,163][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.881    [weighted Loss:2.881    Policy Loss: 6.903    Value Loss: 5.235    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 431170     Buffer Size: 19819      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:46:41,914][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 6.881    Value Loss: 5.243    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 433719     Buffer Size: 19866      Transition Number: 1200.414k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:49:27,832][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.197    [weighted Loss:4.197    Policy Loss: 7.153    Value Loss: 5.166    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 436222     Buffer Size: 19938      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:52:12,592][train][INFO][train.py>_log] ==> #88000      Total Loss: 3.927    [weighted Loss:3.927    Policy Loss: 6.672    Value Loss: 5.536    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 438595     Buffer Size: 20066      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:55:00,800][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 7.089    Value Loss: 5.392    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 441483     Buffer Size: 20426      Transition Number: 1200.180k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:57:46,006][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.407    [weighted Loss:3.407    Policy Loss: 6.545    Value Loss: 5.256    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 444242     Buffer Size: 20818      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:00:31,114][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.967    [weighted Loss:3.967    Policy Loss: 6.934    Value Loss: 5.503    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 446752     Buffer Size: 20847      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:03:16,949][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 6.563    Value Loss: 5.192    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 449352     Buffer Size: 20818      Transition Number: 1200.594k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:06:06,103][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 6.581    Value Loss: 5.612    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 451732     Buffer Size: 20749      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:08:51,286][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 5.826    Value Loss: 5.321    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 454135     Buffer Size: 20694      Transition Number: 1200.506k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:11:36,455][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 6.338    Value Loss: 5.187    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 456477     Buffer Size: 20649      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:14:21,392][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 6.199    Value Loss: 4.963    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 458861     Buffer Size: 20539      Transition Number: 1200.387k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:17:07,835][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 6.086    Value Loss: 5.307    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 461246     Buffer Size: 20090      Transition Number: 1200.364k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:19:58,156][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 5.966    Value Loss: 5.516    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 463766     Buffer Size: 19573      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:22:44,169][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 7.444    Value Loss: 5.124    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 466484     Buffer Size: 19605      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:25:29,851][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 6.814    Value Loss: 5.268    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 469130     Buffer Size: 19663      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:28:17,832][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.215    [weighted Loss:3.215    Policy Loss: 6.572    Value Loss: 5.278    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 471913     Buffer Size: 20022      Transition Number: 1200.053k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:31:03,489][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.568    Value Loss: 5.399    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 474576     Buffer Size: 20346      Transition Number: 1200.122k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:33:48,524][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.695    [weighted Loss:3.695    Policy Loss: 6.396    Value Loss: 5.151    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 477354     Buffer Size: 20754      Transition Number: 1200.058k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:36:34,654][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 6.329    Value Loss: 5.653    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 480129     Buffer Size: 21130      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:39:23,181][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 6.464    Value Loss: 5.476    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 482666     Buffer Size: 21350      Transition Number: 1200.176k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:42:08,804][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 5.856    Value Loss: 5.414    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 485090     Buffer Size: 21516      Transition Number: 1200.083k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:44:53,900][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.123    [weighted Loss:3.123    Policy Loss: 6.119    Value Loss: 6.015    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 487527     Buffer Size: 21417      Transition Number: 1200.114k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:47:38,247][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 6.057    Value Loss: 6.079    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 489884     Buffer Size: 21334      Transition Number: 1200.549k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:50:24,092][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.776    [weighted Loss:2.776    Policy Loss: 6.426    Value Loss: 5.082    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 492352     Buffer Size: 20992      Transition Number: 1200.032k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:53:14,034][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.864    [weighted Loss:2.864    Policy Loss: 5.915    Value Loss: 5.053    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 494739     Buffer Size: 20676      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:55:58,250][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 6.578    Value Loss: 5.178    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 497442     Buffer Size: 20600      Transition Number: 1200.675k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:58:42,917][train][INFO][train.py>_log] ==> #112000     Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 6.266    Value Loss: 5.385    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 500099     Buffer Size: 20537      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:01:30,908][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 6.829    Value Loss: 5.203    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 502629     Buffer Size: 20501      Transition Number: 1200.412k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:04:17,220][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 6.787    Value Loss: 5.192    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 505055     Buffer Size: 20507      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:07:03,441][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.393    [weighted Loss:3.393    Policy Loss: 6.545    Value Loss: 5.426    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 508398     Buffer Size: 21309      Transition Number: 1200.084k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:09:47,645][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 6.895    Value Loss: 5.295    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 511651     Buffer Size: 22085      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:12:37,581][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 6.325    Value Loss: 5.434    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 514415     Buffer Size: 22460      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:15:22,733][train][INFO][train.py>_log] ==> #118000     Total Loss: 4.688    [weighted Loss:4.688    Policy Loss: 7.139    Value Loss: 6.009    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 517135     Buffer Size: 22834      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:18:08,378][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 6.705    Value Loss: 5.768    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 519629     Buffer Size: 22766      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:20:54,053][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.159    [weighted Loss:2.159    Policy Loss: 6.581    Value Loss: 5.907    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 522123     Buffer Size: 22580      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:23:42,561][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 6.472    Value Loss: 5.789    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 524667     Buffer Size: 22570      Transition Number: 1200.180k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:26:28,290][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 6.525    Value Loss: 5.653    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 527154     Buffer Size: 22596      Transition Number: 1200.060k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:29:13,491][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 5.972    Value Loss: 5.423    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 529530     Buffer Size: 21969      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:31:59,544][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 5.990    Value Loss: 5.051    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 531997     Buffer Size: 21009      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:34:45,572][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.371    [weighted Loss:3.371    Policy Loss: 6.143    Value Loss: 5.249    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 534457     Buffer Size: 20614      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:37:32,731][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.436    [weighted Loss:4.436    Policy Loss: 7.089    Value Loss: 5.257    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 536921     Buffer Size: 20382      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:40:18,101][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 6.673    Value Loss: 5.411    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 539371     Buffer Size: 20318      Transition Number: 1200.246k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:43:03,510][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 6.653    Value Loss: 5.278    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 541870     Buffer Size: 20333      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:45:52,125][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 6.679    Value Loss: 5.444    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 544442     Buffer Size: 20371      Transition Number: 1199.936k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:48:37,968][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.514    Value Loss: 5.572    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 546979     Buffer Size: 20400      Transition Number: 1200.649k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:51:22,753][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 7.121    Value Loss: 5.364    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 549610     Buffer Size: 20598      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:54:07,867][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.876    [weighted Loss:2.876    Policy Loss: 6.608    Value Loss: 5.748    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 552204     Buffer Size: 20812      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:56:56,073][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.547    Value Loss: 5.790    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 554875     Buffer Size: 20997      Transition Number: 1200.257k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:59:40,567][train][INFO][train.py>_log] ==> #134000     Total Loss: 4.036    [weighted Loss:4.036    Policy Loss: 6.712    Value Loss: 5.997    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 557398     Buffer Size: 21096      Transition Number: 1200.240k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:02:24,630][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 6.721    Value Loss: 5.615    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 560234     Buffer Size: 21491      Transition Number: 1200.059k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:05:08,827][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 6.309    Value Loss: 5.650    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 563140     Buffer Size: 21934      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:07:54,154][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 6.138    Value Loss: 5.749    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 565624     Buffer Size: 21955      Transition Number: 1200.174k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:10:42,630][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 6.173    Value Loss: 5.919    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 568174     Buffer Size: 21920      Transition Number: 1200.212k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:13:27,471][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 6.469    Value Loss: 5.973    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 570593     Buffer Size: 21779      Transition Number: 1200.306k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:16:12,689][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.705    [weighted Loss:3.705    Policy Loss: 6.090    Value Loss: 5.456    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 573057     Buffer Size: 21614      Transition Number: 1200.041k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:19:01,847][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 6.705    Value Loss: 5.946    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 576098     Buffer Size: 21959      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:21:45,570][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 6.626    Value Loss: 5.723    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 579051     Buffer Size: 22400      Transition Number: 1200.327k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:24:30,714][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 5.521    Value Loss: 5.586    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 582073     Buffer Size: 22545      Transition Number: 1200.041k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:27:15,965][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.657    [weighted Loss:3.657    Policy Loss: 5.817    Value Loss: 6.093    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 585046     Buffer Size: 22495      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:30:04,259][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 5.819    Value Loss: 5.877    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 587599     Buffer Size: 22381      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:32:50,188][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.397    Value Loss: 5.942    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 590132     Buffer Size: 22352      Transition Number: 1200.471k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:35:35,468][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.597    [weighted Loss:2.597    Policy Loss: 6.070    Value Loss: 5.699    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 592575     Buffer Size: 22364      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:38:20,608][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.003    Value Loss: 5.497    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 595112     Buffer Size: 22382      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:41:06,177][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 6.785    Value Loss: 5.537    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 597640     Buffer Size: 21991      Transition Number: 1200.245k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:43:55,307][train][INFO][train.py>_log] ==> #150000     Total Loss: 4.048    [weighted Loss:4.048    Policy Loss: 6.445    Value Loss: 5.417    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 600151     Buffer Size: 21443      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:46:40,514][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.601    [weighted Loss:2.601    Policy Loss: 6.371    Value Loss: 5.566    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 602718     Buffer Size: 21049      Transition Number: 1200.394k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:49:25,394][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 5.873    Value Loss: 5.768    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 605274     Buffer Size: 20605      Transition Number: 1200.081k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:52:13,634][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 6.284    Value Loss: 5.785    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 608863     Buffer Size: 21422      Transition Number: 1200.125k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:54:59,571][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 5.727    Value Loss: 5.800    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 612333     Buffer Size: 22328      Transition Number: 1200.127k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:57:44,444][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.047    [weighted Loss:3.047    Policy Loss: 5.932    Value Loss: 6.122    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 614819     Buffer Size: 22381      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:00:30,187][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 5.834    Value Loss: 5.362    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 617329     Buffer Size: 22382      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:03:18,999][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 6.280    Value Loss: 5.484    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 620010     Buffer Size: 22406      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:06:04,201][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.548    [weighted Loss:3.548    Policy Loss: 6.655    Value Loss: 5.678    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 622513     Buffer Size: 22477      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:08:50,468][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 6.785    Value Loss: 5.633    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 625215     Buffer Size: 22456      Transition Number: 1200.219k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:11:35,822][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 6.639    Value Loss: 5.626    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 627903     Buffer Size: 22439      Transition Number: 1200.008k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:14:25,397][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 6.673    Value Loss: 5.854    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 630523     Buffer Size: 21477      Transition Number: 1200.028k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:17:10,762][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 6.809    Value Loss: 5.253    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 633111     Buffer Size: 20585      Transition Number: 1200.136k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:19:57,041][train][INFO][train.py>_log] ==> #163000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 6.181    Value Loss: 5.401    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 635727     Buffer Size: 20594      Transition Number: 1199.944k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:22:42,624][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 7.392    Value Loss: 5.526    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 638217     Buffer Size: 20649      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:25:30,495][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 6.557    Value Loss: 5.265    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 641072     Buffer Size: 20821      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:28:17,184][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.264    [weighted Loss:3.264    Policy Loss: 7.365    Value Loss: 5.633    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 643878     Buffer Size: 21016      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:31:02,862][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.611    [weighted Loss:2.611    Policy Loss: 6.363    Value Loss: 5.273    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 646389     Buffer Size: 20916      Transition Number: 1199.935k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:33:47,932][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.819    [weighted Loss:2.819    Policy Loss: 7.090    Value Loss: 5.259    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 648897     Buffer Size: 20847      Transition Number: 1200.170k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:36:38,737][train][INFO][train.py>_log] ==> #169000     Total Loss: 3.402    [weighted Loss:3.402    Policy Loss: 6.780    Value Loss: 5.320    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 651620     Buffer Size: 20896      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:39:24,433][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 6.036    Value Loss: 5.973    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 654304     Buffer Size: 20918      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:42:10,320][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 6.552    Value Loss: 5.233    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 656847     Buffer Size: 20937      Transition Number: 1200.301k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:44:55,932][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 6.722    Value Loss: 5.395    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 659458     Buffer Size: 20936      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:47:44,814][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 5.841    Value Loss: 5.369    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 662046     Buffer Size: 20602      Transition Number: 1200.046k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:50:31,842][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.046    [weighted Loss:3.046    Policy Loss: 6.119    Value Loss: 5.142    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 664556     Buffer Size: 20292      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:53:17,872][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 7.168    Value Loss: 4.921    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 667021     Buffer Size: 20233      Transition Number: 1200.171k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:56:02,344][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.220    [weighted Loss:1.220    Policy Loss: 6.785    Value Loss: 5.182    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 669526     Buffer Size: 20194      Transition Number: 1200.627k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:58:50,684][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 7.483    Value Loss: 5.328    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 672980     Buffer Size: 20921      Transition Number: 1200.269k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:01:37,762][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.662    [weighted Loss:3.662    Policy Loss: 6.670    Value Loss: 5.443    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 676414     Buffer Size: 21742      Transition Number: 1200.374k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:04:23,165][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 6.009    Value Loss: 5.911    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 679210     Buffer Size: 21889      Transition Number: 1200.220k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:07:08,619][train][INFO][train.py>_log] ==> #180000     Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 6.623    Value Loss: 5.718    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 681903     Buffer Size: 22005      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:09:58,680][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 6.005    Value Loss: 5.970    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 684549     Buffer Size: 22089      Transition Number: 1200.155k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:12:42,957][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 6.790    Value Loss: 5.882    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 687092     Buffer Size: 22169      Transition Number: 1200.364k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:15:27,970][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.344    [weighted Loss:3.344    Policy Loss: 6.603    Value Loss: 5.957    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 689873     Buffer Size: 22402      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:18:12,879][train][INFO][train.py>_log] ==> #184000     Total Loss: 4.229    [weighted Loss:4.229    Policy Loss: 6.882    Value Loss: 5.738    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 692547     Buffer Size: 22617      Transition Number: 1200.069k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:21:02,245][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 5.850    Value Loss: 5.808    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 695282     Buffer Size: 21881      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:23:47,934][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.751    [weighted Loss:3.751    Policy Loss: 6.844    Value Loss: 5.634    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 697958     Buffer Size: 21169      Transition Number: 1200.122k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:26:34,124][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.682    [weighted Loss:2.682    Policy Loss: 6.595    Value Loss: 5.410    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 700461     Buffer Size: 20986      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:29:19,582][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 6.036    Value Loss: 5.289    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 702952     Buffer Size: 20824      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:32:06,187][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 6.535    Value Loss: 5.417    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 705437     Buffer Size: 20799      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:34:53,212][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.958    [weighted Loss:3.958    Policy Loss: 6.949    Value Loss: 5.264    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 707895     Buffer Size: 20781      Transition Number: 1200.166k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:37:38,146][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 6.108    Value Loss: 5.530    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 710419     Buffer Size: 20666      Transition Number: 1200.194k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:40:22,763][train][INFO][train.py>_log] ==> #192000     Total Loss: 3.641    [weighted Loss:3.641    Policy Loss: 6.852    Value Loss: 5.395    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 713009     Buffer Size: 20495      Transition Number: 1200.095k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:43:10,945][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 6.734    Value Loss: 5.271    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 715682     Buffer Size: 20499      Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:45:56,247][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.309    [weighted Loss:3.309    Policy Loss: 6.571    Value Loss: 5.059    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 718330     Buffer Size: 20548      Transition Number: 1200.590k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:48:42,697][train][INFO][train.py>_log] ==> #195000     Total Loss: 3.623    [weighted Loss:3.623    Policy Loss: 6.332    Value Loss: 5.658    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 720860     Buffer Size: 20530      Transition Number: 1200.156k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:51:28,599][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.352    [weighted Loss:3.352    Policy Loss: 6.291    Value Loss: 5.017    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 723322     Buffer Size: 20557      Transition Number: 1200.238k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:54:17,592][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.922    [weighted Loss:2.922    Policy Loss: 7.722    Value Loss: 5.467    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 725848     Buffer Size: 20561      Transition Number: 1200.408k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:57:03,396][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 6.363    Value Loss: 5.436    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 728418     Buffer Size: 20583      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:59:48,891][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 6.289    Value Loss: 5.290    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 731150     Buffer Size: 20641      Transition Number: 1200.043k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:02:35,645][train][INFO][train.py>_log] ==> #200000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 6.781    Value Loss: 5.434    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 733836     Buffer Size: 20691      Transition Number: 1200.216k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:05:22,328][train][INFO][train.py>_log] ==> #201000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 7.411    Value Loss: 5.455    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 736427     Buffer Size: 20661      Transition Number: 1200.318k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:08:09,839][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.725    [weighted Loss:3.725    Policy Loss: 6.250    Value Loss: 5.498    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 739069     Buffer Size: 20608      Transition Number: 1200.233k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:10:55,081][train][INFO][train.py>_log] ==> #203000     Total Loss: 3.312    [weighted Loss:3.312    Policy Loss: 6.779    Value Loss: 5.607    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 741716     Buffer Size: 20746      Transition Number: 1200.167k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:13:40,640][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.352    [weighted Loss:3.352    Policy Loss: 6.218    Value Loss: 5.475    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 744378     Buffer Size: 20895      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:16:30,208][train][INFO][train.py>_log] ==> #205000     Total Loss: 3.442    [weighted Loss:3.442    Policy Loss: 6.278    Value Loss: 5.497    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 746925     Buffer Size: 20928      Transition Number: 1200.020k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:19:16,019][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 6.202    Value Loss: 5.169    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 749474     Buffer Size: 20908      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:22:02,438][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 6.175    Value Loss: 5.422    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 751942     Buffer Size: 20823      Transition Number: 1200.404k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:24:47,706][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 5.911    Value Loss: 4.934    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 754538     Buffer Size: 20661      Transition Number: 1200.046k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:27:37,079][train][INFO][train.py>_log] ==> #209000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 6.249    Value Loss: 5.742    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 757374     Buffer Size: 20871      Transition Number: 1200.272k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:30:22,631][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 5.577    Value Loss: 5.485    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 760166     Buffer Size: 21099      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:33:07,103][train][INFO][train.py>_log] ==> #211000     Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 6.425    Value Loss: 5.678    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 762837     Buffer Size: 21195      Transition Number: 1200.054k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:35:51,913][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 5.522    Value Loss: 5.579    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 765516     Buffer Size: 21277      Transition Number: 1200.369k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:38:38,680][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 6.550    Value Loss: 5.238    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 768068     Buffer Size: 21255      Transition Number: 1200.101k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:41:27,326][train][INFO][train.py>_log] ==> #214000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 6.271    Value Loss: 5.416    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 770572     Buffer Size: 21261      Transition Number: 1200.131k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:44:14,702][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 6.759    Value Loss: 5.540    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 773164     Buffer Size: 21264      Transition Number: 1200.082k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:47:00,078][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.872    [weighted Loss:2.872    Policy Loss: 6.496    Value Loss: 5.646    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 775618     Buffer Size: 21301      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:49:48,733][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 6.255    Value Loss: 5.530    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 778245     Buffer Size: 21102      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:52:34,168][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 6.945    Value Loss: 5.211    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 780848     Buffer Size: 20797      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:55:20,126][train][INFO][train.py>_log] ==> #219000     Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 7.312    Value Loss: 5.394    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 783543     Buffer Size: 20649      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:58:06,656][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 6.423    Value Loss: 5.316    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 786223     Buffer Size: 20464      Transition Number: 1200.227k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:00:56,061][train][INFO][train.py>_log] ==> #221000     Total Loss: 3.052    [weighted Loss:3.052    Policy Loss: 6.604    Value Loss: 5.012    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 788885     Buffer Size: 20500      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:03:41,769][train][INFO][train.py>_log] ==> #222000     Total Loss: 3.231    [weighted Loss:3.231    Policy Loss: 6.597    Value Loss: 5.124    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 791498     Buffer Size: 20552      Transition Number: 1200.191k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:06:26,997][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 6.331    Value Loss: 6.021    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 794052     Buffer Size: 20548      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:09:12,769][train][INFO][train.py>_log] ==> #224000     Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 6.712    Value Loss: 5.444    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 796613     Buffer Size: 20566      Transition Number: 1200.250k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:11:59,818][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 6.599    Value Loss: 5.470    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 799122     Buffer Size: 20499      Transition Number: 1200.288k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:14:47,795][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 6.580    Value Loss: 5.593    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 801688     Buffer Size: 20417      Transition Number: 1200.506k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:17:34,126][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.619    [weighted Loss:3.619    Policy Loss: 6.458    Value Loss: 5.703    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 804815     Buffer Size: 20912      Transition Number: 1200.354k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:20:18,570][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 6.622    Value Loss: 5.665    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 807937     Buffer Size: 21458      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:23:06,064][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 6.576    Value Loss: 5.718    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 810859     Buffer Size: 21768      Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:25:52,313][train][INFO][train.py>_log] ==> #230000     Total Loss: 3.300    [weighted Loss:3.300    Policy Loss: 6.428    Value Loss: 6.177    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 813728     Buffer Size: 22046      Transition Number: 1200.070k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:28:37,145][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.485    Value Loss: 5.993    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 816446     Buffer Size: 22229      Transition Number: 1200.124k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:31:21,914][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 6.423    Value Loss: 5.305    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 819182     Buffer Size: 22345      Transition Number: 1200.055k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:34:10,811][train][INFO][train.py>_log] ==> #233000     Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 6.892    Value Loss: 5.907    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 821759     Buffer Size: 22494      Transition Number: 1200.117k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:36:56,730][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 6.571    Value Loss: 5.447    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 824417     Buffer Size: 22625      Transition Number: 1200.344k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:39:42,312][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 6.856    Value Loss: 5.300    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 827008     Buffer Size: 22144      Transition Number: 1200.132k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:42:27,204][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 6.487    Value Loss: 5.607    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 829653     Buffer Size: 21655      Transition Number: 1200.474k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:45:13,754][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.219    Value Loss: 5.853    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 833414     Buffer Size: 22541      Transition Number: 1200.122k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:48:01,011][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.179    [weighted Loss:3.179    Policy Loss: 6.359    Value Loss: 6.157    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 837229     Buffer Size: 23477      Transition Number: 1200.260k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:50:47,488][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.772    [weighted Loss:2.772    Policy Loss: 6.293    Value Loss: 5.917    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 839973     Buffer Size: 23500      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:53:33,987][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 6.419    Value Loss: 6.118    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 842752     Buffer Size: 23590      Transition Number: 1200.579k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:56:23,749][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 6.789    Value Loss: 5.775    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 845329     Buffer Size: 23468      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:59:09,153][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 6.591    Value Loss: 5.548    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 847865     Buffer Size: 23368      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:01:55,966][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 6.195    Value Loss: 5.605    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 850384     Buffer Size: 23239      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:04:42,366][train][INFO][train.py>_log] ==> #244000     Total Loss: 3.632    [weighted Loss:3.632    Policy Loss: 6.617    Value Loss: 5.612    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 852980     Buffer Size: 23048      Transition Number: 1199.983k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:07:31,215][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 6.600    Value Loss: 5.305    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 855532     Buffer Size: 21735      Transition Number: 1200.217k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:10:17,248][train][INFO][train.py>_log] ==> #246000     Total Loss: 3.239    [weighted Loss:3.239    Policy Loss: 6.310    Value Loss: 5.444    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 858036     Buffer Size: 20545      Transition Number: 1200.388k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:13:03,181][train][INFO][train.py>_log] ==> #247000     Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 6.773    Value Loss: 5.359    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 860604     Buffer Size: 20279      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:15:49,322][train][INFO][train.py>_log] ==> #248000     Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 6.672    Value Loss: 4.992    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 863091     Buffer Size: 20048      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:18:37,123][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 6.369    Value Loss: 4.968    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 865720     Buffer Size: 20134      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:21:25,007][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 6.514    Value Loss: 5.683    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 868402     Buffer Size: 20218      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:24:11,264][train][INFO][train.py>_log] ==> #251000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 7.104    Value Loss: 5.281    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 870959     Buffer Size: 20265      Transition Number: 1200.376k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:26:57,593][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.786    [weighted Loss:2.786    Policy Loss: 6.585    Value Loss: 5.344    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 873519     Buffer Size: 20287      Transition Number: 1200.071k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:29:47,346][train][INFO][train.py>_log] ==> #253000     Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 6.511    Value Loss: 5.383    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 876029     Buffer Size: 20292      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:32:33,745][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 6.625    Value Loss: 5.059    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 878543     Buffer Size: 20242      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:35:19,591][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.747    [weighted Loss:2.747    Policy Loss: 7.404    Value Loss: 5.262    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 881116     Buffer Size: 20261      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:38:05,037][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 7.268    Value Loss: 4.964    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 883627     Buffer Size: 20283      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:40:54,238][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 6.912    Value Loss: 5.373    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 888069     Buffer Size: 22043      Transition Number: 1200.221k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:43:40,405][train][INFO][train.py>_log] ==> #258000     Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 7.023    Value Loss: 5.705    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 892549     Buffer Size: 23947      Transition Number: 1200.207k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:46:26,398][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 6.106    Value Loss: 6.043    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 895464     Buffer Size: 24364      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:49:13,354][train][INFO][train.py>_log] ==> #260000     Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 6.517    Value Loss: 5.449    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 898401     Buffer Size: 24778      Transition Number: 1200.203k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:51:58,704][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.744    [weighted Loss:2.744    Policy Loss: 6.309    Value Loss: 6.017    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 900959     Buffer Size: 24850      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:54:48,252][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 6.143    Value Loss: 5.261    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 903550     Buffer Size: 24920      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:57:34,052][train][INFO][train.py>_log] ==> #263000     Total Loss: 3.428    [weighted Loss:3.428    Policy Loss: 6.797    Value Loss: 5.634    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 906144     Buffer Size: 25024      Transition Number: 1200.220k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:00:20,495][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.432    [weighted Loss:3.432    Policy Loss: 6.949    Value Loss: 5.176    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 908770     Buffer Size: 25120      Transition Number: 1200.166k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:03:09,987][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 6.728    Value Loss: 5.200    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 911348     Buffer Size: 23124      Transition Number: 1200.181k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:05:56,154][train][INFO][train.py>_log] ==> #266000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 8.090    Value Loss: 5.413    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 913826     Buffer Size: 21099      Transition Number: 1200.243k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:08:42,272][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 7.064    Value Loss: 5.095    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 916359     Buffer Size: 20612      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:11:28,710][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 6.878    Value Loss: 5.532    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 918879     Buffer Size: 20208      Transition Number: 1200.072k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:14:18,117][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 6.929    Value Loss: 5.251    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 921545     Buffer Size: 20232      Transition Number: 1200.683k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:17:04,815][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 7.396    Value Loss: 5.093    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 924191     Buffer Size: 20234      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:19:49,524][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 7.359    Value Loss: 5.277    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 926927     Buffer Size: 20308      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:22:34,182][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 6.495    Value Loss: 5.262    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 929576     Buffer Size: 20416      Transition Number: 1200.219k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:25:21,739][train][INFO][train.py>_log] ==> #273000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 7.151    Value Loss: 5.221    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 932173     Buffer Size: 20428      Transition Number: 1200.250k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:28:12,033][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.581    [weighted Loss:3.581    Policy Loss: 6.921    Value Loss: 5.364    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 934820     Buffer Size: 20451      Transition Number: 1200.159k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:30:58,261][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 7.174    Value Loss: 5.487    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 937184     Buffer Size: 20360      Transition Number: 1200.396k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:33:42,894][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 7.302    Value Loss: 5.125    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 939638     Buffer Size: 20206      Transition Number: 1200.208k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:36:31,327][train][INFO][train.py>_log] ==> #277000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 7.383    Value Loss: 5.299    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 942228     Buffer Size: 20085      Transition Number: 1200.167k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:39:17,389][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 7.384    Value Loss: 5.112    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 944694     Buffer Size: 19975      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:42:03,219][train][INFO][train.py>_log] ==> #279000     Total Loss: 3.042    [weighted Loss:3.042    Policy Loss: 7.731    Value Loss: 5.012    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 947245     Buffer Size: 19742      Transition Number: 1200.145k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:44:48,645][train][INFO][train.py>_log] ==> #280000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 7.717    Value Loss: 5.311    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 949762     Buffer Size: 19572      Transition Number: 1200.274k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:47:37,694][train][INFO][train.py>_log] ==> #281000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 7.404    Value Loss: 5.244    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 952419     Buffer Size: 19700      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:50:23,689][train][INFO][train.py>_log] ==> #282000     Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 7.784    Value Loss: 5.278    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 955030     Buffer Size: 19836      Transition Number: 1200.143k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:53:09,540][train][INFO][train.py>_log] ==> #283000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 8.047    Value Loss: 5.289    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 957594     Buffer Size: 20072      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:55:54,896][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 8.331    Value Loss: 5.315    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 960207     Buffer Size: 20352      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:58:40,705][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 7.943    Value Loss: 5.138    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 962581     Buffer Size: 20328      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:01:29,718][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.144    [weighted Loss:3.144    Policy Loss: 8.273    Value Loss: 5.439    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 965173     Buffer Size: 20278      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:04:14,992][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 7.689    Value Loss: 4.998    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 967576     Buffer Size: 20173      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:07:01,586][train][INFO][train.py>_log] ==> #288000     Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 8.181    Value Loss: 5.116    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 970013     Buffer Size: 20077      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:09:51,774][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 7.813    Value Loss: 5.314    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 972565     Buffer Size: 19969      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:12:38,656][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 8.079    Value Loss: 5.300    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 975091     Buffer Size: 19854      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:15:23,680][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 7.759    Value Loss: 4.859    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 977488     Buffer Size: 19706      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:18:08,308][train][INFO][train.py>_log] ==> #292000     Total Loss: 3.866    [weighted Loss:3.866    Policy Loss: 8.238    Value Loss: 4.544    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 979919     Buffer Size: 19498      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:20:57,147][train][INFO][train.py>_log] ==> #293000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 7.846    Value Loss: 4.980    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 982390     Buffer Size: 19412      Transition Number: 1200.212k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:23:43,287][train][INFO][train.py>_log] ==> #294000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 7.700    Value Loss: 5.352    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 984821     Buffer Size: 19315      Transition Number: 1200.238k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:26:31,416][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 7.935    Value Loss: 5.082    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 987373     Buffer Size: 19309      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:29:17,466][train][INFO][train.py>_log] ==> #296000     Total Loss: 3.051    [weighted Loss:3.051    Policy Loss: 8.050    Value Loss: 5.031    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 989923     Buffer Size: 19310      Transition Number: 1200.325k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:32:08,112][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.076    [weighted Loss:3.076    Policy Loss: 7.675    Value Loss: 4.808    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 992463     Buffer Size: 19229      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:34:55,316][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 7.547    Value Loss: 4.806    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 995008     Buffer Size: 19163      Transition Number: 1200.101k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:37:42,111][train][INFO][train.py>_log] ==> #299000     Total Loss: 3.682    [weighted Loss:3.682    Policy Loss: 8.168    Value Loss: 5.236    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 997587     Buffer Size: 19132      Transition Number: 1200.322k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:40:28,348][train][INFO][train.py>_log] ==> #300000     Total Loss: 3.174    [weighted Loss:3.174    Policy Loss: 7.727    Value Loss: 5.002    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000082    Buffer Size: 19126      Transition Number: 1200.139k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:43:16,508][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 7.384    Value Loss: 5.280    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002723    Buffer Size: 19335      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:46:02,960][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 8.313    Value Loss: 5.153    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1005243    Buffer Size: 19523      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:48:48,745][train][INFO][train.py>_log] ==> #303000     Total Loss: 3.727    [weighted Loss:3.727    Policy Loss: 8.223    Value Loss: 5.563    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1007738    Buffer Size: 19600      Transition Number: 1200.539k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:51:33,674][train][INFO][train.py>_log] ==> #304000     Total Loss: 3.289    [weighted Loss:3.289    Policy Loss: 7.735    Value Loss: 5.256    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1010125    Buffer Size: 19606      Transition Number: 1200.003k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:54:23,158][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 8.066    Value Loss: 5.390    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1012589    Buffer Size: 19629      Transition Number: 1200.078k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:57:08,287][train][INFO][train.py>_log] ==> #306000     Total Loss: 3.871    [weighted Loss:3.871    Policy Loss: 8.074    Value Loss: 4.938    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1014972    Buffer Size: 19659      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:59:53,556][train][INFO][train.py>_log] ==> #307000     Total Loss: 4.180    [weighted Loss:4.180    Policy Loss: 7.528    Value Loss: 5.087    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 1017520    Buffer Size: 19777      Transition Number: 1200.405k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:02:38,751][train][INFO][train.py>_log] ==> #308000     Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 7.755    Value Loss: 4.761    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1020044    Buffer Size: 19878      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:05:28,095][train][INFO][train.py>_log] ==> #309000     Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 8.060    Value Loss: 5.505    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 1022907    Buffer Size: 20149      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:08:12,972][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.412    [weighted Loss:3.412    Policy Loss: 7.728    Value Loss: 5.784    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025747    Buffer Size: 20383      Transition Number: 1200.256k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:10:58,759][train][INFO][train.py>_log] ==> #311000     Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 7.561    Value Loss: 5.782    Reward Loss: 1.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 1028300    Buffer Size: 20521      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:13:44,202][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 7.804    Value Loss: 5.565    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030854    Buffer Size: 20671      Transition Number: 1200.008k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:16:30,798][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.601    [weighted Loss:3.601    Policy Loss: 7.839    Value Loss: 5.665    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1033287    Buffer Size: 20657      Transition Number: 1200.134k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:19:18,045][train][INFO][train.py>_log] ==> #314000     Total Loss: 3.863    [weighted Loss:3.863    Policy Loss: 7.445    Value Loss: 5.631    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035776    Buffer Size: 20642      Transition Number: 1200.374k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:22:03,194][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.065    [weighted Loss:1.065    Policy Loss: 7.241    Value Loss: 5.448    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1038293    Buffer Size: 20584      Transition Number: 1200.107k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:24:49,284][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 7.300    Value Loss: 5.368    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1040806    Buffer Size: 20527      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:27:40,031][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 7.877    Value Loss: 5.363    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043278    Buffer Size: 20113      Transition Number: 1200.614k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:30:25,696][train][INFO][train.py>_log] ==> #318000     Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 7.524    Value Loss: 5.275    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1045700    Buffer Size: 19724      Transition Number: 1200.342k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:33:11,673][train][INFO][train.py>_log] ==> #319000     Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 8.018    Value Loss: 4.933    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048337    Buffer Size: 19611      Transition Number: 1200.111k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:35:57,785][train][INFO][train.py>_log] ==> #320000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 7.472    Value Loss: 5.097    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1050790    Buffer Size: 19543      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:38:47,116][train][INFO][train.py>_log] ==> #321000     Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 8.127    Value Loss: 5.163    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 1053491    Buffer Size: 19696      Transition Number: 1200.138k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:41:33,000][train][INFO][train.py>_log] ==> #322000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 7.567    Value Loss: 5.035    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 1056076    Buffer Size: 19864      Transition Number: 1200.405k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:44:18,733][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 7.721    Value Loss: 5.150    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1058743    Buffer Size: 19930      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:47:04,953][train][INFO][train.py>_log] ==> #324000     Total Loss: 3.134    [weighted Loss:3.134    Policy Loss: 7.533    Value Loss: 5.362    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 1061343    Buffer Size: 20019      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:49:54,662][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 7.457    Value Loss: 5.374    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063901    Buffer Size: 20097      Transition Number: 1200.158k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:52:45,318][train][INFO][train.py>_log] ==> #326000     Total Loss: 3.110    [weighted Loss:3.110    Policy Loss: 7.257    Value Loss: 5.050    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1066522    Buffer Size: 20116      Transition Number: 1200.158k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:55:32,334][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 7.084    Value Loss: 5.197    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069086    Buffer Size: 20124      Transition Number: 1200.248k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:58:19,444][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 7.437    Value Loss: 5.525    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1071679    Buffer Size: 20173      Transition Number: 1200.155k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:01:08,998][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 6.805    Value Loss: 4.978    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1074359    Buffer Size: 20102      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:03:57,111][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 7.590    Value Loss: 5.016    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076862    Buffer Size: 20066      Transition Number: 1200.224k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:06:43,486][train][INFO][train.py>_log] ==> #331000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.880    Value Loss: 5.442    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1079348    Buffer Size: 19989      Transition Number: 1200.147k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:09:31,114][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 7.352    Value Loss: 5.134    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1081915    Buffer Size: 19911      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:12:22,232][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 6.948    Value Loss: 4.972    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1084353    Buffer Size: 19872      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:15:08,578][train][INFO][train.py>_log] ==> #334000     Total Loss: 3.110    [weighted Loss:3.110    Policy Loss: 7.177    Value Loss: 5.491    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1086880    Buffer Size: 19835      Transition Number: 1200.392k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:17:54,635][train][INFO][train.py>_log] ==> #335000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 6.883    Value Loss: 5.674    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089762    Buffer Size: 20068      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:20:40,137][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.585    [weighted Loss:3.585    Policy Loss: 7.212    Value Loss: 5.653    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092566    Buffer Size: 20294      Transition Number: 1200.120k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:23:28,148][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 7.018    Value Loss: 5.812    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1095161    Buffer Size: 20354      Transition Number: 1200.063k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:26:17,482][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 7.187    Value Loss: 5.602    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1097760    Buffer Size: 20412      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:29:03,059][train][INFO][train.py>_log] ==> #339000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 7.055    Value Loss: 5.693    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100471    Buffer Size: 20568      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:31:50,423][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.990    [weighted Loss:2.990    Policy Loss: 6.711    Value Loss: 5.763    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103197    Buffer Size: 20772      Transition Number: 1200.136k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:34:39,733][train][INFO][train.py>_log] ==> #341000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 7.335    Value Loss: 5.634    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1105823    Buffer Size: 20887      Transition Number: 1200.353k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:37:25,768][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 6.878    Value Loss: 5.590    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1108333    Buffer Size: 20935      Transition Number: 1200.193k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:40:12,731][train][INFO][train.py>_log] ==> #343000     Total Loss: 3.999    [weighted Loss:3.999    Policy Loss: 7.622    Value Loss: 4.976    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111077    Buffer Size: 20838      Transition Number: 1200.061k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:43:00,050][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 7.328    Value Loss: 5.340    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113728    Buffer Size: 20753      Transition Number: 1200.085k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:45:49,224][train][INFO][train.py>_log] ==> #345000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 6.942    Value Loss: 5.628    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 1116438    Buffer Size: 20750      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:48:34,620][train][INFO][train.py>_log] ==> #346000     Total Loss: 3.920    [weighted Loss:3.920    Policy Loss: 7.323    Value Loss: 5.174    Reward Loss: 1.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 1118936    Buffer Size: 20750      Transition Number: 1200.054k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:51:20,156][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.926    [weighted Loss:2.926    Policy Loss: 7.318    Value Loss: 5.547    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1121340    Buffer Size: 20555      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:54:06,955][train][INFO][train.py>_log] ==> #348000     Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 6.775    Value Loss: 5.116    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1123889    Buffer Size: 20360      Transition Number: 1200.571k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:56:54,530][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.157    [weighted Loss:3.157    Policy Loss: 7.005    Value Loss: 5.252    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126381    Buffer Size: 20298      Transition Number: 1200.305k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:59:42,424][train][INFO][train.py>_log] ==> #350000     Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 7.413    Value Loss: 5.158    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128886    Buffer Size: 20235      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:02:29,331][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.127    [weighted Loss:3.127    Policy Loss: 7.387    Value Loss: 4.880    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1131441    Buffer Size: 19953      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:05:16,150][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 6.854    Value Loss: 5.045    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133886    Buffer Size: 19721      Transition Number: 1200.014k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:08:06,257][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.448    [weighted Loss:2.448    Policy Loss: 7.675    Value Loss: 5.159    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1136869    Buffer Size: 20025      Transition Number: 1200.286k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:10:50,987][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 7.388    Value Loss: 5.464    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139717    Buffer Size: 20344      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:13:37,158][train][INFO][train.py>_log] ==> #355000     Total Loss: 3.137    [weighted Loss:3.137    Policy Loss: 7.411    Value Loss: 5.676    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1142305    Buffer Size: 20457      Transition Number: 1200.215k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:16:25,344][train][INFO][train.py>_log] ==> #356000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 7.132    Value Loss: 5.222    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144841    Buffer Size: 20538      Transition Number: 1200.077k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:19:14,859][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.553    [weighted Loss:3.553    Policy Loss: 7.706    Value Loss: 5.291    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147382    Buffer Size: 20459      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:22:01,765][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 7.520    Value Loss: 5.294    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1149898    Buffer Size: 20377      Transition Number: 1200.056k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:24:47,542][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 7.390    Value Loss: 5.301    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152398    Buffer Size: 20395      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:27:33,048][train][INFO][train.py>_log] ==> #360000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 7.704    Value Loss: 5.414    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1154861    Buffer Size: 20332      Transition Number: 1200.116k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:30:21,332][train][INFO][train.py>_log] ==> #361000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 6.947    Value Loss: 5.474    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1157339    Buffer Size: 19829      Transition Number: 1200.214k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:33:09,410][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 7.397    Value Loss: 4.858    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 1159751    Buffer Size: 19400      Transition Number: 1200.073k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:35:55,390][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.150    [weighted Loss:3.150    Policy Loss: 7.601    Value Loss: 4.732    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1162269    Buffer Size: 19266      Transition Number: 1200.047k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:38:40,949][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.462    [weighted Loss:2.462    Policy Loss: 7.105    Value Loss: 4.800    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1164821    Buffer Size: 19190      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:41:30,057][train][INFO][train.py>_log] ==> #365000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 7.085    Value Loss: 4.840    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1167399    Buffer Size: 19248      Transition Number: 1200.208k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:44:16,825][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 7.625    Value Loss: 4.722    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1169887    Buffer Size: 19269      Transition Number: 1200.153k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:47:03,797][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 6.510    Value Loss: 4.809    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1172499    Buffer Size: 19272      Transition Number: 1200.151k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:49:50,014][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.322    [weighted Loss:3.322    Policy Loss: 7.092    Value Loss: 4.794    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1175058    Buffer Size: 19307      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:52:39,422][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 7.192    Value Loss: 4.995    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1177641    Buffer Size: 19406      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:55:25,603][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.832    [weighted Loss:2.832    Policy Loss: 7.695    Value Loss: 5.057    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1180209    Buffer Size: 19505      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:58:11,792][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.614    [weighted Loss:2.614    Policy Loss: 6.739    Value Loss: 5.398    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1182818    Buffer Size: 19624      Transition Number: 1200.415k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:00:56,895][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.584    [weighted Loss:2.584    Policy Loss: 6.985    Value Loss: 4.766    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1185361    Buffer Size: 19745      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:03:44,715][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.903    [weighted Loss:2.903    Policy Loss: 7.230    Value Loss: 5.123    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1187894    Buffer Size: 19864      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:06:31,354][train][INFO][train.py>_log] ==> #374000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 7.103    Value Loss: 5.545    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1190385    Buffer Size: 19968      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:09:17,799][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.847    [weighted Loss:2.847    Policy Loss: 7.384    Value Loss: 5.160    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1192925    Buffer Size: 20071      Transition Number: 1200.213k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:12:03,177][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 7.248    Value Loss: 5.427    Reward Loss: 1.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 1195473    Buffer Size: 20187      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:14:53,357][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 7.157    Value Loss: 5.283    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1198007    Buffer Size: 20220      Transition Number: 1200.006k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:17:40,272][train][INFO][train.py>_log] ==> #378000     Total Loss: 3.101    [weighted Loss:3.101    Policy Loss: 7.498    Value Loss: 5.665    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1200650    Buffer Size: 20269      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:20:25,773][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 6.907    Value Loss: 5.343    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1203084    Buffer Size: 20322      Transition Number: 1200.120k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:23:12,840][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 7.108    Value Loss: 5.137    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1205643    Buffer Size: 20347      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:26:01,603][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 6.862    Value Loss: 4.956    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1208127    Buffer Size: 20279      Transition Number: 1200.596k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:28:49,157][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.995    [weighted Loss:2.995    Policy Loss: 6.763    Value Loss: 5.498    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1210654    Buffer Size: 20202      Transition Number: 1200.295k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:31:35,143][train][INFO][train.py>_log] ==> #383000     Total Loss: 3.014    [weighted Loss:3.014    Policy Loss: 6.771    Value Loss: 5.160    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 1213152    Buffer Size: 20094      Transition Number: 1200.188k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:34:21,491][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 6.322    Value Loss: 5.198    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1215638    Buffer Size: 19961      Transition Number: 1200.020k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:37:10,450][train][INFO][train.py>_log] ==> #385000     Total Loss: 3.235    [weighted Loss:3.235    Policy Loss: 6.641    Value Loss: 5.240    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218157    Buffer Size: 19897      Transition Number: 1200.110k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:39:57,408][train][INFO][train.py>_log] ==> #386000     Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 6.851    Value Loss: 5.020    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 1220662    Buffer Size: 19818      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:42:43,179][train][INFO][train.py>_log] ==> #387000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 6.471    Value Loss: 5.577    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223190    Buffer Size: 19675      Transition Number: 1200.079k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:45:29,090][train][INFO][train.py>_log] ==> #388000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 6.915    Value Loss: 4.978    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225669    Buffer Size: 19535      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:48:19,233][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 6.928    Value Loss: 5.058    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1228457    Buffer Size: 19784      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:51:06,061][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 6.340    Value Loss: 5.404    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1231354    Buffer Size: 20093      Transition Number: 1200.123k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:53:55,841][train][INFO][train.py>_log] ==> #391000     Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 6.995    Value Loss: 4.948    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1233983    Buffer Size: 20192      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:56:42,268][train][INFO][train.py>_log] ==> #392000     Total Loss: 2.405    [weighted Loss:2.405    Policy Loss: 6.668    Value Loss: 5.285    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236571    Buffer Size: 20288      Transition Number: 1200.400k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:59:30,476][train][INFO][train.py>_log] ==> #393000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 6.611    Value Loss: 4.997    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1239253    Buffer Size: 20461      Transition Number: 1200.071k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:02:18,045][train][INFO][train.py>_log] ==> #394000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 7.072    Value Loss: 5.177    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241936    Buffer Size: 20629      Transition Number: 1200.206k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:05:04,625][train][INFO][train.py>_log] ==> #395000     Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 6.827    Value Loss: 5.615    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1244534    Buffer Size: 20697      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:07:51,543][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 6.311    Value Loss: 5.342    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 1247144    Buffer Size: 20697      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:10:42,136][train][INFO][train.py>_log] ==> #397000     Total Loss: 3.284    [weighted Loss:3.284    Policy Loss: 7.581    Value Loss: 5.656    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1249582    Buffer Size: 20414      Transition Number: 1200.039k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:13:29,452][train][INFO][train.py>_log] ==> #398000     Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 6.644    Value Loss: 5.256    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252031    Buffer Size: 20110      Transition Number: 1200.145k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:16:17,235][train][INFO][train.py>_log] ==> #399000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 7.089    Value Loss: 5.710    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1254802    Buffer Size: 20177      Transition Number: 1200.102k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:19:04,345][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.867    [weighted Loss:2.867    Policy Loss: 6.670    Value Loss: 5.306    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1257441    Buffer Size: 20255      Transition Number: 1200.121k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:21:54,518][train][INFO][train.py>_log] ==> #401000     Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 6.469    Value Loss: 5.620    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1260506    Buffer Size: 20510      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:24:40,628][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 6.654    Value Loss: 5.707    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1263501    Buffer Size: 20765      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:27:29,411][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 6.574    Value Loss: 5.693    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266159    Buffer Size: 20871      Transition Number: 1200.076k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:30:15,365][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 6.689    Value Loss: 5.483    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1268807    Buffer Size: 20966      Transition Number: 1200.031k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:33:02,458][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 7.094    Value Loss: 5.693    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 1271384    Buffer Size: 21003      Transition Number: 1200.144k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:35:51,958][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 6.536    Value Loss: 5.803    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1273925    Buffer Size: 21013      Transition Number: 1200.341k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:38:37,263][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 6.142    Value Loss: 5.573    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1276523    Buffer Size: 20909      Transition Number: 1200.014k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:41:24,418][train][INFO][train.py>_log] ==> #408000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 6.962    Value Loss: 5.157    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1279145    Buffer Size: 20753      Transition Number: 1200.764k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:44:13,461][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.813    [weighted Loss:2.813    Policy Loss: 6.838    Value Loss: 5.075    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1281773    Buffer Size: 20424      Transition Number: 1200.253k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:47:00,264][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.854    [weighted Loss:2.854    Policy Loss: 6.560    Value Loss: 5.448    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 1284330    Buffer Size: 20191      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:49:48,459][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 6.734    Value Loss: 5.108    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1286876    Buffer Size: 20029      Transition Number: 1200.239k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:52:35,528][train][INFO][train.py>_log] ==> #412000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 6.778    Value Loss: 5.207    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1289370    Buffer Size: 19885      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:55:24,577][train][INFO][train.py>_log] ==> #413000     Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 6.418    Value Loss: 5.139    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1291859    Buffer Size: 19788      Transition Number: 1200.183k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:58:12,612][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.961    [weighted Loss:2.961    Policy Loss: 6.630    Value Loss: 4.969    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 1294438    Buffer Size: 19677      Transition Number: 1200.184k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:01:00,211][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.958    [weighted Loss:2.958    Policy Loss: 6.695    Value Loss: 5.693    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1297090    Buffer Size: 19631      Transition Number: 1200.001k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:03:47,424][train][INFO][train.py>_log] ==> #416000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 6.511    Value Loss: 5.429    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299682    Buffer Size: 19598      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:06:33,954][train][INFO][train.py>_log] ==> #417000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 6.356    Value Loss: 4.912    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1302285    Buffer Size: 19524      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:09:23,554][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 6.785    Value Loss: 4.968    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304859    Buffer Size: 19506      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:12:13,390][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 7.333    Value Loss: 5.497    Reward Loss: 1.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 1307478    Buffer Size: 19522      Transition Number: 1200.243k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:15:02,085][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 7.174    Value Loss: 5.111    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1309997    Buffer Size: 19584      Transition Number: 1200.068k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:17:50,120][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.701    [weighted Loss:2.701    Policy Loss: 6.693    Value Loss: 5.315    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1312474    Buffer Size: 19692      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:20:37,164][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 6.893    Value Loss: 4.930    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 1315052    Buffer Size: 19745      Transition Number: 1200.051k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:23:25,226][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 7.340    Value Loss: 5.184    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1317603    Buffer Size: 19657      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:26:10,544][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 6.775    Value Loss: 5.365    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1320052    Buffer Size: 19581      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:29:00,863][train][INFO][train.py>_log] ==> #425000     Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 6.946    Value Loss: 5.692    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 1322604    Buffer Size: 19522      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:31:48,164][train][INFO][train.py>_log] ==> #426000     Total Loss: 3.582    [weighted Loss:3.582    Policy Loss: 6.942    Value Loss: 4.997    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1325148    Buffer Size: 19466      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:34:35,434][train][INFO][train.py>_log] ==> #427000     Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 7.202    Value Loss: 5.003    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1327633    Buffer Size: 19442      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:37:22,582][train][INFO][train.py>_log] ==> #428000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 7.131    Value Loss: 5.326    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 1330137    Buffer Size: 19420      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:40:08,307][train][INFO][train.py>_log] ==> #429000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 6.999    Value Loss: 5.096    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332652    Buffer Size: 19339      Transition Number: 1200.689k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:42:57,865][train][INFO][train.py>_log] ==> #430000     Total Loss: 2.955    [weighted Loss:2.955    Policy Loss: 7.327    Value Loss: 4.922    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1335193    Buffer Size: 19251      Transition Number: 1200.244k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:45:46,950][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 6.577    Value Loss: 5.279    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1337760    Buffer Size: 19190      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:48:34,356][train][INFO][train.py>_log] ==> #432000     Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 6.750    Value Loss: 5.240    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1340291    Buffer Size: 19137      Transition Number: 1200.389k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:51:27,231][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 7.117    Value Loss: 5.130    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1342844    Buffer Size: 19077      Transition Number: 1200.088k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:54:12,701][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 7.082    Value Loss: 5.219    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1345276    Buffer Size: 19039      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:57:01,629][train][INFO][train.py>_log] ==> #435000     Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 6.584    Value Loss: 5.084    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 1347792    Buffer Size: 19002      Transition Number: 1200.377k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:59:48,044][train][INFO][train.py>_log] ==> #436000     Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 6.963    Value Loss: 5.204    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350259    Buffer Size: 18955      Transition Number: 1200.186k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:02:37,105][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 7.074    Value Loss: 4.876    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 1352813    Buffer Size: 18953      Transition Number: 1200.253k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:05:26,031][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 6.673    Value Loss: 4.959    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1355308    Buffer Size: 18937      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:08:13,310][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 7.066    Value Loss: 5.231    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1357790    Buffer Size: 18983      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:11:02,892][train][INFO][train.py>_log] ==> #440000     Total Loss: 3.082    [weighted Loss:3.082    Policy Loss: 6.384    Value Loss: 4.873    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 1360277    Buffer Size: 19035      Transition Number: 1200.056k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:13:53,650][train][INFO][train.py>_log] ==> #441000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 6.927    Value Loss: 5.301    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1362865    Buffer Size: 19113      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:16:45,511][train][INFO][train.py>_log] ==> #442000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 7.289    Value Loss: 5.189    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1365431    Buffer Size: 19210      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:19:33,414][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.198    [weighted Loss:3.198    Policy Loss: 7.758    Value Loss: 4.914    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1367911    Buffer Size: 19220      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:22:22,040][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 6.920    Value Loss: 4.715    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370498    Buffer Size: 19221      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:25:12,164][train][INFO][train.py>_log] ==> #445000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 7.282    Value Loss: 5.301    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373029    Buffer Size: 19151      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:28:01,053][train][INFO][train.py>_log] ==> #446000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 6.853    Value Loss: 5.208    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375496    Buffer Size: 19070      Transition Number: 1200.069k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:30:47,964][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.165    [weighted Loss:3.165    Policy Loss: 6.890    Value Loss: 5.061    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 1378024    Buffer Size: 19102      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:33:35,477][train][INFO][train.py>_log] ==> #448000     Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 7.582    Value Loss: 5.410    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 1380599    Buffer Size: 19135      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:36:25,770][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.566    [weighted Loss:2.566    Policy Loss: 7.452    Value Loss: 4.982    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1383042    Buffer Size: 19073      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:39:12,445][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 6.932    Value Loss: 5.359    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1385718    Buffer Size: 19042      Transition Number: 1200.230k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:41:58,770][train][INFO][train.py>_log] ==> #451000     Total Loss: 2.352    [weighted Loss:2.352    Policy Loss: 7.023    Value Loss: 4.710    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1388251    Buffer Size: 19047      Transition Number: 1200.129k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:44:46,882][train][INFO][train.py>_log] ==> #452000     Total Loss: 2.856    [weighted Loss:2.856    Policy Loss: 6.963    Value Loss: 4.933    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 1390765    Buffer Size: 19077      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:47:38,360][train][INFO][train.py>_log] ==> #453000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 6.755    Value Loss: 4.775    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1393355    Buffer Size: 19149      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:50:28,850][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 6.745    Value Loss: 4.705    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 1395922    Buffer Size: 19155      Transition Number: 1200.398k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:53:16,512][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 7.904    Value Loss: 5.026    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 1398493    Buffer Size: 19089      Transition Number: 1200.101k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:56:02,901][train][INFO][train.py>_log] ==> #456000     Total Loss: 3.890    [weighted Loss:3.890    Policy Loss: 7.563    Value Loss: 4.791    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1401142    Buffer Size: 19047      Transition Number: 1200.100k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:58:52,541][train][INFO][train.py>_log] ==> #457000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 7.335    Value Loss: 4.815    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1403912    Buffer Size: 19369      Transition Number: 1200.380k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:01:38,395][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 7.747    Value Loss: 5.180    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406762    Buffer Size: 19691      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:04:24,211][train][INFO][train.py>_log] ==> #459000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 8.130    Value Loss: 5.469    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1409340    Buffer Size: 19883      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:07:10,394][train][INFO][train.py>_log] ==> #460000     Total Loss: 2.683    [weighted Loss:2.683    Policy Loss: 7.573    Value Loss: 5.603    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411958    Buffer Size: 20034      Transition Number: 1200.211k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:09:59,931][train][INFO][train.py>_log] ==> #461000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 7.039    Value Loss: 5.618    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1414681    Buffer Size: 20184      Transition Number: 1200.062k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:12:46,464][train][INFO][train.py>_log] ==> #462000     Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 7.165    Value Loss: 5.243    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1417372    Buffer Size: 20322      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:15:32,904][train][INFO][train.py>_log] ==> #463000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 6.821    Value Loss: 5.216    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1419934    Buffer Size: 20434      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:18:20,195][train][INFO][train.py>_log] ==> #464000     Total Loss: 3.951    [weighted Loss:3.951    Policy Loss: 6.433    Value Loss: 5.454    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1422505    Buffer Size: 20443      Transition Number: 1199.959k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:21:11,345][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.571    [weighted Loss:3.571    Policy Loss: 7.073    Value Loss: 5.187    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424991    Buffer Size: 20110      Transition Number: 1200.225k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:24:01,046][train][INFO][train.py>_log] ==> #466000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 6.662    Value Loss: 5.206    Reward Loss: 1.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 1427579    Buffer Size: 19785      Transition Number: 1200.244k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:26:50,668][train][INFO][train.py>_log] ==> #467000     Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 6.448    Value Loss: 5.038    Reward Loss: 1.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 1430204    Buffer Size: 19642      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:29:37,252][train][INFO][train.py>_log] ==> #468000     Total Loss: 1.389    [weighted Loss:1.389    Policy Loss: 7.072    Value Loss: 4.843    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1432680    Buffer Size: 19504      Transition Number: 1200.157k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:32:27,842][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 6.926    Value Loss: 5.017    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435266    Buffer Size: 19318      Transition Number: 1200.142k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:35:17,170][train][INFO][train.py>_log] ==> #470000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 6.649    Value Loss: 4.932    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 1437861    Buffer Size: 19157      Transition Number: 1200.309k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:38:06,749][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 6.980    Value Loss: 5.009    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440665    Buffer Size: 19277      Transition Number: 1200.622k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:40:54,730][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 7.801    Value Loss: 5.218    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 1443422    Buffer Size: 19415      Transition Number: 1200.386k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:43:46,058][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 6.647    Value Loss: 5.098    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1446206    Buffer Size: 19622      Transition Number: 1200.310k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:46:37,257][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 6.640    Value Loss: 5.224    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 1448982    Buffer Size: 19794      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:49:24,573][train][INFO][train.py>_log] ==> #475000     Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 6.901    Value Loss: 5.327    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451661    Buffer Size: 19891      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:52:12,982][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 6.769    Value Loss: 5.494    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1454267    Buffer Size: 20004      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:55:03,573][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 6.607    Value Loss: 5.315    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1456829    Buffer Size: 20019      Transition Number: 1200.406k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:57:49,901][train][INFO][train.py>_log] ==> #478000     Total Loss: 1.779    [weighted Loss:1.779    Policy Loss: 7.022    Value Loss: 4.958    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 1459365    Buffer Size: 19859      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:00:37,174][train][INFO][train.py>_log] ==> #479000     Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 7.036    Value Loss: 5.219    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1461965    Buffer Size: 19709      Transition Number: 1200.325k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:03:25,871][train][INFO][train.py>_log] ==> #480000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 6.900    Value Loss: 5.105    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1464589    Buffer Size: 19570      Transition Number: 1200.114k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:06:16,227][train][INFO][train.py>_log] ==> #481000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 7.193    Value Loss: 5.164    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1467207    Buffer Size: 19494      Transition Number: 1200.587k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:09:03,162][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 7.113    Value Loss: 5.215    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1469770    Buffer Size: 19454      Transition Number: 1200.500k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:11:48,971][train][INFO][train.py>_log] ==> #483000     Total Loss: 2.708    [weighted Loss:2.708    Policy Loss: 7.127    Value Loss: 4.792    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1472348    Buffer Size: 19452      Transition Number: 1200.275k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:14:36,285][train][INFO][train.py>_log] ==> #484000     Total Loss: 3.312    [weighted Loss:3.312    Policy Loss: 7.417    Value Loss: 5.443    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1474914    Buffer Size: 19540      Transition Number: 1200.187k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:17:24,540][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 7.680    Value Loss: 5.411    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1477689    Buffer Size: 19745      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:20:13,512][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 7.489    Value Loss: 5.514    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1480433    Buffer Size: 19931      Transition Number: 1200.163k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:23:02,516][train][INFO][train.py>_log] ==> #487000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 7.504    Value Loss: 5.286    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1482979    Buffer Size: 19915      Transition Number: 1200.367k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:25:51,456][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 6.941    Value Loss: 5.119    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485516    Buffer Size: 19849      Transition Number: 1200.489k Batch Size: 256        Lr: 0.10000 
