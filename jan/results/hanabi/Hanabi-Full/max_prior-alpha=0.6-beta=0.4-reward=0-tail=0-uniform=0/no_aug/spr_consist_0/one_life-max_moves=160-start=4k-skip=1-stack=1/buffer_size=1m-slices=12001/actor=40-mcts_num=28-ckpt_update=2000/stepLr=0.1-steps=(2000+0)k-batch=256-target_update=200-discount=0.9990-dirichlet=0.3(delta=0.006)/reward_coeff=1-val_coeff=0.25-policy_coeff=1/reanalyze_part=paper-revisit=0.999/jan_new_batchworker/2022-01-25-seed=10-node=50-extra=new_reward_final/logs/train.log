[2022-01-25 04:45:51,040][train][INFO][train.py>_log] ==> #0          Total Loss: 47.204   [weighted Loss:47.204   Policy Loss: 12.732   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1108       Buffer Size: 1108       Transition Number: 10.927  k Batch Size: 256        Lr: 0.00000 
[2022-01-25 04:48:36,648][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.049    [weighted Loss:6.049    Policy Loss: 13.326   Value Loss: 4.729    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 14007      Buffer Size: 14007      Transition Number: 174.519 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:51:21,182][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.597    [weighted Loss:4.597    Policy Loss: 12.496   Value Loss: 3.968    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 26493      Buffer Size: 26493      Transition Number: 329.809 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:54:06,026][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.328    [weighted Loss:4.328    Policy Loss: 9.958    Value Loss: 3.834    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 47667      Buffer Size: 47667      Transition Number: 492.254 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:56:49,333][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 8.898    Value Loss: 3.720    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 68809      Buffer Size: 68809      Transition Number: 650.435 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 04:59:37,365][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.961    [weighted Loss:2.961    Policy Loss: 8.795    Value Loss: 3.667    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 84711      Buffer Size: 84711      Transition Number: 809.891 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:02:22,209][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 9.601    Value Loss: 4.033    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 100550     Buffer Size: 100550     Transition Number: 969.864 k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:05:07,050][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.374    [weighted Loss:4.374    Policy Loss: 7.879    Value Loss: 4.057    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 111861     Buffer Size: 111861     Transition Number: 1126.889k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:08:07,823][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 7.953    Value Loss: 4.168    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 124131     Buffer Size: 116126     Transition Number: 1200.483k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:11:07,193][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.484    [weighted Loss:3.484    Policy Loss: 7.981    Value Loss: 4.332    Reward Loss: 1.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 134481     Buffer Size: 112779     Transition Number: 1200.178k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:14:04,775][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.367    [weighted Loss:4.367    Policy Loss: 7.729    Value Loss: 4.268    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 144712     Buffer Size: 104415     Transition Number: 1200.306k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:17:06,085][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.651    [weighted Loss:4.651    Policy Loss: 8.303    Value Loss: 4.388    Reward Loss: 1.958    Consistency Loss: 0.000    ] Replay Episodes Collected: 155112     Buffer Size: 91726      Transition Number: 1200.128k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:20:06,363][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.779    [weighted Loss:2.779    Policy Loss: 7.079    Value Loss: 4.023    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 165365     Buffer Size: 83458      Transition Number: 1200.227k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:23:05,463][train][INFO][train.py>_log] ==> #13000      Total Loss: 3.568    [weighted Loss:3.568    Policy Loss: 8.627    Value Loss: 4.182    Reward Loss: 1.950    Consistency Loss: 0.000    ] Replay Episodes Collected: 175258     Buffer Size: 76717      Transition Number: 1200.182k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:25:58,859][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.301    [weighted Loss:4.301    Policy Loss: 8.681    Value Loss: 4.029    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 184946     Buffer Size: 73919      Transition Number: 1200.079k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:28:55,992][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.802    [weighted Loss:4.802    Policy Loss: 9.770    Value Loss: 4.108    Reward Loss: 2.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 195134     Buffer Size: 72195      Transition Number: 1200.281k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:31:51,692][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.721    [weighted Loss:3.721    Policy Loss: 9.215    Value Loss: 4.046    Reward Loss: 1.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 205245     Buffer Size: 71858      Transition Number: 1200.129k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:34:45,129][train][INFO][train.py>_log] ==> #17000      Total Loss: 4.898    [weighted Loss:4.898    Policy Loss: 9.673    Value Loss: 4.480    Reward Loss: 1.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 214087     Buffer Size: 70713      Transition Number: 1200.057k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:37:35,982][train][INFO][train.py>_log] ==> #18000      Total Loss: 5.202    [weighted Loss:5.202    Policy Loss: 10.254   Value Loss: 4.210    Reward Loss: 1.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 222639     Buffer Size: 69664      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:40:27,291][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.236    [weighted Loss:4.236    Policy Loss: 9.758    Value Loss: 4.162    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 230390     Buffer Size: 67869      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:43:17,854][train][INFO][train.py>_log] ==> #20000      Total Loss: 5.418    [weighted Loss:5.418    Policy Loss: 10.312   Value Loss: 4.484    Reward Loss: 1.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 238122     Buffer Size: 66192      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:46:12,103][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.869    [weighted Loss:4.869    Policy Loss: 9.958    Value Loss: 4.648    Reward Loss: 2.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 246474     Buffer Size: 64958      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:49:07,318][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.130    [weighted Loss:4.130    Policy Loss: 8.943    Value Loss: 4.694    Reward Loss: 2.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 255007     Buffer Size: 63591      Transition Number: 1200.129k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:52:00,136][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.483    [weighted Loss:4.483    Policy Loss: 9.094    Value Loss: 4.666    Reward Loss: 1.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 262298     Buffer Size: 61166      Transition Number: 1200.201k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:54:49,557][train][INFO][train.py>_log] ==> #24000      Total Loss: 5.063    [weighted Loss:5.063    Policy Loss: 9.268    Value Loss: 4.961    Reward Loss: 2.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 269418     Buffer Size: 59347      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-25 05:57:37,720][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.004    [weighted Loss:5.004    Policy Loss: 8.992    Value Loss: 5.110    Reward Loss: 2.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 275722     Buffer Size: 57407      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:00:23,822][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.418    [weighted Loss:5.418    Policy Loss: 8.774    Value Loss: 5.193    Reward Loss: 2.092    Consistency Loss: 0.000    ] Replay Episodes Collected: 281847     Buffer Size: 55757      Transition Number: 1200.193k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:03:08,635][train][INFO][train.py>_log] ==> #27000      Total Loss: 5.720    [weighted Loss:5.720    Policy Loss: 9.510    Value Loss: 4.940    Reward Loss: 2.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 286497     Buffer Size: 53668      Transition Number: 1200.201k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:05:53,583][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.158    [weighted Loss:4.158    Policy Loss: 8.222    Value Loss: 5.079    Reward Loss: 1.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 291078     Buffer Size: 51059      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:08:38,978][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.112    [weighted Loss:4.112    Policy Loss: 7.910    Value Loss: 5.265    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 294037     Buffer Size: 47327      Transition Number: 1200.239k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:11:28,314][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.499    [weighted Loss:4.499    Policy Loss: 7.401    Value Loss: 5.102    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 297072     Buffer Size: 43002      Transition Number: 1200.085k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:14:13,554][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 6.445    Value Loss: 5.137    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 299375     Buffer Size: 39087      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:16:57,978][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 5.876    Value Loss: 5.264    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 301722     Buffer Size: 35241      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:19:45,221][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 5.430    Value Loss: 5.646    Reward Loss: 1.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 304014     Buffer Size: 31391      Transition Number: 1200.156k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:22:31,203][train][INFO][train.py>_log] ==> #34000      Total Loss: 3.498    [weighted Loss:3.498    Policy Loss: 5.413    Value Loss: 5.174    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 306309     Buffer Size: 27930      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:25:16,356][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.359    [weighted Loss:3.359    Policy Loss: 5.452    Value Loss: 5.246    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 308495     Buffer Size: 24673      Transition Number: 1200.040k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:28:01,154][train][INFO][train.py>_log] ==> #36000      Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 4.751    Value Loss: 5.229    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 310600     Buffer Size: 22510      Transition Number: 1200.450k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:30:49,375][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 4.427    Value Loss: 5.102    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 312780     Buffer Size: 20436      Transition Number: 1200.064k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:33:33,275][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 5.844    Value Loss: 5.195    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 314954     Buffer Size: 19555      Transition Number: 1200.118k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:36:17,247][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.429    [weighted Loss:3.429    Policy Loss: 5.239    Value Loss: 5.190    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 317331     Buffer Size: 19046      Transition Number: 1200.043k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:39:01,164][train][INFO][train.py>_log] ==> #40000      Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 5.548    Value Loss: 5.006    Reward Loss: 1.193    Consistency Loss: 0.000    ] Replay Episodes Collected: 319539     Buffer Size: 18937      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:41:49,379][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.512    [weighted Loss:2.512    Policy Loss: 5.637    Value Loss: 4.914    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 321860     Buffer Size: 18820      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:44:33,787][train][INFO][train.py>_log] ==> #42000      Total Loss: 1.558    [weighted Loss:1.558    Policy Loss: 5.963    Value Loss: 4.897    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 324161     Buffer Size: 18781      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:47:18,620][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 6.422    Value Loss: 5.234    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 326624     Buffer Size: 19067      Transition Number: 1200.212k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:50:03,113][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 6.559    Value Loss: 5.076    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 329142     Buffer Size: 19430      Transition Number: 1200.132k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:52:48,572][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 6.563    Value Loss: 5.202    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 331427     Buffer Size: 19577      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:55:37,896][train][INFO][train.py>_log] ==> #46000      Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 6.291    Value Loss: 5.254    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 333823     Buffer Size: 19780      Transition Number: 1199.956k Batch Size: 256        Lr: 0.10000 
[2022-01-25 06:58:22,143][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.738    [weighted Loss:2.738    Policy Loss: 6.753    Value Loss: 5.235    Reward Loss: 1.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 336086     Buffer Size: 19865      Transition Number: 1200.340k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:01:06,666][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 5.553    Value Loss: 5.056    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 338455     Buffer Size: 19818      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:03:53,786][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.011    [weighted Loss:3.011    Policy Loss: 5.855    Value Loss: 5.381    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 342057     Buffer Size: 21106      Transition Number: 1200.423k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:06:40,977][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 5.587    Value Loss: 4.818    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 345549     Buffer Size: 22332      Transition Number: 1200.004k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:09:26,838][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 5.115    Value Loss: 5.141    Reward Loss: 1.274    Consistency Loss: 0.000    ] Replay Episodes Collected: 347987     Buffer Size: 22234      Transition Number: 1200.411k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:12:12,974][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.132    [weighted Loss:3.132    Policy Loss: 5.046    Value Loss: 5.075    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 350449     Buffer Size: 21927      Transition Number: 1200.102k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:15:02,915][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 5.046    Value Loss: 4.632    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 352774     Buffer Size: 21555      Transition Number: 1200.479k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:17:48,827][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 5.418    Value Loss: 4.443    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 355102     Buffer Size: 21193      Transition Number: 1200.178k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:20:35,118][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 5.421    Value Loss: 4.472    Reward Loss: 1.077    Consistency Loss: 0.000    ] Replay Episodes Collected: 357550     Buffer Size: 21056      Transition Number: 1200.210k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:23:20,779][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 6.049    Value Loss: 4.747    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 359918     Buffer Size: 20641      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:26:10,482][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.819    [weighted Loss:2.819    Policy Loss: 5.793    Value Loss: 4.406    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 362239     Buffer Size: 19070      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:28:55,853][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.150    [weighted Loss:2.150    Policy Loss: 5.561    Value Loss: 4.441    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 364577     Buffer Size: 17992      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:31:41,818][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.997    [weighted Loss:2.997    Policy Loss: 6.538    Value Loss: 4.940    Reward Loss: 1.172    Consistency Loss: 0.000    ] Replay Episodes Collected: 366956     Buffer Size: 17806      Transition Number: 1199.950k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:34:27,929][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 6.178    Value Loss: 4.525    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 369245     Buffer Size: 17725      Transition Number: 1200.154k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:37:13,366][train][INFO][train.py>_log] ==> #61000      Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 6.556    Value Loss: 4.696    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 371701     Buffer Size: 17978      Transition Number: 1200.165k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:40:01,365][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 6.857    Value Loss: 5.018    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 374170     Buffer Size: 18222      Transition Number: 1200.206k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:42:47,519][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.220    [weighted Loss:3.220    Policy Loss: 7.031    Value Loss: 4.892    Reward Loss: 1.389    Consistency Loss: 0.000    ] Replay Episodes Collected: 376620     Buffer Size: 18331      Transition Number: 1200.073k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:45:32,648][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.216    [weighted Loss:3.216    Policy Loss: 7.440    Value Loss: 5.107    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 379130     Buffer Size: 18478      Transition Number: 1200.318k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:48:22,580][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.076    [weighted Loss:3.076    Policy Loss: 7.097    Value Loss: 5.134    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 381548     Buffer Size: 18732      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:51:08,466][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 7.425    Value Loss: 4.892    Reward Loss: 1.284    Consistency Loss: 0.000    ] Replay Episodes Collected: 383944     Buffer Size: 19002      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:53:53,926][train][INFO][train.py>_log] ==> #67000      Total Loss: 4.324    [weighted Loss:4.324    Policy Loss: 7.270    Value Loss: 5.281    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 386439     Buffer Size: 19294      Transition Number: 1200.182k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:56:39,264][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.188    [weighted Loss:3.188    Policy Loss: 7.366    Value Loss: 4.865    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 388981     Buffer Size: 19615      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-25 07:59:28,877][train][INFO][train.py>_log] ==> #69000      Total Loss: 4.599    [weighted Loss:4.599    Policy Loss: 7.764    Value Loss: 5.456    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 391385     Buffer Size: 19699      Transition Number: 1200.863k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:02:13,802][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 7.436    Value Loss: 4.855    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 393866     Buffer Size: 19741      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:05:00,021][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.554    [weighted Loss:3.554    Policy Loss: 8.150    Value Loss: 4.949    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 396229     Buffer Size: 19773      Transition Number: 1200.340k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:07:44,925][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 7.923    Value Loss: 5.309    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 398675     Buffer Size: 19730      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:10:30,483][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.239    [weighted Loss:2.239    Policy Loss: 7.486    Value Loss: 5.223    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 401178     Buffer Size: 19694      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:13:21,129][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 7.562    Value Loss: 4.774    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 403727     Buffer Size: 19645      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:16:07,403][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.434    [weighted Loss:4.434    Policy Loss: 8.431    Value Loss: 5.248    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 406295     Buffer Size: 19550      Transition Number: 1200.296k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:18:53,759][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 7.881    Value Loss: 4.868    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 408758     Buffer Size: 19441      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:21:43,390][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.831    [weighted Loss:3.831    Policy Loss: 7.035    Value Loss: 5.001    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 411292     Buffer Size: 19371      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:24:29,682][train][INFO][train.py>_log] ==> #78000      Total Loss: 4.161    [weighted Loss:4.161    Policy Loss: 7.231    Value Loss: 5.176    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 413797     Buffer Size: 19349      Transition Number: 1200.118k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:27:15,914][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 7.359    Value Loss: 4.967    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 416186     Buffer Size: 19363      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:30:02,479][train][INFO][train.py>_log] ==> #80000      Total Loss: 4.507    [weighted Loss:4.507    Policy Loss: 7.478    Value Loss: 4.992    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 418597     Buffer Size: 19371      Transition Number: 1200.151k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:32:52,183][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 6.914    Value Loss: 5.256    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 421182     Buffer Size: 19407      Transition Number: 1200.044k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:35:36,720][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.781    [weighted Loss:3.781    Policy Loss: 7.105    Value Loss: 5.055    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 423626     Buffer Size: 19417      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:38:21,976][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.719    [weighted Loss:2.719    Policy Loss: 7.786    Value Loss: 5.262    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 426202     Buffer Size: 19573      Transition Number: 1200.195k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:41:07,200][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.645    [weighted Loss:4.645    Policy Loss: 7.560    Value Loss: 5.465    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 428696     Buffer Size: 19767      Transition Number: 1200.117k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:43:53,163][train][INFO][train.py>_log] ==> #85000      Total Loss: 2.881    [weighted Loss:2.881    Policy Loss: 6.903    Value Loss: 5.235    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 431170     Buffer Size: 19819      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:46:41,914][train][INFO][train.py>_log] ==> #86000      Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 6.881    Value Loss: 5.243    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 433719     Buffer Size: 19866      Transition Number: 1200.414k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:49:27,832][train][INFO][train.py>_log] ==> #87000      Total Loss: 4.197    [weighted Loss:4.197    Policy Loss: 7.153    Value Loss: 5.166    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 436222     Buffer Size: 19938      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:52:12,592][train][INFO][train.py>_log] ==> #88000      Total Loss: 3.927    [weighted Loss:3.927    Policy Loss: 6.672    Value Loss: 5.536    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 438595     Buffer Size: 20066      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:55:00,800][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 7.089    Value Loss: 5.392    Reward Loss: 1.433    Consistency Loss: 0.000    ] Replay Episodes Collected: 441483     Buffer Size: 20426      Transition Number: 1200.180k Batch Size: 256        Lr: 0.10000 
[2022-01-25 08:57:46,006][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.407    [weighted Loss:3.407    Policy Loss: 6.545    Value Loss: 5.256    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 444242     Buffer Size: 20818      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:00:31,114][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.967    [weighted Loss:3.967    Policy Loss: 6.934    Value Loss: 5.503    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 446752     Buffer Size: 20847      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:03:16,949][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 6.563    Value Loss: 5.192    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 449352     Buffer Size: 20818      Transition Number: 1200.594k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:06:06,103][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 6.581    Value Loss: 5.612    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 451732     Buffer Size: 20749      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:08:51,286][train][INFO][train.py>_log] ==> #94000      Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 5.826    Value Loss: 5.321    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 454135     Buffer Size: 20694      Transition Number: 1200.506k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:11:36,455][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.979    [weighted Loss:2.979    Policy Loss: 6.338    Value Loss: 5.187    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 456477     Buffer Size: 20649      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:14:21,392][train][INFO][train.py>_log] ==> #96000      Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 6.199    Value Loss: 4.963    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 458861     Buffer Size: 20539      Transition Number: 1200.387k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:17:07,835][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 6.086    Value Loss: 5.307    Reward Loss: 1.315    Consistency Loss: 0.000    ] Replay Episodes Collected: 461246     Buffer Size: 20090      Transition Number: 1200.364k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:19:58,156][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 5.966    Value Loss: 5.516    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 463766     Buffer Size: 19573      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:22:44,169][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 7.444    Value Loss: 5.124    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 466484     Buffer Size: 19605      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:25:29,851][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 6.814    Value Loss: 5.268    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 469130     Buffer Size: 19663      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:28:17,832][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.215    [weighted Loss:3.215    Policy Loss: 6.572    Value Loss: 5.278    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 471913     Buffer Size: 20022      Transition Number: 1200.053k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:31:03,489][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.568    Value Loss: 5.399    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 474576     Buffer Size: 20346      Transition Number: 1200.122k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:33:48,524][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.695    [weighted Loss:3.695    Policy Loss: 6.396    Value Loss: 5.151    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 477354     Buffer Size: 20754      Transition Number: 1200.058k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:36:34,654][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 6.329    Value Loss: 5.653    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 480129     Buffer Size: 21130      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:39:23,181][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 6.464    Value Loss: 5.476    Reward Loss: 1.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 482666     Buffer Size: 21350      Transition Number: 1200.176k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:42:08,804][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 5.856    Value Loss: 5.414    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 485090     Buffer Size: 21516      Transition Number: 1200.083k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:44:53,900][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.123    [weighted Loss:3.123    Policy Loss: 6.119    Value Loss: 6.015    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 487527     Buffer Size: 21417      Transition Number: 1200.114k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:47:38,247][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 6.057    Value Loss: 6.079    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 489884     Buffer Size: 21334      Transition Number: 1200.549k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:50:24,092][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.776    [weighted Loss:2.776    Policy Loss: 6.426    Value Loss: 5.082    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 492352     Buffer Size: 20992      Transition Number: 1200.032k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:53:14,034][train][INFO][train.py>_log] ==> #110000     Total Loss: 2.864    [weighted Loss:2.864    Policy Loss: 5.915    Value Loss: 5.053    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 494739     Buffer Size: 20676      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:55:58,250][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 6.578    Value Loss: 5.178    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 497442     Buffer Size: 20600      Transition Number: 1200.675k Batch Size: 256        Lr: 0.10000 
[2022-01-25 09:58:42,917][train][INFO][train.py>_log] ==> #112000     Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 6.266    Value Loss: 5.385    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 500099     Buffer Size: 20537      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:01:30,908][train][INFO][train.py>_log] ==> #113000     Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 6.829    Value Loss: 5.203    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 502629     Buffer Size: 20501      Transition Number: 1200.412k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:04:17,220][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 6.787    Value Loss: 5.192    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 505055     Buffer Size: 20507      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:07:03,441][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.393    [weighted Loss:3.393    Policy Loss: 6.545    Value Loss: 5.426    Reward Loss: 1.444    Consistency Loss: 0.000    ] Replay Episodes Collected: 508398     Buffer Size: 21309      Transition Number: 1200.084k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:09:47,645][train][INFO][train.py>_log] ==> #116000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 6.895    Value Loss: 5.295    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 511651     Buffer Size: 22085      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:12:37,581][train][INFO][train.py>_log] ==> #117000     Total Loss: 2.919    [weighted Loss:2.919    Policy Loss: 6.325    Value Loss: 5.434    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 514415     Buffer Size: 22460      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:15:22,733][train][INFO][train.py>_log] ==> #118000     Total Loss: 4.688    [weighted Loss:4.688    Policy Loss: 7.139    Value Loss: 6.009    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 517135     Buffer Size: 22834      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:18:08,378][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 6.705    Value Loss: 5.768    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 519629     Buffer Size: 22766      Transition Number: 1199.965k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:20:54,053][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.159    [weighted Loss:2.159    Policy Loss: 6.581    Value Loss: 5.907    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 522123     Buffer Size: 22580      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:23:42,561][train][INFO][train.py>_log] ==> #121000     Total Loss: 2.968    [weighted Loss:2.968    Policy Loss: 6.472    Value Loss: 5.789    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 524667     Buffer Size: 22570      Transition Number: 1200.180k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:26:28,290][train][INFO][train.py>_log] ==> #122000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 6.525    Value Loss: 5.653    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 527154     Buffer Size: 22596      Transition Number: 1200.060k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:29:13,491][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 5.972    Value Loss: 5.423    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 529530     Buffer Size: 21969      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:31:59,544][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 5.990    Value Loss: 5.051    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 531997     Buffer Size: 21009      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:34:45,572][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.371    [weighted Loss:3.371    Policy Loss: 6.143    Value Loss: 5.249    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 534457     Buffer Size: 20614      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:37:32,731][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.436    [weighted Loss:4.436    Policy Loss: 7.089    Value Loss: 5.257    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 536921     Buffer Size: 20382      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:40:18,101][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 6.673    Value Loss: 5.411    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 539371     Buffer Size: 20318      Transition Number: 1200.246k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:43:03,510][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 6.653    Value Loss: 5.278    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 541870     Buffer Size: 20333      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:45:52,125][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 6.679    Value Loss: 5.444    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 544442     Buffer Size: 20371      Transition Number: 1199.936k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:48:37,968][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.514    Value Loss: 5.572    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 546979     Buffer Size: 20400      Transition Number: 1200.649k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:51:22,753][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 7.121    Value Loss: 5.364    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 549610     Buffer Size: 20598      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:54:07,867][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.876    [weighted Loss:2.876    Policy Loss: 6.608    Value Loss: 5.748    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 552204     Buffer Size: 20812      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:56:56,073][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.547    Value Loss: 5.790    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 554875     Buffer Size: 20997      Transition Number: 1200.257k Batch Size: 256        Lr: 0.10000 
[2022-01-25 10:59:40,567][train][INFO][train.py>_log] ==> #134000     Total Loss: 4.036    [weighted Loss:4.036    Policy Loss: 6.712    Value Loss: 5.997    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 557398     Buffer Size: 21096      Transition Number: 1200.240k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:02:24,630][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 6.721    Value Loss: 5.615    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 560234     Buffer Size: 21491      Transition Number: 1200.059k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:05:08,827][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 6.309    Value Loss: 5.650    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 563140     Buffer Size: 21934      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:07:54,154][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 6.138    Value Loss: 5.749    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 565624     Buffer Size: 21955      Transition Number: 1200.174k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:10:42,630][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 6.173    Value Loss: 5.919    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 568174     Buffer Size: 21920      Transition Number: 1200.212k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:13:27,471][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 6.469    Value Loss: 5.973    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 570593     Buffer Size: 21779      Transition Number: 1200.306k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:16:12,689][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.705    [weighted Loss:3.705    Policy Loss: 6.090    Value Loss: 5.456    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 573057     Buffer Size: 21614      Transition Number: 1200.041k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:19:01,847][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 6.705    Value Loss: 5.946    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 576098     Buffer Size: 21959      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:21:45,570][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 6.626    Value Loss: 5.723    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 579051     Buffer Size: 22400      Transition Number: 1200.327k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:24:30,714][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 5.521    Value Loss: 5.586    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 582073     Buffer Size: 22545      Transition Number: 1200.041k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:27:15,965][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.657    [weighted Loss:3.657    Policy Loss: 5.817    Value Loss: 6.093    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 585046     Buffer Size: 22495      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:30:04,259][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 5.819    Value Loss: 5.877    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 587599     Buffer Size: 22381      Transition Number: 1199.995k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:32:50,188][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.397    Value Loss: 5.942    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 590132     Buffer Size: 22352      Transition Number: 1200.471k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:35:35,468][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.597    [weighted Loss:2.597    Policy Loss: 6.070    Value Loss: 5.699    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 592575     Buffer Size: 22364      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:38:20,608][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.003    Value Loss: 5.497    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 595112     Buffer Size: 22382      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:41:06,177][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.947    [weighted Loss:2.947    Policy Loss: 6.785    Value Loss: 5.537    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 597640     Buffer Size: 21991      Transition Number: 1200.245k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:43:55,307][train][INFO][train.py>_log] ==> #150000     Total Loss: 4.048    [weighted Loss:4.048    Policy Loss: 6.445    Value Loss: 5.417    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 600151     Buffer Size: 21443      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:46:40,514][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.601    [weighted Loss:2.601    Policy Loss: 6.371    Value Loss: 5.566    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 602718     Buffer Size: 21049      Transition Number: 1200.394k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:49:25,394][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 5.873    Value Loss: 5.768    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 605274     Buffer Size: 20605      Transition Number: 1200.081k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:52:13,634][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 6.284    Value Loss: 5.785    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 608863     Buffer Size: 21422      Transition Number: 1200.125k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:54:59,571][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 5.727    Value Loss: 5.800    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 612333     Buffer Size: 22328      Transition Number: 1200.127k Batch Size: 256        Lr: 0.10000 
[2022-01-25 11:57:44,444][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.047    [weighted Loss:3.047    Policy Loss: 5.932    Value Loss: 6.122    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 614819     Buffer Size: 22381      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:00:30,187][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 5.834    Value Loss: 5.362    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 617329     Buffer Size: 22382      Transition Number: 1199.980k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:03:18,999][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 6.280    Value Loss: 5.484    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 620010     Buffer Size: 22406      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:06:04,201][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.548    [weighted Loss:3.548    Policy Loss: 6.655    Value Loss: 5.678    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 622513     Buffer Size: 22477      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:08:50,468][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.225    [weighted Loss:2.225    Policy Loss: 6.785    Value Loss: 5.633    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 625215     Buffer Size: 22456      Transition Number: 1200.219k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:11:35,822][train][INFO][train.py>_log] ==> #160000     Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 6.639    Value Loss: 5.626    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 627903     Buffer Size: 22439      Transition Number: 1200.008k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:14:25,397][train][INFO][train.py>_log] ==> #161000     Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 6.673    Value Loss: 5.854    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 630523     Buffer Size: 21477      Transition Number: 1200.028k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:17:10,762][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 6.809    Value Loss: 5.253    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 633111     Buffer Size: 20585      Transition Number: 1200.136k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:19:57,041][train][INFO][train.py>_log] ==> #163000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 6.181    Value Loss: 5.401    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 635727     Buffer Size: 20594      Transition Number: 1199.944k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:22:42,624][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 7.392    Value Loss: 5.526    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 638217     Buffer Size: 20649      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:25:30,495][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 6.557    Value Loss: 5.265    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 641072     Buffer Size: 20821      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:28:17,184][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.264    [weighted Loss:3.264    Policy Loss: 7.365    Value Loss: 5.633    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 643878     Buffer Size: 21016      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:31:02,862][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.611    [weighted Loss:2.611    Policy Loss: 6.363    Value Loss: 5.273    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 646389     Buffer Size: 20916      Transition Number: 1199.935k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:33:47,932][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.819    [weighted Loss:2.819    Policy Loss: 7.090    Value Loss: 5.259    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 648897     Buffer Size: 20847      Transition Number: 1200.170k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:36:38,737][train][INFO][train.py>_log] ==> #169000     Total Loss: 3.402    [weighted Loss:3.402    Policy Loss: 6.780    Value Loss: 5.320    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 651620     Buffer Size: 20896      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:39:24,433][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.093    [weighted Loss:2.093    Policy Loss: 6.036    Value Loss: 5.973    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 654304     Buffer Size: 20918      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:42:10,320][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 6.552    Value Loss: 5.233    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 656847     Buffer Size: 20937      Transition Number: 1200.301k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:44:55,932][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 6.722    Value Loss: 5.395    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 659458     Buffer Size: 20936      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:47:44,814][train][INFO][train.py>_log] ==> #173000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 5.841    Value Loss: 5.369    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 662046     Buffer Size: 20602      Transition Number: 1200.046k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:50:31,842][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.046    [weighted Loss:3.046    Policy Loss: 6.119    Value Loss: 5.142    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 664556     Buffer Size: 20292      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:53:17,872][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 7.168    Value Loss: 4.921    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 667021     Buffer Size: 20233      Transition Number: 1200.171k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:56:02,344][train][INFO][train.py>_log] ==> #176000     Total Loss: 1.220    [weighted Loss:1.220    Policy Loss: 6.785    Value Loss: 5.182    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 669526     Buffer Size: 20194      Transition Number: 1200.627k Batch Size: 256        Lr: 0.10000 
[2022-01-25 12:58:50,684][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 7.483    Value Loss: 5.328    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 672980     Buffer Size: 20921      Transition Number: 1200.269k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:01:37,762][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.662    [weighted Loss:3.662    Policy Loss: 6.670    Value Loss: 5.443    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 676414     Buffer Size: 21742      Transition Number: 1200.374k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:04:23,165][train][INFO][train.py>_log] ==> #179000     Total Loss: 1.835    [weighted Loss:1.835    Policy Loss: 6.009    Value Loss: 5.911    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 679210     Buffer Size: 21889      Transition Number: 1200.220k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:07:08,619][train][INFO][train.py>_log] ==> #180000     Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 6.623    Value Loss: 5.718    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 681903     Buffer Size: 22005      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:09:58,680][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 6.005    Value Loss: 5.970    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 684549     Buffer Size: 22089      Transition Number: 1200.155k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:12:42,957][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 6.790    Value Loss: 5.882    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 687092     Buffer Size: 22169      Transition Number: 1200.364k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:15:27,970][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.344    [weighted Loss:3.344    Policy Loss: 6.603    Value Loss: 5.957    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 689873     Buffer Size: 22402      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:18:12,879][train][INFO][train.py>_log] ==> #184000     Total Loss: 4.229    [weighted Loss:4.229    Policy Loss: 6.882    Value Loss: 5.738    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 692547     Buffer Size: 22617      Transition Number: 1200.069k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:21:02,245][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 5.850    Value Loss: 5.808    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 695282     Buffer Size: 21881      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:23:47,934][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.751    [weighted Loss:3.751    Policy Loss: 6.844    Value Loss: 5.634    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 697958     Buffer Size: 21169      Transition Number: 1200.122k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:26:34,124][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.682    [weighted Loss:2.682    Policy Loss: 6.595    Value Loss: 5.410    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 700461     Buffer Size: 20986      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:29:19,582][train][INFO][train.py>_log] ==> #188000     Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 6.036    Value Loss: 5.289    Reward Loss: 1.538    Consistency Loss: 0.000    ] Replay Episodes Collected: 702952     Buffer Size: 20824      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:32:06,187][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.578    [weighted Loss:2.578    Policy Loss: 6.535    Value Loss: 5.417    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 705437     Buffer Size: 20799      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:34:53,212][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.958    [weighted Loss:3.958    Policy Loss: 6.949    Value Loss: 5.264    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 707895     Buffer Size: 20781      Transition Number: 1200.166k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:37:38,146][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 6.108    Value Loss: 5.530    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 710419     Buffer Size: 20666      Transition Number: 1200.194k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:40:22,763][train][INFO][train.py>_log] ==> #192000     Total Loss: 3.641    [weighted Loss:3.641    Policy Loss: 6.852    Value Loss: 5.395    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 713009     Buffer Size: 20495      Transition Number: 1200.095k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:43:10,945][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 6.734    Value Loss: 5.271    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 715682     Buffer Size: 20499      Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:45:56,247][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.309    [weighted Loss:3.309    Policy Loss: 6.571    Value Loss: 5.059    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 718330     Buffer Size: 20548      Transition Number: 1200.590k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:48:42,697][train][INFO][train.py>_log] ==> #195000     Total Loss: 3.623    [weighted Loss:3.623    Policy Loss: 6.332    Value Loss: 5.658    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 720860     Buffer Size: 20530      Transition Number: 1200.156k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:51:28,599][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.352    [weighted Loss:3.352    Policy Loss: 6.291    Value Loss: 5.017    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 723322     Buffer Size: 20557      Transition Number: 1200.238k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:54:17,592][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.922    [weighted Loss:2.922    Policy Loss: 7.722    Value Loss: 5.467    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 725848     Buffer Size: 20561      Transition Number: 1200.408k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:57:03,396][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 6.363    Value Loss: 5.436    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 728418     Buffer Size: 20583      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-25 13:59:48,891][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 6.289    Value Loss: 5.290    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 731150     Buffer Size: 20641      Transition Number: 1200.043k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:02:35,645][train][INFO][train.py>_log] ==> #200000     Total Loss: 3.129    [weighted Loss:3.129    Policy Loss: 6.781    Value Loss: 5.434    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 733836     Buffer Size: 20691      Transition Number: 1200.216k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:05:22,328][train][INFO][train.py>_log] ==> #201000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 7.411    Value Loss: 5.455    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 736427     Buffer Size: 20661      Transition Number: 1200.318k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:08:09,839][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.725    [weighted Loss:3.725    Policy Loss: 6.250    Value Loss: 5.498    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 739069     Buffer Size: 20608      Transition Number: 1200.233k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:10:55,081][train][INFO][train.py>_log] ==> #203000     Total Loss: 3.312    [weighted Loss:3.312    Policy Loss: 6.779    Value Loss: 5.607    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 741716     Buffer Size: 20746      Transition Number: 1200.167k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:13:40,640][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.352    [weighted Loss:3.352    Policy Loss: 6.218    Value Loss: 5.475    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 744378     Buffer Size: 20895      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:16:30,208][train][INFO][train.py>_log] ==> #205000     Total Loss: 3.442    [weighted Loss:3.442    Policy Loss: 6.278    Value Loss: 5.497    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 746925     Buffer Size: 20928      Transition Number: 1200.020k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:19:16,019][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 6.202    Value Loss: 5.169    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 749474     Buffer Size: 20908      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:22:02,438][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 6.175    Value Loss: 5.422    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 751942     Buffer Size: 20823      Transition Number: 1200.404k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:24:47,706][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 5.911    Value Loss: 4.934    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 754538     Buffer Size: 20661      Transition Number: 1200.046k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:27:37,079][train][INFO][train.py>_log] ==> #209000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 6.249    Value Loss: 5.742    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 757374     Buffer Size: 20871      Transition Number: 1200.272k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:30:22,631][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.068    [weighted Loss:2.068    Policy Loss: 5.577    Value Loss: 5.485    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 760166     Buffer Size: 21099      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:33:07,103][train][INFO][train.py>_log] ==> #211000     Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 6.425    Value Loss: 5.678    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 762837     Buffer Size: 21195      Transition Number: 1200.054k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:35:51,913][train][INFO][train.py>_log] ==> #212000     Total Loss: 1.624    [weighted Loss:1.624    Policy Loss: 5.522    Value Loss: 5.579    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 765516     Buffer Size: 21277      Transition Number: 1200.369k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:38:38,680][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 6.550    Value Loss: 5.238    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 768068     Buffer Size: 21255      Transition Number: 1200.101k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:41:27,326][train][INFO][train.py>_log] ==> #214000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 6.271    Value Loss: 5.416    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 770572     Buffer Size: 21261      Transition Number: 1200.131k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:44:14,702][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.486    [weighted Loss:2.486    Policy Loss: 6.759    Value Loss: 5.540    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 773164     Buffer Size: 21264      Transition Number: 1200.082k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:47:00,078][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.872    [weighted Loss:2.872    Policy Loss: 6.496    Value Loss: 5.646    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 775618     Buffer Size: 21301      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:49:48,733][train][INFO][train.py>_log] ==> #217000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 6.255    Value Loss: 5.530    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 778245     Buffer Size: 21102      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:52:34,168][train][INFO][train.py>_log] ==> #218000     Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 6.945    Value Loss: 5.211    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 780848     Buffer Size: 20797      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:55:20,126][train][INFO][train.py>_log] ==> #219000     Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 7.312    Value Loss: 5.394    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 783543     Buffer Size: 20649      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-25 14:58:06,656][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 6.423    Value Loss: 5.316    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 786223     Buffer Size: 20464      Transition Number: 1200.227k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:00:56,061][train][INFO][train.py>_log] ==> #221000     Total Loss: 3.052    [weighted Loss:3.052    Policy Loss: 6.604    Value Loss: 5.012    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 788885     Buffer Size: 20500      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:03:41,769][train][INFO][train.py>_log] ==> #222000     Total Loss: 3.231    [weighted Loss:3.231    Policy Loss: 6.597    Value Loss: 5.124    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 791498     Buffer Size: 20552      Transition Number: 1200.191k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:06:26,997][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 6.331    Value Loss: 6.021    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 794052     Buffer Size: 20548      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:09:12,769][train][INFO][train.py>_log] ==> #224000     Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 6.712    Value Loss: 5.444    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 796613     Buffer Size: 20566      Transition Number: 1200.250k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:11:59,818][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 6.599    Value Loss: 5.470    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 799122     Buffer Size: 20499      Transition Number: 1200.288k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:14:47,795][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 6.580    Value Loss: 5.593    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 801688     Buffer Size: 20417      Transition Number: 1200.506k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:17:34,126][train][INFO][train.py>_log] ==> #227000     Total Loss: 3.619    [weighted Loss:3.619    Policy Loss: 6.458    Value Loss: 5.703    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 804815     Buffer Size: 20912      Transition Number: 1200.354k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:20:18,570][train][INFO][train.py>_log] ==> #228000     Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 6.622    Value Loss: 5.665    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 807937     Buffer Size: 21458      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:23:06,064][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.329    [weighted Loss:3.329    Policy Loss: 6.576    Value Loss: 5.718    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 810859     Buffer Size: 21768      Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:25:52,313][train][INFO][train.py>_log] ==> #230000     Total Loss: 3.300    [weighted Loss:3.300    Policy Loss: 6.428    Value Loss: 6.177    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 813728     Buffer Size: 22046      Transition Number: 1200.070k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:28:37,145][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.485    Value Loss: 5.993    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 816446     Buffer Size: 22229      Transition Number: 1200.124k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:31:21,914][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 6.423    Value Loss: 5.305    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 819182     Buffer Size: 22345      Transition Number: 1200.055k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:34:10,811][train][INFO][train.py>_log] ==> #233000     Total Loss: 1.946    [weighted Loss:1.946    Policy Loss: 6.892    Value Loss: 5.907    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 821759     Buffer Size: 22494      Transition Number: 1200.117k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:36:56,730][train][INFO][train.py>_log] ==> #234000     Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 6.571    Value Loss: 5.447    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 824417     Buffer Size: 22625      Transition Number: 1200.344k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:39:42,312][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 6.856    Value Loss: 5.300    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 827008     Buffer Size: 22144      Transition Number: 1200.132k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:42:27,204][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 6.487    Value Loss: 5.607    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 829653     Buffer Size: 21655      Transition Number: 1200.474k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:45:13,754][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 6.219    Value Loss: 5.853    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 833414     Buffer Size: 22541      Transition Number: 1200.122k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:48:01,011][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.179    [weighted Loss:3.179    Policy Loss: 6.359    Value Loss: 6.157    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 837229     Buffer Size: 23477      Transition Number: 1200.260k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:50:47,488][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.772    [weighted Loss:2.772    Policy Loss: 6.293    Value Loss: 5.917    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 839973     Buffer Size: 23500      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:53:33,987][train][INFO][train.py>_log] ==> #240000     Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 6.419    Value Loss: 6.118    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 842752     Buffer Size: 23590      Transition Number: 1200.579k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:56:23,749][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 6.789    Value Loss: 5.775    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 845329     Buffer Size: 23468      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-25 15:59:09,153][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 6.591    Value Loss: 5.548    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 847865     Buffer Size: 23368      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:01:55,966][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 6.195    Value Loss: 5.605    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 850384     Buffer Size: 23239      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:04:42,366][train][INFO][train.py>_log] ==> #244000     Total Loss: 3.632    [weighted Loss:3.632    Policy Loss: 6.617    Value Loss: 5.612    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 852980     Buffer Size: 23048      Transition Number: 1199.983k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:07:31,215][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 6.600    Value Loss: 5.305    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 855532     Buffer Size: 21735      Transition Number: 1200.217k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:10:17,248][train][INFO][train.py>_log] ==> #246000     Total Loss: 3.239    [weighted Loss:3.239    Policy Loss: 6.310    Value Loss: 5.444    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 858036     Buffer Size: 20545      Transition Number: 1200.388k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:13:03,181][train][INFO][train.py>_log] ==> #247000     Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 6.773    Value Loss: 5.359    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 860604     Buffer Size: 20279      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:15:49,322][train][INFO][train.py>_log] ==> #248000     Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 6.672    Value Loss: 4.992    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 863091     Buffer Size: 20048      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:18:37,123][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 6.369    Value Loss: 4.968    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 865720     Buffer Size: 20134      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:21:25,007][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 6.514    Value Loss: 5.683    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 868402     Buffer Size: 20218      Transition Number: 1199.938k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:24:11,264][train][INFO][train.py>_log] ==> #251000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 7.104    Value Loss: 5.281    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 870959     Buffer Size: 20265      Transition Number: 1200.376k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:26:57,593][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.786    [weighted Loss:2.786    Policy Loss: 6.585    Value Loss: 5.344    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 873519     Buffer Size: 20287      Transition Number: 1200.071k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:29:47,346][train][INFO][train.py>_log] ==> #253000     Total Loss: 1.509    [weighted Loss:1.509    Policy Loss: 6.511    Value Loss: 5.383    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 876029     Buffer Size: 20292      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:32:33,745][train][INFO][train.py>_log] ==> #254000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 6.625    Value Loss: 5.059    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 878543     Buffer Size: 20242      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:35:19,591][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.747    [weighted Loss:2.747    Policy Loss: 7.404    Value Loss: 5.262    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 881116     Buffer Size: 20261      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:38:05,037][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 7.268    Value Loss: 4.964    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 883627     Buffer Size: 20283      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:40:54,238][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.607    [weighted Loss:2.607    Policy Loss: 6.912    Value Loss: 5.373    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 888069     Buffer Size: 22043      Transition Number: 1200.221k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:43:40,405][train][INFO][train.py>_log] ==> #258000     Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 7.023    Value Loss: 5.705    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 892549     Buffer Size: 23947      Transition Number: 1200.207k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:46:26,398][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 6.106    Value Loss: 6.043    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 895464     Buffer Size: 24364      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:49:13,354][train][INFO][train.py>_log] ==> #260000     Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 6.517    Value Loss: 5.449    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 898401     Buffer Size: 24778      Transition Number: 1200.203k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:51:58,704][train][INFO][train.py>_log] ==> #261000     Total Loss: 2.744    [weighted Loss:2.744    Policy Loss: 6.309    Value Loss: 6.017    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 900959     Buffer Size: 24850      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:54:48,252][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 6.143    Value Loss: 5.261    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 903550     Buffer Size: 24920      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 16:57:34,052][train][INFO][train.py>_log] ==> #263000     Total Loss: 3.428    [weighted Loss:3.428    Policy Loss: 6.797    Value Loss: 5.634    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 906144     Buffer Size: 25024      Transition Number: 1200.220k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:00:20,495][train][INFO][train.py>_log] ==> #264000     Total Loss: 3.432    [weighted Loss:3.432    Policy Loss: 6.949    Value Loss: 5.176    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 908770     Buffer Size: 25120      Transition Number: 1200.166k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:03:09,987][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 6.728    Value Loss: 5.200    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 911348     Buffer Size: 23124      Transition Number: 1200.181k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:05:56,154][train][INFO][train.py>_log] ==> #266000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 8.090    Value Loss: 5.413    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 913826     Buffer Size: 21099      Transition Number: 1200.243k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:08:42,272][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 7.064    Value Loss: 5.095    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 916359     Buffer Size: 20612      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:11:28,710][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 6.878    Value Loss: 5.532    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 918879     Buffer Size: 20208      Transition Number: 1200.072k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:14:18,117][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 6.929    Value Loss: 5.251    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 921545     Buffer Size: 20232      Transition Number: 1200.683k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:17:04,815][train][INFO][train.py>_log] ==> #270000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 7.396    Value Loss: 5.093    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 924191     Buffer Size: 20234      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:19:49,524][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 7.359    Value Loss: 5.277    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 926927     Buffer Size: 20308      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:22:34,182][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 6.495    Value Loss: 5.262    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 929576     Buffer Size: 20416      Transition Number: 1200.219k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:25:21,739][train][INFO][train.py>_log] ==> #273000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 7.151    Value Loss: 5.221    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 932173     Buffer Size: 20428      Transition Number: 1200.250k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:28:12,033][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.581    [weighted Loss:3.581    Policy Loss: 6.921    Value Loss: 5.364    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 934820     Buffer Size: 20451      Transition Number: 1200.159k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:30:58,261][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 7.174    Value Loss: 5.487    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 937184     Buffer Size: 20360      Transition Number: 1200.396k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:33:42,894][train][INFO][train.py>_log] ==> #276000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 7.302    Value Loss: 5.125    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 939638     Buffer Size: 20206      Transition Number: 1200.208k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:36:31,327][train][INFO][train.py>_log] ==> #277000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 7.383    Value Loss: 5.299    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 942228     Buffer Size: 20085      Transition Number: 1200.167k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:39:17,389][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 7.384    Value Loss: 5.112    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 944694     Buffer Size: 19975      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:42:03,219][train][INFO][train.py>_log] ==> #279000     Total Loss: 3.042    [weighted Loss:3.042    Policy Loss: 7.731    Value Loss: 5.012    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 947245     Buffer Size: 19742      Transition Number: 1200.145k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:44:48,645][train][INFO][train.py>_log] ==> #280000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 7.717    Value Loss: 5.311    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 949762     Buffer Size: 19572      Transition Number: 1200.274k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:47:37,694][train][INFO][train.py>_log] ==> #281000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 7.404    Value Loss: 5.244    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 952419     Buffer Size: 19700      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:50:23,689][train][INFO][train.py>_log] ==> #282000     Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 7.784    Value Loss: 5.278    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 955030     Buffer Size: 19836      Transition Number: 1200.143k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:53:09,540][train][INFO][train.py>_log] ==> #283000     Total Loss: 3.530    [weighted Loss:3.530    Policy Loss: 8.047    Value Loss: 5.289    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 957594     Buffer Size: 20072      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:55:54,896][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 8.331    Value Loss: 5.315    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 960207     Buffer Size: 20352      Transition Number: 1200.035k Batch Size: 256        Lr: 0.10000 
[2022-01-25 17:58:40,705][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 7.943    Value Loss: 5.138    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 962581     Buffer Size: 20328      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:01:29,718][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.144    [weighted Loss:3.144    Policy Loss: 8.273    Value Loss: 5.439    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 965173     Buffer Size: 20278      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:04:14,992][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 7.689    Value Loss: 4.998    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 967576     Buffer Size: 20173      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:07:01,586][train][INFO][train.py>_log] ==> #288000     Total Loss: 4.169    [weighted Loss:4.169    Policy Loss: 8.181    Value Loss: 5.116    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 970013     Buffer Size: 20077      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:09:51,774][train][INFO][train.py>_log] ==> #289000     Total Loss: 1.799    [weighted Loss:1.799    Policy Loss: 7.813    Value Loss: 5.314    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 972565     Buffer Size: 19969      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:12:38,656][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 8.079    Value Loss: 5.300    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 975091     Buffer Size: 19854      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:15:23,680][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 7.759    Value Loss: 4.859    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 977488     Buffer Size: 19706      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:18:08,308][train][INFO][train.py>_log] ==> #292000     Total Loss: 3.866    [weighted Loss:3.866    Policy Loss: 8.238    Value Loss: 4.544    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 979919     Buffer Size: 19498      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:20:57,147][train][INFO][train.py>_log] ==> #293000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 7.846    Value Loss: 4.980    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 982390     Buffer Size: 19412      Transition Number: 1200.212k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:23:43,287][train][INFO][train.py>_log] ==> #294000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 7.700    Value Loss: 5.352    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 984821     Buffer Size: 19315      Transition Number: 1200.238k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:26:31,416][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 7.935    Value Loss: 5.082    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 987373     Buffer Size: 19309      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:29:17,466][train][INFO][train.py>_log] ==> #296000     Total Loss: 3.051    [weighted Loss:3.051    Policy Loss: 8.050    Value Loss: 5.031    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 989923     Buffer Size: 19310      Transition Number: 1200.325k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:32:08,112][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.076    [weighted Loss:3.076    Policy Loss: 7.675    Value Loss: 4.808    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 992463     Buffer Size: 19229      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:34:55,316][train][INFO][train.py>_log] ==> #298000     Total Loss: 2.080    [weighted Loss:2.080    Policy Loss: 7.547    Value Loss: 4.806    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 995008     Buffer Size: 19163      Transition Number: 1200.101k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:37:42,111][train][INFO][train.py>_log] ==> #299000     Total Loss: 3.682    [weighted Loss:3.682    Policy Loss: 8.168    Value Loss: 5.236    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 997587     Buffer Size: 19132      Transition Number: 1200.322k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:40:28,348][train][INFO][train.py>_log] ==> #300000     Total Loss: 3.174    [weighted Loss:3.174    Policy Loss: 7.727    Value Loss: 5.002    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000082    Buffer Size: 19126      Transition Number: 1200.139k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:43:16,508][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 7.384    Value Loss: 5.280    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002723    Buffer Size: 19335      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:46:02,960][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 8.313    Value Loss: 5.153    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1005243    Buffer Size: 19523      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:48:48,745][train][INFO][train.py>_log] ==> #303000     Total Loss: 3.727    [weighted Loss:3.727    Policy Loss: 8.223    Value Loss: 5.563    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1007738    Buffer Size: 19600      Transition Number: 1200.539k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:51:33,674][train][INFO][train.py>_log] ==> #304000     Total Loss: 3.289    [weighted Loss:3.289    Policy Loss: 7.735    Value Loss: 5.256    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1010125    Buffer Size: 19606      Transition Number: 1200.003k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:54:23,158][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 8.066    Value Loss: 5.390    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1012589    Buffer Size: 19629      Transition Number: 1200.078k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:57:08,287][train][INFO][train.py>_log] ==> #306000     Total Loss: 3.871    [weighted Loss:3.871    Policy Loss: 8.074    Value Loss: 4.938    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1014972    Buffer Size: 19659      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-25 18:59:53,556][train][INFO][train.py>_log] ==> #307000     Total Loss: 4.180    [weighted Loss:4.180    Policy Loss: 7.528    Value Loss: 5.087    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 1017520    Buffer Size: 19777      Transition Number: 1200.405k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:02:38,751][train][INFO][train.py>_log] ==> #308000     Total Loss: 3.307    [weighted Loss:3.307    Policy Loss: 7.755    Value Loss: 4.761    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 1020044    Buffer Size: 19878      Transition Number: 1199.945k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:05:28,095][train][INFO][train.py>_log] ==> #309000     Total Loss: 1.517    [weighted Loss:1.517    Policy Loss: 8.060    Value Loss: 5.505    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 1022907    Buffer Size: 20149      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:08:12,972][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.412    [weighted Loss:3.412    Policy Loss: 7.728    Value Loss: 5.784    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1025747    Buffer Size: 20383      Transition Number: 1200.256k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:10:58,759][train][INFO][train.py>_log] ==> #311000     Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 7.561    Value Loss: 5.782    Reward Loss: 1.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 1028300    Buffer Size: 20521      Transition Number: 1199.934k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:13:44,202][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 7.804    Value Loss: 5.565    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030854    Buffer Size: 20671      Transition Number: 1200.008k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:16:30,798][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.601    [weighted Loss:3.601    Policy Loss: 7.839    Value Loss: 5.665    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1033287    Buffer Size: 20657      Transition Number: 1200.134k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:19:18,045][train][INFO][train.py>_log] ==> #314000     Total Loss: 3.863    [weighted Loss:3.863    Policy Loss: 7.445    Value Loss: 5.631    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035776    Buffer Size: 20642      Transition Number: 1200.374k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:22:03,194][train][INFO][train.py>_log] ==> #315000     Total Loss: 1.065    [weighted Loss:1.065    Policy Loss: 7.241    Value Loss: 5.448    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1038293    Buffer Size: 20584      Transition Number: 1200.107k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:24:49,284][train][INFO][train.py>_log] ==> #316000     Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 7.300    Value Loss: 5.368    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1040806    Buffer Size: 20527      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:27:40,031][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 7.877    Value Loss: 5.363    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043278    Buffer Size: 20113      Transition Number: 1200.614k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:30:25,696][train][INFO][train.py>_log] ==> #318000     Total Loss: 3.706    [weighted Loss:3.706    Policy Loss: 7.524    Value Loss: 5.275    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1045700    Buffer Size: 19724      Transition Number: 1200.342k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:33:11,673][train][INFO][train.py>_log] ==> #319000     Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 8.018    Value Loss: 4.933    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048337    Buffer Size: 19611      Transition Number: 1200.111k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:35:57,785][train][INFO][train.py>_log] ==> #320000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 7.472    Value Loss: 5.097    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1050790    Buffer Size: 19543      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:38:47,116][train][INFO][train.py>_log] ==> #321000     Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 8.127    Value Loss: 5.163    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 1053491    Buffer Size: 19696      Transition Number: 1200.138k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:41:33,000][train][INFO][train.py>_log] ==> #322000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 7.567    Value Loss: 5.035    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 1056076    Buffer Size: 19864      Transition Number: 1200.405k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:44:18,733][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 7.721    Value Loss: 5.150    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1058743    Buffer Size: 19930      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:47:04,953][train][INFO][train.py>_log] ==> #324000     Total Loss: 3.134    [weighted Loss:3.134    Policy Loss: 7.533    Value Loss: 5.362    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 1061343    Buffer Size: 20019      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:49:54,662][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 7.457    Value Loss: 5.374    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063901    Buffer Size: 20097      Transition Number: 1200.158k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:52:45,318][train][INFO][train.py>_log] ==> #326000     Total Loss: 3.110    [weighted Loss:3.110    Policy Loss: 7.257    Value Loss: 5.050    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1066522    Buffer Size: 20116      Transition Number: 1200.158k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:55:32,334][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 7.084    Value Loss: 5.197    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069086    Buffer Size: 20124      Transition Number: 1200.248k Batch Size: 256        Lr: 0.10000 
[2022-01-25 19:58:19,444][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 7.437    Value Loss: 5.525    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1071679    Buffer Size: 20173      Transition Number: 1200.155k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:01:08,998][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 6.805    Value Loss: 4.978    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1074359    Buffer Size: 20102      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:03:57,111][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 7.590    Value Loss: 5.016    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076862    Buffer Size: 20066      Transition Number: 1200.224k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:06:43,486][train][INFO][train.py>_log] ==> #331000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.880    Value Loss: 5.442    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 1079348    Buffer Size: 19989      Transition Number: 1200.147k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:09:31,114][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 7.352    Value Loss: 5.134    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1081915    Buffer Size: 19911      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:12:22,232][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 6.948    Value Loss: 4.972    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1084353    Buffer Size: 19872      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:15:08,578][train][INFO][train.py>_log] ==> #334000     Total Loss: 3.110    [weighted Loss:3.110    Policy Loss: 7.177    Value Loss: 5.491    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1086880    Buffer Size: 19835      Transition Number: 1200.392k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:17:54,635][train][INFO][train.py>_log] ==> #335000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 6.883    Value Loss: 5.674    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089762    Buffer Size: 20068      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:20:40,137][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.585    [weighted Loss:3.585    Policy Loss: 7.212    Value Loss: 5.653    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092566    Buffer Size: 20294      Transition Number: 1200.120k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:23:28,148][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 7.018    Value Loss: 5.812    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1095161    Buffer Size: 20354      Transition Number: 1200.063k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:26:17,482][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 7.187    Value Loss: 5.602    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1097760    Buffer Size: 20412      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:29:03,059][train][INFO][train.py>_log] ==> #339000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 7.055    Value Loss: 5.693    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100471    Buffer Size: 20568      Transition Number: 1199.957k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:31:50,423][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.990    [weighted Loss:2.990    Policy Loss: 6.711    Value Loss: 5.763    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103197    Buffer Size: 20772      Transition Number: 1200.136k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:34:39,733][train][INFO][train.py>_log] ==> #341000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 7.335    Value Loss: 5.634    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1105823    Buffer Size: 20887      Transition Number: 1200.353k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:37:25,768][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 6.878    Value Loss: 5.590    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1108333    Buffer Size: 20935      Transition Number: 1200.193k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:40:12,731][train][INFO][train.py>_log] ==> #343000     Total Loss: 3.999    [weighted Loss:3.999    Policy Loss: 7.622    Value Loss: 4.976    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111077    Buffer Size: 20838      Transition Number: 1200.061k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:43:00,050][train][INFO][train.py>_log] ==> #344000     Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 7.328    Value Loss: 5.340    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113728    Buffer Size: 20753      Transition Number: 1200.085k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:45:49,224][train][INFO][train.py>_log] ==> #345000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 6.942    Value Loss: 5.628    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 1116438    Buffer Size: 20750      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:48:34,620][train][INFO][train.py>_log] ==> #346000     Total Loss: 3.920    [weighted Loss:3.920    Policy Loss: 7.323    Value Loss: 5.174    Reward Loss: 1.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 1118936    Buffer Size: 20750      Transition Number: 1200.054k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:51:20,156][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.926    [weighted Loss:2.926    Policy Loss: 7.318    Value Loss: 5.547    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1121340    Buffer Size: 20555      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:54:06,955][train][INFO][train.py>_log] ==> #348000     Total Loss: 3.507    [weighted Loss:3.507    Policy Loss: 6.775    Value Loss: 5.116    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1123889    Buffer Size: 20360      Transition Number: 1200.571k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:56:54,530][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.157    [weighted Loss:3.157    Policy Loss: 7.005    Value Loss: 5.252    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126381    Buffer Size: 20298      Transition Number: 1200.305k Batch Size: 256        Lr: 0.10000 
[2022-01-25 20:59:42,424][train][INFO][train.py>_log] ==> #350000     Total Loss: 3.049    [weighted Loss:3.049    Policy Loss: 7.413    Value Loss: 5.158    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128886    Buffer Size: 20235      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:02:29,331][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.127    [weighted Loss:3.127    Policy Loss: 7.387    Value Loss: 4.880    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1131441    Buffer Size: 19953      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:05:16,150][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.455    [weighted Loss:2.455    Policy Loss: 6.854    Value Loss: 5.045    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133886    Buffer Size: 19721      Transition Number: 1200.014k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:08:06,257][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.448    [weighted Loss:2.448    Policy Loss: 7.675    Value Loss: 5.159    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1136869    Buffer Size: 20025      Transition Number: 1200.286k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:10:50,987][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 7.388    Value Loss: 5.464    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139717    Buffer Size: 20344      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:13:37,158][train][INFO][train.py>_log] ==> #355000     Total Loss: 3.137    [weighted Loss:3.137    Policy Loss: 7.411    Value Loss: 5.676    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1142305    Buffer Size: 20457      Transition Number: 1200.215k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:16:25,344][train][INFO][train.py>_log] ==> #356000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 7.132    Value Loss: 5.222    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144841    Buffer Size: 20538      Transition Number: 1200.077k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:19:14,859][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.553    [weighted Loss:3.553    Policy Loss: 7.706    Value Loss: 5.291    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147382    Buffer Size: 20459      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:22:01,765][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 7.520    Value Loss: 5.294    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1149898    Buffer Size: 20377      Transition Number: 1200.056k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:24:47,542][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 7.390    Value Loss: 5.301    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152398    Buffer Size: 20395      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:27:33,048][train][INFO][train.py>_log] ==> #360000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 7.704    Value Loss: 5.414    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1154861    Buffer Size: 20332      Transition Number: 1200.116k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:30:21,332][train][INFO][train.py>_log] ==> #361000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 6.947    Value Loss: 5.474    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1157339    Buffer Size: 19829      Transition Number: 1200.214k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:33:09,410][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 7.397    Value Loss: 4.858    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 1159751    Buffer Size: 19400      Transition Number: 1200.073k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:35:55,390][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.150    [weighted Loss:3.150    Policy Loss: 7.601    Value Loss: 4.732    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1162269    Buffer Size: 19266      Transition Number: 1200.047k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:38:40,949][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.462    [weighted Loss:2.462    Policy Loss: 7.105    Value Loss: 4.800    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1164821    Buffer Size: 19190      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:41:30,057][train][INFO][train.py>_log] ==> #365000     Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 7.085    Value Loss: 4.840    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1167399    Buffer Size: 19248      Transition Number: 1200.208k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:44:16,825][train][INFO][train.py>_log] ==> #366000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 7.625    Value Loss: 4.722    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1169887    Buffer Size: 19269      Transition Number: 1200.153k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:47:03,797][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 6.510    Value Loss: 4.809    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1172499    Buffer Size: 19272      Transition Number: 1200.151k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:49:50,014][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.322    [weighted Loss:3.322    Policy Loss: 7.092    Value Loss: 4.794    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1175058    Buffer Size: 19307      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:52:39,422][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 7.192    Value Loss: 4.995    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1177641    Buffer Size: 19406      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:55:25,603][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.832    [weighted Loss:2.832    Policy Loss: 7.695    Value Loss: 5.057    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1180209    Buffer Size: 19505      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-25 21:58:11,792][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.614    [weighted Loss:2.614    Policy Loss: 6.739    Value Loss: 5.398    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1182818    Buffer Size: 19624      Transition Number: 1200.415k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:00:56,895][train][INFO][train.py>_log] ==> #372000     Total Loss: 2.584    [weighted Loss:2.584    Policy Loss: 6.985    Value Loss: 4.766    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1185361    Buffer Size: 19745      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:03:44,715][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.903    [weighted Loss:2.903    Policy Loss: 7.230    Value Loss: 5.123    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1187894    Buffer Size: 19864      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:06:31,354][train][INFO][train.py>_log] ==> #374000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 7.103    Value Loss: 5.545    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1190385    Buffer Size: 19968      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:09:17,799][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.847    [weighted Loss:2.847    Policy Loss: 7.384    Value Loss: 5.160    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1192925    Buffer Size: 20071      Transition Number: 1200.213k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:12:03,177][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 7.248    Value Loss: 5.427    Reward Loss: 1.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 1195473    Buffer Size: 20187      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:14:53,357][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 7.157    Value Loss: 5.283    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1198007    Buffer Size: 20220      Transition Number: 1200.006k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:17:40,272][train][INFO][train.py>_log] ==> #378000     Total Loss: 3.101    [weighted Loss:3.101    Policy Loss: 7.498    Value Loss: 5.665    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1200650    Buffer Size: 20269      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:20:25,773][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 6.907    Value Loss: 5.343    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1203084    Buffer Size: 20322      Transition Number: 1200.120k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:23:12,840][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 7.108    Value Loss: 5.137    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1205643    Buffer Size: 20347      Transition Number: 1199.991k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:26:01,603][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 6.862    Value Loss: 4.956    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1208127    Buffer Size: 20279      Transition Number: 1200.596k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:28:49,157][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.995    [weighted Loss:2.995    Policy Loss: 6.763    Value Loss: 5.498    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1210654    Buffer Size: 20202      Transition Number: 1200.295k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:31:35,143][train][INFO][train.py>_log] ==> #383000     Total Loss: 3.014    [weighted Loss:3.014    Policy Loss: 6.771    Value Loss: 5.160    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 1213152    Buffer Size: 20094      Transition Number: 1200.188k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:34:21,491][train][INFO][train.py>_log] ==> #384000     Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 6.322    Value Loss: 5.198    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1215638    Buffer Size: 19961      Transition Number: 1200.020k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:37:10,450][train][INFO][train.py>_log] ==> #385000     Total Loss: 3.235    [weighted Loss:3.235    Policy Loss: 6.641    Value Loss: 5.240    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218157    Buffer Size: 19897      Transition Number: 1200.110k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:39:57,408][train][INFO][train.py>_log] ==> #386000     Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 6.851    Value Loss: 5.020    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 1220662    Buffer Size: 19818      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:42:43,179][train][INFO][train.py>_log] ==> #387000     Total Loss: 2.253    [weighted Loss:2.253    Policy Loss: 6.471    Value Loss: 5.577    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223190    Buffer Size: 19675      Transition Number: 1200.079k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:45:29,090][train][INFO][train.py>_log] ==> #388000     Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 6.915    Value Loss: 4.978    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225669    Buffer Size: 19535      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:48:19,233][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 6.928    Value Loss: 5.058    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1228457    Buffer Size: 19784      Transition Number: 1199.955k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:51:06,061][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 6.340    Value Loss: 5.404    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1231354    Buffer Size: 20093      Transition Number: 1200.123k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:53:55,841][train][INFO][train.py>_log] ==> #391000     Total Loss: 2.965    [weighted Loss:2.965    Policy Loss: 6.995    Value Loss: 4.948    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1233983    Buffer Size: 20192      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:56:42,268][train][INFO][train.py>_log] ==> #392000     Total Loss: 2.405    [weighted Loss:2.405    Policy Loss: 6.668    Value Loss: 5.285    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1236571    Buffer Size: 20288      Transition Number: 1200.400k Batch Size: 256        Lr: 0.10000 
[2022-01-25 22:59:30,476][train][INFO][train.py>_log] ==> #393000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 6.611    Value Loss: 4.997    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1239253    Buffer Size: 20461      Transition Number: 1200.071k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:02:18,045][train][INFO][train.py>_log] ==> #394000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 7.072    Value Loss: 5.177    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241936    Buffer Size: 20629      Transition Number: 1200.206k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:05:04,625][train][INFO][train.py>_log] ==> #395000     Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 6.827    Value Loss: 5.615    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1244534    Buffer Size: 20697      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:07:51,543][train][INFO][train.py>_log] ==> #396000     Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 6.311    Value Loss: 5.342    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 1247144    Buffer Size: 20697      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:10:42,136][train][INFO][train.py>_log] ==> #397000     Total Loss: 3.284    [weighted Loss:3.284    Policy Loss: 7.581    Value Loss: 5.656    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1249582    Buffer Size: 20414      Transition Number: 1200.039k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:13:29,452][train][INFO][train.py>_log] ==> #398000     Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 6.644    Value Loss: 5.256    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252031    Buffer Size: 20110      Transition Number: 1200.145k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:16:17,235][train][INFO][train.py>_log] ==> #399000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 7.089    Value Loss: 5.710    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1254802    Buffer Size: 20177      Transition Number: 1200.102k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:19:04,345][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.867    [weighted Loss:2.867    Policy Loss: 6.670    Value Loss: 5.306    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1257441    Buffer Size: 20255      Transition Number: 1200.121k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:21:54,518][train][INFO][train.py>_log] ==> #401000     Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 6.469    Value Loss: 5.620    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1260506    Buffer Size: 20510      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:24:40,628][train][INFO][train.py>_log] ==> #402000     Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 6.654    Value Loss: 5.707    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1263501    Buffer Size: 20765      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:27:29,411][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 6.574    Value Loss: 5.693    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266159    Buffer Size: 20871      Transition Number: 1200.076k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:30:15,365][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 6.689    Value Loss: 5.483    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1268807    Buffer Size: 20966      Transition Number: 1200.031k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:33:02,458][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 7.094    Value Loss: 5.693    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 1271384    Buffer Size: 21003      Transition Number: 1200.144k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:35:51,958][train][INFO][train.py>_log] ==> #406000     Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 6.536    Value Loss: 5.803    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1273925    Buffer Size: 21013      Transition Number: 1200.341k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:38:37,263][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 6.142    Value Loss: 5.573    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1276523    Buffer Size: 20909      Transition Number: 1200.014k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:41:24,418][train][INFO][train.py>_log] ==> #408000     Total Loss: 2.138    [weighted Loss:2.138    Policy Loss: 6.962    Value Loss: 5.157    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1279145    Buffer Size: 20753      Transition Number: 1200.764k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:44:13,461][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.813    [weighted Loss:2.813    Policy Loss: 6.838    Value Loss: 5.075    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1281773    Buffer Size: 20424      Transition Number: 1200.253k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:47:00,264][train][INFO][train.py>_log] ==> #410000     Total Loss: 2.854    [weighted Loss:2.854    Policy Loss: 6.560    Value Loss: 5.448    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 1284330    Buffer Size: 20191      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:49:48,459][train][INFO][train.py>_log] ==> #411000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 6.734    Value Loss: 5.108    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1286876    Buffer Size: 20029      Transition Number: 1200.239k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:52:35,528][train][INFO][train.py>_log] ==> #412000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 6.778    Value Loss: 5.207    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1289370    Buffer Size: 19885      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:55:24,577][train][INFO][train.py>_log] ==> #413000     Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 6.418    Value Loss: 5.139    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1291859    Buffer Size: 19788      Transition Number: 1200.183k Batch Size: 256        Lr: 0.10000 
[2022-01-25 23:58:12,612][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.961    [weighted Loss:2.961    Policy Loss: 6.630    Value Loss: 4.969    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 1294438    Buffer Size: 19677      Transition Number: 1200.184k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:01:00,211][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.958    [weighted Loss:2.958    Policy Loss: 6.695    Value Loss: 5.693    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1297090    Buffer Size: 19631      Transition Number: 1200.001k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:03:47,424][train][INFO][train.py>_log] ==> #416000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 6.511    Value Loss: 5.429    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299682    Buffer Size: 19598      Transition Number: 1199.967k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:06:33,954][train][INFO][train.py>_log] ==> #417000     Total Loss: 1.448    [weighted Loss:1.448    Policy Loss: 6.356    Value Loss: 4.912    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1302285    Buffer Size: 19524      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:09:23,554][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 6.785    Value Loss: 4.968    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304859    Buffer Size: 19506      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:12:13,390][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.529    [weighted Loss:2.529    Policy Loss: 7.333    Value Loss: 5.497    Reward Loss: 1.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 1307478    Buffer Size: 19522      Transition Number: 1200.243k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:15:02,085][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 7.174    Value Loss: 5.111    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1309997    Buffer Size: 19584      Transition Number: 1200.068k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:17:50,120][train][INFO][train.py>_log] ==> #421000     Total Loss: 2.701    [weighted Loss:2.701    Policy Loss: 6.693    Value Loss: 5.315    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 1312474    Buffer Size: 19692      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:20:37,164][train][INFO][train.py>_log] ==> #422000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 6.893    Value Loss: 4.930    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 1315052    Buffer Size: 19745      Transition Number: 1200.051k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:23:25,226][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 7.340    Value Loss: 5.184    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1317603    Buffer Size: 19657      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:26:10,544][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 6.775    Value Loss: 5.365    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1320052    Buffer Size: 19581      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:29:00,863][train][INFO][train.py>_log] ==> #425000     Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 6.946    Value Loss: 5.692    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 1322604    Buffer Size: 19522      Transition Number: 1199.954k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:31:48,164][train][INFO][train.py>_log] ==> #426000     Total Loss: 3.582    [weighted Loss:3.582    Policy Loss: 6.942    Value Loss: 4.997    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1325148    Buffer Size: 19466      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:34:35,434][train][INFO][train.py>_log] ==> #427000     Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 7.202    Value Loss: 5.003    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1327633    Buffer Size: 19442      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:37:22,582][train][INFO][train.py>_log] ==> #428000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 7.131    Value Loss: 5.326    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 1330137    Buffer Size: 19420      Transition Number: 1200.103k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:40:08,307][train][INFO][train.py>_log] ==> #429000     Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 6.999    Value Loss: 5.096    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332652    Buffer Size: 19339      Transition Number: 1200.689k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:42:57,865][train][INFO][train.py>_log] ==> #430000     Total Loss: 2.955    [weighted Loss:2.955    Policy Loss: 7.327    Value Loss: 4.922    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1335193    Buffer Size: 19251      Transition Number: 1200.244k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:45:46,950][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 6.577    Value Loss: 5.279    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1337760    Buffer Size: 19190      Transition Number: 1199.963k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:48:34,356][train][INFO][train.py>_log] ==> #432000     Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 6.750    Value Loss: 5.240    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1340291    Buffer Size: 19137      Transition Number: 1200.389k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:51:27,231][train][INFO][train.py>_log] ==> #433000     Total Loss: 2.296    [weighted Loss:2.296    Policy Loss: 7.117    Value Loss: 5.130    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1342844    Buffer Size: 19077      Transition Number: 1200.088k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:54:12,701][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 7.082    Value Loss: 5.219    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1345276    Buffer Size: 19039      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:57:01,629][train][INFO][train.py>_log] ==> #435000     Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 6.584    Value Loss: 5.084    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 1347792    Buffer Size: 19002      Transition Number: 1200.377k Batch Size: 256        Lr: 0.10000 
[2022-01-26 00:59:48,044][train][INFO][train.py>_log] ==> #436000     Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 6.963    Value Loss: 5.204    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350259    Buffer Size: 18955      Transition Number: 1200.186k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:02:37,105][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 7.074    Value Loss: 4.876    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 1352813    Buffer Size: 18953      Transition Number: 1200.253k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:05:26,031][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.793    [weighted Loss:2.793    Policy Loss: 6.673    Value Loss: 4.959    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1355308    Buffer Size: 18937      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:08:13,310][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.307    [weighted Loss:2.307    Policy Loss: 7.066    Value Loss: 5.231    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1357790    Buffer Size: 18983      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:11:02,892][train][INFO][train.py>_log] ==> #440000     Total Loss: 3.082    [weighted Loss:3.082    Policy Loss: 6.384    Value Loss: 4.873    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 1360277    Buffer Size: 19035      Transition Number: 1200.056k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:13:53,650][train][INFO][train.py>_log] ==> #441000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 6.927    Value Loss: 5.301    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1362865    Buffer Size: 19113      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:16:45,511][train][INFO][train.py>_log] ==> #442000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 7.289    Value Loss: 5.189    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1365431    Buffer Size: 19210      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:19:33,414][train][INFO][train.py>_log] ==> #443000     Total Loss: 3.198    [weighted Loss:3.198    Policy Loss: 7.758    Value Loss: 4.914    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1367911    Buffer Size: 19220      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:22:22,040][train][INFO][train.py>_log] ==> #444000     Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 6.920    Value Loss: 4.715    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370498    Buffer Size: 19221      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:25:12,164][train][INFO][train.py>_log] ==> #445000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 7.282    Value Loss: 5.301    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373029    Buffer Size: 19151      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:28:01,053][train][INFO][train.py>_log] ==> #446000     Total Loss: 2.415    [weighted Loss:2.415    Policy Loss: 6.853    Value Loss: 5.208    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375496    Buffer Size: 19070      Transition Number: 1200.069k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:30:47,964][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.165    [weighted Loss:3.165    Policy Loss: 6.890    Value Loss: 5.061    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 1378024    Buffer Size: 19102      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:33:35,477][train][INFO][train.py>_log] ==> #448000     Total Loss: 1.936    [weighted Loss:1.936    Policy Loss: 7.582    Value Loss: 5.410    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 1380599    Buffer Size: 19135      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:36:25,770][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.566    [weighted Loss:2.566    Policy Loss: 7.452    Value Loss: 4.982    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1383042    Buffer Size: 19073      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:39:12,445][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 6.932    Value Loss: 5.359    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1385718    Buffer Size: 19042      Transition Number: 1200.230k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:41:58,770][train][INFO][train.py>_log] ==> #451000     Total Loss: 2.352    [weighted Loss:2.352    Policy Loss: 7.023    Value Loss: 4.710    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1388251    Buffer Size: 19047      Transition Number: 1200.129k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:44:46,882][train][INFO][train.py>_log] ==> #452000     Total Loss: 2.856    [weighted Loss:2.856    Policy Loss: 6.963    Value Loss: 4.933    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 1390765    Buffer Size: 19077      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:47:38,360][train][INFO][train.py>_log] ==> #453000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 6.755    Value Loss: 4.775    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1393355    Buffer Size: 19149      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:50:28,850][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 6.745    Value Loss: 4.705    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 1395922    Buffer Size: 19155      Transition Number: 1200.398k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:53:16,512][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 7.904    Value Loss: 5.026    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 1398493    Buffer Size: 19089      Transition Number: 1200.101k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:56:02,901][train][INFO][train.py>_log] ==> #456000     Total Loss: 3.890    [weighted Loss:3.890    Policy Loss: 7.563    Value Loss: 4.791    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1401142    Buffer Size: 19047      Transition Number: 1200.100k Batch Size: 256        Lr: 0.10000 
[2022-01-26 01:58:52,541][train][INFO][train.py>_log] ==> #457000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 7.335    Value Loss: 4.815    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1403912    Buffer Size: 19369      Transition Number: 1200.380k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:01:38,395][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 7.747    Value Loss: 5.180    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406762    Buffer Size: 19691      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:04:24,211][train][INFO][train.py>_log] ==> #459000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 8.130    Value Loss: 5.469    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1409340    Buffer Size: 19883      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:07:10,394][train][INFO][train.py>_log] ==> #460000     Total Loss: 2.683    [weighted Loss:2.683    Policy Loss: 7.573    Value Loss: 5.603    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411958    Buffer Size: 20034      Transition Number: 1200.211k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:09:59,931][train][INFO][train.py>_log] ==> #461000     Total Loss: 2.617    [weighted Loss:2.617    Policy Loss: 7.039    Value Loss: 5.618    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1414681    Buffer Size: 20184      Transition Number: 1200.062k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:12:46,464][train][INFO][train.py>_log] ==> #462000     Total Loss: 3.096    [weighted Loss:3.096    Policy Loss: 7.165    Value Loss: 5.243    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 1417372    Buffer Size: 20322      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:15:32,904][train][INFO][train.py>_log] ==> #463000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 6.821    Value Loss: 5.216    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1419934    Buffer Size: 20434      Transition Number: 1199.951k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:18:20,195][train][INFO][train.py>_log] ==> #464000     Total Loss: 3.951    [weighted Loss:3.951    Policy Loss: 6.433    Value Loss: 5.454    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1422505    Buffer Size: 20443      Transition Number: 1199.959k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:21:11,345][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.571    [weighted Loss:3.571    Policy Loss: 7.073    Value Loss: 5.187    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424991    Buffer Size: 20110      Transition Number: 1200.225k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:24:01,046][train][INFO][train.py>_log] ==> #466000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 6.662    Value Loss: 5.206    Reward Loss: 1.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 1427579    Buffer Size: 19785      Transition Number: 1200.244k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:26:50,668][train][INFO][train.py>_log] ==> #467000     Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 6.448    Value Loss: 5.038    Reward Loss: 1.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 1430204    Buffer Size: 19642      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:29:37,252][train][INFO][train.py>_log] ==> #468000     Total Loss: 1.389    [weighted Loss:1.389    Policy Loss: 7.072    Value Loss: 4.843    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1432680    Buffer Size: 19504      Transition Number: 1200.157k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:32:27,842][train][INFO][train.py>_log] ==> #469000     Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 6.926    Value Loss: 5.017    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435266    Buffer Size: 19318      Transition Number: 1200.142k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:35:17,170][train][INFO][train.py>_log] ==> #470000     Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 6.649    Value Loss: 4.932    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 1437861    Buffer Size: 19157      Transition Number: 1200.309k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:38:06,749][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.857    [weighted Loss:2.857    Policy Loss: 6.980    Value Loss: 5.009    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440665    Buffer Size: 19277      Transition Number: 1200.622k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:40:54,730][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 7.801    Value Loss: 5.218    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 1443422    Buffer Size: 19415      Transition Number: 1200.386k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:43:46,058][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 6.647    Value Loss: 5.098    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1446206    Buffer Size: 19622      Transition Number: 1200.310k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:46:37,257][train][INFO][train.py>_log] ==> #474000     Total Loss: 2.397    [weighted Loss:2.397    Policy Loss: 6.640    Value Loss: 5.224    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 1448982    Buffer Size: 19794      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:49:24,573][train][INFO][train.py>_log] ==> #475000     Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 6.901    Value Loss: 5.327    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451661    Buffer Size: 19891      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:52:12,982][train][INFO][train.py>_log] ==> #476000     Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 6.769    Value Loss: 5.494    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1454267    Buffer Size: 20004      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:55:03,573][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 6.607    Value Loss: 5.315    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1456829    Buffer Size: 20019      Transition Number: 1200.406k Batch Size: 256        Lr: 0.10000 
[2022-01-26 02:57:49,901][train][INFO][train.py>_log] ==> #478000     Total Loss: 1.779    [weighted Loss:1.779    Policy Loss: 7.022    Value Loss: 4.958    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 1459365    Buffer Size: 19859      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:00:37,174][train][INFO][train.py>_log] ==> #479000     Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 7.036    Value Loss: 5.219    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1461965    Buffer Size: 19709      Transition Number: 1200.325k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:03:25,871][train][INFO][train.py>_log] ==> #480000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 6.900    Value Loss: 5.105    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1464589    Buffer Size: 19570      Transition Number: 1200.114k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:06:16,227][train][INFO][train.py>_log] ==> #481000     Total Loss: 2.139    [weighted Loss:2.139    Policy Loss: 7.193    Value Loss: 5.164    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1467207    Buffer Size: 19494      Transition Number: 1200.587k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:09:03,162][train][INFO][train.py>_log] ==> #482000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 7.113    Value Loss: 5.215    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1469770    Buffer Size: 19454      Transition Number: 1200.500k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:11:48,971][train][INFO][train.py>_log] ==> #483000     Total Loss: 2.708    [weighted Loss:2.708    Policy Loss: 7.127    Value Loss: 4.792    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1472348    Buffer Size: 19452      Transition Number: 1200.275k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:14:36,285][train][INFO][train.py>_log] ==> #484000     Total Loss: 3.312    [weighted Loss:3.312    Policy Loss: 7.417    Value Loss: 5.443    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1474914    Buffer Size: 19540      Transition Number: 1200.187k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:17:24,540][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 7.680    Value Loss: 5.411    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1477689    Buffer Size: 19745      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:20:13,512][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 7.489    Value Loss: 5.514    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1480433    Buffer Size: 19931      Transition Number: 1200.163k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:23:02,516][train][INFO][train.py>_log] ==> #487000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 7.504    Value Loss: 5.286    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 1482979    Buffer Size: 19915      Transition Number: 1200.367k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:25:51,456][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 6.941    Value Loss: 5.119    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485516    Buffer Size: 19849      Transition Number: 1200.489k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:28:44,532][train][INFO][train.py>_log] ==> #489000     Total Loss: 3.453    [weighted Loss:3.453    Policy Loss: 7.012    Value Loss: 4.806    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1488189    Buffer Size: 19718      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:31:31,822][train][INFO][train.py>_log] ==> #490000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 7.084    Value Loss: 5.230    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1490721    Buffer Size: 19620      Transition Number: 1200.557k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:34:18,132][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 7.094    Value Loss: 5.226    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1493190    Buffer Size: 19502      Transition Number: 1201.164k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:37:04,983][train][INFO][train.py>_log] ==> #492000     Total Loss: 3.393    [weighted Loss:3.393    Policy Loss: 7.283    Value Loss: 4.902    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1495612    Buffer Size: 19364      Transition Number: 1200.451k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:39:54,417][train][INFO][train.py>_log] ==> #493000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 7.206    Value Loss: 4.985    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1498188    Buffer Size: 19209      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:42:43,538][train][INFO][train.py>_log] ==> #494000     Total Loss: 1.856    [weighted Loss:1.856    Policy Loss: 7.656    Value Loss: 5.210    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1500757    Buffer Size: 19193      Transition Number: 1200.220k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:45:33,374][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.914    [weighted Loss:2.914    Policy Loss: 7.575    Value Loss: 5.193    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 1503322    Buffer Size: 19315      Transition Number: 1200.124k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:48:21,761][train][INFO][train.py>_log] ==> #496000     Total Loss: 1.141    [weighted Loss:1.141    Policy Loss: 7.424    Value Loss: 5.185    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1505851    Buffer Size: 19462      Transition Number: 1200.186k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:51:12,348][train][INFO][train.py>_log] ==> #497000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 7.697    Value Loss: 5.436    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 1508671    Buffer Size: 19710      Transition Number: 1200.351k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:54:00,127][train][INFO][train.py>_log] ==> #498000     Total Loss: 0.935    [weighted Loss:0.935    Policy Loss: 7.575    Value Loss: 5.218    Reward Loss: 1.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 1511408    Buffer Size: 19961      Transition Number: 1200.286k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:56:47,644][train][INFO][train.py>_log] ==> #499000     Total Loss: 3.854    [weighted Loss:3.854    Policy Loss: 7.254    Value Loss: 5.400    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1514132    Buffer Size: 20202      Transition Number: 1200.131k Batch Size: 256        Lr: 0.10000 
[2022-01-26 03:59:36,911][train][INFO][train.py>_log] ==> #500000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 6.784    Value Loss: 5.248    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 1516897    Buffer Size: 20477      Transition Number: 1200.179k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:02:27,838][train][INFO][train.py>_log] ==> #501000     Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 7.035    Value Loss: 5.737    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 1519512    Buffer Size: 20540      Transition Number: 1200.008k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:05:14,267][train][INFO][train.py>_log] ==> #502000     Total Loss: 3.047    [weighted Loss:3.047    Policy Loss: 7.249    Value Loss: 5.422    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1522076    Buffer Size: 20574      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:08:03,883][train][INFO][train.py>_log] ==> #503000     Total Loss: 0.595    [weighted Loss:0.595    Policy Loss: 6.970    Value Loss: 5.886    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524739    Buffer Size: 20561      Transition Number: 1200.193k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:10:49,973][train][INFO][train.py>_log] ==> #504000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 7.470    Value Loss: 5.406    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1527232    Buffer Size: 20500      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:13:40,000][train][INFO][train.py>_log] ==> #505000     Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 6.784    Value Loss: 5.687    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1529869    Buffer Size: 20483      Transition Number: 1200.078k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:16:27,245][train][INFO][train.py>_log] ==> #506000     Total Loss: 3.132    [weighted Loss:3.132    Policy Loss: 6.757    Value Loss: 5.785    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1532475    Buffer Size: 20474      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:19:16,273][train][INFO][train.py>_log] ==> #507000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 7.039    Value Loss: 5.036    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1535223    Buffer Size: 20407      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:22:05,019][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 6.564    Value Loss: 5.662    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1537876    Buffer Size: 20359      Transition Number: 1199.976k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:24:56,157][train][INFO][train.py>_log] ==> #509000     Total Loss: 1.533    [weighted Loss:1.533    Policy Loss: 7.158    Value Loss: 5.696    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1540428    Buffer Size: 20324      Transition Number: 1200.269k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:27:43,875][train][INFO][train.py>_log] ==> #510000     Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 7.254    Value Loss: 5.442    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1543041    Buffer Size: 20292      Transition Number: 1200.158k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:30:32,286][train][INFO][train.py>_log] ==> #511000     Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 7.192    Value Loss: 5.261    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1545705    Buffer Size: 20381      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:33:21,355][train][INFO][train.py>_log] ==> #512000     Total Loss: 2.511    [weighted Loss:2.511    Policy Loss: 7.413    Value Loss: 5.627    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1548337    Buffer Size: 20418      Transition Number: 1200.333k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:36:12,591][train][INFO][train.py>_log] ==> #513000     Total Loss: 1.403    [weighted Loss:1.403    Policy Loss: 6.399    Value Loss: 5.466    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1551334    Buffer Size: 20629      Transition Number: 1200.264k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:39:00,464][train][INFO][train.py>_log] ==> #514000     Total Loss: 2.731    [weighted Loss:2.731    Policy Loss: 6.647    Value Loss: 5.736    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1554232    Buffer Size: 20859      Transition Number: 1200.038k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:41:47,274][train][INFO][train.py>_log] ==> #515000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 6.791    Value Loss: 5.359    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1556915    Buffer Size: 20968      Transition Number: 1200.067k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:44:33,308][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.321    [weighted Loss:2.321    Policy Loss: 6.663    Value Loss: 5.963    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 1559656    Buffer Size: 21089      Transition Number: 1200.272k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:47:23,198][train][INFO][train.py>_log] ==> #517000     Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 6.488    Value Loss: 5.614    Reward Loss: 1.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 1562345    Buffer Size: 21189      Transition Number: 1200.077k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:50:13,914][train][INFO][train.py>_log] ==> #518000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 6.847    Value Loss: 6.006    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1564990    Buffer Size: 21243      Transition Number: 1200.259k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:53:03,987][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 6.816    Value Loss: 5.618    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1567602    Buffer Size: 21138      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:55:54,378][train][INFO][train.py>_log] ==> #520000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 6.574    Value Loss: 5.424    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1570165    Buffer Size: 21040      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-26 04:58:44,043][train][INFO][train.py>_log] ==> #521000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 6.848    Value Loss: 5.866    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 1572808    Buffer Size: 20754      Transition Number: 1199.937k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:01:33,081][train][INFO][train.py>_log] ==> #522000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 7.051    Value Loss: 5.615    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1575431    Buffer Size: 20496      Transition Number: 1200.115k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:04:22,048][train][INFO][train.py>_log] ==> #523000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 6.743    Value Loss: 5.677    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1578503    Buffer Size: 20741      Transition Number: 1200.114k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:07:10,957][train][INFO][train.py>_log] ==> #524000     Total Loss: 1.977    [weighted Loss:1.977    Policy Loss: 6.362    Value Loss: 5.560    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1581495    Buffer Size: 20953      Transition Number: 1200.006k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:10:00,811][train][INFO][train.py>_log] ==> #525000     Total Loss: 3.063    [weighted Loss:3.063    Policy Loss: 6.612    Value Loss: 5.739    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 1584296    Buffer Size: 21094      Transition Number: 1200.009k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:12:47,959][train][INFO][train.py>_log] ==> #526000     Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 6.429    Value Loss: 5.718    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1586979    Buffer Size: 21238      Transition Number: 1200.349k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:15:38,367][train][INFO][train.py>_log] ==> #527000     Total Loss: 2.509    [weighted Loss:2.509    Policy Loss: 6.726    Value Loss: 5.695    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1589598    Buffer Size: 21229      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:18:30,081][train][INFO][train.py>_log] ==> #528000     Total Loss: 2.733    [weighted Loss:2.733    Policy Loss: 6.804    Value Loss: 5.460    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 1592258    Buffer Size: 21200      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:21:20,622][train][INFO][train.py>_log] ==> #529000     Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 6.952    Value Loss: 5.443    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1594796    Buffer Size: 21074      Transition Number: 1200.067k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:24:09,225][train][INFO][train.py>_log] ==> #530000     Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 6.720    Value Loss: 5.733    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1597302    Buffer Size: 20827      Transition Number: 1200.156k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:26:59,685][train][INFO][train.py>_log] ==> #531000     Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 7.253    Value Loss: 5.815    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1599861    Buffer Size: 20308      Transition Number: 1200.351k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:29:51,332][train][INFO][train.py>_log] ==> #532000     Total Loss: 1.932    [weighted Loss:1.932    Policy Loss: 6.637    Value Loss: 5.021    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 1602346    Buffer Size: 19888      Transition Number: 1200.204k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:32:41,063][train][INFO][train.py>_log] ==> #533000     Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 7.023    Value Loss: 5.261    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 1604938    Buffer Size: 19670      Transition Number: 1200.181k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:35:27,051][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 6.538    Value Loss: 5.243    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1607420    Buffer Size: 19537      Transition Number: 1200.383k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:38:14,283][train][INFO][train.py>_log] ==> #535000     Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 7.065    Value Loss: 5.177    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1610077    Buffer Size: 19648      Transition Number: 1200.081k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:41:04,095][train][INFO][train.py>_log] ==> #536000     Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 7.043    Value Loss: 5.278    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1612752    Buffer Size: 19780      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:43:56,366][train][INFO][train.py>_log] ==> #537000     Total Loss: 3.320    [weighted Loss:3.320    Policy Loss: 7.040    Value Loss: 5.395    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1615324    Buffer Size: 19803      Transition Number: 1200.133k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:46:45,988][train][INFO][train.py>_log] ==> #538000     Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 6.966    Value Loss: 5.316    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1617961    Buffer Size: 19840      Transition Number: 1200.030k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:49:39,659][train][INFO][train.py>_log] ==> #539000     Total Loss: 2.180    [weighted Loss:2.180    Policy Loss: 6.953    Value Loss: 5.410    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1620634    Buffer Size: 19971      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:52:31,534][train][INFO][train.py>_log] ==> #540000     Total Loss: 3.414    [weighted Loss:3.414    Policy Loss: 6.862    Value Loss: 6.052    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 1623328    Buffer Size: 20082      Transition Number: 1200.065k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:55:25,168][train][INFO][train.py>_log] ==> #541000     Total Loss: 3.328    [weighted Loss:3.328    Policy Loss: 6.970    Value Loss: 5.986    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1626044    Buffer Size: 20203      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-26 05:58:17,095][train][INFO][train.py>_log] ==> #542000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 7.320    Value Loss: 5.703    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1628796    Buffer Size: 20270      Transition Number: 1200.348k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:01:10,043][train][INFO][train.py>_log] ==> #543000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 6.798    Value Loss: 5.927    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1632200    Buffer Size: 20878      Transition Number: 1200.339k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:03:59,891][train][INFO][train.py>_log] ==> #544000     Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 6.784    Value Loss: 5.928    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1635602    Buffer Size: 21623      Transition Number: 1200.111k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:06:52,112][train][INFO][train.py>_log] ==> #545000     Total Loss: 2.425    [weighted Loss:2.425    Policy Loss: 6.665    Value Loss: 5.359    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1638466    Buffer Size: 21931      Transition Number: 1200.327k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:09:41,200][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.250    [weighted Loss:1.250    Policy Loss: 6.784    Value Loss: 5.842    Reward Loss: 1.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 1641322    Buffer Size: 22175      Transition Number: 1199.940k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:12:32,982][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.767    [weighted Loss:2.767    Policy Loss: 6.448    Value Loss: 5.693    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 1644424    Buffer Size: 22531      Transition Number: 1200.456k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:15:23,899][train][INFO][train.py>_log] ==> #548000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 6.664    Value Loss: 5.603    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 1647584    Buffer Size: 22867      Transition Number: 1200.165k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:18:14,269][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 6.637    Value Loss: 5.941    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 1650298    Buffer Size: 22829      Transition Number: 1200.372k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:21:06,028][train][INFO][train.py>_log] ==> #550000     Total Loss: 3.305    [weighted Loss:3.305    Policy Loss: 6.676    Value Loss: 5.850    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1653001    Buffer Size: 22497      Transition Number: 1199.977k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:23:55,504][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.019    [weighted Loss:3.019    Policy Loss: 7.038    Value Loss: 5.739    Reward Loss: 1.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 1655617    Buffer Size: 21653      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:26:45,628][train][INFO][train.py>_log] ==> #552000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 6.748    Value Loss: 5.268    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1658210    Buffer Size: 21030      Transition Number: 1199.989k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:29:38,643][train][INFO][train.py>_log] ==> #553000     Total Loss: 1.633    [weighted Loss:1.633    Policy Loss: 6.583    Value Loss: 5.376    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1661102    Buffer Size: 20960      Transition Number: 1200.356k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:32:29,157][train][INFO][train.py>_log] ==> #554000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 6.799    Value Loss: 4.996    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1663890    Buffer Size: 20824      Transition Number: 1200.441k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:35:20,877][train][INFO][train.py>_log] ==> #555000     Total Loss: 2.721    [weighted Loss:2.721    Policy Loss: 6.696    Value Loss: 5.106    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1666631    Buffer Size: 20512      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:38:10,971][train][INFO][train.py>_log] ==> #556000     Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 7.109    Value Loss: 5.065    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1669329    Buffer Size: 20339      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:41:02,079][train][INFO][train.py>_log] ==> #557000     Total Loss: 2.358    [weighted Loss:2.358    Policy Loss: 6.740    Value Loss: 5.479    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1672292    Buffer Size: 20558      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:43:51,104][train][INFO][train.py>_log] ==> #558000     Total Loss: 1.889    [weighted Loss:1.889    Policy Loss: 6.765    Value Loss: 5.572    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1675244    Buffer Size: 20841      Transition Number: 1200.043k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:46:39,416][train][INFO][train.py>_log] ==> #559000     Total Loss: 2.981    [weighted Loss:2.981    Policy Loss: 7.160    Value Loss: 5.986    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1677901    Buffer Size: 20989      Transition Number: 1199.953k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:49:28,561][train][INFO][train.py>_log] ==> #560000     Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 6.450    Value Loss: 5.693    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1680587    Buffer Size: 21037      Transition Number: 1200.068k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:52:20,611][train][INFO][train.py>_log] ==> #561000     Total Loss: 2.773    [weighted Loss:2.773    Policy Loss: 6.500    Value Loss: 5.571    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 1683209    Buffer Size: 20937      Transition Number: 1200.201k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:55:10,537][train][INFO][train.py>_log] ==> #562000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 6.632    Value Loss: 5.640    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 1685835    Buffer Size: 20829      Transition Number: 1200.083k Batch Size: 256        Lr: 0.10000 
[2022-01-26 06:58:04,294][train][INFO][train.py>_log] ==> #563000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 6.513    Value Loss: 5.513    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1688756    Buffer Size: 20989      Transition Number: 1200.358k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:00:51,966][train][INFO][train.py>_log] ==> #564000     Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 6.071    Value Loss: 5.889    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 1691554    Buffer Size: 21056      Transition Number: 1200.099k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:03:43,856][train][INFO][train.py>_log] ==> #565000     Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 5.554    Value Loss: 5.633    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1694253    Buffer Size: 20938      Transition Number: 1199.962k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:06:34,446][train][INFO][train.py>_log] ==> #566000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 6.057    Value Loss: 5.755    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1697072    Buffer Size: 20861      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:09:26,465][train][INFO][train.py>_log] ==> #567000     Total Loss: 3.588    [weighted Loss:3.588    Policy Loss: 6.023    Value Loss: 5.708    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1699760    Buffer Size: 20804      Transition Number: 1200.247k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:12:17,256][train][INFO][train.py>_log] ==> #568000     Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 6.388    Value Loss: 5.526    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1702327    Buffer Size: 20752      Transition Number: 1200.068k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:15:13,668][train][INFO][train.py>_log] ==> #569000     Total Loss: 1.411    [weighted Loss:1.411    Policy Loss: 6.528    Value Loss: 5.052    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1705097    Buffer Size: 20738      Transition Number: 1200.075k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:18:08,314][train][INFO][train.py>_log] ==> #570000     Total Loss: 1.543    [weighted Loss:1.543    Policy Loss: 6.499    Value Loss: 5.480    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1707871    Buffer Size: 20681      Transition Number: 1200.627k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:20:58,442][train][INFO][train.py>_log] ==> #571000     Total Loss: 3.475    [weighted Loss:3.475    Policy Loss: 6.283    Value Loss: 5.366    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1710684    Buffer Size: 20523      Transition Number: 1200.141k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:23:52,581][train][INFO][train.py>_log] ==> #572000     Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 5.496    Value Loss: 5.198    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1713440    Buffer Size: 20403      Transition Number: 1200.225k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:26:50,659][train][INFO][train.py>_log] ==> #573000     Total Loss: 1.989    [weighted Loss:1.989    Policy Loss: 6.230    Value Loss: 4.969    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1716120    Buffer Size: 20275      Transition Number: 1200.158k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:29:41,598][train][INFO][train.py>_log] ==> #574000     Total Loss: 2.199    [weighted Loss:2.199    Policy Loss: 5.955    Value Loss: 5.453    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 1718861    Buffer Size: 20220      Transition Number: 1200.051k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:32:35,370][train][INFO][train.py>_log] ==> #575000     Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 6.680    Value Loss: 5.335    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1721767    Buffer Size: 20449      Transition Number: 1200.032k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:35:27,157][train][INFO][train.py>_log] ==> #576000     Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 6.008    Value Loss: 5.371    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1724542    Buffer Size: 20615      Transition Number: 1200.348k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:38:18,327][train][INFO][train.py>_log] ==> #577000     Total Loss: 2.024    [weighted Loss:2.024    Policy Loss: 6.068    Value Loss: 5.359    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 1727268    Buffer Size: 20662      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:41:13,741][train][INFO][train.py>_log] ==> #578000     Total Loss: 1.800    [weighted Loss:1.800    Policy Loss: 6.783    Value Loss: 5.216    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1730019    Buffer Size: 20653      Transition Number: 1200.338k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:44:03,955][train][INFO][train.py>_log] ==> #579000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 6.067    Value Loss: 5.563    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1732635    Buffer Size: 20543      Transition Number: 1200.037k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:46:55,816][train][INFO][train.py>_log] ==> #580000     Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 6.180    Value Loss: 5.011    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 1735222    Buffer Size: 20469      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:49:49,062][train][INFO][train.py>_log] ==> #581000     Total Loss: 2.897    [weighted Loss:2.897    Policy Loss: 6.221    Value Loss: 5.387    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1737836    Buffer Size: 20379      Transition Number: 1200.341k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:52:40,595][train][INFO][train.py>_log] ==> #582000     Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 6.658    Value Loss: 5.557    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1740481    Buffer Size: 20154      Transition Number: 1200.444k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:55:32,425][train][INFO][train.py>_log] ==> #583000     Total Loss: 1.389    [weighted Loss:1.389    Policy Loss: 6.511    Value Loss: 5.346    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1743317    Buffer Size: 20029      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-26 07:58:24,444][train][INFO][train.py>_log] ==> #584000     Total Loss: 2.488    [weighted Loss:2.488    Policy Loss: 6.608    Value Loss: 5.185    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1746096    Buffer Size: 19960      Transition Number: 1200.397k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:01:21,248][train][INFO][train.py>_log] ==> #585000     Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 6.642    Value Loss: 5.186    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1749665    Buffer Size: 20631      Transition Number: 1200.622k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:04:12,120][train][INFO][train.py>_log] ==> #586000     Total Loss: 2.524    [weighted Loss:2.524    Policy Loss: 6.336    Value Loss: 5.750    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1753150    Buffer Size: 21381      Transition Number: 1200.247k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:07:04,993][train][INFO][train.py>_log] ==> #587000     Total Loss: 1.964    [weighted Loss:1.964    Policy Loss: 6.614    Value Loss: 5.644    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1756373    Buffer Size: 21897      Transition Number: 1199.972k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:10:00,932][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 6.584    Value Loss: 5.945    Reward Loss: 1.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 1759576    Buffer Size: 22391      Transition Number: 1200.078k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:12:56,965][train][INFO][train.py>_log] ==> #589000     Total Loss: 0.873    [weighted Loss:0.873    Policy Loss: 6.080    Value Loss: 6.125    Reward Loss: 1.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 1762502    Buffer Size: 22626      Transition Number: 1200.453k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:15:51,845][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 6.397    Value Loss: 6.069    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1765368    Buffer Size: 22709      Transition Number: 1200.468k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:18:45,214][train][INFO][train.py>_log] ==> #591000     Total Loss: 1.146    [weighted Loss:1.146    Policy Loss: 6.148    Value Loss: 5.751    Reward Loss: 1.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 1768110    Buffer Size: 22661      Transition Number: 1200.090k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:21:40,707][train][INFO][train.py>_log] ==> #592000     Total Loss: 2.368    [weighted Loss:2.368    Policy Loss: 6.116    Value Loss: 5.741    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 1770898    Buffer Size: 22105      Transition Number: 1200.045k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:24:43,273][train][INFO][train.py>_log] ==> #593000     Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 6.213    Value Loss: 5.429    Reward Loss: 1.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 1773623    Buffer Size: 21447      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:27:40,062][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 6.268    Value Loss: 6.021    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 1776363    Buffer Size: 20943      Transition Number: 1200.375k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:30:39,002][train][INFO][train.py>_log] ==> #595000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 5.898    Value Loss: 4.979    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1779063    Buffer Size: 20502      Transition Number: 1200.203k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:33:40,032][train][INFO][train.py>_log] ==> #596000     Total Loss: 2.648    [weighted Loss:2.648    Policy Loss: 6.312    Value Loss: 5.139    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1781779    Buffer Size: 20242      Transition Number: 1199.960k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:36:37,479][train][INFO][train.py>_log] ==> #597000     Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 6.206    Value Loss: 5.106    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 1784586    Buffer Size: 20150      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:39:29,457][train][INFO][train.py>_log] ==> #598000     Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 6.857    Value Loss: 5.197    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1787184    Buffer Size: 20156      Transition Number: 1199.978k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:42:22,893][train][INFO][train.py>_log] ==> #599000     Total Loss: 3.014    [weighted Loss:3.014    Policy Loss: 6.585    Value Loss: 5.471    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 1790054    Buffer Size: 20280      Transition Number: 1200.230k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:45:20,720][train][INFO][train.py>_log] ==> #600000     Total Loss: 0.847    [weighted Loss:0.847    Policy Loss: 6.877    Value Loss: 5.521    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1792968    Buffer Size: 20355      Transition Number: 1200.067k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:48:22,972][train][INFO][train.py>_log] ==> #601000     Total Loss: 2.385    [weighted Loss:2.385    Policy Loss: 6.151    Value Loss: 5.679    Reward Loss: 1.875    Consistency Loss: 0.000    ] Replay Episodes Collected: 1795990    Buffer Size: 20467      Transition Number: 1200.045k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:51:26,531][train][INFO][train.py>_log] ==> #602000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 6.653    Value Loss: 5.366    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1799041    Buffer Size: 20620      Transition Number: 1200.247k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:54:25,874][train][INFO][train.py>_log] ==> #603000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 6.371    Value Loss: 5.423    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1801966    Buffer Size: 20782      Transition Number: 1200.102k Batch Size: 256        Lr: 0.10000 
[2022-01-26 08:57:19,846][train][INFO][train.py>_log] ==> #604000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 6.730    Value Loss: 5.072    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1804916    Buffer Size: 20898      Transition Number: 1199.943k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:00:19,855][train][INFO][train.py>_log] ==> #605000     Total Loss: 1.370    [weighted Loss:1.370    Policy Loss: 5.965    Value Loss: 5.685    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1807807    Buffer Size: 20978      Transition Number: 1200.048k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:03:13,956][train][INFO][train.py>_log] ==> #606000     Total Loss: 2.501    [weighted Loss:2.501    Policy Loss: 6.057    Value Loss: 5.637    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 1810742    Buffer Size: 20989      Transition Number: 1200.043k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:06:09,886][train][INFO][train.py>_log] ==> #607000     Total Loss: 2.102    [weighted Loss:2.102    Policy Loss: 6.809    Value Loss: 5.404    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1813864    Buffer Size: 21189      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:09:09,520][train][INFO][train.py>_log] ==> #608000     Total Loss: 0.670    [weighted Loss:0.670    Policy Loss: 5.864    Value Loss: 4.951    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1817029    Buffer Size: 21367      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:12:06,832][train][INFO][train.py>_log] ==> #609000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 6.273    Value Loss: 5.610    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1819800    Buffer Size: 21285      Transition Number: 1200.054k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:15:00,747][train][INFO][train.py>_log] ==> #610000     Total Loss: 1.506    [weighted Loss:1.506    Policy Loss: 6.522    Value Loss: 5.630    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1822537    Buffer Size: 21232      Transition Number: 1200.043k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:17:54,355][train][INFO][train.py>_log] ==> #611000     Total Loss: 2.086    [weighted Loss:2.086    Policy Loss: 6.190    Value Loss: 5.252    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1825283    Buffer Size: 21106      Transition Number: 1200.169k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:20:47,956][train][INFO][train.py>_log] ==> #612000     Total Loss: 1.538    [weighted Loss:1.538    Policy Loss: 6.388    Value Loss: 5.158    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1827919    Buffer Size: 21007      Transition Number: 1200.246k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:23:44,231][train][INFO][train.py>_log] ==> #613000     Total Loss: 1.734    [weighted Loss:1.734    Policy Loss: 6.623    Value Loss: 5.744    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 1830842    Buffer Size: 21030      Transition Number: 1199.983k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:26:40,130][train][INFO][train.py>_log] ==> #614000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 6.736    Value Loss: 5.340    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 1833701    Buffer Size: 20911      Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:29:33,831][train][INFO][train.py>_log] ==> #615000     Total Loss: 1.180    [weighted Loss:1.180    Policy Loss: 6.389    Value Loss: 5.466    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1836551    Buffer Size: 20741      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:32:28,012][train][INFO][train.py>_log] ==> #616000     Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 6.000    Value Loss: 5.382    Reward Loss: 1.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 1839346    Buffer Size: 20681      Transition Number: 1200.041k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:35:26,579][train][INFO][train.py>_log] ==> #617000     Total Loss: 1.817    [weighted Loss:1.817    Policy Loss: 6.140    Value Loss: 5.392    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1842230    Buffer Size: 20731      Transition Number: 1200.011k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:38:18,783][train][INFO][train.py>_log] ==> #618000     Total Loss: 2.883    [weighted Loss:2.883    Policy Loss: 5.809    Value Loss: 5.678    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1844996    Buffer Size: 20773      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:41:13,329][train][INFO][train.py>_log] ==> #619000     Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 6.486    Value Loss: 5.278    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1847848    Buffer Size: 20823      Transition Number: 1199.947k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:44:07,940][train][INFO][train.py>_log] ==> #620000     Total Loss: 2.460    [weighted Loss:2.460    Policy Loss: 5.804    Value Loss: 5.424    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1850653    Buffer Size: 20840      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:47:08,243][train][INFO][train.py>_log] ==> #621000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 5.820    Value Loss: 5.236    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1853515    Buffer Size: 20769      Transition Number: 1200.352k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:50:01,756][train][INFO][train.py>_log] ==> #622000     Total Loss: 2.637    [weighted Loss:2.637    Policy Loss: 6.889    Value Loss: 5.477    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1856280    Buffer Size: 20666      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:52:54,709][train][INFO][train.py>_log] ==> #623000     Total Loss: 1.998    [weighted Loss:1.998    Policy Loss: 7.066    Value Loss: 5.718    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 1859788    Buffer Size: 21379      Transition Number: 1200.195k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:55:46,523][train][INFO][train.py>_log] ==> #624000     Total Loss: 1.137    [weighted Loss:1.137    Policy Loss: 5.929    Value Loss: 5.718    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1863334    Buffer Size: 22142      Transition Number: 1200.284k Batch Size: 256        Lr: 0.10000 
[2022-01-26 09:58:43,532][train][INFO][train.py>_log] ==> #625000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 5.892    Value Loss: 6.099    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1866594    Buffer Size: 22426      Transition Number: 1200.659k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:01:37,020][train][INFO][train.py>_log] ==> #626000     Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 5.490    Value Loss: 5.739    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1869724    Buffer Size: 22678      Transition Number: 1200.219k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:04:30,893][train][INFO][train.py>_log] ==> #627000     Total Loss: 2.350    [weighted Loss:2.350    Policy Loss: 5.473    Value Loss: 5.811    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 1872511    Buffer Size: 22662      Transition Number: 1200.076k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:07:26,043][train][INFO][train.py>_log] ==> #628000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 5.326    Value Loss: 5.507    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1875289    Buffer Size: 22668      Transition Number: 1200.058k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:10:24,732][train][INFO][train.py>_log] ==> #629000     Total Loss: 1.952    [weighted Loss:1.952    Policy Loss: 5.555    Value Loss: 5.856    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 1878312    Buffer Size: 22880      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:13:26,008][train][INFO][train.py>_log] ==> #630000     Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 5.717    Value Loss: 5.975    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 1881449    Buffer Size: 22555      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:16:28,576][train][INFO][train.py>_log] ==> #631000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 5.763    Value Loss: 5.445    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 1884386    Buffer Size: 21659      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:19:32,034][train][INFO][train.py>_log] ==> #632000     Total Loss: 2.436    [weighted Loss:2.436    Policy Loss: 5.654    Value Loss: 5.142    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 1887319    Buffer Size: 21200      Transition Number: 1200.030k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:22:39,675][train][INFO][train.py>_log] ==> #633000     Total Loss: 2.337    [weighted Loss:2.337    Policy Loss: 5.950    Value Loss: 5.307    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 1890173    Buffer Size: 20765      Transition Number: 1200.465k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:25:43,065][train][INFO][train.py>_log] ==> #634000     Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 7.442    Value Loss: 5.136    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 1892998    Buffer Size: 20570      Transition Number: 1199.966k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:28:45,652][train][INFO][train.py>_log] ==> #635000     Total Loss: 1.623    [weighted Loss:1.623    Policy Loss: 5.726    Value Loss: 5.667    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1895912    Buffer Size: 20545      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:31:47,688][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.974    [weighted Loss:2.974    Policy Loss: 6.489    Value Loss: 5.550    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1898824    Buffer Size: 20315      Transition Number: 1200.019k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:34:52,052][train][INFO][train.py>_log] ==> #637000     Total Loss: 1.490    [weighted Loss:1.490    Policy Loss: 5.924    Value Loss: 5.111    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1901979    Buffer Size: 20314      Transition Number: 1200.605k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:37:56,032][train][INFO][train.py>_log] ==> #638000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 6.794    Value Loss: 5.476    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1905216    Buffer Size: 20528      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:40:57,639][train][INFO][train.py>_log] ==> #639000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 6.721    Value Loss: 5.816    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1908358    Buffer Size: 20836      Transition Number: 1200.158k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:44:00,176][train][INFO][train.py>_log] ==> #640000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 6.061    Value Loss: 5.772    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 1911577    Buffer Size: 21222      Transition Number: 1200.071k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:47:03,329][train][INFO][train.py>_log] ==> #641000     Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 6.428    Value Loss: 6.347    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 1914494    Buffer Size: 21492      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:50:05,272][train][INFO][train.py>_log] ==> #642000     Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 6.279    Value Loss: 5.888    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1917457    Buffer Size: 21600      Transition Number: 1200.187k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:53:06,208][train][INFO][train.py>_log] ==> #643000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 6.183    Value Loss: 5.960    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1920213    Buffer Size: 21549      Transition Number: 1200.337k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:56:07,881][train][INFO][train.py>_log] ==> #644000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 6.241    Value Loss: 5.702    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1922912    Buffer Size: 21322      Transition Number: 1200.466k Batch Size: 256        Lr: 0.10000 
[2022-01-26 10:59:12,981][train][INFO][train.py>_log] ==> #645000     Total Loss: 2.658    [weighted Loss:2.658    Policy Loss: 6.005    Value Loss: 5.415    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1926070    Buffer Size: 21205      Transition Number: 1200.565k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:02:14,209][train][INFO][train.py>_log] ==> #646000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 5.769    Value Loss: 5.432    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 1929069    Buffer Size: 21027      Transition Number: 1200.199k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:05:16,148][train][INFO][train.py>_log] ==> #647000     Total Loss: 2.108    [weighted Loss:2.108    Policy Loss: 5.945    Value Loss: 5.639    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 1932134    Buffer Size: 20926      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:08:15,877][train][INFO][train.py>_log] ==> #648000     Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 6.279    Value Loss: 5.593    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1935049    Buffer Size: 20930      Transition Number: 1200.138k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:11:13,351][train][INFO][train.py>_log] ==> #649000     Total Loss: 2.046    [weighted Loss:2.046    Policy Loss: 6.025    Value Loss: 5.542    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 1937985    Buffer Size: 20850      Transition Number: 1200.086k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:14:15,320][train][INFO][train.py>_log] ==> #650000     Total Loss: 1.648    [weighted Loss:1.648    Policy Loss: 6.782    Value Loss: 5.273    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1940923    Buffer Size: 20919      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:17:14,618][train][INFO][train.py>_log] ==> #651000     Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 6.298    Value Loss: 5.391    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 1944086    Buffer Size: 21204      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:20:11,256][train][INFO][train.py>_log] ==> #652000     Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 6.131    Value Loss: 5.812    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1947244    Buffer Size: 21339      Transition Number: 1199.975k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:23:13,241][train][INFO][train.py>_log] ==> #653000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 5.857    Value Loss: 5.424    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1950201    Buffer Size: 21326      Transition Number: 1200.248k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:26:14,875][train][INFO][train.py>_log] ==> #654000     Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 5.863    Value Loss: 5.335    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 1953248    Buffer Size: 21277      Transition Number: 1200.007k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:29:16,496][train][INFO][train.py>_log] ==> #655000     Total Loss: 1.516    [weighted Loss:1.516    Policy Loss: 6.499    Value Loss: 5.796    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1956176    Buffer Size: 21199      Transition Number: 1200.096k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:32:14,788][train][INFO][train.py>_log] ==> #656000     Total Loss: 1.848    [weighted Loss:1.848    Policy Loss: 5.918    Value Loss: 5.675    Reward Loss: 1.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 1959022    Buffer Size: 21199      Transition Number: 1199.992k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:35:17,211][train][INFO][train.py>_log] ==> #657000     Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 6.633    Value Loss: 5.818    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1961947    Buffer Size: 21112      Transition Number: 1200.184k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:38:19,635][train][INFO][train.py>_log] ==> #658000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 6.047    Value Loss: 5.786    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 1964785    Buffer Size: 20845      Transition Number: 1200.046k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:41:20,815][train][INFO][train.py>_log] ==> #659000     Total Loss: 2.641    [weighted Loss:2.641    Policy Loss: 5.937    Value Loss: 5.779    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1967695    Buffer Size: 20712      Transition Number: 1199.944k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:44:20,440][train][INFO][train.py>_log] ==> #660000     Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 6.253    Value Loss: 5.666    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1970610    Buffer Size: 20718      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:47:21,304][train][INFO][train.py>_log] ==> #661000     Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 5.801    Value Loss: 5.382    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1973618    Buffer Size: 20770      Transition Number: 1200.237k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:50:23,218][train][INFO][train.py>_log] ==> #662000     Total Loss: 2.235    [weighted Loss:2.235    Policy Loss: 5.972    Value Loss: 5.546    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1976750    Buffer Size: 20822      Transition Number: 1200.146k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:53:18,205][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 6.261    Value Loss: 5.148    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1979715    Buffer Size: 20953      Transition Number: 1200.092k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:56:14,038][train][INFO][train.py>_log] ==> #664000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 5.837    Value Loss: 5.512    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 1982614    Buffer Size: 21152      Transition Number: 1200.085k Batch Size: 256        Lr: 0.10000 
[2022-01-26 11:59:10,743][train][INFO][train.py>_log] ==> #665000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 6.486    Value Loss: 5.311    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 1985389    Buffer Size: 21178      Transition Number: 1200.205k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:02:03,647][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.630    [weighted Loss:2.630    Policy Loss: 6.585    Value Loss: 5.461    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1988134    Buffer Size: 21100      Transition Number: 1200.380k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:04:59,192][train][INFO][train.py>_log] ==> #667000     Total Loss: 1.318    [weighted Loss:1.318    Policy Loss: 5.971    Value Loss: 5.052    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1990962    Buffer Size: 21010      Transition Number: 1200.349k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:07:54,249][train][INFO][train.py>_log] ==> #668000     Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 5.984    Value Loss: 5.537    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 1993791    Buffer Size: 20911      Transition Number: 1200.205k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:10:49,777][train][INFO][train.py>_log] ==> #669000     Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 6.203    Value Loss: 5.396    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1996504    Buffer Size: 20716      Transition Number: 1200.253k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:13:44,398][train][INFO][train.py>_log] ==> #670000     Total Loss: 1.226    [weighted Loss:1.226    Policy Loss: 5.773    Value Loss: 5.337    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1999215    Buffer Size: 20527      Transition Number: 1199.994k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:16:37,730][train][INFO][train.py>_log] ==> #671000     Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 6.084    Value Loss: 5.784    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2002163    Buffer Size: 20570      Transition Number: 1200.165k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:19:30,967][train][INFO][train.py>_log] ==> #672000     Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 5.797    Value Loss: 5.361    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 2005073    Buffer Size: 20716      Transition Number: 1200.358k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:22:26,939][train][INFO][train.py>_log] ==> #673000     Total Loss: 2.628    [weighted Loss:2.628    Policy Loss: 6.730    Value Loss: 5.627    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 2007895    Buffer Size: 20840      Transition Number: 1200.297k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:25:20,019][train][INFO][train.py>_log] ==> #674000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 6.164    Value Loss: 5.643    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2010718    Buffer Size: 20934      Transition Number: 1200.059k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:28:12,655][train][INFO][train.py>_log] ==> #675000     Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 6.488    Value Loss: 5.830    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 2013680    Buffer Size: 21110      Transition Number: 1200.094k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:31:04,141][train][INFO][train.py>_log] ==> #676000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 6.045    Value Loss: 5.761    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2016563    Buffer Size: 21293      Transition Number: 1200.081k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:33:58,782][train][INFO][train.py>_log] ==> #677000     Total Loss: 2.593    [weighted Loss:2.593    Policy Loss: 6.323    Value Loss: 5.651    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 2019375    Buffer Size: 21411      Transition Number: 1200.052k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:36:51,635][train][INFO][train.py>_log] ==> #678000     Total Loss: 1.941    [weighted Loss:1.941    Policy Loss: 6.353    Value Loss: 5.813    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 2022188    Buffer Size: 21432      Transition Number: 1200.037k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:39:47,585][train][INFO][train.py>_log] ==> #679000     Total Loss: 1.703    [weighted Loss:1.703    Policy Loss: 6.403    Value Loss: 5.573    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 2025125    Buffer Size: 21382      Transition Number: 1200.276k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:42:40,704][train][INFO][train.py>_log] ==> #680000     Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 6.460    Value Loss: 6.234    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 2027944    Buffer Size: 21375      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:45:35,185][train][INFO][train.py>_log] ==> #681000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 6.503    Value Loss: 5.940    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 2030992    Buffer Size: 21630      Transition Number: 1200.102k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:48:28,836][train][INFO][train.py>_log] ==> #682000     Total Loss: 1.333    [weighted Loss:1.333    Policy Loss: 6.690    Value Loss: 5.619    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 2034033    Buffer Size: 21873      Transition Number: 1200.053k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:51:23,626][train][INFO][train.py>_log] ==> #683000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 5.936    Value Loss: 6.051    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2036787    Buffer Size: 21754      Transition Number: 1199.961k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:54:21,584][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.046    [weighted Loss:2.046    Policy Loss: 6.208    Value Loss: 5.622    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 2039581    Buffer Size: 21655      Transition Number: 1200.072k Batch Size: 256        Lr: 0.10000 
[2022-01-26 12:57:16,273][train][INFO][train.py>_log] ==> #685000     Total Loss: 1.987    [weighted Loss:1.987    Policy Loss: 5.761    Value Loss: 5.856    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2042384    Buffer Size: 21551      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:00:11,018][train][INFO][train.py>_log] ==> #686000     Total Loss: 1.757    [weighted Loss:1.757    Policy Loss: 6.127    Value Loss: 5.887    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 2045220    Buffer Size: 21425      Transition Number: 1200.014k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:03:06,431][train][INFO][train.py>_log] ==> #687000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 5.775    Value Loss: 5.993    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 2048200    Buffer Size: 21440      Transition Number: 1200.086k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:06:00,501][train][INFO][train.py>_log] ==> #688000     Total Loss: 0.993    [weighted Loss:0.993    Policy Loss: 5.404    Value Loss: 5.585    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 2051139    Buffer Size: 21381      Transition Number: 1200.161k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:08:55,997][train][INFO][train.py>_log] ==> #689000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 5.515    Value Loss: 5.590    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 2054060    Buffer Size: 21122      Transition Number: 1200.153k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:11:50,259][train][INFO][train.py>_log] ==> #690000     Total Loss: 1.711    [weighted Loss:1.711    Policy Loss: 6.907    Value Loss: 5.541    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2056966    Buffer Size: 21077      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:14:42,322][train][INFO][train.py>_log] ==> #691000     Total Loss: 1.584    [weighted Loss:1.584    Policy Loss: 5.858    Value Loss: 6.242    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 2060351    Buffer Size: 21605      Transition Number: 1200.278k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:17:36,466][train][INFO][train.py>_log] ==> #692000     Total Loss: 1.753    [weighted Loss:1.753    Policy Loss: 6.503    Value Loss: 6.200    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2063728    Buffer Size: 22184      Transition Number: 1200.117k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:20:28,756][train][INFO][train.py>_log] ==> #693000     Total Loss: 3.278    [weighted Loss:3.278    Policy Loss: 6.430    Value Loss: 6.215    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 2066499    Buffer Size: 22314      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:23:21,764][train][INFO][train.py>_log] ==> #694000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 5.788    Value Loss: 5.717    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 2069370    Buffer Size: 22340      Transition Number: 1200.119k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:26:17,368][train][INFO][train.py>_log] ==> #695000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 6.081    Value Loss: 6.227    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 2072693    Buffer Size: 22681      Transition Number: 1200.173k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:29:10,442][train][INFO][train.py>_log] ==> #696000     Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 5.982    Value Loss: 6.391    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 2075863    Buffer Size: 23076      Transition Number: 1200.182k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:32:03,105][train][INFO][train.py>_log] ==> #697000     Total Loss: 2.382    [weighted Loss:2.382    Policy Loss: 6.280    Value Loss: 6.190    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 2078722    Buffer Size: 23125      Transition Number: 1200.384k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:34:58,685][train][INFO][train.py>_log] ==> #698000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 6.048    Value Loss: 6.063    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2081617    Buffer Size: 22901      Transition Number: 1200.568k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:37:53,349][train][INFO][train.py>_log] ==> #699000     Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 6.338    Value Loss: 5.846    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 2084315    Buffer Size: 22290      Transition Number: 1200.102k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:40:46,488][train][INFO][train.py>_log] ==> #700000     Total Loss: 3.039    [weighted Loss:3.039    Policy Loss: 6.366    Value Loss: 5.862    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 2087047    Buffer Size: 21856      Transition Number: 1200.208k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:43:40,358][train][INFO][train.py>_log] ==> #701000     Total Loss: 1.980    [weighted Loss:1.980    Policy Loss: 6.377    Value Loss: 5.405    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2089774    Buffer Size: 21754      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:46:33,075][train][INFO][train.py>_log] ==> #702000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 6.383    Value Loss: 5.401    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 2092513    Buffer Size: 21421      Transition Number: 1200.194k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:49:24,914][train][INFO][train.py>_log] ==> #703000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 5.818    Value Loss: 5.602    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 2095432    Buffer Size: 21055      Transition Number: 1200.247k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:52:18,218][train][INFO][train.py>_log] ==> #704000     Total Loss: 1.444    [weighted Loss:1.444    Policy Loss: 5.849    Value Loss: 5.496    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2098226    Buffer Size: 20892      Transition Number: 1200.514k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:55:14,456][train][INFO][train.py>_log] ==> #705000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 5.668    Value Loss: 5.442    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 2101116    Buffer Size: 20813      Transition Number: 1200.165k Batch Size: 256        Lr: 0.10000 
[2022-01-26 13:58:07,677][train][INFO][train.py>_log] ==> #706000     Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 6.091    Value Loss: 5.296    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2103981    Buffer Size: 20869      Transition Number: 1200.112k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:00:57,648][train][INFO][train.py>_log] ==> #707000     Total Loss: 3.188    [weighted Loss:3.188    Policy Loss: 6.470    Value Loss: 5.958    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2106696    Buffer Size: 21046      Transition Number: 1199.996k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:03:51,821][train][INFO][train.py>_log] ==> #708000     Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 5.635    Value Loss: 5.729    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2109571    Buffer Size: 21219      Transition Number: 1200.106k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:06:47,583][train][INFO][train.py>_log] ==> #709000     Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 5.932    Value Loss: 5.644    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2112322    Buffer Size: 21255      Transition Number: 1199.993k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:09:41,369][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.130    [weighted Loss:2.130    Policy Loss: 6.628    Value Loss: 5.660    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 2115049    Buffer Size: 21242      Transition Number: 1200.186k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:12:35,573][train][INFO][train.py>_log] ==> #711000     Total Loss: 2.243    [weighted Loss:2.243    Policy Loss: 7.343    Value Loss: 6.433    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 2119055    Buffer Size: 22184      Transition Number: 1200.076k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:15:28,655][train][INFO][train.py>_log] ==> #712000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 6.820    Value Loss: 6.170    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 2123053    Buffer Size: 23252      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:18:21,314][train][INFO][train.py>_log] ==> #713000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 6.287    Value Loss: 6.162    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 2126221    Buffer Size: 23659      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:21:20,213][train][INFO][train.py>_log] ==> #714000     Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 6.529    Value Loss: 6.509    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 2129580    Buffer Size: 24058      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:24:21,112][train][INFO][train.py>_log] ==> #715000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 6.203    Value Loss: 6.353    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 2132870    Buffer Size: 24376      Transition Number: 1200.056k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:27:20,785][train][INFO][train.py>_log] ==> #716000     Total Loss: 2.269    [weighted Loss:2.269    Policy Loss: 5.901    Value Loss: 6.381    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2136103    Buffer Size: 24748      Transition Number: 1200.060k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:30:17,615][train][INFO][train.py>_log] ==> #717000     Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 5.978    Value Loss: 6.054    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 2138876    Buffer Size: 24775      Transition Number: 1200.392k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:33:16,442][train][INFO][train.py>_log] ==> #718000     Total Loss: 3.067    [weighted Loss:3.067    Policy Loss: 6.224    Value Loss: 6.130    Reward Loss: 1.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 2141713    Buffer Size: 24068      Transition Number: 1200.037k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:36:11,932][train][INFO][train.py>_log] ==> #719000     Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 5.408    Value Loss: 6.117    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 2144717    Buffer Size: 23115      Transition Number: 1200.076k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:39:09,627][train][INFO][train.py>_log] ==> #720000     Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 6.117    Value Loss: 5.892    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 2147817    Buffer Size: 22623      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:42:10,152][train][INFO][train.py>_log] ==> #721000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 5.859    Value Loss: 5.917    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 2150995    Buffer Size: 22409      Transition Number: 1200.262k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:45:06,889][train][INFO][train.py>_log] ==> #722000     Total Loss: 1.106    [weighted Loss:1.106    Policy Loss: 5.724    Value Loss: 5.514    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2154147    Buffer Size: 22275      Transition Number: 1200.187k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:48:04,783][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 5.993    Value Loss: 5.673    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2157474    Buffer Size: 22324      Transition Number: 1200.123k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:51:00,222][train][INFO][train.py>_log] ==> #724000     Total Loss: 1.201    [weighted Loss:1.201    Policy Loss: 5.660    Value Loss: 5.775    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 2160784    Buffer Size: 22658      Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:53:57,546][train][INFO][train.py>_log] ==> #725000     Total Loss: 1.555    [weighted Loss:1.555    Policy Loss: 6.138    Value Loss: 6.043    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 2163921    Buffer Size: 23085      Transition Number: 1200.327k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:56:52,994][train][INFO][train.py>_log] ==> #726000     Total Loss: 2.785    [weighted Loss:2.785    Policy Loss: 6.660    Value Loss: 6.249    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 2167054    Buffer Size: 23328      Transition Number: 1199.985k Batch Size: 256        Lr: 0.10000 
[2022-01-26 14:59:46,322][train][INFO][train.py>_log] ==> #727000     Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 6.055    Value Loss: 6.058    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 2169924    Buffer Size: 23230      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:02:39,652][train][INFO][train.py>_log] ==> #728000     Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 6.511    Value Loss: 6.067    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 2172769    Buffer Size: 23084      Transition Number: 1200.204k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:05:36,082][train][INFO][train.py>_log] ==> #729000     Total Loss: 2.853    [weighted Loss:2.853    Policy Loss: 6.449    Value Loss: 6.059    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 2175482    Buffer Size: 22790      Transition Number: 1200.128k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:08:29,496][train][INFO][train.py>_log] ==> #730000     Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 6.312    Value Loss: 5.870    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 2178211    Buffer Size: 22429      Transition Number: 1200.044k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:11:22,348][train][INFO][train.py>_log] ==> #731000     Total Loss: 1.393    [weighted Loss:1.393    Policy Loss: 6.141    Value Loss: 5.725    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2181427    Buffer Size: 22483      Transition Number: 1200.417k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:14:17,442][train][INFO][train.py>_log] ==> #732000     Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 6.339    Value Loss: 6.043    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 2184659    Buffer Size: 22551      Transition Number: 1200.209k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:17:15,518][train][INFO][train.py>_log] ==> #733000     Total Loss: 1.846    [weighted Loss:1.846    Policy Loss: 5.613    Value Loss: 6.026    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 2187406    Buffer Size: 22243      Transition Number: 1200.236k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:20:11,941][train][INFO][train.py>_log] ==> #734000     Total Loss: 2.192    [weighted Loss:2.192    Policy Loss: 6.216    Value Loss: 5.546    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 2190138    Buffer Size: 21918      Transition Number: 1200.295k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:23:07,752][train][INFO][train.py>_log] ==> #735000     Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 6.205    Value Loss: 5.557    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 2192992    Buffer Size: 21876      Transition Number: 1200.463k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:26:02,436][train][INFO][train.py>_log] ==> #736000     Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 5.519    Value Loss: 5.689    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 2195859    Buffer Size: 21854      Transition Number: 1199.974k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:28:59,872][train][INFO][train.py>_log] ==> #737000     Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 5.778    Value Loss: 5.558    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 2198781    Buffer Size: 21933      Transition Number: 1200.177k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:31:56,169][train][INFO][train.py>_log] ==> #738000     Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 6.328    Value Loss: 5.801    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2201736    Buffer Size: 21759      Transition Number: 1200.062k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:34:53,052][train][INFO][train.py>_log] ==> #739000     Total Loss: 1.836    [weighted Loss:1.836    Policy Loss: 6.159    Value Loss: 5.555    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2204722    Buffer Size: 21367      Transition Number: 1200.155k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:37:49,606][train][INFO][train.py>_log] ==> #740000     Total Loss: 2.606    [weighted Loss:2.606    Policy Loss: 6.615    Value Loss: 6.118    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 2207709    Buffer Size: 21276      Transition Number: 1200.351k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:40:48,149][train][INFO][train.py>_log] ==> #741000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 5.693    Value Loss: 5.339    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 2210625    Buffer Size: 21265      Transition Number: 1200.365k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:43:47,840][train][INFO][train.py>_log] ==> #742000     Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 5.662    Value Loss: 5.264    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 2213540    Buffer Size: 21196      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:46:47,028][train][INFO][train.py>_log] ==> #743000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 6.354    Value Loss: 5.458    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2216458    Buffer Size: 21110      Transition Number: 1200.075k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:49:45,153][train][INFO][train.py>_log] ==> #744000     Total Loss: 0.760    [weighted Loss:0.760    Policy Loss: 7.006    Value Loss: 5.617    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 2219295    Buffer Size: 21021      Transition Number: 1200.305k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:52:47,036][train][INFO][train.py>_log] ==> #745000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 6.778    Value Loss: 5.677    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 2222450    Buffer Size: 21127      Transition Number: 1200.216k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:55:44,007][train][INFO][train.py>_log] ==> #746000     Total Loss: 2.604    [weighted Loss:2.604    Policy Loss: 6.855    Value Loss: 5.834    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2225484    Buffer Size: 21214      Transition Number: 1200.038k Batch Size: 256        Lr: 0.10000 
[2022-01-26 15:58:42,409][train][INFO][train.py>_log] ==> #747000     Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 6.666    Value Loss: 5.776    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 2228561    Buffer Size: 21373      Transition Number: 1200.041k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:01:39,619][train][INFO][train.py>_log] ==> #748000     Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 6.722    Value Loss: 5.697    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2231658    Buffer Size: 21654      Transition Number: 1200.166k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:04:39,954][train][INFO][train.py>_log] ==> #749000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 5.882    Value Loss: 5.842    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 2235516    Buffer Size: 22547      Transition Number: 1200.229k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:07:36,023][train][INFO][train.py>_log] ==> #750000     Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 6.516    Value Loss: 6.271    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 2239247    Buffer Size: 23475      Transition Number: 1200.331k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:10:34,588][train][INFO][train.py>_log] ==> #751000     Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 6.721    Value Loss: 6.042    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 2242448    Buffer Size: 23819      Transition Number: 1199.941k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:13:33,908][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 5.590    Value Loss: 6.292    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 2245635    Buffer Size: 24006      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:16:37,129][train][INFO][train.py>_log] ==> #753000     Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 5.993    Value Loss: 5.954    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2248784    Buffer Size: 24045      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:19:33,198][train][INFO][train.py>_log] ==> #754000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 5.179    Value Loss: 6.361    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 2251830    Buffer Size: 24014      Transition Number: 1200.228k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:22:28,860][train][INFO][train.py>_log] ==> #755000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 5.966    Value Loss: 5.828    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 2254610    Buffer Size: 23723      Transition Number: 1200.117k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:25:28,017][train][INFO][train.py>_log] ==> #756000     Total Loss: 2.126    [weighted Loss:2.126    Policy Loss: 5.451    Value Loss: 5.625    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 2257441    Buffer Size: 23004      Transition Number: 1200.280k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:28:23,825][train][INFO][train.py>_log] ==> #757000     Total Loss: 1.843    [weighted Loss:1.843    Policy Loss: 5.561    Value Loss: 6.150    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2260085    Buffer Size: 22074      Transition Number: 1200.131k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:31:23,088][train][INFO][train.py>_log] ==> #758000     Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 5.640    Value Loss: 5.877    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2262730    Buffer Size: 21463      Transition Number: 1200.084k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:34:23,398][train][INFO][train.py>_log] ==> #759000     Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 5.788    Value Loss: 5.262    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2265521    Buffer Size: 21052      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:37:21,688][train][INFO][train.py>_log] ==> #760000     Total Loss: 1.587    [weighted Loss:1.587    Policy Loss: 5.669    Value Loss: 5.503    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 2268249    Buffer Size: 20644      Transition Number: 1199.958k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:40:19,418][train][INFO][train.py>_log] ==> #761000     Total Loss: 1.696    [weighted Loss:1.696    Policy Loss: 5.812    Value Loss: 5.405    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 2271021    Buffer Size: 20379      Transition Number: 1200.212k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:43:14,655][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.445    [weighted Loss:1.445    Policy Loss: 6.114    Value Loss: 5.029    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 2273881    Buffer Size: 20300      Transition Number: 1199.949k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:46:10,868][train][INFO][train.py>_log] ==> #763000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 5.627    Value Loss: 5.429    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 2276853    Buffer Size: 20510      Transition Number: 1199.971k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:49:08,686][train][INFO][train.py>_log] ==> #764000     Total Loss: 0.950    [weighted Loss:0.950    Policy Loss: 5.741    Value Loss: 5.748    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 2279888    Buffer Size: 20741      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:52:01,779][train][INFO][train.py>_log] ==> #765000     Total Loss: 1.572    [weighted Loss:1.572    Policy Loss: 6.889    Value Loss: 5.602    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 2282864    Buffer Size: 21134      Transition Number: 1200.077k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:54:58,823][train][INFO][train.py>_log] ==> #766000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 6.241    Value Loss: 5.885    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2285888    Buffer Size: 21540      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-26 16:57:53,567][train][INFO][train.py>_log] ==> #767000     Total Loss: 1.735    [weighted Loss:1.735    Policy Loss: 5.913    Value Loss: 5.759    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 2288810    Buffer Size: 21878      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:00:46,353][train][INFO][train.py>_log] ==> #768000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 5.774    Value Loss: 6.257    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2291693    Buffer Size: 22143      Transition Number: 1199.970k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:03:44,428][train][INFO][train.py>_log] ==> #769000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 5.666    Value Loss: 6.127    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 2294619    Buffer Size: 22184      Transition Number: 1200.052k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:06:38,615][train][INFO][train.py>_log] ==> #770000     Total Loss: 1.302    [weighted Loss:1.302    Policy Loss: 5.576    Value Loss: 5.876    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 2297511    Buffer Size: 22138      Transition Number: 1200.668k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:09:37,505][train][INFO][train.py>_log] ==> #771000     Total Loss: 1.180    [weighted Loss:1.180    Policy Loss: 5.644    Value Loss: 5.666    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2300385    Buffer Size: 21940      Transition Number: 1200.422k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:12:35,138][train][INFO][train.py>_log] ==> #772000     Total Loss: 1.506    [weighted Loss:1.506    Policy Loss: 5.714    Value Loss: 5.796    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2303227    Buffer Size: 21653      Transition Number: 1199.964k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:15:32,017][train][INFO][train.py>_log] ==> #773000     Total Loss: 1.596    [weighted Loss:1.596    Policy Loss: 5.501    Value Loss: 5.800    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 2306270    Buffer Size: 21507      Transition Number: 1200.184k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:18:29,667][train][INFO][train.py>_log] ==> #774000     Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 5.257    Value Loss: 5.681    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2309426    Buffer Size: 21417      Transition Number: 1200.210k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:21:26,039][train][INFO][train.py>_log] ==> #775000     Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 6.283    Value Loss: 5.786    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 2312322    Buffer Size: 21234      Transition Number: 1200.112k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:24:22,763][train][INFO][train.py>_log] ==> #776000     Total Loss: 1.990    [weighted Loss:1.990    Policy Loss: 5.925    Value Loss: 5.597    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 2315202    Buffer Size: 21142      Transition Number: 1200.110k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:27:22,437][train][INFO][train.py>_log] ==> #777000     Total Loss: 1.945    [weighted Loss:1.945    Policy Loss: 6.233    Value Loss: 5.861    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 2317944    Buffer Size: 21008      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:30:20,911][train][INFO][train.py>_log] ==> #778000     Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 6.117    Value Loss: 5.585    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2320636    Buffer Size: 20896      Transition Number: 1200.100k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:33:20,975][train][INFO][train.py>_log] ==> #779000     Total Loss: 2.594    [weighted Loss:2.594    Policy Loss: 7.025    Value Loss: 5.571    Reward Loss: 1.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 2323498    Buffer Size: 20816      Transition Number: 1200.300k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:36:18,320][train][INFO][train.py>_log] ==> #780000     Total Loss: 1.417    [weighted Loss:1.417    Policy Loss: 5.857    Value Loss: 5.239    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2326310    Buffer Size: 20611      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:39:16,348][train][INFO][train.py>_log] ==> #781000     Total Loss: 1.429    [weighted Loss:1.429    Policy Loss: 6.226    Value Loss: 5.245    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2329222    Buffer Size: 20495      Transition Number: 1200.057k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:42:14,884][train][INFO][train.py>_log] ==> #782000     Total Loss: 1.414    [weighted Loss:1.414    Policy Loss: 6.953    Value Loss: 5.441    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2332134    Buffer Size: 20535      Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:45:12,908][train][INFO][train.py>_log] ==> #783000     Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 6.394    Value Loss: 5.306    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 2335034    Buffer Size: 20569      Transition Number: 1200.117k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:48:07,604][train][INFO][train.py>_log] ==> #784000     Total Loss: 2.265    [weighted Loss:2.265    Policy Loss: 6.387    Value Loss: 5.589    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2337967    Buffer Size: 20732      Transition Number: 1200.065k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:51:07,100][train][INFO][train.py>_log] ==> #785000     Total Loss: 1.379    [weighted Loss:1.379    Policy Loss: 6.597    Value Loss: 5.817    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2340984    Buffer Size: 21043      Transition Number: 1200.344k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:54:07,111][train][INFO][train.py>_log] ==> #786000     Total Loss: 1.460    [weighted Loss:1.460    Policy Loss: 6.646    Value Loss: 5.776    Reward Loss: 1.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 2343987    Buffer Size: 21298      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-26 17:57:05,891][train][INFO][train.py>_log] ==> #787000     Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 6.056    Value Loss: 5.854    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2347009    Buffer Size: 21515      Transition Number: 1200.060k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:00:03,460][train][INFO][train.py>_log] ==> #788000     Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 5.898    Value Loss: 5.842    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 2349952    Buffer Size: 21634      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:03:03,091][train][INFO][train.py>_log] ==> #789000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 5.737    Value Loss: 5.784    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2352849    Buffer Size: 21696      Transition Number: 1200.088k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:06:01,296][train][INFO][train.py>_log] ==> #790000     Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 5.992    Value Loss: 5.903    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 2355753    Buffer Size: 21745      Transition Number: 1200.096k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:09:00,330][train][INFO][train.py>_log] ==> #791000     Total Loss: 1.281    [weighted Loss:1.281    Policy Loss: 5.858    Value Loss: 5.460    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2358789    Buffer Size: 21753      Transition Number: 1200.135k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:11:59,262][train][INFO][train.py>_log] ==> #792000     Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 5.310    Value Loss: 6.172    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2361739    Buffer Size: 21681      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:14:57,669][train][INFO][train.py>_log] ==> #793000     Total Loss: 2.604    [weighted Loss:2.604    Policy Loss: 6.031    Value Loss: 5.842    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 2364591    Buffer Size: 21619      Transition Number: 1200.222k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:17:55,745][train][INFO][train.py>_log] ==> #794000     Total Loss: 2.523    [weighted Loss:2.523    Policy Loss: 6.285    Value Loss: 5.658    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2367476    Buffer Size: 21558      Transition Number: 1200.233k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:20:51,497][train][INFO][train.py>_log] ==> #795000     Total Loss: 3.231    [weighted Loss:3.231    Policy Loss: 6.052    Value Loss: 5.749    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2370569    Buffer Size: 21719      Transition Number: 1200.227k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:23:51,010][train][INFO][train.py>_log] ==> #796000     Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 6.285    Value Loss: 5.689    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 2373845    Buffer Size: 21918      Transition Number: 1199.939k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:26:49,887][train][INFO][train.py>_log] ==> #797000     Total Loss: 2.682    [weighted Loss:2.682    Policy Loss: 6.005    Value Loss: 5.902    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2377134    Buffer Size: 22174      Transition Number: 1200.434k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:29:47,786][train][INFO][train.py>_log] ==> #798000     Total Loss: 1.146    [weighted Loss:1.146    Policy Loss: 5.658    Value Loss: 6.309    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 2380327    Buffer Size: 22440      Transition Number: 1200.225k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:32:44,560][train][INFO][train.py>_log] ==> #799000     Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 6.247    Value Loss: 5.890    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2383608    Buffer Size: 22729      Transition Number: 1200.319k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:35:43,102][train][INFO][train.py>_log] ==> #800000     Total Loss: 1.857    [weighted Loss:1.857    Policy Loss: 6.342    Value Loss: 6.487    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 2386919    Buffer Size: 23079      Transition Number: 1200.241k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:38:39,571][train][INFO][train.py>_log] ==> #801000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 6.039    Value Loss: 6.054    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2389866    Buffer Size: 23117      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:41:36,303][train][INFO][train.py>_log] ==> #802000     Total Loss: 1.269    [weighted Loss:1.269    Policy Loss: 5.889    Value Loss: 6.282    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2392789    Buffer Size: 22986      Transition Number: 1200.170k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:44:33,340][train][INFO][train.py>_log] ==> #803000     Total Loss: 2.178    [weighted Loss:2.178    Policy Loss: 5.860    Value Loss: 5.780    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2395382    Buffer Size: 22522      Transition Number: 1200.105k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:47:32,643][train][INFO][train.py>_log] ==> #804000     Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 6.749    Value Loss: 6.173    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 2398107    Buffer Size: 22051      Transition Number: 1200.165k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:50:33,036][train][INFO][train.py>_log] ==> #805000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 6.199    Value Loss: 5.656    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 2401535    Buffer Size: 22220      Transition Number: 1200.164k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:53:28,504][train][INFO][train.py>_log] ==> #806000     Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 5.671    Value Loss: 5.996    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 2404856    Buffer Size: 22408      Transition Number: 1200.476k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:56:25,973][train][INFO][train.py>_log] ==> #807000     Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 5.863    Value Loss: 5.950    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2408308    Buffer Size: 22569      Transition Number: 1200.283k Batch Size: 256        Lr: 0.10000 
[2022-01-26 18:59:23,400][train][INFO][train.py>_log] ==> #808000     Total Loss: 1.488    [weighted Loss:1.488    Policy Loss: 6.412    Value Loss: 6.028    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 2411742    Buffer Size: 22917      Transition Number: 1199.987k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:02:21,692][train][INFO][train.py>_log] ==> #809000     Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 6.327    Value Loss: 6.016    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2414742    Buffer Size: 22991      Transition Number: 1200.087k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:05:17,033][train][INFO][train.py>_log] ==> #810000     Total Loss: 1.756    [weighted Loss:1.756    Policy Loss: 6.339    Value Loss: 6.135    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 2417638    Buffer Size: 23139      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:08:11,489][train][INFO][train.py>_log] ==> #811000     Total Loss: 2.895    [weighted Loss:2.895    Policy Loss: 6.649    Value Loss: 5.836    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 2420325    Buffer Size: 23250      Transition Number: 1200.137k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:11:13,629][train][INFO][train.py>_log] ==> #812000     Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 6.295    Value Loss: 5.954    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 2423150    Buffer Size: 22976      Transition Number: 1200.044k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:14:11,713][train][INFO][train.py>_log] ==> #813000     Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 5.927    Value Loss: 6.197    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 2425976    Buffer Size: 22484      Transition Number: 1199.968k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:17:09,182][train][INFO][train.py>_log] ==> #814000     Total Loss: 2.451    [weighted Loss:2.451    Policy Loss: 5.987    Value Loss: 5.713    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 2428820    Buffer Size: 22028      Transition Number: 1200.354k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:20:07,934][train][INFO][train.py>_log] ==> #815000     Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 5.389    Value Loss: 5.872    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 2431586    Buffer Size: 21387      Transition Number: 1200.125k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:23:07,239][train][INFO][train.py>_log] ==> #816000     Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 5.749    Value Loss: 5.229    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 2434289    Buffer Size: 20934      Transition Number: 1200.172k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:26:04,866][train][INFO][train.py>_log] ==> #817000     Total Loss: 1.654    [weighted Loss:1.654    Policy Loss: 6.243    Value Loss: 5.765    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 2437101    Buffer Size: 20941      Transition Number: 1200.097k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:29:01,527][train][INFO][train.py>_log] ==> #818000     Total Loss: 1.776    [weighted Loss:1.776    Policy Loss: 6.148    Value Loss: 5.473    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 2439935    Buffer Size: 21012      Transition Number: 1200.012k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:32:00,575][train][INFO][train.py>_log] ==> #819000     Total Loss: 1.494    [weighted Loss:1.494    Policy Loss: 5.477    Value Loss: 6.008    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 2442787    Buffer Size: 21101      Transition Number: 1200.012k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:34:57,649][train][INFO][train.py>_log] ==> #820000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 6.291    Value Loss: 5.261    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2445607    Buffer Size: 21145      Transition Number: 1200.235k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:37:57,691][train][INFO][train.py>_log] ==> #821000     Total Loss: 1.223    [weighted Loss:1.223    Policy Loss: 5.641    Value Loss: 5.537    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2448496    Buffer Size: 21070      Transition Number: 1200.091k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:40:55,768][train][INFO][train.py>_log] ==> #822000     Total Loss: 1.553    [weighted Loss:1.553    Policy Loss: 6.258    Value Loss: 5.551    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 2451431    Buffer Size: 21048      Transition Number: 1200.038k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:43:52,608][train][INFO][train.py>_log] ==> #823000     Total Loss: 3.036    [weighted Loss:3.036    Policy Loss: 6.571    Value Loss: 5.889    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 2456352    Buffer Size: 23000      Transition Number: 1200.106k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:46:50,483][train][INFO][train.py>_log] ==> #824000     Total Loss: 1.700    [weighted Loss:1.700    Policy Loss: 6.236    Value Loss: 6.387    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 2461323    Buffer Size: 24939      Transition Number: 1200.217k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:49:47,633][train][INFO][train.py>_log] ==> #825000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 6.165    Value Loss: 6.337    Reward Loss: 1.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 2464673    Buffer Size: 25348      Transition Number: 1200.066k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:52:44,141][train][INFO][train.py>_log] ==> #826000     Total Loss: 1.506    [weighted Loss:1.506    Policy Loss: 6.285    Value Loss: 6.258    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2468135    Buffer Size: 25794      Transition Number: 1199.948k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:55:45,531][train][INFO][train.py>_log] ==> #827000     Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 6.457    Value Loss: 6.072    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 2471240    Buffer Size: 25910      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 19:58:40,512][train][INFO][train.py>_log] ==> #828000     Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 6.473    Value Loss: 6.186    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2474341    Buffer Size: 26123      Transition Number: 1200.272k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:01:39,695][train][INFO][train.py>_log] ==> #829000     Total Loss: 2.023    [weighted Loss:2.023    Policy Loss: 6.483    Value Loss: 6.159    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 2477236    Buffer Size: 26212      Transition Number: 1200.075k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:04:37,644][train][INFO][train.py>_log] ==> #830000     Total Loss: 1.058    [weighted Loss:1.058    Policy Loss: 6.141    Value Loss: 6.384    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2480127    Buffer Size: 24783      Transition Number: 1200.243k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:07:36,023][train][INFO][train.py>_log] ==> #831000     Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 6.409    Value Loss: 6.233    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2482809    Buffer Size: 22854      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:10:33,619][train][INFO][train.py>_log] ==> #832000     Total Loss: 2.569    [weighted Loss:2.569    Policy Loss: 5.614    Value Loss: 5.410    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2485464    Buffer Size: 21745      Transition Number: 1200.005k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:13:31,905][train][INFO][train.py>_log] ==> #833000     Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 5.740    Value Loss: 5.381    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2488221    Buffer Size: 21116      Transition Number: 1200.023k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:16:29,745][train][INFO][train.py>_log] ==> #834000     Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 5.601    Value Loss: 6.008    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 2490917    Buffer Size: 20720      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:19:27,072][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.057    [weighted Loss:2.057    Policy Loss: 5.687    Value Loss: 5.853    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2493811    Buffer Size: 20625      Transition Number: 1200.058k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:22:26,434][train][INFO][train.py>_log] ==> #836000     Total Loss: 1.938    [weighted Loss:1.938    Policy Loss: 5.987    Value Loss: 5.546    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2496820    Buffer Size: 20580      Transition Number: 1200.159k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:25:25,828][train][INFO][train.py>_log] ==> #837000     Total Loss: 2.620    [weighted Loss:2.620    Policy Loss: 6.091    Value Loss: 5.635    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 2499762    Buffer Size: 20647      Transition Number: 1200.174k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:28:22,788][train][INFO][train.py>_log] ==> #838000     Total Loss: 1.125    [weighted Loss:1.125    Policy Loss: 5.918    Value Loss: 5.789    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 2502703    Buffer Size: 20843      Transition Number: 1200.099k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:31:21,115][train][INFO][train.py>_log] ==> #839000     Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 5.877    Value Loss: 5.882    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 2506333    Buffer Size: 21673      Transition Number: 1200.142k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:34:22,026][train][INFO][train.py>_log] ==> #840000     Total Loss: 1.191    [weighted Loss:1.191    Policy Loss: 6.199    Value Loss: 6.265    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2510022    Buffer Size: 22530      Transition Number: 1200.314k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:37:21,123][train][INFO][train.py>_log] ==> #841000     Total Loss: 1.458    [weighted Loss:1.458    Policy Loss: 6.396    Value Loss: 6.097    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2513055    Buffer Size: 22826      Transition Number: 1200.051k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:40:17,958][train][INFO][train.py>_log] ==> #842000     Total Loss: 1.756    [weighted Loss:1.756    Policy Loss: 5.573    Value Loss: 6.226    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2516116    Buffer Size: 22973      Transition Number: 1200.164k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:43:16,653][train][INFO][train.py>_log] ==> #843000     Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 5.393    Value Loss: 5.818    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 2518748    Buffer Size: 22730      Transition Number: 1200.391k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:46:10,883][train][INFO][train.py>_log] ==> #844000     Total Loss: 2.370    [weighted Loss:2.370    Policy Loss: 6.057    Value Loss: 5.706    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 2521376    Buffer Size: 22442      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:49:09,662][train][INFO][train.py>_log] ==> #845000     Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 6.270    Value Loss: 5.603    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 2524105    Buffer Size: 22211      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:52:03,218][train][INFO][train.py>_log] ==> #846000     Total Loss: 1.991    [weighted Loss:1.991    Policy Loss: 5.930    Value Loss: 5.625    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 2526846    Buffer Size: 21658      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:55:02,457][train][INFO][train.py>_log] ==> #847000     Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 5.865    Value Loss: 5.518    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2529777    Buffer Size: 20933      Transition Number: 1200.182k Batch Size: 256        Lr: 0.10000 
[2022-01-26 20:58:01,652][train][INFO][train.py>_log] ==> #848000     Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 6.144    Value Loss: 5.520    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2532778    Buffer Size: 20565      Transition Number: 1200.152k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:01:04,136][train][INFO][train.py>_log] ==> #849000     Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 6.333    Value Loss: 5.573    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 2536029    Buffer Size: 20628      Transition Number: 1200.405k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:04:03,672][train][INFO][train.py>_log] ==> #850000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 5.952    Value Loss: 5.640    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 2539230    Buffer Size: 20913      Transition Number: 1200.365k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:06:59,138][train][INFO][train.py>_log] ==> #851000     Total Loss: 0.619    [weighted Loss:0.619    Policy Loss: 6.068    Value Loss: 6.261    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 2542385    Buffer Size: 21393      Transition Number: 1200.062k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:09:54,159][train][INFO][train.py>_log] ==> #852000     Total Loss: 1.708    [weighted Loss:1.708    Policy Loss: 6.368    Value Loss: 6.144    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 2545610    Buffer Size: 21852      Transition Number: 1200.256k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:12:53,561][train][INFO][train.py>_log] ==> #853000     Total Loss: 2.909    [weighted Loss:2.909    Policy Loss: 6.406    Value Loss: 6.246    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 2549080    Buffer Size: 22486      Transition Number: 1200.146k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:15:49,741][train][INFO][train.py>_log] ==> #854000     Total Loss: 1.469    [weighted Loss:1.469    Policy Loss: 6.399    Value Loss: 5.901    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2552463    Buffer Size: 23102      Transition Number: 1200.100k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:18:44,468][train][INFO][train.py>_log] ==> #855000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 6.495    Value Loss: 6.259    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 2555758    Buffer Size: 23642      Transition Number: 1200.141k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:21:40,975][train][INFO][train.py>_log] ==> #856000     Total Loss: 1.973    [weighted Loss:1.973    Policy Loss: 6.327    Value Loss: 6.763    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 2559056    Buffer Size: 23959      Transition Number: 1200.095k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:24:39,272][train][INFO][train.py>_log] ==> #857000     Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 6.712    Value Loss: 5.724    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2561868    Buffer Size: 23914      Transition Number: 1200.268k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:27:37,801][train][INFO][train.py>_log] ==> #858000     Total Loss: 1.257    [weighted Loss:1.257    Policy Loss: 6.399    Value Loss: 5.845    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2564620    Buffer Size: 23777      Transition Number: 1200.356k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:30:35,408][train][INFO][train.py>_log] ==> #859000     Total Loss: 0.734    [weighted Loss:0.734    Policy Loss: 6.660    Value Loss: 6.232    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 2567924    Buffer Size: 23899      Transition Number: 1200.205k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:33:33,787][train][INFO][train.py>_log] ==> #860000     Total Loss: 2.759    [weighted Loss:2.759    Policy Loss: 6.361    Value Loss: 6.417    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 2571190    Buffer Size: 23920      Transition Number: 1200.191k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:36:31,991][train][INFO][train.py>_log] ==> #861000     Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 5.850    Value Loss: 6.583    Reward Loss: 1.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 2574293    Buffer Size: 23771      Transition Number: 1200.371k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:39:30,572][train][INFO][train.py>_log] ==> #862000     Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 5.996    Value Loss: 5.971    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2577540    Buffer Size: 23572      Transition Number: 1200.180k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:42:31,812][train][INFO][train.py>_log] ==> #863000     Total Loss: 1.720    [weighted Loss:1.720    Policy Loss: 5.870    Value Loss: 6.515    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 2580639    Buffer Size: 23225      Transition Number: 1200.045k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:45:29,623][train][INFO][train.py>_log] ==> #864000     Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 5.421    Value Loss: 6.033    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2583576    Buffer Size: 23020      Transition Number: 1199.969k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:48:28,616][train][INFO][train.py>_log] ==> #865000     Total Loss: 0.717    [weighted Loss:0.717    Policy Loss: 6.122    Value Loss: 5.933    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 2586487    Buffer Size: 23018      Transition Number: 1200.049k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:51:29,537][train][INFO][train.py>_log] ==> #866000     Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 5.246    Value Loss: 6.119    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 2589463    Buffer Size: 22825      Transition Number: 1200.188k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:54:28,306][train][INFO][train.py>_log] ==> #867000     Total Loss: 2.424    [weighted Loss:2.424    Policy Loss: 5.945    Value Loss: 5.693    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 2592474    Buffer Size: 22473      Transition Number: 1200.095k Batch Size: 256        Lr: 0.10000 
[2022-01-26 21:57:26,864][train][INFO][train.py>_log] ==> #868000     Total Loss: 2.130    [weighted Loss:2.130    Policy Loss: 5.488    Value Loss: 5.868    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2595559    Buffer Size: 22228      Transition Number: 1199.941k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:00:28,194][train][INFO][train.py>_log] ==> #869000     Total Loss: 1.425    [weighted Loss:1.425    Policy Loss: 6.001    Value Loss: 5.787    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 2598508    Buffer Size: 21992      Transition Number: 1200.093k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:03:27,560][train][INFO][train.py>_log] ==> #870000     Total Loss: 0.633    [weighted Loss:0.633    Policy Loss: 5.762    Value Loss: 5.743    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 2601468    Buffer Size: 21924      Transition Number: 1200.033k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:06:22,265][train][INFO][train.py>_log] ==> #871000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 5.745    Value Loss: 5.814    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 2604466    Buffer Size: 21992      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:09:24,596][train][INFO][train.py>_log] ==> #872000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 6.090    Value Loss: 5.633    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2607496    Buffer Size: 22113      Transition Number: 1200.106k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:12:22,201][train][INFO][train.py>_log] ==> #873000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 6.255    Value Loss: 6.116    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 2610746    Buffer Size: 22404      Transition Number: 1200.067k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:15:21,920][train][INFO][train.py>_log] ==> #874000     Total Loss: 2.234    [weighted Loss:2.234    Policy Loss: 6.038    Value Loss: 6.026    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2614004    Buffer Size: 22667      Transition Number: 1200.115k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:18:20,028][train][INFO][train.py>_log] ==> #875000     Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 5.915    Value Loss: 6.051    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 2617071    Buffer Size: 22784      Transition Number: 1200.070k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:21:19,268][train][INFO][train.py>_log] ==> #876000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 5.884    Value Loss: 6.246    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2620158    Buffer Size: 22883      Transition Number: 1200.038k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:24:19,023][train][INFO][train.py>_log] ==> #877000     Total Loss: 1.878    [weighted Loss:1.878    Policy Loss: 5.953    Value Loss: 6.274    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2623329    Buffer Size: 23102      Transition Number: 1200.171k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:27:17,948][train][INFO][train.py>_log] ==> #878000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 5.992    Value Loss: 6.090    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2626487    Buffer Size: 23284      Transition Number: 1200.362k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:30:18,298][train][INFO][train.py>_log] ==> #879000     Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 6.366    Value Loss: 6.392    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2629698    Buffer Size: 23222      Transition Number: 1200.162k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:33:19,618][train][INFO][train.py>_log] ==> #880000     Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 6.143    Value Loss: 5.981    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 2632784    Buffer Size: 23114      Transition Number: 1200.176k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:36:19,468][train][INFO][train.py>_log] ==> #881000     Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 6.199    Value Loss: 5.924    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 2635839    Buffer Size: 22830      Transition Number: 1200.050k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:39:19,617][train][INFO][train.py>_log] ==> #882000     Total Loss: 1.421    [weighted Loss:1.421    Policy Loss: 5.335    Value Loss: 5.809    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 2638917    Buffer Size: 22590      Transition Number: 1200.293k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:42:20,100][train][INFO][train.py>_log] ==> #883000     Total Loss: 1.491    [weighted Loss:1.491    Policy Loss: 6.061    Value Loss: 6.028    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 2641847    Buffer Size: 22343      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:45:17,256][train][INFO][train.py>_log] ==> #884000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 6.215    Value Loss: 5.813    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 2644787    Buffer Size: 22032      Transition Number: 1200.117k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:48:13,843][train][INFO][train.py>_log] ==> #885000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 6.341    Value Loss: 5.581    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 2647843    Buffer Size: 21949      Transition Number: 1200.328k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:51:09,660][train][INFO][train.py>_log] ==> #886000     Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 6.180    Value Loss: 5.579    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 2650866    Buffer Size: 21915      Transition Number: 1200.203k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:54:10,732][train][INFO][train.py>_log] ==> #887000     Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 5.402    Value Loss: 5.940    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 2654098    Buffer Size: 21971      Transition Number: 1200.038k Batch Size: 256        Lr: 0.10000 
[2022-01-26 22:57:11,064][train][INFO][train.py>_log] ==> #888000     Total Loss: 1.532    [weighted Loss:1.532    Policy Loss: 5.797    Value Loss: 6.154    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2657345    Buffer Size: 22108      Transition Number: 1200.247k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:00:14,967][train][INFO][train.py>_log] ==> #889000     Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 5.845    Value Loss: 6.161    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 2660373    Buffer Size: 22087      Transition Number: 1200.130k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:03:16,452][train][INFO][train.py>_log] ==> #890000     Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 5.918    Value Loss: 5.955    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 2663283    Buffer Size: 22048      Transition Number: 1200.161k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:06:16,849][train][INFO][train.py>_log] ==> #891000     Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 5.343    Value Loss: 6.243    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2666354    Buffer Size: 21987      Transition Number: 1200.061k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:09:15,579][train][INFO][train.py>_log] ==> #892000     Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 5.907    Value Loss: 5.929    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 2669205    Buffer Size: 21757      Transition Number: 1199.998k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:12:15,990][train][INFO][train.py>_log] ==> #893000     Total Loss: 2.581    [weighted Loss:2.581    Policy Loss: 6.098    Value Loss: 5.635    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2672133    Buffer Size: 21599      Transition Number: 1200.025k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:15:17,005][train][INFO][train.py>_log] ==> #894000     Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 6.252    Value Loss: 5.941    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 2675064    Buffer Size: 21450      Transition Number: 1200.059k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:18:14,421][train][INFO][train.py>_log] ==> #895000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 5.647    Value Loss: 5.476    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 2677961    Buffer Size: 21197      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:21:16,663][train][INFO][train.py>_log] ==> #896000     Total Loss: 2.589    [weighted Loss:2.589    Policy Loss: 5.681    Value Loss: 5.549    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 2680959    Buffer Size: 21110      Transition Number: 1199.999k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:24:16,876][train][INFO][train.py>_log] ==> #897000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 5.858    Value Loss: 5.344    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2684299    Buffer Size: 21557      Transition Number: 1200.364k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:27:20,169][train][INFO][train.py>_log] ==> #898000     Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 6.049    Value Loss: 6.167    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 2687650    Buffer Size: 21985      Transition Number: 1200.230k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:30:18,243][train][INFO][train.py>_log] ==> #899000     Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 5.971    Value Loss: 6.260    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 2690603    Buffer Size: 22032      Transition Number: 1200.143k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:33:18,716][train][INFO][train.py>_log] ==> #900000     Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 6.093    Value Loss: 5.886    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 2693547    Buffer Size: 21964      Transition Number: 1199.981k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:36:19,779][train][INFO][train.py>_log] ==> #901000     Total Loss: 2.030    [weighted Loss:2.030    Policy Loss: 6.079    Value Loss: 5.458    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 2696863    Buffer Size: 22242      Transition Number: 1200.629k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:39:17,063][train][INFO][train.py>_log] ==> #902000     Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 5.564    Value Loss: 5.578    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 2700029    Buffer Size: 22591      Transition Number: 1200.398k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:42:18,483][train][INFO][train.py>_log] ==> #903000     Total Loss: 1.827    [weighted Loss:1.827    Policy Loss: 6.050    Value Loss: 5.790    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2703430    Buffer Size: 22977      Transition Number: 1200.016k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:45:19,545][train][INFO][train.py>_log] ==> #904000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 5.755    Value Loss: 5.928    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 2706759    Buffer Size: 23044      Transition Number: 1200.055k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:48:21,940][train][INFO][train.py>_log] ==> #905000     Total Loss: 1.357    [weighted Loss:1.357    Policy Loss: 6.130    Value Loss: 6.047    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2710221    Buffer Size: 22983      Transition Number: 1200.081k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:51:21,351][train][INFO][train.py>_log] ==> #906000     Total Loss: 1.861    [weighted Loss:1.861    Policy Loss: 6.046    Value Loss: 6.269    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2713629    Buffer Size: 23292      Transition Number: 1200.146k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:54:18,838][train][INFO][train.py>_log] ==> #907000     Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 5.815    Value Loss: 6.320    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2716605    Buffer Size: 23462      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-26 23:57:19,810][train][INFO][train.py>_log] ==> #908000     Total Loss: 2.054    [weighted Loss:2.054    Policy Loss: 6.264    Value Loss: 6.154    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2719653    Buffer Size: 23253      Transition Number: 1200.814k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:00:26,648][train][INFO][train.py>_log] ==> #909000     Total Loss: 1.521    [weighted Loss:1.521    Policy Loss: 5.434    Value Loss: 6.114    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2722834    Buffer Size: 22901      Transition Number: 1200.047k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:03:28,523][train][INFO][train.py>_log] ==> #910000     Total Loss: 1.551    [weighted Loss:1.551    Policy Loss: 6.189    Value Loss: 6.174    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 2725988    Buffer Size: 22667      Transition Number: 1200.226k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:06:28,312][train][INFO][train.py>_log] ==> #911000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 6.800    Value Loss: 5.924    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 2728874    Buffer Size: 22215      Transition Number: 1200.001k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:09:26,504][train][INFO][train.py>_log] ==> #912000     Total Loss: 2.078    [weighted Loss:2.078    Policy Loss: 6.294    Value Loss: 5.455    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 2731704    Buffer Size: 21793      Transition Number: 1200.370k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:12:27,588][train][INFO][train.py>_log] ==> #913000     Total Loss: 1.293    [weighted Loss:1.293    Policy Loss: 6.159    Value Loss: 5.734    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2734553    Buffer Size: 21345      Transition Number: 1200.388k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:15:29,114][train][INFO][train.py>_log] ==> #914000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 6.163    Value Loss: 5.364    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 2737329    Buffer Size: 21112      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:18:29,810][train][INFO][train.py>_log] ==> #915000     Total Loss: 1.269    [weighted Loss:1.269    Policy Loss: 5.532    Value Loss: 6.050    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 2740880    Buffer Size: 21583      Transition Number: 1200.204k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:21:33,443][train][INFO][train.py>_log] ==> #916000     Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 6.269    Value Loss: 6.015    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 2744392    Buffer Size: 22053      Transition Number: 1200.027k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:24:35,703][train][INFO][train.py>_log] ==> #917000     Total Loss: 1.135    [weighted Loss:1.135    Policy Loss: 6.058    Value Loss: 5.925    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 2747566    Buffer Size: 22187      Transition Number: 1200.254k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:27:35,290][train][INFO][train.py>_log] ==> #918000     Total Loss: 1.326    [weighted Loss:1.326    Policy Loss: 7.091    Value Loss: 5.980    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2750674    Buffer Size: 22460      Transition Number: 1200.378k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:30:35,828][train][INFO][train.py>_log] ==> #919000     Total Loss: 1.409    [weighted Loss:1.409    Policy Loss: 6.244    Value Loss: 6.204    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 2753696    Buffer Size: 22712      Transition Number: 1200.074k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:33:35,513][train][INFO][train.py>_log] ==> #920000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 6.445    Value Loss: 6.159    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 2756805    Buffer Size: 22968      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:36:36,427][train][INFO][train.py>_log] ==> #921000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 6.153    Value Loss: 6.036    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 2760309    Buffer Size: 23639      Transition Number: 1200.515k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:39:38,971][train][INFO][train.py>_log] ==> #922000     Total Loss: 1.519    [weighted Loss:1.519    Policy Loss: 6.239    Value Loss: 6.137    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2763786    Buffer Size: 23856      Transition Number: 1200.231k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:42:40,065][train][INFO][train.py>_log] ==> #923000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 6.157    Value Loss: 6.078    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 2766767    Buffer Size: 23436      Transition Number: 1200.288k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:45:40,898][train][INFO][train.py>_log] ==> #924000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 6.210    Value Loss: 6.189    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2769754    Buffer Size: 23160      Transition Number: 1200.022k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:48:41,175][train][INFO][train.py>_log] ==> #925000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 6.119    Value Loss: 5.730    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2772531    Buffer Size: 22763      Transition Number: 1200.087k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:51:41,247][train][INFO][train.py>_log] ==> #926000     Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 5.842    Value Loss: 5.664    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2775283    Buffer Size: 22419      Transition Number: 1199.982k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:54:43,250][train][INFO][train.py>_log] ==> #927000     Total Loss: 1.040    [weighted Loss:1.040    Policy Loss: 6.060    Value Loss: 5.553    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2778157    Buffer Size: 22102      Transition Number: 1200.149k Batch Size: 256        Lr: 0.10000 
[2022-01-27 00:57:45,972][train][INFO][train.py>_log] ==> #928000     Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 6.088    Value Loss: 5.578    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 2780940    Buffer Size: 21486      Transition Number: 1200.068k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:00:44,934][train][INFO][train.py>_log] ==> #929000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 6.351    Value Loss: 5.432    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2784033    Buffer Size: 20897      Transition Number: 1200.039k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:03:45,757][train][INFO][train.py>_log] ==> #930000     Total Loss: 0.928    [weighted Loss:0.928    Policy Loss: 7.407    Value Loss: 5.136    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 2787109    Buffer Size: 20723      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:06:43,950][train][INFO][train.py>_log] ==> #931000     Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 6.379    Value Loss: 5.703    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2790560    Buffer Size: 21056      Transition Number: 1200.282k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:09:44,951][train][INFO][train.py>_log] ==> #932000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 6.932    Value Loss: 6.100    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2794015    Buffer Size: 21644      Transition Number: 1200.326k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:12:44,922][train][INFO][train.py>_log] ==> #933000     Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 6.979    Value Loss: 6.447    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 2797508    Buffer Size: 22324      Transition Number: 1200.147k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:15:45,825][train][INFO][train.py>_log] ==> #934000     Total Loss: 1.986    [weighted Loss:1.986    Policy Loss: 6.260    Value Loss: 5.882    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 2800827    Buffer Size: 22918      Transition Number: 1200.252k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:18:45,697][train][INFO][train.py>_log] ==> #935000     Total Loss: 0.987    [weighted Loss:0.987    Policy Loss: 6.638    Value Loss: 6.092    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2803593    Buffer Size: 23056      Transition Number: 1200.111k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:21:41,865][train][INFO][train.py>_log] ==> #936000     Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 6.580    Value Loss: 6.008    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2806361    Buffer Size: 23021      Transition Number: 1200.505k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:24:41,691][train][INFO][train.py>_log] ==> #937000     Total Loss: 0.558    [weighted Loss:0.558    Policy Loss: 6.122    Value Loss: 6.368    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 2809288    Buffer Size: 23067      Transition Number: 1200.168k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:27:38,213][train][INFO][train.py>_log] ==> #938000     Total Loss: 1.847    [weighted Loss:1.847    Policy Loss: 5.936    Value Loss: 5.886    Reward Loss: 1.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 2812166    Buffer Size: 22884      Transition Number: 1200.329k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:30:34,147][train][INFO][train.py>_log] ==> #939000     Total Loss: 2.081    [weighted Loss:2.081    Policy Loss: 5.946    Value Loss: 5.956    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 2815201    Buffer Size: 22536      Transition Number: 1200.096k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:33:36,568][train][INFO][train.py>_log] ==> #940000     Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 6.390    Value Loss: 5.706    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2818254    Buffer Size: 22213      Transition Number: 1200.164k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:36:37,786][train][INFO][train.py>_log] ==> #941000     Total Loss: 2.022    [weighted Loss:2.022    Policy Loss: 6.074    Value Loss: 5.914    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 2821234    Buffer Size: 21698      Transition Number: 1200.127k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:39:42,035][train][INFO][train.py>_log] ==> #942000     Total Loss: 2.815    [weighted Loss:2.815    Policy Loss: 5.880    Value Loss: 5.611    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 2824237    Buffer Size: 21543      Transition Number: 1200.068k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:42:42,470][train][INFO][train.py>_log] ==> #943000     Total Loss: 1.914    [weighted Loss:1.914    Policy Loss: 5.879    Value Loss: 5.958    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 2827017    Buffer Size: 21446      Transition Number: 1200.285k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:45:42,443][train][INFO][train.py>_log] ==> #944000     Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 5.989    Value Loss: 5.258    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2829895    Buffer Size: 21245      Transition Number: 1200.334k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:48:43,595][train][INFO][train.py>_log] ==> #945000     Total Loss: 1.788    [weighted Loss:1.788    Policy Loss: 6.076    Value Loss: 5.667    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 2833741    Buffer Size: 21939      Transition Number: 1200.178k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:51:43,849][train][INFO][train.py>_log] ==> #946000     Total Loss: 1.142    [weighted Loss:1.142    Policy Loss: 6.230    Value Loss: 5.973    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2837648    Buffer Size: 22602      Transition Number: 1200.380k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:54:44,097][train][INFO][train.py>_log] ==> #947000     Total Loss: 1.688    [weighted Loss:1.688    Policy Loss: 5.365    Value Loss: 5.829    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2840842    Buffer Size: 22634      Transition Number: 1200.106k Batch Size: 256        Lr: 0.10000 
[2022-01-27 01:57:44,459][train][INFO][train.py>_log] ==> #948000     Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 6.262    Value Loss: 5.789    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2844052    Buffer Size: 22812      Transition Number: 1200.207k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:00:44,046][train][INFO][train.py>_log] ==> #949000     Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 6.447    Value Loss: 5.610    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2846909    Buffer Size: 22689      Transition Number: 1200.619k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:03:45,007][train][INFO][train.py>_log] ==> #950000     Total Loss: 2.035    [weighted Loss:2.035    Policy Loss: 6.723    Value Loss: 5.912    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2849773    Buffer Size: 22674      Transition Number: 1200.036k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:06:46,481][train][INFO][train.py>_log] ==> #951000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 6.401    Value Loss: 6.199    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2852744    Buffer Size: 22806      Transition Number: 1200.084k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:09:48,212][train][INFO][train.py>_log] ==> #952000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 6.313    Value Loss: 5.687    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 2855777    Buffer Size: 22026      Transition Number: 1200.140k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:12:50,253][train][INFO][train.py>_log] ==> #953000     Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 6.067    Value Loss: 5.524    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 2858745    Buffer Size: 21271      Transition Number: 1200.257k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:15:51,160][train][INFO][train.py>_log] ==> #954000     Total Loss: 1.628    [weighted Loss:1.628    Policy Loss: 5.630    Value Loss: 5.630    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2861714    Buffer Size: 21113      Transition Number: 1200.000k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:18:49,984][train][INFO][train.py>_log] ==> #955000     Total Loss: 1.580    [weighted Loss:1.580    Policy Loss: 6.063    Value Loss: 5.730    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 2864498    Buffer Size: 20773      Transition Number: 1200.177k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:21:47,770][train][INFO][train.py>_log] ==> #956000     Total Loss: 1.627    [weighted Loss:1.627    Policy Loss: 6.129    Value Loss: 5.484    Reward Loss: 1.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 2867226    Buffer Size: 20688      Transition Number: 1200.243k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:24:54,333][train][INFO][train.py>_log] ==> #957000     Total Loss: 1.152    [weighted Loss:1.152    Policy Loss: 6.336    Value Loss: 5.766    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 2870276    Buffer Size: 20794      Transition Number: 1200.002k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:27:56,200][train][INFO][train.py>_log] ==> #958000     Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 6.582    Value Loss: 5.899    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 2873202    Buffer Size: 20772      Transition Number: 1200.194k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:30:57,472][train][INFO][train.py>_log] ==> #959000     Total Loss: 1.167    [weighted Loss:1.167    Policy Loss: 6.435    Value Loss: 5.520    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2876327    Buffer Size: 20785      Transition Number: 1200.219k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:34:00,590][train][INFO][train.py>_log] ==> #960000     Total Loss: 2.119    [weighted Loss:2.119    Policy Loss: 6.532    Value Loss: 5.711    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 2879432    Buffer Size: 20798      Transition Number: 1200.105k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:36:59,836][train][INFO][train.py>_log] ==> #961000     Total Loss: 1.767    [weighted Loss:1.767    Policy Loss: 7.021    Value Loss: 5.660    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 2882857    Buffer Size: 21173      Transition Number: 1200.279k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:40:00,085][train][INFO][train.py>_log] ==> #962000     Total Loss: 1.876    [weighted Loss:1.876    Policy Loss: 7.303    Value Loss: 5.736    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 2886255    Buffer Size: 21782      Transition Number: 1200.096k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:42:58,478][train][INFO][train.py>_log] ==> #963000     Total Loss: 2.615    [weighted Loss:2.615    Policy Loss: 6.772    Value Loss: 6.116    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2889592    Buffer Size: 22373      Transition Number: 1200.110k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:45:59,066][train][INFO][train.py>_log] ==> #964000     Total Loss: 1.411    [weighted Loss:1.411    Policy Loss: 6.638    Value Loss: 6.212    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2892983    Buffer Size: 22806      Transition Number: 1199.990k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:49:01,209][train][INFO][train.py>_log] ==> #965000     Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 7.274    Value Loss: 6.069    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 2896207    Buffer Size: 23172      Transition Number: 1200.277k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:52:02,137][train][INFO][train.py>_log] ==> #966000     Total Loss: 2.448    [weighted Loss:2.448    Policy Loss: 7.042    Value Loss: 6.025    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 2899407    Buffer Size: 23441      Transition Number: 1200.123k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:55:03,526][train][INFO][train.py>_log] ==> #967000     Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 6.091    Value Loss: 6.392    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 2902943    Buffer Size: 23942      Transition Number: 1200.039k Batch Size: 256        Lr: 0.10000 
[2022-01-27 02:58:02,315][train][INFO][train.py>_log] ==> #968000     Total Loss: 2.124    [weighted Loss:2.124    Policy Loss: 6.478    Value Loss: 6.372    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 2906376    Buffer Size: 24140      Transition Number: 1200.150k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:01:02,151][train][INFO][train.py>_log] ==> #969000     Total Loss: 2.352    [weighted Loss:2.352    Policy Loss: 6.301    Value Loss: 6.283    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 2910821    Buffer Size: 25190      Transition Number: 1200.070k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:04:00,822][train][INFO][train.py>_log] ==> #970000     Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 6.297    Value Loss: 6.619    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 2915199    Buffer Size: 26261      Transition Number: 1200.173k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:06:57,374][train][INFO][train.py>_log] ==> #971000     Total Loss: 1.706    [weighted Loss:1.706    Policy Loss: 6.379    Value Loss: 6.550    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 2918844    Buffer Size: 26762      Transition Number: 1199.986k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:09:55,733][train][INFO][train.py>_log] ==> #972000     Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 6.288    Value Loss: 6.368    Reward Loss: 1.916    Consistency Loss: 0.000    ] Replay Episodes Collected: 2922594    Buffer Size: 27291      Transition Number: 1200.106k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:12:55,785][train][INFO][train.py>_log] ==> #973000     Total Loss: 1.841    [weighted Loss:1.841    Policy Loss: 6.268    Value Loss: 6.500    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 2925507    Buffer Size: 27077      Transition Number: 1200.278k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:15:55,487][train][INFO][train.py>_log] ==> #974000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 5.366    Value Loss: 6.019    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2928330    Buffer Size: 26717      Transition Number: 1200.382k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:18:57,063][train][INFO][train.py>_log] ==> #975000     Total Loss: 2.241    [weighted Loss:2.241    Policy Loss: 5.748    Value Loss: 5.780    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2931086    Buffer Size: 26067      Transition Number: 1200.094k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:22:00,522][train][INFO][train.py>_log] ==> #976000     Total Loss: 2.693    [weighted Loss:2.693    Policy Loss: 5.568    Value Loss: 5.716    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2933868    Buffer Size: 24832      Transition Number: 1200.049k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:25:04,344][train][INFO][train.py>_log] ==> #977000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 6.044    Value Loss: 5.598    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 2936839    Buffer Size: 23263      Transition Number: 1199.984k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:28:07,012][train][INFO][train.py>_log] ==> #978000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 6.083    Value Loss: 5.735    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2939793    Buffer Size: 22103      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:31:06,869][train][INFO][train.py>_log] ==> #979000     Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 6.334    Value Loss: 5.653    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 2942663    Buffer Size: 21255      Transition Number: 1200.152k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:34:08,585][train][INFO][train.py>_log] ==> #980000     Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 6.227    Value Loss: 5.817    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2945657    Buffer Size: 20904      Transition Number: 1199.997k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:37:12,254][train][INFO][train.py>_log] ==> #981000     Total Loss: 0.472    [weighted Loss:0.472    Policy Loss: 6.489    Value Loss: 5.811    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 2949101    Buffer Size: 21339      Transition Number: 1200.104k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:40:14,745][train][INFO][train.py>_log] ==> #982000     Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 6.642    Value Loss: 5.617    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2952464    Buffer Size: 21915      Transition Number: 1199.979k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:43:11,569][train][INFO][train.py>_log] ==> #983000     Total Loss: 1.166    [weighted Loss:1.166    Policy Loss: 6.905    Value Loss: 5.870    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 2955627    Buffer Size: 22366      Transition Number: 1200.233k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:46:11,596][train][INFO][train.py>_log] ==> #984000     Total Loss: 1.666    [weighted Loss:1.666    Policy Loss: 6.149    Value Loss: 5.963    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2958752    Buffer Size: 22698      Transition Number: 1200.026k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:49:12,257][train][INFO][train.py>_log] ==> #985000     Total Loss: 1.325    [weighted Loss:1.325    Policy Loss: 6.551    Value Loss: 5.909    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2961656    Buffer Size: 22736      Transition Number: 1200.037k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:52:15,462][train][INFO][train.py>_log] ==> #986000     Total Loss: 1.119    [weighted Loss:1.119    Policy Loss: 5.900    Value Loss: 6.056    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 2964684    Buffer Size: 22768      Transition Number: 1200.061k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:55:19,301][train][INFO][train.py>_log] ==> #987000     Total Loss: 0.934    [weighted Loss:0.934    Policy Loss: 5.915    Value Loss: 6.227    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2967829    Buffer Size: 22933      Transition Number: 1200.064k Batch Size: 256        Lr: 0.10000 
[2022-01-27 03:58:19,354][train][INFO][train.py>_log] ==> #988000     Total Loss: 1.539    [weighted Loss:1.539    Policy Loss: 5.998    Value Loss: 6.025    Reward Loss: 1.533    Consistency Loss: 0.000    ] Replay Episodes Collected: 2970883    Buffer Size: 22708      Transition Number: 1200.081k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:01:23,190][train][INFO][train.py>_log] ==> #989000     Total Loss: 1.622    [weighted Loss:1.622    Policy Loss: 6.193    Value Loss: 5.723    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2973945    Buffer Size: 22325      Transition Number: 1200.127k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:04:21,957][train][INFO][train.py>_log] ==> #990000     Total Loss: 1.419    [weighted Loss:1.419    Policy Loss: 5.204    Value Loss: 6.079    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2976939    Buffer Size: 22040      Transition Number: 1200.053k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:07:26,777][train][INFO][train.py>_log] ==> #991000     Total Loss: 2.034    [weighted Loss:2.034    Policy Loss: 6.144    Value Loss: 5.521    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2979922    Buffer Size: 21786      Transition Number: 1200.156k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:10:28,792][train][INFO][train.py>_log] ==> #992000     Total Loss: 0.918    [weighted Loss:0.918    Policy Loss: 6.366    Value Loss: 5.440    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2982936    Buffer Size: 21684      Transition Number: 1200.053k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:13:32,141][train][INFO][train.py>_log] ==> #993000     Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 6.224    Value Loss: 5.996    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 2986168    Buffer Size: 21815      Transition Number: 1200.101k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:16:32,379][train][INFO][train.py>_log] ==> #994000     Total Loss: 1.075    [weighted Loss:1.075    Policy Loss: 6.242    Value Loss: 6.039    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2989316    Buffer Size: 21890      Transition Number: 1200.170k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:19:34,525][train][INFO][train.py>_log] ==> #995000     Total Loss: 1.476    [weighted Loss:1.476    Policy Loss: 5.922    Value Loss: 5.748    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2992334    Buffer Size: 21876      Transition Number: 1200.098k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:22:32,904][train][INFO][train.py>_log] ==> #996000     Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 5.904    Value Loss: 5.924    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 2995282    Buffer Size: 21916      Transition Number: 1200.080k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:25:35,510][train][INFO][train.py>_log] ==> #997000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 6.676    Value Loss: 6.287    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 2998308    Buffer Size: 21972      Transition Number: 1200.045k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:28:40,974][train][INFO][train.py>_log] ==> #998000     Total Loss: 1.195    [weighted Loss:1.195    Policy Loss: 6.354    Value Loss: 6.101    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 3001465    Buffer Size: 22089      Transition Number: 1200.163k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:31:42,944][train][INFO][train.py>_log] ==> #999000     Total Loss: 0.826    [weighted Loss:0.826    Policy Loss: 5.532    Value Loss: 5.467    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 3004316    Buffer Size: 22032      Transition Number: 1200.066k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:34:45,749][train][INFO][train.py>_log] ==> #1000000    Total Loss: 1.168    [weighted Loss:1.168    Policy Loss: 5.686    Value Loss: 5.638    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 3007278    Buffer Size: 21859      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:37:44,824][train][INFO][train.py>_log] ==> #1001000    Total Loss: 0.862    [weighted Loss:0.862    Policy Loss: 5.622    Value Loss: 5.832    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 3010147    Buffer Size: 21625      Transition Number: 1200.067k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:40:43,413][train][INFO][train.py>_log] ==> #1002000    Total Loss: 2.619    [weighted Loss:2.619    Policy Loss: 5.504    Value Loss: 5.700    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 3012932    Buffer Size: 21456      Transition Number: 1200.107k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:43:45,325][train][INFO][train.py>_log] ==> #1003000    Total Loss: 1.533    [weighted Loss:1.533    Policy Loss: 5.673    Value Loss: 6.119    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 3015820    Buffer Size: 21257      Transition Number: 1200.107k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:46:42,615][train][INFO][train.py>_log] ==> #1004000    Total Loss: 1.814    [weighted Loss:1.814    Policy Loss: 6.151    Value Loss: 5.445    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 3018593    Buffer Size: 21029      Transition Number: 1200.092k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:49:46,211][train][INFO][train.py>_log] ==> #1005000    Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 5.766    Value Loss: 5.457    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 3021805    Buffer Size: 21142      Transition Number: 1200.114k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:52:46,576][train][INFO][train.py>_log] ==> #1006000    Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 5.757    Value Loss: 5.305    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 3025059    Buffer Size: 21398      Transition Number: 1200.021k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:55:46,942][train][INFO][train.py>_log] ==> #1007000    Total Loss: 1.500    [weighted Loss:1.500    Policy Loss: 6.453    Value Loss: 5.687    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 3028179    Buffer Size: 21587      Transition Number: 1200.210k Batch Size: 256        Lr: 0.10000 
[2022-01-27 04:58:47,443][train][INFO][train.py>_log] ==> #1008000    Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 5.477    Value Loss: 5.989    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 3031296    Buffer Size: 21748      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:01:50,608][train][INFO][train.py>_log] ==> #1009000    Total Loss: 1.705    [weighted Loss:1.705    Policy Loss: 6.323    Value Loss: 5.526    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 3034358    Buffer Size: 21857      Transition Number: 1199.942k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:04:55,547][train][INFO][train.py>_log] ==> #1010000    Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 5.910    Value Loss: 5.895    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 3037409    Buffer Size: 22009      Transition Number: 1200.034k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:07:57,472][train][INFO][train.py>_log] ==> #1011000    Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 6.189    Value Loss: 5.713    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 3040694    Buffer Size: 22477      Transition Number: 1200.163k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:11:01,847][train][INFO][train.py>_log] ==> #1012000    Total Loss: 0.442    [weighted Loss:0.442    Policy Loss: 6.106    Value Loss: 5.957    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 3044009    Buffer Size: 22646      Transition Number: 1200.263k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:14:04,616][train][INFO][train.py>_log] ==> #1013000    Total Loss: 1.129    [weighted Loss:1.129    Policy Loss: 5.460    Value Loss: 6.195    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 3046908    Buffer Size: 22311      Transition Number: 1200.205k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:17:03,729][train][INFO][train.py>_log] ==> #1014000    Total Loss: 1.301    [weighted Loss:1.301    Policy Loss: 6.009    Value Loss: 5.610    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 3049711    Buffer Size: 22085      Transition Number: 1200.160k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:20:05,391][train][INFO][train.py>_log] ==> #1015000    Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 5.906    Value Loss: 5.545    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 3052653    Buffer Size: 21935      Transition Number: 1200.109k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:23:06,471][train][INFO][train.py>_log] ==> #1016000    Total Loss: 1.653    [weighted Loss:1.653    Policy Loss: 6.166    Value Loss: 5.610    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 3055513    Buffer Size: 21808      Transition Number: 1200.089k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:26:10,376][train][INFO][train.py>_log] ==> #1017000    Total Loss: 1.129    [weighted Loss:1.129    Policy Loss: 6.114    Value Loss: 5.327    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 3058631    Buffer Size: 21958      Transition Number: 1199.988k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:29:13,862][train][INFO][train.py>_log] ==> #1018000    Total Loss: 1.039    [weighted Loss:1.039    Policy Loss: 5.416    Value Loss: 5.677    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 3061823    Buffer Size: 21893      Transition Number: 1199.973k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:32:19,478][train][INFO][train.py>_log] ==> #1019000    Total Loss: 2.040    [weighted Loss:2.040    Policy Loss: 6.122    Value Loss: 5.072    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 3064738    Buffer Size: 21423      Transition Number: 1200.202k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:35:20,612][train][INFO][train.py>_log] ==> #1020000    Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 6.232    Value Loss: 5.475    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 3067578    Buffer Size: 21207      Transition Number: 1200.123k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:38:20,390][train][INFO][train.py>_log] ==> #1021000    Total Loss: 0.950    [weighted Loss:0.950    Policy Loss: 6.372    Value Loss: 5.529    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 3070793    Buffer Size: 21514      Transition Number: 1200.374k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:41:19,502][train][INFO][train.py>_log] ==> #1022000    Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 6.270    Value Loss: 5.706    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 3074001    Buffer Size: 21772      Transition Number: 1200.019k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:44:23,921][train][INFO][train.py>_log] ==> #1023000    Total Loss: 1.623    [weighted Loss:1.623    Policy Loss: 6.197    Value Loss: 5.965    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 3077080    Buffer Size: 21870      Transition Number: 1200.017k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:47:29,909][train][INFO][train.py>_log] ==> #1024000    Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 6.541    Value Loss: 5.446    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 3080183    Buffer Size: 21759      Transition Number: 1200.129k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:50:32,282][train][INFO][train.py>_log] ==> #1025000    Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 6.934    Value Loss: 5.869    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 3083597    Buffer Size: 21931      Transition Number: 1200.094k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:53:33,119][train][INFO][train.py>_log] ==> #1026000    Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 7.206    Value Loss: 5.541    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 3086981    Buffer Size: 22388      Transition Number: 1200.211k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:56:35,733][train][INFO][train.py>_log] ==> #1027000    Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 6.836    Value Loss: 6.139    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 3090316    Buffer Size: 22891      Transition Number: 1200.003k Batch Size: 256        Lr: 0.10000 
[2022-01-27 05:59:38,883][train][INFO][train.py>_log] ==> #1028000    Total Loss: 1.906    [weighted Loss:1.906    Policy Loss: 7.250    Value Loss: 6.137    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 3093630    Buffer Size: 23038      Transition Number: 1200.076k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:02:40,517][train][INFO][train.py>_log] ==> #1029000    Total Loss: 2.753    [weighted Loss:2.753    Policy Loss: 7.456    Value Loss: 6.102    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 3097255    Buffer Size: 23551      Transition Number: 1200.381k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:05:37,291][train][INFO][train.py>_log] ==> #1030000    Total Loss: 1.738    [weighted Loss:1.738    Policy Loss: 7.421    Value Loss: 6.312    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 3100850    Buffer Size: 24220      Transition Number: 1200.116k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:08:37,316][train][INFO][train.py>_log] ==> #1031000    Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 6.913    Value Loss: 6.687    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 3103910    Buffer Size: 24425      Transition Number: 1200.230k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:11:38,067][train][INFO][train.py>_log] ==> #1032000    Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 7.056    Value Loss: 6.380    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 3106959    Buffer Size: 24324      Transition Number: 1200.013k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:14:39,243][train][INFO][train.py>_log] ==> #1033000    Total Loss: 2.559    [weighted Loss:2.559    Policy Loss: 7.063    Value Loss: 6.186    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 3110377    Buffer Size: 24560      Transition Number: 1200.015k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:17:39,849][train][INFO][train.py>_log] ==> #1034000    Total Loss: 2.053    [weighted Loss:2.053    Policy Loss: 6.468    Value Loss: 6.248    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 3113741    Buffer Size: 24792      Transition Number: 1200.030k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:20:41,235][train][INFO][train.py>_log] ==> #1035000    Total Loss: 1.639    [weighted Loss:1.639    Policy Loss: 6.339    Value Loss: 6.718    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 3116861    Buffer Size: 24667      Transition Number: 1200.305k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:23:41,369][train][INFO][train.py>_log] ==> #1036000    Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 6.612    Value Loss: 5.656    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 3119855    Buffer Size: 24300      Transition Number: 1200.148k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:26:43,347][train][INFO][train.py>_log] ==> #1037000    Total Loss: 1.115    [weighted Loss:1.115    Policy Loss: 6.139    Value Loss: 6.125    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 3122670    Buffer Size: 23525      Transition Number: 1200.150k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:29:43,452][train][INFO][train.py>_log] ==> #1038000    Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 6.330    Value Loss: 5.735    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 3125468    Buffer Size: 22934      Transition Number: 1200.284k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:32:44,409][train][INFO][train.py>_log] ==> #1039000    Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 5.925    Value Loss: 5.451    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 3128412    Buffer Size: 22760      Transition Number: 1200.113k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:35:45,217][train][INFO][train.py>_log] ==> #1040000    Total Loss: 1.694    [weighted Loss:1.694    Policy Loss: 6.327    Value Loss: 5.733    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 3131317    Buffer Size: 22378      Transition Number: 1200.029k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:38:49,382][train][INFO][train.py>_log] ==> #1041000    Total Loss: 1.555    [weighted Loss:1.555    Policy Loss: 5.498    Value Loss: 6.015    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 3134373    Buffer Size: 21860      Transition Number: 1200.400k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:41:51,196][train][INFO][train.py>_log] ==> #1042000    Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 5.844    Value Loss: 5.729    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 3137404    Buffer Size: 21598      Transition Number: 1200.094k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:44:56,758][train][INFO][train.py>_log] ==> #1043000    Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 5.716    Value Loss: 5.694    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 3140479    Buffer Size: 21492      Transition Number: 1200.100k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:47:55,822][train][INFO][train.py>_log] ==> #1044000    Total Loss: 1.995    [weighted Loss:1.995    Policy Loss: 6.037    Value Loss: 5.679    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 3143418    Buffer Size: 21519      Transition Number: 1200.259k Batch Size: 256        Lr: 0.10000 
[2022-01-27 06:51:00,711][train][INFO][train.py>_log] ==> #1045000    Total Loss: 1.404    [weighted Loss:1.404    Policy Loss: 6.356    Value Loss: 5.708    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 3147176    Buffer Size: 22177      Transition Number: 1200.123k Batch Size: 256        Lr: 0.10000 
