[2022-01-02 09:41:33,626][train][INFO][train.py>_log] ==> #0          Total Loss: 29.667   [weighted Loss:29.667   Policy Loss: 17.597   Value Loss: 36.163   Reward Loss: 3.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 6480       Buffer Size: 6480       Transition Number: 80.285  k Batch Size: 256        Lr: 0.00000 
[2022-01-02 09:45:55,131][train][INFO][train.py>_log] ==> #1000       Total Loss: 4.349    [weighted Loss:4.349    Policy Loss: 8.880    Value Loss: 7.950    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 6996       Buffer Size: 6996       Transition Number: 113.585 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 09:50:17,865][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.430    [weighted Loss:3.430    Policy Loss: 6.643    Value Loss: 7.022    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 7638       Buffer Size: 7638       Transition Number: 156.325 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 09:54:42,197][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.791    [weighted Loss:3.791    Policy Loss: 6.996    Value Loss: 7.286    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 8252       Buffer Size: 8252       Transition Number: 197.079 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 09:59:05,876][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.246    [weighted Loss:4.246    Policy Loss: 7.007    Value Loss: 6.445    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 8800       Buffer Size: 8800       Transition Number: 232.868 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:03:29,647][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.552    [weighted Loss:3.552    Policy Loss: 7.090    Value Loss: 6.732    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 9405       Buffer Size: 9405       Transition Number: 273.087 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:07:49,887][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.086    [weighted Loss:4.086    Policy Loss: 7.180    Value Loss: 6.291    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 10004      Buffer Size: 10004      Transition Number: 312.324 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:12:10,080][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.956    [weighted Loss:4.956    Policy Loss: 7.274    Value Loss: 6.191    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 10536      Buffer Size: 10536      Transition Number: 347.412 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:16:34,177][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.142    [weighted Loss:4.142    Policy Loss: 8.047    Value Loss: 6.368    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 11177      Buffer Size: 11177      Transition Number: 389.712 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:21:00,367][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.648    [weighted Loss:3.648    Policy Loss: 7.469    Value Loss: 6.509    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 11803      Buffer Size: 11803      Transition Number: 430.772 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:25:20,790][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.472    [weighted Loss:4.472    Policy Loss: 7.585    Value Loss: 5.987    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 12408      Buffer Size: 12408      Transition Number: 470.762 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:29:40,581][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.728    [weighted Loss:4.728    Policy Loss: 7.230    Value Loss: 6.094    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 12976      Buffer Size: 12976      Transition Number: 507.927 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:33:59,389][train][INFO][train.py>_log] ==> #12000      Total Loss: 4.732    [weighted Loss:4.732    Policy Loss: 8.499    Value Loss: 6.538    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 13557      Buffer Size: 13557      Transition Number: 546.055 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:38:20,406][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.428    [weighted Loss:4.428    Policy Loss: 8.200    Value Loss: 5.829    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 14151      Buffer Size: 14151      Transition Number: 584.775 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:42:39,500][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.278    [weighted Loss:4.278    Policy Loss: 7.539    Value Loss: 5.949    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 14739      Buffer Size: 14739      Transition Number: 622.996 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:46:56,298][train][INFO][train.py>_log] ==> #15000      Total Loss: 5.852    [weighted Loss:5.852    Policy Loss: 8.818    Value Loss: 5.944    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 15334      Buffer Size: 15334      Transition Number: 661.849 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:51:13,382][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 8.240    Value Loss: 5.823    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 15917      Buffer Size: 15917      Transition Number: 699.720 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:55:31,686][train][INFO][train.py>_log] ==> #17000      Total Loss: 3.945    [weighted Loss:3.945    Policy Loss: 8.864    Value Loss: 6.016    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 16503      Buffer Size: 16503      Transition Number: 737.840 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 10:59:47,814][train][INFO][train.py>_log] ==> #18000      Total Loss: 4.158    [weighted Loss:4.158    Policy Loss: 8.631    Value Loss: 6.145    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 17053      Buffer Size: 17053      Transition Number: 773.590 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:04:05,041][train][INFO][train.py>_log] ==> #19000      Total Loss: 4.238    [weighted Loss:4.238    Policy Loss: 8.800    Value Loss: 5.680    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 17659      Buffer Size: 17659      Transition Number: 812.716 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:08:23,786][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.303    [weighted Loss:4.303    Policy Loss: 8.734    Value Loss: 5.598    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 18261      Buffer Size: 18261      Transition Number: 851.675 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:12:43,248][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.590    [weighted Loss:5.590    Policy Loss: 9.295    Value Loss: 5.820    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 18801      Buffer Size: 18801      Transition Number: 886.433 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:17:01,013][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.884    [weighted Loss:4.884    Policy Loss: 8.637    Value Loss: 5.861    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 19431      Buffer Size: 19431      Transition Number: 926.975 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:21:20,057][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.328    [weighted Loss:4.328    Policy Loss: 8.848    Value Loss: 6.016    Reward Loss: 1.934    Consistency Loss: 0.000    ] Replay Episodes Collected: 19999      Buffer Size: 19999      Transition Number: 963.038 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:25:39,762][train][INFO][train.py>_log] ==> #24000      Total Loss: 6.333    [weighted Loss:6.333    Policy Loss: 9.453    Value Loss: 5.731    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 20617      Buffer Size: 20359      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:30:08,615][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.853    [weighted Loss:5.853    Policy Loss: 9.518    Value Loss: 6.293    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 21222      Buffer Size: 17891      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:34:35,569][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.000    [weighted Loss:5.000    Policy Loss: 9.647    Value Loss: 5.804    Reward Loss: 1.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 21847      Buffer Size: 15340      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:38:56,625][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.456    [weighted Loss:3.456    Policy Loss: 9.816    Value Loss: 5.842    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 22418      Buffer Size: 15357      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:43:18,812][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 9.738    Value Loss: 5.836    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 23038      Buffer Size: 15388      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:47:47,512][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.928    [weighted Loss:3.928    Policy Loss: 10.539   Value Loss: 5.837    Reward Loss: 1.914    Consistency Loss: 0.000    ] Replay Episodes Collected: 23603      Buffer Size: 15411      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:52:11,634][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.576    [weighted Loss:2.576    Policy Loss: 10.300   Value Loss: 5.541    Reward Loss: 1.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 24212      Buffer Size: 15424      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 11:56:34,578][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.244    [weighted Loss:4.244    Policy Loss: 10.725   Value Loss: 5.542    Reward Loss: 1.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 24845      Buffer Size: 15449      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:01:01,319][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.078    [weighted Loss:4.078    Policy Loss: 10.221   Value Loss: 5.768    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 25448      Buffer Size: 15466      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:05:28,391][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.555    [weighted Loss:4.555    Policy Loss: 10.187   Value Loss: 6.072    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 26037      Buffer Size: 15486      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:09:54,308][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.543    [weighted Loss:4.543    Policy Loss: 10.451   Value Loss: 5.772    Reward Loss: 1.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 26629      Buffer Size: 15505      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:14:17,424][train][INFO][train.py>_log] ==> #35000      Total Loss: 6.392    [weighted Loss:6.392    Policy Loss: 10.945   Value Loss: 6.399    Reward Loss: 1.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 27247      Buffer Size: 15523      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:18:40,928][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.891    [weighted Loss:3.891    Policy Loss: 10.850   Value Loss: 5.880    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 27811      Buffer Size: 15542      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:23:05,746][train][INFO][train.py>_log] ==> #37000      Total Loss: 4.909    [weighted Loss:4.909    Policy Loss: 10.382   Value Loss: 6.071    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 28422      Buffer Size: 15555      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:27:31,270][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.494    [weighted Loss:2.494    Policy Loss: 10.042   Value Loss: 6.135    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 29031      Buffer Size: 15566      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:31:55,735][train][INFO][train.py>_log] ==> #39000      Total Loss: 4.454    [weighted Loss:4.454    Policy Loss: 10.101   Value Loss: 6.123    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 29652      Buffer Size: 15577      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:36:22,181][train][INFO][train.py>_log] ==> #40000      Total Loss: 5.799    [weighted Loss:5.799    Policy Loss: 10.249   Value Loss: 6.310    Reward Loss: 1.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 30225      Buffer Size: 15580      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:40:55,249][train][INFO][train.py>_log] ==> #41000      Total Loss: 6.103    [weighted Loss:6.103    Policy Loss: 9.808    Value Loss: 6.149    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 30860      Buffer Size: 15583      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:45:24,422][train][INFO][train.py>_log] ==> #42000      Total Loss: 5.041    [weighted Loss:5.041    Policy Loss: 10.132   Value Loss: 6.217    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 31483      Buffer Size: 15586      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:49:55,104][train][INFO][train.py>_log] ==> #43000      Total Loss: 4.706    [weighted Loss:4.706    Policy Loss: 10.085   Value Loss: 6.644    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 32106      Buffer Size: 15592      Transition Number: 1000.057k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:54:21,132][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.879    [weighted Loss:3.879    Policy Loss: 10.203   Value Loss: 5.811    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 32716      Buffer Size: 15595      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00050 
[2022-01-02 12:58:47,525][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.597    [weighted Loss:4.597    Policy Loss: 10.200   Value Loss: 6.604    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 33285      Buffer Size: 15589      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:03:10,550][train][INFO][train.py>_log] ==> #46000      Total Loss: 3.516    [weighted Loss:3.516    Policy Loss: 10.178   Value Loss: 6.349    Reward Loss: 1.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 33885      Buffer Size: 15585      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:07:31,022][train][INFO][train.py>_log] ==> #47000      Total Loss: 6.161    [weighted Loss:6.161    Policy Loss: 9.924    Value Loss: 6.489    Reward Loss: 1.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 34510      Buffer Size: 15582      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:11:53,322][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.876    [weighted Loss:3.876    Policy Loss: 10.503   Value Loss: 6.131    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 35113      Buffer Size: 15582      Transition Number: 1000.031k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:16:16,333][train][INFO][train.py>_log] ==> #49000      Total Loss: 5.934    [weighted Loss:5.934    Policy Loss: 10.336   Value Loss: 6.722    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 35693      Buffer Size: 15573      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:20:38,194][train][INFO][train.py>_log] ==> #50000      Total Loss: 4.266    [weighted Loss:4.266    Policy Loss: 10.914   Value Loss: 6.770    Reward Loss: 1.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 36296      Buffer Size: 15571      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:24:59,215][train][INFO][train.py>_log] ==> #51000      Total Loss: 4.988    [weighted Loss:4.988    Policy Loss: 10.419   Value Loss: 6.734    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 36877      Buffer Size: 15570      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:29:19,481][train][INFO][train.py>_log] ==> #52000      Total Loss: 5.792    [weighted Loss:5.792    Policy Loss: 10.022   Value Loss: 6.242    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 37481      Buffer Size: 15575      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:33:46,343][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.465    [weighted Loss:3.465    Policy Loss: 10.387   Value Loss: 6.403    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 38068      Buffer Size: 15582      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:38:07,664][train][INFO][train.py>_log] ==> #54000      Total Loss: 4.507    [weighted Loss:4.507    Policy Loss: 10.364   Value Loss: 6.540    Reward Loss: 1.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 38690      Buffer Size: 15584      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:42:27,087][train][INFO][train.py>_log] ==> #55000      Total Loss: 5.267    [weighted Loss:5.267    Policy Loss: 10.551   Value Loss: 6.573    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 39288      Buffer Size: 15615      Transition Number: 999.931 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:46:51,432][train][INFO][train.py>_log] ==> #56000      Total Loss: 5.014    [weighted Loss:5.014    Policy Loss: 10.164   Value Loss: 6.955    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 39910      Buffer Size: 15653      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:51:17,511][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.932    [weighted Loss:4.932    Policy Loss: 10.264   Value Loss: 7.010    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 40528      Buffer Size: 15692      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 13:55:37,463][train][INFO][train.py>_log] ==> #58000      Total Loss: 5.546    [weighted Loss:5.546    Policy Loss: 10.060   Value Loss: 6.770    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 41158      Buffer Size: 15728      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:00:00,281][train][INFO][train.py>_log] ==> #59000      Total Loss: 4.848    [weighted Loss:4.848    Policy Loss: 9.877    Value Loss: 7.107    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 41776      Buffer Size: 15773      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:04:18,425][train][INFO][train.py>_log] ==> #60000      Total Loss: 4.469    [weighted Loss:4.469    Policy Loss: 10.028   Value Loss: 7.991    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 42411      Buffer Size: 15832      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:08:42,277][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.810    [weighted Loss:4.810    Policy Loss: 10.598   Value Loss: 7.474    Reward Loss: 1.907    Consistency Loss: 0.000    ] Replay Episodes Collected: 43055      Buffer Size: 15904      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:13:03,021][train][INFO][train.py>_log] ==> #62000      Total Loss: 6.045    [weighted Loss:6.045    Policy Loss: 10.156   Value Loss: 7.551    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 43694      Buffer Size: 15970      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:17:22,980][train][INFO][train.py>_log] ==> #63000      Total Loss: 5.027    [weighted Loss:5.027    Policy Loss: 9.840    Value Loss: 7.272    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 44282      Buffer Size: 16005      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:21:44,500][train][INFO][train.py>_log] ==> #64000      Total Loss: 5.927    [weighted Loss:5.927    Policy Loss: 10.319   Value Loss: 7.862    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 44932      Buffer Size: 16051      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:26:07,316][train][INFO][train.py>_log] ==> #65000      Total Loss: 5.005    [weighted Loss:5.005    Policy Loss: 9.197    Value Loss: 7.464    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 45527      Buffer Size: 16074      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:30:29,189][train][INFO][train.py>_log] ==> #66000      Total Loss: 5.528    [weighted Loss:5.528    Policy Loss: 8.797    Value Loss: 7.988    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 46110      Buffer Size: 16092      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:34:52,628][train][INFO][train.py>_log] ==> #67000      Total Loss: 6.076    [weighted Loss:6.076    Policy Loss: 8.869    Value Loss: 7.433    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 46703      Buffer Size: 16109      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:39:16,509][train][INFO][train.py>_log] ==> #68000      Total Loss: 5.890    [weighted Loss:5.890    Policy Loss: 8.740    Value Loss: 7.999    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 47324      Buffer Size: 16118      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:43:42,216][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.976    [weighted Loss:3.976    Policy Loss: 8.612    Value Loss: 7.506    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 47919      Buffer Size: 16124      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:47:59,823][train][INFO][train.py>_log] ==> #70000      Total Loss: 4.165    [weighted Loss:4.165    Policy Loss: 8.483    Value Loss: 7.678    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 48540      Buffer Size: 16124      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:52:20,466][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.612    [weighted Loss:3.612    Policy Loss: 8.326    Value Loss: 7.568    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 49121      Buffer Size: 16120      Transition Number: 1000.164k Batch Size: 256        Lr: 0.00050 
[2022-01-02 14:56:45,531][train][INFO][train.py>_log] ==> #72000      Total Loss: 4.756    [weighted Loss:4.756    Policy Loss: 7.813    Value Loss: 7.170    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 49696      Buffer Size: 16127      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:01:10,731][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.084    [weighted Loss:3.084    Policy Loss: 8.196    Value Loss: 7.366    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 50306      Buffer Size: 16119      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:05:34,096][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.172    [weighted Loss:4.172    Policy Loss: 7.922    Value Loss: 7.717    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 50878      Buffer Size: 16106      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:09:55,700][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.719    [weighted Loss:4.719    Policy Loss: 7.889    Value Loss: 7.471    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 51491      Buffer Size: 16094      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:14:15,071][train][INFO][train.py>_log] ==> #76000      Total Loss: 6.369    [weighted Loss:6.369    Policy Loss: 7.937    Value Loss: 7.797    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 52102      Buffer Size: 16087      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:18:40,298][train][INFO][train.py>_log] ==> #77000      Total Loss: 5.141    [weighted Loss:5.141    Policy Loss: 7.160    Value Loss: 7.974    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 52679      Buffer Size: 16067      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:22:59,865][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.297    [weighted Loss:5.297    Policy Loss: 7.459    Value Loss: 7.874    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 53260      Buffer Size: 16048      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:27:19,320][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 7.587    Value Loss: 7.789    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 53832      Buffer Size: 16017      Transition Number: 1000.121k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:31:42,998][train][INFO][train.py>_log] ==> #80000      Total Loss: 5.172    [weighted Loss:5.172    Policy Loss: 7.666    Value Loss: 7.620    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 54436      Buffer Size: 15976      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:36:07,477][train][INFO][train.py>_log] ==> #81000      Total Loss: 5.242    [weighted Loss:5.242    Policy Loss: 7.519    Value Loss: 8.146    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 55041      Buffer Size: 15916      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:40:31,808][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.453    [weighted Loss:3.453    Policy Loss: 7.252    Value Loss: 7.716    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 55645      Buffer Size: 15841      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:44:53,535][train][INFO][train.py>_log] ==> #83000      Total Loss: 1.557    [weighted Loss:1.557    Policy Loss: 7.320    Value Loss: 7.568    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 56223      Buffer Size: 15771      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:49:17,165][train][INFO][train.py>_log] ==> #84000      Total Loss: 5.024    [weighted Loss:5.024    Policy Loss: 8.163    Value Loss: 8.005    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 56815      Buffer Size: 15696      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:53:43,124][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.362    [weighted Loss:3.362    Policy Loss: 7.431    Value Loss: 7.320    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 57397      Buffer Size: 15612      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 15:58:05,561][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.803    [weighted Loss:1.803    Policy Loss: 7.849    Value Loss: 7.464    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 57967      Buffer Size: 15515      Transition Number: 1000.241k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:02:26,268][train][INFO][train.py>_log] ==> #87000      Total Loss: 5.419    [weighted Loss:5.419    Policy Loss: 7.999    Value Loss: 7.112    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 58563      Buffer Size: 15392      Transition Number: 1000.031k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:06:44,570][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.179    [weighted Loss:4.179    Policy Loss: 7.692    Value Loss: 7.418    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 59132      Buffer Size: 15295      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:11:11,922][train][INFO][train.py>_log] ==> #89000      Total Loss: 4.829    [weighted Loss:4.829    Policy Loss: 7.832    Value Loss: 6.880    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 59700      Buffer Size: 15221      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:15:30,913][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 7.982    Value Loss: 6.831    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 60309      Buffer Size: 15145      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:19:50,577][train][INFO][train.py>_log] ==> #91000      Total Loss: 5.370    [weighted Loss:5.370    Policy Loss: 8.042    Value Loss: 7.346    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 60898      Buffer Size: 15090      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:24:12,908][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.861    [weighted Loss:3.861    Policy Loss: 8.153    Value Loss: 7.101    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 61436      Buffer Size: 15050      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:28:35,469][train][INFO][train.py>_log] ==> #93000      Total Loss: 4.462    [weighted Loss:4.462    Policy Loss: 8.291    Value Loss: 6.619    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 62022      Buffer Size: 15009      Transition Number: 1000.323k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:32:55,483][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.316    [weighted Loss:4.316    Policy Loss: 8.341    Value Loss: 6.743    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 62616      Buffer Size: 14965      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:37:16,755][train][INFO][train.py>_log] ==> #95000      Total Loss: 4.711    [weighted Loss:4.711    Policy Loss: 8.377    Value Loss: 7.206    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 63177      Buffer Size: 14930      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:41:33,645][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.373    [weighted Loss:5.373    Policy Loss: 8.138    Value Loss: 7.043    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 63766      Buffer Size: 14897      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:46:00,182][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.329    [weighted Loss:4.329    Policy Loss: 8.410    Value Loss: 6.788    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 64313      Buffer Size: 14868      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:50:16,572][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.733    [weighted Loss:3.733    Policy Loss: 7.986    Value Loss: 6.679    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 64881      Buffer Size: 14843      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:54:35,901][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.544    [weighted Loss:3.544    Policy Loss: 8.281    Value Loss: 6.632    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 65467      Buffer Size: 14829      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 16:58:58,900][train][INFO][train.py>_log] ==> #100000     Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 8.463    Value Loss: 6.654    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 66051      Buffer Size: 14804      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:03:24,897][train][INFO][train.py>_log] ==> #101000     Total Loss: 5.407    [weighted Loss:5.407    Policy Loss: 8.889    Value Loss: 6.732    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 66617      Buffer Size: 14777      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:07:46,287][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.908    [weighted Loss:2.908    Policy Loss: 8.864    Value Loss: 7.117    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 67215      Buffer Size: 14761      Transition Number: 1000.168k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:12:05,546][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.784    [weighted Loss:3.784    Policy Loss: 8.474    Value Loss: 6.867    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 67779      Buffer Size: 14742      Transition Number: 1000.243k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:16:28,670][train][INFO][train.py>_log] ==> #104000     Total Loss: 4.892    [weighted Loss:4.892    Policy Loss: 8.460    Value Loss: 6.564    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 68362      Buffer Size: 14723      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:20:53,229][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.242    [weighted Loss:3.242    Policy Loss: 9.241    Value Loss: 6.922    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 68952      Buffer Size: 14713      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:25:14,310][train][INFO][train.py>_log] ==> #106000     Total Loss: 3.878    [weighted Loss:3.878    Policy Loss: 8.783    Value Loss: 6.311    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 69513      Buffer Size: 14713      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:29:34,549][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.931    [weighted Loss:3.931    Policy Loss: 9.136    Value Loss: 7.137    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 70114      Buffer Size: 14715      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:33:56,217][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.889    [weighted Loss:4.889    Policy Loss: 9.066    Value Loss: 6.832    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 70694      Buffer Size: 14709      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:38:19,808][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 9.535    Value Loss: 6.810    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 71254      Buffer Size: 14725      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:42:40,517][train][INFO][train.py>_log] ==> #110000     Total Loss: 5.761    [weighted Loss:5.761    Policy Loss: 8.942    Value Loss: 6.807    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 71852      Buffer Size: 14743      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:46:57,652][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.497    [weighted Loss:3.497    Policy Loss: 8.970    Value Loss: 6.240    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 72455      Buffer Size: 14809      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:51:18,176][train][INFO][train.py>_log] ==> #112000     Total Loss: 5.893    [weighted Loss:5.893    Policy Loss: 8.876    Value Loss: 6.881    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 73071      Buffer Size: 14875      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:55:39,109][train][INFO][train.py>_log] ==> #113000     Total Loss: 4.404    [weighted Loss:4.404    Policy Loss: 9.044    Value Loss: 7.443    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 73720      Buffer Size: 14996      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 17:59:58,894][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.758    [weighted Loss:3.758    Policy Loss: 9.448    Value Loss: 7.655    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 74391      Buffer Size: 15129      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:04:17,623][train][INFO][train.py>_log] ==> #115000     Total Loss: 5.371    [weighted Loss:5.371    Policy Loss: 10.320   Value Loss: 8.104    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 75201      Buffer Size: 15403      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:08:34,782][train][INFO][train.py>_log] ==> #116000     Total Loss: 6.154    [weighted Loss:6.154    Policy Loss: 10.456   Value Loss: 8.257    Reward Loss: 1.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 75974      Buffer Size: 15651      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:12:58,514][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.391    [weighted Loss:4.391    Policy Loss: 10.343   Value Loss: 8.894    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 76741      Buffer Size: 15893      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:17:16,466][train][INFO][train.py>_log] ==> #118000     Total Loss: 6.104    [weighted Loss:6.104    Policy Loss: 10.857   Value Loss: 8.696    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 77524      Buffer Size: 16148      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:21:36,221][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.390    [weighted Loss:3.390    Policy Loss: 10.292   Value Loss: 8.487    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 78226      Buffer Size: 16347      Transition Number: 999.932 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:25:57,758][train][INFO][train.py>_log] ==> #120000     Total Loss: 5.271    [weighted Loss:5.271    Policy Loss: 9.651    Value Loss: 8.575    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 78969      Buffer Size: 16555      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:30:19,241][train][INFO][train.py>_log] ==> #121000     Total Loss: 5.501    [weighted Loss:5.501    Policy Loss: 9.595    Value Loss: 9.221    Reward Loss: 1.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 79667      Buffer Size: 16727      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:34:36,749][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.813    [weighted Loss:3.813    Policy Loss: 9.152    Value Loss: 8.509    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 80330      Buffer Size: 16881      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:38:59,731][train][INFO][train.py>_log] ==> #123000     Total Loss: 5.189    [weighted Loss:5.189    Policy Loss: 8.821    Value Loss: 8.922    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 80965      Buffer Size: 17009      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:43:18,216][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.233    [weighted Loss:4.233    Policy Loss: 8.544    Value Loss: 9.197    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 81618      Buffer Size: 17130      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:47:43,577][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 8.422    Value Loss: 9.006    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 82215      Buffer Size: 17224      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:52:02,951][train][INFO][train.py>_log] ==> #126000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 8.575    Value Loss: 9.098    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 82842      Buffer Size: 17329      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 18:56:19,611][train][INFO][train.py>_log] ==> #127000     Total Loss: 4.818    [weighted Loss:4.818    Policy Loss: 8.568    Value Loss: 8.872    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 83416      Buffer Size: 17398      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:00:38,903][train][INFO][train.py>_log] ==> #128000     Total Loss: 3.855    [weighted Loss:3.855    Policy Loss: 8.095    Value Loss: 9.291    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 83996      Buffer Size: 17465      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:05:01,753][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.693    [weighted Loss:3.693    Policy Loss: 7.771    Value Loss: 8.713    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 84578      Buffer Size: 17510      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:09:21,329][train][INFO][train.py>_log] ==> #130000     Total Loss: 4.207    [weighted Loss:4.207    Policy Loss: 7.672    Value Loss: 9.102    Reward Loss: 1.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 85141      Buffer Size: 17554      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:13:41,149][train][INFO][train.py>_log] ==> #131000     Total Loss: 5.008    [weighted Loss:5.008    Policy Loss: 8.055    Value Loss: 8.791    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 85696      Buffer Size: 17595      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:18:01,347][train][INFO][train.py>_log] ==> #132000     Total Loss: 4.777    [weighted Loss:4.777    Policy Loss: 7.580    Value Loss: 8.836    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 86297      Buffer Size: 17636      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:22:23,389][train][INFO][train.py>_log] ==> #133000     Total Loss: 4.270    [weighted Loss:4.270    Policy Loss: 7.650    Value Loss: 8.712    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 86823      Buffer Size: 17659      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:26:44,379][train][INFO][train.py>_log] ==> #134000     Total Loss: 4.463    [weighted Loss:4.463    Policy Loss: 7.964    Value Loss: 8.611    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 87421      Buffer Size: 17685      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:31:01,717][train][INFO][train.py>_log] ==> #135000     Total Loss: 4.815    [weighted Loss:4.815    Policy Loss: 7.555    Value Loss: 7.919    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 87973      Buffer Size: 17700      Transition Number: 1000.183k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:35:23,011][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 7.637    Value Loss: 8.982    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 88570      Buffer Size: 17711      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:39:49,981][train][INFO][train.py>_log] ==> #137000     Total Loss: 4.071    [weighted Loss:4.071    Policy Loss: 7.903    Value Loss: 9.464    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 89128      Buffer Size: 17706      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:44:09,504][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.143    [weighted Loss:4.143    Policy Loss: 7.294    Value Loss: 8.030    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 89730      Buffer Size: 17685      Transition Number: 1000.031k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:48:28,208][train][INFO][train.py>_log] ==> #139000     Total Loss: 5.504    [weighted Loss:5.504    Policy Loss: 8.099    Value Loss: 8.394    Reward Loss: 1.897    Consistency Loss: 0.000    ] Replay Episodes Collected: 90293      Buffer Size: 17621      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:52:49,520][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.934    [weighted Loss:3.934    Policy Loss: 7.340    Value Loss: 8.018    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 90874      Buffer Size: 17550      Transition Number: 1000.206k Batch Size: 256        Lr: 0.00050 
[2022-01-02 19:57:14,702][train][INFO][train.py>_log] ==> #141000     Total Loss: 3.748    [weighted Loss:3.748    Policy Loss: 7.533    Value Loss: 8.050    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 91432      Buffer Size: 17431      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:01:34,398][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 7.337    Value Loss: 7.952    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 92007      Buffer Size: 17210      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:05:54,540][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.870    [weighted Loss:3.870    Policy Loss: 7.457    Value Loss: 8.192    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 92610      Buffer Size: 16926      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:10:19,286][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.618    [weighted Loss:3.618    Policy Loss: 7.910    Value Loss: 7.992    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 93200      Buffer Size: 16658      Transition Number: 1000.131k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:14:45,830][train][INFO][train.py>_log] ==> #145000     Total Loss: 5.067    [weighted Loss:5.067    Policy Loss: 7.666    Value Loss: 7.581    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 93773      Buffer Size: 16389      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:19:02,148][train][INFO][train.py>_log] ==> #146000     Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 7.550    Value Loss: 7.636    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 94322      Buffer Size: 16166      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:23:19,791][train][INFO][train.py>_log] ==> #147000     Total Loss: 4.085    [weighted Loss:4.085    Policy Loss: 7.938    Value Loss: 7.898    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 94901      Buffer Size: 15939      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:27:39,910][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.935    [weighted Loss:3.935    Policy Loss: 7.393    Value Loss: 7.577    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 95511      Buffer Size: 15748      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:32:04,342][train][INFO][train.py>_log] ==> #149000     Total Loss: 4.127    [weighted Loss:4.127    Policy Loss: 7.566    Value Loss: 7.276    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 96085      Buffer Size: 15586      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:36:27,105][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.067    [weighted Loss:3.067    Policy Loss: 7.607    Value Loss: 7.447    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 96628      Buffer Size: 15458      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:40:47,492][train][INFO][train.py>_log] ==> #151000     Total Loss: 4.501    [weighted Loss:4.501    Policy Loss: 8.178    Value Loss: 7.514    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 97232      Buffer Size: 15335      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:45:11,341][train][INFO][train.py>_log] ==> #152000     Total Loss: 3.488    [weighted Loss:3.488    Policy Loss: 7.461    Value Loss: 7.571    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 97838      Buffer Size: 15212      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:49:37,875][train][INFO][train.py>_log] ==> #153000     Total Loss: 5.661    [weighted Loss:5.661    Policy Loss: 7.742    Value Loss: 7.722    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 98390      Buffer Size: 15122      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:53:58,297][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 7.539    Value Loss: 7.391    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 99008      Buffer Size: 15046      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00050 
[2022-01-02 20:58:17,870][train][INFO][train.py>_log] ==> #155000     Total Loss: 2.556    [weighted Loss:2.556    Policy Loss: 7.343    Value Loss: 7.341    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 99562      Buffer Size: 14999      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:02:36,291][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.196    [weighted Loss:3.196    Policy Loss: 8.211    Value Loss: 7.395    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 100149     Buffer Size: 14949      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:07:04,118][train][INFO][train.py>_log] ==> #157000     Total Loss: 4.745    [weighted Loss:4.745    Policy Loss: 7.831    Value Loss: 7.335    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 100699     Buffer Size: 14912      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:11:25,871][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 7.844    Value Loss: 7.571    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 101290     Buffer Size: 14869      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:15:46,240][train][INFO][train.py>_log] ==> #159000     Total Loss: 4.270    [weighted Loss:4.270    Policy Loss: 7.970    Value Loss: 7.182    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 101861     Buffer Size: 14850      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:20:08,716][train][INFO][train.py>_log] ==> #160000     Total Loss: 4.705    [weighted Loss:4.705    Policy Loss: 7.852    Value Loss: 7.729    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 102465     Buffer Size: 14829      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:24:34,310][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.969    [weighted Loss:3.969    Policy Loss: 8.167    Value Loss: 7.507    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 103048     Buffer Size: 14828      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:28:57,981][train][INFO][train.py>_log] ==> #162000     Total Loss: 4.260    [weighted Loss:4.260    Policy Loss: 8.172    Value Loss: 7.279    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 103645     Buffer Size: 14823      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:33:18,596][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.539    [weighted Loss:3.539    Policy Loss: 8.108    Value Loss: 7.528    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 104250     Buffer Size: 14831      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:37:37,536][train][INFO][train.py>_log] ==> #164000     Total Loss: 3.199    [weighted Loss:3.199    Policy Loss: 8.305    Value Loss: 7.172    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 104823     Buffer Size: 14833      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:42:03,808][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.673    [weighted Loss:3.673    Policy Loss: 8.098    Value Loss: 7.361    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 105432     Buffer Size: 14848      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:46:23,194][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.899    [weighted Loss:3.899    Policy Loss: 8.433    Value Loss: 6.988    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 106046     Buffer Size: 14873      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:50:40,261][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.582    [weighted Loss:3.582    Policy Loss: 8.411    Value Loss: 7.327    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 106622     Buffer Size: 14905      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:54:58,614][train][INFO][train.py>_log] ==> #168000     Total Loss: 5.766    [weighted Loss:5.766    Policy Loss: 8.664    Value Loss: 7.462    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 107226     Buffer Size: 14923      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 21:59:25,451][train][INFO][train.py>_log] ==> #169000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 8.353    Value Loss: 7.242    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 107821     Buffer Size: 14953      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:03:46,003][train][INFO][train.py>_log] ==> #170000     Total Loss: 4.239    [weighted Loss:4.239    Policy Loss: 9.173    Value Loss: 7.303    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 108407     Buffer Size: 14977      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:08:04,781][train][INFO][train.py>_log] ==> #171000     Total Loss: 5.052    [weighted Loss:5.052    Policy Loss: 9.069    Value Loss: 7.653    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 109011     Buffer Size: 15012      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:12:26,216][train][INFO][train.py>_log] ==> #172000     Total Loss: 4.450    [weighted Loss:4.450    Policy Loss: 9.205    Value Loss: 7.871    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 109607     Buffer Size: 15050      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:16:51,429][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 8.609    Value Loss: 6.775    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 110210     Buffer Size: 15108      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:21:13,001][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 8.797    Value Loss: 7.738    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 110809     Buffer Size: 15157      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:25:31,255][train][INFO][train.py>_log] ==> #175000     Total Loss: 4.929    [weighted Loss:4.929    Policy Loss: 9.375    Value Loss: 7.949    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 111409     Buffer Size: 15225      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:29:51,184][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 9.036    Value Loss: 7.883    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 112029     Buffer Size: 15300      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:34:13,891][train][INFO][train.py>_log] ==> #177000     Total Loss: 4.047    [weighted Loss:4.047    Policy Loss: 9.192    Value Loss: 7.813    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 112634     Buffer Size: 15368      Transition Number: 1000.102k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:38:34,500][train][INFO][train.py>_log] ==> #178000     Total Loss: 4.796    [weighted Loss:4.796    Policy Loss: 9.077    Value Loss: 7.905    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 113201     Buffer Size: 15438      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:42:51,540][train][INFO][train.py>_log] ==> #179000     Total Loss: 5.693    [weighted Loss:5.693    Policy Loss: 9.335    Value Loss: 9.288    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 113849     Buffer Size: 15517      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:47:08,376][train][INFO][train.py>_log] ==> #180000     Total Loss: 4.455    [weighted Loss:4.455    Policy Loss: 9.247    Value Loss: 8.801    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 114401     Buffer Size: 15583      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:51:33,392][train][INFO][train.py>_log] ==> #181000     Total Loss: 4.224    [weighted Loss:4.224    Policy Loss: 8.807    Value Loss: 8.077    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 115032     Buffer Size: 15677      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00050 
[2022-01-02 22:55:51,183][train][INFO][train.py>_log] ==> #182000     Total Loss: 4.331    [weighted Loss:4.331    Policy Loss: 9.504    Value Loss: 8.045    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 115639     Buffer Size: 15761      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:00:08,476][train][INFO][train.py>_log] ==> #183000     Total Loss: 4.898    [weighted Loss:4.898    Policy Loss: 9.366    Value Loss: 8.472    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 116271     Buffer Size: 15879      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:04:29,388][train][INFO][train.py>_log] ==> #184000     Total Loss: 4.423    [weighted Loss:4.423    Policy Loss: 8.890    Value Loss: 9.156    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 116917     Buffer Size: 15981      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:08:57,940][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 9.221    Value Loss: 8.647    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 117512     Buffer Size: 16061      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:13:16,379][train][INFO][train.py>_log] ==> #186000     Total Loss: 4.193    [weighted Loss:4.193    Policy Loss: 8.880    Value Loss: 8.585    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 118126     Buffer Size: 16139      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:17:34,521][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 8.906    Value Loss: 9.168    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 118692     Buffer Size: 16177      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:21:56,879][train][INFO][train.py>_log] ==> #188000     Total Loss: 5.157    [weighted Loss:5.157    Policy Loss: 8.237    Value Loss: 8.338    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 119269     Buffer Size: 16221      Transition Number: 1000.197k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:26:20,923][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.271    [weighted Loss:3.271    Policy Loss: 8.362    Value Loss: 8.330    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 119852     Buffer Size: 16239      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:30:38,493][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.664    [weighted Loss:3.664    Policy Loss: 8.908    Value Loss: 9.016    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 120441     Buffer Size: 16255      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:35:00,431][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 7.927    Value Loss: 8.306    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 121026     Buffer Size: 16260      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:39:19,172][train][INFO][train.py>_log] ==> #192000     Total Loss: 5.688    [weighted Loss:5.688    Policy Loss: 8.063    Value Loss: 8.205    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 121598     Buffer Size: 16261      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:43:44,437][train][INFO][train.py>_log] ==> #193000     Total Loss: 5.286    [weighted Loss:5.286    Policy Loss: 7.891    Value Loss: 8.078    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 122171     Buffer Size: 16241      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:48:03,851][train][INFO][train.py>_log] ==> #194000     Total Loss: 4.176    [weighted Loss:4.176    Policy Loss: 7.669    Value Loss: 7.707    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 122746     Buffer Size: 16218      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:52:25,683][train][INFO][train.py>_log] ==> #195000     Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 7.954    Value Loss: 7.712    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 123343     Buffer Size: 16201      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00050 
[2022-01-02 23:56:48,426][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 8.122    Value Loss: 8.181    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 123924     Buffer Size: 16193      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:01:14,094][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 7.924    Value Loss: 8.108    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 124527     Buffer Size: 16178      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:05:33,665][train][INFO][train.py>_log] ==> #198000     Total Loss: 3.956    [weighted Loss:3.956    Policy Loss: 7.732    Value Loss: 7.857    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 125102     Buffer Size: 16149      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:09:57,390][train][INFO][train.py>_log] ==> #199000     Total Loss: 1.579    [weighted Loss:1.579    Policy Loss: 7.467    Value Loss: 8.075    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 125674     Buffer Size: 16116      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:14:22,652][train][INFO][train.py>_log] ==> #200000     Total Loss: 5.549    [weighted Loss:5.549    Policy Loss: 7.786    Value Loss: 8.110    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 126277     Buffer Size: 16067      Transition Number: 1000.016k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:18:50,977][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.017    [weighted Loss:2.017    Policy Loss: 7.898    Value Loss: 8.466    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 126871     Buffer Size: 16021      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:23:09,464][train][INFO][train.py>_log] ==> #202000     Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 7.708    Value Loss: 7.586    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 127460     Buffer Size: 15952      Transition Number: 1000.168k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:27:31,942][train][INFO][train.py>_log] ==> #203000     Total Loss: 3.266    [weighted Loss:3.266    Policy Loss: 8.195    Value Loss: 8.010    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 128036     Buffer Size: 15894      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:31:52,670][train][INFO][train.py>_log] ==> #204000     Total Loss: 4.417    [weighted Loss:4.417    Policy Loss: 7.586    Value Loss: 8.125    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 128613     Buffer Size: 15840      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:36:17,791][train][INFO][train.py>_log] ==> #205000     Total Loss: 5.433    [weighted Loss:5.433    Policy Loss: 8.048    Value Loss: 7.949    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 129215     Buffer Size: 15778      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:40:38,112][train][INFO][train.py>_log] ==> #206000     Total Loss: 4.188    [weighted Loss:4.188    Policy Loss: 7.561    Value Loss: 7.559    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 129794     Buffer Size: 15724      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:44:58,853][train][INFO][train.py>_log] ==> #207000     Total Loss: 3.445    [weighted Loss:3.445    Policy Loss: 8.021    Value Loss: 7.849    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 130436     Buffer Size: 15670      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:49:20,433][train][INFO][train.py>_log] ==> #208000     Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 8.443    Value Loss: 8.526    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 131004     Buffer Size: 15621      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:53:44,784][train][INFO][train.py>_log] ==> #209000     Total Loss: 4.637    [weighted Loss:4.637    Policy Loss: 8.578    Value Loss: 7.543    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 131611     Buffer Size: 15549      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 00:58:06,706][train][INFO][train.py>_log] ==> #210000     Total Loss: 5.229    [weighted Loss:5.229    Policy Loss: 8.586    Value Loss: 8.564    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 132203     Buffer Size: 15481      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:02:25,179][train][INFO][train.py>_log] ==> #211000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 8.513    Value Loss: 7.201    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 132811     Buffer Size: 15447      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:06:45,988][train][INFO][train.py>_log] ==> #212000     Total Loss: 5.143    [weighted Loss:5.143    Policy Loss: 9.173    Value Loss: 8.155    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 133400     Buffer Size: 15421      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:11:11,125][train][INFO][train.py>_log] ==> #213000     Total Loss: 6.499    [weighted Loss:6.499    Policy Loss: 8.755    Value Loss: 7.971    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 134049     Buffer Size: 15450      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:15:30,621][train][INFO][train.py>_log] ==> #214000     Total Loss: 4.328    [weighted Loss:4.328    Policy Loss: 9.552    Value Loss: 8.002    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 134634     Buffer Size: 15474      Transition Number: 999.929 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:19:51,511][train][INFO][train.py>_log] ==> #215000     Total Loss: 4.963    [weighted Loss:4.963    Policy Loss: 9.984    Value Loss: 8.453    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 135299     Buffer Size: 15539      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:24:14,321][train][INFO][train.py>_log] ==> #216000     Total Loss: 5.010    [weighted Loss:5.010    Policy Loss: 9.471    Value Loss: 8.581    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 135926     Buffer Size: 15608      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:28:40,432][train][INFO][train.py>_log] ==> #217000     Total Loss: 4.936    [weighted Loss:4.936    Policy Loss: 9.461    Value Loss: 7.888    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 136570     Buffer Size: 15665      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:33:00,116][train][INFO][train.py>_log] ==> #218000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 9.513    Value Loss: 8.252    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 137199     Buffer Size: 15754      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:37:17,579][train][INFO][train.py>_log] ==> #219000     Total Loss: 4.187    [weighted Loss:4.187    Policy Loss: 9.742    Value Loss: 7.990    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 137845     Buffer Size: 15855      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:41:36,946][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.010    [weighted Loss:3.010    Policy Loss: 9.980    Value Loss: 8.326    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 138498     Buffer Size: 15955      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:46:00,687][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 10.107   Value Loss: 8.505    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 139144     Buffer Size: 16057      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:50:19,369][train][INFO][train.py>_log] ==> #222000     Total Loss: 6.171    [weighted Loss:6.171    Policy Loss: 10.490   Value Loss: 8.498    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 139775     Buffer Size: 16148      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:54:38,140][train][INFO][train.py>_log] ==> #223000     Total Loss: 4.238    [weighted Loss:4.238    Policy Loss: 11.190   Value Loss: 8.791    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 140439     Buffer Size: 16261      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 01:58:56,359][train][INFO][train.py>_log] ==> #224000     Total Loss: 4.052    [weighted Loss:4.052    Policy Loss: 10.684   Value Loss: 9.285    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 141073     Buffer Size: 16372      Transition Number: 999.926 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:03:20,649][train][INFO][train.py>_log] ==> #225000     Total Loss: 3.436    [weighted Loss:3.436    Policy Loss: 10.729   Value Loss: 8.919    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 141764     Buffer Size: 16528      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:07:41,468][train][INFO][train.py>_log] ==> #226000     Total Loss: 6.357    [weighted Loss:6.357    Policy Loss: 10.980   Value Loss: 8.338    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 142465     Buffer Size: 16693      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:11:57,357][train][INFO][train.py>_log] ==> #227000     Total Loss: 5.015    [weighted Loss:5.015    Policy Loss: 10.620   Value Loss: 8.549    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 143154     Buffer Size: 16850      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:16:17,536][train][INFO][train.py>_log] ==> #228000     Total Loss: 2.689    [weighted Loss:2.689    Policy Loss: 10.728   Value Loss: 8.710    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 143852     Buffer Size: 17010      Transition Number: 1000.016k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:20:40,365][train][INFO][train.py>_log] ==> #229000     Total Loss: 5.059    [weighted Loss:5.059    Policy Loss: 11.096   Value Loss: 9.089    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 144520     Buffer Size: 17169      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:25:00,338][train][INFO][train.py>_log] ==> #230000     Total Loss: 4.644    [weighted Loss:4.644    Policy Loss: 10.575   Value Loss: 8.824    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 145200     Buffer Size: 17307      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:29:19,634][train][INFO][train.py>_log] ==> #231000     Total Loss: 5.868    [weighted Loss:5.868    Policy Loss: 10.450   Value Loss: 8.885    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 145829     Buffer Size: 17407      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:33:42,824][train][INFO][train.py>_log] ==> #232000     Total Loss: 5.125    [weighted Loss:5.125    Policy Loss: 10.061   Value Loss: 8.387    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 146457     Buffer Size: 17479      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:38:08,846][train][INFO][train.py>_log] ==> #233000     Total Loss: 4.394    [weighted Loss:4.394    Policy Loss: 10.215   Value Loss: 8.808    Reward Loss: 1.575    Consistency Loss: 0.000    ] Replay Episodes Collected: 147053     Buffer Size: 17538      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:42:30,067][train][INFO][train.py>_log] ==> #234000     Total Loss: 4.756    [weighted Loss:4.756    Policy Loss: 10.133   Value Loss: 8.468    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 147658     Buffer Size: 17598      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:46:47,084][train][INFO][train.py>_log] ==> #235000     Total Loss: 6.140    [weighted Loss:6.140    Policy Loss: 10.216   Value Loss: 9.220    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 148264     Buffer Size: 17633      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:51:06,064][train][INFO][train.py>_log] ==> #236000     Total Loss: 4.318    [weighted Loss:4.318    Policy Loss: 9.629    Value Loss: 9.358    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 148855     Buffer Size: 17676      Transition Number: 1000.073k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:55:33,995][train][INFO][train.py>_log] ==> #237000     Total Loss: 5.994    [weighted Loss:5.994    Policy Loss: 9.600    Value Loss: 8.702    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 149448     Buffer Size: 17701      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00050 
[2022-01-03 02:59:54,788][train][INFO][train.py>_log] ==> #238000     Total Loss: 4.824    [weighted Loss:4.824    Policy Loss: 9.786    Value Loss: 9.104    Reward Loss: 1.590    Consistency Loss: 0.000    ] Replay Episodes Collected: 150034     Buffer Size: 17713      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:04:14,919][train][INFO][train.py>_log] ==> #239000     Total Loss: 4.685    [weighted Loss:4.685    Policy Loss: 9.694    Value Loss: 9.051    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 150618     Buffer Size: 17711      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:08:32,396][train][INFO][train.py>_log] ==> #240000     Total Loss: 4.397    [weighted Loss:4.397    Policy Loss: 9.395    Value Loss: 8.509    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 151222     Buffer Size: 17704      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:12:56,696][train][INFO][train.py>_log] ==> #241000     Total Loss: 5.294    [weighted Loss:5.294    Policy Loss: 9.264    Value Loss: 9.173    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 151777     Buffer Size: 17658      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:17:17,267][train][INFO][train.py>_log] ==> #242000     Total Loss: 4.501    [weighted Loss:4.501    Policy Loss: 9.104    Value Loss: 9.428    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 152366     Buffer Size: 17650      Transition Number: 1000.261k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:21:36,207][train][INFO][train.py>_log] ==> #243000     Total Loss: 4.308    [weighted Loss:4.308    Policy Loss: 8.755    Value Loss: 8.909    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 152959     Buffer Size: 17572      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:25:54,726][train][INFO][train.py>_log] ==> #244000     Total Loss: 3.315    [weighted Loss:3.315    Policy Loss: 8.937    Value Loss: 9.058    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 153511     Buffer Size: 17503      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:30:21,625][train][INFO][train.py>_log] ==> #245000     Total Loss: 4.768    [weighted Loss:4.768    Policy Loss: 8.628    Value Loss: 9.062    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 154084     Buffer Size: 17438      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:34:43,132][train][INFO][train.py>_log] ==> #246000     Total Loss: 5.062    [weighted Loss:5.062    Policy Loss: 9.004    Value Loss: 9.417    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 154661     Buffer Size: 17354      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:39:06,828][train][INFO][train.py>_log] ==> #247000     Total Loss: 4.838    [weighted Loss:4.838    Policy Loss: 8.717    Value Loss: 8.712    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 155223     Buffer Size: 17251      Transition Number: 1000.001k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:43:26,521][train][INFO][train.py>_log] ==> #248000     Total Loss: 6.235    [weighted Loss:6.235    Policy Loss: 8.351    Value Loss: 8.672    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 155813     Buffer Size: 17159      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:47:53,428][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 8.497    Value Loss: 9.523    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 156343     Buffer Size: 17067      Transition Number: 1000.211k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:52:11,745][train][INFO][train.py>_log] ==> #250000     Total Loss: 4.459    [weighted Loss:4.459    Policy Loss: 8.298    Value Loss: 8.655    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 156969     Buffer Size: 16943      Transition Number: 1000.076k Batch Size: 256        Lr: 0.00050 
[2022-01-03 03:56:32,184][train][INFO][train.py>_log] ==> #251000     Total Loss: 4.921    [weighted Loss:4.921    Policy Loss: 8.889    Value Loss: 9.651    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 157474     Buffer Size: 16819      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:00:53,980][train][INFO][train.py>_log] ==> #252000     Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 7.772    Value Loss: 9.075    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 158081     Buffer Size: 16664      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:05:18,185][train][INFO][train.py>_log] ==> #253000     Total Loss: 4.390    [weighted Loss:4.390    Policy Loss: 8.112    Value Loss: 8.736    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 158646     Buffer Size: 16493      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:09:37,847][train][INFO][train.py>_log] ==> #254000     Total Loss: 4.773    [weighted Loss:4.773    Policy Loss: 7.660    Value Loss: 8.416    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 159208     Buffer Size: 16298      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:13:57,842][train][INFO][train.py>_log] ==> #255000     Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 7.864    Value Loss: 9.147    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 159774     Buffer Size: 16115      Transition Number: 1000.092k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:18:18,576][train][INFO][train.py>_log] ==> #256000     Total Loss: 4.671    [weighted Loss:4.671    Policy Loss: 7.625    Value Loss: 8.272    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 160332     Buffer Size: 15937      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:22:45,064][train][INFO][train.py>_log] ==> #257000     Total Loss: 3.769    [weighted Loss:3.769    Policy Loss: 7.488    Value Loss: 8.488    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 160876     Buffer Size: 15774      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:27:03,348][train][INFO][train.py>_log] ==> #258000     Total Loss: 4.580    [weighted Loss:4.580    Policy Loss: 7.967    Value Loss: 8.695    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 161467     Buffer Size: 15631      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:31:21,241][train][INFO][train.py>_log] ==> #259000     Total Loss: 4.365    [weighted Loss:4.365    Policy Loss: 7.723    Value Loss: 8.467    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 162017     Buffer Size: 15527      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:35:38,358][train][INFO][train.py>_log] ==> #260000     Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 7.355    Value Loss: 8.871    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 162579     Buffer Size: 15434      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:40:02,690][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.420    [weighted Loss:3.420    Policy Loss: 7.394    Value Loss: 8.563    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 163115     Buffer Size: 15342      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:44:22,071][train][INFO][train.py>_log] ==> #262000     Total Loss: 3.771    [weighted Loss:3.771    Policy Loss: 7.361    Value Loss: 8.202    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 163694     Buffer Size: 15240      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:48:41,395][train][INFO][train.py>_log] ==> #263000     Total Loss: 3.539    [weighted Loss:3.539    Policy Loss: 7.480    Value Loss: 8.341    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 164278     Buffer Size: 15148      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:53:01,911][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 7.426    Value Loss: 8.266    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 164820     Buffer Size: 15068      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 04:57:25,694][train][INFO][train.py>_log] ==> #265000     Total Loss: 3.817    [weighted Loss:3.817    Policy Loss: 7.465    Value Loss: 7.930    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 165412     Buffer Size: 14998      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:01:44,817][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 7.682    Value Loss: 8.554    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 165955     Buffer Size: 14928      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:06:03,519][train][INFO][train.py>_log] ==> #267000     Total Loss: 4.742    [weighted Loss:4.742    Policy Loss: 7.664    Value Loss: 7.883    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 166541     Buffer Size: 14871      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:10:27,723][train][INFO][train.py>_log] ==> #268000     Total Loss: 4.160    [weighted Loss:4.160    Policy Loss: 8.182    Value Loss: 8.351    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 167093     Buffer Size: 14809      Transition Number: 999.930 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:14:54,328][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 8.215    Value Loss: 7.421    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 167663     Buffer Size: 14768      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:19:12,515][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 8.775    Value Loss: 8.004    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 168232     Buffer Size: 14745      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:23:31,247][train][INFO][train.py>_log] ==> #271000     Total Loss: 5.500    [weighted Loss:5.500    Policy Loss: 8.647    Value Loss: 7.784    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 168780     Buffer Size: 14723      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:27:50,109][train][INFO][train.py>_log] ==> #272000     Total Loss: 3.756    [weighted Loss:3.756    Policy Loss: 8.680    Value Loss: 7.256    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 169350     Buffer Size: 14712      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:32:12,021][train][INFO][train.py>_log] ==> #273000     Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 9.456    Value Loss: 7.441    Reward Loss: 1.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 169911     Buffer Size: 14723      Transition Number: 1000.073k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:36:33,765][train][INFO][train.py>_log] ==> #274000     Total Loss: 4.475    [weighted Loss:4.475    Policy Loss: 9.408    Value Loss: 8.109    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 170465     Buffer Size: 14731      Transition Number: 1000.125k Batch Size: 256        Lr: 0.00050 
[2022-01-03 05:40:50,706][train][INFO][train.py>_log] ==> #275000     Total Loss: 4.950    [weighted Loss:4.950    Policy Loss: 9.692    Value Loss: 7.559    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 171050     Buffer Size: 14768      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00050 
