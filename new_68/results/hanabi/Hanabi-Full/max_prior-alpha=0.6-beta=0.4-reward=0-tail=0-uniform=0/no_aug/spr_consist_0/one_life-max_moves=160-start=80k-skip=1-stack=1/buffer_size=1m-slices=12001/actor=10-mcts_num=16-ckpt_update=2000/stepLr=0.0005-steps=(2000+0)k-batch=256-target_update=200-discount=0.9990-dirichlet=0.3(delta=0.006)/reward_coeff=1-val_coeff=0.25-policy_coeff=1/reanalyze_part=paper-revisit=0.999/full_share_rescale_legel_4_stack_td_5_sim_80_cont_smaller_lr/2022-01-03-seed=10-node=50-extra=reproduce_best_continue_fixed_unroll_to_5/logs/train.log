[2022-01-03 06:01:46,251][train][INFO][train.py>_log] ==> #0          Total Loss: 21.867   [weighted Loss:21.867   Policy Loss: 13.775   Value Loss: 22.508   Reward Loss: 2.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 6514       Buffer Size: 6514       Transition Number: 80.407  k Batch Size: 256        Lr: 0.00000 
[2022-01-03 06:04:55,400][train][INFO][train.py>_log] ==> #1000       Total Loss: 2.840    [weighted Loss:2.840    Policy Loss: 6.123    Value Loss: 6.712    Reward Loss: 0.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 6897       Buffer Size: 6897       Transition Number: 104.510 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:08:09,261][train][INFO][train.py>_log] ==> #2000       Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.163    Value Loss: 6.601    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 7369       Buffer Size: 7369       Transition Number: 135.426 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:11:15,497][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 4.208    Value Loss: 5.233    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 7719       Buffer Size: 7719       Transition Number: 158.366 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:14:23,938][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 4.549    Value Loss: 4.712    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 8190       Buffer Size: 8190       Transition Number: 189.481 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:17:34,148][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 4.507    Value Loss: 4.680    Reward Loss: 0.942    Consistency Loss: 0.000    ] Replay Episodes Collected: 8648       Buffer Size: 8648       Transition Number: 219.643 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:20:42,129][train][INFO][train.py>_log] ==> #6000       Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 4.594    Value Loss: 4.874    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 9003       Buffer Size: 9003       Transition Number: 243.162 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:23:49,287][train][INFO][train.py>_log] ==> #7000       Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 4.659    Value Loss: 4.426    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 9445       Buffer Size: 9445       Transition Number: 272.065 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:26:57,946][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.507    [weighted Loss:2.507    Policy Loss: 4.765    Value Loss: 4.444    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 9902       Buffer Size: 9902       Transition Number: 301.942 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:30:09,702][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 4.917    Value Loss: 4.291    Reward Loss: 0.994    Consistency Loss: 0.000    ] Replay Episodes Collected: 10281      Buffer Size: 10281      Transition Number: 326.677 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:33:16,190][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.548    [weighted Loss:2.548    Policy Loss: 4.865    Value Loss: 4.417    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 10733      Buffer Size: 10733      Transition Number: 356.128 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:36:23,355][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.768    [weighted Loss:1.768    Policy Loss: 4.825    Value Loss: 4.722    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 11154      Buffer Size: 11154      Transition Number: 383.337 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:39:29,317][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 5.139    Value Loss: 4.094    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 11564      Buffer Size: 11564      Transition Number: 409.947 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:42:42,290][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.796    [weighted Loss:2.796    Policy Loss: 5.656    Value Loss: 4.915    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 11953      Buffer Size: 11953      Transition Number: 435.071 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:45:47,778][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.087    [weighted Loss:2.087    Policy Loss: 4.982    Value Loss: 4.408    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 12419      Buffer Size: 12419      Transition Number: 465.289 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:48:54,902][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 5.309    Value Loss: 4.145    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 12826      Buffer Size: 12826      Transition Number: 491.637 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:51:59,500][train][INFO][train.py>_log] ==> #16000      Total Loss: 2.643    [weighted Loss:2.643    Policy Loss: 5.639    Value Loss: 4.106    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 13227      Buffer Size: 13227      Transition Number: 517.651 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:55:11,665][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 5.206    Value Loss: 4.280    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 13639      Buffer Size: 13639      Transition Number: 544.339 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 06:58:16,274][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.405    [weighted Loss:1.405    Policy Loss: 5.077    Value Loss: 4.104    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 14042      Buffer Size: 14042      Transition Number: 570.340 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:01:20,333][train][INFO][train.py>_log] ==> #19000      Total Loss: 1.957    [weighted Loss:1.957    Policy Loss: 5.587    Value Loss: 4.100    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 14468      Buffer Size: 14468      Transition Number: 597.923 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:04:25,813][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 5.383    Value Loss: 4.359    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 14861      Buffer Size: 14861      Transition Number: 623.393 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:07:34,515][train][INFO][train.py>_log] ==> #21000      Total Loss: 4.035    [weighted Loss:4.035    Policy Loss: 5.937    Value Loss: 4.284    Reward Loss: 1.109    Consistency Loss: 0.000    ] Replay Episodes Collected: 15301      Buffer Size: 15301      Transition Number: 651.676 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:10:37,538][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.905    [weighted Loss:2.905    Policy Loss: 5.701    Value Loss: 4.388    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 15702      Buffer Size: 15702      Transition Number: 677.594 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:13:42,366][train][INFO][train.py>_log] ==> #23000      Total Loss: 3.132    [weighted Loss:3.132    Policy Loss: 5.773    Value Loss: 4.123    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 16122      Buffer Size: 16122      Transition Number: 704.671 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:16:46,179][train][INFO][train.py>_log] ==> #24000      Total Loss: 3.269    [weighted Loss:3.269    Policy Loss: 5.472    Value Loss: 4.269    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 16495      Buffer Size: 16495      Transition Number: 728.791 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:19:53,955][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 5.440    Value Loss: 4.057    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 16911      Buffer Size: 16911      Transition Number: 755.750 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:22:57,551][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.682    [weighted Loss:1.682    Policy Loss: 5.861    Value Loss: 4.066    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 17335      Buffer Size: 17335      Transition Number: 783.327 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:26:00,604][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 6.204    Value Loss: 4.230    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 17737      Buffer Size: 17737      Transition Number: 809.088 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:29:05,377][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.486    [weighted Loss:3.486    Policy Loss: 5.596    Value Loss: 4.089    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 18167      Buffer Size: 18167      Transition Number: 836.814 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:32:13,383][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 5.935    Value Loss: 4.455    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 18539      Buffer Size: 18539      Transition Number: 860.651 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:35:17,512][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.145    [weighted Loss:3.145    Policy Loss: 5.576    Value Loss: 4.311    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 18988      Buffer Size: 18988      Transition Number: 889.835 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:38:22,386][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 5.678    Value Loss: 4.058    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 19344      Buffer Size: 19344      Transition Number: 912.816 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:41:27,303][train][INFO][train.py>_log] ==> #32000      Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 5.889    Value Loss: 4.018    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 19807      Buffer Size: 19807      Transition Number: 942.800 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:44:35,346][train][INFO][train.py>_log] ==> #33000      Total Loss: 3.176    [weighted Loss:3.176    Policy Loss: 6.021    Value Loss: 3.876    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 20192      Buffer Size: 20192      Transition Number: 967.815 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:47:40,058][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 5.764    Value Loss: 4.174    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 20614      Buffer Size: 20614      Transition Number: 995.052 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:50:47,519][train][INFO][train.py>_log] ==> #35000      Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 5.463    Value Loss: 4.097    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 21021      Buffer Size: 19308      Transition Number: 1000.245k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:53:55,379][train][INFO][train.py>_log] ==> #36000      Total Loss: 3.232    [weighted Loss:3.232    Policy Loss: 5.971    Value Loss: 4.281    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 21455      Buffer Size: 17460      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 07:57:05,346][train][INFO][train.py>_log] ==> #37000      Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 6.196    Value Loss: 4.146    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 21876      Buffer Size: 15663      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:00:12,209][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 6.902    Value Loss: 4.089    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 22246      Buffer Size: 15405      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:03:16,317][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.801    [weighted Loss:3.801    Policy Loss: 6.956    Value Loss: 3.889    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 22690      Buffer Size: 15412      Transition Number: 1000.307k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:06:20,142][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 6.640    Value Loss: 4.185    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 23089      Buffer Size: 15414      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:09:28,958][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 7.008    Value Loss: 3.765    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 23499      Buffer Size: 15416      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:12:34,569][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 7.054    Value Loss: 4.466    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 23847      Buffer Size: 15415      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:15:39,153][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.849    [weighted Loss:2.849    Policy Loss: 7.008    Value Loss: 4.057    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 24317      Buffer Size: 15421      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:18:44,126][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.726    [weighted Loss:3.726    Policy Loss: 7.006    Value Loss: 4.110    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 24701      Buffer Size: 15428      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:21:52,667][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.534    [weighted Loss:3.534    Policy Loss: 7.146    Value Loss: 4.586    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 25132      Buffer Size: 15429      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:24:55,611][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 6.883    Value Loss: 4.063    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 25493      Buffer Size: 15431      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:27:59,944][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.604    [weighted Loss:4.604    Policy Loss: 6.914    Value Loss: 4.193    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 25933      Buffer Size: 15431      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:31:02,335][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 6.419    Value Loss: 4.630    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 26329      Buffer Size: 15436      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:34:10,099][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 7.026    Value Loss: 4.450    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 26744      Buffer Size: 15427      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:37:12,180][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 6.628    Value Loss: 4.586    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 27136      Buffer Size: 15423      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:40:15,649][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 6.162    Value Loss: 4.363    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 27539      Buffer Size: 15421      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:43:19,620][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 6.560    Value Loss: 4.253    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 27980      Buffer Size: 15416      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:46:28,785][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.197    [weighted Loss:3.197    Policy Loss: 6.570    Value Loss: 4.513    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 28354      Buffer Size: 15406      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:49:32,799][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.093    [weighted Loss:3.093    Policy Loss: 6.569    Value Loss: 4.342    Reward Loss: 1.064    Consistency Loss: 0.000    ] Replay Episodes Collected: 28766      Buffer Size: 15402      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:52:38,894][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 6.409    Value Loss: 4.450    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 29196      Buffer Size: 15395      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:55:42,697][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.541    [weighted Loss:3.541    Policy Loss: 6.607    Value Loss: 4.181    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 29583      Buffer Size: 15387      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 08:58:50,720][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.432    [weighted Loss:3.432    Policy Loss: 6.380    Value Loss: 4.430    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 30015      Buffer Size: 15383      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:01:55,227][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 6.457    Value Loss: 4.742    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 30416      Buffer Size: 15375      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:04:58,861][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.419    [weighted Loss:2.419    Policy Loss: 6.313    Value Loss: 4.354    Reward Loss: 1.001    Consistency Loss: 0.000    ] Replay Episodes Collected: 30840      Buffer Size: 15357      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:08:03,468][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.639    [weighted Loss:2.639    Policy Loss: 6.901    Value Loss: 4.594    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 31213      Buffer Size: 15348      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:11:13,147][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.127    [weighted Loss:4.127    Policy Loss: 6.688    Value Loss: 4.083    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 31645      Buffer Size: 15339      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:14:17,038][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.065    [weighted Loss:3.065    Policy Loss: 6.609    Value Loss: 4.498    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 32064      Buffer Size: 15329      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:17:21,368][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.908    [weighted Loss:3.908    Policy Loss: 6.686    Value Loss: 4.302    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 32465      Buffer Size: 15321      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:20:24,630][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 6.389    Value Loss: 4.492    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 32882      Buffer Size: 15312      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:23:31,629][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 6.417    Value Loss: 4.270    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 33279      Buffer Size: 15298      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:26:35,845][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 6.291    Value Loss: 4.304    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 33717      Buffer Size: 15283      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:29:40,304][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 6.345    Value Loss: 4.406    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 34089      Buffer Size: 15274      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:32:46,076][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 6.743    Value Loss: 4.407    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 34522      Buffer Size: 15268      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:35:54,138][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.384    [weighted Loss:3.384    Policy Loss: 6.184    Value Loss: 4.248    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 34932      Buffer Size: 15260      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:38:57,290][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.630    [weighted Loss:3.630    Policy Loss: 6.728    Value Loss: 4.446    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 35361      Buffer Size: 15255      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:42:00,859][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.811    [weighted Loss:1.811    Policy Loss: 6.557    Value Loss: 4.329    Reward Loss: 1.102    Consistency Loss: 0.000    ] Replay Episodes Collected: 35728      Buffer Size: 15245      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:45:04,863][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 6.707    Value Loss: 4.202    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 36134      Buffer Size: 15235      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:48:11,922][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 6.574    Value Loss: 4.343    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 36560      Buffer Size: 15227      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:51:18,310][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.685    [weighted Loss:3.685    Policy Loss: 6.134    Value Loss: 4.647    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 36992      Buffer Size: 15221      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:54:23,134][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.622    [weighted Loss:3.622    Policy Loss: 6.577    Value Loss: 4.429    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 37397      Buffer Size: 15218      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 09:57:26,333][train][INFO][train.py>_log] ==> #76000      Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 6.645    Value Loss: 4.314    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 37818      Buffer Size: 15216      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:00:35,497][train][INFO][train.py>_log] ==> #77000      Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 6.536    Value Loss: 4.196    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 38242      Buffer Size: 15216      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:03:39,928][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 6.342    Value Loss: 4.242    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 38622      Buffer Size: 15219      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:06:42,863][train][INFO][train.py>_log] ==> #79000      Total Loss: 1.494    [weighted Loss:1.494    Policy Loss: 6.667    Value Loss: 4.109    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 39044      Buffer Size: 15224      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:09:47,805][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 6.605    Value Loss: 4.403    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 39466      Buffer Size: 15222      Transition Number: 1000.096k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:12:54,451][train][INFO][train.py>_log] ==> #81000      Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 6.301    Value Loss: 4.255    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 39879      Buffer Size: 15219      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:15:58,489][train][INFO][train.py>_log] ==> #82000      Total Loss: 4.063    [weighted Loss:4.063    Policy Loss: 6.808    Value Loss: 4.281    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 40315      Buffer Size: 15218      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:19:00,775][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.936    [weighted Loss:2.936    Policy Loss: 6.749    Value Loss: 4.098    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 40690      Buffer Size: 15225      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:22:04,988][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 6.660    Value Loss: 4.301    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 41156      Buffer Size: 15227      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:25:11,935][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.037    [weighted Loss:3.037    Policy Loss: 7.129    Value Loss: 4.403    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 41495      Buffer Size: 15230      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:28:16,486][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.067    [weighted Loss:3.067    Policy Loss: 6.972    Value Loss: 4.335    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 41962      Buffer Size: 15245      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:31:19,320][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.404    [weighted Loss:3.404    Policy Loss: 6.839    Value Loss: 4.258    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 42373      Buffer Size: 15263      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:34:22,281][train][INFO][train.py>_log] ==> #88000      Total Loss: 3.465    [weighted Loss:3.465    Policy Loss: 6.602    Value Loss: 4.222    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 42761      Buffer Size: 15275      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:37:28,308][train][INFO][train.py>_log] ==> #89000      Total Loss: 2.240    [weighted Loss:2.240    Policy Loss: 6.724    Value Loss: 4.543    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 43168      Buffer Size: 15293      Transition Number: 1000.073k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:40:31,575][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 6.978    Value Loss: 4.639    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 43583      Buffer Size: 15314      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:43:36,558][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 6.730    Value Loss: 4.026    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 44026      Buffer Size: 15338      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:46:40,259][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.022    [weighted Loss:3.022    Policy Loss: 6.712    Value Loss: 4.297    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 44379      Buffer Size: 15359      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:49:47,228][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 6.297    Value Loss: 4.147    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 44827      Buffer Size: 15378      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:52:52,842][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.279    [weighted Loss:3.279    Policy Loss: 6.551    Value Loss: 4.045    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 45210      Buffer Size: 15398      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:55:55,156][train][INFO][train.py>_log] ==> #95000      Total Loss: 3.681    [weighted Loss:3.681    Policy Loss: 6.813    Value Loss: 4.068    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 45667      Buffer Size: 15418      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 10:59:00,365][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.256    [weighted Loss:3.256    Policy Loss: 6.421    Value Loss: 4.134    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 46008      Buffer Size: 15441      Transition Number: 1000.118k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:02:07,832][train][INFO][train.py>_log] ==> #97000      Total Loss: 2.501    [weighted Loss:2.501    Policy Loss: 6.731    Value Loss: 4.573    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 46466      Buffer Size: 15468      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:05:12,314][train][INFO][train.py>_log] ==> #98000      Total Loss: 2.545    [weighted Loss:2.545    Policy Loss: 6.685    Value Loss: 4.561    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 46845      Buffer Size: 15492      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:08:16,395][train][INFO][train.py>_log] ==> #99000      Total Loss: 2.967    [weighted Loss:2.967    Policy Loss: 6.747    Value Loss: 4.304    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 47291      Buffer Size: 15515      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:11:20,901][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.495    [weighted Loss:3.495    Policy Loss: 6.609    Value Loss: 4.399    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 47675      Buffer Size: 15537      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:14:27,119][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.489    Value Loss: 4.092    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 48087      Buffer Size: 15559      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:17:30,111][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 6.636    Value Loss: 4.372    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 48487      Buffer Size: 15583      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:20:34,725][train][INFO][train.py>_log] ==> #103000     Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 6.589    Value Loss: 4.687    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 48920      Buffer Size: 15606      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:23:37,443][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.159    [weighted Loss:3.159    Policy Loss: 6.527    Value Loss: 4.316    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 49324      Buffer Size: 15628      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:26:44,650][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.042    [weighted Loss:3.042    Policy Loss: 6.615    Value Loss: 4.228    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 49723      Buffer Size: 15650      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:29:47,919][train][INFO][train.py>_log] ==> #106000     Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 6.094    Value Loss: 4.382    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 50120      Buffer Size: 15669      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:32:51,957][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.002    [weighted Loss:3.002    Policy Loss: 6.126    Value Loss: 4.320    Reward Loss: 1.045    Consistency Loss: 0.000    ] Replay Episodes Collected: 50549      Buffer Size: 15689      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:35:54,467][train][INFO][train.py>_log] ==> #108000     Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 6.188    Value Loss: 4.540    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 50954      Buffer Size: 15706      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:39:01,655][train][INFO][train.py>_log] ==> #109000     Total Loss: 3.872    [weighted Loss:3.872    Policy Loss: 6.653    Value Loss: 4.440    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 51371      Buffer Size: 15725      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:42:07,120][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.839    [weighted Loss:3.839    Policy Loss: 6.828    Value Loss: 4.303    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 51760      Buffer Size: 15748      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:45:13,233][train][INFO][train.py>_log] ==> #111000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 6.652    Value Loss: 4.394    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 52204      Buffer Size: 15762      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:48:16,119][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.916    [weighted Loss:2.916    Policy Loss: 6.270    Value Loss: 4.561    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 52606      Buffer Size: 15782      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:51:24,010][train][INFO][train.py>_log] ==> #113000     Total Loss: 3.612    [weighted Loss:3.612    Policy Loss: 6.665    Value Loss: 4.416    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 53009      Buffer Size: 15793      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:54:28,793][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 6.785    Value Loss: 4.546    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 53410      Buffer Size: 15807      Transition Number: 1000.092k Batch Size: 256        Lr: 0.00050 
[2022-01-03 11:57:32,556][train][INFO][train.py>_log] ==> #115000     Total Loss: 3.811    [weighted Loss:3.811    Policy Loss: 6.398    Value Loss: 4.359    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 53854      Buffer Size: 15817      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:00:35,475][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 6.791    Value Loss: 4.799    Reward Loss: 1.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 54258      Buffer Size: 15831      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:03:42,733][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 6.613    Value Loss: 4.492    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 54636      Buffer Size: 15842      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:06:46,156][train][INFO][train.py>_log] ==> #118000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 6.565    Value Loss: 4.852    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 55080      Buffer Size: 15857      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:09:49,200][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 6.628    Value Loss: 4.612    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 55503      Buffer Size: 15876      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:12:51,170][train][INFO][train.py>_log] ==> #120000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 6.475    Value Loss: 4.651    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 55878      Buffer Size: 15885      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:15:58,369][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.580    [weighted Loss:3.580    Policy Loss: 6.774    Value Loss: 4.810    Reward Loss: 1.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 56310      Buffer Size: 15900      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:19:02,789][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 6.542    Value Loss: 4.668    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 56709      Buffer Size: 15912      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:22:05,364][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.454    [weighted Loss:3.454    Policy Loss: 6.422    Value Loss: 4.885    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 57153      Buffer Size: 15925      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:25:09,297][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 6.429    Value Loss: 4.478    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 57518      Buffer Size: 15935      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:28:18,505][train][INFO][train.py>_log] ==> #125000     Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 6.461    Value Loss: 4.364    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 57954      Buffer Size: 15939      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:31:22,855][train][INFO][train.py>_log] ==> #126000     Total Loss: 3.404    [weighted Loss:3.404    Policy Loss: 6.503    Value Loss: 4.752    Reward Loss: 1.017    Consistency Loss: 0.000    ] Replay Episodes Collected: 58370      Buffer Size: 15943      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:34:26,113][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 6.336    Value Loss: 4.669    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 58797      Buffer Size: 15948      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:37:28,876][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 6.219    Value Loss: 4.455    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 59197      Buffer Size: 15953      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:40:36,553][train][INFO][train.py>_log] ==> #129000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 6.461    Value Loss: 4.425    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 59635      Buffer Size: 15956      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:43:38,731][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 6.243    Value Loss: 5.046    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 60045      Buffer Size: 15957      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:46:41,920][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.962    [weighted Loss:2.962    Policy Loss: 6.655    Value Loss: 4.090    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 60435      Buffer Size: 15966      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:49:46,181][train][INFO][train.py>_log] ==> #132000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 6.408    Value Loss: 4.346    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 60864      Buffer Size: 15978      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:52:52,950][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 6.471    Value Loss: 4.426    Reward Loss: 1.040    Consistency Loss: 0.000    ] Replay Episodes Collected: 61285      Buffer Size: 15995      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:55:56,546][train][INFO][train.py>_log] ==> #134000     Total Loss: 3.778    [weighted Loss:3.778    Policy Loss: 6.893    Value Loss: 4.552    Reward Loss: 0.957    Consistency Loss: 0.000    ] Replay Episodes Collected: 61706      Buffer Size: 16004      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 12:59:01,869][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.085    [weighted Loss:3.085    Policy Loss: 6.810    Value Loss: 4.538    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 62118      Buffer Size: 16026      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:02:05,210][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.846    [weighted Loss:2.846    Policy Loss: 6.762    Value Loss: 4.446    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 62549      Buffer Size: 16036      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:05:12,179][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.710    [weighted Loss:3.710    Policy Loss: 6.917    Value Loss: 4.499    Reward Loss: 1.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 62979      Buffer Size: 16061      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:08:17,516][train][INFO][train.py>_log] ==> #138000     Total Loss: 2.494    [weighted Loss:2.494    Policy Loss: 6.663    Value Loss: 4.716    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 63393      Buffer Size: 16096      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:11:20,776][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.927    [weighted Loss:2.927    Policy Loss: 6.478    Value Loss: 4.660    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 63844      Buffer Size: 16132      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:14:23,325][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.007    [weighted Loss:3.007    Policy Loss: 6.836    Value Loss: 4.763    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 64273      Buffer Size: 16161      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:17:29,954][train][INFO][train.py>_log] ==> #141000     Total Loss: 3.161    [weighted Loss:3.161    Policy Loss: 6.655    Value Loss: 5.231    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 64700      Buffer Size: 16203      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:20:33,922][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.387    [weighted Loss:3.387    Policy Loss: 6.543    Value Loss: 5.224    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 65125      Buffer Size: 16243      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:23:36,599][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.788    [weighted Loss:3.788    Policy Loss: 6.756    Value Loss: 4.876    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 65574      Buffer Size: 16282      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:26:38,925][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.412    [weighted Loss:3.412    Policy Loss: 6.326    Value Loss: 5.132    Reward Loss: 1.197    Consistency Loss: 0.000    ] Replay Episodes Collected: 66012      Buffer Size: 16329      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:29:48,210][train][INFO][train.py>_log] ==> #145000     Total Loss: 3.193    [weighted Loss:3.193    Policy Loss: 6.800    Value Loss: 5.194    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 66435      Buffer Size: 16374      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:32:52,274][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.491    [weighted Loss:3.491    Policy Loss: 6.763    Value Loss: 5.180    Reward Loss: 1.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 66893      Buffer Size: 16418      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:35:55,215][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 6.148    Value Loss: 5.581    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 67345      Buffer Size: 16477      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:38:57,392][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 6.416    Value Loss: 5.263    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 67780      Buffer Size: 16532      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:42:04,261][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 6.637    Value Loss: 5.517    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 68235      Buffer Size: 16578      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:45:07,703][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 6.260    Value Loss: 5.431    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 68666      Buffer Size: 16629      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:48:08,606][train][INFO][train.py>_log] ==> #151000     Total Loss: 3.000    [weighted Loss:3.000    Policy Loss: 6.723    Value Loss: 5.471    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 69094      Buffer Size: 16678      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:51:21,193][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.384    [weighted Loss:2.384    Policy Loss: 6.588    Value Loss: 5.665    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 69558      Buffer Size: 16727      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:54:37,523][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.879    [weighted Loss:2.879    Policy Loss: 6.222    Value Loss: 5.615    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 70029      Buffer Size: 16765      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00050 
[2022-01-03 13:57:49,137][train][INFO][train.py>_log] ==> #154000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 6.262    Value Loss: 5.945    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 70461      Buffer Size: 16803      Transition Number: 1000.102k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:01:01,544][train][INFO][train.py>_log] ==> #155000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 6.019    Value Loss: 5.558    Reward Loss: 1.156    Consistency Loss: 0.000    ] Replay Episodes Collected: 70906      Buffer Size: 16816      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:04:13,150][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.714    [weighted Loss:3.714    Policy Loss: 6.136    Value Loss: 5.128    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 71349      Buffer Size: 16839      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:07:30,084][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 6.004    Value Loss: 5.029    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 71760      Buffer Size: 16842      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:10:40,619][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.600    [weighted Loss:2.600    Policy Loss: 6.268    Value Loss: 5.553    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 72212      Buffer Size: 16856      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:13:50,682][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.372    [weighted Loss:2.372    Policy Loss: 5.894    Value Loss: 5.204    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 72635      Buffer Size: 16870      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:17:05,146][train][INFO][train.py>_log] ==> #160000     Total Loss: 3.083    [weighted Loss:3.083    Policy Loss: 5.776    Value Loss: 5.382    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 73069      Buffer Size: 16879      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:20:20,944][train][INFO][train.py>_log] ==> #161000     Total Loss: 1.935    [weighted Loss:1.935    Policy Loss: 5.759    Value Loss: 5.107    Reward Loss: 1.099    Consistency Loss: 0.000    ] Replay Episodes Collected: 73503      Buffer Size: 16880      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:23:35,777][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.991    [weighted Loss:2.991    Policy Loss: 5.847    Value Loss: 5.519    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 73932      Buffer Size: 16886      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:26:49,562][train][INFO][train.py>_log] ==> #163000     Total Loss: 1.263    [weighted Loss:1.263    Policy Loss: 5.756    Value Loss: 5.702    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 74382      Buffer Size: 16893      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:30:04,225][train][INFO][train.py>_log] ==> #164000     Total Loss: 1.376    [weighted Loss:1.376    Policy Loss: 6.031    Value Loss: 5.366    Reward Loss: 1.115    Consistency Loss: 0.000    ] Replay Episodes Collected: 74808      Buffer Size: 16891      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:33:24,917][train][INFO][train.py>_log] ==> #165000     Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 5.655    Value Loss: 5.324    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 75264      Buffer Size: 16894      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:36:37,732][train][INFO][train.py>_log] ==> #166000     Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 6.046    Value Loss: 5.591    Reward Loss: 1.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 75688      Buffer Size: 16893      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:39:51,087][train][INFO][train.py>_log] ==> #167000     Total Loss: 2.658    [weighted Loss:2.658    Policy Loss: 5.759    Value Loss: 5.514    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 76134      Buffer Size: 16889      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:43:04,588][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.574    [weighted Loss:2.574    Policy Loss: 5.515    Value Loss: 5.122    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 76581      Buffer Size: 16884      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:46:22,142][train][INFO][train.py>_log] ==> #169000     Total Loss: 3.266    [weighted Loss:3.266    Policy Loss: 5.771    Value Loss: 4.819    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 77009      Buffer Size: 16874      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:49:37,793][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.900    [weighted Loss:2.900    Policy Loss: 5.712    Value Loss: 5.437    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 77442      Buffer Size: 16862      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:52:49,993][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.156    [weighted Loss:3.156    Policy Loss: 5.735    Value Loss: 5.551    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 77890      Buffer Size: 16849      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:56:00,889][train][INFO][train.py>_log] ==> #172000     Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 5.547    Value Loss: 5.200    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 78339      Buffer Size: 16829      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 14:59:16,747][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 5.698    Value Loss: 5.193    Reward Loss: 1.095    Consistency Loss: 0.000    ] Replay Episodes Collected: 78748      Buffer Size: 16813      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:02:28,736][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.632    [weighted Loss:2.632    Policy Loss: 5.778    Value Loss: 5.395    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 79185      Buffer Size: 16789      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:05:39,826][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.082    [weighted Loss:2.082    Policy Loss: 5.302    Value Loss: 5.447    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 79636      Buffer Size: 16765      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:08:52,681][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 5.589    Value Loss: 5.266    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 80067      Buffer Size: 16727      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:12:07,989][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 5.573    Value Loss: 5.273    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 80495      Buffer Size: 16686      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:15:23,998][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.969    [weighted Loss:2.969    Policy Loss: 5.703    Value Loss: 5.061    Reward Loss: 1.065    Consistency Loss: 0.000    ] Replay Episodes Collected: 80950      Buffer Size: 16647      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:18:38,495][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 5.649    Value Loss: 5.145    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 81401      Buffer Size: 16596      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:21:52,171][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 5.548    Value Loss: 5.440    Reward Loss: 1.157    Consistency Loss: 0.000    ] Replay Episodes Collected: 81840      Buffer Size: 16551      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:25:12,657][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 5.683    Value Loss: 5.113    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 82255      Buffer Size: 16498      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:28:27,360][train][INFO][train.py>_log] ==> #182000     Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 5.766    Value Loss: 4.896    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 82715      Buffer Size: 16451      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:31:43,959][train][INFO][train.py>_log] ==> #183000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 5.481    Value Loss: 4.875    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 83156      Buffer Size: 16397      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:34:59,048][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.079    [weighted Loss:3.079    Policy Loss: 5.594    Value Loss: 5.086    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 83585      Buffer Size: 16339      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:38:15,917][train][INFO][train.py>_log] ==> #185000     Total Loss: 3.017    [weighted Loss:3.017    Policy Loss: 5.666    Value Loss: 5.059    Reward Loss: 1.145    Consistency Loss: 0.000    ] Replay Episodes Collected: 84014      Buffer Size: 16275      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:41:26,953][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 5.474    Value Loss: 4.810    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 84455      Buffer Size: 16217      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:44:36,761][train][INFO][train.py>_log] ==> #187000     Total Loss: 2.479    [weighted Loss:2.479    Policy Loss: 5.609    Value Loss: 4.701    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 84877      Buffer Size: 16162      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:47:50,825][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 5.623    Value Loss: 4.621    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 85316      Buffer Size: 16113      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:51:08,232][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 5.994    Value Loss: 4.732    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 85753      Buffer Size: 16065      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:54:20,442][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.671    [weighted Loss:3.671    Policy Loss: 6.095    Value Loss: 4.932    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 86183      Buffer Size: 16034      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 15:57:34,371][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.394    [weighted Loss:3.394    Policy Loss: 6.125    Value Loss: 4.683    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 86597      Buffer Size: 16001      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:00:49,406][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.364    [weighted Loss:2.364    Policy Loss: 6.251    Value Loss: 4.909    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 87045      Buffer Size: 15981      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:04:06,706][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.906    [weighted Loss:3.906    Policy Loss: 6.199    Value Loss: 4.717    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 87483      Buffer Size: 15961      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:07:17,101][train][INFO][train.py>_log] ==> #194000     Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 5.865    Value Loss: 4.502    Reward Loss: 1.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 87874      Buffer Size: 15948      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:10:30,746][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.431    [weighted Loss:2.431    Policy Loss: 6.000    Value Loss: 5.067    Reward Loss: 1.211    Consistency Loss: 0.000    ] Replay Episodes Collected: 88343      Buffer Size: 15929      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:13:45,368][train][INFO][train.py>_log] ==> #196000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 6.060    Value Loss: 4.429    Reward Loss: 1.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 88772      Buffer Size: 15915      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:17:03,354][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 5.836    Value Loss: 4.908    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 89186      Buffer Size: 15904      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:20:14,679][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 6.037    Value Loss: 4.878    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 89650      Buffer Size: 15893      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:23:25,657][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 6.258    Value Loss: 4.594    Reward Loss: 1.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 90068      Buffer Size: 15889      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:26:37,686][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.043    [weighted Loss:2.043    Policy Loss: 6.027    Value Loss: 4.452    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 90488      Buffer Size: 15881      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:29:56,963][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.929    [weighted Loss:2.929    Policy Loss: 6.238    Value Loss: 4.576    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 90939      Buffer Size: 15872      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:33:10,216][train][INFO][train.py>_log] ==> #202000     Total Loss: 4.374    [weighted Loss:4.374    Policy Loss: 6.500    Value Loss: 5.052    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 91382      Buffer Size: 15869      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:36:19,646][train][INFO][train.py>_log] ==> #203000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 6.370    Value Loss: 4.770    Reward Loss: 1.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 91765      Buffer Size: 15863      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:39:27,257][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.153    [weighted Loss:3.153    Policy Loss: 6.464    Value Loss: 4.223    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 92215      Buffer Size: 15845      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:42:44,458][train][INFO][train.py>_log] ==> #205000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 5.982    Value Loss: 5.225    Reward Loss: 1.231    Consistency Loss: 0.000    ] Replay Episodes Collected: 92616      Buffer Size: 15834      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:45:55,229][train][INFO][train.py>_log] ==> #206000     Total Loss: 1.016    [weighted Loss:1.016    Policy Loss: 6.128    Value Loss: 4.608    Reward Loss: 1.130    Consistency Loss: 0.000    ] Replay Episodes Collected: 93044      Buffer Size: 15822      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:49:05,672][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 6.174    Value Loss: 4.917    Reward Loss: 1.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 93453      Buffer Size: 15804      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:52:19,464][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 6.188    Value Loss: 4.813    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 93880      Buffer Size: 15791      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:55:36,524][train][INFO][train.py>_log] ==> #209000     Total Loss: 3.084    [weighted Loss:3.084    Policy Loss: 6.154    Value Loss: 4.729    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 94327      Buffer Size: 15777      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 16:58:50,243][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.087    [weighted Loss:3.087    Policy Loss: 6.109    Value Loss: 4.701    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 94742      Buffer Size: 15764      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:02:02,290][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.548    [weighted Loss:2.548    Policy Loss: 6.181    Value Loss: 4.799    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 95153      Buffer Size: 15745      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:05:14,234][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.194    [weighted Loss:3.194    Policy Loss: 6.430    Value Loss: 4.626    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 95608      Buffer Size: 15732      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:08:30,253][train][INFO][train.py>_log] ==> #213000     Total Loss: 3.241    [weighted Loss:3.241    Policy Loss: 6.283    Value Loss: 4.883    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 96006      Buffer Size: 15719      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:11:39,566][train][INFO][train.py>_log] ==> #214000     Total Loss: 3.132    [weighted Loss:3.132    Policy Loss: 6.439    Value Loss: 4.871    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 96437      Buffer Size: 15712      Transition Number: 1000.250k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:14:51,144][train][INFO][train.py>_log] ==> #215000     Total Loss: 3.019    [weighted Loss:3.019    Policy Loss: 6.146    Value Loss: 5.034    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 96859      Buffer Size: 15701      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:18:06,988][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.915    [weighted Loss:2.915    Policy Loss: 6.475    Value Loss: 4.883    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 97287      Buffer Size: 15697      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:21:22,742][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.581    [weighted Loss:3.581    Policy Loss: 6.804    Value Loss: 5.064    Reward Loss: 1.184    Consistency Loss: 0.000    ] Replay Episodes Collected: 97720      Buffer Size: 15684      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:24:32,256][train][INFO][train.py>_log] ==> #218000     Total Loss: 3.135    [weighted Loss:3.135    Policy Loss: 6.280    Value Loss: 4.901    Reward Loss: 1.205    Consistency Loss: 0.000    ] Replay Episodes Collected: 98150      Buffer Size: 15674      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:27:43,831][train][INFO][train.py>_log] ==> #219000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 6.319    Value Loss: 4.878    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 98561      Buffer Size: 15663      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:30:58,753][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 6.100    Value Loss: 4.798    Reward Loss: 1.170    Consistency Loss: 0.000    ] Replay Episodes Collected: 99014      Buffer Size: 15659      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:34:15,630][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 6.112    Value Loss: 5.650    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 99442      Buffer Size: 15653      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:37:26,957][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.793    [weighted Loss:1.793    Policy Loss: 6.505    Value Loss: 5.155    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 99886      Buffer Size: 15640      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:40:38,529][train][INFO][train.py>_log] ==> #223000     Total Loss: 2.275    [weighted Loss:2.275    Policy Loss: 6.012    Value Loss: 4.823    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 100287     Buffer Size: 15629      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:43:50,894][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 6.023    Value Loss: 4.630    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 100731     Buffer Size: 15615      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:47:10,351][train][INFO][train.py>_log] ==> #225000     Total Loss: 1.619    [weighted Loss:1.619    Policy Loss: 6.525    Value Loss: 4.673    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 101161     Buffer Size: 15607      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:50:22,411][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.346    [weighted Loss:3.346    Policy Loss: 6.013    Value Loss: 5.225    Reward Loss: 1.187    Consistency Loss: 0.000    ] Replay Episodes Collected: 101571     Buffer Size: 15593      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:53:34,652][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 5.952    Value Loss: 4.685    Reward Loss: 1.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 102012     Buffer Size: 15579      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00050 
[2022-01-03 17:56:49,776][train][INFO][train.py>_log] ==> #228000     Total Loss: 3.545    [weighted Loss:3.545    Policy Loss: 6.006    Value Loss: 5.262    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 102450     Buffer Size: 15564      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:00:06,847][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.943    [weighted Loss:2.943    Policy Loss: 6.019    Value Loss: 4.870    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 102871     Buffer Size: 15550      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:03:22,071][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.509    [weighted Loss:2.509    Policy Loss: 5.537    Value Loss: 4.965    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 103309     Buffer Size: 15540      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:06:32,939][train][INFO][train.py>_log] ==> #231000     Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 6.210    Value Loss: 5.053    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 103744     Buffer Size: 15532      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:09:47,930][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 6.103    Value Loss: 4.989    Reward Loss: 1.128    Consistency Loss: 0.000    ] Replay Episodes Collected: 104174     Buffer Size: 15521      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:13:05,788][train][INFO][train.py>_log] ==> #233000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 5.740    Value Loss: 5.340    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 104613     Buffer Size: 15522      Transition Number: 1000.038k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:16:15,198][train][INFO][train.py>_log] ==> #234000     Total Loss: 3.525    [weighted Loss:3.525    Policy Loss: 5.816    Value Loss: 5.261    Reward Loss: 1.159    Consistency Loss: 0.000    ] Replay Episodes Collected: 105053     Buffer Size: 15512      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:19:28,178][train][INFO][train.py>_log] ==> #235000     Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 5.827    Value Loss: 5.190    Reward Loss: 1.132    Consistency Loss: 0.000    ] Replay Episodes Collected: 105453     Buffer Size: 15512      Transition Number: 1000.333k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:22:40,591][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 5.979    Value Loss: 5.297    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 105907     Buffer Size: 15488      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:25:54,591][train][INFO][train.py>_log] ==> #237000     Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 5.998    Value Loss: 5.201    Reward Loss: 1.091    Consistency Loss: 0.000    ] Replay Episodes Collected: 106311     Buffer Size: 15468      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:29:04,447][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.612    [weighted Loss:2.612    Policy Loss: 5.682    Value Loss: 5.367    Reward Loss: 1.129    Consistency Loss: 0.000    ] Replay Episodes Collected: 106730     Buffer Size: 15464      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:32:17,026][train][INFO][train.py>_log] ==> #239000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 5.765    Value Loss: 4.999    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 107161     Buffer Size: 15450      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:35:29,782][train][INFO][train.py>_log] ==> #240000     Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 5.927    Value Loss: 4.949    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 107594     Buffer Size: 15438      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:38:46,850][train][INFO][train.py>_log] ==> #241000     Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 5.794    Value Loss: 5.308    Reward Loss: 1.179    Consistency Loss: 0.000    ] Replay Episodes Collected: 108020     Buffer Size: 15433      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:42:02,967][train][INFO][train.py>_log] ==> #242000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 5.691    Value Loss: 5.244    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 108451     Buffer Size: 15427      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:45:15,149][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.817    [weighted Loss:2.817    Policy Loss: 5.897    Value Loss: 5.103    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 108887     Buffer Size: 15422      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:48:25,981][train][INFO][train.py>_log] ==> #244000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 5.828    Value Loss: 5.153    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 109305     Buffer Size: 15418      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:51:44,572][train][INFO][train.py>_log] ==> #245000     Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 5.771    Value Loss: 5.318    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 109743     Buffer Size: 15406      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:54:54,443][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 5.729    Value Loss: 5.363    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 110148     Buffer Size: 15403      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 18:58:07,222][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.395    [weighted Loss:2.395    Policy Loss: 5.709    Value Loss: 5.030    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 110572     Buffer Size: 15403      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:01:17,434][train][INFO][train.py>_log] ==> #248000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 5.741    Value Loss: 5.370    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 111002     Buffer Size: 15403      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:04:33,298][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.601    [weighted Loss:2.601    Policy Loss: 5.612    Value Loss: 5.157    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 111426     Buffer Size: 15394      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:07:44,193][train][INFO][train.py>_log] ==> #250000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 5.786    Value Loss: 5.383    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 111835     Buffer Size: 15387      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:10:59,136][train][INFO][train.py>_log] ==> #251000     Total Loss: 3.288    [weighted Loss:3.288    Policy Loss: 5.927    Value Loss: 5.271    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 112301     Buffer Size: 15373      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:14:12,030][train][INFO][train.py>_log] ==> #252000     Total Loss: 1.599    [weighted Loss:1.599    Policy Loss: 5.577    Value Loss: 5.097    Reward Loss: 1.141    Consistency Loss: 0.000    ] Replay Episodes Collected: 112685     Buffer Size: 15366      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:17:27,658][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 5.669    Value Loss: 5.129    Reward Loss: 1.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 113134     Buffer Size: 15357      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:20:39,964][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.191    [weighted Loss:2.191    Policy Loss: 5.565    Value Loss: 4.886    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 113545     Buffer Size: 15348      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:23:51,674][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 5.677    Value Loss: 4.944    Reward Loss: 1.186    Consistency Loss: 0.000    ] Replay Episodes Collected: 113987     Buffer Size: 15340      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:27:03,785][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.439    [weighted Loss:3.439    Policy Loss: 5.318    Value Loss: 5.246    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 114424     Buffer Size: 15333      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:30:22,013][train][INFO][train.py>_log] ==> #257000     Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 5.985    Value Loss: 4.923    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 114851     Buffer Size: 15320      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:33:36,177][train][INFO][train.py>_log] ==> #258000     Total Loss: 3.059    [weighted Loss:3.059    Policy Loss: 5.675    Value Loss: 5.295    Reward Loss: 1.046    Consistency Loss: 0.000    ] Replay Episodes Collected: 115266     Buffer Size: 15316      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:36:48,693][train][INFO][train.py>_log] ==> #259000     Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 5.339    Value Loss: 5.562    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 115693     Buffer Size: 15313      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:40:04,661][train][INFO][train.py>_log] ==> #260000     Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 5.789    Value Loss: 5.369    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 116155     Buffer Size: 15301      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:43:22,884][train][INFO][train.py>_log] ==> #261000     Total Loss: 1.903    [weighted Loss:1.903    Policy Loss: 5.745    Value Loss: 5.030    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 116571     Buffer Size: 15304      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:46:37,427][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.966    [weighted Loss:2.966    Policy Loss: 5.436    Value Loss: 5.231    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 116990     Buffer Size: 15305      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:49:51,654][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 5.650    Value Loss: 5.542    Reward Loss: 1.142    Consistency Loss: 0.000    ] Replay Episodes Collected: 117461     Buffer Size: 15299      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:53:06,017][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 5.750    Value Loss: 5.051    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 117881     Buffer Size: 15299      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:56:21,060][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 5.827    Value Loss: 5.547    Reward Loss: 1.194    Consistency Loss: 0.000    ] Replay Episodes Collected: 118289     Buffer Size: 15301      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 19:59:33,402][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 5.811    Value Loss: 5.207    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 118737     Buffer Size: 15299      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:02:45,047][train][INFO][train.py>_log] ==> #267000     Total Loss: 3.297    [weighted Loss:3.297    Policy Loss: 5.566    Value Loss: 4.962    Reward Loss: 1.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 119147     Buffer Size: 15300      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:05:59,414][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 5.710    Value Loss: 5.192    Reward Loss: 1.056    Consistency Loss: 0.000    ] Replay Episodes Collected: 119590     Buffer Size: 15298      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:09:13,741][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 5.400    Value Loss: 4.945    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 120011     Buffer Size: 15283      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:12:23,885][train][INFO][train.py>_log] ==> #270000     Total Loss: 1.606    [weighted Loss:1.606    Policy Loss: 5.857    Value Loss: 5.229    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 120426     Buffer Size: 15275      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:15:37,673][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.184    [weighted Loss:2.184    Policy Loss: 5.352    Value Loss: 5.493    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 120864     Buffer Size: 15267      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:18:50,192][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.733    [weighted Loss:2.733    Policy Loss: 5.543    Value Loss: 4.738    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 121302     Buffer Size: 15266      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:22:07,873][train][INFO][train.py>_log] ==> #273000     Total Loss: 3.001    [weighted Loss:3.001    Policy Loss: 5.787    Value Loss: 5.284    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 121726     Buffer Size: 15261      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:25:21,050][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.063    [weighted Loss:3.063    Policy Loss: 5.633    Value Loss: 5.314    Reward Loss: 1.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 122161     Buffer Size: 15259      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:28:31,964][train][INFO][train.py>_log] ==> #275000     Total Loss: 3.105    [weighted Loss:3.105    Policy Loss: 5.819    Value Loss: 5.043    Reward Loss: 1.175    Consistency Loss: 0.000    ] Replay Episodes Collected: 122572     Buffer Size: 15258      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:31:44,116][train][INFO][train.py>_log] ==> #276000     Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 6.026    Value Loss: 5.343    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 123022     Buffer Size: 15267      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:35:00,594][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 5.613    Value Loss: 5.525    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 123418     Buffer Size: 15283      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:38:13,336][train][INFO][train.py>_log] ==> #278000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 5.785    Value Loss: 4.924    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 123898     Buffer Size: 15297      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:41:29,913][train][INFO][train.py>_log] ==> #279000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 6.062    Value Loss: 5.332    Reward Loss: 1.120    Consistency Loss: 0.000    ] Replay Episodes Collected: 124324     Buffer Size: 15318      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:44:44,925][train][INFO][train.py>_log] ==> #280000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 5.913    Value Loss: 5.053    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 124748     Buffer Size: 15337      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:48:00,989][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.974    [weighted Loss:2.974    Policy Loss: 5.802    Value Loss: 5.363    Reward Loss: 1.033    Consistency Loss: 0.000    ] Replay Episodes Collected: 125189     Buffer Size: 15341      Transition Number: 1000.178k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:51:08,725][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 5.955    Value Loss: 5.272    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 125601     Buffer Size: 15346      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:54:18,326][train][INFO][train.py>_log] ==> #283000     Total Loss: 1.478    [weighted Loss:1.478    Policy Loss: 6.039    Value Loss: 5.638    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 126057     Buffer Size: 15370      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 20:57:32,001][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.927    [weighted Loss:2.927    Policy Loss: 5.788    Value Loss: 5.453    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 126488     Buffer Size: 15407      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:00:45,020][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 5.964    Value Loss: 5.200    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 126918     Buffer Size: 15428      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:03:54,490][train][INFO][train.py>_log] ==> #286000     Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 5.938    Value Loss: 5.674    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 127336     Buffer Size: 15453      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:07:03,948][train][INFO][train.py>_log] ==> #287000     Total Loss: 3.018    [weighted Loss:3.018    Policy Loss: 6.026    Value Loss: 5.488    Reward Loss: 1.036    Consistency Loss: 0.000    ] Replay Episodes Collected: 127795     Buffer Size: 15495      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:10:13,392][train][INFO][train.py>_log] ==> #288000     Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 6.072    Value Loss: 5.781    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 128238     Buffer Size: 15536      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:13:27,549][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.997    [weighted Loss:2.997    Policy Loss: 6.088    Value Loss: 5.842    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 128676     Buffer Size: 15581      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:16:35,769][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 5.827    Value Loss: 5.550    Reward Loss: 1.216    Consistency Loss: 0.000    ] Replay Episodes Collected: 129103     Buffer Size: 15622      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:19:45,511][train][INFO][train.py>_log] ==> #291000     Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 5.766    Value Loss: 5.622    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 129559     Buffer Size: 15657      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:22:57,856][train][INFO][train.py>_log] ==> #292000     Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 5.843    Value Loss: 5.617    Reward Loss: 1.188    Consistency Loss: 0.000    ] Replay Episodes Collected: 129987     Buffer Size: 15695      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:26:13,731][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.768    [weighted Loss:2.768    Policy Loss: 5.773    Value Loss: 6.088    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 130421     Buffer Size: 15728      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:29:26,259][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.460    [weighted Loss:2.460    Policy Loss: 5.603    Value Loss: 5.521    Reward Loss: 1.207    Consistency Loss: 0.000    ] Replay Episodes Collected: 130840     Buffer Size: 15758      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:32:41,709][train][INFO][train.py>_log] ==> #295000     Total Loss: 2.372    [weighted Loss:2.372    Policy Loss: 5.912    Value Loss: 5.748    Reward Loss: 1.089    Consistency Loss: 0.000    ] Replay Episodes Collected: 131312     Buffer Size: 15788      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:35:55,281][train][INFO][train.py>_log] ==> #296000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 5.754    Value Loss: 5.745    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 131734     Buffer Size: 15811      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:39:12,355][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.512    [weighted Loss:3.512    Policy Loss: 6.001    Value Loss: 6.389    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 132165     Buffer Size: 15830      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:42:21,985][train][INFO][train.py>_log] ==> #298000     Total Loss: 1.578    [weighted Loss:1.578    Policy Loss: 5.787    Value Loss: 5.810    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 132597     Buffer Size: 15850      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:45:31,017][train][INFO][train.py>_log] ==> #299000     Total Loss: 2.566    [weighted Loss:2.566    Policy Loss: 5.679    Value Loss: 6.003    Reward Loss: 1.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 133011     Buffer Size: 15857      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:48:42,741][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.764    [weighted Loss:2.764    Policy Loss: 5.958    Value Loss: 5.920    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 133433     Buffer Size: 15863      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:51:58,984][train][INFO][train.py>_log] ==> #301000     Total Loss: 3.331    [weighted Loss:3.331    Policy Loss: 5.777    Value Loss: 5.911    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 133872     Buffer Size: 15879      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:55:07,921][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 5.551    Value Loss: 6.091    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 134306     Buffer Size: 15886      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 21:58:18,034][train][INFO][train.py>_log] ==> #303000     Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 5.405    Value Loss: 5.992    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 134710     Buffer Size: 15883      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:01:28,039][train][INFO][train.py>_log] ==> #304000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 5.798    Value Loss: 5.349    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 135127     Buffer Size: 15887      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:04:45,790][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 5.583    Value Loss: 6.088    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 135533     Buffer Size: 15890      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:07:57,092][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 5.702    Value Loss: 5.621    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 135982     Buffer Size: 15897      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:11:10,358][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 5.336    Value Loss: 6.341    Reward Loss: 1.101    Consistency Loss: 0.000    ] Replay Episodes Collected: 136400     Buffer Size: 15888      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:14:21,688][train][INFO][train.py>_log] ==> #308000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 5.470    Value Loss: 5.884    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 136833     Buffer Size: 15893      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:17:36,247][train][INFO][train.py>_log] ==> #309000     Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 5.631    Value Loss: 5.851    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 137240     Buffer Size: 15883      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:20:48,030][train][INFO][train.py>_log] ==> #310000     Total Loss: 1.286    [weighted Loss:1.286    Policy Loss: 5.264    Value Loss: 5.416    Reward Loss: 1.082    Consistency Loss: 0.000    ] Replay Episodes Collected: 137682     Buffer Size: 15884      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:24:00,260][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 5.235    Value Loss: 5.609    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 138072     Buffer Size: 15871      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:27:10,201][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 4.720    Value Loss: 5.720    Reward Loss: 1.023    Consistency Loss: 0.000    ] Replay Episodes Collected: 138512     Buffer Size: 15856      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:30:28,089][train][INFO][train.py>_log] ==> #313000     Total Loss: 2.493    [weighted Loss:2.493    Policy Loss: 5.217    Value Loss: 5.634    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 138933     Buffer Size: 15836      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:33:44,204][train][INFO][train.py>_log] ==> #314000     Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 5.245    Value Loss: 5.810    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 139365     Buffer Size: 15818      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:36:57,135][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 4.938    Value Loss: 5.609    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 139798     Buffer Size: 15798      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:40:06,987][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.296    [weighted Loss:3.296    Policy Loss: 4.955    Value Loss: 5.779    Reward Loss: 1.064    Consistency Loss: 0.000    ] Replay Episodes Collected: 140198     Buffer Size: 15772      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:43:22,724][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 4.994    Value Loss: 5.698    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 140630     Buffer Size: 15751      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:46:36,455][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.019    [weighted Loss:2.019    Policy Loss: 4.775    Value Loss: 6.169    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 141042     Buffer Size: 15740      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:49:50,227][train][INFO][train.py>_log] ==> #319000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 4.678    Value Loss: 5.693    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 141460     Buffer Size: 15722      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:53:03,178][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.757    [weighted Loss:1.757    Policy Loss: 4.772    Value Loss: 5.623    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 141925     Buffer Size: 15679      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:56:19,028][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 4.905    Value Loss: 5.520    Reward Loss: 1.070    Consistency Loss: 0.000    ] Replay Episodes Collected: 142303     Buffer Size: 15655      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 22:59:31,636][train][INFO][train.py>_log] ==> #322000     Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 5.222    Value Loss: 5.910    Reward Loss: 1.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 142745     Buffer Size: 15620      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:02:46,106][train][INFO][train.py>_log] ==> #323000     Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 5.162    Value Loss: 5.526    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 143157     Buffer Size: 15579      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:05:59,801][train][INFO][train.py>_log] ==> #324000     Total Loss: 1.903    [weighted Loss:1.903    Policy Loss: 5.188    Value Loss: 5.731    Reward Loss: 1.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 143599     Buffer Size: 15521      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:09:16,990][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.853    [weighted Loss:1.853    Policy Loss: 4.670    Value Loss: 5.933    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 144008     Buffer Size: 15482      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:12:29,713][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 5.143    Value Loss: 5.559    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 144440     Buffer Size: 15439      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:15:44,304][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.527    [weighted Loss:2.527    Policy Loss: 5.372    Value Loss: 5.874    Reward Loss: 1.178    Consistency Loss: 0.000    ] Replay Episodes Collected: 144879     Buffer Size: 15407      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:18:57,136][train][INFO][train.py>_log] ==> #328000     Total Loss: 1.999    [weighted Loss:1.999    Policy Loss: 5.299    Value Loss: 5.994    Reward Loss: 1.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 145283     Buffer Size: 15384      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:22:11,898][train][INFO][train.py>_log] ==> #329000     Total Loss: 1.510    [weighted Loss:1.510    Policy Loss: 5.689    Value Loss: 5.628    Reward Loss: 1.098    Consistency Loss: 0.000    ] Replay Episodes Collected: 145712     Buffer Size: 15363      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:25:20,669][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 5.372    Value Loss: 5.761    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 146138     Buffer Size: 15354      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:28:30,078][train][INFO][train.py>_log] ==> #331000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 5.164    Value Loss: 5.589    Reward Loss: 1.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 146569     Buffer Size: 15338      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:31:39,173][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 5.634    Value Loss: 5.401    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 146944     Buffer Size: 15338      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:34:55,958][train][INFO][train.py>_log] ==> #333000     Total Loss: 2.492    [weighted Loss:2.492    Policy Loss: 5.215    Value Loss: 5.190    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 147382     Buffer Size: 15320      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:38:08,636][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 5.196    Value Loss: 5.561    Reward Loss: 1.105    Consistency Loss: 0.000    ] Replay Episodes Collected: 147820     Buffer Size: 15315      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:41:21,244][train][INFO][train.py>_log] ==> #335000     Total Loss: 2.002    [weighted Loss:2.002    Policy Loss: 5.403    Value Loss: 5.627    Reward Loss: 1.124    Consistency Loss: 0.000    ] Replay Episodes Collected: 148246     Buffer Size: 15318      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:44:33,625][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.253    [weighted Loss:3.253    Policy Loss: 5.309    Value Loss: 6.050    Reward Loss: 1.235    Consistency Loss: 0.000    ] Replay Episodes Collected: 148661     Buffer Size: 15323      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:47:47,958][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.896    [weighted Loss:2.896    Policy Loss: 5.384    Value Loss: 5.315    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 149069     Buffer Size: 15319      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:50:57,235][train][INFO][train.py>_log] ==> #338000     Total Loss: 3.063    [weighted Loss:3.063    Policy Loss: 5.355    Value Loss: 5.838    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 149497     Buffer Size: 15314      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:54:09,416][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.950    [weighted Loss:2.950    Policy Loss: 5.302    Value Loss: 5.463    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 149916     Buffer Size: 15317      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00050 
[2022-01-03 23:57:22,322][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.625    [weighted Loss:2.625    Policy Loss: 4.878    Value Loss: 5.460    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 150339     Buffer Size: 15324      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:00:34,121][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.306    [weighted Loss:2.306    Policy Loss: 5.174    Value Loss: 5.331    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 150730     Buffer Size: 15321      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:03:43,179][train][INFO][train.py>_log] ==> #342000     Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 5.189    Value Loss: 5.768    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 151176     Buffer Size: 15327      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:06:54,141][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 5.321    Value Loss: 5.147    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 151566     Buffer Size: 15327      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:10:02,509][train][INFO][train.py>_log] ==> #344000     Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 5.145    Value Loss: 5.172    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 151988     Buffer Size: 15333      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:13:18,943][train][INFO][train.py>_log] ==> #345000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 5.146    Value Loss: 5.966    Reward Loss: 1.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 152400     Buffer Size: 15346      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:16:25,998][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 5.192    Value Loss: 5.742    Reward Loss: 1.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 152816     Buffer Size: 15345      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:19:38,269][train][INFO][train.py>_log] ==> #347000     Total Loss: 1.834    [weighted Loss:1.834    Policy Loss: 5.303    Value Loss: 5.469    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 153217     Buffer Size: 15352      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:22:51,570][train][INFO][train.py>_log] ==> #348000     Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 5.188    Value Loss: 5.621    Reward Loss: 1.010    Consistency Loss: 0.000    ] Replay Episodes Collected: 153633     Buffer Size: 15359      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:26:08,507][train][INFO][train.py>_log] ==> #349000     Total Loss: 1.757    [weighted Loss:1.757    Policy Loss: 5.373    Value Loss: 5.216    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 154053     Buffer Size: 15365      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:29:19,772][train][INFO][train.py>_log] ==> #350000     Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 4.990    Value Loss: 5.484    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 154455     Buffer Size: 15363      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:32:30,558][train][INFO][train.py>_log] ==> #351000     Total Loss: 1.294    [weighted Loss:1.294    Policy Loss: 5.193    Value Loss: 5.343    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 154871     Buffer Size: 15361      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:35:38,175][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 4.812    Value Loss: 5.324    Reward Loss: 1.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 155275     Buffer Size: 15360      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:38:51,176][train][INFO][train.py>_log] ==> #353000     Total Loss: 3.069    [weighted Loss:3.069    Policy Loss: 5.213    Value Loss: 5.113    Reward Loss: 1.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 155704     Buffer Size: 15367      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:42:01,295][train][INFO][train.py>_log] ==> #354000     Total Loss: 2.896    [weighted Loss:2.896    Policy Loss: 5.082    Value Loss: 5.173    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 156112     Buffer Size: 15367      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:45:12,474][train][INFO][train.py>_log] ==> #355000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 5.300    Value Loss: 5.320    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 156502     Buffer Size: 15368      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:48:25,643][train][INFO][train.py>_log] ==> #356000     Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 5.213    Value Loss: 5.506    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 156961     Buffer Size: 15363      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:51:38,183][train][INFO][train.py>_log] ==> #357000     Total Loss: 1.115    [weighted Loss:1.115    Policy Loss: 5.087    Value Loss: 5.673    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 157366     Buffer Size: 15362      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:54:49,681][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.532    [weighted Loss:2.532    Policy Loss: 5.064    Value Loss: 5.470    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 157762     Buffer Size: 15361      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 00:58:00,465][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.967    [weighted Loss:2.967    Policy Loss: 4.906    Value Loss: 5.556    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 158153     Buffer Size: 15358      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 01:01:09,875][train][INFO][train.py>_log] ==> #360000     Total Loss: 1.851    [weighted Loss:1.851    Policy Loss: 5.039    Value Loss: 5.375    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 158607     Buffer Size: 15358      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 01:04:24,296][train][INFO][train.py>_log] ==> #361000     Total Loss: 1.430    [weighted Loss:1.430    Policy Loss: 5.154    Value Loss: 5.255    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 159028     Buffer Size: 15355      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 01:07:38,522][train][INFO][train.py>_log] ==> #362000     Total Loss: 1.953    [weighted Loss:1.953    Policy Loss: 5.224    Value Loss: 5.763    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 159421     Buffer Size: 15349      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 01:10:51,900][train][INFO][train.py>_log] ==> #363000     Total Loss: 1.888    [weighted Loss:1.888    Policy Loss: 4.819    Value Loss: 5.845    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 159856     Buffer Size: 15346      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00050 
[2022-01-04 01:14:05,790][train][INFO][train.py>_log] ==> #364000     Total Loss: 2.492    [weighted Loss:2.492    Policy Loss: 4.911    Value Loss: 5.247    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 160285     Buffer Size: 15322      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00050 
[2022-01-04 01:17:24,271][train][INFO][train.py>_log] ==> #365000     Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 5.025    Value Loss: 5.662    Reward Loss: 0.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 160678     Buffer Size: 15321      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00050 
