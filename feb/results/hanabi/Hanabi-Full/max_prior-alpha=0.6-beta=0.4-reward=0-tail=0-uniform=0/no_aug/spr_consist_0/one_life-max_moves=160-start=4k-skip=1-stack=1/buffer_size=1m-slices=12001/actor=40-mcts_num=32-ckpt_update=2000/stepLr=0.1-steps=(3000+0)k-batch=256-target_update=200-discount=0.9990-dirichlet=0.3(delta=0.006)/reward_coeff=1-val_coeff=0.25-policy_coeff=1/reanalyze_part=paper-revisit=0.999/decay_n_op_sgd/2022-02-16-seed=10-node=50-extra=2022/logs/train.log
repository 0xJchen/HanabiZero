[2022-02-16 16:34:26,891][train][INFO][train.py>_log] ==> #0          Total Loss: 46.759   [weighted Loss:46.759   Policy Loss: 12.288   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1172       Buffer Size: 1172       Transition Number: 10.923  k Batch Size: 256        Lr: 0.00000 
[2022-02-16 16:37:19,980][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.363    [weighted Loss:6.363    Policy Loss: 14.859   Value Loss: 4.701    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 16047      Buffer Size: 16047      Transition Number: 199.827 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 16:40:06,503][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.138    [weighted Loss:5.138    Policy Loss: 12.805   Value Loss: 4.524    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 29977      Buffer Size: 29977      Transition Number: 373.364 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 16:42:45,692][train][INFO][train.py>_log] ==> #3000       Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 9.686    Value Loss: 3.995    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 56146      Buffer Size: 56146      Transition Number: 546.861 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 16:45:25,877][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.236    [weighted Loss:4.236    Policy Loss: 9.581    Value Loss: 4.057    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 82787      Buffer Size: 82787      Transition Number: 717.039 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 16:48:03,790][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 10.074   Value Loss: 3.983    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 96034      Buffer Size: 96034      Transition Number: 877.584 k Batch Size: 256        Lr: 0.10000 
