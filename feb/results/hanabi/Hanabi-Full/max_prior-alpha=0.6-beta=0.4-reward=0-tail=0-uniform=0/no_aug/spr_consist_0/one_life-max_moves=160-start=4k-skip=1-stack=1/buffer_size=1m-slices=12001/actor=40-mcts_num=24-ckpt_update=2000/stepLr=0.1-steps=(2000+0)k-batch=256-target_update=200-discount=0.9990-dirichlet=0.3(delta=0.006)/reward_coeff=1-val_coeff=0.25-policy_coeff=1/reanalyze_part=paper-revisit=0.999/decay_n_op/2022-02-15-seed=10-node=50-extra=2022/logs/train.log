[2022-02-15 16:00:07,804][train][INFO][train.py>_log] ==> #0          Total Loss: 47.263   [weighted Loss:47.263   Policy Loss: 12.791   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1063       Buffer Size: 1063       Transition Number: 10.579  k Batch Size: 256        Lr: 0.00000 
[2022-02-15 16:02:38,574][train][INFO][train.py>_log] ==> #1000       Total Loss: nan      [weighted Loss:nan      Policy Loss: 25.028   Value Loss: 33.282   Reward Loss: nan      Consistency Loss: 0.000    ] Replay Episodes Collected: 11120      Buffer Size: 11120      Transition Number: 138.510 k Batch Size: 256        Lr: 0.10000 
[2022-02-15 16:05:07,984][train][INFO][train.py>_log] ==> #2000       Total Loss: nan      [weighted Loss:nan      Policy Loss: nan      Value Loss: 41.093   Reward Loss: nan      Consistency Loss: 0.000    ] Replay Episodes Collected: 20837      Buffer Size: 20837      Transition Number: 259.253 k Batch Size: 256        Lr: 0.10000 
