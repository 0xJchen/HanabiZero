[2022-02-19 09:09:36,446][train][INFO][train.py>_log] ==> #0          Total Loss: 46.982   [weighted Loss:46.982   Policy Loss: 12.510   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1161       Buffer Size: 1161       Transition Number: 11.562  k Batch Size: 256        Lr: 0.00000 
[2022-02-19 09:12:19,437][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.060    [weighted Loss:6.060    Policy Loss: 14.402   Value Loss: 4.930    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 11681      Buffer Size: 11681      Transition Number: 145.307 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:14:55,763][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.003    [weighted Loss:7.003    Policy Loss: 13.709   Value Loss: 4.313    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 21480      Buffer Size: 21480      Transition Number: 267.819 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:17:33,033][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.862    [weighted Loss:5.862    Policy Loss: 13.191   Value Loss: 4.729    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 28924      Buffer Size: 28924      Transition Number: 383.657 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:20:14,838][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.034    [weighted Loss:6.034    Policy Loss: 10.748   Value Loss: 4.156    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 36533      Buffer Size: 36533      Transition Number: 505.113 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:22:51,292][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 9.161    Value Loss: 4.035    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 41805      Buffer Size: 41805      Transition Number: 619.551 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:25:28,111][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.941    [weighted Loss:3.941    Policy Loss: 6.669    Value Loss: 4.428    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 47141      Buffer Size: 47141      Transition Number: 728.814 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:28:09,500][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 6.617    Value Loss: 4.424    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 50713      Buffer Size: 50713      Transition Number: 826.481 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:30:46,258][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 4.421    Value Loss: 4.078    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 54327      Buffer Size: 54327      Transition Number: 936.928 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:33:23,697][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 3.359    Value Loss: 4.286    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 57379      Buffer Size: 53518      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:36:04,083][train][INFO][train.py>_log] ==> #10000      Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 2.884    Value Loss: 4.010    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 60510      Buffer Size: 48126      Transition Number: 1000.245k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:38:46,590][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 3.074    Value Loss: 3.854    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 63016      Buffer Size: 42487      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:41:29,142][train][INFO][train.py>_log] ==> #12000      Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 3.327    Value Loss: 4.160    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 65591      Buffer Size: 37551      Transition Number: 1000.150k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:44:12,537][train][INFO][train.py>_log] ==> #13000      Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 3.003    Value Loss: 4.073    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 67577      Buffer Size: 32687      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:46:51,145][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.643    [weighted Loss:1.643    Policy Loss: 3.067    Value Loss: 4.267    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 69434      Buffer Size: 28873      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:49:30,929][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 3.411    Value Loss: 3.898    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 71491      Buffer Size: 25350      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:52:11,723][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 3.406    Value Loss: 4.476    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 73391      Buffer Size: 23237      Transition Number: 1000.296k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:54:49,599][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 3.716    Value Loss: 4.409    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 75378      Buffer Size: 21804      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:57:29,731][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 3.303    Value Loss: 4.400    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 77327      Buffer Size: 20438      Transition Number: 1000.024k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:00:10,682][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 3.437    Value Loss: 4.697    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 79324      Buffer Size: 19138      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:02:53,063][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 3.396    Value Loss: 4.552    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 81277      Buffer Size: 18451      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:05:31,540][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.150    [weighted Loss:1.150    Policy Loss: 3.568    Value Loss: 4.628    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 83293      Buffer Size: 17871      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:08:11,518][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 3.813    Value Loss: 4.447    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 85228      Buffer Size: 17921      Transition Number: 1000.028k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:10:50,954][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 3.784    Value Loss: 4.641    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 87256      Buffer Size: 18107      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:13:29,697][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 3.955    Value Loss: 4.479    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 89283      Buffer Size: 18133      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:16:11,313][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 4.629    Value Loss: 4.793    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 91245      Buffer Size: 18154      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:18:47,939][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.328    [weighted Loss:1.328    Policy Loss: 4.659    Value Loss: 4.524    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 93201      Buffer Size: 18137      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:21:25,022][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 4.747    Value Loss: 5.072    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 95495      Buffer Size: 18622      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:24:06,979][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 4.860    Value Loss: 4.921    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 97792      Buffer Size: 18910      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:26:42,932][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 4.463    Value Loss: 4.870    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 99938      Buffer Size: 19123      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:29:20,609][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 3.754    Value Loss: 4.990    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 102122     Buffer Size: 19266      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:31:59,179][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.199    [weighted Loss:2.199    Policy Loss: 3.652    Value Loss: 5.200    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 103888     Buffer Size: 19297      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:34:39,722][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 3.587    Value Loss: 4.683    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 105815     Buffer Size: 19183      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:37:14,996][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 3.702    Value Loss: 5.439    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 107893     Buffer Size: 19105      Transition Number: 1000.270k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:39:54,413][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.764    [weighted Loss:1.764    Policy Loss: 3.775    Value Loss: 5.272    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 109801     Buffer Size: 19105      Transition Number: 1000.340k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:42:33,315][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 4.269    Value Loss: 5.492    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 111726     Buffer Size: 19033      Transition Number: 1000.158k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:45:11,793][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 3.776    Value Loss: 5.679    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 113613     Buffer Size: 18868      Transition Number: 1000.354k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:47:53,547][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.445    [weighted Loss:1.445    Policy Loss: 3.560    Value Loss: 4.941    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 115601     Buffer Size: 18384      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:50:29,921][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 4.300    Value Loss: 5.729    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 117507     Buffer Size: 18091      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:53:07,705][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 4.572    Value Loss: 5.509    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 119262     Buffer Size: 17774      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:55:49,104][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.153    [weighted Loss:2.153    Policy Loss: 4.632    Value Loss: 5.385    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 121119     Buffer Size: 17627      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:58:25,670][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 4.695    Value Loss: 5.147    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 122824     Buffer Size: 17450      Transition Number: 1000.132k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:01:05,273][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 5.163    Value Loss: 5.528    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 124612     Buffer Size: 17169      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:03:43,858][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 6.045    Value Loss: 5.342    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 126323     Buffer Size: 16849      Transition Number: 1000.426k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:06:24,824][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 5.956    Value Loss: 4.897    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 127985     Buffer Size: 16508      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:09:03,344][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.086    [weighted Loss:3.086    Policy Loss: 6.890    Value Loss: 5.057    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 129750     Buffer Size: 16128      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:11:44,219][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.570    [weighted Loss:4.570    Policy Loss: 7.755    Value Loss: 4.959    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 131463     Buffer Size: 15891      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:14:23,322][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 7.173    Value Loss: 5.158    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 133306     Buffer Size: 15578      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:17:02,261][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 6.912    Value Loss: 4.792    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 135005     Buffer Size: 15333      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:19:45,430][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.105    Value Loss: 4.908    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 136761     Buffer Size: 15112      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:22:24,194][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 7.613    Value Loss: 4.582    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 138620     Buffer Size: 14989      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:25:02,234][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 7.970    Value Loss: 4.641    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 140322     Buffer Size: 14978      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:27:43,680][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.854    [weighted Loss:3.854    Policy Loss: 7.468    Value Loss: 4.316    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 142221     Buffer Size: 15004      Transition Number: 1000.330k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:30:21,397][train][INFO][train.py>_log] ==> #53000      Total Loss: 4.678    [weighted Loss:4.678    Policy Loss: 7.932    Value Loss: 4.480    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 144011     Buffer Size: 15007      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:33:00,441][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.258    [weighted Loss:3.258    Policy Loss: 8.444    Value Loss: 4.669    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 145836     Buffer Size: 14969      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:35:39,768][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 8.170    Value Loss: 4.561    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 147692     Buffer Size: 14981      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:38:20,760][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 7.099    Value Loss: 5.075    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 149573     Buffer Size: 15043      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:40:59,598][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 7.424    Value Loss: 4.645    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 151335     Buffer Size: 15060      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:43:42,599][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 6.518    Value Loss: 4.763    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 153257     Buffer Size: 15066      Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:46:22,152][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 7.030    Value Loss: 4.468    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 155057     Buffer Size: 15028      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:49:01,803][train][INFO][train.py>_log] ==> #60000      Total Loss: 4.625    [weighted Loss:4.625    Policy Loss: 7.590    Value Loss: 4.472    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 156995     Buffer Size: 14963      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:51:45,782][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 7.835    Value Loss: 4.784    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 158868     Buffer Size: 14933      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:54:25,686][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.242    [weighted Loss:4.242    Policy Loss: 6.915    Value Loss: 4.582    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 160763     Buffer Size: 14926      Transition Number: 1000.252k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:57:03,894][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.335    [weighted Loss:4.335    Policy Loss: 7.939    Value Loss: 4.491    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 162521     Buffer Size: 14887      Transition Number: 1000.301k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:59:43,595][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 7.806    Value Loss: 4.808    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 164283     Buffer Size: 14835      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:02:25,105][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 7.948    Value Loss: 4.370    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 166134     Buffer Size: 14819      Transition Number: 1000.036k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:05:04,207][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 8.002    Value Loss: 4.856    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 167963     Buffer Size: 14823      Transition Number: 1000.164k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:07:47,519][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 7.985    Value Loss: 4.884    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 169752     Buffer Size: 14745      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:10:26,065][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 7.799    Value Loss: 4.821    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 171553     Buffer Size: 14682      Transition Number: 1000.399k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:13:04,496][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 8.012    Value Loss: 4.644    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 173349     Buffer Size: 14599      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:15:46,636][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 7.324    Value Loss: 4.704    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 175127     Buffer Size: 14512      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:18:26,318][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.781    [weighted Loss:3.781    Policy Loss: 7.643    Value Loss: 4.889    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 176923     Buffer Size: 14381      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:21:06,324][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 7.283    Value Loss: 4.751    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 178797     Buffer Size: 14238      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:23:46,662][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.133    [weighted Loss:3.133    Policy Loss: 7.081    Value Loss: 4.639    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 180679     Buffer Size: 14193      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:26:31,220][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 6.823    Value Loss: 4.796    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 182415     Buffer Size: 14133      Transition Number: 1000.182k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:29:10,248][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 7.721    Value Loss: 4.569    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 184207     Buffer Size: 14124      Transition Number: 1000.280k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:31:52,919][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 7.690    Value Loss: 4.474    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 186030     Buffer Size: 14107      Transition Number: 1000.073k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:34:31,937][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.997    [weighted Loss:3.997    Policy Loss: 8.141    Value Loss: 4.988    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 188311     Buffer Size: 14619      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:37:12,454][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.072    [weighted Loss:5.072    Policy Loss: 8.845    Value Loss: 5.474    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 190627     Buffer Size: 15196      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:39:56,021][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.303    [weighted Loss:4.303    Policy Loss: 8.602    Value Loss: 5.368    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 192347     Buffer Size: 15441      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:42:35,871][train][INFO][train.py>_log] ==> #80000      Total Loss: 5.309    [weighted Loss:5.309    Policy Loss: 8.714    Value Loss: 5.575    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 194281     Buffer Size: 15685      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:45:15,760][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.730    [weighted Loss:4.730    Policy Loss: 9.491    Value Loss: 5.621    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 196030     Buffer Size: 15780      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:47:58,440][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 8.551    Value Loss: 5.533    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 197889     Buffer Size: 15868      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:50:39,295][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 8.221    Value Loss: 5.797    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 199586     Buffer Size: 15931      Transition Number: 1000.700k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:53:18,946][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.667    [weighted Loss:3.667    Policy Loss: 8.200    Value Loss: 5.759    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 201384     Buffer Size: 16002      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:56:00,655][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.694    [weighted Loss:3.694    Policy Loss: 8.529    Value Loss: 5.227    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 203195     Buffer Size: 15827      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:58:41,522][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.632    [weighted Loss:4.632    Policy Loss: 8.372    Value Loss: 5.137    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 204945     Buffer Size: 15381      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:01:22,212][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 7.355    Value Loss: 5.023    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 206909     Buffer Size: 15144      Transition Number: 1000.290k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:04:06,255][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.713    Value Loss: 5.009    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 208748     Buffer Size: 15071      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:06:45,232][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.899    [weighted Loss:3.899    Policy Loss: 7.724    Value Loss: 5.183    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 210544     Buffer Size: 15075      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:09:24,596][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 6.983    Value Loss: 5.333    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 212340     Buffer Size: 15129      Transition Number: 999.927 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:12:07,644][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 7.122    Value Loss: 5.197    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 214225     Buffer Size: 15174      Transition Number: 1000.088k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:14:45,785][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.012    [weighted Loss:4.012    Policy Loss: 7.231    Value Loss: 4.840    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 216076     Buffer Size: 15228      Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:17:26,344][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 6.741    Value Loss: 5.105    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 218251     Buffer Size: 15626      Transition Number: 1000.194k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:20:06,383][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 6.931    Value Loss: 5.459    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 220376     Buffer Size: 16003      Transition Number: 1000.256k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:22:46,381][train][INFO][train.py>_log] ==> #95000      Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 7.406    Value Loss: 5.591    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 223879     Buffer Size: 17538      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:25:26,450][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 8.022    Value Loss: 6.171    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 227291     Buffer Size: 19149      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:28:08,754][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.138    [weighted Loss:4.138    Policy Loss: 7.903    Value Loss: 6.222    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 229608     Buffer Size: 19716      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:30:51,163][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.157    [weighted Loss:4.157    Policy Loss: 7.298    Value Loss: 6.335    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 232158     Buffer Size: 20307      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:33:30,261][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 7.813    Value Loss: 5.509    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 233887     Buffer Size: 20402      Transition Number: 1000.165k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:36:13,642][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.230    [weighted Loss:4.230    Policy Loss: 7.466    Value Loss: 6.120    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 235770     Buffer Size: 20441      Transition Number: 1000.285k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:38:54,740][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 7.966    Value Loss: 5.774    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 237673     Buffer Size: 20281      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:41:35,759][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.366    [weighted Loss:3.366    Policy Loss: 7.213    Value Loss: 5.753    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 239539     Buffer Size: 19982      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:44:16,446][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 6.731    Value Loss: 5.566    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 241289     Buffer Size: 19130      Transition Number: 1000.124k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:47:00,606][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 7.157    Value Loss: 5.398    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 243220     Buffer Size: 17496      Transition Number: 1000.227k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:49:39,120][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.767    [weighted Loss:3.767    Policy Loss: 6.938    Value Loss: 5.427    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 244946     Buffer Size: 16407      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:52:22,777][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 6.970    Value Loss: 5.575    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 246844     Buffer Size: 15797      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:55:03,000][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 6.606    Value Loss: 5.234    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 248715     Buffer Size: 15546      Transition Number: 1000.018k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:57:41,424][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 6.942    Value Loss: 5.058    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 250552     Buffer Size: 15551      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:00:23,694][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 6.843    Value Loss: 5.253    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 252425     Buffer Size: 15552      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:03:03,595][train][INFO][train.py>_log] ==> #110000     Total Loss: 4.178    [weighted Loss:4.178    Policy Loss: 7.728    Value Loss: 5.151    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 254222     Buffer Size: 15585      Transition Number: 1000.223k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:05:42,555][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 7.761    Value Loss: 5.418    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 256145     Buffer Size: 15577      Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:08:22,550][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 7.481    Value Loss: 5.220    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 257995     Buffer Size: 15628      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:11:04,765][train][INFO][train.py>_log] ==> #113000     Total Loss: 4.461    [weighted Loss:4.461    Policy Loss: 7.734    Value Loss: 5.339    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 259771     Buffer Size: 15718      Transition Number: 1000.304k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:13:43,642][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 7.239    Value Loss: 4.801    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 261734     Buffer Size: 15760      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:16:25,353][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.969    [weighted Loss:4.969    Policy Loss: 8.769    Value Loss: 4.740    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 263619     Buffer Size: 15829      Transition Number: 1000.427k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:19:03,318][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.345    [weighted Loss:4.345    Policy Loss: 8.191    Value Loss: 4.794    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 265475     Buffer Size: 15884      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:21:44,448][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 8.211    Value Loss: 4.993    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 267386     Buffer Size: 15909      Transition Number: 1000.221k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:24:26,728][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.923    Value Loss: 4.997    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 269219     Buffer Size: 15907      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:27:07,528][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.435    [weighted Loss:4.435    Policy Loss: 8.467    Value Loss: 4.995    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 271086     Buffer Size: 15921      Transition Number: 1000.232k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:29:46,610][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 7.236    Value Loss: 5.197    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 273067     Buffer Size: 15910      Transition Number: 1000.209k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:32:26,254][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.407    [weighted Loss:3.407    Policy Loss: 7.696    Value Loss: 5.079    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 274845     Buffer Size: 15824      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:35:09,133][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.516    [weighted Loss:3.516    Policy Loss: 7.304    Value Loss: 5.146    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 276694     Buffer Size: 15741      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:37:50,383][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 7.178    Value Loss: 5.026    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 278492     Buffer Size: 15646      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:40:33,784][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.476    [weighted Loss:4.476    Policy Loss: 6.990    Value Loss: 5.060    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 280352     Buffer Size: 15520      Transition Number: 1000.190k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:43:13,492][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 7.433    Value Loss: 4.932    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 282249     Buffer Size: 15373      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:45:52,907][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.053    [weighted Loss:4.053    Policy Loss: 6.937    Value Loss: 4.802    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 284025     Buffer Size: 15288      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:48:36,939][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 6.801    Value Loss: 5.156    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 285911     Buffer Size: 15226      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:51:17,388][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 6.604    Value Loss: 4.930    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 287768     Buffer Size: 15131      Transition Number: 1000.539k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:53:56,331][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.846    [weighted Loss:3.846    Policy Loss: 7.313    Value Loss: 4.696    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 289542     Buffer Size: 15061      Transition Number: 1000.182k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:56:38,165][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 6.375    Value Loss: 5.069    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 291419     Buffer Size: 14997      Transition Number: 999.930 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:59:19,543][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 6.516    Value Loss: 4.762    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 293264     Buffer Size: 14937      Transition Number: 1000.330k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:01:59,589][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 6.212    Value Loss: 4.816    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 295052     Buffer Size: 14869      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:04:43,341][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 6.181    Value Loss: 4.436    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 296936     Buffer Size: 14861      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:07:25,099][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 6.531    Value Loss: 5.073    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 298832     Buffer Size: 14833      Transition Number: 1000.176k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:10:06,357][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 6.336    Value Loss: 5.070    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 301278     Buffer Size: 15395      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:12:48,098][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.967    Value Loss: 5.445    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 303579     Buffer Size: 15949      Transition Number: 1000.033k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:15:28,266][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 6.935    Value Loss: 5.611    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 305310     Buffer Size: 16074      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:18:08,768][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.364    [weighted Loss:4.364    Policy Loss: 7.441    Value Loss: 5.208    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 307181     Buffer Size: 16165      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:20:50,979][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 6.799    Value Loss: 5.244    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 309219     Buffer Size: 16210      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:23:33,137][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 6.917    Value Loss: 5.263    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 310994     Buffer Size: 16276      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:26:12,392][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 6.385    Value Loss: 5.402    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 312743     Buffer Size: 16343      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:28:57,836][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 7.018    Value Loss: 5.150    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 314684     Buffer Size: 16415      Transition Number: 1000.117k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:31:38,573][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.553    [weighted Loss:3.553    Policy Loss: 6.364    Value Loss: 5.263    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 316513     Buffer Size: 16161      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:34:20,317][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.894    [weighted Loss:2.894    Policy Loss: 6.679    Value Loss: 4.950    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 318471     Buffer Size: 15582      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:37:04,003][train][INFO][train.py>_log] ==> #145000     Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 6.901    Value Loss: 5.368    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 320236     Buffer Size: 15387      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:39:43,392][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.841    Value Loss: 4.898    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 322090     Buffer Size: 15374      Transition Number: 1000.288k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:42:23,739][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 7.030    Value Loss: 4.984    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 323844     Buffer Size: 15378      Transition Number: 1000.339k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:45:06,034][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.930    Value Loss: 4.892    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 325696     Buffer Size: 15408      Transition Number: 1000.137k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:47:46,819][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 6.854    Value Loss: 5.171    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 327582     Buffer Size: 15464      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:50:28,865][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.752    [weighted Loss:3.752    Policy Loss: 7.182    Value Loss: 5.222    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 329418     Buffer Size: 15503      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:53:12,375][train][INFO][train.py>_log] ==> #151000     Total Loss: 4.071    [weighted Loss:4.071    Policy Loss: 7.033    Value Loss: 4.896    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 331343     Buffer Size: 15537      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:55:52,841][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 7.057    Value Loss: 4.876    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 333051     Buffer Size: 15572      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:58:33,918][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 6.556    Value Loss: 5.080    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 334960     Buffer Size: 15608      Transition Number: 1000.151k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:01:17,135][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 7.342    Value Loss: 5.055    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 336853     Buffer Size: 15700      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:03:55,182][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.685    [weighted Loss:3.685    Policy Loss: 6.172    Value Loss: 5.135    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 338636     Buffer Size: 15757      Transition Number: 1000.157k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:06:35,319][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 6.472    Value Loss: 4.913    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 340437     Buffer Size: 15799      Transition Number: 1000.075k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:09:17,915][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 6.936    Value Loss: 5.083    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 342363     Buffer Size: 15864      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:12:00,808][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 6.466    Value Loss: 5.548    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 344226     Buffer Size: 15924      Transition Number: 1000.199k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:14:42,724][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 5.816    Value Loss: 5.158    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 346072     Buffer Size: 15935      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:17:26,316][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 6.574    Value Loss: 5.119    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 347856     Buffer Size: 15930      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:20:08,413][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 6.152    Value Loss: 4.967    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 349618     Buffer Size: 15902      Transition Number: 1000.087k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:22:49,641][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 6.539    Value Loss: 5.419    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 351460     Buffer Size: 15875      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:25:32,810][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.552    [weighted Loss:3.552    Policy Loss: 6.757    Value Loss: 5.265    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 353335     Buffer Size: 15850      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:28:12,496][train][INFO][train.py>_log] ==> #164000     Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 6.564    Value Loss: 4.900    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 355024     Buffer Size: 15867      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:30:55,439][train][INFO][train.py>_log] ==> #165000     Total Loss: 4.433    [weighted Loss:4.433    Policy Loss: 6.663    Value Loss: 5.226    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 356906     Buffer Size: 15890      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:33:37,645][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.639    [weighted Loss:3.639    Policy Loss: 6.662    Value Loss: 5.233    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 358726     Buffer Size: 15871      Transition Number: 1000.103k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:36:18,668][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 7.122    Value Loss: 5.265    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 360707     Buffer Size: 15976      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:38:59,246][train][INFO][train.py>_log] ==> #168000     Total Loss: 4.541    [weighted Loss:4.541    Policy Loss: 7.179    Value Loss: 5.555    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 362640     Buffer Size: 16131      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:41:42,493][train][INFO][train.py>_log] ==> #169000     Total Loss: 4.152    [weighted Loss:4.152    Policy Loss: 6.437    Value Loss: 5.063    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 364519     Buffer Size: 16246      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:44:23,551][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 7.395    Value Loss: 5.611    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 366422     Buffer Size: 16381      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:47:05,196][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 7.259    Value Loss: 5.494    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 368224     Buffer Size: 16462      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:49:49,741][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 7.071    Value Loss: 5.719    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 370119     Buffer Size: 16512      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:52:30,395][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.195    [weighted Loss:3.195    Policy Loss: 7.497    Value Loss: 5.207    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 372084     Buffer Size: 16673      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:55:12,648][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 7.234    Value Loss: 5.867    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 373994     Buffer Size: 16806      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:57:56,192][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 7.170    Value Loss: 5.662    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 375834     Buffer Size: 16888      Transition Number: 1000.187k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:00:41,466][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.701    [weighted Loss:3.701    Policy Loss: 7.219    Value Loss: 5.406    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 377786     Buffer Size: 16811      Transition Number: 1000.022k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:03:21,841][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 7.598    Value Loss: 5.801    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 379697     Buffer Size: 16852      Transition Number: 1000.241k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:06:03,591][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 7.623    Value Loss: 5.541    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 381681     Buffer Size: 16919      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:08:45,129][train][INFO][train.py>_log] ==> #179000     Total Loss: 4.728    [weighted Loss:4.728    Policy Loss: 7.897    Value Loss: 5.600    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 383635     Buffer Size: 17026      Transition Number: 1000.214k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:11:26,904][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 7.360    Value Loss: 5.704    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 385659     Buffer Size: 17240      Transition Number: 1000.211k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:14:10,403][train][INFO][train.py>_log] ==> #181000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 7.141    Value Loss: 5.609    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 387483     Buffer Size: 17294      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:16:51,384][train][INFO][train.py>_log] ==> #182000     Total Loss: 4.237    [weighted Loss:4.237    Policy Loss: 7.510    Value Loss: 5.602    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 389432     Buffer Size: 17244      Transition Number: 1000.249k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:19:35,131][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 7.274    Value Loss: 5.583    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 391349     Buffer Size: 17182      Transition Number: 1000.398k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:22:15,371][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.646    [weighted Loss:3.646    Policy Loss: 6.883    Value Loss: 5.502    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 393085     Buffer Size: 17150      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:24:58,034][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.110    [weighted Loss:2.110    Policy Loss: 6.946    Value Loss: 5.874    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 394978     Buffer Size: 17163      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:27:40,482][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.480    [weighted Loss:3.480    Policy Loss: 6.647    Value Loss: 5.666    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 396873     Buffer Size: 17092      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:30:26,186][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 6.495    Value Loss: 5.845    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 398904     Buffer Size: 17074      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:33:08,572][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.811    [weighted Loss:3.811    Policy Loss: 6.686    Value Loss: 5.613    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 400873     Buffer Size: 17001      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:35:52,675][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.738    [weighted Loss:3.738    Policy Loss: 6.240    Value Loss: 5.645    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 402744     Buffer Size: 16797      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:38:34,435][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 6.492    Value Loss: 5.610    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 404541     Buffer Size: 16733      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:41:15,072][train][INFO][train.py>_log] ==> #191000     Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 6.712    Value Loss: 5.462    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 406681     Buffer Size: 16898      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:43:59,183][train][INFO][train.py>_log] ==> #192000     Total Loss: 4.239    [weighted Loss:4.239    Policy Loss: 6.718    Value Loss: 5.618    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 408742     Buffer Size: 17122      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:46:40,780][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 6.155    Value Loss: 5.496    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 410690     Buffer Size: 17180      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:49:22,624][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 6.390    Value Loss: 5.054    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 412606     Buffer Size: 17183      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:52:06,017][train][INFO][train.py>_log] ==> #195000     Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 6.258    Value Loss: 5.572    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 414538     Buffer Size: 17107      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:54:52,100][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.546    [weighted Loss:3.546    Policy Loss: 6.882    Value Loss: 5.430    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 416418     Buffer Size: 17011      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:57:33,044][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 6.213    Value Loss: 5.306    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 418241     Buffer Size: 16898      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:00:16,813][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 7.198    Value Loss: 4.983    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 420186     Buffer Size: 16899      Transition Number: 1000.261k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:03:01,114][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 6.687    Value Loss: 5.264    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 422108     Buffer Size: 16840      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:05:59,281][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 6.786    Value Loss: 5.160    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 424021     Buffer Size: 16585      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:08:40,631][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 6.320    Value Loss: 4.893    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 426105     Buffer Size: 16399      Transition Number: 999.950 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:11:25,906][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 5.985    Value Loss: 4.843    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 427942     Buffer Size: 16367      Transition Number: 1000.176k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:14:09,297][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 5.966    Value Loss: 5.150    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 429814     Buffer Size: 16320      Transition Number: 1000.301k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:16:52,669][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 5.794    Value Loss: 4.957    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 431790     Buffer Size: 16295      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:19:35,724][train][INFO][train.py>_log] ==> #205000     Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 5.721    Value Loss: 4.965    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 433620     Buffer Size: 16279      Transition Number: 1000.004k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:22:21,175][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 5.951    Value Loss: 4.747    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 435544     Buffer Size: 16288      Transition Number: 1000.330k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:25:02,897][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 5.790    Value Loss: 5.002    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 437435     Buffer Size: 16261      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:27:49,152][train][INFO][train.py>_log] ==> #208000     Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 5.931    Value Loss: 4.685    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 439401     Buffer Size: 16243      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:30:33,474][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 5.699    Value Loss: 5.102    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 441264     Buffer Size: 16232      Transition Number: 1000.468k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:33:14,987][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 6.077    Value Loss: 4.962    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 443116     Buffer Size: 16162      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:36:01,440][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 6.302    Value Loss: 4.685    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 445001     Buffer Size: 16135      Transition Number: 999.945 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:38:42,626][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 6.176    Value Loss: 4.810    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 446894     Buffer Size: 16127      Transition Number: 1000.062k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:41:26,546][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.627    [weighted Loss:2.627    Policy Loss: 6.110    Value Loss: 4.710    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 448858     Buffer Size: 16106      Transition Number: 1000.176k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:44:10,856][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 6.623    Value Loss: 4.541    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 450718     Buffer Size: 16096      Transition Number: 1000.065k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:46:53,318][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 6.510    Value Loss: 4.817    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 452716     Buffer Size: 16095      Transition Number: 999.945 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:49:35,339][train][INFO][train.py>_log] ==> #216000     Total Loss: 3.583    [weighted Loss:3.583    Policy Loss: 6.399    Value Loss: 4.741    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 454635     Buffer Size: 16103      Transition Number: 1000.093k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:52:18,396][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 6.868    Value Loss: 4.774    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 456495     Buffer Size: 16089      Transition Number: 1000.266k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:55:00,984][train][INFO][train.py>_log] ==> #218000     Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 6.825    Value Loss: 4.775    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 458374     Buffer Size: 16079      Transition Number: 999.970 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:57:45,263][train][INFO][train.py>_log] ==> #219000     Total Loss: 4.332    [weighted Loss:4.332    Policy Loss: 7.004    Value Loss: 4.897    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 460309     Buffer Size: 16073      Transition Number: 1000.201k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:00:29,630][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 6.365    Value Loss: 4.905    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 462236     Buffer Size: 16085      Transition Number: 1000.006k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:03:13,716][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 6.511    Value Loss: 4.777    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 464334     Buffer Size: 16135      Transition Number: 999.963 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:05:58,943][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 6.064    Value Loss: 5.116    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 466266     Buffer Size: 16181      Transition Number: 1000.127k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:08:44,583][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 6.878    Value Loss: 5.171    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 468290     Buffer Size: 16207      Transition Number: 1000.027k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:11:30,793][train][INFO][train.py>_log] ==> #224000     Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 6.636    Value Loss: 4.915    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 470171     Buffer Size: 16246      Transition Number: 1000.194k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:14:17,982][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.571    Value Loss: 4.881    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 472185     Buffer Size: 16275      Transition Number: 1000.468k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:17:05,058][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.773    [weighted Loss:3.773    Policy Loss: 6.556    Value Loss: 4.958    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 474142     Buffer Size: 16290      Transition Number: 999.981 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:19:48,318][train][INFO][train.py>_log] ==> #227000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 7.042    Value Loss: 4.801    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 476062     Buffer Size: 16307      Transition Number: 1000.204k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:22:33,992][train][INFO][train.py>_log] ==> #228000     Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 6.244    Value Loss: 4.852    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 477991     Buffer Size: 16300      Transition Number: 1000.479k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:25:18,375][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 6.764    Value Loss: 5.157    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 479878     Buffer Size: 16247      Transition Number: 1000.106k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:28:03,285][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.522    [weighted Loss:2.522    Policy Loss: 6.498    Value Loss: 4.717    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 481836     Buffer Size: 16205      Transition Number: 1000.317k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:30:47,747][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 6.759    Value Loss: 4.815    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 483764     Buffer Size: 16154      Transition Number: 1000.003k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:33:33,809][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 7.210    Value Loss: 4.742    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 485761     Buffer Size: 16115      Transition Number: 1000.223k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:36:17,724][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 6.879    Value Loss: 4.956    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 487635     Buffer Size: 16075      Transition Number: 1000.020k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:39:00,401][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 6.685    Value Loss: 4.845    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 489441     Buffer Size: 16050      Transition Number: 1000.341k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:41:46,194][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.863    [weighted Loss:3.863    Policy Loss: 6.927    Value Loss: 4.817    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 491462     Buffer Size: 16007      Transition Number: 999.990 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:44:31,743][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.421    [weighted Loss:3.421    Policy Loss: 6.938    Value Loss: 4.844    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 493485     Buffer Size: 15999      Transition Number: 1000.230k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:47:16,415][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 7.255    Value Loss: 5.211    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 495402     Buffer Size: 15994      Transition Number: 999.965 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:50:01,462][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.977    [weighted Loss:3.977    Policy Loss: 6.992    Value Loss: 4.657    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 497472     Buffer Size: 15998      Transition Number: 1000.319k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:52:45,587][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 7.027    Value Loss: 4.801    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 499338     Buffer Size: 16013      Transition Number: 1000.090k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:55:30,088][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 7.162    Value Loss: 5.054    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 501333     Buffer Size: 16032      Transition Number: 999.977 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:58:16,924][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.400    [weighted Loss:2.400    Policy Loss: 6.881    Value Loss: 5.000    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 503299     Buffer Size: 16044      Transition Number: 999.965 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:01:03,589][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 6.904    Value Loss: 4.954    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 505254     Buffer Size: 16069      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:03:47,461][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 7.221    Value Loss: 5.204    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 507191     Buffer Size: 16095      Transition Number: 1000.245k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:06:32,009][train][INFO][train.py>_log] ==> #244000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 6.947    Value Loss: 5.096    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 509107     Buffer Size: 16107      Transition Number: 1000.299k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:09:17,710][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 7.038    Value Loss: 4.841    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 511155     Buffer Size: 16150      Transition Number: 1000.144k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:12:01,850][train][INFO][train.py>_log] ==> #246000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 7.286    Value Loss: 4.931    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 513196     Buffer Size: 16189      Transition Number: 1000.190k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:14:46,986][train][INFO][train.py>_log] ==> #247000     Total Loss: 4.421    [weighted Loss:4.421    Policy Loss: 7.567    Value Loss: 5.129    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 515182     Buffer Size: 16195      Transition Number: 1000.031k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:17:30,868][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.700    [weighted Loss:2.700    Policy Loss: 7.463    Value Loss: 5.368    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 517028     Buffer Size: 16191      Transition Number: 1000.045k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:20:15,306][train][INFO][train.py>_log] ==> #249000     Total Loss: 4.101    [weighted Loss:4.101    Policy Loss: 7.323    Value Loss: 4.949    Reward Loss: 1.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 518941     Buffer Size: 16161      Transition Number: 1000.023k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:22:58,288][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 6.940    Value Loss: 5.002    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 520827     Buffer Size: 16149      Transition Number: 1000.070k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:25:44,744][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 7.606    Value Loss: 4.829    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 522731     Buffer Size: 16134      Transition Number: 1000.131k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:28:30,231][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 7.411    Value Loss: 5.012    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 524732     Buffer Size: 16134      Transition Number: 1000.572k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:31:16,583][train][INFO][train.py>_log] ==> #253000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 7.647    Value Loss: 4.693    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 526717     Buffer Size: 16095      Transition Number: 1000.112k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:34:01,982][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 7.395    Value Loss: 4.885    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 528668     Buffer Size: 16061      Transition Number: 1000.483k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:36:46,298][train][INFO][train.py>_log] ==> #255000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 7.337    Value Loss: 5.137    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 530577     Buffer Size: 16033      Transition Number: 999.993 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:39:30,841][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.999    [weighted Loss:3.999    Policy Loss: 6.984    Value Loss: 5.217    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 532503     Buffer Size: 16012      Transition Number: 1000.023k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:42:14,540][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 7.463    Value Loss: 4.962    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 534418     Buffer Size: 16029      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:45:02,763][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 6.690    Value Loss: 5.085    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 536412     Buffer Size: 16051      Transition Number: 1000.068k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:47:47,737][train][INFO][train.py>_log] ==> #259000     Total Loss: 3.544    [weighted Loss:3.544    Policy Loss: 6.732    Value Loss: 4.947    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 538259     Buffer Size: 16095      Transition Number: 1000.096k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:50:33,620][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 6.907    Value Loss: 4.766    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 540333     Buffer Size: 16150      Transition Number: 1000.069k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:53:19,431][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.285    [weighted Loss:3.285    Policy Loss: 6.692    Value Loss: 5.090    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 542372     Buffer Size: 16194      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:56:06,648][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 6.825    Value Loss: 5.250    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 544414     Buffer Size: 16242      Transition Number: 1000.061k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:58:51,701][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 6.869    Value Loss: 5.242    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 546429     Buffer Size: 16313      Transition Number: 1000.096k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:01:36,571][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 7.114    Value Loss: 5.271    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 548323     Buffer Size: 16390      Transition Number: 999.951 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:04:19,921][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 6.987    Value Loss: 5.133    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 550268     Buffer Size: 16447      Transition Number: 1000.150k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:07:04,270][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 7.098    Value Loss: 5.218    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 552196     Buffer Size: 16490      Transition Number: 1000.320k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:09:51,970][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 6.841    Value Loss: 5.396    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 554170     Buffer Size: 16507      Transition Number: 1000.131k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:12:39,224][train][INFO][train.py>_log] ==> #268000     Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 6.887    Value Loss: 5.094    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 556148     Buffer Size: 16525      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:15:24,130][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 6.460    Value Loss: 5.219    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 558125     Buffer Size: 16504      Transition Number: 1000.001k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:18:08,015][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 6.839    Value Loss: 5.297    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 560084     Buffer Size: 16507      Transition Number: 999.991 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:20:54,583][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.871    [weighted Loss:2.871    Policy Loss: 7.141    Value Loss: 5.093    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 562021     Buffer Size: 16487      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:23:40,532][train][INFO][train.py>_log] ==> #272000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 6.619    Value Loss: 5.291    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 564024     Buffer Size: 16503      Transition Number: 1000.519k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:26:28,077][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 6.465    Value Loss: 4.897    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 565998     Buffer Size: 16490      Transition Number: 999.991 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:29:15,491][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 6.821    Value Loss: 4.922    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 567962     Buffer Size: 16489      Transition Number: 999.988 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:32:02,748][train][INFO][train.py>_log] ==> #275000     Total Loss: 3.592    [weighted Loss:3.592    Policy Loss: 6.627    Value Loss: 5.025    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 569989     Buffer Size: 16481      Transition Number: 999.947 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:34:47,850][train][INFO][train.py>_log] ==> #276000     Total Loss: 3.791    [weighted Loss:3.791    Policy Loss: 6.515    Value Loss: 5.240    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 571981     Buffer Size: 16464      Transition Number: 1000.109k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:37:36,282][train][INFO][train.py>_log] ==> #277000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 6.455    Value Loss: 5.042    Reward Loss: 1.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 573920     Buffer Size: 16446      Transition Number: 1000.076k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:40:22,896][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 6.239    Value Loss: 5.049    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 575887     Buffer Size: 16442      Transition Number: 1000.019k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:43:12,841][train][INFO][train.py>_log] ==> #279000     Total Loss: 3.976    [weighted Loss:3.976    Policy Loss: 6.659    Value Loss: 5.172    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 577924     Buffer Size: 16387      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:46:01,339][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 6.321    Value Loss: 4.694    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 579854     Buffer Size: 16327      Transition Number: 1000.154k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:48:49,186][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 6.707    Value Loss: 5.046    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 581886     Buffer Size: 16252      Transition Number: 1000.379k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:51:37,131][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 6.039    Value Loss: 4.524    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 583793     Buffer Size: 16198      Transition Number: 1000.028k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:54:26,278][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 6.614    Value Loss: 5.299    Reward Loss: 1.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 585820     Buffer Size: 16167      Transition Number: 999.942 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:57:12,302][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.511    [weighted Loss:2.511    Policy Loss: 6.343    Value Loss: 4.986    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 587797     Buffer Size: 16142      Transition Number: 1000.084k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:00:00,578][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 6.818    Value Loss: 5.140    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 589844     Buffer Size: 16092      Transition Number: 999.992 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:02:48,597][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 7.158    Value Loss: 4.666    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 591891     Buffer Size: 16044      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:05:35,648][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 6.923    Value Loss: 5.005    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 593905     Buffer Size: 16022      Transition Number: 999.993 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:08:23,917][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.769    [weighted Loss:2.769    Policy Loss: 6.780    Value Loss: 4.890    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 595890     Buffer Size: 16011      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:11:11,928][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 6.879    Value Loss: 4.760    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 597844     Buffer Size: 16038      Transition Number: 1000.465k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:13:59,240][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 7.226    Value Loss: 4.910    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 599877     Buffer Size: 16043      Transition Number: 999.960 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:16:46,483][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 6.841    Value Loss: 4.719    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 601895     Buffer Size: 16020      Transition Number: 1000.180k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:19:32,496][train][INFO][train.py>_log] ==> #292000     Total Loss: 4.229    [weighted Loss:4.229    Policy Loss: 7.519    Value Loss: 4.757    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 603765     Buffer Size: 15994      Transition Number: 1000.018k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:22:19,552][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.759    [weighted Loss:2.759    Policy Loss: 7.112    Value Loss: 4.639    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 605789     Buffer Size: 15972      Transition Number: 999.954 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:25:05,838][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 6.957    Value Loss: 4.566    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 607811     Buffer Size: 15942      Transition Number: 999.968 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:27:51,427][train][INFO][train.py>_log] ==> #295000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 7.566    Value Loss: 5.133    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 609824     Buffer Size: 15916      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:30:37,071][train][INFO][train.py>_log] ==> #296000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 6.588    Value Loss: 4.901    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 611860     Buffer Size: 15895      Transition Number: 999.974 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:33:24,619][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 6.623    Value Loss: 4.828    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 613811     Buffer Size: 15858      Transition Number: 999.963 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:36:09,767][train][INFO][train.py>_log] ==> #298000     Total Loss: 3.729    [weighted Loss:3.729    Policy Loss: 7.392    Value Loss: 4.840    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 615797     Buffer Size: 15815      Transition Number: 1000.055k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:38:55,286][train][INFO][train.py>_log] ==> #299000     Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 7.354    Value Loss: 4.845    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 617724     Buffer Size: 15793      Transition Number: 1000.003k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:41:40,891][train][INFO][train.py>_log] ==> #300000     Total Loss: 4.020    [weighted Loss:4.020    Policy Loss: 7.068    Value Loss: 4.870    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 619800     Buffer Size: 15774      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:44:28,508][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 7.338    Value Loss: 4.918    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 621744     Buffer Size: 15770      Transition Number: 1000.166k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:47:16,744][train][INFO][train.py>_log] ==> #302000     Total Loss: 3.108    [weighted Loss:3.108    Policy Loss: 7.180    Value Loss: 4.818    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 623725     Buffer Size: 15770      Transition Number: 1000.082k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:50:02,602][train][INFO][train.py>_log] ==> #303000     Total Loss: 3.537    [weighted Loss:3.537    Policy Loss: 7.084    Value Loss: 4.887    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 625750     Buffer Size: 15781      Transition Number: 1000.255k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:52:51,189][train][INFO][train.py>_log] ==> #304000     Total Loss: 3.821    [weighted Loss:3.821    Policy Loss: 7.045    Value Loss: 5.208    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 627747     Buffer Size: 15773      Transition Number: 1000.055k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:55:39,504][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 6.934    Value Loss: 4.979    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 629777     Buffer Size: 15802      Transition Number: 1000.008k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:58:30,525][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.256    [weighted Loss:1.256    Policy Loss: 6.890    Value Loss: 4.886    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 631840     Buffer Size: 15816      Transition Number: 1000.011k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:01:16,445][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 6.355    Value Loss: 5.363    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 633797     Buffer Size: 15834      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:04:04,558][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 6.697    Value Loss: 4.875    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 635828     Buffer Size: 15854      Transition Number: 1000.222k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:06:52,692][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 6.573    Value Loss: 5.096    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 637804     Buffer Size: 15870      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:09:40,937][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.309    [weighted Loss:3.309    Policy Loss: 6.651    Value Loss: 4.815    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 639885     Buffer Size: 15896      Transition Number: 999.994 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:12:27,689][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 6.244    Value Loss: 5.161    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 641895     Buffer Size: 15921      Transition Number: 1000.696k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:15:16,284][train][INFO][train.py>_log] ==> #312000     Total Loss: 3.293    [weighted Loss:3.293    Policy Loss: 6.115    Value Loss: 5.134    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 643853     Buffer Size: 15958      Transition Number: 1000.178k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:18:04,394][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.660    Value Loss: 4.782    Reward Loss: 1.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 645913     Buffer Size: 15960      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:20:53,482][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 6.601    Value Loss: 5.188    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 648044     Buffer Size: 15993      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:23:39,941][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 6.245    Value Loss: 4.964    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 649995     Buffer Size: 15992      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:26:32,255][train][INFO][train.py>_log] ==> #316000     Total Loss: 2.159    [weighted Loss:2.159    Policy Loss: 6.288    Value Loss: 4.825    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 652041     Buffer Size: 15978      Transition Number: 999.943 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:29:15,540][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 6.828    Value Loss: 4.761    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 654019     Buffer Size: 15969      Transition Number: 1000.018k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:32:02,928][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 6.651    Value Loss: 4.708    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 656085     Buffer Size: 15942      Transition Number: 1000.116k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:34:50,862][train][INFO][train.py>_log] ==> #319000     Total Loss: 4.336    [weighted Loss:4.336    Policy Loss: 6.473    Value Loss: 5.235    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 658101     Buffer Size: 15900      Transition Number: 1000.289k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:37:38,372][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 6.825    Value Loss: 5.070    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 660064     Buffer Size: 15855      Transition Number: 1000.071k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:40:28,279][train][INFO][train.py>_log] ==> #321000     Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 6.215    Value Loss: 4.688    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 662147     Buffer Size: 15791      Transition Number: 1000.039k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:43:18,381][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 6.729    Value Loss: 4.804    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 664224     Buffer Size: 15727      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:46:05,124][train][INFO][train.py>_log] ==> #323000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 6.723    Value Loss: 4.834    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 666215     Buffer Size: 15750      Transition Number: 1000.045k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:48:52,412][train][INFO][train.py>_log] ==> #324000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 6.368    Value Loss: 4.810    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 668262     Buffer Size: 15761      Transition Number: 1000.557k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:51:39,968][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 7.085    Value Loss: 4.586    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 670295     Buffer Size: 15749      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:54:24,970][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 7.010    Value Loss: 5.399    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 672246     Buffer Size: 15776      Transition Number: 999.988 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:57:15,233][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 6.855    Value Loss: 4.687    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 674288     Buffer Size: 15783      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:00:02,618][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 6.951    Value Loss: 4.873    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 676296     Buffer Size: 15764      Transition Number: 999.989 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:02:49,655][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 7.151    Value Loss: 4.863    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 678376     Buffer Size: 15757      Transition Number: 1000.040k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:05:34,670][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.395    [weighted Loss:3.395    Policy Loss: 6.916    Value Loss: 5.314    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 680356     Buffer Size: 15747      Transition Number: 1000.102k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:08:24,694][train][INFO][train.py>_log] ==> #331000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 6.549    Value Loss: 4.668    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 682397     Buffer Size: 15707      Transition Number: 999.979 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:11:13,573][train][INFO][train.py>_log] ==> #332000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 6.763    Value Loss: 4.842    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 684463     Buffer Size: 15670      Transition Number: 999.975 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:14:01,118][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 6.618    Value Loss: 4.851    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 686458     Buffer Size: 15628      Transition Number: 1000.215k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:16:51,466][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 7.034    Value Loss: 4.650    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 688441     Buffer Size: 15591      Transition Number: 1000.133k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:19:40,208][train][INFO][train.py>_log] ==> #335000     Total Loss: 3.698    [weighted Loss:3.698    Policy Loss: 7.084    Value Loss: 4.754    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 690479     Buffer Size: 15577      Transition Number: 999.981 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:22:31,065][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 7.098    Value Loss: 4.698    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 692525     Buffer Size: 15578      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:25:22,629][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 7.033    Value Loss: 4.816    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 694560     Buffer Size: 15584      Transition Number: 1000.129k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:28:08,798][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 6.559    Value Loss: 4.782    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 696541     Buffer Size: 15579      Transition Number: 1000.211k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:30:57,819][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 6.810    Value Loss: 4.711    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 698590     Buffer Size: 15549      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:33:47,221][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 6.601    Value Loss: 4.600    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 700562     Buffer Size: 15521      Transition Number: 1000.057k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:36:36,781][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 7.274    Value Loss: 4.789    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 702594     Buffer Size: 15504      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:39:25,130][train][INFO][train.py>_log] ==> #342000     Total Loss: 3.735    [weighted Loss:3.735    Policy Loss: 7.054    Value Loss: 5.286    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 704594     Buffer Size: 15479      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:42:16,397][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 7.062    Value Loss: 4.911    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 706707     Buffer Size: 15467      Transition Number: 1000.118k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:45:03,271][train][INFO][train.py>_log] ==> #344000     Total Loss: 3.879    [weighted Loss:3.879    Policy Loss: 6.963    Value Loss: 4.839    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 708739     Buffer Size: 15466      Transition Number: 1000.041k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:47:51,614][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.369    [weighted Loss:3.369    Policy Loss: 7.083    Value Loss: 4.695    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 710790     Buffer Size: 15438      Transition Number: 999.982 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:50:41,964][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 7.275    Value Loss: 4.543    Reward Loss: 1.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 712843     Buffer Size: 15442      Transition Number: 1000.462k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:53:29,826][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 7.171    Value Loss: 4.662    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 714868     Buffer Size: 15444      Transition Number: 1000.069k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:56:20,232][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 7.033    Value Loss: 5.157    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 716915     Buffer Size: 15447      Transition Number: 999.957 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:59:09,711][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 7.082    Value Loss: 4.552    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 718922     Buffer Size: 15442      Transition Number: 999.949 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:01:57,081][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.367    Value Loss: 4.457    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 721000     Buffer Size: 15448      Transition Number: 1000.265k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:04:46,310][train][INFO][train.py>_log] ==> #351000     Total Loss: 2.753    [weighted Loss:2.753    Policy Loss: 6.983    Value Loss: 4.720    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 723079     Buffer Size: 15449      Transition Number: 1000.186k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:07:34,437][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 7.047    Value Loss: 4.581    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 725174     Buffer Size: 15462      Transition Number: 1000.119k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:10:23,911][train][INFO][train.py>_log] ==> #353000     Total Loss: 3.452    [weighted Loss:3.452    Policy Loss: 7.636    Value Loss: 4.650    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 727233     Buffer Size: 15489      Transition Number: 1000.136k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:13:12,115][train][INFO][train.py>_log] ==> #354000     Total Loss: 3.533    [weighted Loss:3.533    Policy Loss: 7.200    Value Loss: 4.893    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 729345     Buffer Size: 15491      Transition Number: 1000.081k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:16:00,685][train][INFO][train.py>_log] ==> #355000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 7.735    Value Loss: 4.936    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 731353     Buffer Size: 15514      Transition Number: 1000.398k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:18:49,524][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.349    [weighted Loss:1.349    Policy Loss: 7.642    Value Loss: 4.900    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 733378     Buffer Size: 15545      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:21:40,425][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.809    [weighted Loss:3.809    Policy Loss: 7.191    Value Loss: 4.780    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 735488     Buffer Size: 15567      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:24:31,600][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 7.208    Value Loss: 4.379    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 737577     Buffer Size: 15593      Transition Number: 999.986 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:27:21,481][train][INFO][train.py>_log] ==> #359000     Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 7.048    Value Loss: 5.067    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 739738     Buffer Size: 15601      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:30:10,729][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 7.074    Value Loss: 4.466    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 741862     Buffer Size: 15601      Transition Number: 999.971 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:33:00,085][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 7.018    Value Loss: 4.691    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 743929     Buffer Size: 15692      Transition Number: 999.948 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:35:46,113][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 7.132    Value Loss: 5.258    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 746011     Buffer Size: 15796      Transition Number: 1000.065k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:38:36,721][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 6.583    Value Loss: 5.000    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 748152     Buffer Size: 15846      Transition Number: 999.961 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:41:25,003][train][INFO][train.py>_log] ==> #364000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 6.794    Value Loss: 5.111    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 750198     Buffer Size: 15892      Transition Number: 1000.082k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:44:12,641][train][INFO][train.py>_log] ==> #365000     Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 6.929    Value Loss: 5.093    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 752288     Buffer Size: 15917      Transition Number: 1000.054k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:46:59,314][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.024    [weighted Loss:1.024    Policy Loss: 6.224    Value Loss: 4.722    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 754345     Buffer Size: 15925      Transition Number: 999.980 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:49:49,159][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.053    [weighted Loss:2.053    Policy Loss: 6.488    Value Loss: 4.692    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 756442     Buffer Size: 15984      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:52:39,160][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 6.919    Value Loss: 4.935    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 758564     Buffer Size: 16040      Transition Number: 1000.353k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:55:30,397][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 6.605    Value Loss: 4.958    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 760665     Buffer Size: 15983      Transition Number: 1000.107k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:58:22,855][train][INFO][train.py>_log] ==> #370000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.637    Value Loss: 5.000    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 762813     Buffer Size: 15924      Transition Number: 1000.220k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:01:15,628][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 6.474    Value Loss: 4.615    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 764915     Buffer Size: 15897      Transition Number: 1000.402k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:04:05,255][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 6.428    Value Loss: 4.521    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 767008     Buffer Size: 15867      Transition Number: 1000.128k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:06:56,861][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 6.528    Value Loss: 4.640    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 769059     Buffer Size: 15868      Transition Number: 1000.304k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:09:47,780][train][INFO][train.py>_log] ==> #374000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 6.500    Value Loss: 5.003    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 771205     Buffer Size: 15872      Transition Number: 999.966 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:12:38,919][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 6.255    Value Loss: 4.751    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 773310     Buffer Size: 15823      Transition Number: 1000.212k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:15:30,427][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 6.390    Value Loss: 4.588    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 775415     Buffer Size: 15758      Transition Number: 1000.084k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:18:20,711][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 6.447    Value Loss: 4.704    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 777522     Buffer Size: 15739      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:21:09,473][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.877    [weighted Loss:2.877    Policy Loss: 6.699    Value Loss: 4.857    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 779558     Buffer Size: 15732      Transition Number: 999.951 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:23:59,320][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 6.602    Value Loss: 4.587    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 781642     Buffer Size: 15708      Transition Number: 1000.169k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:26:48,806][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 6.464    Value Loss: 4.926    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 783695     Buffer Size: 15688      Transition Number: 999.949 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:29:40,096][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 6.100    Value Loss: 4.913    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 785849     Buffer Size: 15689      Transition Number: 1000.001k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:32:31,539][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 6.086    Value Loss: 4.739    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 787888     Buffer Size: 15706      Transition Number: 1000.086k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:35:20,911][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 6.148    Value Loss: 5.049    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 789945     Buffer Size: 15715      Transition Number: 999.942 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:38:09,829][train][INFO][train.py>_log] ==> #384000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 6.599    Value Loss: 4.564    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 792148     Buffer Size: 15745      Transition Number: 1000.121k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:41:01,238][train][INFO][train.py>_log] ==> #385000     Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 5.886    Value Loss: 4.694    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 794301     Buffer Size: 15794      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:43:53,498][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.633    [weighted Loss:1.633    Policy Loss: 6.100    Value Loss: 4.432    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 796456     Buffer Size: 15842      Transition Number: 1000.063k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:46:44,199][train][INFO][train.py>_log] ==> #387000     Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 6.405    Value Loss: 4.842    Reward Loss: 1.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 798545     Buffer Size: 15878      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:49:32,348][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 6.064    Value Loss: 4.458    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 800540     Buffer Size: 15916      Transition Number: 1000.743k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:52:21,439][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 6.250    Value Loss: 4.967    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 802563     Buffer Size: 15908      Transition Number: 1000.087k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:55:09,657][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 6.595    Value Loss: 4.448    Reward Loss: 1.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 804524     Buffer Size: 15914      Transition Number: 1000.306k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:58:00,210][train][INFO][train.py>_log] ==> #391000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 6.665    Value Loss: 4.880    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 806613     Buffer Size: 15917      Transition Number: 1000.151k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:00:47,644][train][INFO][train.py>_log] ==> #392000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 6.833    Value Loss: 4.803    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 808580     Buffer Size: 15909      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:03:39,335][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 6.614    Value Loss: 4.520    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 810783     Buffer Size: 15894      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:06:26,371][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 6.579    Value Loss: 4.460    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 812729     Buffer Size: 15879      Transition Number: 1000.114k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:09:13,942][train][INFO][train.py>_log] ==> #395000     Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 6.251    Value Loss: 4.813    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 814807     Buffer Size: 15872      Transition Number: 999.947 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:12:02,603][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 6.379    Value Loss: 5.053    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 816879     Buffer Size: 15872      Transition Number: 1000.090k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:14:53,818][train][INFO][train.py>_log] ==> #397000     Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 6.454    Value Loss: 4.615    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 818991     Buffer Size: 15871      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:17:43,411][train][INFO][train.py>_log] ==> #398000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 6.512    Value Loss: 4.820    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 821106     Buffer Size: 15875      Transition Number: 1000.006k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:20:33,602][train][INFO][train.py>_log] ==> #399000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 7.007    Value Loss: 4.488    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 823104     Buffer Size: 15890      Transition Number: 1000.235k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:23:34,097][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 6.545    Value Loss: 4.556    Reward Loss: 1.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 825274     Buffer Size: 15906      Transition Number: 1000.144k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:26:24,379][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 6.598    Value Loss: 4.652    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 827483     Buffer Size: 15899      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:29:11,113][train][INFO][train.py>_log] ==> #402000     Total Loss: 3.445    [weighted Loss:3.445    Policy Loss: 6.676    Value Loss: 4.838    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 829481     Buffer Size: 15904      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:32:00,193][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 6.041    Value Loss: 4.840    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 831516     Buffer Size: 15878      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:34:50,888][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 6.333    Value Loss: 4.647    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 833586     Buffer Size: 15855      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:37:43,461][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 6.107    Value Loss: 4.487    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 835722     Buffer Size: 15807      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:40:35,579][train][INFO][train.py>_log] ==> #406000     Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 5.988    Value Loss: 4.832    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 837830     Buffer Size: 15761      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:43:25,752][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 6.144    Value Loss: 4.358    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 839923     Buffer Size: 15703      Transition Number: 1000.325k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:46:15,933][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.311    [weighted Loss:1.311    Policy Loss: 6.066    Value Loss: 4.689    Reward Loss: 1.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 841989     Buffer Size: 15639      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:49:12,732][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 6.129    Value Loss: 4.125    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 844136     Buffer Size: 15575      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:52:01,787][train][INFO][train.py>_log] ==> #410000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 5.930    Value Loss: 4.266    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 846224     Buffer Size: 15533      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:54:54,836][train][INFO][train.py>_log] ==> #411000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 6.339    Value Loss: 4.081    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 848350     Buffer Size: 15483      Transition Number: 1000.168k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:57:44,908][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.085    [weighted Loss:3.085    Policy Loss: 5.982    Value Loss: 4.368    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 850382     Buffer Size: 15446      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:00:35,960][train][INFO][train.py>_log] ==> #413000     Total Loss: 3.144    [weighted Loss:3.144    Policy Loss: 6.141    Value Loss: 4.372    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 852473     Buffer Size: 15403      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:03:26,263][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 6.254    Value Loss: 4.152    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 854524     Buffer Size: 15368      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:06:19,051][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 6.008    Value Loss: 4.177    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 856582     Buffer Size: 15335      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:09:08,050][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 6.231    Value Loss: 4.127    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 858657     Buffer Size: 15313      Transition Number: 1000.081k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:12:00,174][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 6.213    Value Loss: 4.177    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 860815     Buffer Size: 15301      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:14:48,135][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.955    [weighted Loss:2.955    Policy Loss: 6.224    Value Loss: 4.176    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 862857     Buffer Size: 15296      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:17:38,398][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 6.402    Value Loss: 4.186    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 864965     Buffer Size: 15284      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:20:30,214][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 5.973    Value Loss: 4.138    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 867064     Buffer Size: 15278      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:23:20,558][train][INFO][train.py>_log] ==> #421000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 6.414    Value Loss: 4.270    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 869180     Buffer Size: 15268      Transition Number: 1000.236k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:26:09,560][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 6.534    Value Loss: 4.298    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 871290     Buffer Size: 15252      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:29:02,921][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 6.532    Value Loss: 4.180    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 873424     Buffer Size: 15230      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:31:55,184][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 5.916    Value Loss: 4.493    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 875493     Buffer Size: 15207      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:34:48,615][train][INFO][train.py>_log] ==> #425000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 6.220    Value Loss: 4.042    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 877663     Buffer Size: 15193      Transition Number: 1000.381k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:37:38,158][train][INFO][train.py>_log] ==> #426000     Total Loss: 2.358    [weighted Loss:2.358    Policy Loss: 6.450    Value Loss: 4.217    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 879718     Buffer Size: 15159      Transition Number: 1000.125k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:40:29,098][train][INFO][train.py>_log] ==> #427000     Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 6.076    Value Loss: 4.279    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 881850     Buffer Size: 15140      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:43:19,867][train][INFO][train.py>_log] ==> #428000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 6.514    Value Loss: 3.889    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 883983     Buffer Size: 15126      Transition Number: 1000.307k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:46:12,039][train][INFO][train.py>_log] ==> #429000     Total Loss: 3.358    [weighted Loss:3.358    Policy Loss: 6.443    Value Loss: 4.372    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 886104     Buffer Size: 15112      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:49:03,506][train][INFO][train.py>_log] ==> #430000     Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 6.246    Value Loss: 4.108    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 888184     Buffer Size: 15113      Transition Number: 1000.230k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:51:52,346][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 6.824    Value Loss: 4.225    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 890276     Buffer Size: 15117      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:54:43,537][train][INFO][train.py>_log] ==> #432000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 6.497    Value Loss: 4.142    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 892376     Buffer Size: 15126      Transition Number: 999.932 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:57:36,391][train][INFO][train.py>_log] ==> #433000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 6.803    Value Loss: 4.323    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 894541     Buffer Size: 15144      Transition Number: 1000.398k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:00:26,615][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 6.715    Value Loss: 4.486    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 896666     Buffer Size: 15155      Transition Number: 1000.719k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:03:19,072][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 6.728    Value Loss: 4.313    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 898759     Buffer Size: 15149      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:06:11,027][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 6.721    Value Loss: 4.253    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 900946     Buffer Size: 15159      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:08:59,836][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 6.657    Value Loss: 4.443    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 903080     Buffer Size: 15177      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:11:52,771][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 6.809    Value Loss: 4.184    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 905237     Buffer Size: 15175      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:14:42,917][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 6.634    Value Loss: 4.251    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 907345     Buffer Size: 15185      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:17:36,656][train][INFO][train.py>_log] ==> #440000     Total Loss: 3.406    [weighted Loss:3.406    Policy Loss: 6.958    Value Loss: 4.176    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 909612     Buffer Size: 15196      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:20:29,570][train][INFO][train.py>_log] ==> #441000     Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 6.808    Value Loss: 4.228    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 911713     Buffer Size: 15218      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:23:25,384][train][INFO][train.py>_log] ==> #442000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 6.176    Value Loss: 4.240    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 913969     Buffer Size: 15237      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:26:14,893][train][INFO][train.py>_log] ==> #443000     Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 6.544    Value Loss: 4.119    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 916068     Buffer Size: 15256      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:29:07,530][train][INFO][train.py>_log] ==> #444000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.501    Value Loss: 3.910    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 918230     Buffer Size: 15261      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:31:57,710][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 6.876    Value Loss: 4.038    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 920319     Buffer Size: 15288      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:34:50,774][train][INFO][train.py>_log] ==> #446000     Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 6.399    Value Loss: 4.754    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 922494     Buffer Size: 15311      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:37:46,100][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 6.536    Value Loss: 4.553    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 924616     Buffer Size: 15334      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:40:37,766][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 6.615    Value Loss: 4.430    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 926803     Buffer Size: 15359      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:43:30,767][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 6.690    Value Loss: 4.395    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 928903     Buffer Size: 15372      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:46:22,074][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 6.177    Value Loss: 4.269    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 931115     Buffer Size: 15395      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:49:11,300][train][INFO][train.py>_log] ==> #451000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 6.634    Value Loss: 4.290    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 933176     Buffer Size: 15413      Transition Number: 1000.165k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:52:06,263][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 6.582    Value Loss: 4.366    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 935405     Buffer Size: 15426      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:54:56,558][train][INFO][train.py>_log] ==> #453000     Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 6.522    Value Loss: 4.239    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 937496     Buffer Size: 15435      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:57:47,825][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 6.882    Value Loss: 4.381    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 939625     Buffer Size: 15442      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:00:41,546][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.938    [weighted Loss:2.938    Policy Loss: 6.661    Value Loss: 4.240    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 941826     Buffer Size: 15436      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:03:36,468][train][INFO][train.py>_log] ==> #456000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 6.391    Value Loss: 4.234    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 944058     Buffer Size: 15432      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:06:27,281][train][INFO][train.py>_log] ==> #457000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 6.644    Value Loss: 4.629    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 946160     Buffer Size: 15421      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:09:19,697][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.934    [weighted Loss:1.934    Policy Loss: 6.358    Value Loss: 4.271    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 948380     Buffer Size: 15430      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:12:11,841][train][INFO][train.py>_log] ==> #459000     Total Loss: 3.343    [weighted Loss:3.343    Policy Loss: 6.275    Value Loss: 4.266    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 950520     Buffer Size: 15425      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:15:05,889][train][INFO][train.py>_log] ==> #460000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 6.684    Value Loss: 4.153    Reward Loss: 1.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 952679     Buffer Size: 15430      Transition Number: 1000.252k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:17:55,179][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 6.615    Value Loss: 4.218    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 954776     Buffer Size: 15435      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:20:48,334][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.711    Value Loss: 4.329    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 956920     Buffer Size: 15455      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:23:42,414][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 6.655    Value Loss: 4.450    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 959108     Buffer Size: 15482      Transition Number: 1000.558k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:26:34,708][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 6.613    Value Loss: 4.044    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 961285     Buffer Size: 15497      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:29:26,362][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 6.770    Value Loss: 4.563    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 963453     Buffer Size: 15516      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:32:19,339][train][INFO][train.py>_log] ==> #466000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 6.590    Value Loss: 4.242    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 965573     Buffer Size: 15538      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:35:13,314][train][INFO][train.py>_log] ==> #467000     Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 6.866    Value Loss: 4.412    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 967780     Buffer Size: 15561      Transition Number: 1000.428k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:38:05,907][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 6.983    Value Loss: 4.235    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 969899     Buffer Size: 15576      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:41:00,491][train][INFO][train.py>_log] ==> #469000     Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 6.990    Value Loss: 4.518    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 972051     Buffer Size: 15577      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:43:55,336][train][INFO][train.py>_log] ==> #470000     Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 6.628    Value Loss: 4.256    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 974282     Buffer Size: 15589      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:46:45,057][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 6.969    Value Loss: 4.249    Reward Loss: 1.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 976337     Buffer Size: 15597      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:49:37,912][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 6.522    Value Loss: 4.569    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 978483     Buffer Size: 15604      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:52:28,643][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.942    [weighted Loss:2.942    Policy Loss: 6.607    Value Loss: 4.278    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 980702     Buffer Size: 15615      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:55:21,600][train][INFO][train.py>_log] ==> #474000     Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 6.455    Value Loss: 4.608    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 982818     Buffer Size: 15623      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:58:14,604][train][INFO][train.py>_log] ==> #475000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 6.487    Value Loss: 4.272    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 984962     Buffer Size: 15644      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:01:05,455][train][INFO][train.py>_log] ==> #476000     Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 6.385    Value Loss: 4.339    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 987144     Buffer Size: 15668      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:03:58,607][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 6.829    Value Loss: 4.164    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 989296     Buffer Size: 15695      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:06:49,318][train][INFO][train.py>_log] ==> #478000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 6.997    Value Loss: 4.272    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 991416     Buffer Size: 15711      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:09:40,261][train][INFO][train.py>_log] ==> #479000     Total Loss: 3.253    [weighted Loss:3.253    Policy Loss: 7.339    Value Loss: 4.551    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 993584     Buffer Size: 15725      Transition Number: 1000.079k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:12:33,945][train][INFO][train.py>_log] ==> #480000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 6.658    Value Loss: 4.414    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 995770     Buffer Size: 15754      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:15:27,681][train][INFO][train.py>_log] ==> #481000     Total Loss: 3.696    [weighted Loss:3.696    Policy Loss: 6.897    Value Loss: 4.396    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 997903     Buffer Size: 15775      Transition Number: 1000.164k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:18:18,352][train][INFO][train.py>_log] ==> #482000     Total Loss: 0.966    [weighted Loss:0.966    Policy Loss: 7.035    Value Loss: 4.396    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000026    Buffer Size: 15762      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:21:11,522][train][INFO][train.py>_log] ==> #483000     Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 6.944    Value Loss: 4.572    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002194    Buffer Size: 15772      Transition Number: 1000.298k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:24:05,185][train][INFO][train.py>_log] ==> #484000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 7.128    Value Loss: 4.861    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1004365    Buffer Size: 15779      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:26:59,675][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 7.281    Value Loss: 4.519    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1006613    Buffer Size: 15782      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:29:53,328][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 6.689    Value Loss: 4.786    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1008771    Buffer Size: 15800      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:32:46,219][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 7.190    Value Loss: 4.710    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1010953    Buffer Size: 15789      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:35:41,559][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 6.609    Value Loss: 4.393    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013152    Buffer Size: 15776      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:38:37,096][train][INFO][train.py>_log] ==> #489000     Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 6.456    Value Loss: 4.680    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 1015373    Buffer Size: 15789      Transition Number: 1000.315k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:41:30,705][train][INFO][train.py>_log] ==> #490000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 6.670    Value Loss: 4.664    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1017563    Buffer Size: 15794      Transition Number: 1000.362k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:44:24,486][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.154    [weighted Loss:2.154    Policy Loss: 6.661    Value Loss: 4.376    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 1019682    Buffer Size: 15790      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:47:18,696][train][INFO][train.py>_log] ==> #492000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.738    Value Loss: 4.145    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1021884    Buffer Size: 15806      Transition Number: 1000.260k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:50:12,341][train][INFO][train.py>_log] ==> #493000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 6.609    Value Loss: 4.285    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1024029    Buffer Size: 15815      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:53:07,524][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 6.882    Value Loss: 4.306    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1026218    Buffer Size: 15842      Transition Number: 1000.412k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:56:00,526][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 6.293    Value Loss: 4.386    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1028434    Buffer Size: 15864      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:58:55,331][train][INFO][train.py>_log] ==> #496000     Total Loss: 1.913    [weighted Loss:1.913    Policy Loss: 6.760    Value Loss: 4.327    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030665    Buffer Size: 15901      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:01:51,317][train][INFO][train.py>_log] ==> #497000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 6.577    Value Loss: 4.452    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032909    Buffer Size: 15917      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:04:47,787][train][INFO][train.py>_log] ==> #498000     Total Loss: 3.169    [weighted Loss:3.169    Policy Loss: 7.106    Value Loss: 4.267    Reward Loss: 1.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035200    Buffer Size: 15932      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:07:42,485][train][INFO][train.py>_log] ==> #499000     Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 6.421    Value Loss: 4.349    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1037332    Buffer Size: 15927      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:10:35,551][train][INFO][train.py>_log] ==> #500000     Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 6.894    Value Loss: 4.291    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1039551    Buffer Size: 15924      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:13:30,212][train][INFO][train.py>_log] ==> #501000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.715    Value Loss: 4.710    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1041766    Buffer Size: 15918      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:16:23,072][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 6.586    Value Loss: 4.292    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043929    Buffer Size: 15925      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:19:19,718][train][INFO][train.py>_log] ==> #503000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 6.633    Value Loss: 4.254    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1046164    Buffer Size: 15920      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:22:11,444][train][INFO][train.py>_log] ==> #504000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 6.465    Value Loss: 4.628    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048336    Buffer Size: 15925      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:25:05,607][train][INFO][train.py>_log] ==> #505000     Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 6.541    Value Loss: 4.130    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1050520    Buffer Size: 15925      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:28:00,429][train][INFO][train.py>_log] ==> #506000     Total Loss: 1.161    [weighted Loss:1.161    Policy Loss: 6.955    Value Loss: 4.237    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1052681    Buffer Size: 15922      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:30:53,126][train][INFO][train.py>_log] ==> #507000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 6.769    Value Loss: 4.329    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1054828    Buffer Size: 15907      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:33:45,611][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 6.945    Value Loss: 4.219    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 1056986    Buffer Size: 15912      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:36:39,830][train][INFO][train.py>_log] ==> #509000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 6.839    Value Loss: 4.611    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1059141    Buffer Size: 15910      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:39:29,914][train][INFO][train.py>_log] ==> #510000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.913    Value Loss: 4.453    Reward Loss: 1.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 1061280    Buffer Size: 15885      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:42:25,190][train][INFO][train.py>_log] ==> #511000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 7.187    Value Loss: 4.475    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063475    Buffer Size: 15866      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:45:17,443][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 6.933    Value Loss: 4.653    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 1065622    Buffer Size: 15852      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:48:09,790][train][INFO][train.py>_log] ==> #513000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 7.333    Value Loss: 4.801    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1067819    Buffer Size: 15842      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:51:02,181][train][INFO][train.py>_log] ==> #514000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 7.259    Value Loss: 4.211    Reward Loss: 1.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069979    Buffer Size: 15837      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:53:56,162][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 7.533    Value Loss: 4.495    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1072105    Buffer Size: 15823      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:56:51,699][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 7.478    Value Loss: 4.193    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1074313    Buffer Size: 15820      Transition Number: 1000.493k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:59:49,285][train][INFO][train.py>_log] ==> #517000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 7.419    Value Loss: 4.449    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076549    Buffer Size: 15817      Transition Number: 1000.272k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:02:41,037][train][INFO][train.py>_log] ==> #518000     Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 7.833    Value Loss: 4.367    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1078602    Buffer Size: 15815      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:05:33,360][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 7.587    Value Loss: 4.576    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1080743    Buffer Size: 15830      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:08:27,744][train][INFO][train.py>_log] ==> #520000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 7.927    Value Loss: 4.312    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1082959    Buffer Size: 15842      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:11:22,331][train][INFO][train.py>_log] ==> #521000     Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 7.710    Value Loss: 4.306    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1085148    Buffer Size: 15861      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:14:15,808][train][INFO][train.py>_log] ==> #522000     Total Loss: 3.263    [weighted Loss:3.263    Policy Loss: 8.325    Value Loss: 4.439    Reward Loss: 1.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 1087271    Buffer Size: 15891      Transition Number: 1000.501k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:17:08,427][train][INFO][train.py>_log] ==> #523000     Total Loss: 3.969    [weighted Loss:3.969    Policy Loss: 8.224    Value Loss: 4.371    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089410    Buffer Size: 15891      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:20:01,524][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.125    [weighted Loss:2.125    Policy Loss: 8.170    Value Loss: 4.705    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1091616    Buffer Size: 15910      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:22:55,516][train][INFO][train.py>_log] ==> #525000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 7.949    Value Loss: 4.564    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1093726    Buffer Size: 15899      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:25:51,520][train][INFO][train.py>_log] ==> #526000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 7.530    Value Loss: 4.523    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1095977    Buffer Size: 15895      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:28:46,483][train][INFO][train.py>_log] ==> #527000     Total Loss: 3.600    [weighted Loss:3.600    Policy Loss: 7.521    Value Loss: 4.666    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098116    Buffer Size: 15919      Transition Number: 1000.202k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:31:38,995][train][INFO][train.py>_log] ==> #528000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 7.768    Value Loss: 4.633    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100264    Buffer Size: 15909      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:34:33,485][train][INFO][train.py>_log] ==> #529000     Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 7.719    Value Loss: 4.696    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1102461    Buffer Size: 15920      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:37:27,796][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 7.853    Value Loss: 4.311    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 1104626    Buffer Size: 15946      Transition Number: 1000.144k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:40:23,390][train][INFO][train.py>_log] ==> #531000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 8.042    Value Loss: 4.211    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1106802    Buffer Size: 15956      Transition Number: 1000.077k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:43:17,499][train][INFO][train.py>_log] ==> #532000     Total Loss: 2.723    [weighted Loss:2.723    Policy Loss: 8.112    Value Loss: 4.316    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1109008    Buffer Size: 15981      Transition Number: 1000.118k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:46:13,213][train][INFO][train.py>_log] ==> #533000     Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 7.749    Value Loss: 4.440    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111176    Buffer Size: 15999      Transition Number: 1000.299k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:49:09,129][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 8.022    Value Loss: 4.988    Reward Loss: 1.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113410    Buffer Size: 15988      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:52:03,206][train][INFO][train.py>_log] ==> #535000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 7.888    Value Loss: 4.475    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1115624    Buffer Size: 16002      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:54:57,232][train][INFO][train.py>_log] ==> #536000     Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 7.886    Value Loss: 4.523    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117795    Buffer Size: 15998      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:57:53,915][train][INFO][train.py>_log] ==> #537000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 7.611    Value Loss: 4.595    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1120037    Buffer Size: 15982      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:00:47,022][train][INFO][train.py>_log] ==> #538000     Total Loss: 0.964    [weighted Loss:0.964    Policy Loss: 7.670    Value Loss: 4.522    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1122183    Buffer Size: 15980      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:03:41,479][train][INFO][train.py>_log] ==> #539000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 7.882    Value Loss: 4.351    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1124320    Buffer Size: 15954      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:06:37,442][train][INFO][train.py>_log] ==> #540000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 7.975    Value Loss: 4.337    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126535    Buffer Size: 15948      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:09:33,947][train][INFO][train.py>_log] ==> #541000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 7.842    Value Loss: 4.551    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128732    Buffer Size: 15932      Transition Number: 1000.294k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:12:29,830][train][INFO][train.py>_log] ==> #542000     Total Loss: 0.994    [weighted Loss:0.994    Policy Loss: 7.544    Value Loss: 4.446    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1130956    Buffer Size: 15899      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:15:24,932][train][INFO][train.py>_log] ==> #543000     Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 7.513    Value Loss: 4.440    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133216    Buffer Size: 15883      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:18:18,077][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 7.404    Value Loss: 4.660    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135327    Buffer Size: 15877      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:21:12,113][train][INFO][train.py>_log] ==> #545000     Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 7.754    Value Loss: 4.553    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1137565    Buffer Size: 15871      Transition Number: 1000.335k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:24:08,283][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 7.160    Value Loss: 4.473    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139777    Buffer Size: 15872      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:27:03,987][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 7.345    Value Loss: 4.444    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1141974    Buffer Size: 15883      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:29:59,237][train][INFO][train.py>_log] ==> #548000     Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 7.306    Value Loss: 4.424    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144211    Buffer Size: 15909      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:32:54,299][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 7.285    Value Loss: 4.983    Reward Loss: 1.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 1146421    Buffer Size: 15937      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:35:51,345][train][INFO][train.py>_log] ==> #550000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 7.390    Value Loss: 4.321    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 1148650    Buffer Size: 15967      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:38:45,375][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 7.710    Value Loss: 4.218    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1150832    Buffer Size: 15984      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:41:36,040][train][INFO][train.py>_log] ==> #552000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 7.745    Value Loss: 4.260    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152948    Buffer Size: 15998      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:44:27,566][train][INFO][train.py>_log] ==> #553000     Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 7.578    Value Loss: 4.374    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1155075    Buffer Size: 16006      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:47:25,064][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 8.102    Value Loss: 4.646    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 1157291    Buffer Size: 16001      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:50:16,936][train][INFO][train.py>_log] ==> #555000     Total Loss: 2.336    [weighted Loss:2.336    Policy Loss: 7.973    Value Loss: 4.353    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1159451    Buffer Size: 15991      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:53:10,084][train][INFO][train.py>_log] ==> #556000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 7.878    Value Loss: 4.645    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1161660    Buffer Size: 15984      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:56:05,781][train][INFO][train.py>_log] ==> #557000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 8.116    Value Loss: 4.275    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1163876    Buffer Size: 15963      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:58:57,954][train][INFO][train.py>_log] ==> #558000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 7.782    Value Loss: 4.605    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 1166022    Buffer Size: 15961      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00400 
