[2022-02-19 09:09:36,446][train][INFO][train.py>_log] ==> #0          Total Loss: 46.982   [weighted Loss:46.982   Policy Loss: 12.510   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1161       Buffer Size: 1161       Transition Number: 11.562  k Batch Size: 256        Lr: 0.00000 
[2022-02-19 09:12:19,437][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.060    [weighted Loss:6.060    Policy Loss: 14.402   Value Loss: 4.930    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 11681      Buffer Size: 11681      Transition Number: 145.307 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:14:55,763][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.003    [weighted Loss:7.003    Policy Loss: 13.709   Value Loss: 4.313    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 21480      Buffer Size: 21480      Transition Number: 267.819 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:17:33,033][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.862    [weighted Loss:5.862    Policy Loss: 13.191   Value Loss: 4.729    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 28924      Buffer Size: 28924      Transition Number: 383.657 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:20:14,838][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.034    [weighted Loss:6.034    Policy Loss: 10.748   Value Loss: 4.156    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 36533      Buffer Size: 36533      Transition Number: 505.113 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:22:51,292][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 9.161    Value Loss: 4.035    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 41805      Buffer Size: 41805      Transition Number: 619.551 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:25:28,111][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.941    [weighted Loss:3.941    Policy Loss: 6.669    Value Loss: 4.428    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 47141      Buffer Size: 47141      Transition Number: 728.814 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:28:09,500][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 6.617    Value Loss: 4.424    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 50713      Buffer Size: 50713      Transition Number: 826.481 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:30:46,258][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 4.421    Value Loss: 4.078    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 54327      Buffer Size: 54327      Transition Number: 936.928 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:33:23,697][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 3.359    Value Loss: 4.286    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 57379      Buffer Size: 53518      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:36:04,083][train][INFO][train.py>_log] ==> #10000      Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 2.884    Value Loss: 4.010    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 60510      Buffer Size: 48126      Transition Number: 1000.245k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:38:46,590][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 3.074    Value Loss: 3.854    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 63016      Buffer Size: 42487      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:41:29,142][train][INFO][train.py>_log] ==> #12000      Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 3.327    Value Loss: 4.160    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 65591      Buffer Size: 37551      Transition Number: 1000.150k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:44:12,537][train][INFO][train.py>_log] ==> #13000      Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 3.003    Value Loss: 4.073    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 67577      Buffer Size: 32687      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:46:51,145][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.643    [weighted Loss:1.643    Policy Loss: 3.067    Value Loss: 4.267    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 69434      Buffer Size: 28873      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:49:30,929][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 3.411    Value Loss: 3.898    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 71491      Buffer Size: 25350      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:52:11,723][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 3.406    Value Loss: 4.476    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 73391      Buffer Size: 23237      Transition Number: 1000.296k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:54:49,599][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 3.716    Value Loss: 4.409    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 75378      Buffer Size: 21804      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:57:29,731][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 3.303    Value Loss: 4.400    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 77327      Buffer Size: 20438      Transition Number: 1000.024k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:00:10,682][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 3.437    Value Loss: 4.697    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 79324      Buffer Size: 19138      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:02:53,063][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 3.396    Value Loss: 4.552    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 81277      Buffer Size: 18451      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:05:31,540][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.150    [weighted Loss:1.150    Policy Loss: 3.568    Value Loss: 4.628    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 83293      Buffer Size: 17871      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:08:11,518][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 3.813    Value Loss: 4.447    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 85228      Buffer Size: 17921      Transition Number: 1000.028k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:10:50,954][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 3.784    Value Loss: 4.641    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 87256      Buffer Size: 18107      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:13:29,697][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 3.955    Value Loss: 4.479    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 89283      Buffer Size: 18133      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:16:11,313][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 4.629    Value Loss: 4.793    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 91245      Buffer Size: 18154      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:18:47,939][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.328    [weighted Loss:1.328    Policy Loss: 4.659    Value Loss: 4.524    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 93201      Buffer Size: 18137      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:21:25,022][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 4.747    Value Loss: 5.072    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 95495      Buffer Size: 18622      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:24:06,979][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 4.860    Value Loss: 4.921    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 97792      Buffer Size: 18910      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:26:42,932][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 4.463    Value Loss: 4.870    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 99938      Buffer Size: 19123      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:29:20,609][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 3.754    Value Loss: 4.990    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 102122     Buffer Size: 19266      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:31:59,179][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.199    [weighted Loss:2.199    Policy Loss: 3.652    Value Loss: 5.200    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 103888     Buffer Size: 19297      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:34:39,722][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 3.587    Value Loss: 4.683    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 105815     Buffer Size: 19183      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:37:14,996][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 3.702    Value Loss: 5.439    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 107893     Buffer Size: 19105      Transition Number: 1000.270k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:39:54,413][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.764    [weighted Loss:1.764    Policy Loss: 3.775    Value Loss: 5.272    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 109801     Buffer Size: 19105      Transition Number: 1000.340k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:42:33,315][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 4.269    Value Loss: 5.492    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 111726     Buffer Size: 19033      Transition Number: 1000.158k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:45:11,793][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 3.776    Value Loss: 5.679    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 113613     Buffer Size: 18868      Transition Number: 1000.354k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:47:53,547][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.445    [weighted Loss:1.445    Policy Loss: 3.560    Value Loss: 4.941    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 115601     Buffer Size: 18384      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:50:29,921][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 4.300    Value Loss: 5.729    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 117507     Buffer Size: 18091      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:53:07,705][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 4.572    Value Loss: 5.509    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 119262     Buffer Size: 17774      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:55:49,104][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.153    [weighted Loss:2.153    Policy Loss: 4.632    Value Loss: 5.385    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 121119     Buffer Size: 17627      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:58:25,670][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 4.695    Value Loss: 5.147    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 122824     Buffer Size: 17450      Transition Number: 1000.132k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:01:05,273][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 5.163    Value Loss: 5.528    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 124612     Buffer Size: 17169      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:03:43,858][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 6.045    Value Loss: 5.342    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 126323     Buffer Size: 16849      Transition Number: 1000.426k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:06:24,824][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 5.956    Value Loss: 4.897    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 127985     Buffer Size: 16508      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:09:03,344][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.086    [weighted Loss:3.086    Policy Loss: 6.890    Value Loss: 5.057    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 129750     Buffer Size: 16128      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:11:44,219][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.570    [weighted Loss:4.570    Policy Loss: 7.755    Value Loss: 4.959    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 131463     Buffer Size: 15891      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:14:23,322][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 7.173    Value Loss: 5.158    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 133306     Buffer Size: 15578      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:17:02,261][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 6.912    Value Loss: 4.792    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 135005     Buffer Size: 15333      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:19:45,430][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.105    Value Loss: 4.908    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 136761     Buffer Size: 15112      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:22:24,194][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 7.613    Value Loss: 4.582    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 138620     Buffer Size: 14989      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:25:02,234][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 7.970    Value Loss: 4.641    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 140322     Buffer Size: 14978      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:27:43,680][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.854    [weighted Loss:3.854    Policy Loss: 7.468    Value Loss: 4.316    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 142221     Buffer Size: 15004      Transition Number: 1000.330k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:30:21,397][train][INFO][train.py>_log] ==> #53000      Total Loss: 4.678    [weighted Loss:4.678    Policy Loss: 7.932    Value Loss: 4.480    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 144011     Buffer Size: 15007      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:33:00,441][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.258    [weighted Loss:3.258    Policy Loss: 8.444    Value Loss: 4.669    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 145836     Buffer Size: 14969      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:35:39,768][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 8.170    Value Loss: 4.561    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 147692     Buffer Size: 14981      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:38:20,760][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 7.099    Value Loss: 5.075    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 149573     Buffer Size: 15043      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:40:59,598][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 7.424    Value Loss: 4.645    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 151335     Buffer Size: 15060      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:43:42,599][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 6.518    Value Loss: 4.763    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 153257     Buffer Size: 15066      Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:46:22,152][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 7.030    Value Loss: 4.468    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 155057     Buffer Size: 15028      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:49:01,803][train][INFO][train.py>_log] ==> #60000      Total Loss: 4.625    [weighted Loss:4.625    Policy Loss: 7.590    Value Loss: 4.472    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 156995     Buffer Size: 14963      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:51:45,782][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 7.835    Value Loss: 4.784    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 158868     Buffer Size: 14933      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:54:25,686][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.242    [weighted Loss:4.242    Policy Loss: 6.915    Value Loss: 4.582    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 160763     Buffer Size: 14926      Transition Number: 1000.252k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:57:03,894][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.335    [weighted Loss:4.335    Policy Loss: 7.939    Value Loss: 4.491    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 162521     Buffer Size: 14887      Transition Number: 1000.301k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:59:43,595][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 7.806    Value Loss: 4.808    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 164283     Buffer Size: 14835      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:02:25,105][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 7.948    Value Loss: 4.370    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 166134     Buffer Size: 14819      Transition Number: 1000.036k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:05:04,207][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 8.002    Value Loss: 4.856    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 167963     Buffer Size: 14823      Transition Number: 1000.164k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:07:47,519][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 7.985    Value Loss: 4.884    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 169752     Buffer Size: 14745      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:10:26,065][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 7.799    Value Loss: 4.821    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 171553     Buffer Size: 14682      Transition Number: 1000.399k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:13:04,496][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 8.012    Value Loss: 4.644    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 173349     Buffer Size: 14599      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:15:46,636][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 7.324    Value Loss: 4.704    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 175127     Buffer Size: 14512      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:18:26,318][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.781    [weighted Loss:3.781    Policy Loss: 7.643    Value Loss: 4.889    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 176923     Buffer Size: 14381      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:21:06,324][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 7.283    Value Loss: 4.751    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 178797     Buffer Size: 14238      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:23:46,662][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.133    [weighted Loss:3.133    Policy Loss: 7.081    Value Loss: 4.639    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 180679     Buffer Size: 14193      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:26:31,220][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 6.823    Value Loss: 4.796    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 182415     Buffer Size: 14133      Transition Number: 1000.182k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:29:10,248][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 7.721    Value Loss: 4.569    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 184207     Buffer Size: 14124      Transition Number: 1000.280k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:31:52,919][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 7.690    Value Loss: 4.474    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 186030     Buffer Size: 14107      Transition Number: 1000.073k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:34:31,937][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.997    [weighted Loss:3.997    Policy Loss: 8.141    Value Loss: 4.988    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 188311     Buffer Size: 14619      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:37:12,454][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.072    [weighted Loss:5.072    Policy Loss: 8.845    Value Loss: 5.474    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 190627     Buffer Size: 15196      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:39:56,021][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.303    [weighted Loss:4.303    Policy Loss: 8.602    Value Loss: 5.368    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 192347     Buffer Size: 15441      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:42:35,871][train][INFO][train.py>_log] ==> #80000      Total Loss: 5.309    [weighted Loss:5.309    Policy Loss: 8.714    Value Loss: 5.575    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 194281     Buffer Size: 15685      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:45:15,760][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.730    [weighted Loss:4.730    Policy Loss: 9.491    Value Loss: 5.621    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 196030     Buffer Size: 15780      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:47:58,440][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 8.551    Value Loss: 5.533    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 197889     Buffer Size: 15868      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:50:39,295][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 8.221    Value Loss: 5.797    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 199586     Buffer Size: 15931      Transition Number: 1000.700k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:53:18,946][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.667    [weighted Loss:3.667    Policy Loss: 8.200    Value Loss: 5.759    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 201384     Buffer Size: 16002      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:56:00,655][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.694    [weighted Loss:3.694    Policy Loss: 8.529    Value Loss: 5.227    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 203195     Buffer Size: 15827      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:58:41,522][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.632    [weighted Loss:4.632    Policy Loss: 8.372    Value Loss: 5.137    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 204945     Buffer Size: 15381      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:01:22,212][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 7.355    Value Loss: 5.023    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 206909     Buffer Size: 15144      Transition Number: 1000.290k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:04:06,255][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.713    Value Loss: 5.009    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 208748     Buffer Size: 15071      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:06:45,232][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.899    [weighted Loss:3.899    Policy Loss: 7.724    Value Loss: 5.183    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 210544     Buffer Size: 15075      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:09:24,596][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 6.983    Value Loss: 5.333    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 212340     Buffer Size: 15129      Transition Number: 999.927 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:12:07,644][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 7.122    Value Loss: 5.197    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 214225     Buffer Size: 15174      Transition Number: 1000.088k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:14:45,785][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.012    [weighted Loss:4.012    Policy Loss: 7.231    Value Loss: 4.840    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 216076     Buffer Size: 15228      Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:17:26,344][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 6.741    Value Loss: 5.105    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 218251     Buffer Size: 15626      Transition Number: 1000.194k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:20:06,383][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 6.931    Value Loss: 5.459    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 220376     Buffer Size: 16003      Transition Number: 1000.256k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:22:46,381][train][INFO][train.py>_log] ==> #95000      Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 7.406    Value Loss: 5.591    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 223879     Buffer Size: 17538      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:25:26,450][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 8.022    Value Loss: 6.171    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 227291     Buffer Size: 19149      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:28:08,754][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.138    [weighted Loss:4.138    Policy Loss: 7.903    Value Loss: 6.222    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 229608     Buffer Size: 19716      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:30:51,163][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.157    [weighted Loss:4.157    Policy Loss: 7.298    Value Loss: 6.335    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 232158     Buffer Size: 20307      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:33:30,261][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 7.813    Value Loss: 5.509    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 233887     Buffer Size: 20402      Transition Number: 1000.165k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:36:13,642][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.230    [weighted Loss:4.230    Policy Loss: 7.466    Value Loss: 6.120    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 235770     Buffer Size: 20441      Transition Number: 1000.285k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:38:54,740][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 7.966    Value Loss: 5.774    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 237673     Buffer Size: 20281      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:41:35,759][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.366    [weighted Loss:3.366    Policy Loss: 7.213    Value Loss: 5.753    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 239539     Buffer Size: 19982      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:44:16,446][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 6.731    Value Loss: 5.566    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 241289     Buffer Size: 19130      Transition Number: 1000.124k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:47:00,606][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 7.157    Value Loss: 5.398    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 243220     Buffer Size: 17496      Transition Number: 1000.227k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:49:39,120][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.767    [weighted Loss:3.767    Policy Loss: 6.938    Value Loss: 5.427    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 244946     Buffer Size: 16407      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:52:22,777][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 6.970    Value Loss: 5.575    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 246844     Buffer Size: 15797      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:55:03,000][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 6.606    Value Loss: 5.234    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 248715     Buffer Size: 15546      Transition Number: 1000.018k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:57:41,424][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 6.942    Value Loss: 5.058    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 250552     Buffer Size: 15551      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:00:23,694][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 6.843    Value Loss: 5.253    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 252425     Buffer Size: 15552      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:03:03,595][train][INFO][train.py>_log] ==> #110000     Total Loss: 4.178    [weighted Loss:4.178    Policy Loss: 7.728    Value Loss: 5.151    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 254222     Buffer Size: 15585      Transition Number: 1000.223k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:05:42,555][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 7.761    Value Loss: 5.418    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 256145     Buffer Size: 15577      Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:08:22,550][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 7.481    Value Loss: 5.220    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 257995     Buffer Size: 15628      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:11:04,765][train][INFO][train.py>_log] ==> #113000     Total Loss: 4.461    [weighted Loss:4.461    Policy Loss: 7.734    Value Loss: 5.339    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 259771     Buffer Size: 15718      Transition Number: 1000.304k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:13:43,642][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 7.239    Value Loss: 4.801    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 261734     Buffer Size: 15760      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:16:25,353][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.969    [weighted Loss:4.969    Policy Loss: 8.769    Value Loss: 4.740    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 263619     Buffer Size: 15829      Transition Number: 1000.427k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:19:03,318][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.345    [weighted Loss:4.345    Policy Loss: 8.191    Value Loss: 4.794    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 265475     Buffer Size: 15884      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:21:44,448][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 8.211    Value Loss: 4.993    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 267386     Buffer Size: 15909      Transition Number: 1000.221k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:24:26,728][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.923    Value Loss: 4.997    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 269219     Buffer Size: 15907      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:27:07,528][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.435    [weighted Loss:4.435    Policy Loss: 8.467    Value Loss: 4.995    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 271086     Buffer Size: 15921      Transition Number: 1000.232k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:29:46,610][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 7.236    Value Loss: 5.197    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 273067     Buffer Size: 15910      Transition Number: 1000.209k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:32:26,254][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.407    [weighted Loss:3.407    Policy Loss: 7.696    Value Loss: 5.079    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 274845     Buffer Size: 15824      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:35:09,133][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.516    [weighted Loss:3.516    Policy Loss: 7.304    Value Loss: 5.146    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 276694     Buffer Size: 15741      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:37:50,383][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 7.178    Value Loss: 5.026    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 278492     Buffer Size: 15646      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:40:33,784][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.476    [weighted Loss:4.476    Policy Loss: 6.990    Value Loss: 5.060    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 280352     Buffer Size: 15520      Transition Number: 1000.190k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:43:13,492][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 7.433    Value Loss: 4.932    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 282249     Buffer Size: 15373      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:45:52,907][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.053    [weighted Loss:4.053    Policy Loss: 6.937    Value Loss: 4.802    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 284025     Buffer Size: 15288      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:48:36,939][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 6.801    Value Loss: 5.156    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 285911     Buffer Size: 15226      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:51:17,388][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 6.604    Value Loss: 4.930    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 287768     Buffer Size: 15131      Transition Number: 1000.539k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:53:56,331][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.846    [weighted Loss:3.846    Policy Loss: 7.313    Value Loss: 4.696    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 289542     Buffer Size: 15061      Transition Number: 1000.182k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:56:38,165][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 6.375    Value Loss: 5.069    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 291419     Buffer Size: 14997      Transition Number: 999.930 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:59:19,543][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 6.516    Value Loss: 4.762    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 293264     Buffer Size: 14937      Transition Number: 1000.330k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:01:59,589][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 6.212    Value Loss: 4.816    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 295052     Buffer Size: 14869      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:04:43,341][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 6.181    Value Loss: 4.436    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 296936     Buffer Size: 14861      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:07:25,099][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 6.531    Value Loss: 5.073    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 298832     Buffer Size: 14833      Transition Number: 1000.176k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:10:06,357][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 6.336    Value Loss: 5.070    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 301278     Buffer Size: 15395      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:12:48,098][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.967    Value Loss: 5.445    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 303579     Buffer Size: 15949      Transition Number: 1000.033k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:15:28,266][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 6.935    Value Loss: 5.611    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 305310     Buffer Size: 16074      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:18:08,768][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.364    [weighted Loss:4.364    Policy Loss: 7.441    Value Loss: 5.208    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 307181     Buffer Size: 16165      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:20:50,979][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 6.799    Value Loss: 5.244    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 309219     Buffer Size: 16210      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:23:33,137][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 6.917    Value Loss: 5.263    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 310994     Buffer Size: 16276      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:26:12,392][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 6.385    Value Loss: 5.402    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 312743     Buffer Size: 16343      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:28:57,836][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 7.018    Value Loss: 5.150    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 314684     Buffer Size: 16415      Transition Number: 1000.117k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:31:38,573][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.553    [weighted Loss:3.553    Policy Loss: 6.364    Value Loss: 5.263    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 316513     Buffer Size: 16161      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:34:20,317][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.894    [weighted Loss:2.894    Policy Loss: 6.679    Value Loss: 4.950    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 318471     Buffer Size: 15582      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:37:04,003][train][INFO][train.py>_log] ==> #145000     Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 6.901    Value Loss: 5.368    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 320236     Buffer Size: 15387      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:39:43,392][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.841    Value Loss: 4.898    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 322090     Buffer Size: 15374      Transition Number: 1000.288k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:42:23,739][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 7.030    Value Loss: 4.984    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 323844     Buffer Size: 15378      Transition Number: 1000.339k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:45:06,034][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.930    Value Loss: 4.892    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 325696     Buffer Size: 15408      Transition Number: 1000.137k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:47:46,819][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 6.854    Value Loss: 5.171    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 327582     Buffer Size: 15464      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:50:28,865][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.752    [weighted Loss:3.752    Policy Loss: 7.182    Value Loss: 5.222    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 329418     Buffer Size: 15503      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:53:12,375][train][INFO][train.py>_log] ==> #151000     Total Loss: 4.071    [weighted Loss:4.071    Policy Loss: 7.033    Value Loss: 4.896    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 331343     Buffer Size: 15537      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:55:52,841][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 7.057    Value Loss: 4.876    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 333051     Buffer Size: 15572      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:58:33,918][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 6.556    Value Loss: 5.080    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 334960     Buffer Size: 15608      Transition Number: 1000.151k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:01:17,135][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 7.342    Value Loss: 5.055    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 336853     Buffer Size: 15700      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:03:55,182][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.685    [weighted Loss:3.685    Policy Loss: 6.172    Value Loss: 5.135    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 338636     Buffer Size: 15757      Transition Number: 1000.157k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:06:35,319][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 6.472    Value Loss: 4.913    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 340437     Buffer Size: 15799      Transition Number: 1000.075k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:09:17,915][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 6.936    Value Loss: 5.083    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 342363     Buffer Size: 15864      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:12:00,808][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 6.466    Value Loss: 5.548    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 344226     Buffer Size: 15924      Transition Number: 1000.199k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:14:42,724][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 5.816    Value Loss: 5.158    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 346072     Buffer Size: 15935      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:17:26,316][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 6.574    Value Loss: 5.119    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 347856     Buffer Size: 15930      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:20:08,413][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 6.152    Value Loss: 4.967    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 349618     Buffer Size: 15902      Transition Number: 1000.087k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:22:49,641][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 6.539    Value Loss: 5.419    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 351460     Buffer Size: 15875      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:25:32,810][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.552    [weighted Loss:3.552    Policy Loss: 6.757    Value Loss: 5.265    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 353335     Buffer Size: 15850      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:28:12,496][train][INFO][train.py>_log] ==> #164000     Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 6.564    Value Loss: 4.900    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 355024     Buffer Size: 15867      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:30:55,439][train][INFO][train.py>_log] ==> #165000     Total Loss: 4.433    [weighted Loss:4.433    Policy Loss: 6.663    Value Loss: 5.226    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 356906     Buffer Size: 15890      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:33:37,645][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.639    [weighted Loss:3.639    Policy Loss: 6.662    Value Loss: 5.233    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 358726     Buffer Size: 15871      Transition Number: 1000.103k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:36:18,668][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 7.122    Value Loss: 5.265    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 360707     Buffer Size: 15976      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:38:59,246][train][INFO][train.py>_log] ==> #168000     Total Loss: 4.541    [weighted Loss:4.541    Policy Loss: 7.179    Value Loss: 5.555    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 362640     Buffer Size: 16131      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:41:42,493][train][INFO][train.py>_log] ==> #169000     Total Loss: 4.152    [weighted Loss:4.152    Policy Loss: 6.437    Value Loss: 5.063    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 364519     Buffer Size: 16246      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:44:23,551][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 7.395    Value Loss: 5.611    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 366422     Buffer Size: 16381      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:47:05,196][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 7.259    Value Loss: 5.494    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 368224     Buffer Size: 16462      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:49:49,741][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 7.071    Value Loss: 5.719    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 370119     Buffer Size: 16512      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:52:30,395][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.195    [weighted Loss:3.195    Policy Loss: 7.497    Value Loss: 5.207    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 372084     Buffer Size: 16673      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:55:12,648][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 7.234    Value Loss: 5.867    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 373994     Buffer Size: 16806      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:57:56,192][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 7.170    Value Loss: 5.662    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 375834     Buffer Size: 16888      Transition Number: 1000.187k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:00:41,466][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.701    [weighted Loss:3.701    Policy Loss: 7.219    Value Loss: 5.406    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 377786     Buffer Size: 16811      Transition Number: 1000.022k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:03:21,841][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 7.598    Value Loss: 5.801    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 379697     Buffer Size: 16852      Transition Number: 1000.241k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:06:03,591][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 7.623    Value Loss: 5.541    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 381681     Buffer Size: 16919      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:08:45,129][train][INFO][train.py>_log] ==> #179000     Total Loss: 4.728    [weighted Loss:4.728    Policy Loss: 7.897    Value Loss: 5.600    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 383635     Buffer Size: 17026      Transition Number: 1000.214k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:11:26,904][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 7.360    Value Loss: 5.704    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 385659     Buffer Size: 17240      Transition Number: 1000.211k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:14:10,403][train][INFO][train.py>_log] ==> #181000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 7.141    Value Loss: 5.609    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 387483     Buffer Size: 17294      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:16:51,384][train][INFO][train.py>_log] ==> #182000     Total Loss: 4.237    [weighted Loss:4.237    Policy Loss: 7.510    Value Loss: 5.602    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 389432     Buffer Size: 17244      Transition Number: 1000.249k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:19:35,131][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 7.274    Value Loss: 5.583    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 391349     Buffer Size: 17182      Transition Number: 1000.398k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:22:15,371][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.646    [weighted Loss:3.646    Policy Loss: 6.883    Value Loss: 5.502    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 393085     Buffer Size: 17150      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:24:58,034][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.110    [weighted Loss:2.110    Policy Loss: 6.946    Value Loss: 5.874    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 394978     Buffer Size: 17163      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:27:40,482][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.480    [weighted Loss:3.480    Policy Loss: 6.647    Value Loss: 5.666    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 396873     Buffer Size: 17092      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:30:26,186][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 6.495    Value Loss: 5.845    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 398904     Buffer Size: 17074      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:33:08,572][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.811    [weighted Loss:3.811    Policy Loss: 6.686    Value Loss: 5.613    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 400873     Buffer Size: 17001      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:35:52,675][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.738    [weighted Loss:3.738    Policy Loss: 6.240    Value Loss: 5.645    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 402744     Buffer Size: 16797      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:38:34,435][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 6.492    Value Loss: 5.610    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 404541     Buffer Size: 16733      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:41:15,072][train][INFO][train.py>_log] ==> #191000     Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 6.712    Value Loss: 5.462    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 406681     Buffer Size: 16898      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:43:59,183][train][INFO][train.py>_log] ==> #192000     Total Loss: 4.239    [weighted Loss:4.239    Policy Loss: 6.718    Value Loss: 5.618    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 408742     Buffer Size: 17122      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:46:40,780][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 6.155    Value Loss: 5.496    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 410690     Buffer Size: 17180      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:49:22,624][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 6.390    Value Loss: 5.054    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 412606     Buffer Size: 17183      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:52:06,017][train][INFO][train.py>_log] ==> #195000     Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 6.258    Value Loss: 5.572    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 414538     Buffer Size: 17107      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:54:52,100][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.546    [weighted Loss:3.546    Policy Loss: 6.882    Value Loss: 5.430    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 416418     Buffer Size: 17011      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:57:33,044][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 6.213    Value Loss: 5.306    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 418241     Buffer Size: 16898      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:00:16,813][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 7.198    Value Loss: 4.983    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 420186     Buffer Size: 16899      Transition Number: 1000.261k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:03:01,114][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 6.687    Value Loss: 5.264    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 422108     Buffer Size: 16840      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:05:59,281][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 6.786    Value Loss: 5.160    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 424021     Buffer Size: 16585      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:08:40,631][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 6.320    Value Loss: 4.893    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 426105     Buffer Size: 16399      Transition Number: 999.950 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:11:25,906][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 5.985    Value Loss: 4.843    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 427942     Buffer Size: 16367      Transition Number: 1000.176k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:14:09,297][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 5.966    Value Loss: 5.150    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 429814     Buffer Size: 16320      Transition Number: 1000.301k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:16:52,669][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 5.794    Value Loss: 4.957    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 431790     Buffer Size: 16295      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:19:35,724][train][INFO][train.py>_log] ==> #205000     Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 5.721    Value Loss: 4.965    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 433620     Buffer Size: 16279      Transition Number: 1000.004k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:22:21,175][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 5.951    Value Loss: 4.747    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 435544     Buffer Size: 16288      Transition Number: 1000.330k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:25:02,897][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 5.790    Value Loss: 5.002    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 437435     Buffer Size: 16261      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:27:49,152][train][INFO][train.py>_log] ==> #208000     Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 5.931    Value Loss: 4.685    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 439401     Buffer Size: 16243      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:30:33,474][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 5.699    Value Loss: 5.102    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 441264     Buffer Size: 16232      Transition Number: 1000.468k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:33:14,987][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 6.077    Value Loss: 4.962    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 443116     Buffer Size: 16162      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:36:01,440][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 6.302    Value Loss: 4.685    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 445001     Buffer Size: 16135      Transition Number: 999.945 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:38:42,626][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 6.176    Value Loss: 4.810    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 446894     Buffer Size: 16127      Transition Number: 1000.062k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:41:26,546][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.627    [weighted Loss:2.627    Policy Loss: 6.110    Value Loss: 4.710    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 448858     Buffer Size: 16106      Transition Number: 1000.176k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:44:10,856][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 6.623    Value Loss: 4.541    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 450718     Buffer Size: 16096      Transition Number: 1000.065k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:46:53,318][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 6.510    Value Loss: 4.817    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 452716     Buffer Size: 16095      Transition Number: 999.945 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:49:35,339][train][INFO][train.py>_log] ==> #216000     Total Loss: 3.583    [weighted Loss:3.583    Policy Loss: 6.399    Value Loss: 4.741    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 454635     Buffer Size: 16103      Transition Number: 1000.093k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:52:18,396][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 6.868    Value Loss: 4.774    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 456495     Buffer Size: 16089      Transition Number: 1000.266k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:55:00,984][train][INFO][train.py>_log] ==> #218000     Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 6.825    Value Loss: 4.775    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 458374     Buffer Size: 16079      Transition Number: 999.970 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:57:45,263][train][INFO][train.py>_log] ==> #219000     Total Loss: 4.332    [weighted Loss:4.332    Policy Loss: 7.004    Value Loss: 4.897    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 460309     Buffer Size: 16073      Transition Number: 1000.201k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:00:29,630][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 6.365    Value Loss: 4.905    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 462236     Buffer Size: 16085      Transition Number: 1000.006k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:03:13,716][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 6.511    Value Loss: 4.777    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 464334     Buffer Size: 16135      Transition Number: 999.963 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:05:58,943][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 6.064    Value Loss: 5.116    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 466266     Buffer Size: 16181      Transition Number: 1000.127k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:08:44,583][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 6.878    Value Loss: 5.171    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 468290     Buffer Size: 16207      Transition Number: 1000.027k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:11:30,793][train][INFO][train.py>_log] ==> #224000     Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 6.636    Value Loss: 4.915    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 470171     Buffer Size: 16246      Transition Number: 1000.194k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:14:17,982][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.571    Value Loss: 4.881    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 472185     Buffer Size: 16275      Transition Number: 1000.468k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:17:05,058][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.773    [weighted Loss:3.773    Policy Loss: 6.556    Value Loss: 4.958    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 474142     Buffer Size: 16290      Transition Number: 999.981 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:19:48,318][train][INFO][train.py>_log] ==> #227000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 7.042    Value Loss: 4.801    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 476062     Buffer Size: 16307      Transition Number: 1000.204k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:22:33,992][train][INFO][train.py>_log] ==> #228000     Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 6.244    Value Loss: 4.852    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 477991     Buffer Size: 16300      Transition Number: 1000.479k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:25:18,375][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 6.764    Value Loss: 5.157    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 479878     Buffer Size: 16247      Transition Number: 1000.106k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:28:03,285][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.522    [weighted Loss:2.522    Policy Loss: 6.498    Value Loss: 4.717    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 481836     Buffer Size: 16205      Transition Number: 1000.317k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:30:47,747][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 6.759    Value Loss: 4.815    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 483764     Buffer Size: 16154      Transition Number: 1000.003k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:33:33,809][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 7.210    Value Loss: 4.742    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 485761     Buffer Size: 16115      Transition Number: 1000.223k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:36:17,724][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 6.879    Value Loss: 4.956    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 487635     Buffer Size: 16075      Transition Number: 1000.020k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:39:00,401][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 6.685    Value Loss: 4.845    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 489441     Buffer Size: 16050      Transition Number: 1000.341k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:41:46,194][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.863    [weighted Loss:3.863    Policy Loss: 6.927    Value Loss: 4.817    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 491462     Buffer Size: 16007      Transition Number: 999.990 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:44:31,743][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.421    [weighted Loss:3.421    Policy Loss: 6.938    Value Loss: 4.844    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 493485     Buffer Size: 15999      Transition Number: 1000.230k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:47:16,415][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 7.255    Value Loss: 5.211    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 495402     Buffer Size: 15994      Transition Number: 999.965 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:50:01,462][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.977    [weighted Loss:3.977    Policy Loss: 6.992    Value Loss: 4.657    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 497472     Buffer Size: 15998      Transition Number: 1000.319k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:52:45,587][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 7.027    Value Loss: 4.801    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 499338     Buffer Size: 16013      Transition Number: 1000.090k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:55:30,088][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 7.162    Value Loss: 5.054    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 501333     Buffer Size: 16032      Transition Number: 999.977 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:58:16,924][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.400    [weighted Loss:2.400    Policy Loss: 6.881    Value Loss: 5.000    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 503299     Buffer Size: 16044      Transition Number: 999.965 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:01:03,589][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 6.904    Value Loss: 4.954    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 505254     Buffer Size: 16069      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:03:47,461][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 7.221    Value Loss: 5.204    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 507191     Buffer Size: 16095      Transition Number: 1000.245k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:06:32,009][train][INFO][train.py>_log] ==> #244000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 6.947    Value Loss: 5.096    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 509107     Buffer Size: 16107      Transition Number: 1000.299k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:09:17,710][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 7.038    Value Loss: 4.841    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 511155     Buffer Size: 16150      Transition Number: 1000.144k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:12:01,850][train][INFO][train.py>_log] ==> #246000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 7.286    Value Loss: 4.931    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 513196     Buffer Size: 16189      Transition Number: 1000.190k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:14:46,986][train][INFO][train.py>_log] ==> #247000     Total Loss: 4.421    [weighted Loss:4.421    Policy Loss: 7.567    Value Loss: 5.129    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 515182     Buffer Size: 16195      Transition Number: 1000.031k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:17:30,868][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.700    [weighted Loss:2.700    Policy Loss: 7.463    Value Loss: 5.368    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 517028     Buffer Size: 16191      Transition Number: 1000.045k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:20:15,306][train][INFO][train.py>_log] ==> #249000     Total Loss: 4.101    [weighted Loss:4.101    Policy Loss: 7.323    Value Loss: 4.949    Reward Loss: 1.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 518941     Buffer Size: 16161      Transition Number: 1000.023k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:22:58,288][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 6.940    Value Loss: 5.002    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 520827     Buffer Size: 16149      Transition Number: 1000.070k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:25:44,744][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 7.606    Value Loss: 4.829    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 522731     Buffer Size: 16134      Transition Number: 1000.131k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:28:30,231][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 7.411    Value Loss: 5.012    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 524732     Buffer Size: 16134      Transition Number: 1000.572k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:31:16,583][train][INFO][train.py>_log] ==> #253000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 7.647    Value Loss: 4.693    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 526717     Buffer Size: 16095      Transition Number: 1000.112k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:34:01,982][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 7.395    Value Loss: 4.885    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 528668     Buffer Size: 16061      Transition Number: 1000.483k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:36:46,298][train][INFO][train.py>_log] ==> #255000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 7.337    Value Loss: 5.137    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 530577     Buffer Size: 16033      Transition Number: 999.993 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:39:30,841][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.999    [weighted Loss:3.999    Policy Loss: 6.984    Value Loss: 5.217    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 532503     Buffer Size: 16012      Transition Number: 1000.023k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:42:14,540][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 7.463    Value Loss: 4.962    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 534418     Buffer Size: 16029      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:45:02,763][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 6.690    Value Loss: 5.085    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 536412     Buffer Size: 16051      Transition Number: 1000.068k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:47:47,737][train][INFO][train.py>_log] ==> #259000     Total Loss: 3.544    [weighted Loss:3.544    Policy Loss: 6.732    Value Loss: 4.947    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 538259     Buffer Size: 16095      Transition Number: 1000.096k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:50:33,620][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 6.907    Value Loss: 4.766    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 540333     Buffer Size: 16150      Transition Number: 1000.069k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:53:19,431][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.285    [weighted Loss:3.285    Policy Loss: 6.692    Value Loss: 5.090    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 542372     Buffer Size: 16194      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:56:06,648][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 6.825    Value Loss: 5.250    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 544414     Buffer Size: 16242      Transition Number: 1000.061k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:58:51,701][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 6.869    Value Loss: 5.242    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 546429     Buffer Size: 16313      Transition Number: 1000.096k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:01:36,571][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 7.114    Value Loss: 5.271    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 548323     Buffer Size: 16390      Transition Number: 999.951 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:04:19,921][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 6.987    Value Loss: 5.133    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 550268     Buffer Size: 16447      Transition Number: 1000.150k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:07:04,270][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 7.098    Value Loss: 5.218    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 552196     Buffer Size: 16490      Transition Number: 1000.320k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:09:51,970][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 6.841    Value Loss: 5.396    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 554170     Buffer Size: 16507      Transition Number: 1000.131k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:12:39,224][train][INFO][train.py>_log] ==> #268000     Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 6.887    Value Loss: 5.094    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 556148     Buffer Size: 16525      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:15:24,130][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 6.460    Value Loss: 5.219    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 558125     Buffer Size: 16504      Transition Number: 1000.001k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:18:08,015][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 6.839    Value Loss: 5.297    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 560084     Buffer Size: 16507      Transition Number: 999.991 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:20:54,583][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.871    [weighted Loss:2.871    Policy Loss: 7.141    Value Loss: 5.093    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 562021     Buffer Size: 16487      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:23:40,532][train][INFO][train.py>_log] ==> #272000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 6.619    Value Loss: 5.291    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 564024     Buffer Size: 16503      Transition Number: 1000.519k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:26:28,077][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 6.465    Value Loss: 4.897    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 565998     Buffer Size: 16490      Transition Number: 999.991 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:29:15,491][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 6.821    Value Loss: 4.922    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 567962     Buffer Size: 16489      Transition Number: 999.988 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:32:02,748][train][INFO][train.py>_log] ==> #275000     Total Loss: 3.592    [weighted Loss:3.592    Policy Loss: 6.627    Value Loss: 5.025    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 569989     Buffer Size: 16481      Transition Number: 999.947 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:34:47,850][train][INFO][train.py>_log] ==> #276000     Total Loss: 3.791    [weighted Loss:3.791    Policy Loss: 6.515    Value Loss: 5.240    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 571981     Buffer Size: 16464      Transition Number: 1000.109k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:37:36,282][train][INFO][train.py>_log] ==> #277000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 6.455    Value Loss: 5.042    Reward Loss: 1.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 573920     Buffer Size: 16446      Transition Number: 1000.076k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:40:22,896][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 6.239    Value Loss: 5.049    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 575887     Buffer Size: 16442      Transition Number: 1000.019k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:43:12,841][train][INFO][train.py>_log] ==> #279000     Total Loss: 3.976    [weighted Loss:3.976    Policy Loss: 6.659    Value Loss: 5.172    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 577924     Buffer Size: 16387      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:46:01,339][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 6.321    Value Loss: 4.694    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 579854     Buffer Size: 16327      Transition Number: 1000.154k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:48:49,186][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 6.707    Value Loss: 5.046    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 581886     Buffer Size: 16252      Transition Number: 1000.379k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:51:37,131][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 6.039    Value Loss: 4.524    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 583793     Buffer Size: 16198      Transition Number: 1000.028k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:54:26,278][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 6.614    Value Loss: 5.299    Reward Loss: 1.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 585820     Buffer Size: 16167      Transition Number: 999.942 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:57:12,302][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.511    [weighted Loss:2.511    Policy Loss: 6.343    Value Loss: 4.986    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 587797     Buffer Size: 16142      Transition Number: 1000.084k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:00:00,578][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 6.818    Value Loss: 5.140    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 589844     Buffer Size: 16092      Transition Number: 999.992 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:02:48,597][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 7.158    Value Loss: 4.666    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 591891     Buffer Size: 16044      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:05:35,648][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 6.923    Value Loss: 5.005    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 593905     Buffer Size: 16022      Transition Number: 999.993 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:08:23,917][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.769    [weighted Loss:2.769    Policy Loss: 6.780    Value Loss: 4.890    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 595890     Buffer Size: 16011      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:11:11,928][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 6.879    Value Loss: 4.760    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 597844     Buffer Size: 16038      Transition Number: 1000.465k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:13:59,240][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 7.226    Value Loss: 4.910    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 599877     Buffer Size: 16043      Transition Number: 999.960 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:16:46,483][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 6.841    Value Loss: 4.719    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 601895     Buffer Size: 16020      Transition Number: 1000.180k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:19:32,496][train][INFO][train.py>_log] ==> #292000     Total Loss: 4.229    [weighted Loss:4.229    Policy Loss: 7.519    Value Loss: 4.757    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 603765     Buffer Size: 15994      Transition Number: 1000.018k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:22:19,552][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.759    [weighted Loss:2.759    Policy Loss: 7.112    Value Loss: 4.639    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 605789     Buffer Size: 15972      Transition Number: 999.954 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:25:05,838][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 6.957    Value Loss: 4.566    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 607811     Buffer Size: 15942      Transition Number: 999.968 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:27:51,427][train][INFO][train.py>_log] ==> #295000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 7.566    Value Loss: 5.133    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 609824     Buffer Size: 15916      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:30:37,071][train][INFO][train.py>_log] ==> #296000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 6.588    Value Loss: 4.901    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 611860     Buffer Size: 15895      Transition Number: 999.974 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:33:24,619][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 6.623    Value Loss: 4.828    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 613811     Buffer Size: 15858      Transition Number: 999.963 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:36:09,767][train][INFO][train.py>_log] ==> #298000     Total Loss: 3.729    [weighted Loss:3.729    Policy Loss: 7.392    Value Loss: 4.840    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 615797     Buffer Size: 15815      Transition Number: 1000.055k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:38:55,286][train][INFO][train.py>_log] ==> #299000     Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 7.354    Value Loss: 4.845    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 617724     Buffer Size: 15793      Transition Number: 1000.003k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:41:40,891][train][INFO][train.py>_log] ==> #300000     Total Loss: 4.020    [weighted Loss:4.020    Policy Loss: 7.068    Value Loss: 4.870    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 619800     Buffer Size: 15774      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:44:28,508][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 7.338    Value Loss: 4.918    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 621744     Buffer Size: 15770      Transition Number: 1000.166k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:47:16,744][train][INFO][train.py>_log] ==> #302000     Total Loss: 3.108    [weighted Loss:3.108    Policy Loss: 7.180    Value Loss: 4.818    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 623725     Buffer Size: 15770      Transition Number: 1000.082k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:50:02,602][train][INFO][train.py>_log] ==> #303000     Total Loss: 3.537    [weighted Loss:3.537    Policy Loss: 7.084    Value Loss: 4.887    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 625750     Buffer Size: 15781      Transition Number: 1000.255k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:52:51,189][train][INFO][train.py>_log] ==> #304000     Total Loss: 3.821    [weighted Loss:3.821    Policy Loss: 7.045    Value Loss: 5.208    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 627747     Buffer Size: 15773      Transition Number: 1000.055k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:55:39,504][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 6.934    Value Loss: 4.979    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 629777     Buffer Size: 15802      Transition Number: 1000.008k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:58:30,525][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.256    [weighted Loss:1.256    Policy Loss: 6.890    Value Loss: 4.886    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 631840     Buffer Size: 15816      Transition Number: 1000.011k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:01:16,445][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 6.355    Value Loss: 5.363    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 633797     Buffer Size: 15834      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:04:04,558][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 6.697    Value Loss: 4.875    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 635828     Buffer Size: 15854      Transition Number: 1000.222k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:06:52,692][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 6.573    Value Loss: 5.096    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 637804     Buffer Size: 15870      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:09:40,937][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.309    [weighted Loss:3.309    Policy Loss: 6.651    Value Loss: 4.815    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 639885     Buffer Size: 15896      Transition Number: 999.994 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:12:27,689][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 6.244    Value Loss: 5.161    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 641895     Buffer Size: 15921      Transition Number: 1000.696k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:15:16,284][train][INFO][train.py>_log] ==> #312000     Total Loss: 3.293    [weighted Loss:3.293    Policy Loss: 6.115    Value Loss: 5.134    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 643853     Buffer Size: 15958      Transition Number: 1000.178k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:18:04,394][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.660    Value Loss: 4.782    Reward Loss: 1.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 645913     Buffer Size: 15960      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:20:53,482][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 6.601    Value Loss: 5.188    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 648044     Buffer Size: 15993      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:23:39,941][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 6.245    Value Loss: 4.964    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 649995     Buffer Size: 15992      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:26:32,255][train][INFO][train.py>_log] ==> #316000     Total Loss: 2.159    [weighted Loss:2.159    Policy Loss: 6.288    Value Loss: 4.825    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 652041     Buffer Size: 15978      Transition Number: 999.943 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:29:15,540][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 6.828    Value Loss: 4.761    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 654019     Buffer Size: 15969      Transition Number: 1000.018k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:32:02,928][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 6.651    Value Loss: 4.708    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 656085     Buffer Size: 15942      Transition Number: 1000.116k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:34:50,862][train][INFO][train.py>_log] ==> #319000     Total Loss: 4.336    [weighted Loss:4.336    Policy Loss: 6.473    Value Loss: 5.235    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 658101     Buffer Size: 15900      Transition Number: 1000.289k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:37:38,372][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 6.825    Value Loss: 5.070    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 660064     Buffer Size: 15855      Transition Number: 1000.071k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:40:28,279][train][INFO][train.py>_log] ==> #321000     Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 6.215    Value Loss: 4.688    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 662147     Buffer Size: 15791      Transition Number: 1000.039k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:43:18,381][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 6.729    Value Loss: 4.804    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 664224     Buffer Size: 15727      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:46:05,124][train][INFO][train.py>_log] ==> #323000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 6.723    Value Loss: 4.834    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 666215     Buffer Size: 15750      Transition Number: 1000.045k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:48:52,412][train][INFO][train.py>_log] ==> #324000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 6.368    Value Loss: 4.810    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 668262     Buffer Size: 15761      Transition Number: 1000.557k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:51:39,968][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 7.085    Value Loss: 4.586    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 670295     Buffer Size: 15749      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:54:24,970][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 7.010    Value Loss: 5.399    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 672246     Buffer Size: 15776      Transition Number: 999.988 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:57:15,233][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 6.855    Value Loss: 4.687    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 674288     Buffer Size: 15783      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:00:02,618][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 6.951    Value Loss: 4.873    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 676296     Buffer Size: 15764      Transition Number: 999.989 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:02:49,655][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 7.151    Value Loss: 4.863    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 678376     Buffer Size: 15757      Transition Number: 1000.040k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:05:34,670][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.395    [weighted Loss:3.395    Policy Loss: 6.916    Value Loss: 5.314    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 680356     Buffer Size: 15747      Transition Number: 1000.102k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:08:24,694][train][INFO][train.py>_log] ==> #331000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 6.549    Value Loss: 4.668    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 682397     Buffer Size: 15707      Transition Number: 999.979 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:11:13,573][train][INFO][train.py>_log] ==> #332000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 6.763    Value Loss: 4.842    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 684463     Buffer Size: 15670      Transition Number: 999.975 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:14:01,118][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 6.618    Value Loss: 4.851    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 686458     Buffer Size: 15628      Transition Number: 1000.215k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:16:51,466][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 7.034    Value Loss: 4.650    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 688441     Buffer Size: 15591      Transition Number: 1000.133k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:19:40,208][train][INFO][train.py>_log] ==> #335000     Total Loss: 3.698    [weighted Loss:3.698    Policy Loss: 7.084    Value Loss: 4.754    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 690479     Buffer Size: 15577      Transition Number: 999.981 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:22:31,065][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 7.098    Value Loss: 4.698    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 692525     Buffer Size: 15578      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:25:22,629][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 7.033    Value Loss: 4.816    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 694560     Buffer Size: 15584      Transition Number: 1000.129k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:28:08,798][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 6.559    Value Loss: 4.782    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 696541     Buffer Size: 15579      Transition Number: 1000.211k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:30:57,819][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 6.810    Value Loss: 4.711    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 698590     Buffer Size: 15549      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:33:47,221][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 6.601    Value Loss: 4.600    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 700562     Buffer Size: 15521      Transition Number: 1000.057k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:36:36,781][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 7.274    Value Loss: 4.789    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 702594     Buffer Size: 15504      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:39:25,130][train][INFO][train.py>_log] ==> #342000     Total Loss: 3.735    [weighted Loss:3.735    Policy Loss: 7.054    Value Loss: 5.286    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 704594     Buffer Size: 15479      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:42:16,397][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 7.062    Value Loss: 4.911    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 706707     Buffer Size: 15467      Transition Number: 1000.118k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:45:03,271][train][INFO][train.py>_log] ==> #344000     Total Loss: 3.879    [weighted Loss:3.879    Policy Loss: 6.963    Value Loss: 4.839    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 708739     Buffer Size: 15466      Transition Number: 1000.041k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:47:51,614][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.369    [weighted Loss:3.369    Policy Loss: 7.083    Value Loss: 4.695    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 710790     Buffer Size: 15438      Transition Number: 999.982 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:50:41,964][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 7.275    Value Loss: 4.543    Reward Loss: 1.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 712843     Buffer Size: 15442      Transition Number: 1000.462k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:53:29,826][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 7.171    Value Loss: 4.662    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 714868     Buffer Size: 15444      Transition Number: 1000.069k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:56:20,232][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 7.033    Value Loss: 5.157    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 716915     Buffer Size: 15447      Transition Number: 999.957 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:59:09,711][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 7.082    Value Loss: 4.552    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 718922     Buffer Size: 15442      Transition Number: 999.949 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:01:57,081][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.367    Value Loss: 4.457    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 721000     Buffer Size: 15448      Transition Number: 1000.265k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:04:46,310][train][INFO][train.py>_log] ==> #351000     Total Loss: 2.753    [weighted Loss:2.753    Policy Loss: 6.983    Value Loss: 4.720    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 723079     Buffer Size: 15449      Transition Number: 1000.186k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:07:34,437][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 7.047    Value Loss: 4.581    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 725174     Buffer Size: 15462      Transition Number: 1000.119k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:10:23,911][train][INFO][train.py>_log] ==> #353000     Total Loss: 3.452    [weighted Loss:3.452    Policy Loss: 7.636    Value Loss: 4.650    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 727233     Buffer Size: 15489      Transition Number: 1000.136k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:13:12,115][train][INFO][train.py>_log] ==> #354000     Total Loss: 3.533    [weighted Loss:3.533    Policy Loss: 7.200    Value Loss: 4.893    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 729345     Buffer Size: 15491      Transition Number: 1000.081k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:16:00,685][train][INFO][train.py>_log] ==> #355000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 7.735    Value Loss: 4.936    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 731353     Buffer Size: 15514      Transition Number: 1000.398k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:18:49,524][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.349    [weighted Loss:1.349    Policy Loss: 7.642    Value Loss: 4.900    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 733378     Buffer Size: 15545      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:21:40,425][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.809    [weighted Loss:3.809    Policy Loss: 7.191    Value Loss: 4.780    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 735488     Buffer Size: 15567      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:24:31,600][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 7.208    Value Loss: 4.379    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 737577     Buffer Size: 15593      Transition Number: 999.986 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:27:21,481][train][INFO][train.py>_log] ==> #359000     Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 7.048    Value Loss: 5.067    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 739738     Buffer Size: 15601      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:30:10,729][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 7.074    Value Loss: 4.466    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 741862     Buffer Size: 15601      Transition Number: 999.971 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:33:00,085][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 7.018    Value Loss: 4.691    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 743929     Buffer Size: 15692      Transition Number: 999.948 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:35:46,113][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 7.132    Value Loss: 5.258    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 746011     Buffer Size: 15796      Transition Number: 1000.065k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:38:36,721][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 6.583    Value Loss: 5.000    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 748152     Buffer Size: 15846      Transition Number: 999.961 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:41:25,003][train][INFO][train.py>_log] ==> #364000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 6.794    Value Loss: 5.111    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 750198     Buffer Size: 15892      Transition Number: 1000.082k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:44:12,641][train][INFO][train.py>_log] ==> #365000     Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 6.929    Value Loss: 5.093    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 752288     Buffer Size: 15917      Transition Number: 1000.054k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:46:59,314][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.024    [weighted Loss:1.024    Policy Loss: 6.224    Value Loss: 4.722    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 754345     Buffer Size: 15925      Transition Number: 999.980 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:49:49,159][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.053    [weighted Loss:2.053    Policy Loss: 6.488    Value Loss: 4.692    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 756442     Buffer Size: 15984      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:52:39,160][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 6.919    Value Loss: 4.935    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 758564     Buffer Size: 16040      Transition Number: 1000.353k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:55:30,397][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 6.605    Value Loss: 4.958    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 760665     Buffer Size: 15983      Transition Number: 1000.107k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:58:22,855][train][INFO][train.py>_log] ==> #370000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.637    Value Loss: 5.000    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 762813     Buffer Size: 15924      Transition Number: 1000.220k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:01:15,628][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 6.474    Value Loss: 4.615    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 764915     Buffer Size: 15897      Transition Number: 1000.402k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:04:05,255][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 6.428    Value Loss: 4.521    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 767008     Buffer Size: 15867      Transition Number: 1000.128k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:06:56,861][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 6.528    Value Loss: 4.640    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 769059     Buffer Size: 15868      Transition Number: 1000.304k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:09:47,780][train][INFO][train.py>_log] ==> #374000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 6.500    Value Loss: 5.003    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 771205     Buffer Size: 15872      Transition Number: 999.966 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:12:38,919][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 6.255    Value Loss: 4.751    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 773310     Buffer Size: 15823      Transition Number: 1000.212k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:15:30,427][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 6.390    Value Loss: 4.588    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 775415     Buffer Size: 15758      Transition Number: 1000.084k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:18:20,711][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 6.447    Value Loss: 4.704    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 777522     Buffer Size: 15739      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:21:09,473][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.877    [weighted Loss:2.877    Policy Loss: 6.699    Value Loss: 4.857    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 779558     Buffer Size: 15732      Transition Number: 999.951 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:23:59,320][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 6.602    Value Loss: 4.587    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 781642     Buffer Size: 15708      Transition Number: 1000.169k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:26:48,806][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 6.464    Value Loss: 4.926    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 783695     Buffer Size: 15688      Transition Number: 999.949 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:29:40,096][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 6.100    Value Loss: 4.913    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 785849     Buffer Size: 15689      Transition Number: 1000.001k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:32:31,539][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 6.086    Value Loss: 4.739    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 787888     Buffer Size: 15706      Transition Number: 1000.086k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:35:20,911][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 6.148    Value Loss: 5.049    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 789945     Buffer Size: 15715      Transition Number: 999.942 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:38:09,829][train][INFO][train.py>_log] ==> #384000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 6.599    Value Loss: 4.564    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 792148     Buffer Size: 15745      Transition Number: 1000.121k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:41:01,238][train][INFO][train.py>_log] ==> #385000     Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 5.886    Value Loss: 4.694    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 794301     Buffer Size: 15794      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:43:53,498][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.633    [weighted Loss:1.633    Policy Loss: 6.100    Value Loss: 4.432    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 796456     Buffer Size: 15842      Transition Number: 1000.063k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:46:44,199][train][INFO][train.py>_log] ==> #387000     Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 6.405    Value Loss: 4.842    Reward Loss: 1.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 798545     Buffer Size: 15878      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:49:32,348][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 6.064    Value Loss: 4.458    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 800540     Buffer Size: 15916      Transition Number: 1000.743k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:52:21,439][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 6.250    Value Loss: 4.967    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 802563     Buffer Size: 15908      Transition Number: 1000.087k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:55:09,657][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 6.595    Value Loss: 4.448    Reward Loss: 1.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 804524     Buffer Size: 15914      Transition Number: 1000.306k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:58:00,210][train][INFO][train.py>_log] ==> #391000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 6.665    Value Loss: 4.880    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 806613     Buffer Size: 15917      Transition Number: 1000.151k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:00:47,644][train][INFO][train.py>_log] ==> #392000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 6.833    Value Loss: 4.803    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 808580     Buffer Size: 15909      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:03:39,335][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 6.614    Value Loss: 4.520    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 810783     Buffer Size: 15894      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:06:26,371][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 6.579    Value Loss: 4.460    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 812729     Buffer Size: 15879      Transition Number: 1000.114k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:09:13,942][train][INFO][train.py>_log] ==> #395000     Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 6.251    Value Loss: 4.813    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 814807     Buffer Size: 15872      Transition Number: 999.947 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:12:02,603][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 6.379    Value Loss: 5.053    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 816879     Buffer Size: 15872      Transition Number: 1000.090k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:14:53,818][train][INFO][train.py>_log] ==> #397000     Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 6.454    Value Loss: 4.615    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 818991     Buffer Size: 15871      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:17:43,411][train][INFO][train.py>_log] ==> #398000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 6.512    Value Loss: 4.820    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 821106     Buffer Size: 15875      Transition Number: 1000.006k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:20:33,602][train][INFO][train.py>_log] ==> #399000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 7.007    Value Loss: 4.488    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 823104     Buffer Size: 15890      Transition Number: 1000.235k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:23:34,097][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 6.545    Value Loss: 4.556    Reward Loss: 1.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 825274     Buffer Size: 15906      Transition Number: 1000.144k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:26:24,379][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 6.598    Value Loss: 4.652    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 827483     Buffer Size: 15899      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:29:11,113][train][INFO][train.py>_log] ==> #402000     Total Loss: 3.445    [weighted Loss:3.445    Policy Loss: 6.676    Value Loss: 4.838    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 829481     Buffer Size: 15904      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:32:00,193][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 6.041    Value Loss: 4.840    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 831516     Buffer Size: 15878      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:34:50,888][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 6.333    Value Loss: 4.647    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 833586     Buffer Size: 15855      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:37:43,461][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 6.107    Value Loss: 4.487    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 835722     Buffer Size: 15807      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:40:35,579][train][INFO][train.py>_log] ==> #406000     Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 5.988    Value Loss: 4.832    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 837830     Buffer Size: 15761      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:43:25,752][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 6.144    Value Loss: 4.358    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 839923     Buffer Size: 15703      Transition Number: 1000.325k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:46:15,933][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.311    [weighted Loss:1.311    Policy Loss: 6.066    Value Loss: 4.689    Reward Loss: 1.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 841989     Buffer Size: 15639      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:49:12,732][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 6.129    Value Loss: 4.125    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 844136     Buffer Size: 15575      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:52:01,787][train][INFO][train.py>_log] ==> #410000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 5.930    Value Loss: 4.266    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 846224     Buffer Size: 15533      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:54:54,836][train][INFO][train.py>_log] ==> #411000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 6.339    Value Loss: 4.081    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 848350     Buffer Size: 15483      Transition Number: 1000.168k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:57:44,908][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.085    [weighted Loss:3.085    Policy Loss: 5.982    Value Loss: 4.368    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 850382     Buffer Size: 15446      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:00:35,960][train][INFO][train.py>_log] ==> #413000     Total Loss: 3.144    [weighted Loss:3.144    Policy Loss: 6.141    Value Loss: 4.372    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 852473     Buffer Size: 15403      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:03:26,263][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 6.254    Value Loss: 4.152    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 854524     Buffer Size: 15368      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:06:19,051][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 6.008    Value Loss: 4.177    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 856582     Buffer Size: 15335      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:09:08,050][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 6.231    Value Loss: 4.127    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 858657     Buffer Size: 15313      Transition Number: 1000.081k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:12:00,174][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 6.213    Value Loss: 4.177    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 860815     Buffer Size: 15301      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:14:48,135][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.955    [weighted Loss:2.955    Policy Loss: 6.224    Value Loss: 4.176    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 862857     Buffer Size: 15296      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:17:38,398][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 6.402    Value Loss: 4.186    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 864965     Buffer Size: 15284      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:20:30,214][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 5.973    Value Loss: 4.138    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 867064     Buffer Size: 15278      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:23:20,558][train][INFO][train.py>_log] ==> #421000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 6.414    Value Loss: 4.270    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 869180     Buffer Size: 15268      Transition Number: 1000.236k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:26:09,560][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 6.534    Value Loss: 4.298    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 871290     Buffer Size: 15252      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:29:02,921][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 6.532    Value Loss: 4.180    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 873424     Buffer Size: 15230      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:31:55,184][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 5.916    Value Loss: 4.493    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 875493     Buffer Size: 15207      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:34:48,615][train][INFO][train.py>_log] ==> #425000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 6.220    Value Loss: 4.042    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 877663     Buffer Size: 15193      Transition Number: 1000.381k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:37:38,158][train][INFO][train.py>_log] ==> #426000     Total Loss: 2.358    [weighted Loss:2.358    Policy Loss: 6.450    Value Loss: 4.217    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 879718     Buffer Size: 15159      Transition Number: 1000.125k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:40:29,098][train][INFO][train.py>_log] ==> #427000     Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 6.076    Value Loss: 4.279    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 881850     Buffer Size: 15140      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:43:19,867][train][INFO][train.py>_log] ==> #428000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 6.514    Value Loss: 3.889    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 883983     Buffer Size: 15126      Transition Number: 1000.307k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:46:12,039][train][INFO][train.py>_log] ==> #429000     Total Loss: 3.358    [weighted Loss:3.358    Policy Loss: 6.443    Value Loss: 4.372    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 886104     Buffer Size: 15112      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:49:03,506][train][INFO][train.py>_log] ==> #430000     Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 6.246    Value Loss: 4.108    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 888184     Buffer Size: 15113      Transition Number: 1000.230k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:51:52,346][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 6.824    Value Loss: 4.225    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 890276     Buffer Size: 15117      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:54:43,537][train][INFO][train.py>_log] ==> #432000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 6.497    Value Loss: 4.142    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 892376     Buffer Size: 15126      Transition Number: 999.932 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:57:36,391][train][INFO][train.py>_log] ==> #433000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 6.803    Value Loss: 4.323    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 894541     Buffer Size: 15144      Transition Number: 1000.398k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:00:26,615][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 6.715    Value Loss: 4.486    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 896666     Buffer Size: 15155      Transition Number: 1000.719k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:03:19,072][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 6.728    Value Loss: 4.313    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 898759     Buffer Size: 15149      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:06:11,027][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 6.721    Value Loss: 4.253    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 900946     Buffer Size: 15159      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:08:59,836][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 6.657    Value Loss: 4.443    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 903080     Buffer Size: 15177      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:11:52,771][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 6.809    Value Loss: 4.184    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 905237     Buffer Size: 15175      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:14:42,917][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 6.634    Value Loss: 4.251    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 907345     Buffer Size: 15185      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:17:36,656][train][INFO][train.py>_log] ==> #440000     Total Loss: 3.406    [weighted Loss:3.406    Policy Loss: 6.958    Value Loss: 4.176    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 909612     Buffer Size: 15196      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:20:29,570][train][INFO][train.py>_log] ==> #441000     Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 6.808    Value Loss: 4.228    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 911713     Buffer Size: 15218      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:23:25,384][train][INFO][train.py>_log] ==> #442000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 6.176    Value Loss: 4.240    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 913969     Buffer Size: 15237      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:26:14,893][train][INFO][train.py>_log] ==> #443000     Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 6.544    Value Loss: 4.119    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 916068     Buffer Size: 15256      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:29:07,530][train][INFO][train.py>_log] ==> #444000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.501    Value Loss: 3.910    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 918230     Buffer Size: 15261      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:31:57,710][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 6.876    Value Loss: 4.038    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 920319     Buffer Size: 15288      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:34:50,774][train][INFO][train.py>_log] ==> #446000     Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 6.399    Value Loss: 4.754    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 922494     Buffer Size: 15311      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:37:46,100][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 6.536    Value Loss: 4.553    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 924616     Buffer Size: 15334      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:40:37,766][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 6.615    Value Loss: 4.430    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 926803     Buffer Size: 15359      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:43:30,767][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 6.690    Value Loss: 4.395    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 928903     Buffer Size: 15372      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:46:22,074][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 6.177    Value Loss: 4.269    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 931115     Buffer Size: 15395      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:49:11,300][train][INFO][train.py>_log] ==> #451000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 6.634    Value Loss: 4.290    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 933176     Buffer Size: 15413      Transition Number: 1000.165k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:52:06,263][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 6.582    Value Loss: 4.366    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 935405     Buffer Size: 15426      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:54:56,558][train][INFO][train.py>_log] ==> #453000     Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 6.522    Value Loss: 4.239    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 937496     Buffer Size: 15435      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:57:47,825][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 6.882    Value Loss: 4.381    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 939625     Buffer Size: 15442      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:00:41,546][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.938    [weighted Loss:2.938    Policy Loss: 6.661    Value Loss: 4.240    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 941826     Buffer Size: 15436      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:03:36,468][train][INFO][train.py>_log] ==> #456000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 6.391    Value Loss: 4.234    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 944058     Buffer Size: 15432      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:06:27,281][train][INFO][train.py>_log] ==> #457000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 6.644    Value Loss: 4.629    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 946160     Buffer Size: 15421      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:09:19,697][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.934    [weighted Loss:1.934    Policy Loss: 6.358    Value Loss: 4.271    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 948380     Buffer Size: 15430      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:12:11,841][train][INFO][train.py>_log] ==> #459000     Total Loss: 3.343    [weighted Loss:3.343    Policy Loss: 6.275    Value Loss: 4.266    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 950520     Buffer Size: 15425      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:15:05,889][train][INFO][train.py>_log] ==> #460000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 6.684    Value Loss: 4.153    Reward Loss: 1.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 952679     Buffer Size: 15430      Transition Number: 1000.252k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:17:55,179][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 6.615    Value Loss: 4.218    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 954776     Buffer Size: 15435      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:20:48,334][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.711    Value Loss: 4.329    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 956920     Buffer Size: 15455      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:23:42,414][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 6.655    Value Loss: 4.450    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 959108     Buffer Size: 15482      Transition Number: 1000.558k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:26:34,708][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 6.613    Value Loss: 4.044    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 961285     Buffer Size: 15497      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:29:26,362][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 6.770    Value Loss: 4.563    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 963453     Buffer Size: 15516      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:32:19,339][train][INFO][train.py>_log] ==> #466000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 6.590    Value Loss: 4.242    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 965573     Buffer Size: 15538      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:35:13,314][train][INFO][train.py>_log] ==> #467000     Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 6.866    Value Loss: 4.412    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 967780     Buffer Size: 15561      Transition Number: 1000.428k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:38:05,907][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 6.983    Value Loss: 4.235    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 969899     Buffer Size: 15576      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:41:00,491][train][INFO][train.py>_log] ==> #469000     Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 6.990    Value Loss: 4.518    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 972051     Buffer Size: 15577      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:43:55,336][train][INFO][train.py>_log] ==> #470000     Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 6.628    Value Loss: 4.256    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 974282     Buffer Size: 15589      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:46:45,057][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 6.969    Value Loss: 4.249    Reward Loss: 1.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 976337     Buffer Size: 15597      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:49:37,912][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 6.522    Value Loss: 4.569    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 978483     Buffer Size: 15604      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:52:28,643][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.942    [weighted Loss:2.942    Policy Loss: 6.607    Value Loss: 4.278    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 980702     Buffer Size: 15615      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:55:21,600][train][INFO][train.py>_log] ==> #474000     Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 6.455    Value Loss: 4.608    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 982818     Buffer Size: 15623      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:58:14,604][train][INFO][train.py>_log] ==> #475000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 6.487    Value Loss: 4.272    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 984962     Buffer Size: 15644      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:01:05,455][train][INFO][train.py>_log] ==> #476000     Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 6.385    Value Loss: 4.339    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 987144     Buffer Size: 15668      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:03:58,607][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 6.829    Value Loss: 4.164    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 989296     Buffer Size: 15695      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:06:49,318][train][INFO][train.py>_log] ==> #478000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 6.997    Value Loss: 4.272    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 991416     Buffer Size: 15711      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:09:40,261][train][INFO][train.py>_log] ==> #479000     Total Loss: 3.253    [weighted Loss:3.253    Policy Loss: 7.339    Value Loss: 4.551    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 993584     Buffer Size: 15725      Transition Number: 1000.079k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:12:33,945][train][INFO][train.py>_log] ==> #480000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 6.658    Value Loss: 4.414    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 995770     Buffer Size: 15754      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:15:27,681][train][INFO][train.py>_log] ==> #481000     Total Loss: 3.696    [weighted Loss:3.696    Policy Loss: 6.897    Value Loss: 4.396    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 997903     Buffer Size: 15775      Transition Number: 1000.164k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:18:18,352][train][INFO][train.py>_log] ==> #482000     Total Loss: 0.966    [weighted Loss:0.966    Policy Loss: 7.035    Value Loss: 4.396    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000026    Buffer Size: 15762      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:21:11,522][train][INFO][train.py>_log] ==> #483000     Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 6.944    Value Loss: 4.572    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002194    Buffer Size: 15772      Transition Number: 1000.298k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:24:05,185][train][INFO][train.py>_log] ==> #484000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 7.128    Value Loss: 4.861    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1004365    Buffer Size: 15779      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:26:59,675][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 7.281    Value Loss: 4.519    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1006613    Buffer Size: 15782      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:29:53,328][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 6.689    Value Loss: 4.786    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1008771    Buffer Size: 15800      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:32:46,219][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 7.190    Value Loss: 4.710    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1010953    Buffer Size: 15789      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:35:41,559][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 6.609    Value Loss: 4.393    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013152    Buffer Size: 15776      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:38:37,096][train][INFO][train.py>_log] ==> #489000     Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 6.456    Value Loss: 4.680    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 1015373    Buffer Size: 15789      Transition Number: 1000.315k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:41:30,705][train][INFO][train.py>_log] ==> #490000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 6.670    Value Loss: 4.664    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1017563    Buffer Size: 15794      Transition Number: 1000.362k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:44:24,486][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.154    [weighted Loss:2.154    Policy Loss: 6.661    Value Loss: 4.376    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 1019682    Buffer Size: 15790      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:47:18,696][train][INFO][train.py>_log] ==> #492000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.738    Value Loss: 4.145    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1021884    Buffer Size: 15806      Transition Number: 1000.260k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:50:12,341][train][INFO][train.py>_log] ==> #493000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 6.609    Value Loss: 4.285    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1024029    Buffer Size: 15815      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:53:07,524][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 6.882    Value Loss: 4.306    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1026218    Buffer Size: 15842      Transition Number: 1000.412k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:56:00,526][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 6.293    Value Loss: 4.386    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1028434    Buffer Size: 15864      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:58:55,331][train][INFO][train.py>_log] ==> #496000     Total Loss: 1.913    [weighted Loss:1.913    Policy Loss: 6.760    Value Loss: 4.327    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030665    Buffer Size: 15901      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:01:51,317][train][INFO][train.py>_log] ==> #497000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 6.577    Value Loss: 4.452    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032909    Buffer Size: 15917      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:04:47,787][train][INFO][train.py>_log] ==> #498000     Total Loss: 3.169    [weighted Loss:3.169    Policy Loss: 7.106    Value Loss: 4.267    Reward Loss: 1.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035200    Buffer Size: 15932      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:07:42,485][train][INFO][train.py>_log] ==> #499000     Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 6.421    Value Loss: 4.349    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1037332    Buffer Size: 15927      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:10:35,551][train][INFO][train.py>_log] ==> #500000     Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 6.894    Value Loss: 4.291    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1039551    Buffer Size: 15924      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:13:30,212][train][INFO][train.py>_log] ==> #501000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.715    Value Loss: 4.710    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1041766    Buffer Size: 15918      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:16:23,072][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 6.586    Value Loss: 4.292    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043929    Buffer Size: 15925      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:19:19,718][train][INFO][train.py>_log] ==> #503000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 6.633    Value Loss: 4.254    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1046164    Buffer Size: 15920      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:22:11,444][train][INFO][train.py>_log] ==> #504000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 6.465    Value Loss: 4.628    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048336    Buffer Size: 15925      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:25:05,607][train][INFO][train.py>_log] ==> #505000     Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 6.541    Value Loss: 4.130    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1050520    Buffer Size: 15925      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:28:00,429][train][INFO][train.py>_log] ==> #506000     Total Loss: 1.161    [weighted Loss:1.161    Policy Loss: 6.955    Value Loss: 4.237    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1052681    Buffer Size: 15922      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:30:53,126][train][INFO][train.py>_log] ==> #507000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 6.769    Value Loss: 4.329    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1054828    Buffer Size: 15907      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:33:45,611][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 6.945    Value Loss: 4.219    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 1056986    Buffer Size: 15912      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:36:39,830][train][INFO][train.py>_log] ==> #509000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 6.839    Value Loss: 4.611    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1059141    Buffer Size: 15910      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:39:29,914][train][INFO][train.py>_log] ==> #510000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.913    Value Loss: 4.453    Reward Loss: 1.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 1061280    Buffer Size: 15885      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:42:25,190][train][INFO][train.py>_log] ==> #511000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 7.187    Value Loss: 4.475    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063475    Buffer Size: 15866      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:45:17,443][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 6.933    Value Loss: 4.653    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 1065622    Buffer Size: 15852      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:48:09,790][train][INFO][train.py>_log] ==> #513000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 7.333    Value Loss: 4.801    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1067819    Buffer Size: 15842      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:51:02,181][train][INFO][train.py>_log] ==> #514000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 7.259    Value Loss: 4.211    Reward Loss: 1.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069979    Buffer Size: 15837      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:53:56,162][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 7.533    Value Loss: 4.495    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1072105    Buffer Size: 15823      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:56:51,699][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 7.478    Value Loss: 4.193    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1074313    Buffer Size: 15820      Transition Number: 1000.493k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:59:49,285][train][INFO][train.py>_log] ==> #517000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 7.419    Value Loss: 4.449    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076549    Buffer Size: 15817      Transition Number: 1000.272k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:02:41,037][train][INFO][train.py>_log] ==> #518000     Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 7.833    Value Loss: 4.367    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1078602    Buffer Size: 15815      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:05:33,360][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 7.587    Value Loss: 4.576    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1080743    Buffer Size: 15830      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:08:27,744][train][INFO][train.py>_log] ==> #520000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 7.927    Value Loss: 4.312    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1082959    Buffer Size: 15842      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:11:22,331][train][INFO][train.py>_log] ==> #521000     Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 7.710    Value Loss: 4.306    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1085148    Buffer Size: 15861      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:14:15,808][train][INFO][train.py>_log] ==> #522000     Total Loss: 3.263    [weighted Loss:3.263    Policy Loss: 8.325    Value Loss: 4.439    Reward Loss: 1.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 1087271    Buffer Size: 15891      Transition Number: 1000.501k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:17:08,427][train][INFO][train.py>_log] ==> #523000     Total Loss: 3.969    [weighted Loss:3.969    Policy Loss: 8.224    Value Loss: 4.371    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089410    Buffer Size: 15891      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:20:01,524][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.125    [weighted Loss:2.125    Policy Loss: 8.170    Value Loss: 4.705    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1091616    Buffer Size: 15910      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:22:55,516][train][INFO][train.py>_log] ==> #525000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 7.949    Value Loss: 4.564    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1093726    Buffer Size: 15899      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:25:51,520][train][INFO][train.py>_log] ==> #526000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 7.530    Value Loss: 4.523    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1095977    Buffer Size: 15895      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:28:46,483][train][INFO][train.py>_log] ==> #527000     Total Loss: 3.600    [weighted Loss:3.600    Policy Loss: 7.521    Value Loss: 4.666    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098116    Buffer Size: 15919      Transition Number: 1000.202k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:31:38,995][train][INFO][train.py>_log] ==> #528000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 7.768    Value Loss: 4.633    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100264    Buffer Size: 15909      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:34:33,485][train][INFO][train.py>_log] ==> #529000     Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 7.719    Value Loss: 4.696    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1102461    Buffer Size: 15920      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:37:27,796][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 7.853    Value Loss: 4.311    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 1104626    Buffer Size: 15946      Transition Number: 1000.144k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:40:23,390][train][INFO][train.py>_log] ==> #531000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 8.042    Value Loss: 4.211    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1106802    Buffer Size: 15956      Transition Number: 1000.077k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:43:17,499][train][INFO][train.py>_log] ==> #532000     Total Loss: 2.723    [weighted Loss:2.723    Policy Loss: 8.112    Value Loss: 4.316    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1109008    Buffer Size: 15981      Transition Number: 1000.118k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:46:13,213][train][INFO][train.py>_log] ==> #533000     Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 7.749    Value Loss: 4.440    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111176    Buffer Size: 15999      Transition Number: 1000.299k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:49:09,129][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 8.022    Value Loss: 4.988    Reward Loss: 1.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113410    Buffer Size: 15988      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:52:03,206][train][INFO][train.py>_log] ==> #535000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 7.888    Value Loss: 4.475    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1115624    Buffer Size: 16002      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:54:57,232][train][INFO][train.py>_log] ==> #536000     Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 7.886    Value Loss: 4.523    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117795    Buffer Size: 15998      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:57:53,915][train][INFO][train.py>_log] ==> #537000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 7.611    Value Loss: 4.595    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1120037    Buffer Size: 15982      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:00:47,022][train][INFO][train.py>_log] ==> #538000     Total Loss: 0.964    [weighted Loss:0.964    Policy Loss: 7.670    Value Loss: 4.522    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1122183    Buffer Size: 15980      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:03:41,479][train][INFO][train.py>_log] ==> #539000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 7.882    Value Loss: 4.351    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1124320    Buffer Size: 15954      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:06:37,442][train][INFO][train.py>_log] ==> #540000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 7.975    Value Loss: 4.337    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126535    Buffer Size: 15948      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:09:33,947][train][INFO][train.py>_log] ==> #541000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 7.842    Value Loss: 4.551    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128732    Buffer Size: 15932      Transition Number: 1000.294k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:12:29,830][train][INFO][train.py>_log] ==> #542000     Total Loss: 0.994    [weighted Loss:0.994    Policy Loss: 7.544    Value Loss: 4.446    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1130956    Buffer Size: 15899      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:15:24,932][train][INFO][train.py>_log] ==> #543000     Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 7.513    Value Loss: 4.440    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133216    Buffer Size: 15883      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:18:18,077][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 7.404    Value Loss: 4.660    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135327    Buffer Size: 15877      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:21:12,113][train][INFO][train.py>_log] ==> #545000     Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 7.754    Value Loss: 4.553    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1137565    Buffer Size: 15871      Transition Number: 1000.335k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:24:08,283][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 7.160    Value Loss: 4.473    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139777    Buffer Size: 15872      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:27:03,987][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 7.345    Value Loss: 4.444    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1141974    Buffer Size: 15883      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:29:59,237][train][INFO][train.py>_log] ==> #548000     Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 7.306    Value Loss: 4.424    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144211    Buffer Size: 15909      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:32:54,299][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 7.285    Value Loss: 4.983    Reward Loss: 1.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 1146421    Buffer Size: 15937      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:35:51,345][train][INFO][train.py>_log] ==> #550000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 7.390    Value Loss: 4.321    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 1148650    Buffer Size: 15967      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:38:45,375][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 7.710    Value Loss: 4.218    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1150832    Buffer Size: 15984      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:41:36,040][train][INFO][train.py>_log] ==> #552000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 7.745    Value Loss: 4.260    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152948    Buffer Size: 15998      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:44:27,566][train][INFO][train.py>_log] ==> #553000     Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 7.578    Value Loss: 4.374    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1155075    Buffer Size: 16006      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:47:25,064][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 8.102    Value Loss: 4.646    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 1157291    Buffer Size: 16001      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:50:16,936][train][INFO][train.py>_log] ==> #555000     Total Loss: 2.336    [weighted Loss:2.336    Policy Loss: 7.973    Value Loss: 4.353    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1159451    Buffer Size: 15991      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:53:10,084][train][INFO][train.py>_log] ==> #556000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 7.878    Value Loss: 4.645    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1161660    Buffer Size: 15984      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:56:05,781][train][INFO][train.py>_log] ==> #557000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 8.116    Value Loss: 4.275    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1163876    Buffer Size: 15963      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:58:57,954][train][INFO][train.py>_log] ==> #558000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 7.782    Value Loss: 4.605    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 1166022    Buffer Size: 15961      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:01:54,722][train][INFO][train.py>_log] ==> #559000     Total Loss: 1.213    [weighted Loss:1.213    Policy Loss: 8.007    Value Loss: 4.393    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 1168233    Buffer Size: 15940      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:04:48,956][train][INFO][train.py>_log] ==> #560000     Total Loss: 3.219    [weighted Loss:3.219    Policy Loss: 7.763    Value Loss: 4.838    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1170444    Buffer Size: 15921      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:07:42,415][train][INFO][train.py>_log] ==> #561000     Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 7.843    Value Loss: 4.596    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 1172538    Buffer Size: 15893      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:10:35,322][train][INFO][train.py>_log] ==> #562000     Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 8.203    Value Loss: 4.613    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 1174674    Buffer Size: 15878      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:13:29,246][train][INFO][train.py>_log] ==> #563000     Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 8.287    Value Loss: 4.418    Reward Loss: 1.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 1176884    Buffer Size: 15843      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:16:23,988][train][INFO][train.py>_log] ==> #564000     Total Loss: 2.767    [weighted Loss:2.767    Policy Loss: 7.515    Value Loss: 4.437    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1179046    Buffer Size: 15799      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:19:20,744][train][INFO][train.py>_log] ==> #565000     Total Loss: 2.487    [weighted Loss:2.487    Policy Loss: 7.672    Value Loss: 4.424    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1181224    Buffer Size: 15780      Transition Number: 1000.240k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:22:16,741][train][INFO][train.py>_log] ==> #566000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 7.641    Value Loss: 4.640    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1183480    Buffer Size: 15759      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:25:09,656][train][INFO][train.py>_log] ==> #567000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 7.940    Value Loss: 4.554    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1185635    Buffer Size: 15761      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:28:04,256][train][INFO][train.py>_log] ==> #568000     Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 7.545    Value Loss: 4.317    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1187840    Buffer Size: 15786      Transition Number: 1000.542k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:31:01,294][train][INFO][train.py>_log] ==> #569000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 7.646    Value Loss: 4.499    Reward Loss: 1.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 1190066    Buffer Size: 15794      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:33:54,453][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.864    [weighted Loss:2.864    Policy Loss: 8.034    Value Loss: 4.073    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1192287    Buffer Size: 15814      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:36:50,870][train][INFO][train.py>_log] ==> #571000     Total Loss: 1.079    [weighted Loss:1.079    Policy Loss: 7.729    Value Loss: 4.131    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 1194500    Buffer Size: 15843      Transition Number: 1000.233k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:39:48,251][train][INFO][train.py>_log] ==> #572000     Total Loss: 3.731    [weighted Loss:3.731    Policy Loss: 7.562    Value Loss: 4.236    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1196712    Buffer Size: 15860      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:42:44,124][train][INFO][train.py>_log] ==> #573000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 7.954    Value Loss: 4.363    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1198900    Buffer Size: 15884      Transition Number: 1000.264k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:45:37,369][train][INFO][train.py>_log] ==> #574000     Total Loss: 3.516    [weighted Loss:3.516    Policy Loss: 7.804    Value Loss: 4.653    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 1201068    Buffer Size: 15889      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:48:31,704][train][INFO][train.py>_log] ==> #575000     Total Loss: 3.432    [weighted Loss:3.432    Policy Loss: 7.863    Value Loss: 4.448    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1203231    Buffer Size: 15906      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:51:24,349][train][INFO][train.py>_log] ==> #576000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 8.343    Value Loss: 4.350    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1205466    Buffer Size: 15929      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:54:20,161][train][INFO][train.py>_log] ==> #577000     Total Loss: 2.800    [weighted Loss:2.800    Policy Loss: 8.250    Value Loss: 4.330    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1207655    Buffer Size: 15941      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:57:17,590][train][INFO][train.py>_log] ==> #578000     Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 7.752    Value Loss: 4.768    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1209896    Buffer Size: 15965      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:00:14,499][train][INFO][train.py>_log] ==> #579000     Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 8.136    Value Loss: 4.494    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 1212138    Buffer Size: 16001      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:03:13,278][train][INFO][train.py>_log] ==> #580000     Total Loss: 3.502    [weighted Loss:3.502    Policy Loss: 8.509    Value Loss: 4.563    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1214398    Buffer Size: 16034      Transition Number: 1000.213k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:06:10,280][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 8.129    Value Loss: 4.620    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216647    Buffer Size: 16064      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:09:08,662][train][INFO][train.py>_log] ==> #582000     Total Loss: 2.312    [weighted Loss:2.312    Policy Loss: 8.792    Value Loss: 4.692    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218865    Buffer Size: 16066      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:12:08,026][train][INFO][train.py>_log] ==> #583000     Total Loss: 2.994    [weighted Loss:2.994    Policy Loss: 8.009    Value Loss: 4.570    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1221137    Buffer Size: 16077      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:15:05,112][train][INFO][train.py>_log] ==> #584000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 8.149    Value Loss: 4.225    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223338    Buffer Size: 16091      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:18:04,525][train][INFO][train.py>_log] ==> #585000     Total Loss: 4.370    [weighted Loss:4.370    Policy Loss: 8.535    Value Loss: 4.607    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225594    Buffer Size: 16090      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:21:03,761][train][INFO][train.py>_log] ==> #586000     Total Loss: 3.326    [weighted Loss:3.326    Policy Loss: 8.098    Value Loss: 4.254    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 1227874    Buffer Size: 16098      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:24:03,814][train][INFO][train.py>_log] ==> #587000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 8.162    Value Loss: 4.462    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1230147    Buffer Size: 16089      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:27:04,398][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 8.418    Value Loss: 4.639    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1232415    Buffer Size: 16061      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:30:02,458][train][INFO][train.py>_log] ==> #589000     Total Loss: 3.325    [weighted Loss:3.325    Policy Loss: 8.472    Value Loss: 4.394    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1234701    Buffer Size: 16065      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:33:01,635][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 8.402    Value Loss: 4.438    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1237005    Buffer Size: 16059      Transition Number: 1000.194k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:36:00,322][train][INFO][train.py>_log] ==> #591000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 8.361    Value Loss: 4.546    Reward Loss: 1.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 1239211    Buffer Size: 16029      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:39:00,702][train][INFO][train.py>_log] ==> #592000     Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 7.939    Value Loss: 4.309    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241476    Buffer Size: 16015      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:41:58,649][train][INFO][train.py>_log] ==> #593000     Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 8.764    Value Loss: 4.445    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1243759    Buffer Size: 15995      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:44:59,171][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.931    [weighted Loss:2.931    Policy Loss: 8.505    Value Loss: 4.349    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1245997    Buffer Size: 15965      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:48:00,034][train][INFO][train.py>_log] ==> #595000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 8.527    Value Loss: 4.553    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1248259    Buffer Size: 15954      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:50:59,274][train][INFO][train.py>_log] ==> #596000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 8.198    Value Loss: 4.161    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 1250506    Buffer Size: 15951      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:53:55,202][train][INFO][train.py>_log] ==> #597000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 8.654    Value Loss: 4.630    Reward Loss: 1.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252686    Buffer Size: 15908      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:56:56,284][train][INFO][train.py>_log] ==> #598000     Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 8.824    Value Loss: 4.486    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1254969    Buffer Size: 15896      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:59:54,683][train][INFO][train.py>_log] ==> #599000     Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 8.605    Value Loss: 4.370    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1257143    Buffer Size: 15875      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-20 13:02:52,384][train][INFO][train.py>_log] ==> #600000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 8.512    Value Loss: 4.404    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1259424    Buffer Size: 15836      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 13:05:52,070][train][INFO][train.py>_log] ==> #601000     Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 8.577    Value Loss: 4.747    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1261673    Buffer Size: 15817      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:08:52,691][train][INFO][train.py>_log] ==> #602000     Total Loss: 3.540    [weighted Loss:3.540    Policy Loss: 9.254    Value Loss: 4.559    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 1263927    Buffer Size: 15778      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:11:51,830][train][INFO][train.py>_log] ==> #603000     Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 8.468    Value Loss: 4.520    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266157    Buffer Size: 15704      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:14:50,892][train][INFO][train.py>_log] ==> #604000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 8.916    Value Loss: 4.397    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1268401    Buffer Size: 15679      Transition Number: 1000.336k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:17:48,334][train][INFO][train.py>_log] ==> #605000     Total Loss: 2.875    [weighted Loss:2.875    Policy Loss: 8.661    Value Loss: 4.417    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1270645    Buffer Size: 15640      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:20:44,110][train][INFO][train.py>_log] ==> #606000     Total Loss: 4.140    [weighted Loss:4.140    Policy Loss: 8.708    Value Loss: 4.422    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1272828    Buffer Size: 15601      Transition Number: 1000.180k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:23:40,585][train][INFO][train.py>_log] ==> #607000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 8.493    Value Loss: 4.413    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1275092    Buffer Size: 15557      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:26:37,456][train][INFO][train.py>_log] ==> #608000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 8.452    Value Loss: 4.359    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1277318    Buffer Size: 15511      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:29:38,021][train][INFO][train.py>_log] ==> #609000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 8.946    Value Loss: 4.269    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1279567    Buffer Size: 15476      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:32:37,996][train][INFO][train.py>_log] ==> #610000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 8.825    Value Loss: 4.308    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1281865    Buffer Size: 15440      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:35:37,889][train][INFO][train.py>_log] ==> #611000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 8.978    Value Loss: 4.307    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1284088    Buffer Size: 15399      Transition Number: 1000.120k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:38:35,304][train][INFO][train.py>_log] ==> #612000     Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 8.794    Value Loss: 4.379    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 1286288    Buffer Size: 15354      Transition Number: 1000.068k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:41:36,827][train][INFO][train.py>_log] ==> #613000     Total Loss: 3.264    [weighted Loss:3.264    Policy Loss: 8.688    Value Loss: 4.342    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1288602    Buffer Size: 15324      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:44:38,278][train][INFO][train.py>_log] ==> #614000     Total Loss: 3.545    [weighted Loss:3.545    Policy Loss: 8.744    Value Loss: 4.553    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1290894    Buffer Size: 15297      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:47:34,761][train][INFO][train.py>_log] ==> #615000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 8.576    Value Loss: 4.423    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1293048    Buffer Size: 15279      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:50:30,354][train][INFO][train.py>_log] ==> #616000     Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 9.055    Value Loss: 4.441    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 1295274    Buffer Size: 15252      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:53:28,072][train][INFO][train.py>_log] ==> #617000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 8.703    Value Loss: 4.388    Reward Loss: 1.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 1297463    Buffer Size: 15236      Transition Number: 1000.016k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:56:25,590][train][INFO][train.py>_log] ==> #618000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 8.432    Value Loss: 4.222    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299657    Buffer Size: 15228      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:59:22,644][train][INFO][train.py>_log] ==> #619000     Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 8.984    Value Loss: 4.275    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1301883    Buffer Size: 15244      Transition Number: 1000.383k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:02:18,779][train][INFO][train.py>_log] ==> #620000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 8.583    Value Loss: 4.104    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304057    Buffer Size: 15232      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:05:13,431][train][INFO][train.py>_log] ==> #621000     Total Loss: 4.317    [weighted Loss:4.317    Policy Loss: 8.809    Value Loss: 4.183    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 1306259    Buffer Size: 15214      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:08:12,242][train][INFO][train.py>_log] ==> #622000     Total Loss: 3.291    [weighted Loss:3.291    Policy Loss: 8.649    Value Loss: 4.277    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1308478    Buffer Size: 15207      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:11:10,172][train][INFO][train.py>_log] ==> #623000     Total Loss: 3.923    [weighted Loss:3.923    Policy Loss: 8.237    Value Loss: 4.468    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1310697    Buffer Size: 15206      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:14:07,911][train][INFO][train.py>_log] ==> #624000     Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 8.612    Value Loss: 4.639    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1312939    Buffer Size: 15198      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:17:06,466][train][INFO][train.py>_log] ==> #625000     Total Loss: 3.403    [weighted Loss:3.403    Policy Loss: 8.950    Value Loss: 4.443    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1315130    Buffer Size: 15174      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:20:03,724][train][INFO][train.py>_log] ==> #626000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 8.748    Value Loss: 4.421    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1317344    Buffer Size: 15132      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:23:03,203][train][INFO][train.py>_log] ==> #627000     Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 8.746    Value Loss: 4.575    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1319637    Buffer Size: 15114      Transition Number: 1000.152k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:26:01,009][train][INFO][train.py>_log] ==> #628000     Total Loss: 1.046    [weighted Loss:1.046    Policy Loss: 8.557    Value Loss: 4.182    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1321860    Buffer Size: 15096      Transition Number: 1000.745k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:28:58,050][train][INFO][train.py>_log] ==> #629000     Total Loss: 3.822    [weighted Loss:3.822    Policy Loss: 9.171    Value Loss: 4.554    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1324037    Buffer Size: 15075      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:31:55,083][train][INFO][train.py>_log] ==> #630000     Total Loss: 2.577    [weighted Loss:2.577    Policy Loss: 8.833    Value Loss: 4.255    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 1326229    Buffer Size: 15070      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:34:53,156][train][INFO][train.py>_log] ==> #631000     Total Loss: 1.165    [weighted Loss:1.165    Policy Loss: 8.669    Value Loss: 4.487    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1328419    Buffer Size: 15071      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:37:50,051][train][INFO][train.py>_log] ==> #632000     Total Loss: 3.936    [weighted Loss:3.936    Policy Loss: 8.642    Value Loss: 4.512    Reward Loss: 1.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 1330614    Buffer Size: 15074      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:40:48,908][train][INFO][train.py>_log] ==> #633000     Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 8.598    Value Loss: 4.246    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332871    Buffer Size: 15097      Transition Number: 1000.511k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:43:49,234][train][INFO][train.py>_log] ==> #634000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 8.921    Value Loss: 4.481    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1335110    Buffer Size: 15097      Transition Number: 1000.284k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:46:46,252][train][INFO][train.py>_log] ==> #635000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 9.361    Value Loss: 4.419    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 1337329    Buffer Size: 15099      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:49:47,808][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 9.226    Value Loss: 4.270    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1339609    Buffer Size: 15106      Transition Number: 1000.211k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:52:48,855][train][INFO][train.py>_log] ==> #637000     Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 8.728    Value Loss: 4.179    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1341835    Buffer Size: 15099      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:55:45,755][train][INFO][train.py>_log] ==> #638000     Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 8.681    Value Loss: 4.114    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1344077    Buffer Size: 15099      Transition Number: 1000.214k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:58:43,700][train][INFO][train.py>_log] ==> #639000     Total Loss: 2.773    [weighted Loss:2.773    Policy Loss: 8.796    Value Loss: 4.307    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1346296    Buffer Size: 15093      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:01:41,945][train][INFO][train.py>_log] ==> #640000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 9.061    Value Loss: 4.404    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1348453    Buffer Size: 15083      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:04:39,331][train][INFO][train.py>_log] ==> #641000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 8.789    Value Loss: 4.485    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350640    Buffer Size: 15074      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:07:42,165][train][INFO][train.py>_log] ==> #642000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 8.743    Value Loss: 4.231    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 1352900    Buffer Size: 15082      Transition Number: 1000.232k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:10:39,620][train][INFO][train.py>_log] ==> #643000     Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 8.764    Value Loss: 4.270    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1355126    Buffer Size: 15083      Transition Number: 1000.102k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:13:42,979][train][INFO][train.py>_log] ==> #644000     Total Loss: 1.086    [weighted Loss:1.086    Policy Loss: 8.736    Value Loss: 4.291    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 1357386    Buffer Size: 15096      Transition Number: 1000.158k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:16:40,762][train][INFO][train.py>_log] ==> #645000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 8.725    Value Loss: 4.291    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 1359682    Buffer Size: 15101      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:19:41,166][train][INFO][train.py>_log] ==> #646000     Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 8.761    Value Loss: 4.489    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 1361846    Buffer Size: 15106      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:22:40,739][train][INFO][train.py>_log] ==> #647000     Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 8.742    Value Loss: 4.513    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1364176    Buffer Size: 15115      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:25:39,259][train][INFO][train.py>_log] ==> #648000     Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 9.013    Value Loss: 4.200    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1366355    Buffer Size: 15130      Transition Number: 1000.038k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:28:38,443][train][INFO][train.py>_log] ==> #649000     Total Loss: 4.185    [weighted Loss:4.185    Policy Loss: 9.238    Value Loss: 4.186    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1368603    Buffer Size: 15125      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:31:38,432][train][INFO][train.py>_log] ==> #650000     Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 8.873    Value Loss: 4.479    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370869    Buffer Size: 15121      Transition Number: 1000.490k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:34:36,381][train][INFO][train.py>_log] ==> #651000     Total Loss: 3.088    [weighted Loss:3.088    Policy Loss: 9.003    Value Loss: 4.160    Reward Loss: 1.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373076    Buffer Size: 15109      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:37:33,029][train][INFO][train.py>_log] ==> #652000     Total Loss: 3.248    [weighted Loss:3.248    Policy Loss: 8.802    Value Loss: 4.135    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375277    Buffer Size: 15090      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:40:31,402][train][INFO][train.py>_log] ==> #653000     Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 8.521    Value Loss: 4.227    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1377530    Buffer Size: 15094      Transition Number: 1000.238k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:43:28,432][train][INFO][train.py>_log] ==> #654000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 8.404    Value Loss: 4.254    Reward Loss: 2.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 1379728    Buffer Size: 15068      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:46:27,968][train][INFO][train.py>_log] ==> #655000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 9.094    Value Loss: 4.481    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1381945    Buffer Size: 15066      Transition Number: 1000.321k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:49:24,020][train][INFO][train.py>_log] ==> #656000     Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 8.797    Value Loss: 4.303    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1384131    Buffer Size: 15050      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:52:24,544][train][INFO][train.py>_log] ==> #657000     Total Loss: 3.764    [weighted Loss:3.764    Policy Loss: 9.346    Value Loss: 4.541    Reward Loss: 1.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 1386390    Buffer Size: 15077      Transition Number: 1000.297k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:55:26,288][train][INFO][train.py>_log] ==> #658000     Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 9.423    Value Loss: 4.360    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 1388674    Buffer Size: 15088      Transition Number: 1000.315k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:58:23,240][train][INFO][train.py>_log] ==> #659000     Total Loss: 3.372    [weighted Loss:3.372    Policy Loss: 9.012    Value Loss: 4.509    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1390896    Buffer Size: 15124      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:01:18,619][train][INFO][train.py>_log] ==> #660000     Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 8.834    Value Loss: 4.430    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1393071    Buffer Size: 15148      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:04:19,708][train][INFO][train.py>_log] ==> #661000     Total Loss: 3.033    [weighted Loss:3.033    Policy Loss: 9.078    Value Loss: 4.192    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1395294    Buffer Size: 15176      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:07:20,944][train][INFO][train.py>_log] ==> #662000     Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 8.811    Value Loss: 4.301    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 1397556    Buffer Size: 15202      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:10:18,404][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 8.904    Value Loss: 4.449    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 1399777    Buffer Size: 15223      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:13:21,424][train][INFO][train.py>_log] ==> #664000     Total Loss: 1.086    [weighted Loss:1.086    Policy Loss: 8.730    Value Loss: 4.351    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1402115    Buffer Size: 15237      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:16:20,968][train][INFO][train.py>_log] ==> #665000     Total Loss: 3.635    [weighted Loss:3.635    Policy Loss: 8.912    Value Loss: 4.701    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1404348    Buffer Size: 15247      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:19:18,222][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 8.628    Value Loss: 4.192    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406568    Buffer Size: 15236      Transition Number: 1000.207k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:22:16,934][train][INFO][train.py>_log] ==> #667000     Total Loss: 3.504    [weighted Loss:3.504    Policy Loss: 9.153    Value Loss: 4.282    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1408791    Buffer Size: 15246      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:25:19,932][train][INFO][train.py>_log] ==> #668000     Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 8.924    Value Loss: 4.305    Reward Loss: 1.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411070    Buffer Size: 15267      Transition Number: 1000.595k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:28:17,813][train][INFO][train.py>_log] ==> #669000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 9.104    Value Loss: 4.505    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1413317    Buffer Size: 15267      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:31:17,023][train][INFO][train.py>_log] ==> #670000     Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 8.925    Value Loss: 4.462    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1415589    Buffer Size: 15291      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:34:15,771][train][INFO][train.py>_log] ==> #671000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 9.103    Value Loss: 4.251    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1417864    Buffer Size: 15299      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:37:17,085][train][INFO][train.py>_log] ==> #672000     Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 9.443    Value Loss: 4.460    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1420132    Buffer Size: 15320      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:40:15,960][train][INFO][train.py>_log] ==> #673000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 9.366    Value Loss: 4.623    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 1422343    Buffer Size: 15329      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:43:15,508][train][INFO][train.py>_log] ==> #674000     Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 9.357    Value Loss: 4.168    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424590    Buffer Size: 15319      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:46:15,234][train][INFO][train.py>_log] ==> #675000     Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 8.896    Value Loss: 4.632    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1426865    Buffer Size: 15317      Transition Number: 1000.250k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:49:15,681][train][INFO][train.py>_log] ==> #676000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 9.441    Value Loss: 4.215    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1429099    Buffer Size: 15300      Transition Number: 1000.218k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:52:16,541][train][INFO][train.py>_log] ==> #677000     Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 9.152    Value Loss: 4.182    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 1431400    Buffer Size: 15276      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:55:13,654][train][INFO][train.py>_log] ==> #678000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 9.077    Value Loss: 4.545    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1433612    Buffer Size: 15261      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:58:14,981][train][INFO][train.py>_log] ==> #679000     Total Loss: 1.283    [weighted Loss:1.283    Policy Loss: 9.196    Value Loss: 4.301    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435891    Buffer Size: 15241      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:01:15,739][train][INFO][train.py>_log] ==> #680000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 9.193    Value Loss: 4.528    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1438176    Buffer Size: 15224      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:04:14,690][train][INFO][train.py>_log] ==> #681000     Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 9.377    Value Loss: 4.437    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440449    Buffer Size: 15212      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:07:11,922][train][INFO][train.py>_log] ==> #682000     Total Loss: 3.278    [weighted Loss:3.278    Policy Loss: 8.944    Value Loss: 4.322    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 1442669    Buffer Size: 15205      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:10:09,061][train][INFO][train.py>_log] ==> #683000     Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 9.268    Value Loss: 4.195    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1444892    Buffer Size: 15203      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:13:09,604][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 8.969    Value Loss: 4.128    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1447165    Buffer Size: 15189      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:16:08,451][train][INFO][train.py>_log] ==> #685000     Total Loss: 3.338    [weighted Loss:3.338    Policy Loss: 9.338    Value Loss: 4.123    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1449411    Buffer Size: 15181      Transition Number: 1000.317k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:19:07,765][train][INFO][train.py>_log] ==> #686000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 9.688    Value Loss: 4.529    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451638    Buffer Size: 15159      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:22:08,928][train][INFO][train.py>_log] ==> #687000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 9.311    Value Loss: 4.585    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1453906    Buffer Size: 15148      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:25:11,718][train][INFO][train.py>_log] ==> #688000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 9.366    Value Loss: 4.589    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1456181    Buffer Size: 15122      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:28:08,977][train][INFO][train.py>_log] ==> #689000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 8.989    Value Loss: 4.732    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1458436    Buffer Size: 15118      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:31:07,864][train][INFO][train.py>_log] ==> #690000     Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 9.162    Value Loss: 4.245    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1460694    Buffer Size: 15112      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:34:10,390][train][INFO][train.py>_log] ==> #691000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 9.714    Value Loss: 4.396    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1462991    Buffer Size: 15109      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:37:09,312][train][INFO][train.py>_log] ==> #692000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 9.395    Value Loss: 4.121    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1465221    Buffer Size: 15093      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:40:08,975][train][INFO][train.py>_log] ==> #693000     Total Loss: 1.424    [weighted Loss:1.424    Policy Loss: 8.754    Value Loss: 4.248    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1467545    Buffer Size: 15093      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:43:07,618][train][INFO][train.py>_log] ==> #694000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 9.342    Value Loss: 4.275    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1469734    Buffer Size: 15088      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:46:09,032][train][INFO][train.py>_log] ==> #695000     Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 9.364    Value Loss: 4.505    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 1472022    Buffer Size: 15100      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:49:07,127][train][INFO][train.py>_log] ==> #696000     Total Loss: 1.045    [weighted Loss:1.045    Policy Loss: 9.187    Value Loss: 4.454    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1474272    Buffer Size: 15086      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:52:07,230][train][INFO][train.py>_log] ==> #697000     Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 9.662    Value Loss: 4.504    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1476554    Buffer Size: 15056      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:55:09,868][train][INFO][train.py>_log] ==> #698000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 9.221    Value Loss: 4.334    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 1478852    Buffer Size: 15048      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:58:10,007][train][INFO][train.py>_log] ==> #699000     Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 9.353    Value Loss: 4.353    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1481099    Buffer Size: 15054      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:01:09,343][train][INFO][train.py>_log] ==> #700000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 9.207    Value Loss: 4.355    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1483345    Buffer Size: 15053      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:04:08,363][train][INFO][train.py>_log] ==> #701000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 9.782    Value Loss: 4.350    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485600    Buffer Size: 15054      Transition Number: 1000.646k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:07:10,195][train][INFO][train.py>_log] ==> #702000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 9.520    Value Loss: 4.457    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1487859    Buffer Size: 15060      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:10:08,591][train][INFO][train.py>_log] ==> #703000     Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 9.434    Value Loss: 4.448    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1490073    Buffer Size: 15056      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:13:07,529][train][INFO][train.py>_log] ==> #704000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 9.002    Value Loss: 4.228    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1492309    Buffer Size: 15065      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:16:08,512][train][INFO][train.py>_log] ==> #705000     Total Loss: 4.466    [weighted Loss:4.466    Policy Loss: 9.625    Value Loss: 4.496    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1494547    Buffer Size: 15070      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:19:08,777][train][INFO][train.py>_log] ==> #706000     Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 9.626    Value Loss: 4.419    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 1496837    Buffer Size: 15088      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:22:11,530][train][INFO][train.py>_log] ==> #707000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 9.400    Value Loss: 4.610    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1499165    Buffer Size: 15103      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:25:12,566][train][INFO][train.py>_log] ==> #708000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 9.349    Value Loss: 4.976    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1501444    Buffer Size: 15106      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:28:12,224][train][INFO][train.py>_log] ==> #709000     Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 9.508    Value Loss: 4.438    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1503673    Buffer Size: 15105      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:31:13,123][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 9.578    Value Loss: 4.824    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1505933    Buffer Size: 15105      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:34:15,928][train][INFO][train.py>_log] ==> #711000     Total Loss: 3.726    [weighted Loss:3.726    Policy Loss: 9.519    Value Loss: 4.550    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1508228    Buffer Size: 15113      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:37:19,420][train][INFO][train.py>_log] ==> #712000     Total Loss: 1.673    [weighted Loss:1.673    Policy Loss: 10.052   Value Loss: 4.335    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1510527    Buffer Size: 15100      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:40:20,730][train][INFO][train.py>_log] ==> #713000     Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 10.091   Value Loss: 4.483    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1512808    Buffer Size: 15112      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:43:21,972][train][INFO][train.py>_log] ==> #714000     Total Loss: 3.773    [weighted Loss:3.773    Policy Loss: 9.255    Value Loss: 4.579    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1515152    Buffer Size: 15099      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:46:21,899][train][INFO][train.py>_log] ==> #715000     Total Loss: 3.929    [weighted Loss:3.929    Policy Loss: 10.010   Value Loss: 4.596    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1517358    Buffer Size: 15090      Transition Number: 1000.166k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:49:24,516][train][INFO][train.py>_log] ==> #716000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 9.782    Value Loss: 4.582    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1519696    Buffer Size: 15101      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:52:25,425][train][INFO][train.py>_log] ==> #717000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 10.095   Value Loss: 4.266    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 1521956    Buffer Size: 15125      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:55:27,158][train][INFO][train.py>_log] ==> #718000     Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 9.466    Value Loss: 4.285    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524183    Buffer Size: 15138      Transition Number: 1000.311k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:58:28,335][train][INFO][train.py>_log] ==> #719000     Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 9.970    Value Loss: 4.826    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1526469    Buffer Size: 15172      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:01:28,429][train][INFO][train.py>_log] ==> #720000     Total Loss: 4.091    [weighted Loss:4.091    Policy Loss: 9.740    Value Loss: 4.645    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1528799    Buffer Size: 15176      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:04:28,654][train][INFO][train.py>_log] ==> #721000     Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 9.886    Value Loss: 4.515    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1531009    Buffer Size: 15200      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:07:28,290][train][INFO][train.py>_log] ==> #722000     Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 9.869    Value Loss: 4.047    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1533264    Buffer Size: 15216      Transition Number: 1000.205k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:10:27,184][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 10.109   Value Loss: 4.525    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1535527    Buffer Size: 15210      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:13:25,159][train][INFO][train.py>_log] ==> #724000     Total Loss: 3.657    [weighted Loss:3.657    Policy Loss: 10.209   Value Loss: 4.189    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 1537710    Buffer Size: 15212      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:16:25,669][train][INFO][train.py>_log] ==> #725000     Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 9.707    Value Loss: 4.464    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 1540015    Buffer Size: 15201      Transition Number: 1000.133k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:19:25,146][train][INFO][train.py>_log] ==> #726000     Total Loss: 3.635    [weighted Loss:3.635    Policy Loss: 9.910    Value Loss: 4.230    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1542220    Buffer Size: 15196      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:22:27,141][train][INFO][train.py>_log] ==> #727000     Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 9.712    Value Loss: 4.444    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1544500    Buffer Size: 15196      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:25:27,568][train][INFO][train.py>_log] ==> #728000     Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 10.118   Value Loss: 4.580    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1546754    Buffer Size: 15200      Transition Number: 1000.166k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:28:29,039][train][INFO][train.py>_log] ==> #729000     Total Loss: 3.539    [weighted Loss:3.539    Policy Loss: 9.822    Value Loss: 4.616    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1549001    Buffer Size: 15182      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:31:31,920][train][INFO][train.py>_log] ==> #730000     Total Loss: 3.369    [weighted Loss:3.369    Policy Loss: 9.999    Value Loss: 4.874    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 1551285    Buffer Size: 15199      Transition Number: 1000.545k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:34:32,693][train][INFO][train.py>_log] ==> #731000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 10.143   Value Loss: 4.199    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1553628    Buffer Size: 15195      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:37:31,041][train][INFO][train.py>_log] ==> #732000     Total Loss: 3.278    [weighted Loss:3.278    Policy Loss: 9.770    Value Loss: 4.355    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1555813    Buffer Size: 15190      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:40:32,147][train][INFO][train.py>_log] ==> #733000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 9.822    Value Loss: 4.645    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1558047    Buffer Size: 15183      Transition Number: 1000.128k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:43:32,191][train][INFO][train.py>_log] ==> #734000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 10.010   Value Loss: 4.283    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1560337    Buffer Size: 15186      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:46:35,514][train][INFO][train.py>_log] ==> #735000     Total Loss: 3.226    [weighted Loss:3.226    Policy Loss: 9.991    Value Loss: 4.328    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 1562638    Buffer Size: 15179      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:49:37,073][train][INFO][train.py>_log] ==> #736000     Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 10.082   Value Loss: 4.472    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1564862    Buffer Size: 15190      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:52:37,950][train][INFO][train.py>_log] ==> #737000     Total Loss: 3.529    [weighted Loss:3.529    Policy Loss: 9.448    Value Loss: 4.261    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 1567152    Buffer Size: 15185      Transition Number: 1000.095k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:55:38,068][train][INFO][train.py>_log] ==> #738000     Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 10.013   Value Loss: 4.726    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1569421    Buffer Size: 15183      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:58:44,651][train][INFO][train.py>_log] ==> #739000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 9.457    Value Loss: 4.401    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1571773    Buffer Size: 15194      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:01:46,999][train][INFO][train.py>_log] ==> #740000     Total Loss: 3.911    [weighted Loss:3.911    Policy Loss: 9.668    Value Loss: 4.610    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 1574108    Buffer Size: 15188      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:04:48,706][train][INFO][train.py>_log] ==> #741000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 9.183    Value Loss: 4.351    Reward Loss: 1.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 1576309    Buffer Size: 15190      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:07:51,226][train][INFO][train.py>_log] ==> #742000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 9.440    Value Loss: 4.521    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1578594    Buffer Size: 15194      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:10:53,121][train][INFO][train.py>_log] ==> #743000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 9.695    Value Loss: 4.456    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1580912    Buffer Size: 15192      Transition Number: 1000.342k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:13:55,093][train][INFO][train.py>_log] ==> #744000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 9.296    Value Loss: 4.411    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1583195    Buffer Size: 15195      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:16:57,662][train][INFO][train.py>_log] ==> #745000     Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 9.701    Value Loss: 4.265    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1585502    Buffer Size: 15199      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:20:02,148][train][INFO][train.py>_log] ==> #746000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 9.889    Value Loss: 4.646    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1587801    Buffer Size: 15194      Transition Number: 1000.271k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:23:03,808][train][INFO][train.py>_log] ==> #747000     Total Loss: 1.122    [weighted Loss:1.122    Policy Loss: 9.800    Value Loss: 4.602    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 1590081    Buffer Size: 15212      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:26:02,958][train][INFO][train.py>_log] ==> #748000     Total Loss: 2.992    [weighted Loss:2.992    Policy Loss: 9.620    Value Loss: 4.750    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1592304    Buffer Size: 15222      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:29:06,628][train][INFO][train.py>_log] ==> #749000     Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 10.016   Value Loss: 4.682    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1594598    Buffer Size: 15218      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:32:06,417][train][INFO][train.py>_log] ==> #750000     Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 9.791    Value Loss: 4.370    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 1596883    Buffer Size: 15224      Transition Number: 1000.285k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:35:10,732][train][INFO][train.py>_log] ==> #751000     Total Loss: 3.383    [weighted Loss:3.383    Policy Loss: 9.798    Value Loss: 4.287    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1599154    Buffer Size: 15225      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:38:12,817][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.356    [weighted Loss:1.356    Policy Loss: 9.920    Value Loss: 4.759    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1601403    Buffer Size: 15231      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:41:14,682][train][INFO][train.py>_log] ==> #753000     Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 9.448    Value Loss: 4.705    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1603732    Buffer Size: 15215      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:44:18,044][train][INFO][train.py>_log] ==> #754000     Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 9.736    Value Loss: 4.644    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1606010    Buffer Size: 15227      Transition Number: 1000.364k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:47:20,460][train][INFO][train.py>_log] ==> #755000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 9.798    Value Loss: 4.566    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1608330    Buffer Size: 15228      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:50:19,044][train][INFO][train.py>_log] ==> #756000     Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 9.673    Value Loss: 4.434    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 1610549    Buffer Size: 15251      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:53:19,756][train][INFO][train.py>_log] ==> #757000     Total Loss: 2.112    [weighted Loss:2.112    Policy Loss: 10.005   Value Loss: 4.662    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1612791    Buffer Size: 15258      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:56:24,126][train][INFO][train.py>_log] ==> #758000     Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 9.602    Value Loss: 4.782    Reward Loss: 1.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 1615064    Buffer Size: 15254      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:59:24,419][train][INFO][train.py>_log] ==> #759000     Total Loss: 3.806    [weighted Loss:3.806    Policy Loss: 9.865    Value Loss: 4.412    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 1617364    Buffer Size: 15249      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:02:30,626][train][INFO][train.py>_log] ==> #760000     Total Loss: 2.240    [weighted Loss:2.240    Policy Loss: 9.606    Value Loss: 4.389    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 1619721    Buffer Size: 15257      Transition Number: 1000.487k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:05:34,609][train][INFO][train.py>_log] ==> #761000     Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 9.429    Value Loss: 4.467    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1622062    Buffer Size: 15233      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:08:38,410][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 9.559    Value Loss: 4.484    Reward Loss: 1.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 1624370    Buffer Size: 15206      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:11:41,219][train][INFO][train.py>_log] ==> #763000     Total Loss: 2.931    [weighted Loss:2.931    Policy Loss: 9.563    Value Loss: 4.192    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1626621    Buffer Size: 15187      Transition Number: 1000.208k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:14:42,359][train][INFO][train.py>_log] ==> #764000     Total Loss: 3.408    [weighted Loss:3.408    Policy Loss: 9.941    Value Loss: 4.412    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1628883    Buffer Size: 15160      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:17:41,513][train][INFO][train.py>_log] ==> #765000     Total Loss: 2.912    [weighted Loss:2.912    Policy Loss: 9.916    Value Loss: 4.520    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1631125    Buffer Size: 15155      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:20:42,575][train][INFO][train.py>_log] ==> #766000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 9.607    Value Loss: 4.488    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1633366    Buffer Size: 15152      Transition Number: 1000.353k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:23:43,777][train][INFO][train.py>_log] ==> #767000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 9.725    Value Loss: 4.236    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 1635631    Buffer Size: 15138      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:26:44,168][train][INFO][train.py>_log] ==> #768000     Total Loss: 3.484    [weighted Loss:3.484    Policy Loss: 9.577    Value Loss: 4.431    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1637879    Buffer Size: 15134      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:29:45,485][train][INFO][train.py>_log] ==> #769000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 9.627    Value Loss: 4.793    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 1640126    Buffer Size: 15152      Transition Number: 1000.207k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:32:49,770][train][INFO][train.py>_log] ==> #770000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 9.516    Value Loss: 4.573    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 1642482    Buffer Size: 15152      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:35:53,701][train][INFO][train.py>_log] ==> #771000     Total Loss: 3.729    [weighted Loss:3.729    Policy Loss: 9.445    Value Loss: 4.608    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1644791    Buffer Size: 15164      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:38:56,033][train][INFO][train.py>_log] ==> #772000     Total Loss: 2.756    [weighted Loss:2.756    Policy Loss: 9.371    Value Loss: 4.623    Reward Loss: 1.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 1647069    Buffer Size: 15183      Transition Number: 1000.615k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:41:58,806][train][INFO][train.py>_log] ==> #773000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 9.781    Value Loss: 4.610    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1649422    Buffer Size: 15198      Transition Number: 1000.347k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:45:02,960][train][INFO][train.py>_log] ==> #774000     Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 9.323    Value Loss: 4.428    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1651717    Buffer Size: 15207      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:48:06,079][train][INFO][train.py>_log] ==> #775000     Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 9.557    Value Loss: 4.367    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1654031    Buffer Size: 15248      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:51:09,261][train][INFO][train.py>_log] ==> #776000     Total Loss: 3.607    [weighted Loss:3.607    Policy Loss: 9.907    Value Loss: 4.449    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1656272    Buffer Size: 15273      Transition Number: 1000.183k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:54:08,933][train][INFO][train.py>_log] ==> #777000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 9.727    Value Loss: 4.439    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1658549    Buffer Size: 15286      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:57:08,655][train][INFO][train.py>_log] ==> #778000     Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 9.544    Value Loss: 4.709    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1660805    Buffer Size: 15312      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:00:10,957][train][INFO][train.py>_log] ==> #779000     Total Loss: 3.428    [weighted Loss:3.428    Policy Loss: 9.869    Value Loss: 4.224    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1663079    Buffer Size: 15345      Transition Number: 1000.339k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:03:14,030][train][INFO][train.py>_log] ==> #780000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 10.310   Value Loss: 4.216    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1665380    Buffer Size: 15362      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:06:18,035][train][INFO][train.py>_log] ==> #781000     Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 10.213   Value Loss: 4.333    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 1667722    Buffer Size: 15377      Transition Number: 1000.400k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:09:22,562][train][INFO][train.py>_log] ==> #782000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 9.734    Value Loss: 4.499    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1670036    Buffer Size: 15369      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:12:25,984][train][INFO][train.py>_log] ==> #783000     Total Loss: 2.416    [weighted Loss:2.416    Policy Loss: 10.077   Value Loss: 4.556    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1672273    Buffer Size: 15371      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:15:27,646][train][INFO][train.py>_log] ==> #784000     Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 9.972    Value Loss: 4.381    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1674549    Buffer Size: 15370      Transition Number: 1000.209k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:18:31,412][train][INFO][train.py>_log] ==> #785000     Total Loss: 1.511    [weighted Loss:1.511    Policy Loss: 10.147   Value Loss: 4.303    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1676883    Buffer Size: 15367      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:21:33,365][train][INFO][train.py>_log] ==> #786000     Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 10.273   Value Loss: 4.466    Reward Loss: 1.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 1679159    Buffer Size: 15353      Transition Number: 1000.442k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:24:34,259][train][INFO][train.py>_log] ==> #787000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 10.232   Value Loss: 4.421    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1681423    Buffer Size: 15349      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:27:37,761][train][INFO][train.py>_log] ==> #788000     Total Loss: 3.564    [weighted Loss:3.564    Policy Loss: 10.337   Value Loss: 4.607    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1683761    Buffer Size: 15343      Transition Number: 1000.405k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:30:41,761][train][INFO][train.py>_log] ==> #789000     Total Loss: 3.987    [weighted Loss:3.987    Policy Loss: 10.004   Value Loss: 4.279    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1686039    Buffer Size: 15325      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:33:44,112][train][INFO][train.py>_log] ==> #790000     Total Loss: 3.650    [weighted Loss:3.650    Policy Loss: 10.037   Value Loss: 4.195    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1688326    Buffer Size: 15331      Transition Number: 1000.236k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:36:47,764][train][INFO][train.py>_log] ==> #791000     Total Loss: 3.236    [weighted Loss:3.236    Policy Loss: 10.315   Value Loss: 4.530    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 1690646    Buffer Size: 15318      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:39:52,459][train][INFO][train.py>_log] ==> #792000     Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 10.294   Value Loss: 4.223    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 1692992    Buffer Size: 15308      Transition Number: 1000.230k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:42:55,654][train][INFO][train.py>_log] ==> #793000     Total Loss: 3.321    [weighted Loss:3.321    Policy Loss: 10.290   Value Loss: 4.247    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1695294    Buffer Size: 15287      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:45:58,975][train][INFO][train.py>_log] ==> #794000     Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 10.221   Value Loss: 4.103    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 1697622    Buffer Size: 15284      Transition Number: 1000.822k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:49:03,299][train][INFO][train.py>_log] ==> #795000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 10.112   Value Loss: 4.551    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1699906    Buffer Size: 15285      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:52:06,199][train][INFO][train.py>_log] ==> #796000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 9.923    Value Loss: 4.295    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 1702220    Buffer Size: 15277      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:55:09,436][train][INFO][train.py>_log] ==> #797000     Total Loss: 2.986    [weighted Loss:2.986    Policy Loss: 9.837    Value Loss: 4.471    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 1704516    Buffer Size: 15261      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:58:12,738][train][INFO][train.py>_log] ==> #798000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 9.719    Value Loss: 4.430    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1706867    Buffer Size: 15266      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00080 
[2022-02-20 23:01:13,062][train][INFO][train.py>_log] ==> #799000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 9.957    Value Loss: 4.339    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1709093    Buffer Size: 15273      Transition Number: 1000.297k Batch Size: 256        Lr: 0.00080 
[2022-02-20 23:04:15,040][train][INFO][train.py>_log] ==> #800000     Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 9.613    Value Loss: 4.223    Reward Loss: 1.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 1711422    Buffer Size: 15265      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00080 
[2022-02-20 23:07:20,614][train][INFO][train.py>_log] ==> #801000     Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 10.197   Value Loss: 4.347    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1713684    Buffer Size: 15244      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:10:20,917][train][INFO][train.py>_log] ==> #802000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 9.769    Value Loss: 4.490    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1715993    Buffer Size: 15225      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:13:24,622][train][INFO][train.py>_log] ==> #803000     Total Loss: 1.803    [weighted Loss:1.803    Policy Loss: 9.578    Value Loss: 4.531    Reward Loss: 1.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 1718304    Buffer Size: 15224      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:16:27,218][train][INFO][train.py>_log] ==> #804000     Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 9.884    Value Loss: 4.296    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1720606    Buffer Size: 15206      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:19:29,101][train][INFO][train.py>_log] ==> #805000     Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 9.564    Value Loss: 4.425    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 1722836    Buffer Size: 15204      Transition Number: 1000.650k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:22:31,014][train][INFO][train.py>_log] ==> #806000     Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 9.404    Value Loss: 4.687    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1725124    Buffer Size: 15165      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:25:35,567][train][INFO][train.py>_log] ==> #807000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 9.557    Value Loss: 4.601    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 1727442    Buffer Size: 15157      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:28:38,443][train][INFO][train.py>_log] ==> #808000     Total Loss: 3.150    [weighted Loss:3.150    Policy Loss: 9.554    Value Loss: 4.380    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1729712    Buffer Size: 15149      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:31:41,304][train][INFO][train.py>_log] ==> #809000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 9.384    Value Loss: 4.627    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1731988    Buffer Size: 15147      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:34:41,191][train][INFO][train.py>_log] ==> #810000     Total Loss: 2.962    [weighted Loss:2.962    Policy Loss: 9.228    Value Loss: 4.398    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1734230    Buffer Size: 15150      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:37:42,100][train][INFO][train.py>_log] ==> #811000     Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 9.056    Value Loss: 4.625    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 1736448    Buffer Size: 15154      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:40:43,482][train][INFO][train.py>_log] ==> #812000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 9.385    Value Loss: 4.318    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1738761    Buffer Size: 15140      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:43:46,571][train][INFO][train.py>_log] ==> #813000     Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 9.148    Value Loss: 4.142    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1741079    Buffer Size: 15146      Transition Number: 1000.564k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:46:48,371][train][INFO][train.py>_log] ==> #814000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 9.068    Value Loss: 4.447    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1743300    Buffer Size: 15145      Transition Number: 1000.116k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:49:53,323][train][INFO][train.py>_log] ==> #815000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 9.365    Value Loss: 4.519    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 1745605    Buffer Size: 15124      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:53:00,181][train][INFO][train.py>_log] ==> #816000     Total Loss: 1.844    [weighted Loss:1.844    Policy Loss: 8.631    Value Loss: 4.550    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1747965    Buffer Size: 15120      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:56:03,262][train][INFO][train.py>_log] ==> #817000     Total Loss: 2.129    [weighted Loss:2.129    Policy Loss: 8.920    Value Loss: 4.460    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1750261    Buffer Size: 15118      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:59:06,063][train][INFO][train.py>_log] ==> #818000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 8.860    Value Loss: 4.461    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1752570    Buffer Size: 15113      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:02:08,056][train][INFO][train.py>_log] ==> #819000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 8.847    Value Loss: 4.854    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1754827    Buffer Size: 15116      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:05:12,157][train][INFO][train.py>_log] ==> #820000     Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 8.957    Value Loss: 4.895    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1757132    Buffer Size: 15110      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:08:15,134][train][INFO][train.py>_log] ==> #821000     Total Loss: 3.186    [weighted Loss:3.186    Policy Loss: 8.840    Value Loss: 4.935    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 1759395    Buffer Size: 15113      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:11:18,066][train][INFO][train.py>_log] ==> #822000     Total Loss: 1.408    [weighted Loss:1.408    Policy Loss: 8.908    Value Loss: 4.413    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1761665    Buffer Size: 15117      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:14:21,566][train][INFO][train.py>_log] ==> #823000     Total Loss: 3.091    [weighted Loss:3.091    Policy Loss: 9.137    Value Loss: 4.306    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1763902    Buffer Size: 15128      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:17:25,761][train][INFO][train.py>_log] ==> #824000     Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 8.897    Value Loss: 4.911    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1766239    Buffer Size: 15103      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:20:28,360][train][INFO][train.py>_log] ==> #825000     Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 8.904    Value Loss: 4.647    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1768545    Buffer Size: 15099      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:23:34,275][train][INFO][train.py>_log] ==> #826000     Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 9.027    Value Loss: 4.687    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1770865    Buffer Size: 15083      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:26:34,433][train][INFO][train.py>_log] ==> #827000     Total Loss: 2.896    [weighted Loss:2.896    Policy Loss: 9.015    Value Loss: 4.710    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 1773081    Buffer Size: 15084      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:29:40,122][train][INFO][train.py>_log] ==> #828000     Total Loss: 3.746    [weighted Loss:3.746    Policy Loss: 9.093    Value Loss: 4.944    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1775442    Buffer Size: 15072      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:32:41,867][train][INFO][train.py>_log] ==> #829000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 8.843    Value Loss: 4.286    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1777717    Buffer Size: 15075      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:35:47,439][train][INFO][train.py>_log] ==> #830000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 8.595    Value Loss: 4.671    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1779991    Buffer Size: 15065      Transition Number: 1000.227k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:38:52,792][train][INFO][train.py>_log] ==> #831000     Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 8.894    Value Loss: 4.585    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1782358    Buffer Size: 15060      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:41:57,914][train][INFO][train.py>_log] ==> #832000     Total Loss: 3.438    [weighted Loss:3.438    Policy Loss: 8.969    Value Loss: 4.366    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1784647    Buffer Size: 15070      Transition Number: 1000.130k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:45:03,865][train][INFO][train.py>_log] ==> #833000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 8.737    Value Loss: 4.531    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1786953    Buffer Size: 15082      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:48:07,911][train][INFO][train.py>_log] ==> #834000     Total Loss: 3.391    [weighted Loss:3.391    Policy Loss: 9.365    Value Loss: 4.282    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1789249    Buffer Size: 15074      Transition Number: 1000.548k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:51:09,048][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 8.900    Value Loss: 4.617    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1791531    Buffer Size: 15063      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:54:17,149][train][INFO][train.py>_log] ==> #836000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 8.850    Value Loss: 4.659    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1793910    Buffer Size: 15070      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:57:22,546][train][INFO][train.py>_log] ==> #837000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 9.042    Value Loss: 4.369    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1796190    Buffer Size: 15067      Transition Number: 1000.255k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:00:30,100][train][INFO][train.py>_log] ==> #838000     Total Loss: 2.859    [weighted Loss:2.859    Policy Loss: 9.236    Value Loss: 4.278    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1798548    Buffer Size: 15053      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:03:35,170][train][INFO][train.py>_log] ==> #839000     Total Loss: 1.718    [weighted Loss:1.718    Policy Loss: 9.158    Value Loss: 4.429    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1800846    Buffer Size: 15041      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:06:39,973][train][INFO][train.py>_log] ==> #840000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 9.150    Value Loss: 4.281    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1803146    Buffer Size: 15049      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:09:41,266][train][INFO][train.py>_log] ==> #841000     Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 9.248    Value Loss: 4.399    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 1805435    Buffer Size: 15038      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:12:47,857][train][INFO][train.py>_log] ==> #842000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 8.895    Value Loss: 4.348    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 1807732    Buffer Size: 15042      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:15:56,227][train][INFO][train.py>_log] ==> #843000     Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 8.923    Value Loss: 4.539    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1810181    Buffer Size: 15046      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:18:58,332][train][INFO][train.py>_log] ==> #844000     Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 8.870    Value Loss: 4.415    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1812456    Buffer Size: 15052      Transition Number: 1000.261k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:22:01,431][train][INFO][train.py>_log] ==> #845000     Total Loss: 1.809    [weighted Loss:1.809    Policy Loss: 8.480    Value Loss: 4.416    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 1814719    Buffer Size: 15056      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:25:01,782][train][INFO][train.py>_log] ==> #846000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 9.003    Value Loss: 4.517    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1816955    Buffer Size: 15059      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:28:04,410][train][INFO][train.py>_log] ==> #847000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 8.670    Value Loss: 4.807    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 1819221    Buffer Size: 15066      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:31:10,953][train][INFO][train.py>_log] ==> #848000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 9.140    Value Loss: 4.686    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1821525    Buffer Size: 15059      Transition Number: 1000.231k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:34:14,798][train][INFO][train.py>_log] ==> #849000     Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 8.847    Value Loss: 4.400    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1823828    Buffer Size: 15057      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:37:19,676][train][INFO][train.py>_log] ==> #850000     Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 8.746    Value Loss: 4.672    Reward Loss: 1.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 1826154    Buffer Size: 15069      Transition Number: 1000.263k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:40:21,399][train][INFO][train.py>_log] ==> #851000     Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 9.038    Value Loss: 4.385    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1828437    Buffer Size: 15063      Transition Number: 1000.598k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:43:24,159][train][INFO][train.py>_log] ==> #852000     Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 8.749    Value Loss: 4.367    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1830708    Buffer Size: 15049      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:46:24,972][train][INFO][train.py>_log] ==> #853000     Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 8.937    Value Loss: 4.599    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1832923    Buffer Size: 15054      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:49:29,671][train][INFO][train.py>_log] ==> #854000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 8.735    Value Loss: 4.302    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1835209    Buffer Size: 15041      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:52:32,358][train][INFO][train.py>_log] ==> #855000     Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 8.887    Value Loss: 4.841    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1837445    Buffer Size: 15044      Transition Number: 1000.089k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:55:35,245][train][INFO][train.py>_log] ==> #856000     Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 9.036    Value Loss: 4.415    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1839740    Buffer Size: 15041      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:58:40,187][train][INFO][train.py>_log] ==> #857000     Total Loss: 0.812    [weighted Loss:0.812    Policy Loss: 8.821    Value Loss: 4.549    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 1842048    Buffer Size: 15034      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:01:41,835][train][INFO][train.py>_log] ==> #858000     Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 9.035    Value Loss: 4.774    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1844333    Buffer Size: 15041      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:04:47,081][train][INFO][train.py>_log] ==> #859000     Total Loss: 3.735    [weighted Loss:3.735    Policy Loss: 8.829    Value Loss: 4.829    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1846645    Buffer Size: 15044      Transition Number: 1000.323k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:07:53,691][train][INFO][train.py>_log] ==> #860000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 9.370    Value Loss: 4.661    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 1848939    Buffer Size: 15036      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:10:56,643][train][INFO][train.py>_log] ==> #861000     Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 9.181    Value Loss: 4.565    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1851265    Buffer Size: 15035      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:14:00,427][train][INFO][train.py>_log] ==> #862000     Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 8.867    Value Loss: 4.599    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1853548    Buffer Size: 15037      Transition Number: 1000.152k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:17:07,551][train][INFO][train.py>_log] ==> #863000     Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 9.215    Value Loss: 5.166    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1855886    Buffer Size: 15027      Transition Number: 1000.269k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:20:13,264][train][INFO][train.py>_log] ==> #864000     Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 9.100    Value Loss: 4.457    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1858229    Buffer Size: 15010      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:23:18,267][train][INFO][train.py>_log] ==> #865000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 8.874    Value Loss: 4.539    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1860520    Buffer Size: 15016      Transition Number: 1000.244k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:26:24,243][train][INFO][train.py>_log] ==> #866000     Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 8.937    Value Loss: 4.286    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1862830    Buffer Size: 15020      Transition Number: 1000.234k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:29:27,226][train][INFO][train.py>_log] ==> #867000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 9.114    Value Loss: 4.654    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1865139    Buffer Size: 15017      Transition Number: 1000.120k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:32:31,470][train][INFO][train.py>_log] ==> #868000     Total Loss: 3.280    [weighted Loss:3.280    Policy Loss: 9.433    Value Loss: 4.503    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1867415    Buffer Size: 14991      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:35:35,133][train][INFO][train.py>_log] ==> #869000     Total Loss: 2.606    [weighted Loss:2.606    Policy Loss: 8.507    Value Loss: 4.731    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1869709    Buffer Size: 14992      Transition Number: 1000.557k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:38:38,853][train][INFO][train.py>_log] ==> #870000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 9.178    Value Loss: 4.456    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1872063    Buffer Size: 14965      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:41:41,125][train][INFO][train.py>_log] ==> #871000     Total Loss: 2.232    [weighted Loss:2.232    Policy Loss: 9.412    Value Loss: 4.385    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1874320    Buffer Size: 14959      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:44:46,706][train][INFO][train.py>_log] ==> #872000     Total Loss: 3.593    [weighted Loss:3.593    Policy Loss: 8.815    Value Loss: 4.433    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1876638    Buffer Size: 14943      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:47:51,684][train][INFO][train.py>_log] ==> #873000     Total Loss: 2.841    [weighted Loss:2.841    Policy Loss: 8.847    Value Loss: 4.442    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1878933    Buffer Size: 14946      Transition Number: 1000.329k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:50:53,189][train][INFO][train.py>_log] ==> #874000     Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 9.057    Value Loss: 4.573    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 1881248    Buffer Size: 14951      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:54:01,266][train][INFO][train.py>_log] ==> #875000     Total Loss: 3.519    [weighted Loss:3.519    Policy Loss: 9.281    Value Loss: 4.841    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1883584    Buffer Size: 14958      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:57:05,289][train][INFO][train.py>_log] ==> #876000     Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 8.711    Value Loss: 4.388    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1885907    Buffer Size: 14974      Transition Number: 1000.276k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:00:08,993][train][INFO][train.py>_log] ==> #877000     Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 8.900    Value Loss: 5.120    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1888156    Buffer Size: 14971      Transition Number: 1000.153k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:03:14,303][train][INFO][train.py>_log] ==> #878000     Total Loss: 3.639    [weighted Loss:3.639    Policy Loss: 9.171    Value Loss: 4.415    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 1890526    Buffer Size: 14970      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:06:20,349][train][INFO][train.py>_log] ==> #879000     Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 8.770    Value Loss: 4.450    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1892858    Buffer Size: 14964      Transition Number: 1000.323k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:09:30,360][train][INFO][train.py>_log] ==> #880000     Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 9.205    Value Loss: 4.539    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1895277    Buffer Size: 14963      Transition Number: 1000.272k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:12:33,850][train][INFO][train.py>_log] ==> #881000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 8.781    Value Loss: 4.513    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1897608    Buffer Size: 14948      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:15:41,438][train][INFO][train.py>_log] ==> #882000     Total Loss: 1.860    [weighted Loss:1.860    Policy Loss: 8.466    Value Loss: 4.899    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1899945    Buffer Size: 14943      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:18:44,598][train][INFO][train.py>_log] ==> #883000     Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 9.207    Value Loss: 4.758    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1902185    Buffer Size: 14954      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:21:51,819][train][INFO][train.py>_log] ==> #884000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 9.012    Value Loss: 4.572    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1904551    Buffer Size: 14955      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:24:57,260][train][INFO][train.py>_log] ==> #885000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 9.124    Value Loss: 4.607    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 1906842    Buffer Size: 14970      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:28:03,453][train][INFO][train.py>_log] ==> #886000     Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 9.217    Value Loss: 4.542    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 1909208    Buffer Size: 14968      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:31:08,302][train][INFO][train.py>_log] ==> #887000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 8.812    Value Loss: 4.316    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1911498    Buffer Size: 14968      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:34:15,940][train][INFO][train.py>_log] ==> #888000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 8.981    Value Loss: 4.320    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1913831    Buffer Size: 14975      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:37:21,146][train][INFO][train.py>_log] ==> #889000     Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 8.837    Value Loss: 4.339    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1916145    Buffer Size: 14978      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:40:24,934][train][INFO][train.py>_log] ==> #890000     Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 8.993    Value Loss: 4.088    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1918458    Buffer Size: 14981      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:43:31,725][train][INFO][train.py>_log] ==> #891000     Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 8.798    Value Loss: 4.531    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 1920811    Buffer Size: 14980      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:46:36,420][train][INFO][train.py>_log] ==> #892000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 8.624    Value Loss: 4.358    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1923117    Buffer Size: 14980      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:49:40,778][train][INFO][train.py>_log] ==> #893000     Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 9.188    Value Loss: 4.675    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1925392    Buffer Size: 14974      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:52:45,825][train][INFO][train.py>_log] ==> #894000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 9.288    Value Loss: 4.327    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1927757    Buffer Size: 14968      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:55:53,072][train][INFO][train.py>_log] ==> #895000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 8.940    Value Loss: 4.829    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1930114    Buffer Size: 14965      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:59:02,153][train][INFO][train.py>_log] ==> #896000     Total Loss: 3.502    [weighted Loss:3.502    Policy Loss: 9.448    Value Loss: 4.693    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1932539    Buffer Size: 14970      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:02:08,397][train][INFO][train.py>_log] ==> #897000     Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 8.884    Value Loss: 4.716    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1934858    Buffer Size: 14976      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:05:13,195][train][INFO][train.py>_log] ==> #898000     Total Loss: 2.645    [weighted Loss:2.645    Policy Loss: 8.966    Value Loss: 4.377    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1937148    Buffer Size: 14979      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:08:20,006][train][INFO][train.py>_log] ==> #899000     Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 8.968    Value Loss: 4.549    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 1939476    Buffer Size: 14981      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:11:24,334][train][INFO][train.py>_log] ==> #900000     Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 8.695    Value Loss: 4.806    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1941783    Buffer Size: 14988      Transition Number: 1000.399k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:14:28,903][train][INFO][train.py>_log] ==> #901000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 8.735    Value Loss: 4.286    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1944057    Buffer Size: 14973      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:17:38,773][train][INFO][train.py>_log] ==> #902000     Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 9.183    Value Loss: 4.570    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1946484    Buffer Size: 14956      Transition Number: 1000.270k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:20:45,234][train][INFO][train.py>_log] ==> #903000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 9.027    Value Loss: 4.719    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1948834    Buffer Size: 14953      Transition Number: 1000.220k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:23:55,414][train][INFO][train.py>_log] ==> #904000     Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 8.844    Value Loss: 4.512    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1951196    Buffer Size: 14942      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:27:01,774][train][INFO][train.py>_log] ==> #905000     Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 8.878    Value Loss: 4.353    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1953508    Buffer Size: 14917      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:30:07,803][train][INFO][train.py>_log] ==> #906000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 8.690    Value Loss: 4.613    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1955839    Buffer Size: 14901      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:33:12,450][train][INFO][train.py>_log] ==> #907000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 8.535    Value Loss: 5.023    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1958094    Buffer Size: 14917      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:36:16,805][train][INFO][train.py>_log] ==> #908000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 9.016    Value Loss: 4.752    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 1960454    Buffer Size: 14937      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:39:22,879][train][INFO][train.py>_log] ==> #909000     Total Loss: 2.589    [weighted Loss:2.589    Policy Loss: 8.737    Value Loss: 4.336    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1962706    Buffer Size: 14941      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:42:30,505][train][INFO][train.py>_log] ==> #910000     Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 8.655    Value Loss: 4.659    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 1965067    Buffer Size: 14931      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:45:36,661][train][INFO][train.py>_log] ==> #911000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 8.856    Value Loss: 4.252    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1967508    Buffer Size: 14935      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:48:42,144][train][INFO][train.py>_log] ==> #912000     Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 9.140    Value Loss: 4.558    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 1969789    Buffer Size: 14951      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:51:47,652][train][INFO][train.py>_log] ==> #913000     Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 8.459    Value Loss: 4.689    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1972095    Buffer Size: 14965      Transition Number: 1000.555k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:54:52,551][train][INFO][train.py>_log] ==> #914000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 9.197    Value Loss: 4.591    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 1974386    Buffer Size: 14948      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:57:57,787][train][INFO][train.py>_log] ==> #915000     Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 8.685    Value Loss: 4.558    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1976699    Buffer Size: 14952      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:01:03,163][train][INFO][train.py>_log] ==> #916000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 8.651    Value Loss: 4.328    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 1979049    Buffer Size: 14953      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:04:12,519][train][INFO][train.py>_log] ==> #917000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 8.511    Value Loss: 4.353    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1981455    Buffer Size: 14949      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:07:19,122][train][INFO][train.py>_log] ==> #918000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 8.746    Value Loss: 4.796    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1983768    Buffer Size: 14956      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:10:26,173][train][INFO][train.py>_log] ==> #919000     Total Loss: 3.077    [weighted Loss:3.077    Policy Loss: 8.967    Value Loss: 4.612    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1986071    Buffer Size: 14970      Transition Number: 1000.462k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:13:36,009][train][INFO][train.py>_log] ==> #920000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 8.812    Value Loss: 4.441    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1988403    Buffer Size: 14964      Transition Number: 1000.120k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:16:44,502][train][INFO][train.py>_log] ==> #921000     Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 8.866    Value Loss: 4.763    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1990810    Buffer Size: 14967      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:19:49,991][train][INFO][train.py>_log] ==> #922000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 8.833    Value Loss: 4.333    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1993129    Buffer Size: 14952      Transition Number: 1000.277k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:22:57,862][train][INFO][train.py>_log] ==> #923000     Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 8.666    Value Loss: 4.528    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 1995456    Buffer Size: 14971      Transition Number: 1000.415k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:25:58,496][train][INFO][train.py>_log] ==> #924000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 9.210    Value Loss: 4.330    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1997744    Buffer Size: 14958      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:29:04,424][train][INFO][train.py>_log] ==> #925000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 9.261    Value Loss: 4.441    Reward Loss: 1.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 2000082    Buffer Size: 14970      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:32:11,233][train][INFO][train.py>_log] ==> #926000     Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 9.142    Value Loss: 4.669    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2002409    Buffer Size: 14983      Transition Number: 1001.143k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:35:18,291][train][INFO][train.py>_log] ==> #927000     Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 8.669    Value Loss: 4.409    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2004743    Buffer Size: 14984      Transition Number: 1000.349k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:38:28,245][train][INFO][train.py>_log] ==> #928000     Total Loss: 3.697    [weighted Loss:3.697    Policy Loss: 8.987    Value Loss: 4.544    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 2007135    Buffer Size: 15003      Transition Number: 1000.431k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:41:38,650][train][INFO][train.py>_log] ==> #929000     Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 8.675    Value Loss: 4.523    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 2009510    Buffer Size: 15001      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:44:44,342][train][INFO][train.py>_log] ==> #930000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 9.032    Value Loss: 4.427    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2011848    Buffer Size: 14986      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:47:47,268][train][INFO][train.py>_log] ==> #931000     Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 8.956    Value Loss: 4.556    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2014207    Buffer Size: 14998      Transition Number: 1000.480k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:50:59,317][train][INFO][train.py>_log] ==> #932000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 8.877    Value Loss: 4.578    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2016660    Buffer Size: 14995      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:54:04,082][train][INFO][train.py>_log] ==> #933000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 8.953    Value Loss: 4.628    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 2018967    Buffer Size: 15009      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:57:11,909][train][INFO][train.py>_log] ==> #934000     Total Loss: 2.507    [weighted Loss:2.507    Policy Loss: 8.810    Value Loss: 4.164    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2021267    Buffer Size: 14995      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:00:21,969][train][INFO][train.py>_log] ==> #935000     Total Loss: 1.190    [weighted Loss:1.190    Policy Loss: 9.229    Value Loss: 4.750    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 2023653    Buffer Size: 14991      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:03:29,843][train][INFO][train.py>_log] ==> #936000     Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 9.324    Value Loss: 4.686    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2025943    Buffer Size: 15010      Transition Number: 1000.250k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:06:37,861][train][INFO][train.py>_log] ==> #937000     Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 9.285    Value Loss: 4.853    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2028319    Buffer Size: 15031      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:09:47,850][train][INFO][train.py>_log] ==> #938000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 9.074    Value Loss: 4.359    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 2030748    Buffer Size: 15031      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:12:55,044][train][INFO][train.py>_log] ==> #939000     Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 9.002    Value Loss: 4.597    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 2033042    Buffer Size: 15031      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:16:02,741][train][INFO][train.py>_log] ==> #940000     Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 9.369    Value Loss: 4.550    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 2035423    Buffer Size: 15042      Transition Number: 1000.267k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:19:11,638][train][INFO][train.py>_log] ==> #941000     Total Loss: 1.257    [weighted Loss:1.257    Policy Loss: 8.879    Value Loss: 4.715    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 2037802    Buffer Size: 15051      Transition Number: 1000.351k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:22:17,219][train][INFO][train.py>_log] ==> #942000     Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 9.663    Value Loss: 4.466    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2040199    Buffer Size: 15064      Transition Number: 1000.150k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:25:26,453][train][INFO][train.py>_log] ==> #943000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 9.376    Value Loss: 4.541    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2042561    Buffer Size: 15058      Transition Number: 1000.413k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:28:33,393][train][INFO][train.py>_log] ==> #944000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 9.374    Value Loss: 4.706    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 2044907    Buffer Size: 15049      Transition Number: 1000.443k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:31:38,876][train][INFO][train.py>_log] ==> #945000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 9.161    Value Loss: 4.643    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 2047243    Buffer Size: 15048      Transition Number: 1000.224k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:34:48,302][train][INFO][train.py>_log] ==> #946000     Total Loss: 1.659    [weighted Loss:1.659    Policy Loss: 9.229    Value Loss: 4.562    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 2049634    Buffer Size: 15041      Transition Number: 1000.148k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:37:56,673][train][INFO][train.py>_log] ==> #947000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 9.142    Value Loss: 4.599    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2051979    Buffer Size: 15032      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:41:05,431][train][INFO][train.py>_log] ==> #948000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 9.299    Value Loss: 4.509    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 2054316    Buffer Size: 15016      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:44:11,937][train][INFO][train.py>_log] ==> #949000     Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 9.109    Value Loss: 4.481    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 2056695    Buffer Size: 15018      Transition Number: 1000.245k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:47:21,921][train][INFO][train.py>_log] ==> #950000     Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 9.117    Value Loss: 4.476    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2059058    Buffer Size: 15010      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:50:30,743][train][INFO][train.py>_log] ==> #951000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 8.958    Value Loss: 4.624    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 2061468    Buffer Size: 15016      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:53:41,546][train][INFO][train.py>_log] ==> #952000     Total Loss: 3.046    [weighted Loss:3.046    Policy Loss: 8.835    Value Loss: 4.368    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2063841    Buffer Size: 15011      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:56:50,130][train][INFO][train.py>_log] ==> #953000     Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 9.742    Value Loss: 4.266    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 2066269    Buffer Size: 15016      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:59:55,298][train][INFO][train.py>_log] ==> #954000     Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 9.295    Value Loss: 4.593    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2068588    Buffer Size: 15011      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:03:02,733][train][INFO][train.py>_log] ==> #955000     Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 9.084    Value Loss: 4.288    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2070945    Buffer Size: 15013      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:06:12,088][train][INFO][train.py>_log] ==> #956000     Total Loss: 1.540    [weighted Loss:1.540    Policy Loss: 9.657    Value Loss: 4.454    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 2073275    Buffer Size: 15023      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:09:17,599][train][INFO][train.py>_log] ==> #957000     Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 9.318    Value Loss: 4.840    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 2075626    Buffer Size: 15023      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:12:26,063][train][INFO][train.py>_log] ==> #958000     Total Loss: 2.850    [weighted Loss:2.850    Policy Loss: 9.476    Value Loss: 4.549    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2077914    Buffer Size: 15031      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:15:32,359][train][INFO][train.py>_log] ==> #959000     Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 9.234    Value Loss: 4.519    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 2080347    Buffer Size: 15036      Transition Number: 1000.316k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:18:37,664][train][INFO][train.py>_log] ==> #960000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 9.300    Value Loss: 4.500    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2082684    Buffer Size: 15052      Transition Number: 1000.455k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:21:45,004][train][INFO][train.py>_log] ==> #961000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 9.299    Value Loss: 4.185    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2085069    Buffer Size: 15049      Transition Number: 1000.325k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:24:52,717][train][INFO][train.py>_log] ==> #962000     Total Loss: 3.001    [weighted Loss:3.001    Policy Loss: 9.260    Value Loss: 4.172    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2087409    Buffer Size: 15033      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:28:01,015][train][INFO][train.py>_log] ==> #963000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 9.463    Value Loss: 4.539    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 2089767    Buffer Size: 15042      Transition Number: 1000.247k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:31:11,636][train][INFO][train.py>_log] ==> #964000     Total Loss: 2.796    [weighted Loss:2.796    Policy Loss: 9.374    Value Loss: 4.232    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2092157    Buffer Size: 15042      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:34:17,989][train][INFO][train.py>_log] ==> #965000     Total Loss: 3.720    [weighted Loss:3.720    Policy Loss: 9.268    Value Loss: 4.371    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2094533    Buffer Size: 15034      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:37:27,752][train][INFO][train.py>_log] ==> #966000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 9.189    Value Loss: 4.413    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 2096865    Buffer Size: 15044      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:40:34,363][train][INFO][train.py>_log] ==> #967000     Total Loss: 3.166    [weighted Loss:3.166    Policy Loss: 9.176    Value Loss: 4.590    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 2099145    Buffer Size: 15044      Transition Number: 1000.156k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:43:41,956][train][INFO][train.py>_log] ==> #968000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 9.732    Value Loss: 4.492    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2101578    Buffer Size: 15031      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:46:46,529][train][INFO][train.py>_log] ==> #969000     Total Loss: 2.084    [weighted Loss:2.084    Policy Loss: 9.169    Value Loss: 4.451    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 2103842    Buffer Size: 15036      Transition Number: 1000.390k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:49:55,205][train][INFO][train.py>_log] ==> #970000     Total Loss: 2.090    [weighted Loss:2.090    Policy Loss: 9.269    Value Loss: 4.849    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 2106239    Buffer Size: 15018      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:53:03,261][train][INFO][train.py>_log] ==> #971000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 9.124    Value Loss: 4.580    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 2108590    Buffer Size: 15012      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:56:11,489][train][INFO][train.py>_log] ==> #972000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 9.393    Value Loss: 4.239    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 2111007    Buffer Size: 15006      Transition Number: 1000.577k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:59:20,877][train][INFO][train.py>_log] ==> #973000     Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 9.084    Value Loss: 4.420    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 2113396    Buffer Size: 14996      Transition Number: 1000.283k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:02:27,686][train][INFO][train.py>_log] ==> #974000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 9.426    Value Loss: 4.573    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 2115749    Buffer Size: 14987      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:05:37,363][train][INFO][train.py>_log] ==> #975000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 9.283    Value Loss: 4.283    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2118112    Buffer Size: 14987      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:08:45,567][train][INFO][train.py>_log] ==> #976000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 9.404    Value Loss: 4.571    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2120503    Buffer Size: 14972      Transition Number: 1000.138k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:11:53,025][train][INFO][train.py>_log] ==> #977000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 9.028    Value Loss: 4.315    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 2122841    Buffer Size: 14965      Transition Number: 1000.308k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:14:55,893][train][INFO][train.py>_log] ==> #978000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 8.911    Value Loss: 4.600    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 2125178    Buffer Size: 14945      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:18:02,581][train][INFO][train.py>_log] ==> #979000     Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 9.182    Value Loss: 4.594    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2127492    Buffer Size: 14950      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:21:13,512][train][INFO][train.py>_log] ==> #980000     Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 9.445    Value Loss: 5.219    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 2129833    Buffer Size: 14941      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:24:22,009][train][INFO][train.py>_log] ==> #981000     Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 9.218    Value Loss: 4.975    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 2132247    Buffer Size: 14932      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:27:30,469][train][INFO][train.py>_log] ==> #982000     Total Loss: 2.847    [weighted Loss:2.847    Policy Loss: 9.026    Value Loss: 4.556    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 2134609    Buffer Size: 14937      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:30:39,470][train][INFO][train.py>_log] ==> #983000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 8.848    Value Loss: 4.318    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2137005    Buffer Size: 14929      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:33:51,686][train][INFO][train.py>_log] ==> #984000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 9.079    Value Loss: 4.615    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 2139400    Buffer Size: 14930      Transition Number: 1000.225k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:36:57,014][train][INFO][train.py>_log] ==> #985000     Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 9.226    Value Loss: 4.197    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 2141731    Buffer Size: 14922      Transition Number: 1000.339k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:40:06,978][train][INFO][train.py>_log] ==> #986000     Total Loss: 2.981    [weighted Loss:2.981    Policy Loss: 9.317    Value Loss: 4.645    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 2144110    Buffer Size: 14932      Transition Number: 1000.763k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:43:14,579][train][INFO][train.py>_log] ==> #987000     Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 9.176    Value Loss: 4.549    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 2146509    Buffer Size: 14915      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:46:21,905][train][INFO][train.py>_log] ==> #988000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 9.650    Value Loss: 4.496    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 2148841    Buffer Size: 14918      Transition Number: 1000.317k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:49:28,272][train][INFO][train.py>_log] ==> #989000     Total Loss: 1.456    [weighted Loss:1.456    Policy Loss: 9.283    Value Loss: 4.324    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 2151169    Buffer Size: 14906      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:52:35,902][train][INFO][train.py>_log] ==> #990000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 9.641    Value Loss: 4.508    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 2153548    Buffer Size: 14915      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:55:45,196][train][INFO][train.py>_log] ==> #991000     Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 8.970    Value Loss: 4.529    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 2155982    Buffer Size: 14927      Transition Number: 1000.377k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:58:53,227][train][INFO][train.py>_log] ==> #992000     Total Loss: 1.078    [weighted Loss:1.078    Policy Loss: 8.998    Value Loss: 4.226    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 2158303    Buffer Size: 14934      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:01:58,161][train][INFO][train.py>_log] ==> #993000     Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 9.191    Value Loss: 4.785    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 2160643    Buffer Size: 14935      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:05:06,949][train][INFO][train.py>_log] ==> #994000     Total Loss: 2.601    [weighted Loss:2.601    Policy Loss: 9.245    Value Loss: 4.459    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 2163009    Buffer Size: 14950      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:08:14,056][train][INFO][train.py>_log] ==> #995000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 9.293    Value Loss: 4.441    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 2165335    Buffer Size: 14979      Transition Number: 1000.236k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:11:22,075][train][INFO][train.py>_log] ==> #996000     Total Loss: 0.786    [weighted Loss:0.786    Policy Loss: 9.029    Value Loss: 4.711    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 2167737    Buffer Size: 15002      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:14:30,195][train][INFO][train.py>_log] ==> #997000     Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 9.671    Value Loss: 4.566    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 2170092    Buffer Size: 14996      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:17:37,857][train][INFO][train.py>_log] ==> #998000     Total Loss: 1.994    [weighted Loss:1.994    Policy Loss: 9.303    Value Loss: 4.578    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 2172498    Buffer Size: 15007      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:20:43,999][train][INFO][train.py>_log] ==> #999000     Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 9.340    Value Loss: 4.480    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 2174848    Buffer Size: 14993      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:24:02,396][train][INFO][train.py>_log] ==> #1000000    Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 9.206    Value Loss: 4.257    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2177166    Buffer Size: 14979      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:27:11,663][train][INFO][train.py>_log] ==> #1001000    Total Loss: 3.123    [weighted Loss:3.123    Policy Loss: 8.967    Value Loss: 4.666    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2179670    Buffer Size: 14982      Transition Number: 1000.200k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:30:19,218][train][INFO][train.py>_log] ==> #1002000    Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 9.574    Value Loss: 5.009    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 2181977    Buffer Size: 14968      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:33:29,757][train][INFO][train.py>_log] ==> #1003000    Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 9.060    Value Loss: 4.260    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 2184473    Buffer Size: 14957      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:36:38,089][train][INFO][train.py>_log] ==> #1004000    Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 9.327    Value Loss: 4.779    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2186850    Buffer Size: 14963      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:39:47,505][train][INFO][train.py>_log] ==> #1005000    Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 9.108    Value Loss: 4.890    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2189214    Buffer Size: 14959      Transition Number: 1000.344k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:42:54,337][train][INFO][train.py>_log] ==> #1006000    Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 9.298    Value Loss: 4.459    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 2191496    Buffer Size: 14950      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:46:03,918][train][INFO][train.py>_log] ==> #1007000    Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 9.087    Value Loss: 4.690    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 2193928    Buffer Size: 14951      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:49:13,420][train][INFO][train.py>_log] ==> #1008000    Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 9.237    Value Loss: 4.842    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 2196339    Buffer Size: 14912      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:52:20,994][train][INFO][train.py>_log] ==> #1009000    Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 9.533    Value Loss: 4.598    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 2198714    Buffer Size: 14899      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:55:26,233][train][INFO][train.py>_log] ==> #1010000    Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 9.214    Value Loss: 4.250    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2201025    Buffer Size: 14896      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:58:30,979][train][INFO][train.py>_log] ==> #1011000    Total Loss: 2.960    [weighted Loss:2.960    Policy Loss: 9.411    Value Loss: 4.548    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2203393    Buffer Size: 14887      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:01:39,735][train][INFO][train.py>_log] ==> #1012000    Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 9.563    Value Loss: 4.250    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2205748    Buffer Size: 14890      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:04:48,170][train][INFO][train.py>_log] ==> #1013000    Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 9.229    Value Loss: 4.502    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 2208063    Buffer Size: 14905      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:07:55,384][train][INFO][train.py>_log] ==> #1014000    Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 9.312    Value Loss: 4.891    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2210455    Buffer Size: 14919      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:11:03,070][train][INFO][train.py>_log] ==> #1015000    Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 8.969    Value Loss: 4.856    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2212837    Buffer Size: 14933      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:14:09,652][train][INFO][train.py>_log] ==> #1016000    Total Loss: 2.676    [weighted Loss:2.676    Policy Loss: 9.361    Value Loss: 4.590    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2215180    Buffer Size: 14935      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:17:14,726][train][INFO][train.py>_log] ==> #1017000    Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 9.504    Value Loss: 4.568    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2217514    Buffer Size: 14932      Transition Number: 1000.402k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:20:22,217][train][INFO][train.py>_log] ==> #1018000    Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 9.149    Value Loss: 5.011    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 2219809    Buffer Size: 14934      Transition Number: 1000.239k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:23:29,167][train][INFO][train.py>_log] ==> #1019000    Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 9.282    Value Loss: 4.275    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2222157    Buffer Size: 14931      Transition Number: 1000.835k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:26:38,651][train][INFO][train.py>_log] ==> #1020000    Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 9.490    Value Loss: 4.687    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 2224508    Buffer Size: 14918      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:29:45,812][train][INFO][train.py>_log] ==> #1021000    Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 9.107    Value Loss: 4.473    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2226874    Buffer Size: 14917      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:32:52,302][train][INFO][train.py>_log] ==> #1022000    Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 9.703    Value Loss: 4.367    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2229221    Buffer Size: 14926      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:36:00,254][train][INFO][train.py>_log] ==> #1023000    Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 9.974    Value Loss: 4.523    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2231513    Buffer Size: 14922      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:39:09,970][train][INFO][train.py>_log] ==> #1024000    Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 9.669    Value Loss: 4.467    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2233984    Buffer Size: 14928      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:42:20,410][train][INFO][train.py>_log] ==> #1025000    Total Loss: 2.719    [weighted Loss:2.719    Policy Loss: 9.499    Value Loss: 4.732    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2236433    Buffer Size: 14937      Transition Number: 1000.194k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:45:30,593][train][INFO][train.py>_log] ==> #1026000    Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 9.302    Value Loss: 4.737    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 2238840    Buffer Size: 14938      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:48:38,537][train][INFO][train.py>_log] ==> #1027000    Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 9.507    Value Loss: 4.356    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 2241130    Buffer Size: 14945      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:51:47,084][train][INFO][train.py>_log] ==> #1028000    Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 9.354    Value Loss: 4.548    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 2243500    Buffer Size: 14951      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:54:55,430][train][INFO][train.py>_log] ==> #1029000    Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 9.396    Value Loss: 4.726    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 2245922    Buffer Size: 14953      Transition Number: 1000.302k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:58:04,611][train][INFO][train.py>_log] ==> #1030000    Total Loss: 0.579    [weighted Loss:0.579    Policy Loss: 9.474    Value Loss: 4.624    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2248348    Buffer Size: 14961      Transition Number: 1000.251k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:01:13,673][train][INFO][train.py>_log] ==> #1031000    Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 9.328    Value Loss: 4.695    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2250739    Buffer Size: 14961      Transition Number: 999.931 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:04:23,402][train][INFO][train.py>_log] ==> #1032000    Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 9.541    Value Loss: 4.601    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2253079    Buffer Size: 14976      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:07:31,501][train][INFO][train.py>_log] ==> #1033000    Total Loss: 1.042    [weighted Loss:1.042    Policy Loss: 9.364    Value Loss: 4.516    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2255368    Buffer Size: 14980      Transition Number: 1000.285k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:10:40,061][train][INFO][train.py>_log] ==> #1034000    Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 9.909    Value Loss: 4.428    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 2257781    Buffer Size: 14981      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:13:46,998][train][INFO][train.py>_log] ==> #1035000    Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 9.760    Value Loss: 4.899    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2260136    Buffer Size: 14979      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:16:55,258][train][INFO][train.py>_log] ==> #1036000    Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 9.742    Value Loss: 4.357    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2262440    Buffer Size: 14984      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:20:04,193][train][INFO][train.py>_log] ==> #1037000    Total Loss: 3.500    [weighted Loss:3.500    Policy Loss: 9.513    Value Loss: 4.293    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2264850    Buffer Size: 14989      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:23:13,093][train][INFO][train.py>_log] ==> #1038000    Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 9.233    Value Loss: 4.467    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 2267301    Buffer Size: 14987      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:26:22,327][train][INFO][train.py>_log] ==> #1039000    Total Loss: 2.844    [weighted Loss:2.844    Policy Loss: 9.289    Value Loss: 4.420    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 2269669    Buffer Size: 15010      Transition Number: 1000.329k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:29:34,672][train][INFO][train.py>_log] ==> #1040000    Total Loss: 2.462    [weighted Loss:2.462    Policy Loss: 9.288    Value Loss: 4.792    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 2272042    Buffer Size: 15015      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:32:46,321][train][INFO][train.py>_log] ==> #1041000    Total Loss: 1.139    [weighted Loss:1.139    Policy Loss: 9.489    Value Loss: 4.437    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 2274472    Buffer Size: 15026      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:35:52,213][train][INFO][train.py>_log] ==> #1042000    Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 9.917    Value Loss: 4.668    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 2276861    Buffer Size: 15042      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:39:01,558][train][INFO][train.py>_log] ==> #1043000    Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 9.772    Value Loss: 4.636    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2279285    Buffer Size: 15024      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:42:10,039][train][INFO][train.py>_log] ==> #1044000    Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 9.599    Value Loss: 4.537    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 2281566    Buffer Size: 15008      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:45:18,889][train][INFO][train.py>_log] ==> #1045000    Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 9.917    Value Loss: 4.439    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 2283926    Buffer Size: 14987      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:48:28,195][train][INFO][train.py>_log] ==> #1046000    Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 9.747    Value Loss: 4.321    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 2286276    Buffer Size: 14979      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:51:38,885][train][INFO][train.py>_log] ==> #1047000    Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 9.100    Value Loss: 4.335    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2288695    Buffer Size: 14985      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:54:46,344][train][INFO][train.py>_log] ==> #1048000    Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 9.083    Value Loss: 4.828    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2291051    Buffer Size: 14976      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:57:54,061][train][INFO][train.py>_log] ==> #1049000    Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 9.632    Value Loss: 4.630    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2293383    Buffer Size: 14963      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:01:03,525][train][INFO][train.py>_log] ==> #1050000    Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 9.755    Value Loss: 4.445    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 2295791    Buffer Size: 14972      Transition Number: 1000.342k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:04:12,203][train][INFO][train.py>_log] ==> #1051000    Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 9.669    Value Loss: 4.432    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 2298217    Buffer Size: 14983      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:07:23,166][train][INFO][train.py>_log] ==> #1052000    Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 9.005    Value Loss: 4.717    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2300624    Buffer Size: 14996      Transition Number: 1000.456k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:10:34,675][train][INFO][train.py>_log] ==> #1053000    Total Loss: 0.733    [weighted Loss:0.733    Policy Loss: 9.616    Value Loss: 4.628    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2303045    Buffer Size: 14985      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:13:41,144][train][INFO][train.py>_log] ==> #1054000    Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 9.460    Value Loss: 4.676    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2305316    Buffer Size: 14989      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:16:48,031][train][INFO][train.py>_log] ==> #1055000    Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 9.516    Value Loss: 4.531    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2307725    Buffer Size: 14999      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:19:57,409][train][INFO][train.py>_log] ==> #1056000    Total Loss: 2.799    [weighted Loss:2.799    Policy Loss: 9.882    Value Loss: 4.390    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2310151    Buffer Size: 15000      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:23:08,603][train][INFO][train.py>_log] ==> #1057000    Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 9.378    Value Loss: 4.860    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 2312500    Buffer Size: 14998      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:26:18,268][train][INFO][train.py>_log] ==> #1058000    Total Loss: 3.527    [weighted Loss:3.527    Policy Loss: 9.394    Value Loss: 4.917    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2314857    Buffer Size: 14978      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:29:25,318][train][INFO][train.py>_log] ==> #1059000    Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 9.344    Value Loss: 4.694    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2317249    Buffer Size: 14976      Transition Number: 1000.276k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:32:33,335][train][INFO][train.py>_log] ==> #1060000    Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 9.580    Value Loss: 4.649    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 2319577    Buffer Size: 14974      Transition Number: 1000.663k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:35:44,034][train][INFO][train.py>_log] ==> #1061000    Total Loss: 2.728    [weighted Loss:2.728    Policy Loss: 9.826    Value Loss: 4.218    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2321973    Buffer Size: 14965      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:38:53,546][train][INFO][train.py>_log] ==> #1062000    Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 9.412    Value Loss: 4.754    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 2324337    Buffer Size: 14963      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:42:04,617][train][INFO][train.py>_log] ==> #1063000    Total Loss: 2.084    [weighted Loss:2.084    Policy Loss: 9.564    Value Loss: 4.447    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2326797    Buffer Size: 14956      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:45:14,994][train][INFO][train.py>_log] ==> #1064000    Total Loss: 1.227    [weighted Loss:1.227    Policy Loss: 9.424    Value Loss: 4.413    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 2329141    Buffer Size: 14969      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:48:23,906][train][INFO][train.py>_log] ==> #1065000    Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 9.366    Value Loss: 4.462    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 2331531    Buffer Size: 14962      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:51:34,665][train][INFO][train.py>_log] ==> #1066000    Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 9.257    Value Loss: 4.532    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2333918    Buffer Size: 14971      Transition Number: 1000.529k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:54:43,817][train][INFO][train.py>_log] ==> #1067000    Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 9.141    Value Loss: 4.664    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2336266    Buffer Size: 14959      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:57:51,863][train][INFO][train.py>_log] ==> #1068000    Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 9.140    Value Loss: 4.752    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2338709    Buffer Size: 14978      Transition Number: 1000.215k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:01:00,173][train][INFO][train.py>_log] ==> #1069000    Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 9.535    Value Loss: 4.531    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2341112    Buffer Size: 14986      Transition Number: 1000.293k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:04:13,360][train][INFO][train.py>_log] ==> #1070000    Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 9.531    Value Loss: 4.484    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 2343497    Buffer Size: 14985      Transition Number: 1000.393k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:07:26,027][train][INFO][train.py>_log] ==> #1071000    Total Loss: 2.846    [weighted Loss:2.846    Policy Loss: 9.568    Value Loss: 4.680    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2345887    Buffer Size: 14979      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:10:37,260][train][INFO][train.py>_log] ==> #1072000    Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 9.702    Value Loss: 4.312    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 2348304    Buffer Size: 14976      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:13:48,196][train][INFO][train.py>_log] ==> #1073000    Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 9.573    Value Loss: 4.414    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 2350693    Buffer Size: 14986      Transition Number: 1000.503k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:17:03,326][train][INFO][train.py>_log] ==> #1074000    Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 9.705    Value Loss: 4.246    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2353143    Buffer Size: 14983      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:20:18,219][train][INFO][train.py>_log] ==> #1075000    Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 8.840    Value Loss: 4.610    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 2355580    Buffer Size: 14965      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:23:30,976][train][INFO][train.py>_log] ==> #1076000    Total Loss: 2.412    [weighted Loss:2.412    Policy Loss: 9.405    Value Loss: 4.741    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 2357965    Buffer Size: 14960      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:26:41,256][train][INFO][train.py>_log] ==> #1077000    Total Loss: 2.719    [weighted Loss:2.719    Policy Loss: 9.004    Value Loss: 4.375    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 2360369    Buffer Size: 14958      Transition Number: 1000.145k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:29:56,065][train][INFO][train.py>_log] ==> #1078000    Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 9.379    Value Loss: 4.466    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2362681    Buffer Size: 14968      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:33:07,819][train][INFO][train.py>_log] ==> #1079000    Total Loss: 2.927    [weighted Loss:2.927    Policy Loss: 9.098    Value Loss: 4.581    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 2365162    Buffer Size: 14958      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:36:19,148][train][INFO][train.py>_log] ==> #1080000    Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 9.179    Value Loss: 4.673    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2367532    Buffer Size: 14946      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:39:30,544][train][INFO][train.py>_log] ==> #1081000    Total Loss: 1.931    [weighted Loss:1.931    Policy Loss: 9.577    Value Loss: 4.729    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2369879    Buffer Size: 14944      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:42:40,360][train][INFO][train.py>_log] ==> #1082000    Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 9.139    Value Loss: 4.300    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2372259    Buffer Size: 14950      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:45:50,832][train][INFO][train.py>_log] ==> #1083000    Total Loss: 3.730    [weighted Loss:3.730    Policy Loss: 9.598    Value Loss: 4.621    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2374566    Buffer Size: 14970      Transition Number: 1000.144k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:49:02,087][train][INFO][train.py>_log] ==> #1084000    Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 9.142    Value Loss: 4.392    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 2376987    Buffer Size: 14980      Transition Number: 1000.601k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:52:13,853][train][INFO][train.py>_log] ==> #1085000    Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 9.559    Value Loss: 4.737    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2379343    Buffer Size: 14985      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:55:28,583][train][INFO][train.py>_log] ==> #1086000    Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 9.463    Value Loss: 4.643    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 2381754    Buffer Size: 14992      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:58:40,028][train][INFO][train.py>_log] ==> #1087000    Total Loss: 2.435    [weighted Loss:2.435    Policy Loss: 9.385    Value Loss: 4.788    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2384161    Buffer Size: 14988      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:01:53,566][train][INFO][train.py>_log] ==> #1088000    Total Loss: 2.604    [weighted Loss:2.604    Policy Loss: 9.175    Value Loss: 4.521    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 2386572    Buffer Size: 14972      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:05:05,509][train][INFO][train.py>_log] ==> #1089000    Total Loss: 2.801    [weighted Loss:2.801    Policy Loss: 8.667    Value Loss: 4.472    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 2388915    Buffer Size: 14968      Transition Number: 1000.296k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:08:19,147][train][INFO][train.py>_log] ==> #1090000    Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 9.142    Value Loss: 4.491    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 2391423    Buffer Size: 14952      Transition Number: 1000.133k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:11:33,291][train][INFO][train.py>_log] ==> #1091000    Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 9.453    Value Loss: 4.447    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2393785    Buffer Size: 14950      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:14:48,467][train][INFO][train.py>_log] ==> #1092000    Total Loss: 3.675    [weighted Loss:3.675    Policy Loss: 9.286    Value Loss: 4.666    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 2396234    Buffer Size: 14940      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:18:04,226][train][INFO][train.py>_log] ==> #1093000    Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 8.983    Value Loss: 4.646    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 2398577    Buffer Size: 14939      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:21:18,058][train][INFO][train.py>_log] ==> #1094000    Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 9.331    Value Loss: 4.581    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2401009    Buffer Size: 14950      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:24:31,808][train][INFO][train.py>_log] ==> #1095000    Total Loss: 3.679    [weighted Loss:3.679    Policy Loss: 9.244    Value Loss: 4.308    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 2403443    Buffer Size: 14950      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:27:45,817][train][INFO][train.py>_log] ==> #1096000    Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 8.875    Value Loss: 4.492    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2405802    Buffer Size: 14953      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:31:02,133][train][INFO][train.py>_log] ==> #1097000    Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 9.107    Value Loss: 4.400    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 2408289    Buffer Size: 14957      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:34:15,508][train][INFO][train.py>_log] ==> #1098000    Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 8.913    Value Loss: 4.575    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 2410679    Buffer Size: 14958      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:37:27,015][train][INFO][train.py>_log] ==> #1099000    Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 9.675    Value Loss: 4.529    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 2413058    Buffer Size: 14971      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:40:38,775][train][INFO][train.py>_log] ==> #1100000    Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 9.246    Value Loss: 4.275    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 2415461    Buffer Size: 14986      Transition Number: 1000.125k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:43:51,875][train][INFO][train.py>_log] ==> #1101000    Total Loss: 1.293    [weighted Loss:1.293    Policy Loss: 9.433    Value Loss: 4.478    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2417904    Buffer Size: 14983      Transition Number: 1000.218k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:47:06,672][train][INFO][train.py>_log] ==> #1102000    Total Loss: 1.296    [weighted Loss:1.296    Policy Loss: 8.602    Value Loss: 4.963    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 2420253    Buffer Size: 14997      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:50:20,367][train][INFO][train.py>_log] ==> #1103000    Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 9.091    Value Loss: 4.403    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2422698    Buffer Size: 15001      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:53:34,267][train][INFO][train.py>_log] ==> #1104000    Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 9.039    Value Loss: 4.623    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 2425157    Buffer Size: 15002      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:56:48,289][train][INFO][train.py>_log] ==> #1105000    Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 9.179    Value Loss: 4.178    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2427494    Buffer Size: 15015      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:00:01,844][train][INFO][train.py>_log] ==> #1106000    Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 9.062    Value Loss: 4.581    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2429962    Buffer Size: 15011      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:03:12,286][train][INFO][train.py>_log] ==> #1107000    Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 8.962    Value Loss: 4.585    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2432327    Buffer Size: 15020      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:06:20,921][train][INFO][train.py>_log] ==> #1108000    Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 9.335    Value Loss: 4.601    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 2434695    Buffer Size: 15033      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:09:35,322][train][INFO][train.py>_log] ==> #1109000    Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 9.568    Value Loss: 4.688    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2437220    Buffer Size: 15056      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:12:46,272][train][INFO][train.py>_log] ==> #1110000    Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 9.532    Value Loss: 4.334    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 2439640    Buffer Size: 15066      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:15:57,840][train][INFO][train.py>_log] ==> #1111000    Total Loss: 2.900    [weighted Loss:2.900    Policy Loss: 9.369    Value Loss: 4.798    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2442073    Buffer Size: 15101      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:19:10,885][train][INFO][train.py>_log] ==> #1112000    Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 9.049    Value Loss: 4.519    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 2444399    Buffer Size: 15113      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:22:22,607][train][INFO][train.py>_log] ==> #1113000    Total Loss: 3.393    [weighted Loss:3.393    Policy Loss: 9.664    Value Loss: 4.380    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2446912    Buffer Size: 15136      Transition Number: 1000.182k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:25:36,407][train][INFO][train.py>_log] ==> #1114000    Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 8.968    Value Loss: 4.421    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 2449356    Buffer Size: 15139      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:28:49,711][train][INFO][train.py>_log] ==> #1115000    Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 9.590    Value Loss: 4.552    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2451832    Buffer Size: 15158      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:32:04,833][train][INFO][train.py>_log] ==> #1116000    Total Loss: 1.825    [weighted Loss:1.825    Policy Loss: 9.237    Value Loss: 4.536    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2454228    Buffer Size: 15187      Transition Number: 1000.277k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:35:18,460][train][INFO][train.py>_log] ==> #1117000    Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 9.534    Value Loss: 4.875    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 2456695    Buffer Size: 15191      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:38:33,951][train][INFO][train.py>_log] ==> #1118000    Total Loss: 2.898    [weighted Loss:2.898    Policy Loss: 9.509    Value Loss: 4.401    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2459176    Buffer Size: 15220      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:41:45,114][train][INFO][train.py>_log] ==> #1119000    Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 9.674    Value Loss: 4.697    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 2461637    Buffer Size: 15254      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:44:56,930][train][INFO][train.py>_log] ==> #1120000    Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 9.730    Value Loss: 4.478    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 2464015    Buffer Size: 15256      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:48:08,803][train][INFO][train.py>_log] ==> #1121000    Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 9.300    Value Loss: 4.486    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2466477    Buffer Size: 15292      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:51:18,701][train][INFO][train.py>_log] ==> #1122000    Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 9.329    Value Loss: 4.330    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 2468872    Buffer Size: 15317      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:54:29,911][train][INFO][train.py>_log] ==> #1123000    Total Loss: 2.783    [weighted Loss:2.783    Policy Loss: 9.410    Value Loss: 4.468    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2471289    Buffer Size: 15338      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:57:38,701][train][INFO][train.py>_log] ==> #1124000    Total Loss: 1.265    [weighted Loss:1.265    Policy Loss: 9.781    Value Loss: 4.524    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2473706    Buffer Size: 15356      Transition Number: 1000.333k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:00:49,399][train][INFO][train.py>_log] ==> #1125000    Total Loss: 2.129    [weighted Loss:2.129    Policy Loss: 9.239    Value Loss: 4.560    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 2476210    Buffer Size: 15333      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:04:02,289][train][INFO][train.py>_log] ==> #1126000    Total Loss: 1.289    [weighted Loss:1.289    Policy Loss: 9.565    Value Loss: 4.371    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2478624    Buffer Size: 15345      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:07:16,582][train][INFO][train.py>_log] ==> #1127000    Total Loss: 3.289    [weighted Loss:3.289    Policy Loss: 9.509    Value Loss: 4.467    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2481011    Buffer Size: 15340      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:10:28,180][train][INFO][train.py>_log] ==> #1128000    Total Loss: 1.575    [weighted Loss:1.575    Policy Loss: 9.484    Value Loss: 4.644    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2483436    Buffer Size: 15318      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:13:39,520][train][INFO][train.py>_log] ==> #1129000    Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 9.842    Value Loss: 4.457    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 2485861    Buffer Size: 15299      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:16:52,477][train][INFO][train.py>_log] ==> #1130000    Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 9.508    Value Loss: 4.230    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 2488330    Buffer Size: 15291      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:20:04,710][train][INFO][train.py>_log] ==> #1131000    Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 8.952    Value Loss: 4.490    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 2490740    Buffer Size: 15284      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:23:19,857][train][INFO][train.py>_log] ==> #1132000    Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 8.997    Value Loss: 4.097    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2493185    Buffer Size: 15279      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:26:29,788][train][INFO][train.py>_log] ==> #1133000    Total Loss: 1.561    [weighted Loss:1.561    Policy Loss: 9.437    Value Loss: 4.038    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2495636    Buffer Size: 15276      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:29:41,668][train][INFO][train.py>_log] ==> #1134000    Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 9.449    Value Loss: 4.467    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 2498086    Buffer Size: 15281      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:32:55,484][train][INFO][train.py>_log] ==> #1135000    Total Loss: 1.904    [weighted Loss:1.904    Policy Loss: 9.788    Value Loss: 4.443    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2500565    Buffer Size: 15279      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:36:09,174][train][INFO][train.py>_log] ==> #1136000    Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 9.503    Value Loss: 4.594    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 2502973    Buffer Size: 15290      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:39:22,646][train][INFO][train.py>_log] ==> #1137000    Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 9.190    Value Loss: 4.238    Reward Loss: 1.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 2505414    Buffer Size: 15271      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:42:34,942][train][INFO][train.py>_log] ==> #1138000    Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 9.583    Value Loss: 4.501    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2507942    Buffer Size: 15275      Transition Number: 1000.220k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:45:44,473][train][INFO][train.py>_log] ==> #1139000    Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 9.370    Value Loss: 4.418    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 2510286    Buffer Size: 15274      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:49:00,246][train][INFO][train.py>_log] ==> #1140000    Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 9.528    Value Loss: 4.660    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 2512734    Buffer Size: 15272      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:52:12,006][train][INFO][train.py>_log] ==> #1141000    Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 9.506    Value Loss: 4.061    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 2515195    Buffer Size: 15266      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:55:24,518][train][INFO][train.py>_log] ==> #1142000    Total Loss: 1.415    [weighted Loss:1.415    Policy Loss: 9.518    Value Loss: 4.347    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 2517726    Buffer Size: 15251      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:58:37,332][train][INFO][train.py>_log] ==> #1143000    Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 9.690    Value Loss: 4.408    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 2520211    Buffer Size: 15259      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:01:46,450][train][INFO][train.py>_log] ==> #1144000    Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 9.812    Value Loss: 4.162    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 2522522    Buffer Size: 15249      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:04:58,479][train][INFO][train.py>_log] ==> #1145000    Total Loss: 1.210    [weighted Loss:1.210    Policy Loss: 9.365    Value Loss: 3.914    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 2524996    Buffer Size: 15239      Transition Number: 1000.102k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:08:12,818][train][INFO][train.py>_log] ==> #1146000    Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 9.506    Value Loss: 3.891    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2527441    Buffer Size: 15246      Transition Number: 1000.267k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:11:25,031][train][INFO][train.py>_log] ==> #1147000    Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 9.556    Value Loss: 4.588    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2529907    Buffer Size: 15233      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:14:37,955][train][INFO][train.py>_log] ==> #1148000    Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 9.163    Value Loss: 4.425    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 2532333    Buffer Size: 15237      Transition Number: 1000.507k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:17:52,145][train][INFO][train.py>_log] ==> #1149000    Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 9.411    Value Loss: 4.219    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2534739    Buffer Size: 15228      Transition Number: 1000.332k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:21:05,787][train][INFO][train.py>_log] ==> #1150000    Total Loss: 1.698    [weighted Loss:1.698    Policy Loss: 9.191    Value Loss: 4.432    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2537281    Buffer Size: 15237      Transition Number: 1000.416k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:24:20,000][train][INFO][train.py>_log] ==> #1151000    Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 9.303    Value Loss: 4.624    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2539776    Buffer Size: 15243      Transition Number: 1000.448k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:27:33,065][train][INFO][train.py>_log] ==> #1152000    Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 9.788    Value Loss: 4.382    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2542266    Buffer Size: 15233      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:30:43,357][train][INFO][train.py>_log] ==> #1153000    Total Loss: 1.642    [weighted Loss:1.642    Policy Loss: 9.230    Value Loss: 4.155    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 2544621    Buffer Size: 15237      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:33:55,747][train][INFO][train.py>_log] ==> #1154000    Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 9.599    Value Loss: 4.592    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2547046    Buffer Size: 15242      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:37:13,998][train][INFO][train.py>_log] ==> #1155000    Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 9.198    Value Loss: 4.398    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2549608    Buffer Size: 15242      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:40:29,599][train][INFO][train.py>_log] ==> #1156000    Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 9.391    Value Loss: 4.247    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 2552052    Buffer Size: 15235      Transition Number: 1000.549k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:43:42,590][train][INFO][train.py>_log] ==> #1157000    Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 9.238    Value Loss: 4.647    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2554507    Buffer Size: 15211      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:46:57,152][train][INFO][train.py>_log] ==> #1158000    Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 9.645    Value Loss: 4.483    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 2557004    Buffer Size: 15212      Transition Number: 1000.218k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:50:09,084][train][INFO][train.py>_log] ==> #1159000    Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 9.368    Value Loss: 4.614    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 2559494    Buffer Size: 15194      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:53:22,374][train][INFO][train.py>_log] ==> #1160000    Total Loss: 1.212    [weighted Loss:1.212    Policy Loss: 9.250    Value Loss: 4.393    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 2562002    Buffer Size: 15187      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:56:37,169][train][INFO][train.py>_log] ==> #1161000    Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 9.587    Value Loss: 4.530    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 2564476    Buffer Size: 15194      Transition Number: 1000.492k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:59:48,031][train][INFO][train.py>_log] ==> #1162000    Total Loss: 1.593    [weighted Loss:1.593    Policy Loss: 9.301    Value Loss: 4.590    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2566858    Buffer Size: 15203      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:03:01,136][train][INFO][train.py>_log] ==> #1163000    Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 9.231    Value Loss: 4.462    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 2569372    Buffer Size: 15198      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:06:15,132][train][INFO][train.py>_log] ==> #1164000    Total Loss: 2.875    [weighted Loss:2.875    Policy Loss: 9.381    Value Loss: 4.941    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2571822    Buffer Size: 15194      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:09:29,898][train][INFO][train.py>_log] ==> #1165000    Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 8.851    Value Loss: 4.604    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2574278    Buffer Size: 15199      Transition Number: 1000.161k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:12:44,303][train][INFO][train.py>_log] ==> #1166000    Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 8.809    Value Loss: 4.345    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 2576737    Buffer Size: 15197      Transition Number: 1000.296k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:15:55,233][train][INFO][train.py>_log] ==> #1167000    Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 9.000    Value Loss: 4.546    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 2579214    Buffer Size: 15180      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:19:09,743][train][INFO][train.py>_log] ==> #1168000    Total Loss: 1.809    [weighted Loss:1.809    Policy Loss: 9.249    Value Loss: 4.310    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2581638    Buffer Size: 15177      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:22:22,756][train][INFO][train.py>_log] ==> #1169000    Total Loss: 2.621    [weighted Loss:2.621    Policy Loss: 8.975    Value Loss: 4.237    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2584083    Buffer Size: 15163      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:25:35,579][train][INFO][train.py>_log] ==> #1170000    Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 9.362    Value Loss: 4.546    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2586558    Buffer Size: 15165      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:28:49,601][train][INFO][train.py>_log] ==> #1171000    Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 8.715    Value Loss: 4.471    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2589065    Buffer Size: 15158      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:32:01,615][train][INFO][train.py>_log] ==> #1172000    Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 8.645    Value Loss: 4.451    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 2591536    Buffer Size: 15165      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:35:17,982][train][INFO][train.py>_log] ==> #1173000    Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 9.204    Value Loss: 4.638    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2594014    Buffer Size: 15169      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:38:33,917][train][INFO][train.py>_log] ==> #1174000    Total Loss: 1.138    [weighted Loss:1.138    Policy Loss: 8.391    Value Loss: 4.127    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2596506    Buffer Size: 15166      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:41:46,416][train][INFO][train.py>_log] ==> #1175000    Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 9.118    Value Loss: 4.565    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 2598908    Buffer Size: 15172      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:44:57,717][train][INFO][train.py>_log] ==> #1176000    Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 8.988    Value Loss: 4.316    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 2601366    Buffer Size: 15170      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:48:10,708][train][INFO][train.py>_log] ==> #1177000    Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 9.558    Value Loss: 4.320    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 2603835    Buffer Size: 15168      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:51:23,321][train][INFO][train.py>_log] ==> #1178000    Total Loss: 1.289    [weighted Loss:1.289    Policy Loss: 9.310    Value Loss: 4.497    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2606237    Buffer Size: 15173      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:54:36,779][train][INFO][train.py>_log] ==> #1179000    Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 9.266    Value Loss: 4.467    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2608691    Buffer Size: 15175      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:57:49,755][train][INFO][train.py>_log] ==> #1180000    Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 9.126    Value Loss: 4.423    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2611265    Buffer Size: 15182      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:01:06,227][train][INFO][train.py>_log] ==> #1181000    Total Loss: 1.740    [weighted Loss:1.740    Policy Loss: 9.361    Value Loss: 4.423    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 2613711    Buffer Size: 15181      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:04:17,922][train][INFO][train.py>_log] ==> #1182000    Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 9.008    Value Loss: 4.258    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2616065    Buffer Size: 15185      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:07:32,828][train][INFO][train.py>_log] ==> #1183000    Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 8.898    Value Loss: 4.139    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2618602    Buffer Size: 15186      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:10:46,933][train][INFO][train.py>_log] ==> #1184000    Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 9.168    Value Loss: 4.550    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2621132    Buffer Size: 15205      Transition Number: 1000.182k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:13:59,991][train][INFO][train.py>_log] ==> #1185000    Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 8.910    Value Loss: 4.410    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2623572    Buffer Size: 15219      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:17:14,721][train][INFO][train.py>_log] ==> #1186000    Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 8.918    Value Loss: 4.333    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 2625976    Buffer Size: 15211      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:20:26,890][train][INFO][train.py>_log] ==> #1187000    Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 9.328    Value Loss: 4.615    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 2628401    Buffer Size: 15215      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:23:41,242][train][INFO][train.py>_log] ==> #1188000    Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 9.323    Value Loss: 4.455    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 2630877    Buffer Size: 15223      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:26:52,548][train][INFO][train.py>_log] ==> #1189000    Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 9.173    Value Loss: 4.607    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 2633325    Buffer Size: 15228      Transition Number: 1000.207k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:30:05,658][train][INFO][train.py>_log] ==> #1190000    Total Loss: 1.389    [weighted Loss:1.389    Policy Loss: 9.164    Value Loss: 4.412    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 2635807    Buffer Size: 15225      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:33:16,097][train][INFO][train.py>_log] ==> #1191000    Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 9.100    Value Loss: 4.395    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2638217    Buffer Size: 15213      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:36:29,400][train][INFO][train.py>_log] ==> #1192000    Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 9.520    Value Loss: 4.488    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 2640663    Buffer Size: 15211      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:39:43,170][train][INFO][train.py>_log] ==> #1193000    Total Loss: 1.640    [weighted Loss:1.640    Policy Loss: 9.478    Value Loss: 4.847    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 2643153    Buffer Size: 15215      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:42:57,692][train][INFO][train.py>_log] ==> #1194000    Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 9.024    Value Loss: 4.475    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2645581    Buffer Size: 15234      Transition Number: 1000.122k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:46:10,419][train][INFO][train.py>_log] ==> #1195000    Total Loss: 2.783    [weighted Loss:2.783    Policy Loss: 9.460    Value Loss: 4.549    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2647999    Buffer Size: 15231      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:49:30,062][train][INFO][train.py>_log] ==> #1196000    Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 9.447    Value Loss: 4.621    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 2650576    Buffer Size: 15226      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:52:42,458][train][INFO][train.py>_log] ==> #1197000    Total Loss: 2.786    [weighted Loss:2.786    Policy Loss: 9.266    Value Loss: 4.773    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 2653054    Buffer Size: 15242      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:55:54,555][train][INFO][train.py>_log] ==> #1198000    Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 9.014    Value Loss: 4.481    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 2655455    Buffer Size: 15247      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:59:07,951][train][INFO][train.py>_log] ==> #1199000    Total Loss: 2.869    [weighted Loss:2.869    Policy Loss: 9.954    Value Loss: 4.683    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2657879    Buffer Size: 15249      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:02:25,289][train][INFO][train.py>_log] ==> #1200000    Total Loss: 1.562    [weighted Loss:1.562    Policy Loss: 9.356    Value Loss: 4.337    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2660453    Buffer Size: 15246      Transition Number: 1000.398k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:05:40,729][train][INFO][train.py>_log] ==> #1201000    Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 9.732    Value Loss: 4.215    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 2662991    Buffer Size: 15249      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:08:52,025][train][INFO][train.py>_log] ==> #1202000    Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 9.495    Value Loss: 4.421    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 2665500    Buffer Size: 15262      Transition Number: 1000.165k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:12:08,178][train][INFO][train.py>_log] ==> #1203000    Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 9.355    Value Loss: 4.596    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 2667933    Buffer Size: 15266      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:15:18,852][train][INFO][train.py>_log] ==> #1204000    Total Loss: 3.257    [weighted Loss:3.257    Policy Loss: 9.833    Value Loss: 3.975    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2670289    Buffer Size: 15274      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:18:31,517][train][INFO][train.py>_log] ==> #1205000    Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 9.838    Value Loss: 4.613    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2672776    Buffer Size: 15280      Transition Number: 1000.270k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:21:44,535][train][INFO][train.py>_log] ==> #1206000    Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 9.868    Value Loss: 4.472    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 2675266    Buffer Size: 15280      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:24:57,918][train][INFO][train.py>_log] ==> #1207000    Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 9.884    Value Loss: 4.469    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 2677710    Buffer Size: 15288      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:28:08,994][train][INFO][train.py>_log] ==> #1208000    Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 10.118   Value Loss: 4.381    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 2680132    Buffer Size: 15285      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:31:23,473][train][INFO][train.py>_log] ==> #1209000    Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 9.780    Value Loss: 4.520    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 2682639    Buffer Size: 15299      Transition Number: 1000.332k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:34:38,690][train][INFO][train.py>_log] ==> #1210000    Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 9.625    Value Loss: 4.621    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2685187    Buffer Size: 15303      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:37:50,823][train][INFO][train.py>_log] ==> #1211000    Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 9.422    Value Loss: 4.407    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2687602    Buffer Size: 15347      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:41:02,125][train][INFO][train.py>_log] ==> #1212000    Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 9.770    Value Loss: 4.888    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2690038    Buffer Size: 15381      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:44:17,393][train][INFO][train.py>_log] ==> #1213000    Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 9.917    Value Loss: 4.682    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 2692591    Buffer Size: 15400      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:47:29,510][train][INFO][train.py>_log] ==> #1214000    Total Loss: 2.890    [weighted Loss:2.890    Policy Loss: 9.997    Value Loss: 4.571    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2695019    Buffer Size: 15440      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:50:44,790][train][INFO][train.py>_log] ==> #1215000    Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 9.885    Value Loss: 4.306    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2697425    Buffer Size: 15488      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:53:57,913][train][INFO][train.py>_log] ==> #1216000    Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 10.033   Value Loss: 4.481    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 2699945    Buffer Size: 15533      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:57:14,854][train][INFO][train.py>_log] ==> #1217000    Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 10.141   Value Loss: 4.570    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 2702525    Buffer Size: 15578      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:00:29,837][train][INFO][train.py>_log] ==> #1218000    Total Loss: 1.692    [weighted Loss:1.692    Policy Loss: 9.748    Value Loss: 4.558    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 2705010    Buffer Size: 15612      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:03:44,730][train][INFO][train.py>_log] ==> #1219000    Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 9.950    Value Loss: 4.616    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2707535    Buffer Size: 15667      Transition Number: 1000.273k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:06:57,074][train][INFO][train.py>_log] ==> #1220000    Total Loss: 3.198    [weighted Loss:3.198    Policy Loss: 9.964    Value Loss: 4.361    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2709942    Buffer Size: 15693      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:10:12,542][train][INFO][train.py>_log] ==> #1221000    Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 9.918    Value Loss: 4.335    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 2712419    Buffer Size: 15732      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:13:24,538][train][INFO][train.py>_log] ==> #1222000    Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 9.681    Value Loss: 4.647    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 2714950    Buffer Size: 15748      Transition Number: 1000.334k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:16:38,672][train][INFO][train.py>_log] ==> #1223000    Total Loss: 2.164    [weighted Loss:2.164    Policy Loss: 9.654    Value Loss: 4.458    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2717397    Buffer Size: 15750      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:19:52,702][train][INFO][train.py>_log] ==> #1224000    Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 9.862    Value Loss: 4.789    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 2719881    Buffer Size: 15752      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:23:05,701][train][INFO][train.py>_log] ==> #1225000    Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 10.338   Value Loss: 4.353    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 2722384    Buffer Size: 15724      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:26:19,981][train][INFO][train.py>_log] ==> #1226000    Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 9.625    Value Loss: 4.407    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2724814    Buffer Size: 15706      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:29:34,603][train][INFO][train.py>_log] ==> #1227000    Total Loss: 1.068    [weighted Loss:1.068    Policy Loss: 10.081   Value Loss: 4.473    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2727300    Buffer Size: 15675      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:32:51,435][train][INFO][train.py>_log] ==> #1228000    Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 9.952    Value Loss: 4.556    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 2729739    Buffer Size: 15653      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:36:05,007][train][INFO][train.py>_log] ==> #1229000    Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 10.019   Value Loss: 4.452    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2732296    Buffer Size: 15629      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:39:20,551][train][INFO][train.py>_log] ==> #1230000    Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 10.332   Value Loss: 4.520    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 2734810    Buffer Size: 15625      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:42:39,203][train][INFO][train.py>_log] ==> #1231000    Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 9.960    Value Loss: 4.568    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2737349    Buffer Size: 15614      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:45:54,908][train][INFO][train.py>_log] ==> #1232000    Total Loss: 2.824    [weighted Loss:2.824    Policy Loss: 9.620    Value Loss: 4.451    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 2739869    Buffer Size: 15602      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:49:11,385][train][INFO][train.py>_log] ==> #1233000    Total Loss: 1.042    [weighted Loss:1.042    Policy Loss: 10.034   Value Loss: 4.619    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2742375    Buffer Size: 15605      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:52:25,509][train][INFO][train.py>_log] ==> #1234000    Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 10.097   Value Loss: 4.021    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2744702    Buffer Size: 15599      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:55:39,820][train][INFO][train.py>_log] ==> #1235000    Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 9.852    Value Loss: 4.146    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 2747257    Buffer Size: 15595      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:58:55,061][train][INFO][train.py>_log] ==> #1236000    Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 9.917    Value Loss: 4.350    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2749783    Buffer Size: 15580      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:02:12,048][train][INFO][train.py>_log] ==> #1237000    Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 10.151   Value Loss: 4.346    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 2752220    Buffer Size: 15570      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:05:25,636][train][INFO][train.py>_log] ==> #1238000    Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 9.735    Value Loss: 4.041    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2754756    Buffer Size: 15543      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:08:39,963][train][INFO][train.py>_log] ==> #1239000    Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 10.358   Value Loss: 4.416    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 2757156    Buffer Size: 15536      Transition Number: 1000.286k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:11:54,839][train][INFO][train.py>_log] ==> #1240000    Total Loss: 2.524    [weighted Loss:2.524    Policy Loss: 9.973    Value Loss: 4.285    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2759682    Buffer Size: 15506      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:15:08,905][train][INFO][train.py>_log] ==> #1241000    Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 9.731    Value Loss: 4.560    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2762130    Buffer Size: 15483      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:18:22,676][train][INFO][train.py>_log] ==> #1242000    Total Loss: 3.263    [weighted Loss:3.263    Policy Loss: 9.822    Value Loss: 4.252    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 2764623    Buffer Size: 15457      Transition Number: 1000.079k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:21:40,907][train][INFO][train.py>_log] ==> #1243000    Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 10.141   Value Loss: 4.377    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2767052    Buffer Size: 15440      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:24:53,451][train][INFO][train.py>_log] ==> #1244000    Total Loss: 3.828    [weighted Loss:3.828    Policy Loss: 9.950    Value Loss: 4.108    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 2769534    Buffer Size: 15427      Transition Number: 1000.131k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:28:08,022][train][INFO][train.py>_log] ==> #1245000    Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 10.306   Value Loss: 4.245    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2772048    Buffer Size: 15393      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:31:23,384][train][INFO][train.py>_log] ==> #1246000    Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 9.919    Value Loss: 4.038    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2774472    Buffer Size: 15386      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:34:36,658][train][INFO][train.py>_log] ==> #1247000    Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 9.205    Value Loss: 4.719    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 2776931    Buffer Size: 15360      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:37:53,653][train][INFO][train.py>_log] ==> #1248000    Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 9.989    Value Loss: 4.420    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 2779516    Buffer Size: 15327      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:41:11,841][train][INFO][train.py>_log] ==> #1249000    Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 9.819    Value Loss: 4.249    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2781975    Buffer Size: 15320      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:44:26,560][train][INFO][train.py>_log] ==> #1250000    Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 10.017   Value Loss: 4.625    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2784446    Buffer Size: 15304      Transition Number: 1000.197k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:47:42,610][train][INFO][train.py>_log] ==> #1251000    Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 9.971    Value Loss: 4.339    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2786987    Buffer Size: 15284      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:50:58,035][train][INFO][train.py>_log] ==> #1252000    Total Loss: 3.377    [weighted Loss:3.377    Policy Loss: 9.810    Value Loss: 4.620    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2789445    Buffer Size: 15276      Transition Number: 1000.401k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:54:12,195][train][INFO][train.py>_log] ==> #1253000    Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 9.323    Value Loss: 4.518    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 2791896    Buffer Size: 15262      Transition Number: 1000.295k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:57:29,082][train][INFO][train.py>_log] ==> #1254000    Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 10.025   Value Loss: 4.370    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2794470    Buffer Size: 15233      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:00:45,659][train][INFO][train.py>_log] ==> #1255000    Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 9.911    Value Loss: 4.272    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2796848    Buffer Size: 15203      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:04:01,748][train][INFO][train.py>_log] ==> #1256000    Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 9.958    Value Loss: 4.599    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2799383    Buffer Size: 15168      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:07:20,569][train][INFO][train.py>_log] ==> #1257000    Total Loss: 2.199    [weighted Loss:2.199    Policy Loss: 9.874    Value Loss: 4.278    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 2801998    Buffer Size: 15146      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:10:37,325][train][INFO][train.py>_log] ==> #1258000    Total Loss: 1.607    [weighted Loss:1.607    Policy Loss: 10.085   Value Loss: 4.447    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2804455    Buffer Size: 15135      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:13:51,124][train][INFO][train.py>_log] ==> #1259000    Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 9.882    Value Loss: 4.507    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 2806867    Buffer Size: 15113      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:17:07,597][train][INFO][train.py>_log] ==> #1260000    Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 10.125   Value Loss: 4.248    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2809470    Buffer Size: 15090      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:20:25,144][train][INFO][train.py>_log] ==> #1261000    Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 10.258   Value Loss: 4.488    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2811919    Buffer Size: 15077      Transition Number: 1000.732k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:23:42,432][train][INFO][train.py>_log] ==> #1262000    Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 9.986    Value Loss: 4.549    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 2814405    Buffer Size: 15062      Transition Number: 1000.345k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:27:02,806][train][INFO][train.py>_log] ==> #1263000    Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 9.632    Value Loss: 4.469    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 2816981    Buffer Size: 15043      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:30:21,892][train][INFO][train.py>_log] ==> #1264000    Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 9.719    Value Loss: 4.418    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 2819448    Buffer Size: 15021      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:33:35,184][train][INFO][train.py>_log] ==> #1265000    Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 10.117   Value Loss: 4.042    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 2821892    Buffer Size: 15006      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:36:54,592][train][INFO][train.py>_log] ==> #1266000    Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 9.922    Value Loss: 4.199    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 2824458    Buffer Size: 15006      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:40:12,366][train][INFO][train.py>_log] ==> #1267000    Total Loss: 2.546    [weighted Loss:2.546    Policy Loss: 10.007   Value Loss: 4.470    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 2826982    Buffer Size: 15005      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:43:27,126][train][INFO][train.py>_log] ==> #1268000    Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 10.047   Value Loss: 4.624    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2829533    Buffer Size: 14988      Transition Number: 1000.298k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:46:42,877][train][INFO][train.py>_log] ==> #1269000    Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 9.703    Value Loss: 4.307    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 2831987    Buffer Size: 14976      Transition Number: 1000.229k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:49:56,327][train][INFO][train.py>_log] ==> #1270000    Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 9.600    Value Loss: 4.345    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2834348    Buffer Size: 14971      Transition Number: 1000.383k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:53:13,732][train][INFO][train.py>_log] ==> #1271000    Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 10.098   Value Loss: 4.416    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 2836889    Buffer Size: 14941      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:56:32,159][train][INFO][train.py>_log] ==> #1272000    Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 9.768    Value Loss: 4.841    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2839433    Buffer Size: 14934      Transition Number: 1000.304k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:59:47,622][train][INFO][train.py>_log] ==> #1273000    Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 9.765    Value Loss: 4.785    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2841837    Buffer Size: 14923      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:03:01,948][train][INFO][train.py>_log] ==> #1274000    Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 9.741    Value Loss: 4.296    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2844382    Buffer Size: 14912      Transition Number: 1000.458k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:06:19,522][train][INFO][train.py>_log] ==> #1275000    Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 9.746    Value Loss: 4.642    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2846870    Buffer Size: 14898      Transition Number: 1000.316k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:09:36,765][train][INFO][train.py>_log] ==> #1276000    Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 9.524    Value Loss: 4.473    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 2849297    Buffer Size: 14884      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:12:55,295][train][INFO][train.py>_log] ==> #1277000    Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 9.892    Value Loss: 4.650    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2851875    Buffer Size: 14878      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:16:10,896][train][INFO][train.py>_log] ==> #1278000    Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 10.029   Value Loss: 4.322    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2854326    Buffer Size: 14879      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:19:28,112][train][INFO][train.py>_log] ==> #1279000    Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 9.525    Value Loss: 4.644    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2856824    Buffer Size: 14868      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:22:44,854][train][INFO][train.py>_log] ==> #1280000    Total Loss: 1.429    [weighted Loss:1.429    Policy Loss: 9.487    Value Loss: 4.680    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 2859395    Buffer Size: 14863      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:26:03,929][train][INFO][train.py>_log] ==> #1281000    Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 9.386    Value Loss: 4.589    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 2861955    Buffer Size: 14845      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:29:24,824][train][INFO][train.py>_log] ==> #1282000    Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 9.969    Value Loss: 4.462    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 2864410    Buffer Size: 14834      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:32:42,554][train][INFO][train.py>_log] ==> #1283000    Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 9.176    Value Loss: 4.662    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2866906    Buffer Size: 14816      Transition Number: 1000.223k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:35:58,518][train][INFO][train.py>_log] ==> #1284000    Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 9.321    Value Loss: 4.709    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2869503    Buffer Size: 14788      Transition Number: 1000.371k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:39:17,678][train][INFO][train.py>_log] ==> #1285000    Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 9.329    Value Loss: 4.638    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2871947    Buffer Size: 14780      Transition Number: 1000.255k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:42:38,050][train][INFO][train.py>_log] ==> #1286000    Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 9.417    Value Loss: 4.519    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2874511    Buffer Size: 14772      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:45:58,719][train][INFO][train.py>_log] ==> #1287000    Total Loss: 2.986    [weighted Loss:2.986    Policy Loss: 9.447    Value Loss: 4.224    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2877036    Buffer Size: 14780      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:49:18,503][train][INFO][train.py>_log] ==> #1288000    Total Loss: 1.562    [weighted Loss:1.562    Policy Loss: 9.092    Value Loss: 4.698    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 2879515    Buffer Size: 14786      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:52:35,020][train][INFO][train.py>_log] ==> #1289000    Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 9.567    Value Loss: 4.727    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 2882038    Buffer Size: 14800      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:55:51,796][train][INFO][train.py>_log] ==> #1290000    Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 8.959    Value Loss: 4.556    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2884593    Buffer Size: 14804      Transition Number: 1000.608k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:59:06,684][train][INFO][train.py>_log] ==> #1291000    Total Loss: 1.746    [weighted Loss:1.746    Policy Loss: 9.200    Value Loss: 4.448    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2887088    Buffer Size: 14793      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:02:23,543][train][INFO][train.py>_log] ==> #1292000    Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 9.345    Value Loss: 4.386    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 2889454    Buffer Size: 14804      Transition Number: 1000.679k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:05:44,329][train][INFO][train.py>_log] ==> #1293000    Total Loss: 1.569    [weighted Loss:1.569    Policy Loss: 8.710    Value Loss: 4.103    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 2892014    Buffer Size: 14812      Transition Number: 1000.455k Batch Size: 256        Lr: 0.00010 
