[2022-02-19 09:09:36,446][train][INFO][train.py>_log] ==> #0          Total Loss: 46.982   [weighted Loss:46.982   Policy Loss: 12.510   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1161       Buffer Size: 1161       Transition Number: 11.562  k Batch Size: 256        Lr: 0.00000 
[2022-02-19 09:12:19,437][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.060    [weighted Loss:6.060    Policy Loss: 14.402   Value Loss: 4.930    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 11681      Buffer Size: 11681      Transition Number: 145.307 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:14:55,763][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.003    [weighted Loss:7.003    Policy Loss: 13.709   Value Loss: 4.313    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 21480      Buffer Size: 21480      Transition Number: 267.819 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:17:33,033][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.862    [weighted Loss:5.862    Policy Loss: 13.191   Value Loss: 4.729    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 28924      Buffer Size: 28924      Transition Number: 383.657 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:20:14,838][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.034    [weighted Loss:6.034    Policy Loss: 10.748   Value Loss: 4.156    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 36533      Buffer Size: 36533      Transition Number: 505.113 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:22:51,292][train][INFO][train.py>_log] ==> #5000       Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 9.161    Value Loss: 4.035    Reward Loss: 1.047    Consistency Loss: 0.000    ] Replay Episodes Collected: 41805      Buffer Size: 41805      Transition Number: 619.551 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:25:28,111][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.941    [weighted Loss:3.941    Policy Loss: 6.669    Value Loss: 4.428    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 47141      Buffer Size: 47141      Transition Number: 728.814 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:28:09,500][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 6.617    Value Loss: 4.424    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 50713      Buffer Size: 50713      Transition Number: 826.481 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:30:46,258][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 4.421    Value Loss: 4.078    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 54327      Buffer Size: 54327      Transition Number: 936.928 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:33:23,697][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 3.359    Value Loss: 4.286    Reward Loss: 1.071    Consistency Loss: 0.000    ] Replay Episodes Collected: 57379      Buffer Size: 53518      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:36:04,083][train][INFO][train.py>_log] ==> #10000      Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 2.884    Value Loss: 4.010    Reward Loss: 0.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 60510      Buffer Size: 48126      Transition Number: 1000.245k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:38:46,590][train][INFO][train.py>_log] ==> #11000      Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 3.074    Value Loss: 3.854    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 63016      Buffer Size: 42487      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:41:29,142][train][INFO][train.py>_log] ==> #12000      Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 3.327    Value Loss: 4.160    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 65591      Buffer Size: 37551      Transition Number: 1000.150k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:44:12,537][train][INFO][train.py>_log] ==> #13000      Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 3.003    Value Loss: 4.073    Reward Loss: 0.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 67577      Buffer Size: 32687      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:46:51,145][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.643    [weighted Loss:1.643    Policy Loss: 3.067    Value Loss: 4.267    Reward Loss: 0.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 69434      Buffer Size: 28873      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:49:30,929][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.668    [weighted Loss:1.668    Policy Loss: 3.411    Value Loss: 3.898    Reward Loss: 0.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 71491      Buffer Size: 25350      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:52:11,723][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 3.406    Value Loss: 4.476    Reward Loss: 0.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 73391      Buffer Size: 23237      Transition Number: 1000.296k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:54:49,599][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 3.716    Value Loss: 4.409    Reward Loss: 0.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 75378      Buffer Size: 21804      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-19 09:57:29,731][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 3.303    Value Loss: 4.400    Reward Loss: 0.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 77327      Buffer Size: 20438      Transition Number: 1000.024k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:00:10,682][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 3.437    Value Loss: 4.697    Reward Loss: 0.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 79324      Buffer Size: 19138      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:02:53,063][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 3.396    Value Loss: 4.552    Reward Loss: 0.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 81277      Buffer Size: 18451      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:05:31,540][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.150    [weighted Loss:1.150    Policy Loss: 3.568    Value Loss: 4.628    Reward Loss: 0.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 83293      Buffer Size: 17871      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:08:11,518][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 3.813    Value Loss: 4.447    Reward Loss: 0.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 85228      Buffer Size: 17921      Transition Number: 1000.028k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:10:50,954][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.236    [weighted Loss:2.236    Policy Loss: 3.784    Value Loss: 4.641    Reward Loss: 0.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 87256      Buffer Size: 18107      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:13:29,697][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.266    [weighted Loss:2.266    Policy Loss: 3.955    Value Loss: 4.479    Reward Loss: 0.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 89283      Buffer Size: 18133      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:16:11,313][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 4.629    Value Loss: 4.793    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 91245      Buffer Size: 18154      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:18:47,939][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.328    [weighted Loss:1.328    Policy Loss: 4.659    Value Loss: 4.524    Reward Loss: 0.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 93201      Buffer Size: 18137      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:21:25,022][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.045    [weighted Loss:3.045    Policy Loss: 4.747    Value Loss: 5.072    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 95495      Buffer Size: 18622      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:24:06,979][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 4.860    Value Loss: 4.921    Reward Loss: 0.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 97792      Buffer Size: 18910      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:26:42,932][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 4.463    Value Loss: 4.870    Reward Loss: 0.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 99938      Buffer Size: 19123      Transition Number: 999.953 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:29:20,609][train][INFO][train.py>_log] ==> #30000      Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 3.754    Value Loss: 4.990    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 102122     Buffer Size: 19266      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:31:59,179][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.199    [weighted Loss:2.199    Policy Loss: 3.652    Value Loss: 5.200    Reward Loss: 0.906    Consistency Loss: 0.000    ] Replay Episodes Collected: 103888     Buffer Size: 19297      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:34:39,722][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 3.587    Value Loss: 4.683    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 105815     Buffer Size: 19183      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:37:14,996][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 3.702    Value Loss: 5.439    Reward Loss: 0.915    Consistency Loss: 0.000    ] Replay Episodes Collected: 107893     Buffer Size: 19105      Transition Number: 1000.270k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:39:54,413][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.764    [weighted Loss:1.764    Policy Loss: 3.775    Value Loss: 5.272    Reward Loss: 0.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 109801     Buffer Size: 19105      Transition Number: 1000.340k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:42:33,315][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.418    [weighted Loss:2.418    Policy Loss: 4.269    Value Loss: 5.492    Reward Loss: 1.015    Consistency Loss: 0.000    ] Replay Episodes Collected: 111726     Buffer Size: 19033      Transition Number: 1000.158k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:45:11,793][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 3.776    Value Loss: 5.679    Reward Loss: 0.965    Consistency Loss: 0.000    ] Replay Episodes Collected: 113613     Buffer Size: 18868      Transition Number: 1000.354k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:47:53,547][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.445    [weighted Loss:1.445    Policy Loss: 3.560    Value Loss: 4.941    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 115601     Buffer Size: 18384      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:50:29,921][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 4.300    Value Loss: 5.729    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 117507     Buffer Size: 18091      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:53:07,705][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 4.572    Value Loss: 5.509    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 119262     Buffer Size: 17774      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:55:49,104][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.153    [weighted Loss:2.153    Policy Loss: 4.632    Value Loss: 5.385    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 121119     Buffer Size: 17627      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 10:58:25,670][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 4.695    Value Loss: 5.147    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 122824     Buffer Size: 17450      Transition Number: 1000.132k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:01:05,273][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 5.163    Value Loss: 5.528    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 124612     Buffer Size: 17169      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:03:43,858][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 6.045    Value Loss: 5.342    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 126323     Buffer Size: 16849      Transition Number: 1000.426k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:06:24,824][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 5.956    Value Loss: 4.897    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 127985     Buffer Size: 16508      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:09:03,344][train][INFO][train.py>_log] ==> #45000      Total Loss: 3.086    [weighted Loss:3.086    Policy Loss: 6.890    Value Loss: 5.057    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 129750     Buffer Size: 16128      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:11:44,219][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.570    [weighted Loss:4.570    Policy Loss: 7.755    Value Loss: 4.959    Reward Loss: 1.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 131463     Buffer Size: 15891      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:14:23,322][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 7.173    Value Loss: 5.158    Reward Loss: 1.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 133306     Buffer Size: 15578      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:17:02,261][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.125    [weighted Loss:3.125    Policy Loss: 6.912    Value Loss: 4.792    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 135005     Buffer Size: 15333      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:19:45,430][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.105    Value Loss: 4.908    Reward Loss: 1.052    Consistency Loss: 0.000    ] Replay Episodes Collected: 136761     Buffer Size: 15112      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:22:24,194][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 7.613    Value Loss: 4.582    Reward Loss: 0.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 138620     Buffer Size: 14989      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:25:02,234][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.535    [weighted Loss:3.535    Policy Loss: 7.970    Value Loss: 4.641    Reward Loss: 0.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 140322     Buffer Size: 14978      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:27:43,680][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.854    [weighted Loss:3.854    Policy Loss: 7.468    Value Loss: 4.316    Reward Loss: 0.920    Consistency Loss: 0.000    ] Replay Episodes Collected: 142221     Buffer Size: 15004      Transition Number: 1000.330k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:30:21,397][train][INFO][train.py>_log] ==> #53000      Total Loss: 4.678    [weighted Loss:4.678    Policy Loss: 7.932    Value Loss: 4.480    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 144011     Buffer Size: 15007      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:33:00,441][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.258    [weighted Loss:3.258    Policy Loss: 8.444    Value Loss: 4.669    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 145836     Buffer Size: 14969      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:35:39,768][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.172    [weighted Loss:3.172    Policy Loss: 8.170    Value Loss: 4.561    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 147692     Buffer Size: 14981      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:38:20,760][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.397    [weighted Loss:3.397    Policy Loss: 7.099    Value Loss: 5.075    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 149573     Buffer Size: 15043      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:40:59,598][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.440    [weighted Loss:3.440    Policy Loss: 7.424    Value Loss: 4.645    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 151335     Buffer Size: 15060      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:43:42,599][train][INFO][train.py>_log] ==> #58000      Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 6.518    Value Loss: 4.763    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 153257     Buffer Size: 15066      Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:46:22,152][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 7.030    Value Loss: 4.468    Reward Loss: 1.014    Consistency Loss: 0.000    ] Replay Episodes Collected: 155057     Buffer Size: 15028      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:49:01,803][train][INFO][train.py>_log] ==> #60000      Total Loss: 4.625    [weighted Loss:4.625    Policy Loss: 7.590    Value Loss: 4.472    Reward Loss: 1.123    Consistency Loss: 0.000    ] Replay Episodes Collected: 156995     Buffer Size: 14963      Transition Number: 1000.048k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:51:45,782][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 7.835    Value Loss: 4.784    Reward Loss: 1.076    Consistency Loss: 0.000    ] Replay Episodes Collected: 158868     Buffer Size: 14933      Transition Number: 999.960 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:54:25,686][train][INFO][train.py>_log] ==> #62000      Total Loss: 4.242    [weighted Loss:4.242    Policy Loss: 6.915    Value Loss: 4.582    Reward Loss: 1.153    Consistency Loss: 0.000    ] Replay Episodes Collected: 160763     Buffer Size: 14926      Transition Number: 1000.252k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:57:03,894][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.335    [weighted Loss:4.335    Policy Loss: 7.939    Value Loss: 4.491    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 162521     Buffer Size: 14887      Transition Number: 1000.301k Batch Size: 256        Lr: 0.10000 
[2022-02-19 11:59:43,595][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 7.806    Value Loss: 4.808    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 164283     Buffer Size: 14835      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:02:25,105][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 7.948    Value Loss: 4.370    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 166134     Buffer Size: 14819      Transition Number: 1000.036k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:05:04,207][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.778    [weighted Loss:2.778    Policy Loss: 8.002    Value Loss: 4.856    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 167963     Buffer Size: 14823      Transition Number: 1000.164k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:07:47,519][train][INFO][train.py>_log] ==> #67000      Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 7.985    Value Loss: 4.884    Reward Loss: 1.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 169752     Buffer Size: 14745      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:10:26,065][train][INFO][train.py>_log] ==> #68000      Total Loss: 3.517    [weighted Loss:3.517    Policy Loss: 7.799    Value Loss: 4.821    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 171553     Buffer Size: 14682      Transition Number: 1000.399k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:13:04,496][train][INFO][train.py>_log] ==> #69000      Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 8.012    Value Loss: 4.644    Reward Loss: 1.104    Consistency Loss: 0.000    ] Replay Episodes Collected: 173349     Buffer Size: 14599      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:15:46,636][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 7.324    Value Loss: 4.704    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 175127     Buffer Size: 14512      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:18:26,318][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.781    [weighted Loss:3.781    Policy Loss: 7.643    Value Loss: 4.889    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 176923     Buffer Size: 14381      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:21:06,324][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.560    [weighted Loss:2.560    Policy Loss: 7.283    Value Loss: 4.751    Reward Loss: 1.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 178797     Buffer Size: 14238      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:23:46,662][train][INFO][train.py>_log] ==> #73000      Total Loss: 3.133    [weighted Loss:3.133    Policy Loss: 7.081    Value Loss: 4.639    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 180679     Buffer Size: 14193      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:26:31,220][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.443    [weighted Loss:3.443    Policy Loss: 6.823    Value Loss: 4.796    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 182415     Buffer Size: 14133      Transition Number: 1000.182k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:29:10,248][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 7.721    Value Loss: 4.569    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 184207     Buffer Size: 14124      Transition Number: 1000.280k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:31:52,919][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 7.690    Value Loss: 4.474    Reward Loss: 1.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 186030     Buffer Size: 14107      Transition Number: 1000.073k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:34:31,937][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.997    [weighted Loss:3.997    Policy Loss: 8.141    Value Loss: 4.988    Reward Loss: 1.112    Consistency Loss: 0.000    ] Replay Episodes Collected: 188311     Buffer Size: 14619      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:37:12,454][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.072    [weighted Loss:5.072    Policy Loss: 8.845    Value Loss: 5.474    Reward Loss: 1.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 190627     Buffer Size: 15196      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:39:56,021][train][INFO][train.py>_log] ==> #79000      Total Loss: 4.303    [weighted Loss:4.303    Policy Loss: 8.602    Value Loss: 5.368    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 192347     Buffer Size: 15441      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:42:35,871][train][INFO][train.py>_log] ==> #80000      Total Loss: 5.309    [weighted Loss:5.309    Policy Loss: 8.714    Value Loss: 5.575    Reward Loss: 1.125    Consistency Loss: 0.000    ] Replay Episodes Collected: 194281     Buffer Size: 15685      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:45:15,760][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.730    [weighted Loss:4.730    Policy Loss: 9.491    Value Loss: 5.621    Reward Loss: 1.165    Consistency Loss: 0.000    ] Replay Episodes Collected: 196030     Buffer Size: 15780      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:47:58,440][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 8.551    Value Loss: 5.533    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 197889     Buffer Size: 15868      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:50:39,295][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 8.221    Value Loss: 5.797    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 199586     Buffer Size: 15931      Transition Number: 1000.700k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:53:18,946][train][INFO][train.py>_log] ==> #84000      Total Loss: 3.667    [weighted Loss:3.667    Policy Loss: 8.200    Value Loss: 5.759    Reward Loss: 1.257    Consistency Loss: 0.000    ] Replay Episodes Collected: 201384     Buffer Size: 16002      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:56:00,655][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.694    [weighted Loss:3.694    Policy Loss: 8.529    Value Loss: 5.227    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 203195     Buffer Size: 15827      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 12:58:41,522][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.632    [weighted Loss:4.632    Policy Loss: 8.372    Value Loss: 5.137    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 204945     Buffer Size: 15381      Transition Number: 999.945 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:01:22,212][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 7.355    Value Loss: 5.023    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 206909     Buffer Size: 15144      Transition Number: 1000.290k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:04:06,255][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.144    [weighted Loss:4.144    Policy Loss: 7.713    Value Loss: 5.009    Reward Loss: 1.139    Consistency Loss: 0.000    ] Replay Episodes Collected: 208748     Buffer Size: 15071      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:06:45,232][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.899    [weighted Loss:3.899    Policy Loss: 7.724    Value Loss: 5.183    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 210544     Buffer Size: 15075      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:09:24,596][train][INFO][train.py>_log] ==> #90000      Total Loss: 2.442    [weighted Loss:2.442    Policy Loss: 6.983    Value Loss: 5.333    Reward Loss: 1.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 212340     Buffer Size: 15129      Transition Number: 999.927 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:12:07,644][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 7.122    Value Loss: 5.197    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 214225     Buffer Size: 15174      Transition Number: 1000.088k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:14:45,785][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.012    [weighted Loss:4.012    Policy Loss: 7.231    Value Loss: 4.840    Reward Loss: 1.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 216076     Buffer Size: 15228      Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:17:26,344][train][INFO][train.py>_log] ==> #93000      Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 6.741    Value Loss: 5.105    Reward Loss: 1.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 218251     Buffer Size: 15626      Transition Number: 1000.194k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:20:06,383][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 6.931    Value Loss: 5.459    Reward Loss: 1.275    Consistency Loss: 0.000    ] Replay Episodes Collected: 220376     Buffer Size: 16003      Transition Number: 1000.256k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:22:46,381][train][INFO][train.py>_log] ==> #95000      Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 7.406    Value Loss: 5.591    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 223879     Buffer Size: 17538      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:25:26,450][train][INFO][train.py>_log] ==> #96000      Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 8.022    Value Loss: 6.171    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 227291     Buffer Size: 19149      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:28:08,754][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.138    [weighted Loss:4.138    Policy Loss: 7.903    Value Loss: 6.222    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 229608     Buffer Size: 19716      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:30:51,163][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.157    [weighted Loss:4.157    Policy Loss: 7.298    Value Loss: 6.335    Reward Loss: 1.283    Consistency Loss: 0.000    ] Replay Episodes Collected: 232158     Buffer Size: 20307      Transition Number: 1000.019k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:33:30,261][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 7.813    Value Loss: 5.509    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 233887     Buffer Size: 20402      Transition Number: 1000.165k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:36:13,642][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.230    [weighted Loss:4.230    Policy Loss: 7.466    Value Loss: 6.120    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 235770     Buffer Size: 20441      Transition Number: 1000.285k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:38:54,740][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.353    [weighted Loss:3.353    Policy Loss: 7.966    Value Loss: 5.774    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 237673     Buffer Size: 20281      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:41:35,759][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.366    [weighted Loss:3.366    Policy Loss: 7.213    Value Loss: 5.753    Reward Loss: 1.423    Consistency Loss: 0.000    ] Replay Episodes Collected: 239539     Buffer Size: 19982      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:44:16,446][train][INFO][train.py>_log] ==> #103000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 6.731    Value Loss: 5.566    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 241289     Buffer Size: 19130      Transition Number: 1000.124k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:47:00,606][train][INFO][train.py>_log] ==> #104000     Total Loss: 3.016    [weighted Loss:3.016    Policy Loss: 7.157    Value Loss: 5.398    Reward Loss: 1.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 243220     Buffer Size: 17496      Transition Number: 1000.227k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:49:39,120][train][INFO][train.py>_log] ==> #105000     Total Loss: 3.767    [weighted Loss:3.767    Policy Loss: 6.938    Value Loss: 5.427    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 244946     Buffer Size: 16407      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:52:22,777][train][INFO][train.py>_log] ==> #106000     Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 6.970    Value Loss: 5.575    Reward Loss: 1.265    Consistency Loss: 0.000    ] Replay Episodes Collected: 246844     Buffer Size: 15797      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:55:03,000][train][INFO][train.py>_log] ==> #107000     Total Loss: 2.254    [weighted Loss:2.254    Policy Loss: 6.606    Value Loss: 5.234    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 248715     Buffer Size: 15546      Transition Number: 1000.018k Batch Size: 256        Lr: 0.10000 
[2022-02-19 13:57:41,424][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.073    [weighted Loss:3.073    Policy Loss: 6.942    Value Loss: 5.058    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 250552     Buffer Size: 15551      Transition Number: 999.983 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:00:23,694][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.392    [weighted Loss:2.392    Policy Loss: 6.843    Value Loss: 5.253    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 252425     Buffer Size: 15552      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:03:03,595][train][INFO][train.py>_log] ==> #110000     Total Loss: 4.178    [weighted Loss:4.178    Policy Loss: 7.728    Value Loss: 5.151    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 254222     Buffer Size: 15585      Transition Number: 1000.223k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:05:42,555][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 7.761    Value Loss: 5.418    Reward Loss: 1.288    Consistency Loss: 0.000    ] Replay Episodes Collected: 256145     Buffer Size: 15577      Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:08:22,550][train][INFO][train.py>_log] ==> #112000     Total Loss: 2.565    [weighted Loss:2.565    Policy Loss: 7.481    Value Loss: 5.220    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 257995     Buffer Size: 15628      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:11:04,765][train][INFO][train.py>_log] ==> #113000     Total Loss: 4.461    [weighted Loss:4.461    Policy Loss: 7.734    Value Loss: 5.339    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 259771     Buffer Size: 15718      Transition Number: 1000.304k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:13:43,642][train][INFO][train.py>_log] ==> #114000     Total Loss: 3.160    [weighted Loss:3.160    Policy Loss: 7.239    Value Loss: 4.801    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 261734     Buffer Size: 15760      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:16:25,353][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.969    [weighted Loss:4.969    Policy Loss: 8.769    Value Loss: 4.740    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 263619     Buffer Size: 15829      Transition Number: 1000.427k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:19:03,318][train][INFO][train.py>_log] ==> #116000     Total Loss: 4.345    [weighted Loss:4.345    Policy Loss: 8.191    Value Loss: 4.794    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 265475     Buffer Size: 15884      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:21:44,448][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 8.211    Value Loss: 4.993    Reward Loss: 1.408    Consistency Loss: 0.000    ] Replay Episodes Collected: 267386     Buffer Size: 15909      Transition Number: 1000.221k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:24:26,728][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 7.923    Value Loss: 4.997    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 269219     Buffer Size: 15907      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:27:07,528][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.435    [weighted Loss:4.435    Policy Loss: 8.467    Value Loss: 4.995    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 271086     Buffer Size: 15921      Transition Number: 1000.232k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:29:46,610][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.126    [weighted Loss:3.126    Policy Loss: 7.236    Value Loss: 5.197    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 273067     Buffer Size: 15910      Transition Number: 1000.209k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:32:26,254][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.407    [weighted Loss:3.407    Policy Loss: 7.696    Value Loss: 5.079    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 274845     Buffer Size: 15824      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:35:09,133][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.516    [weighted Loss:3.516    Policy Loss: 7.304    Value Loss: 5.146    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 276694     Buffer Size: 15741      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:37:50,383][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 7.178    Value Loss: 5.026    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 278492     Buffer Size: 15646      Transition Number: 999.955 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:40:33,784][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.476    [weighted Loss:4.476    Policy Loss: 6.990    Value Loss: 5.060    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 280352     Buffer Size: 15520      Transition Number: 1000.190k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:43:13,492][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 7.433    Value Loss: 4.932    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 282249     Buffer Size: 15373      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:45:52,907][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.053    [weighted Loss:4.053    Policy Loss: 6.937    Value Loss: 4.802    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 284025     Buffer Size: 15288      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:48:36,939][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.061    [weighted Loss:3.061    Policy Loss: 6.801    Value Loss: 5.156    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 285911     Buffer Size: 15226      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:51:17,388][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 6.604    Value Loss: 4.930    Reward Loss: 1.320    Consistency Loss: 0.000    ] Replay Episodes Collected: 287768     Buffer Size: 15131      Transition Number: 1000.539k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:53:56,331][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.846    [weighted Loss:3.846    Policy Loss: 7.313    Value Loss: 4.696    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 289542     Buffer Size: 15061      Transition Number: 1000.182k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:56:38,165][train][INFO][train.py>_log] ==> #130000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 6.375    Value Loss: 5.069    Reward Loss: 1.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 291419     Buffer Size: 14997      Transition Number: 999.930 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 14:59:19,543][train][INFO][train.py>_log] ==> #131000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 6.516    Value Loss: 4.762    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 293264     Buffer Size: 14937      Transition Number: 1000.330k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:01:59,589][train][INFO][train.py>_log] ==> #132000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 6.212    Value Loss: 4.816    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 295052     Buffer Size: 14869      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:04:43,341][train][INFO][train.py>_log] ==> #133000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 6.181    Value Loss: 4.436    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 296936     Buffer Size: 14861      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:07:25,099][train][INFO][train.py>_log] ==> #134000     Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 6.531    Value Loss: 5.073    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 298832     Buffer Size: 14833      Transition Number: 1000.176k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:10:06,357][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 6.336    Value Loss: 5.070    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 301278     Buffer Size: 15395      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:12:48,098][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.967    Value Loss: 5.445    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 303579     Buffer Size: 15949      Transition Number: 1000.033k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:15:28,266][train][INFO][train.py>_log] ==> #137000     Total Loss: 3.308    [weighted Loss:3.308    Policy Loss: 6.935    Value Loss: 5.611    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 305310     Buffer Size: 16074      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:18:08,768][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.364    [weighted Loss:4.364    Policy Loss: 7.441    Value Loss: 5.208    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 307181     Buffer Size: 16165      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:20:50,979][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.799    [weighted Loss:3.799    Policy Loss: 6.799    Value Loss: 5.244    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 309219     Buffer Size: 16210      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:23:33,137][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.200    [weighted Loss:3.200    Policy Loss: 6.917    Value Loss: 5.263    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 310994     Buffer Size: 16276      Transition Number: 1000.096k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:26:12,392][train][INFO][train.py>_log] ==> #141000     Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 6.385    Value Loss: 5.402    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 312743     Buffer Size: 16343      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:28:57,836][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.802    [weighted Loss:3.802    Policy Loss: 7.018    Value Loss: 5.150    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 314684     Buffer Size: 16415      Transition Number: 1000.117k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:31:38,573][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.553    [weighted Loss:3.553    Policy Loss: 6.364    Value Loss: 5.263    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 316513     Buffer Size: 16161      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:34:20,317][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.894    [weighted Loss:2.894    Policy Loss: 6.679    Value Loss: 4.950    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 318471     Buffer Size: 15582      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:37:04,003][train][INFO][train.py>_log] ==> #145000     Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 6.901    Value Loss: 5.368    Reward Loss: 1.546    Consistency Loss: 0.000    ] Replay Episodes Collected: 320236     Buffer Size: 15387      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:39:43,392][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.841    Value Loss: 4.898    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 322090     Buffer Size: 15374      Transition Number: 1000.288k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:42:23,739][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 7.030    Value Loss: 4.984    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 323844     Buffer Size: 15378      Transition Number: 1000.339k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:45:06,034][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.930    Value Loss: 4.892    Reward Loss: 1.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 325696     Buffer Size: 15408      Transition Number: 1000.137k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:47:46,819][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 6.854    Value Loss: 5.171    Reward Loss: 1.365    Consistency Loss: 0.000    ] Replay Episodes Collected: 327582     Buffer Size: 15464      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:50:28,865][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.752    [weighted Loss:3.752    Policy Loss: 7.182    Value Loss: 5.222    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 329418     Buffer Size: 15503      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:53:12,375][train][INFO][train.py>_log] ==> #151000     Total Loss: 4.071    [weighted Loss:4.071    Policy Loss: 7.033    Value Loss: 4.896    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 331343     Buffer Size: 15537      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:55:52,841][train][INFO][train.py>_log] ==> #152000     Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 7.057    Value Loss: 4.876    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 333051     Buffer Size: 15572      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 15:58:33,918][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 6.556    Value Loss: 5.080    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 334960     Buffer Size: 15608      Transition Number: 1000.151k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:01:17,135][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.282    [weighted Loss:3.282    Policy Loss: 7.342    Value Loss: 5.055    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 336853     Buffer Size: 15700      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:03:55,182][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.685    [weighted Loss:3.685    Policy Loss: 6.172    Value Loss: 5.135    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 338636     Buffer Size: 15757      Transition Number: 1000.157k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:06:35,319][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 6.472    Value Loss: 4.913    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 340437     Buffer Size: 15799      Transition Number: 1000.075k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:09:17,915][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.681    [weighted Loss:2.681    Policy Loss: 6.936    Value Loss: 5.083    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 342363     Buffer Size: 15864      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:12:00,808][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.884    [weighted Loss:2.884    Policy Loss: 6.466    Value Loss: 5.548    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 344226     Buffer Size: 15924      Transition Number: 1000.199k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:14:42,724][train][INFO][train.py>_log] ==> #159000     Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 5.816    Value Loss: 5.158    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 346072     Buffer Size: 15935      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:17:26,316][train][INFO][train.py>_log] ==> #160000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 6.574    Value Loss: 5.119    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 347856     Buffer Size: 15930      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:20:08,413][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.070    [weighted Loss:3.070    Policy Loss: 6.152    Value Loss: 4.967    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 349618     Buffer Size: 15902      Transition Number: 1000.087k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:22:49,641][train][INFO][train.py>_log] ==> #162000     Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 6.539    Value Loss: 5.419    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 351460     Buffer Size: 15875      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:25:32,810][train][INFO][train.py>_log] ==> #163000     Total Loss: 3.552    [weighted Loss:3.552    Policy Loss: 6.757    Value Loss: 5.265    Reward Loss: 1.490    Consistency Loss: 0.000    ] Replay Episodes Collected: 353335     Buffer Size: 15850      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:28:12,496][train][INFO][train.py>_log] ==> #164000     Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 6.564    Value Loss: 4.900    Reward Loss: 1.499    Consistency Loss: 0.000    ] Replay Episodes Collected: 355024     Buffer Size: 15867      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:30:55,439][train][INFO][train.py>_log] ==> #165000     Total Loss: 4.433    [weighted Loss:4.433    Policy Loss: 6.663    Value Loss: 5.226    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 356906     Buffer Size: 15890      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:33:37,645][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.639    [weighted Loss:3.639    Policy Loss: 6.662    Value Loss: 5.233    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 358726     Buffer Size: 15871      Transition Number: 1000.103k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:36:18,668][train][INFO][train.py>_log] ==> #167000     Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 7.122    Value Loss: 5.265    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 360707     Buffer Size: 15976      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:38:59,246][train][INFO][train.py>_log] ==> #168000     Total Loss: 4.541    [weighted Loss:4.541    Policy Loss: 7.179    Value Loss: 5.555    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 362640     Buffer Size: 16131      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:41:42,493][train][INFO][train.py>_log] ==> #169000     Total Loss: 4.152    [weighted Loss:4.152    Policy Loss: 6.437    Value Loss: 5.063    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 364519     Buffer Size: 16246      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:44:23,551][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 7.395    Value Loss: 5.611    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 366422     Buffer Size: 16381      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:47:05,196][train][INFO][train.py>_log] ==> #171000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 7.259    Value Loss: 5.494    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 368224     Buffer Size: 16462      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:49:49,741][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.952    [weighted Loss:2.952    Policy Loss: 7.071    Value Loss: 5.719    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 370119     Buffer Size: 16512      Transition Number: 999.937 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:52:30,395][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.195    [weighted Loss:3.195    Policy Loss: 7.497    Value Loss: 5.207    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 372084     Buffer Size: 16673      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:55:12,648][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.227    [weighted Loss:3.227    Policy Loss: 7.234    Value Loss: 5.867    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 373994     Buffer Size: 16806      Transition Number: 999.975 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 16:57:56,192][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 7.170    Value Loss: 5.662    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 375834     Buffer Size: 16888      Transition Number: 1000.187k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:00:41,466][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.701    [weighted Loss:3.701    Policy Loss: 7.219    Value Loss: 5.406    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 377786     Buffer Size: 16811      Transition Number: 1000.022k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:03:21,841][train][INFO][train.py>_log] ==> #177000     Total Loss: 2.383    [weighted Loss:2.383    Policy Loss: 7.598    Value Loss: 5.801    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 379697     Buffer Size: 16852      Transition Number: 1000.241k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:06:03,591][train][INFO][train.py>_log] ==> #178000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 7.623    Value Loss: 5.541    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 381681     Buffer Size: 16919      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:08:45,129][train][INFO][train.py>_log] ==> #179000     Total Loss: 4.728    [weighted Loss:4.728    Policy Loss: 7.897    Value Loss: 5.600    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 383635     Buffer Size: 17026      Transition Number: 1000.214k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:11:26,904][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.791    [weighted Loss:2.791    Policy Loss: 7.360    Value Loss: 5.704    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 385659     Buffer Size: 17240      Transition Number: 1000.211k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:14:10,403][train][INFO][train.py>_log] ==> #181000     Total Loss: 3.596    [weighted Loss:3.596    Policy Loss: 7.141    Value Loss: 5.609    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 387483     Buffer Size: 17294      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:16:51,384][train][INFO][train.py>_log] ==> #182000     Total Loss: 4.237    [weighted Loss:4.237    Policy Loss: 7.510    Value Loss: 5.602    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 389432     Buffer Size: 17244      Transition Number: 1000.249k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:19:35,131][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 7.274    Value Loss: 5.583    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 391349     Buffer Size: 17182      Transition Number: 1000.398k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:22:15,371][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.646    [weighted Loss:3.646    Policy Loss: 6.883    Value Loss: 5.502    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 393085     Buffer Size: 17150      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:24:58,034][train][INFO][train.py>_log] ==> #185000     Total Loss: 2.110    [weighted Loss:2.110    Policy Loss: 6.946    Value Loss: 5.874    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 394978     Buffer Size: 17163      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:27:40,482][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.480    [weighted Loss:3.480    Policy Loss: 6.647    Value Loss: 5.666    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 396873     Buffer Size: 17092      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:30:26,186][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 6.495    Value Loss: 5.845    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 398904     Buffer Size: 17074      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:33:08,572][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.811    [weighted Loss:3.811    Policy Loss: 6.686    Value Loss: 5.613    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 400873     Buffer Size: 17001      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:35:52,675][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.738    [weighted Loss:3.738    Policy Loss: 6.240    Value Loss: 5.645    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 402744     Buffer Size: 16797      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:38:34,435][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.642    [weighted Loss:3.642    Policy Loss: 6.492    Value Loss: 5.610    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 404541     Buffer Size: 16733      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:41:15,072][train][INFO][train.py>_log] ==> #191000     Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 6.712    Value Loss: 5.462    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 406681     Buffer Size: 16898      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:43:59,183][train][INFO][train.py>_log] ==> #192000     Total Loss: 4.239    [weighted Loss:4.239    Policy Loss: 6.718    Value Loss: 5.618    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 408742     Buffer Size: 17122      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:46:40,780][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 6.155    Value Loss: 5.496    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 410690     Buffer Size: 17180      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:49:22,624][train][INFO][train.py>_log] ==> #194000     Total Loss: 2.026    [weighted Loss:2.026    Policy Loss: 6.390    Value Loss: 5.054    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 412606     Buffer Size: 17183      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:52:06,017][train][INFO][train.py>_log] ==> #195000     Total Loss: 4.114    [weighted Loss:4.114    Policy Loss: 6.258    Value Loss: 5.572    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 414538     Buffer Size: 17107      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:54:52,100][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.546    [weighted Loss:3.546    Policy Loss: 6.882    Value Loss: 5.430    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 416418     Buffer Size: 17011      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-02-19 17:57:33,044][train][INFO][train.py>_log] ==> #197000     Total Loss: 2.447    [weighted Loss:2.447    Policy Loss: 6.213    Value Loss: 5.306    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 418241     Buffer Size: 16898      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:00:16,813][train][INFO][train.py>_log] ==> #198000     Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 7.198    Value Loss: 4.983    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 420186     Buffer Size: 16899      Transition Number: 1000.261k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:03:01,114][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 6.687    Value Loss: 5.264    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 422108     Buffer Size: 16840      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:05:59,281][train][INFO][train.py>_log] ==> #200000     Total Loss: 2.978    [weighted Loss:2.978    Policy Loss: 6.786    Value Loss: 5.160    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 424021     Buffer Size: 16585      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-02-19 18:08:40,631][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.917    [weighted Loss:2.917    Policy Loss: 6.320    Value Loss: 4.893    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 426105     Buffer Size: 16399      Transition Number: 999.950 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:11:25,906][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.528    [weighted Loss:3.528    Policy Loss: 5.985    Value Loss: 4.843    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 427942     Buffer Size: 16367      Transition Number: 1000.176k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:14:09,297][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 5.966    Value Loss: 5.150    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 429814     Buffer Size: 16320      Transition Number: 1000.301k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:16:52,669][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.627    [weighted Loss:3.627    Policy Loss: 5.794    Value Loss: 4.957    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 431790     Buffer Size: 16295      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:19:35,724][train][INFO][train.py>_log] ==> #205000     Total Loss: 3.392    [weighted Loss:3.392    Policy Loss: 5.721    Value Loss: 4.965    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 433620     Buffer Size: 16279      Transition Number: 1000.004k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:22:21,175][train][INFO][train.py>_log] ==> #206000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 5.951    Value Loss: 4.747    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 435544     Buffer Size: 16288      Transition Number: 1000.330k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:25:02,897][train][INFO][train.py>_log] ==> #207000     Total Loss: 2.542    [weighted Loss:2.542    Policy Loss: 5.790    Value Loss: 5.002    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 437435     Buffer Size: 16261      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:27:49,152][train][INFO][train.py>_log] ==> #208000     Total Loss: 3.124    [weighted Loss:3.124    Policy Loss: 5.931    Value Loss: 4.685    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 439401     Buffer Size: 16243      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:30:33,474][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 5.699    Value Loss: 5.102    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 441264     Buffer Size: 16232      Transition Number: 1000.468k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:33:14,987][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.190    [weighted Loss:3.190    Policy Loss: 6.077    Value Loss: 4.962    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 443116     Buffer Size: 16162      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:36:01,440][train][INFO][train.py>_log] ==> #211000     Total Loss: 2.229    [weighted Loss:2.229    Policy Loss: 6.302    Value Loss: 4.685    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 445001     Buffer Size: 16135      Transition Number: 999.945 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:38:42,626][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 6.176    Value Loss: 4.810    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 446894     Buffer Size: 16127      Transition Number: 1000.062k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:41:26,546][train][INFO][train.py>_log] ==> #213000     Total Loss: 2.627    [weighted Loss:2.627    Policy Loss: 6.110    Value Loss: 4.710    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 448858     Buffer Size: 16106      Transition Number: 1000.176k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:44:10,856][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 6.623    Value Loss: 4.541    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 450718     Buffer Size: 16096      Transition Number: 1000.065k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:46:53,318][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.963    [weighted Loss:2.963    Policy Loss: 6.510    Value Loss: 4.817    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 452716     Buffer Size: 16095      Transition Number: 999.945 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:49:35,339][train][INFO][train.py>_log] ==> #216000     Total Loss: 3.583    [weighted Loss:3.583    Policy Loss: 6.399    Value Loss: 4.741    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 454635     Buffer Size: 16103      Transition Number: 1000.093k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:52:18,396][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 6.868    Value Loss: 4.774    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 456495     Buffer Size: 16089      Transition Number: 1000.266k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:55:00,984][train][INFO][train.py>_log] ==> #218000     Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 6.825    Value Loss: 4.775    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 458374     Buffer Size: 16079      Transition Number: 999.970 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 18:57:45,263][train][INFO][train.py>_log] ==> #219000     Total Loss: 4.332    [weighted Loss:4.332    Policy Loss: 7.004    Value Loss: 4.897    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 460309     Buffer Size: 16073      Transition Number: 1000.201k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:00:29,630][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 6.365    Value Loss: 4.905    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 462236     Buffer Size: 16085      Transition Number: 1000.006k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:03:13,716][train][INFO][train.py>_log] ==> #221000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 6.511    Value Loss: 4.777    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 464334     Buffer Size: 16135      Transition Number: 999.963 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:05:58,943][train][INFO][train.py>_log] ==> #222000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 6.064    Value Loss: 5.116    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 466266     Buffer Size: 16181      Transition Number: 1000.127k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:08:44,583][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 6.878    Value Loss: 5.171    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 468290     Buffer Size: 16207      Transition Number: 1000.027k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:11:30,793][train][INFO][train.py>_log] ==> #224000     Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 6.636    Value Loss: 4.915    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 470171     Buffer Size: 16246      Transition Number: 1000.194k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:14:17,982][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.571    Value Loss: 4.881    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 472185     Buffer Size: 16275      Transition Number: 1000.468k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:17:05,058][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.773    [weighted Loss:3.773    Policy Loss: 6.556    Value Loss: 4.958    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 474142     Buffer Size: 16290      Transition Number: 999.981 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:19:48,318][train][INFO][train.py>_log] ==> #227000     Total Loss: 1.912    [weighted Loss:1.912    Policy Loss: 7.042    Value Loss: 4.801    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 476062     Buffer Size: 16307      Transition Number: 1000.204k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:22:33,992][train][INFO][train.py>_log] ==> #228000     Total Loss: 3.631    [weighted Loss:3.631    Policy Loss: 6.244    Value Loss: 4.852    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 477991     Buffer Size: 16300      Transition Number: 1000.479k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:25:18,375][train][INFO][train.py>_log] ==> #229000     Total Loss: 3.233    [weighted Loss:3.233    Policy Loss: 6.764    Value Loss: 5.157    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 479878     Buffer Size: 16247      Transition Number: 1000.106k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:28:03,285][train][INFO][train.py>_log] ==> #230000     Total Loss: 2.522    [weighted Loss:2.522    Policy Loss: 6.498    Value Loss: 4.717    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 481836     Buffer Size: 16205      Transition Number: 1000.317k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:30:47,747][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.711    [weighted Loss:3.711    Policy Loss: 6.759    Value Loss: 4.815    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 483764     Buffer Size: 16154      Transition Number: 1000.003k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:33:33,809][train][INFO][train.py>_log] ==> #232000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 7.210    Value Loss: 4.742    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 485761     Buffer Size: 16115      Transition Number: 1000.223k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:36:17,724][train][INFO][train.py>_log] ==> #233000     Total Loss: 2.845    [weighted Loss:2.845    Policy Loss: 6.879    Value Loss: 4.956    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 487635     Buffer Size: 16075      Transition Number: 1000.020k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:39:00,401][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 6.685    Value Loss: 4.845    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 489441     Buffer Size: 16050      Transition Number: 1000.341k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:41:46,194][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.863    [weighted Loss:3.863    Policy Loss: 6.927    Value Loss: 4.817    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 491462     Buffer Size: 16007      Transition Number: 999.990 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:44:31,743][train][INFO][train.py>_log] ==> #236000     Total Loss: 3.421    [weighted Loss:3.421    Policy Loss: 6.938    Value Loss: 4.844    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 493485     Buffer Size: 15999      Transition Number: 1000.230k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:47:16,415][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.892    [weighted Loss:3.892    Policy Loss: 7.255    Value Loss: 5.211    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 495402     Buffer Size: 15994      Transition Number: 999.965 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:50:01,462][train][INFO][train.py>_log] ==> #238000     Total Loss: 3.977    [weighted Loss:3.977    Policy Loss: 6.992    Value Loss: 4.657    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 497472     Buffer Size: 15998      Transition Number: 1000.319k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:52:45,587][train][INFO][train.py>_log] ==> #239000     Total Loss: 2.260    [weighted Loss:2.260    Policy Loss: 7.027    Value Loss: 4.801    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 499338     Buffer Size: 16013      Transition Number: 1000.090k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:55:30,088][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 7.162    Value Loss: 5.054    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 501333     Buffer Size: 16032      Transition Number: 999.977 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 19:58:16,924][train][INFO][train.py>_log] ==> #241000     Total Loss: 2.400    [weighted Loss:2.400    Policy Loss: 6.881    Value Loss: 5.000    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 503299     Buffer Size: 16044      Transition Number: 999.965 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:01:03,589][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.029    [weighted Loss:3.029    Policy Loss: 6.904    Value Loss: 4.954    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 505254     Buffer Size: 16069      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:03:47,461][train][INFO][train.py>_log] ==> #243000     Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 7.221    Value Loss: 5.204    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 507191     Buffer Size: 16095      Transition Number: 1000.245k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:06:32,009][train][INFO][train.py>_log] ==> #244000     Total Loss: 3.030    [weighted Loss:3.030    Policy Loss: 6.947    Value Loss: 5.096    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 509107     Buffer Size: 16107      Transition Number: 1000.299k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:09:17,710][train][INFO][train.py>_log] ==> #245000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 7.038    Value Loss: 4.841    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 511155     Buffer Size: 16150      Transition Number: 1000.144k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:12:01,850][train][INFO][train.py>_log] ==> #246000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 7.286    Value Loss: 4.931    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 513196     Buffer Size: 16189      Transition Number: 1000.190k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:14:46,986][train][INFO][train.py>_log] ==> #247000     Total Loss: 4.421    [weighted Loss:4.421    Policy Loss: 7.567    Value Loss: 5.129    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 515182     Buffer Size: 16195      Transition Number: 1000.031k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:17:30,868][train][INFO][train.py>_log] ==> #248000     Total Loss: 2.700    [weighted Loss:2.700    Policy Loss: 7.463    Value Loss: 5.368    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 517028     Buffer Size: 16191      Transition Number: 1000.045k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:20:15,306][train][INFO][train.py>_log] ==> #249000     Total Loss: 4.101    [weighted Loss:4.101    Policy Loss: 7.323    Value Loss: 4.949    Reward Loss: 1.876    Consistency Loss: 0.000    ] Replay Episodes Collected: 518941     Buffer Size: 16161      Transition Number: 1000.023k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:22:58,288][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.603    [weighted Loss:3.603    Policy Loss: 6.940    Value Loss: 5.002    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 520827     Buffer Size: 16149      Transition Number: 1000.070k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:25:44,744][train][INFO][train.py>_log] ==> #251000     Total Loss: 1.924    [weighted Loss:1.924    Policy Loss: 7.606    Value Loss: 4.829    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 522731     Buffer Size: 16134      Transition Number: 1000.131k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:28:30,231][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 7.411    Value Loss: 5.012    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 524732     Buffer Size: 16134      Transition Number: 1000.572k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:31:16,583][train][INFO][train.py>_log] ==> #253000     Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 7.647    Value Loss: 4.693    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 526717     Buffer Size: 16095      Transition Number: 1000.112k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:34:01,982][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.280    [weighted Loss:2.280    Policy Loss: 7.395    Value Loss: 4.885    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 528668     Buffer Size: 16061      Transition Number: 1000.483k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:36:46,298][train][INFO][train.py>_log] ==> #255000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 7.337    Value Loss: 5.137    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 530577     Buffer Size: 16033      Transition Number: 999.993 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:39:30,841][train][INFO][train.py>_log] ==> #256000     Total Loss: 3.999    [weighted Loss:3.999    Policy Loss: 6.984    Value Loss: 5.217    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 532503     Buffer Size: 16012      Transition Number: 1000.023k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:42:14,540][train][INFO][train.py>_log] ==> #257000     Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 7.463    Value Loss: 4.962    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 534418     Buffer Size: 16029      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:45:02,763][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 6.690    Value Loss: 5.085    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 536412     Buffer Size: 16051      Transition Number: 1000.068k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:47:47,737][train][INFO][train.py>_log] ==> #259000     Total Loss: 3.544    [weighted Loss:3.544    Policy Loss: 6.732    Value Loss: 4.947    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 538259     Buffer Size: 16095      Transition Number: 1000.096k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:50:33,620][train][INFO][train.py>_log] ==> #260000     Total Loss: 1.588    [weighted Loss:1.588    Policy Loss: 6.907    Value Loss: 4.766    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 540333     Buffer Size: 16150      Transition Number: 1000.069k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:53:19,431][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.285    [weighted Loss:3.285    Policy Loss: 6.692    Value Loss: 5.090    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 542372     Buffer Size: 16194      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:56:06,648][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.049    [weighted Loss:2.049    Policy Loss: 6.825    Value Loss: 5.250    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 544414     Buffer Size: 16242      Transition Number: 1000.061k Batch Size: 256        Lr: 0.02000 
[2022-02-19 20:58:51,701][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 6.869    Value Loss: 5.242    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 546429     Buffer Size: 16313      Transition Number: 1000.096k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:01:36,571][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 7.114    Value Loss: 5.271    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 548323     Buffer Size: 16390      Transition Number: 999.951 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:04:19,921][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 6.987    Value Loss: 5.133    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 550268     Buffer Size: 16447      Transition Number: 1000.150k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:07:04,270][train][INFO][train.py>_log] ==> #266000     Total Loss: 2.106    [weighted Loss:2.106    Policy Loss: 7.098    Value Loss: 5.218    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 552196     Buffer Size: 16490      Transition Number: 1000.320k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:09:51,970][train][INFO][train.py>_log] ==> #267000     Total Loss: 2.920    [weighted Loss:2.920    Policy Loss: 6.841    Value Loss: 5.396    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 554170     Buffer Size: 16507      Transition Number: 1000.131k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:12:39,224][train][INFO][train.py>_log] ==> #268000     Total Loss: 3.222    [weighted Loss:3.222    Policy Loss: 6.887    Value Loss: 5.094    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 556148     Buffer Size: 16525      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:15:24,130][train][INFO][train.py>_log] ==> #269000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 6.460    Value Loss: 5.219    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 558125     Buffer Size: 16504      Transition Number: 1000.001k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:18:08,015][train][INFO][train.py>_log] ==> #270000     Total Loss: 3.670    [weighted Loss:3.670    Policy Loss: 6.839    Value Loss: 5.297    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 560084     Buffer Size: 16507      Transition Number: 999.991 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:20:54,583][train][INFO][train.py>_log] ==> #271000     Total Loss: 2.871    [weighted Loss:2.871    Policy Loss: 7.141    Value Loss: 5.093    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 562021     Buffer Size: 16487      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:23:40,532][train][INFO][train.py>_log] ==> #272000     Total Loss: 3.690    [weighted Loss:3.690    Policy Loss: 6.619    Value Loss: 5.291    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 564024     Buffer Size: 16503      Transition Number: 1000.519k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:26:28,077][train][INFO][train.py>_log] ==> #273000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 6.465    Value Loss: 4.897    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 565998     Buffer Size: 16490      Transition Number: 999.991 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:29:15,491][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.072    [weighted Loss:3.072    Policy Loss: 6.821    Value Loss: 4.922    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 567962     Buffer Size: 16489      Transition Number: 999.988 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:32:02,748][train][INFO][train.py>_log] ==> #275000     Total Loss: 3.592    [weighted Loss:3.592    Policy Loss: 6.627    Value Loss: 5.025    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 569989     Buffer Size: 16481      Transition Number: 999.947 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:34:47,850][train][INFO][train.py>_log] ==> #276000     Total Loss: 3.791    [weighted Loss:3.791    Policy Loss: 6.515    Value Loss: 5.240    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 571981     Buffer Size: 16464      Transition Number: 1000.109k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:37:36,282][train][INFO][train.py>_log] ==> #277000     Total Loss: 3.399    [weighted Loss:3.399    Policy Loss: 6.455    Value Loss: 5.042    Reward Loss: 1.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 573920     Buffer Size: 16446      Transition Number: 1000.076k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:40:22,896][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.056    [weighted Loss:3.056    Policy Loss: 6.239    Value Loss: 5.049    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 575887     Buffer Size: 16442      Transition Number: 1000.019k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:43:12,841][train][INFO][train.py>_log] ==> #279000     Total Loss: 3.976    [weighted Loss:3.976    Policy Loss: 6.659    Value Loss: 5.172    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 577924     Buffer Size: 16387      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:46:01,339][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 6.321    Value Loss: 4.694    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 579854     Buffer Size: 16327      Transition Number: 1000.154k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:48:49,186][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.414    [weighted Loss:2.414    Policy Loss: 6.707    Value Loss: 5.046    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 581886     Buffer Size: 16252      Transition Number: 1000.379k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:51:37,131][train][INFO][train.py>_log] ==> #282000     Total Loss: 1.894    [weighted Loss:1.894    Policy Loss: 6.039    Value Loss: 4.524    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 583793     Buffer Size: 16198      Transition Number: 1000.028k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:54:26,278][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.434    [weighted Loss:2.434    Policy Loss: 6.614    Value Loss: 5.299    Reward Loss: 1.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 585820     Buffer Size: 16167      Transition Number: 999.942 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 21:57:12,302][train][INFO][train.py>_log] ==> #284000     Total Loss: 2.511    [weighted Loss:2.511    Policy Loss: 6.343    Value Loss: 4.986    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 587797     Buffer Size: 16142      Transition Number: 1000.084k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:00:00,578][train][INFO][train.py>_log] ==> #285000     Total Loss: 2.144    [weighted Loss:2.144    Policy Loss: 6.818    Value Loss: 5.140    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 589844     Buffer Size: 16092      Transition Number: 999.992 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:02:48,597][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 7.158    Value Loss: 4.666    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 591891     Buffer Size: 16044      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:05:35,648][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.426    [weighted Loss:2.426    Policy Loss: 6.923    Value Loss: 5.005    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 593905     Buffer Size: 16022      Transition Number: 999.993 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:08:23,917][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.769    [weighted Loss:2.769    Policy Loss: 6.780    Value Loss: 4.890    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 595890     Buffer Size: 16011      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:11:11,928][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 6.879    Value Loss: 4.760    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 597844     Buffer Size: 16038      Transition Number: 1000.465k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:13:59,240][train][INFO][train.py>_log] ==> #290000     Total Loss: 3.074    [weighted Loss:3.074    Policy Loss: 7.226    Value Loss: 4.910    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 599877     Buffer Size: 16043      Transition Number: 999.960 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:16:46,483][train][INFO][train.py>_log] ==> #291000     Total Loss: 1.731    [weighted Loss:1.731    Policy Loss: 6.841    Value Loss: 4.719    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 601895     Buffer Size: 16020      Transition Number: 1000.180k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:19:32,496][train][INFO][train.py>_log] ==> #292000     Total Loss: 4.229    [weighted Loss:4.229    Policy Loss: 7.519    Value Loss: 4.757    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 603765     Buffer Size: 15994      Transition Number: 1000.018k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:22:19,552][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.759    [weighted Loss:2.759    Policy Loss: 7.112    Value Loss: 4.639    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 605789     Buffer Size: 15972      Transition Number: 999.954 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:25:05,838][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 6.957    Value Loss: 4.566    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 607811     Buffer Size: 15942      Transition Number: 999.968 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:27:51,427][train][INFO][train.py>_log] ==> #295000     Total Loss: 3.889    [weighted Loss:3.889    Policy Loss: 7.566    Value Loss: 5.133    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 609824     Buffer Size: 15916      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:30:37,071][train][INFO][train.py>_log] ==> #296000     Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 6.588    Value Loss: 4.901    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 611860     Buffer Size: 15895      Transition Number: 999.974 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:33:24,619][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.318    [weighted Loss:3.318    Policy Loss: 6.623    Value Loss: 4.828    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 613811     Buffer Size: 15858      Transition Number: 999.963 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:36:09,767][train][INFO][train.py>_log] ==> #298000     Total Loss: 3.729    [weighted Loss:3.729    Policy Loss: 7.392    Value Loss: 4.840    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 615797     Buffer Size: 15815      Transition Number: 1000.055k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:38:55,286][train][INFO][train.py>_log] ==> #299000     Total Loss: 4.033    [weighted Loss:4.033    Policy Loss: 7.354    Value Loss: 4.845    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 617724     Buffer Size: 15793      Transition Number: 1000.003k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:41:40,891][train][INFO][train.py>_log] ==> #300000     Total Loss: 4.020    [weighted Loss:4.020    Policy Loss: 7.068    Value Loss: 4.870    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 619800     Buffer Size: 15774      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:44:28,508][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.948    [weighted Loss:2.948    Policy Loss: 7.338    Value Loss: 4.918    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 621744     Buffer Size: 15770      Transition Number: 1000.166k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:47:16,744][train][INFO][train.py>_log] ==> #302000     Total Loss: 3.108    [weighted Loss:3.108    Policy Loss: 7.180    Value Loss: 4.818    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 623725     Buffer Size: 15770      Transition Number: 1000.082k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:50:02,602][train][INFO][train.py>_log] ==> #303000     Total Loss: 3.537    [weighted Loss:3.537    Policy Loss: 7.084    Value Loss: 4.887    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 625750     Buffer Size: 15781      Transition Number: 1000.255k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:52:51,189][train][INFO][train.py>_log] ==> #304000     Total Loss: 3.821    [weighted Loss:3.821    Policy Loss: 7.045    Value Loss: 5.208    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 627747     Buffer Size: 15773      Transition Number: 1000.055k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:55:39,504][train][INFO][train.py>_log] ==> #305000     Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 6.934    Value Loss: 4.979    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 629777     Buffer Size: 15802      Transition Number: 1000.008k Batch Size: 256        Lr: 0.02000 
[2022-02-19 22:58:30,525][train][INFO][train.py>_log] ==> #306000     Total Loss: 1.256    [weighted Loss:1.256    Policy Loss: 6.890    Value Loss: 4.886    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 631840     Buffer Size: 15816      Transition Number: 1000.011k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:01:16,445][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 6.355    Value Loss: 5.363    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 633797     Buffer Size: 15834      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:04:04,558][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 6.697    Value Loss: 4.875    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 635828     Buffer Size: 15854      Transition Number: 1000.222k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:06:52,692][train][INFO][train.py>_log] ==> #309000     Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 6.573    Value Loss: 5.096    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 637804     Buffer Size: 15870      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:09:40,937][train][INFO][train.py>_log] ==> #310000     Total Loss: 3.309    [weighted Loss:3.309    Policy Loss: 6.651    Value Loss: 4.815    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 639885     Buffer Size: 15896      Transition Number: 999.994 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:12:27,689][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 6.244    Value Loss: 5.161    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 641895     Buffer Size: 15921      Transition Number: 1000.696k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:15:16,284][train][INFO][train.py>_log] ==> #312000     Total Loss: 3.293    [weighted Loss:3.293    Policy Loss: 6.115    Value Loss: 5.134    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 643853     Buffer Size: 15958      Transition Number: 1000.178k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:18:04,394][train][INFO][train.py>_log] ==> #313000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.660    Value Loss: 4.782    Reward Loss: 1.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 645913     Buffer Size: 15960      Transition Number: 999.996 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:20:53,482][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.401    [weighted Loss:2.401    Policy Loss: 6.601    Value Loss: 5.188    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 648044     Buffer Size: 15993      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:23:39,941][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.766    [weighted Loss:2.766    Policy Loss: 6.245    Value Loss: 4.964    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 649995     Buffer Size: 15992      Transition Number: 999.983 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:26:32,255][train][INFO][train.py>_log] ==> #316000     Total Loss: 2.159    [weighted Loss:2.159    Policy Loss: 6.288    Value Loss: 4.825    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 652041     Buffer Size: 15978      Transition Number: 999.943 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:29:15,540][train][INFO][train.py>_log] ==> #317000     Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 6.828    Value Loss: 4.761    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 654019     Buffer Size: 15969      Transition Number: 1000.018k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:32:02,928][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.399    [weighted Loss:2.399    Policy Loss: 6.651    Value Loss: 4.708    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 656085     Buffer Size: 15942      Transition Number: 1000.116k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:34:50,862][train][INFO][train.py>_log] ==> #319000     Total Loss: 4.336    [weighted Loss:4.336    Policy Loss: 6.473    Value Loss: 5.235    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 658101     Buffer Size: 15900      Transition Number: 1000.289k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:37:38,372][train][INFO][train.py>_log] ==> #320000     Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 6.825    Value Loss: 5.070    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 660064     Buffer Size: 15855      Transition Number: 1000.071k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:40:28,279][train][INFO][train.py>_log] ==> #321000     Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 6.215    Value Loss: 4.688    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 662147     Buffer Size: 15791      Transition Number: 1000.039k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:43:18,381][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 6.729    Value Loss: 4.804    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 664224     Buffer Size: 15727      Transition Number: 1000.000k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:46:05,124][train][INFO][train.py>_log] ==> #323000     Total Loss: 3.183    [weighted Loss:3.183    Policy Loss: 6.723    Value Loss: 4.834    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 666215     Buffer Size: 15750      Transition Number: 1000.045k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:48:52,412][train][INFO][train.py>_log] ==> #324000     Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 6.368    Value Loss: 4.810    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 668262     Buffer Size: 15761      Transition Number: 1000.557k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:51:39,968][train][INFO][train.py>_log] ==> #325000     Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 7.085    Value Loss: 4.586    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 670295     Buffer Size: 15749      Transition Number: 999.967 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:54:24,970][train][INFO][train.py>_log] ==> #326000     Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 7.010    Value Loss: 5.399    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 672246     Buffer Size: 15776      Transition Number: 999.988 k Batch Size: 256        Lr: 0.02000 
[2022-02-19 23:57:15,233][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.575    [weighted Loss:2.575    Policy Loss: 6.855    Value Loss: 4.687    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 674288     Buffer Size: 15783      Transition Number: 1000.079k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:00:02,618][train][INFO][train.py>_log] ==> #328000     Total Loss: 3.389    [weighted Loss:3.389    Policy Loss: 6.951    Value Loss: 4.873    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 676296     Buffer Size: 15764      Transition Number: 999.989 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:02:49,655][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 7.151    Value Loss: 4.863    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 678376     Buffer Size: 15757      Transition Number: 1000.040k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:05:34,670][train][INFO][train.py>_log] ==> #330000     Total Loss: 3.395    [weighted Loss:3.395    Policy Loss: 6.916    Value Loss: 5.314    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 680356     Buffer Size: 15747      Transition Number: 1000.102k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:08:24,694][train][INFO][train.py>_log] ==> #331000     Total Loss: 3.057    [weighted Loss:3.057    Policy Loss: 6.549    Value Loss: 4.668    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 682397     Buffer Size: 15707      Transition Number: 999.979 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:11:13,573][train][INFO][train.py>_log] ==> #332000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 6.763    Value Loss: 4.842    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 684463     Buffer Size: 15670      Transition Number: 999.975 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:14:01,118][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.237    [weighted Loss:3.237    Policy Loss: 6.618    Value Loss: 4.851    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 686458     Buffer Size: 15628      Transition Number: 1000.215k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:16:51,466][train][INFO][train.py>_log] ==> #334000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 7.034    Value Loss: 4.650    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 688441     Buffer Size: 15591      Transition Number: 1000.133k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:19:40,208][train][INFO][train.py>_log] ==> #335000     Total Loss: 3.698    [weighted Loss:3.698    Policy Loss: 7.084    Value Loss: 4.754    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 690479     Buffer Size: 15577      Transition Number: 999.981 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:22:31,065][train][INFO][train.py>_log] ==> #336000     Total Loss: 3.640    [weighted Loss:3.640    Policy Loss: 7.098    Value Loss: 4.698    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 692525     Buffer Size: 15578      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:25:22,629][train][INFO][train.py>_log] ==> #337000     Total Loss: 3.522    [weighted Loss:3.522    Policy Loss: 7.033    Value Loss: 4.816    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 694560     Buffer Size: 15584      Transition Number: 1000.129k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:28:08,798][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 6.559    Value Loss: 4.782    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 696541     Buffer Size: 15579      Transition Number: 1000.211k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:30:57,819][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 6.810    Value Loss: 4.711    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 698590     Buffer Size: 15549      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:33:47,221][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 6.601    Value Loss: 4.600    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 700562     Buffer Size: 15521      Transition Number: 1000.057k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:36:36,781][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.050    [weighted Loss:2.050    Policy Loss: 7.274    Value Loss: 4.789    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 702594     Buffer Size: 15504      Transition Number: 999.973 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:39:25,130][train][INFO][train.py>_log] ==> #342000     Total Loss: 3.735    [weighted Loss:3.735    Policy Loss: 7.054    Value Loss: 5.286    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 704594     Buffer Size: 15479      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:42:16,397][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.794    [weighted Loss:2.794    Policy Loss: 7.062    Value Loss: 4.911    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 706707     Buffer Size: 15467      Transition Number: 1000.118k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:45:03,271][train][INFO][train.py>_log] ==> #344000     Total Loss: 3.879    [weighted Loss:3.879    Policy Loss: 6.963    Value Loss: 4.839    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 708739     Buffer Size: 15466      Transition Number: 1000.041k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:47:51,614][train][INFO][train.py>_log] ==> #345000     Total Loss: 3.369    [weighted Loss:3.369    Policy Loss: 7.083    Value Loss: 4.695    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 710790     Buffer Size: 15438      Transition Number: 999.982 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:50:41,964][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.774    [weighted Loss:2.774    Policy Loss: 7.275    Value Loss: 4.543    Reward Loss: 1.922    Consistency Loss: 0.000    ] Replay Episodes Collected: 712843     Buffer Size: 15442      Transition Number: 1000.462k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:53:29,826][train][INFO][train.py>_log] ==> #347000     Total Loss: 2.537    [weighted Loss:2.537    Policy Loss: 7.171    Value Loss: 4.662    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 714868     Buffer Size: 15444      Transition Number: 1000.069k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:56:20,232][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.544    [weighted Loss:2.544    Policy Loss: 7.033    Value Loss: 5.157    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 716915     Buffer Size: 15447      Transition Number: 999.957 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 00:59:09,711][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 7.082    Value Loss: 4.552    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 718922     Buffer Size: 15442      Transition Number: 999.949 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:01:57,081][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 7.367    Value Loss: 4.457    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 721000     Buffer Size: 15448      Transition Number: 1000.265k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:04:46,310][train][INFO][train.py>_log] ==> #351000     Total Loss: 2.753    [weighted Loss:2.753    Policy Loss: 6.983    Value Loss: 4.720    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 723079     Buffer Size: 15449      Transition Number: 1000.186k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:07:34,437][train][INFO][train.py>_log] ==> #352000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 7.047    Value Loss: 4.581    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 725174     Buffer Size: 15462      Transition Number: 1000.119k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:10:23,911][train][INFO][train.py>_log] ==> #353000     Total Loss: 3.452    [weighted Loss:3.452    Policy Loss: 7.636    Value Loss: 4.650    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 727233     Buffer Size: 15489      Transition Number: 1000.136k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:13:12,115][train][INFO][train.py>_log] ==> #354000     Total Loss: 3.533    [weighted Loss:3.533    Policy Loss: 7.200    Value Loss: 4.893    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 729345     Buffer Size: 15491      Transition Number: 1000.081k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:16:00,685][train][INFO][train.py>_log] ==> #355000     Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 7.735    Value Loss: 4.936    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 731353     Buffer Size: 15514      Transition Number: 1000.398k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:18:49,524][train][INFO][train.py>_log] ==> #356000     Total Loss: 1.349    [weighted Loss:1.349    Policy Loss: 7.642    Value Loss: 4.900    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 733378     Buffer Size: 15545      Transition Number: 999.969 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:21:40,425][train][INFO][train.py>_log] ==> #357000     Total Loss: 3.809    [weighted Loss:3.809    Policy Loss: 7.191    Value Loss: 4.780    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 735488     Buffer Size: 15567      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:24:31,600][train][INFO][train.py>_log] ==> #358000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 7.208    Value Loss: 4.379    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 737577     Buffer Size: 15593      Transition Number: 999.986 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:27:21,481][train][INFO][train.py>_log] ==> #359000     Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 7.048    Value Loss: 5.067    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 739738     Buffer Size: 15601      Transition Number: 1000.056k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:30:10,729][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 7.074    Value Loss: 4.466    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 741862     Buffer Size: 15601      Transition Number: 999.971 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:33:00,085][train][INFO][train.py>_log] ==> #361000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 7.018    Value Loss: 4.691    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 743929     Buffer Size: 15692      Transition Number: 999.948 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:35:46,113][train][INFO][train.py>_log] ==> #362000     Total Loss: 2.387    [weighted Loss:2.387    Policy Loss: 7.132    Value Loss: 5.258    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 746011     Buffer Size: 15796      Transition Number: 1000.065k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:38:36,721][train][INFO][train.py>_log] ==> #363000     Total Loss: 2.499    [weighted Loss:2.499    Policy Loss: 6.583    Value Loss: 5.000    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 748152     Buffer Size: 15846      Transition Number: 999.961 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:41:25,003][train][INFO][train.py>_log] ==> #364000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 6.794    Value Loss: 5.111    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 750198     Buffer Size: 15892      Transition Number: 1000.082k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:44:12,641][train][INFO][train.py>_log] ==> #365000     Total Loss: 2.888    [weighted Loss:2.888    Policy Loss: 6.929    Value Loss: 5.093    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 752288     Buffer Size: 15917      Transition Number: 1000.054k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:46:59,314][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.024    [weighted Loss:1.024    Policy Loss: 6.224    Value Loss: 4.722    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 754345     Buffer Size: 15925      Transition Number: 999.980 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:49:49,159][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.053    [weighted Loss:2.053    Policy Loss: 6.488    Value Loss: 4.692    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 756442     Buffer Size: 15984      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:52:39,160][train][INFO][train.py>_log] ==> #368000     Total Loss: 3.634    [weighted Loss:3.634    Policy Loss: 6.919    Value Loss: 4.935    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 758564     Buffer Size: 16040      Transition Number: 1000.353k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:55:30,397][train][INFO][train.py>_log] ==> #369000     Total Loss: 2.836    [weighted Loss:2.836    Policy Loss: 6.605    Value Loss: 4.958    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 760665     Buffer Size: 15983      Transition Number: 1000.107k Batch Size: 256        Lr: 0.02000 
[2022-02-20 01:58:22,855][train][INFO][train.py>_log] ==> #370000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.637    Value Loss: 5.000    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 762813     Buffer Size: 15924      Transition Number: 1000.220k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:01:15,628][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 6.474    Value Loss: 4.615    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 764915     Buffer Size: 15897      Transition Number: 1000.402k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:04:05,255][train][INFO][train.py>_log] ==> #372000     Total Loss: 1.727    [weighted Loss:1.727    Policy Loss: 6.428    Value Loss: 4.521    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 767008     Buffer Size: 15867      Transition Number: 1000.128k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:06:56,861][train][INFO][train.py>_log] ==> #373000     Total Loss: 2.635    [weighted Loss:2.635    Policy Loss: 6.528    Value Loss: 4.640    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 769059     Buffer Size: 15868      Transition Number: 1000.304k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:09:47,780][train][INFO][train.py>_log] ==> #374000     Total Loss: 3.119    [weighted Loss:3.119    Policy Loss: 6.500    Value Loss: 5.003    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 771205     Buffer Size: 15872      Transition Number: 999.966 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:12:38,919][train][INFO][train.py>_log] ==> #375000     Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 6.255    Value Loss: 4.751    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 773310     Buffer Size: 15823      Transition Number: 1000.212k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:15:30,427][train][INFO][train.py>_log] ==> #376000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 6.390    Value Loss: 4.588    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 775415     Buffer Size: 15758      Transition Number: 1000.084k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:18:20,711][train][INFO][train.py>_log] ==> #377000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 6.447    Value Loss: 4.704    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 777522     Buffer Size: 15739      Transition Number: 1000.059k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:21:09,473][train][INFO][train.py>_log] ==> #378000     Total Loss: 2.877    [weighted Loss:2.877    Policy Loss: 6.699    Value Loss: 4.857    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 779558     Buffer Size: 15732      Transition Number: 999.951 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:23:59,320][train][INFO][train.py>_log] ==> #379000     Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 6.602    Value Loss: 4.587    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 781642     Buffer Size: 15708      Transition Number: 1000.169k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:26:48,806][train][INFO][train.py>_log] ==> #380000     Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 6.464    Value Loss: 4.926    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 783695     Buffer Size: 15688      Transition Number: 999.949 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:29:40,096][train][INFO][train.py>_log] ==> #381000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 6.100    Value Loss: 4.913    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 785849     Buffer Size: 15689      Transition Number: 1000.001k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:32:31,539][train][INFO][train.py>_log] ==> #382000     Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 6.086    Value Loss: 4.739    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 787888     Buffer Size: 15706      Transition Number: 1000.086k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:35:20,911][train][INFO][train.py>_log] ==> #383000     Total Loss: 2.375    [weighted Loss:2.375    Policy Loss: 6.148    Value Loss: 5.049    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 789945     Buffer Size: 15715      Transition Number: 999.942 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:38:09,829][train][INFO][train.py>_log] ==> #384000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 6.599    Value Loss: 4.564    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 792148     Buffer Size: 15745      Transition Number: 1000.121k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:41:01,238][train][INFO][train.py>_log] ==> #385000     Total Loss: 3.120    [weighted Loss:3.120    Policy Loss: 5.886    Value Loss: 4.694    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 794301     Buffer Size: 15794      Transition Number: 999.999 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:43:53,498][train][INFO][train.py>_log] ==> #386000     Total Loss: 1.633    [weighted Loss:1.633    Policy Loss: 6.100    Value Loss: 4.432    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 796456     Buffer Size: 15842      Transition Number: 1000.063k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:46:44,199][train][INFO][train.py>_log] ==> #387000     Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 6.405    Value Loss: 4.842    Reward Loss: 1.947    Consistency Loss: 0.000    ] Replay Episodes Collected: 798545     Buffer Size: 15878      Transition Number: 1000.058k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:49:32,348][train][INFO][train.py>_log] ==> #388000     Total Loss: 2.765    [weighted Loss:2.765    Policy Loss: 6.064    Value Loss: 4.458    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 800540     Buffer Size: 15916      Transition Number: 1000.743k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:52:21,439][train][INFO][train.py>_log] ==> #389000     Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 6.250    Value Loss: 4.967    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 802563     Buffer Size: 15908      Transition Number: 1000.087k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:55:09,657][train][INFO][train.py>_log] ==> #390000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 6.595    Value Loss: 4.448    Reward Loss: 1.977    Consistency Loss: 0.000    ] Replay Episodes Collected: 804524     Buffer Size: 15914      Transition Number: 1000.306k Batch Size: 256        Lr: 0.02000 
[2022-02-20 02:58:00,210][train][INFO][train.py>_log] ==> #391000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 6.665    Value Loss: 4.880    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 806613     Buffer Size: 15917      Transition Number: 1000.151k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:00:47,644][train][INFO][train.py>_log] ==> #392000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 6.833    Value Loss: 4.803    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 808580     Buffer Size: 15909      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:03:39,335][train][INFO][train.py>_log] ==> #393000     Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 6.614    Value Loss: 4.520    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 810783     Buffer Size: 15894      Transition Number: 999.998 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:06:26,371][train][INFO][train.py>_log] ==> #394000     Total Loss: 3.265    [weighted Loss:3.265    Policy Loss: 6.579    Value Loss: 4.460    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 812729     Buffer Size: 15879      Transition Number: 1000.114k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:09:13,942][train][INFO][train.py>_log] ==> #395000     Total Loss: 3.490    [weighted Loss:3.490    Policy Loss: 6.251    Value Loss: 4.813    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 814807     Buffer Size: 15872      Transition Number: 999.947 k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:12:02,603][train][INFO][train.py>_log] ==> #396000     Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 6.379    Value Loss: 5.053    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 816879     Buffer Size: 15872      Transition Number: 1000.090k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:14:53,818][train][INFO][train.py>_log] ==> #397000     Total Loss: 3.224    [weighted Loss:3.224    Policy Loss: 6.454    Value Loss: 4.615    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 818991     Buffer Size: 15871      Transition Number: 1000.036k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:17:43,411][train][INFO][train.py>_log] ==> #398000     Total Loss: 2.406    [weighted Loss:2.406    Policy Loss: 6.512    Value Loss: 4.820    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 821106     Buffer Size: 15875      Transition Number: 1000.006k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:20:33,602][train][INFO][train.py>_log] ==> #399000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 7.007    Value Loss: 4.488    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 823104     Buffer Size: 15890      Transition Number: 1000.235k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:23:34,097][train][INFO][train.py>_log] ==> #400000     Total Loss: 2.379    [weighted Loss:2.379    Policy Loss: 6.545    Value Loss: 4.556    Reward Loss: 1.873    Consistency Loss: 0.000    ] Replay Episodes Collected: 825274     Buffer Size: 15906      Transition Number: 1000.144k Batch Size: 256        Lr: 0.02000 
[2022-02-20 03:26:24,379][train][INFO][train.py>_log] ==> #401000     Total Loss: 2.646    [weighted Loss:2.646    Policy Loss: 6.598    Value Loss: 4.652    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 827483     Buffer Size: 15899      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:29:11,113][train][INFO][train.py>_log] ==> #402000     Total Loss: 3.445    [weighted Loss:3.445    Policy Loss: 6.676    Value Loss: 4.838    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 829481     Buffer Size: 15904      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:32:00,193][train][INFO][train.py>_log] ==> #403000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 6.041    Value Loss: 4.840    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 831516     Buffer Size: 15878      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:34:50,888][train][INFO][train.py>_log] ==> #404000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 6.333    Value Loss: 4.647    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 833586     Buffer Size: 15855      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:37:43,461][train][INFO][train.py>_log] ==> #405000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 6.107    Value Loss: 4.487    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 835722     Buffer Size: 15807      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:40:35,579][train][INFO][train.py>_log] ==> #406000     Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 5.988    Value Loss: 4.832    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 837830     Buffer Size: 15761      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:43:25,752][train][INFO][train.py>_log] ==> #407000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 6.144    Value Loss: 4.358    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 839923     Buffer Size: 15703      Transition Number: 1000.325k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:46:15,933][train][INFO][train.py>_log] ==> #408000     Total Loss: 1.311    [weighted Loss:1.311    Policy Loss: 6.066    Value Loss: 4.689    Reward Loss: 1.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 841989     Buffer Size: 15639      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:49:12,732][train][INFO][train.py>_log] ==> #409000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 6.129    Value Loss: 4.125    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 844136     Buffer Size: 15575      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:52:01,787][train][INFO][train.py>_log] ==> #410000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 5.930    Value Loss: 4.266    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 846224     Buffer Size: 15533      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:54:54,836][train][INFO][train.py>_log] ==> #411000     Total Loss: 1.858    [weighted Loss:1.858    Policy Loss: 6.339    Value Loss: 4.081    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 848350     Buffer Size: 15483      Transition Number: 1000.168k Batch Size: 256        Lr: 0.00400 
[2022-02-20 03:57:44,908][train][INFO][train.py>_log] ==> #412000     Total Loss: 3.085    [weighted Loss:3.085    Policy Loss: 5.982    Value Loss: 4.368    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 850382     Buffer Size: 15446      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:00:35,960][train][INFO][train.py>_log] ==> #413000     Total Loss: 3.144    [weighted Loss:3.144    Policy Loss: 6.141    Value Loss: 4.372    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 852473     Buffer Size: 15403      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:03:26,263][train][INFO][train.py>_log] ==> #414000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 6.254    Value Loss: 4.152    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 854524     Buffer Size: 15368      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:06:19,051][train][INFO][train.py>_log] ==> #415000     Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 6.008    Value Loss: 4.177    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 856582     Buffer Size: 15335      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:09:08,050][train][INFO][train.py>_log] ==> #416000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 6.231    Value Loss: 4.127    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 858657     Buffer Size: 15313      Transition Number: 1000.081k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:12:00,174][train][INFO][train.py>_log] ==> #417000     Total Loss: 2.775    [weighted Loss:2.775    Policy Loss: 6.213    Value Loss: 4.177    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 860815     Buffer Size: 15301      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:14:48,135][train][INFO][train.py>_log] ==> #418000     Total Loss: 2.955    [weighted Loss:2.955    Policy Loss: 6.224    Value Loss: 4.176    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 862857     Buffer Size: 15296      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:17:38,398][train][INFO][train.py>_log] ==> #419000     Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 6.402    Value Loss: 4.186    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 864965     Buffer Size: 15284      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:20:30,214][train][INFO][train.py>_log] ==> #420000     Total Loss: 2.510    [weighted Loss:2.510    Policy Loss: 5.973    Value Loss: 4.138    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 867064     Buffer Size: 15278      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:23:20,558][train][INFO][train.py>_log] ==> #421000     Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 6.414    Value Loss: 4.270    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 869180     Buffer Size: 15268      Transition Number: 1000.236k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:26:09,560][train][INFO][train.py>_log] ==> #422000     Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 6.534    Value Loss: 4.298    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 871290     Buffer Size: 15252      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:29:02,921][train][INFO][train.py>_log] ==> #423000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 6.532    Value Loss: 4.180    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 873424     Buffer Size: 15230      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:31:55,184][train][INFO][train.py>_log] ==> #424000     Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 5.916    Value Loss: 4.493    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 875493     Buffer Size: 15207      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:34:48,615][train][INFO][train.py>_log] ==> #425000     Total Loss: 2.438    [weighted Loss:2.438    Policy Loss: 6.220    Value Loss: 4.042    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 877663     Buffer Size: 15193      Transition Number: 1000.381k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:37:38,158][train][INFO][train.py>_log] ==> #426000     Total Loss: 2.358    [weighted Loss:2.358    Policy Loss: 6.450    Value Loss: 4.217    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 879718     Buffer Size: 15159      Transition Number: 1000.125k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:40:29,098][train][INFO][train.py>_log] ==> #427000     Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 6.076    Value Loss: 4.279    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 881850     Buffer Size: 15140      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:43:19,867][train][INFO][train.py>_log] ==> #428000     Total Loss: 2.094    [weighted Loss:2.094    Policy Loss: 6.514    Value Loss: 3.889    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 883983     Buffer Size: 15126      Transition Number: 1000.307k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:46:12,039][train][INFO][train.py>_log] ==> #429000     Total Loss: 3.358    [weighted Loss:3.358    Policy Loss: 6.443    Value Loss: 4.372    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 886104     Buffer Size: 15112      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:49:03,506][train][INFO][train.py>_log] ==> #430000     Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 6.246    Value Loss: 4.108    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 888184     Buffer Size: 15113      Transition Number: 1000.230k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:51:52,346][train][INFO][train.py>_log] ==> #431000     Total Loss: 2.079    [weighted Loss:2.079    Policy Loss: 6.824    Value Loss: 4.225    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 890276     Buffer Size: 15117      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:54:43,537][train][INFO][train.py>_log] ==> #432000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 6.497    Value Loss: 4.142    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 892376     Buffer Size: 15126      Transition Number: 999.932 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 04:57:36,391][train][INFO][train.py>_log] ==> #433000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 6.803    Value Loss: 4.323    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 894541     Buffer Size: 15144      Transition Number: 1000.398k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:00:26,615][train][INFO][train.py>_log] ==> #434000     Total Loss: 3.041    [weighted Loss:3.041    Policy Loss: 6.715    Value Loss: 4.486    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 896666     Buffer Size: 15155      Transition Number: 1000.719k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:03:19,072][train][INFO][train.py>_log] ==> #435000     Total Loss: 2.580    [weighted Loss:2.580    Policy Loss: 6.728    Value Loss: 4.313    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 898759     Buffer Size: 15149      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:06:11,027][train][INFO][train.py>_log] ==> #436000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 6.721    Value Loss: 4.253    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 900946     Buffer Size: 15159      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:08:59,836][train][INFO][train.py>_log] ==> #437000     Total Loss: 2.835    [weighted Loss:2.835    Policy Loss: 6.657    Value Loss: 4.443    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 903080     Buffer Size: 15177      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:11:52,771][train][INFO][train.py>_log] ==> #438000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 6.809    Value Loss: 4.184    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 905237     Buffer Size: 15175      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:14:42,917][train][INFO][train.py>_log] ==> #439000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 6.634    Value Loss: 4.251    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 907345     Buffer Size: 15185      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:17:36,656][train][INFO][train.py>_log] ==> #440000     Total Loss: 3.406    [weighted Loss:3.406    Policy Loss: 6.958    Value Loss: 4.176    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 909612     Buffer Size: 15196      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:20:29,570][train][INFO][train.py>_log] ==> #441000     Total Loss: 3.433    [weighted Loss:3.433    Policy Loss: 6.808    Value Loss: 4.228    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 911713     Buffer Size: 15218      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:23:25,384][train][INFO][train.py>_log] ==> #442000     Total Loss: 2.287    [weighted Loss:2.287    Policy Loss: 6.176    Value Loss: 4.240    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 913969     Buffer Size: 15237      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:26:14,893][train][INFO][train.py>_log] ==> #443000     Total Loss: 2.132    [weighted Loss:2.132    Policy Loss: 6.544    Value Loss: 4.119    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 916068     Buffer Size: 15256      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:29:07,530][train][INFO][train.py>_log] ==> #444000     Total Loss: 3.080    [weighted Loss:3.080    Policy Loss: 6.501    Value Loss: 3.910    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 918230     Buffer Size: 15261      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:31:57,710][train][INFO][train.py>_log] ==> #445000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 6.876    Value Loss: 4.038    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 920319     Buffer Size: 15288      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:34:50,774][train][INFO][train.py>_log] ==> #446000     Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 6.399    Value Loss: 4.754    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 922494     Buffer Size: 15311      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:37:46,100][train][INFO][train.py>_log] ==> #447000     Total Loss: 3.053    [weighted Loss:3.053    Policy Loss: 6.536    Value Loss: 4.553    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 924616     Buffer Size: 15334      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:40:37,766][train][INFO][train.py>_log] ==> #448000     Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 6.615    Value Loss: 4.430    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 926803     Buffer Size: 15359      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:43:30,767][train][INFO][train.py>_log] ==> #449000     Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 6.690    Value Loss: 4.395    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 928903     Buffer Size: 15372      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:46:22,074][train][INFO][train.py>_log] ==> #450000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 6.177    Value Loss: 4.269    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 931115     Buffer Size: 15395      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:49:11,300][train][INFO][train.py>_log] ==> #451000     Total Loss: 1.883    [weighted Loss:1.883    Policy Loss: 6.634    Value Loss: 4.290    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 933176     Buffer Size: 15413      Transition Number: 1000.165k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:52:06,263][train][INFO][train.py>_log] ==> #452000     Total Loss: 1.749    [weighted Loss:1.749    Policy Loss: 6.582    Value Loss: 4.366    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 935405     Buffer Size: 15426      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:54:56,558][train][INFO][train.py>_log] ==> #453000     Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 6.522    Value Loss: 4.239    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 937496     Buffer Size: 15435      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00400 
[2022-02-20 05:57:47,825][train][INFO][train.py>_log] ==> #454000     Total Loss: 2.294    [weighted Loss:2.294    Policy Loss: 6.882    Value Loss: 4.381    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 939625     Buffer Size: 15442      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:00:41,546][train][INFO][train.py>_log] ==> #455000     Total Loss: 2.938    [weighted Loss:2.938    Policy Loss: 6.661    Value Loss: 4.240    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 941826     Buffer Size: 15436      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:03:36,468][train][INFO][train.py>_log] ==> #456000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 6.391    Value Loss: 4.234    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 944058     Buffer Size: 15432      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:06:27,281][train][INFO][train.py>_log] ==> #457000     Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 6.644    Value Loss: 4.629    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 946160     Buffer Size: 15421      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:09:19,697][train][INFO][train.py>_log] ==> #458000     Total Loss: 1.934    [weighted Loss:1.934    Policy Loss: 6.358    Value Loss: 4.271    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 948380     Buffer Size: 15430      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:12:11,841][train][INFO][train.py>_log] ==> #459000     Total Loss: 3.343    [weighted Loss:3.343    Policy Loss: 6.275    Value Loss: 4.266    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 950520     Buffer Size: 15425      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:15:05,889][train][INFO][train.py>_log] ==> #460000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 6.684    Value Loss: 4.153    Reward Loss: 1.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 952679     Buffer Size: 15430      Transition Number: 1000.252k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:17:55,179][train][INFO][train.py>_log] ==> #461000     Total Loss: 3.102    [weighted Loss:3.102    Policy Loss: 6.615    Value Loss: 4.218    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 954776     Buffer Size: 15435      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:20:48,334][train][INFO][train.py>_log] ==> #462000     Total Loss: 2.680    [weighted Loss:2.680    Policy Loss: 6.711    Value Loss: 4.329    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 956920     Buffer Size: 15455      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:23:42,414][train][INFO][train.py>_log] ==> #463000     Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 6.655    Value Loss: 4.450    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 959108     Buffer Size: 15482      Transition Number: 1000.558k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:26:34,708][train][INFO][train.py>_log] ==> #464000     Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 6.613    Value Loss: 4.044    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 961285     Buffer Size: 15497      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:29:26,362][train][INFO][train.py>_log] ==> #465000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 6.770    Value Loss: 4.563    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 963453     Buffer Size: 15516      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:32:19,339][train][INFO][train.py>_log] ==> #466000     Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 6.590    Value Loss: 4.242    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 965573     Buffer Size: 15538      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:35:13,314][train][INFO][train.py>_log] ==> #467000     Total Loss: 1.630    [weighted Loss:1.630    Policy Loss: 6.866    Value Loss: 4.412    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 967780     Buffer Size: 15561      Transition Number: 1000.428k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:38:05,907][train][INFO][train.py>_log] ==> #468000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 6.983    Value Loss: 4.235    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 969899     Buffer Size: 15576      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:41:00,491][train][INFO][train.py>_log] ==> #469000     Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 6.990    Value Loss: 4.518    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 972051     Buffer Size: 15577      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:43:55,336][train][INFO][train.py>_log] ==> #470000     Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 6.628    Value Loss: 4.256    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 974282     Buffer Size: 15589      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:46:45,057][train][INFO][train.py>_log] ==> #471000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 6.969    Value Loss: 4.249    Reward Loss: 1.831    Consistency Loss: 0.000    ] Replay Episodes Collected: 976337     Buffer Size: 15597      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:49:37,912][train][INFO][train.py>_log] ==> #472000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 6.522    Value Loss: 4.569    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 978483     Buffer Size: 15604      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:52:28,643][train][INFO][train.py>_log] ==> #473000     Total Loss: 2.942    [weighted Loss:2.942    Policy Loss: 6.607    Value Loss: 4.278    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 980702     Buffer Size: 15615      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:55:21,600][train][INFO][train.py>_log] ==> #474000     Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 6.455    Value Loss: 4.608    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 982818     Buffer Size: 15623      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00400 
[2022-02-20 06:58:14,604][train][INFO][train.py>_log] ==> #475000     Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 6.487    Value Loss: 4.272    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 984962     Buffer Size: 15644      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:01:05,455][train][INFO][train.py>_log] ==> #476000     Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 6.385    Value Loss: 4.339    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 987144     Buffer Size: 15668      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:03:58,607][train][INFO][train.py>_log] ==> #477000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 6.829    Value Loss: 4.164    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 989296     Buffer Size: 15695      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:06:49,318][train][INFO][train.py>_log] ==> #478000     Total Loss: 2.439    [weighted Loss:2.439    Policy Loss: 6.997    Value Loss: 4.272    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 991416     Buffer Size: 15711      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:09:40,261][train][INFO][train.py>_log] ==> #479000     Total Loss: 3.253    [weighted Loss:3.253    Policy Loss: 7.339    Value Loss: 4.551    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 993584     Buffer Size: 15725      Transition Number: 1000.079k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:12:33,945][train][INFO][train.py>_log] ==> #480000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 6.658    Value Loss: 4.414    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 995770     Buffer Size: 15754      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:15:27,681][train][INFO][train.py>_log] ==> #481000     Total Loss: 3.696    [weighted Loss:3.696    Policy Loss: 6.897    Value Loss: 4.396    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 997903     Buffer Size: 15775      Transition Number: 1000.164k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:18:18,352][train][INFO][train.py>_log] ==> #482000     Total Loss: 0.966    [weighted Loss:0.966    Policy Loss: 7.035    Value Loss: 4.396    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1000026    Buffer Size: 15762      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:21:11,522][train][INFO][train.py>_log] ==> #483000     Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 6.944    Value Loss: 4.572    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1002194    Buffer Size: 15772      Transition Number: 1000.298k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:24:05,185][train][INFO][train.py>_log] ==> #484000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 7.128    Value Loss: 4.861    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1004365    Buffer Size: 15779      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:26:59,675][train][INFO][train.py>_log] ==> #485000     Total Loss: 2.371    [weighted Loss:2.371    Policy Loss: 7.281    Value Loss: 4.519    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1006613    Buffer Size: 15782      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:29:53,328][train][INFO][train.py>_log] ==> #486000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 6.689    Value Loss: 4.786    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 1008771    Buffer Size: 15800      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:32:46,219][train][INFO][train.py>_log] ==> #487000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 7.190    Value Loss: 4.710    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1010953    Buffer Size: 15789      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:35:41,559][train][INFO][train.py>_log] ==> #488000     Total Loss: 1.928    [weighted Loss:1.928    Policy Loss: 6.609    Value Loss: 4.393    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 1013152    Buffer Size: 15776      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:38:37,096][train][INFO][train.py>_log] ==> #489000     Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 6.456    Value Loss: 4.680    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 1015373    Buffer Size: 15789      Transition Number: 1000.315k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:41:30,705][train][INFO][train.py>_log] ==> #490000     Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 6.670    Value Loss: 4.664    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1017563    Buffer Size: 15794      Transition Number: 1000.362k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:44:24,486][train][INFO][train.py>_log] ==> #491000     Total Loss: 2.154    [weighted Loss:2.154    Policy Loss: 6.661    Value Loss: 4.376    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 1019682    Buffer Size: 15790      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:47:18,696][train][INFO][train.py>_log] ==> #492000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.738    Value Loss: 4.145    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1021884    Buffer Size: 15806      Transition Number: 1000.260k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:50:12,341][train][INFO][train.py>_log] ==> #493000     Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 6.609    Value Loss: 4.285    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1024029    Buffer Size: 15815      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:53:07,524][train][INFO][train.py>_log] ==> #494000     Total Loss: 3.489    [weighted Loss:3.489    Policy Loss: 6.882    Value Loss: 4.306    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1026218    Buffer Size: 15842      Transition Number: 1000.412k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:56:00,526][train][INFO][train.py>_log] ==> #495000     Total Loss: 2.973    [weighted Loss:2.973    Policy Loss: 6.293    Value Loss: 4.386    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1028434    Buffer Size: 15864      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00400 
[2022-02-20 07:58:55,331][train][INFO][train.py>_log] ==> #496000     Total Loss: 1.913    [weighted Loss:1.913    Policy Loss: 6.760    Value Loss: 4.327    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1030665    Buffer Size: 15901      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:01:51,317][train][INFO][train.py>_log] ==> #497000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 6.577    Value Loss: 4.452    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 1032909    Buffer Size: 15917      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:04:47,787][train][INFO][train.py>_log] ==> #498000     Total Loss: 3.169    [weighted Loss:3.169    Policy Loss: 7.106    Value Loss: 4.267    Reward Loss: 1.923    Consistency Loss: 0.000    ] Replay Episodes Collected: 1035200    Buffer Size: 15932      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:07:42,485][train][INFO][train.py>_log] ==> #499000     Total Loss: 2.653    [weighted Loss:2.653    Policy Loss: 6.421    Value Loss: 4.349    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 1037332    Buffer Size: 15927      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:10:35,551][train][INFO][train.py>_log] ==> #500000     Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 6.894    Value Loss: 4.291    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1039551    Buffer Size: 15924      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:13:30,212][train][INFO][train.py>_log] ==> #501000     Total Loss: 3.398    [weighted Loss:3.398    Policy Loss: 6.715    Value Loss: 4.710    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1041766    Buffer Size: 15918      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:16:23,072][train][INFO][train.py>_log] ==> #502000     Total Loss: 2.177    [weighted Loss:2.177    Policy Loss: 6.586    Value Loss: 4.292    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1043929    Buffer Size: 15925      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:19:19,718][train][INFO][train.py>_log] ==> #503000     Total Loss: 2.103    [weighted Loss:2.103    Policy Loss: 6.633    Value Loss: 4.254    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1046164    Buffer Size: 15920      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:22:11,444][train][INFO][train.py>_log] ==> #504000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 6.465    Value Loss: 4.628    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 1048336    Buffer Size: 15925      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:25:05,607][train][INFO][train.py>_log] ==> #505000     Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 6.541    Value Loss: 4.130    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1050520    Buffer Size: 15925      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:28:00,429][train][INFO][train.py>_log] ==> #506000     Total Loss: 1.161    [weighted Loss:1.161    Policy Loss: 6.955    Value Loss: 4.237    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1052681    Buffer Size: 15922      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:30:53,126][train][INFO][train.py>_log] ==> #507000     Total Loss: 1.732    [weighted Loss:1.732    Policy Loss: 6.769    Value Loss: 4.329    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1054828    Buffer Size: 15907      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:33:45,611][train][INFO][train.py>_log] ==> #508000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 6.945    Value Loss: 4.219    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 1056986    Buffer Size: 15912      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:36:39,830][train][INFO][train.py>_log] ==> #509000     Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 6.839    Value Loss: 4.611    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1059141    Buffer Size: 15910      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:39:29,914][train][INFO][train.py>_log] ==> #510000     Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 6.913    Value Loss: 4.453    Reward Loss: 1.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 1061280    Buffer Size: 15885      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:42:25,190][train][INFO][train.py>_log] ==> #511000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 7.187    Value Loss: 4.475    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1063475    Buffer Size: 15866      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:45:17,443][train][INFO][train.py>_log] ==> #512000     Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 6.933    Value Loss: 4.653    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 1065622    Buffer Size: 15852      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:48:09,790][train][INFO][train.py>_log] ==> #513000     Total Loss: 2.187    [weighted Loss:2.187    Policy Loss: 7.333    Value Loss: 4.801    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1067819    Buffer Size: 15842      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:51:02,181][train][INFO][train.py>_log] ==> #514000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 7.259    Value Loss: 4.211    Reward Loss: 1.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 1069979    Buffer Size: 15837      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:53:56,162][train][INFO][train.py>_log] ==> #515000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 7.533    Value Loss: 4.495    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 1072105    Buffer Size: 15823      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:56:51,699][train][INFO][train.py>_log] ==> #516000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 7.478    Value Loss: 4.193    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1074313    Buffer Size: 15820      Transition Number: 1000.493k Batch Size: 256        Lr: 0.00400 
[2022-02-20 08:59:49,285][train][INFO][train.py>_log] ==> #517000     Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 7.419    Value Loss: 4.449    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1076549    Buffer Size: 15817      Transition Number: 1000.272k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:02:41,037][train][INFO][train.py>_log] ==> #518000     Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 7.833    Value Loss: 4.367    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1078602    Buffer Size: 15815      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:05:33,360][train][INFO][train.py>_log] ==> #519000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 7.587    Value Loss: 4.576    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1080743    Buffer Size: 15830      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:08:27,744][train][INFO][train.py>_log] ==> #520000     Total Loss: 3.363    [weighted Loss:3.363    Policy Loss: 7.927    Value Loss: 4.312    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1082959    Buffer Size: 15842      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:11:22,331][train][INFO][train.py>_log] ==> #521000     Total Loss: 1.631    [weighted Loss:1.631    Policy Loss: 7.710    Value Loss: 4.306    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1085148    Buffer Size: 15861      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:14:15,808][train][INFO][train.py>_log] ==> #522000     Total Loss: 3.263    [weighted Loss:3.263    Policy Loss: 8.325    Value Loss: 4.439    Reward Loss: 1.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 1087271    Buffer Size: 15891      Transition Number: 1000.501k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:17:08,427][train][INFO][train.py>_log] ==> #523000     Total Loss: 3.969    [weighted Loss:3.969    Policy Loss: 8.224    Value Loss: 4.371    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1089410    Buffer Size: 15891      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:20:01,524][train][INFO][train.py>_log] ==> #524000     Total Loss: 2.125    [weighted Loss:2.125    Policy Loss: 8.170    Value Loss: 4.705    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1091616    Buffer Size: 15910      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:22:55,516][train][INFO][train.py>_log] ==> #525000     Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 7.949    Value Loss: 4.564    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1093726    Buffer Size: 15899      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:25:51,520][train][INFO][train.py>_log] ==> #526000     Total Loss: 2.880    [weighted Loss:2.880    Policy Loss: 7.530    Value Loss: 4.523    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1095977    Buffer Size: 15895      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:28:46,483][train][INFO][train.py>_log] ==> #527000     Total Loss: 3.600    [weighted Loss:3.600    Policy Loss: 7.521    Value Loss: 4.666    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 1098116    Buffer Size: 15919      Transition Number: 1000.202k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:31:38,995][train][INFO][train.py>_log] ==> #528000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 7.768    Value Loss: 4.633    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1100264    Buffer Size: 15909      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:34:33,485][train][INFO][train.py>_log] ==> #529000     Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 7.719    Value Loss: 4.696    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1102461    Buffer Size: 15920      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:37:27,796][train][INFO][train.py>_log] ==> #530000     Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 7.853    Value Loss: 4.311    Reward Loss: 1.840    Consistency Loss: 0.000    ] Replay Episodes Collected: 1104626    Buffer Size: 15946      Transition Number: 1000.144k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:40:23,390][train][INFO][train.py>_log] ==> #531000     Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 8.042    Value Loss: 4.211    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1106802    Buffer Size: 15956      Transition Number: 1000.077k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:43:17,499][train][INFO][train.py>_log] ==> #532000     Total Loss: 2.723    [weighted Loss:2.723    Policy Loss: 8.112    Value Loss: 4.316    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1109008    Buffer Size: 15981      Transition Number: 1000.118k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:46:13,213][train][INFO][train.py>_log] ==> #533000     Total Loss: 2.535    [weighted Loss:2.535    Policy Loss: 7.749    Value Loss: 4.440    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1111176    Buffer Size: 15999      Transition Number: 1000.299k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:49:09,129][train][INFO][train.py>_log] ==> #534000     Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 8.022    Value Loss: 4.988    Reward Loss: 1.852    Consistency Loss: 0.000    ] Replay Episodes Collected: 1113410    Buffer Size: 15988      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:52:03,206][train][INFO][train.py>_log] ==> #535000     Total Loss: 2.516    [weighted Loss:2.516    Policy Loss: 7.888    Value Loss: 4.475    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1115624    Buffer Size: 16002      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:54:57,232][train][INFO][train.py>_log] ==> #536000     Total Loss: 3.474    [weighted Loss:3.474    Policy Loss: 7.886    Value Loss: 4.523    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1117795    Buffer Size: 15998      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00400 
[2022-02-20 09:57:53,915][train][INFO][train.py>_log] ==> #537000     Total Loss: 3.476    [weighted Loss:3.476    Policy Loss: 7.611    Value Loss: 4.595    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1120037    Buffer Size: 15982      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:00:47,022][train][INFO][train.py>_log] ==> #538000     Total Loss: 0.964    [weighted Loss:0.964    Policy Loss: 7.670    Value Loss: 4.522    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 1122183    Buffer Size: 15980      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:03:41,479][train][INFO][train.py>_log] ==> #539000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 7.882    Value Loss: 4.351    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1124320    Buffer Size: 15954      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:06:37,442][train][INFO][train.py>_log] ==> #540000     Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 7.975    Value Loss: 4.337    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1126535    Buffer Size: 15948      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:09:33,947][train][INFO][train.py>_log] ==> #541000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 7.842    Value Loss: 4.551    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1128732    Buffer Size: 15932      Transition Number: 1000.294k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:12:29,830][train][INFO][train.py>_log] ==> #542000     Total Loss: 0.994    [weighted Loss:0.994    Policy Loss: 7.544    Value Loss: 4.446    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1130956    Buffer Size: 15899      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:15:24,932][train][INFO][train.py>_log] ==> #543000     Total Loss: 2.151    [weighted Loss:2.151    Policy Loss: 7.513    Value Loss: 4.440    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 1133216    Buffer Size: 15883      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:18:18,077][train][INFO][train.py>_log] ==> #544000     Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 7.404    Value Loss: 4.660    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 1135327    Buffer Size: 15877      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:21:12,113][train][INFO][train.py>_log] ==> #545000     Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 7.754    Value Loss: 4.553    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1137565    Buffer Size: 15871      Transition Number: 1000.335k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:24:08,283][train][INFO][train.py>_log] ==> #546000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 7.160    Value Loss: 4.473    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1139777    Buffer Size: 15872      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:27:03,987][train][INFO][train.py>_log] ==> #547000     Total Loss: 2.319    [weighted Loss:2.319    Policy Loss: 7.345    Value Loss: 4.444    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 1141974    Buffer Size: 15883      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:29:59,237][train][INFO][train.py>_log] ==> #548000     Total Loss: 3.249    [weighted Loss:3.249    Policy Loss: 7.306    Value Loss: 4.424    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144211    Buffer Size: 15909      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:32:54,299][train][INFO][train.py>_log] ==> #549000     Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 7.285    Value Loss: 4.983    Reward Loss: 1.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 1146421    Buffer Size: 15937      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:35:51,345][train][INFO][train.py>_log] ==> #550000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 7.390    Value Loss: 4.321    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 1148650    Buffer Size: 15967      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:38:45,375][train][INFO][train.py>_log] ==> #551000     Total Loss: 3.375    [weighted Loss:3.375    Policy Loss: 7.710    Value Loss: 4.218    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1150832    Buffer Size: 15984      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:41:36,040][train][INFO][train.py>_log] ==> #552000     Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 7.745    Value Loss: 4.260    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1152948    Buffer Size: 15998      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:44:27,566][train][INFO][train.py>_log] ==> #553000     Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 7.578    Value Loss: 4.374    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1155075    Buffer Size: 16006      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:47:25,064][train][INFO][train.py>_log] ==> #554000     Total Loss: 3.323    [weighted Loss:3.323    Policy Loss: 8.102    Value Loss: 4.646    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 1157291    Buffer Size: 16001      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:50:16,936][train][INFO][train.py>_log] ==> #555000     Total Loss: 2.336    [weighted Loss:2.336    Policy Loss: 7.973    Value Loss: 4.353    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 1159451    Buffer Size: 15991      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:53:10,084][train][INFO][train.py>_log] ==> #556000     Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 7.878    Value Loss: 4.645    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1161660    Buffer Size: 15984      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:56:05,781][train][INFO][train.py>_log] ==> #557000     Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 8.116    Value Loss: 4.275    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1163876    Buffer Size: 15963      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 10:58:57,954][train][INFO][train.py>_log] ==> #558000     Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 7.782    Value Loss: 4.605    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 1166022    Buffer Size: 15961      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:01:54,722][train][INFO][train.py>_log] ==> #559000     Total Loss: 1.213    [weighted Loss:1.213    Policy Loss: 8.007    Value Loss: 4.393    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 1168233    Buffer Size: 15940      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:04:48,956][train][INFO][train.py>_log] ==> #560000     Total Loss: 3.219    [weighted Loss:3.219    Policy Loss: 7.763    Value Loss: 4.838    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 1170444    Buffer Size: 15921      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:07:42,415][train][INFO][train.py>_log] ==> #561000     Total Loss: 3.062    [weighted Loss:3.062    Policy Loss: 7.843    Value Loss: 4.596    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 1172538    Buffer Size: 15893      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:10:35,322][train][INFO][train.py>_log] ==> #562000     Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 8.203    Value Loss: 4.613    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 1174674    Buffer Size: 15878      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:13:29,246][train][INFO][train.py>_log] ==> #563000     Total Loss: 2.004    [weighted Loss:2.004    Policy Loss: 8.287    Value Loss: 4.418    Reward Loss: 1.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 1176884    Buffer Size: 15843      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:16:23,988][train][INFO][train.py>_log] ==> #564000     Total Loss: 2.767    [weighted Loss:2.767    Policy Loss: 7.515    Value Loss: 4.437    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1179046    Buffer Size: 15799      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:19:20,744][train][INFO][train.py>_log] ==> #565000     Total Loss: 2.487    [weighted Loss:2.487    Policy Loss: 7.672    Value Loss: 4.424    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1181224    Buffer Size: 15780      Transition Number: 1000.240k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:22:16,741][train][INFO][train.py>_log] ==> #566000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 7.641    Value Loss: 4.640    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1183480    Buffer Size: 15759      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:25:09,656][train][INFO][train.py>_log] ==> #567000     Total Loss: 2.347    [weighted Loss:2.347    Policy Loss: 7.940    Value Loss: 4.554    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1185635    Buffer Size: 15761      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:28:04,256][train][INFO][train.py>_log] ==> #568000     Total Loss: 1.560    [weighted Loss:1.560    Policy Loss: 7.545    Value Loss: 4.317    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1187840    Buffer Size: 15786      Transition Number: 1000.542k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:31:01,294][train][INFO][train.py>_log] ==> #569000     Total Loss: 2.120    [weighted Loss:2.120    Policy Loss: 7.646    Value Loss: 4.499    Reward Loss: 1.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 1190066    Buffer Size: 15794      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:33:54,453][train][INFO][train.py>_log] ==> #570000     Total Loss: 2.864    [weighted Loss:2.864    Policy Loss: 8.034    Value Loss: 4.073    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1192287    Buffer Size: 15814      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:36:50,870][train][INFO][train.py>_log] ==> #571000     Total Loss: 1.079    [weighted Loss:1.079    Policy Loss: 7.729    Value Loss: 4.131    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 1194500    Buffer Size: 15843      Transition Number: 1000.233k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:39:48,251][train][INFO][train.py>_log] ==> #572000     Total Loss: 3.731    [weighted Loss:3.731    Policy Loss: 7.562    Value Loss: 4.236    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1196712    Buffer Size: 15860      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:42:44,124][train][INFO][train.py>_log] ==> #573000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 7.954    Value Loss: 4.363    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 1198900    Buffer Size: 15884      Transition Number: 1000.264k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:45:37,369][train][INFO][train.py>_log] ==> #574000     Total Loss: 3.516    [weighted Loss:3.516    Policy Loss: 7.804    Value Loss: 4.653    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 1201068    Buffer Size: 15889      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:48:31,704][train][INFO][train.py>_log] ==> #575000     Total Loss: 3.432    [weighted Loss:3.432    Policy Loss: 7.863    Value Loss: 4.448    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1203231    Buffer Size: 15906      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:51:24,349][train][INFO][train.py>_log] ==> #576000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 8.343    Value Loss: 4.350    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1205466    Buffer Size: 15929      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:54:20,161][train][INFO][train.py>_log] ==> #577000     Total Loss: 2.800    [weighted Loss:2.800    Policy Loss: 8.250    Value Loss: 4.330    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1207655    Buffer Size: 15941      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00400 
[2022-02-20 11:57:17,590][train][INFO][train.py>_log] ==> #578000     Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 7.752    Value Loss: 4.768    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1209896    Buffer Size: 15965      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:00:14,499][train][INFO][train.py>_log] ==> #579000     Total Loss: 2.389    [weighted Loss:2.389    Policy Loss: 8.136    Value Loss: 4.494    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 1212138    Buffer Size: 16001      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:03:13,278][train][INFO][train.py>_log] ==> #580000     Total Loss: 3.502    [weighted Loss:3.502    Policy Loss: 8.509    Value Loss: 4.563    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1214398    Buffer Size: 16034      Transition Number: 1000.213k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:06:10,280][train][INFO][train.py>_log] ==> #581000     Total Loss: 3.659    [weighted Loss:3.659    Policy Loss: 8.129    Value Loss: 4.620    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1216647    Buffer Size: 16064      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:09:08,662][train][INFO][train.py>_log] ==> #582000     Total Loss: 2.312    [weighted Loss:2.312    Policy Loss: 8.792    Value Loss: 4.692    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1218865    Buffer Size: 16066      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:12:08,026][train][INFO][train.py>_log] ==> #583000     Total Loss: 2.994    [weighted Loss:2.994    Policy Loss: 8.009    Value Loss: 4.570    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1221137    Buffer Size: 16077      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:15:05,112][train][INFO][train.py>_log] ==> #584000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 8.149    Value Loss: 4.225    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1223338    Buffer Size: 16091      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:18:04,525][train][INFO][train.py>_log] ==> #585000     Total Loss: 4.370    [weighted Loss:4.370    Policy Loss: 8.535    Value Loss: 4.607    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 1225594    Buffer Size: 16090      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:21:03,761][train][INFO][train.py>_log] ==> #586000     Total Loss: 3.326    [weighted Loss:3.326    Policy Loss: 8.098    Value Loss: 4.254    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 1227874    Buffer Size: 16098      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:24:03,814][train][INFO][train.py>_log] ==> #587000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 8.162    Value Loss: 4.462    Reward Loss: 1.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 1230147    Buffer Size: 16089      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:27:04,398][train][INFO][train.py>_log] ==> #588000     Total Loss: 2.675    [weighted Loss:2.675    Policy Loss: 8.418    Value Loss: 4.639    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 1232415    Buffer Size: 16061      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:30:02,458][train][INFO][train.py>_log] ==> #589000     Total Loss: 3.325    [weighted Loss:3.325    Policy Loss: 8.472    Value Loss: 4.394    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1234701    Buffer Size: 16065      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:33:01,635][train][INFO][train.py>_log] ==> #590000     Total Loss: 2.547    [weighted Loss:2.547    Policy Loss: 8.402    Value Loss: 4.438    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1237005    Buffer Size: 16059      Transition Number: 1000.194k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:36:00,322][train][INFO][train.py>_log] ==> #591000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 8.361    Value Loss: 4.546    Reward Loss: 1.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 1239211    Buffer Size: 16029      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:39:00,702][train][INFO][train.py>_log] ==> #592000     Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 7.939    Value Loss: 4.309    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1241476    Buffer Size: 16015      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:41:58,649][train][INFO][train.py>_log] ==> #593000     Total Loss: 1.890    [weighted Loss:1.890    Policy Loss: 8.764    Value Loss: 4.445    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1243759    Buffer Size: 15995      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:44:59,171][train][INFO][train.py>_log] ==> #594000     Total Loss: 2.931    [weighted Loss:2.931    Policy Loss: 8.505    Value Loss: 4.349    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1245997    Buffer Size: 15965      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:48:00,034][train][INFO][train.py>_log] ==> #595000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 8.527    Value Loss: 4.553    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1248259    Buffer Size: 15954      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:50:59,274][train][INFO][train.py>_log] ==> #596000     Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 8.198    Value Loss: 4.161    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 1250506    Buffer Size: 15951      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:53:55,202][train][INFO][train.py>_log] ==> #597000     Total Loss: 2.984    [weighted Loss:2.984    Policy Loss: 8.654    Value Loss: 4.630    Reward Loss: 1.844    Consistency Loss: 0.000    ] Replay Episodes Collected: 1252686    Buffer Size: 15908      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:56:56,284][train][INFO][train.py>_log] ==> #598000     Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 8.824    Value Loss: 4.486    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1254969    Buffer Size: 15896      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00400 
[2022-02-20 12:59:54,683][train][INFO][train.py>_log] ==> #599000     Total Loss: 2.568    [weighted Loss:2.568    Policy Loss: 8.605    Value Loss: 4.370    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1257143    Buffer Size: 15875      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00400 
[2022-02-20 13:02:52,384][train][INFO][train.py>_log] ==> #600000     Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 8.512    Value Loss: 4.404    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1259424    Buffer Size: 15836      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00400 
[2022-02-20 13:05:52,070][train][INFO][train.py>_log] ==> #601000     Total Loss: 2.757    [weighted Loss:2.757    Policy Loss: 8.577    Value Loss: 4.747    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1261673    Buffer Size: 15817      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:08:52,691][train][INFO][train.py>_log] ==> #602000     Total Loss: 3.540    [weighted Loss:3.540    Policy Loss: 9.254    Value Loss: 4.559    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 1263927    Buffer Size: 15778      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:11:51,830][train][INFO][train.py>_log] ==> #603000     Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 8.468    Value Loss: 4.520    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1266157    Buffer Size: 15704      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:14:50,892][train][INFO][train.py>_log] ==> #604000     Total Loss: 3.431    [weighted Loss:3.431    Policy Loss: 8.916    Value Loss: 4.397    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1268401    Buffer Size: 15679      Transition Number: 1000.336k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:17:48,334][train][INFO][train.py>_log] ==> #605000     Total Loss: 2.875    [weighted Loss:2.875    Policy Loss: 8.661    Value Loss: 4.417    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1270645    Buffer Size: 15640      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:20:44,110][train][INFO][train.py>_log] ==> #606000     Total Loss: 4.140    [weighted Loss:4.140    Policy Loss: 8.708    Value Loss: 4.422    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1272828    Buffer Size: 15601      Transition Number: 1000.180k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:23:40,585][train][INFO][train.py>_log] ==> #607000     Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 8.493    Value Loss: 4.413    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1275092    Buffer Size: 15557      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:26:37,456][train][INFO][train.py>_log] ==> #608000     Total Loss: 2.913    [weighted Loss:2.913    Policy Loss: 8.452    Value Loss: 4.359    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 1277318    Buffer Size: 15511      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:29:38,021][train][INFO][train.py>_log] ==> #609000     Total Loss: 2.629    [weighted Loss:2.629    Policy Loss: 8.946    Value Loss: 4.269    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 1279567    Buffer Size: 15476      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:32:37,996][train][INFO][train.py>_log] ==> #610000     Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 8.825    Value Loss: 4.308    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1281865    Buffer Size: 15440      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:35:37,889][train][INFO][train.py>_log] ==> #611000     Total Loss: 2.315    [weighted Loss:2.315    Policy Loss: 8.978    Value Loss: 4.307    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 1284088    Buffer Size: 15399      Transition Number: 1000.120k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:38:35,304][train][INFO][train.py>_log] ==> #612000     Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 8.794    Value Loss: 4.379    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 1286288    Buffer Size: 15354      Transition Number: 1000.068k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:41:36,827][train][INFO][train.py>_log] ==> #613000     Total Loss: 3.264    [weighted Loss:3.264    Policy Loss: 8.688    Value Loss: 4.342    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1288602    Buffer Size: 15324      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:44:38,278][train][INFO][train.py>_log] ==> #614000     Total Loss: 3.545    [weighted Loss:3.545    Policy Loss: 8.744    Value Loss: 4.553    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1290894    Buffer Size: 15297      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:47:34,761][train][INFO][train.py>_log] ==> #615000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 8.576    Value Loss: 4.423    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1293048    Buffer Size: 15279      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:50:30,354][train][INFO][train.py>_log] ==> #616000     Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 9.055    Value Loss: 4.441    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 1295274    Buffer Size: 15252      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:53:28,072][train][INFO][train.py>_log] ==> #617000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 8.703    Value Loss: 4.388    Reward Loss: 1.940    Consistency Loss: 0.000    ] Replay Episodes Collected: 1297463    Buffer Size: 15236      Transition Number: 1000.016k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:56:25,590][train][INFO][train.py>_log] ==> #618000     Total Loss: 2.472    [weighted Loss:2.472    Policy Loss: 8.432    Value Loss: 4.222    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 1299657    Buffer Size: 15228      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 13:59:22,644][train][INFO][train.py>_log] ==> #619000     Total Loss: 2.099    [weighted Loss:2.099    Policy Loss: 8.984    Value Loss: 4.275    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1301883    Buffer Size: 15244      Transition Number: 1000.383k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:02:18,779][train][INFO][train.py>_log] ==> #620000     Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 8.583    Value Loss: 4.104    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1304057    Buffer Size: 15232      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:05:13,431][train][INFO][train.py>_log] ==> #621000     Total Loss: 4.317    [weighted Loss:4.317    Policy Loss: 8.809    Value Loss: 4.183    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 1306259    Buffer Size: 15214      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:08:12,242][train][INFO][train.py>_log] ==> #622000     Total Loss: 3.291    [weighted Loss:3.291    Policy Loss: 8.649    Value Loss: 4.277    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1308478    Buffer Size: 15207      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:11:10,172][train][INFO][train.py>_log] ==> #623000     Total Loss: 3.923    [weighted Loss:3.923    Policy Loss: 8.237    Value Loss: 4.468    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1310697    Buffer Size: 15206      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:14:07,911][train][INFO][train.py>_log] ==> #624000     Total Loss: 3.684    [weighted Loss:3.684    Policy Loss: 8.612    Value Loss: 4.639    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1312939    Buffer Size: 15198      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:17:06,466][train][INFO][train.py>_log] ==> #625000     Total Loss: 3.403    [weighted Loss:3.403    Policy Loss: 8.950    Value Loss: 4.443    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 1315130    Buffer Size: 15174      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:20:03,724][train][INFO][train.py>_log] ==> #626000     Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 8.748    Value Loss: 4.421    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1317344    Buffer Size: 15132      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:23:03,203][train][INFO][train.py>_log] ==> #627000     Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 8.746    Value Loss: 4.575    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1319637    Buffer Size: 15114      Transition Number: 1000.152k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:26:01,009][train][INFO][train.py>_log] ==> #628000     Total Loss: 1.046    [weighted Loss:1.046    Policy Loss: 8.557    Value Loss: 4.182    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1321860    Buffer Size: 15096      Transition Number: 1000.745k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:28:58,050][train][INFO][train.py>_log] ==> #629000     Total Loss: 3.822    [weighted Loss:3.822    Policy Loss: 9.171    Value Loss: 4.554    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1324037    Buffer Size: 15075      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:31:55,083][train][INFO][train.py>_log] ==> #630000     Total Loss: 2.577    [weighted Loss:2.577    Policy Loss: 8.833    Value Loss: 4.255    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 1326229    Buffer Size: 15070      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:34:53,156][train][INFO][train.py>_log] ==> #631000     Total Loss: 1.165    [weighted Loss:1.165    Policy Loss: 8.669    Value Loss: 4.487    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1328419    Buffer Size: 15071      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:37:50,051][train][INFO][train.py>_log] ==> #632000     Total Loss: 3.936    [weighted Loss:3.936    Policy Loss: 8.642    Value Loss: 4.512    Reward Loss: 1.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 1330614    Buffer Size: 15074      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:40:48,908][train][INFO][train.py>_log] ==> #633000     Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 8.598    Value Loss: 4.246    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 1332871    Buffer Size: 15097      Transition Number: 1000.511k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:43:49,234][train][INFO][train.py>_log] ==> #634000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 8.921    Value Loss: 4.481    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 1335110    Buffer Size: 15097      Transition Number: 1000.284k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:46:46,252][train][INFO][train.py>_log] ==> #635000     Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 9.361    Value Loss: 4.419    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 1337329    Buffer Size: 15099      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:49:47,808][train][INFO][train.py>_log] ==> #636000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 9.226    Value Loss: 4.270    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1339609    Buffer Size: 15106      Transition Number: 1000.211k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:52:48,855][train][INFO][train.py>_log] ==> #637000     Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 8.728    Value Loss: 4.179    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 1341835    Buffer Size: 15099      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:55:45,755][train][INFO][train.py>_log] ==> #638000     Total Loss: 4.203    [weighted Loss:4.203    Policy Loss: 8.681    Value Loss: 4.114    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1344077    Buffer Size: 15099      Transition Number: 1000.214k Batch Size: 256        Lr: 0.00080 
[2022-02-20 14:58:43,700][train][INFO][train.py>_log] ==> #639000     Total Loss: 2.773    [weighted Loss:2.773    Policy Loss: 8.796    Value Loss: 4.307    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1346296    Buffer Size: 15093      Transition Number: 1000.171k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:01:41,945][train][INFO][train.py>_log] ==> #640000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 9.061    Value Loss: 4.404    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1348453    Buffer Size: 15083      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:04:39,331][train][INFO][train.py>_log] ==> #641000     Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 8.789    Value Loss: 4.485    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350640    Buffer Size: 15074      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:07:42,165][train][INFO][train.py>_log] ==> #642000     Total Loss: 3.040    [weighted Loss:3.040    Policy Loss: 8.743    Value Loss: 4.231    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 1352900    Buffer Size: 15082      Transition Number: 1000.232k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:10:39,620][train][INFO][train.py>_log] ==> #643000     Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 8.764    Value Loss: 4.270    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 1355126    Buffer Size: 15083      Transition Number: 1000.102k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:13:42,979][train][INFO][train.py>_log] ==> #644000     Total Loss: 1.086    [weighted Loss:1.086    Policy Loss: 8.736    Value Loss: 4.291    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 1357386    Buffer Size: 15096      Transition Number: 1000.158k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:16:40,762][train][INFO][train.py>_log] ==> #645000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 8.725    Value Loss: 4.291    Reward Loss: 1.881    Consistency Loss: 0.000    ] Replay Episodes Collected: 1359682    Buffer Size: 15101      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:19:41,166][train][INFO][train.py>_log] ==> #646000     Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 8.761    Value Loss: 4.489    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 1361846    Buffer Size: 15106      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:22:40,739][train][INFO][train.py>_log] ==> #647000     Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 8.742    Value Loss: 4.513    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1364176    Buffer Size: 15115      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:25:39,259][train][INFO][train.py>_log] ==> #648000     Total Loss: 3.283    [weighted Loss:3.283    Policy Loss: 9.013    Value Loss: 4.200    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1366355    Buffer Size: 15130      Transition Number: 1000.038k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:28:38,443][train][INFO][train.py>_log] ==> #649000     Total Loss: 4.185    [weighted Loss:4.185    Policy Loss: 9.238    Value Loss: 4.186    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1368603    Buffer Size: 15125      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:31:38,432][train][INFO][train.py>_log] ==> #650000     Total Loss: 2.945    [weighted Loss:2.945    Policy Loss: 8.873    Value Loss: 4.479    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 1370869    Buffer Size: 15121      Transition Number: 1000.490k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:34:36,381][train][INFO][train.py>_log] ==> #651000     Total Loss: 3.088    [weighted Loss:3.088    Policy Loss: 9.003    Value Loss: 4.160    Reward Loss: 1.911    Consistency Loss: 0.000    ] Replay Episodes Collected: 1373076    Buffer Size: 15109      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:37:33,029][train][INFO][train.py>_log] ==> #652000     Total Loss: 3.248    [weighted Loss:3.248    Policy Loss: 8.802    Value Loss: 4.135    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1375277    Buffer Size: 15090      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:40:31,402][train][INFO][train.py>_log] ==> #653000     Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 8.521    Value Loss: 4.227    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1377530    Buffer Size: 15094      Transition Number: 1000.238k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:43:28,432][train][INFO][train.py>_log] ==> #654000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 8.404    Value Loss: 4.254    Reward Loss: 2.012    Consistency Loss: 0.000    ] Replay Episodes Collected: 1379728    Buffer Size: 15068      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:46:27,968][train][INFO][train.py>_log] ==> #655000     Total Loss: 2.091    [weighted Loss:2.091    Policy Loss: 9.094    Value Loss: 4.481    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1381945    Buffer Size: 15066      Transition Number: 1000.321k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:49:24,020][train][INFO][train.py>_log] ==> #656000     Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 8.797    Value Loss: 4.303    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1384131    Buffer Size: 15050      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:52:24,544][train][INFO][train.py>_log] ==> #657000     Total Loss: 3.764    [weighted Loss:3.764    Policy Loss: 9.346    Value Loss: 4.541    Reward Loss: 1.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 1386390    Buffer Size: 15077      Transition Number: 1000.297k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:55:26,288][train][INFO][train.py>_log] ==> #658000     Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 9.423    Value Loss: 4.360    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 1388674    Buffer Size: 15088      Transition Number: 1000.315k Batch Size: 256        Lr: 0.00080 
[2022-02-20 15:58:23,240][train][INFO][train.py>_log] ==> #659000     Total Loss: 3.372    [weighted Loss:3.372    Policy Loss: 9.012    Value Loss: 4.509    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1390896    Buffer Size: 15124      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:01:18,619][train][INFO][train.py>_log] ==> #660000     Total Loss: 3.151    [weighted Loss:3.151    Policy Loss: 8.834    Value Loss: 4.430    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1393071    Buffer Size: 15148      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:04:19,708][train][INFO][train.py>_log] ==> #661000     Total Loss: 3.033    [weighted Loss:3.033    Policy Loss: 9.078    Value Loss: 4.192    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 1395294    Buffer Size: 15176      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:07:20,944][train][INFO][train.py>_log] ==> #662000     Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 8.811    Value Loss: 4.301    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 1397556    Buffer Size: 15202      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:10:18,404][train][INFO][train.py>_log] ==> #663000     Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 8.904    Value Loss: 4.449    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 1399777    Buffer Size: 15223      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:13:21,424][train][INFO][train.py>_log] ==> #664000     Total Loss: 1.086    [weighted Loss:1.086    Policy Loss: 8.730    Value Loss: 4.351    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1402115    Buffer Size: 15237      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:16:20,968][train][INFO][train.py>_log] ==> #665000     Total Loss: 3.635    [weighted Loss:3.635    Policy Loss: 8.912    Value Loss: 4.701    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1404348    Buffer Size: 15247      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:19:18,222][train][INFO][train.py>_log] ==> #666000     Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 8.628    Value Loss: 4.192    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1406568    Buffer Size: 15236      Transition Number: 1000.207k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:22:16,934][train][INFO][train.py>_log] ==> #667000     Total Loss: 3.504    [weighted Loss:3.504    Policy Loss: 9.153    Value Loss: 4.282    Reward Loss: 1.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 1408791    Buffer Size: 15246      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:25:19,932][train][INFO][train.py>_log] ==> #668000     Total Loss: 3.306    [weighted Loss:3.306    Policy Loss: 8.924    Value Loss: 4.305    Reward Loss: 1.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411070    Buffer Size: 15267      Transition Number: 1000.595k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:28:17,813][train][INFO][train.py>_log] ==> #669000     Total Loss: 2.732    [weighted Loss:2.732    Policy Loss: 9.104    Value Loss: 4.505    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1413317    Buffer Size: 15267      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:31:17,023][train][INFO][train.py>_log] ==> #670000     Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 8.925    Value Loss: 4.462    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1415589    Buffer Size: 15291      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:34:15,771][train][INFO][train.py>_log] ==> #671000     Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 9.103    Value Loss: 4.251    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1417864    Buffer Size: 15299      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:37:17,085][train][INFO][train.py>_log] ==> #672000     Total Loss: 2.782    [weighted Loss:2.782    Policy Loss: 9.443    Value Loss: 4.460    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1420132    Buffer Size: 15320      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:40:15,960][train][INFO][train.py>_log] ==> #673000     Total Loss: 3.254    [weighted Loss:3.254    Policy Loss: 9.366    Value Loss: 4.623    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 1422343    Buffer Size: 15329      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:43:15,508][train][INFO][train.py>_log] ==> #674000     Total Loss: 2.427    [weighted Loss:2.427    Policy Loss: 9.357    Value Loss: 4.168    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1424590    Buffer Size: 15319      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:46:15,234][train][INFO][train.py>_log] ==> #675000     Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 8.896    Value Loss: 4.632    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1426865    Buffer Size: 15317      Transition Number: 1000.250k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:49:15,681][train][INFO][train.py>_log] ==> #676000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 9.441    Value Loss: 4.215    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1429099    Buffer Size: 15300      Transition Number: 1000.218k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:52:16,541][train][INFO][train.py>_log] ==> #677000     Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 9.152    Value Loss: 4.182    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 1431400    Buffer Size: 15276      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:55:13,654][train][INFO][train.py>_log] ==> #678000     Total Loss: 1.971    [weighted Loss:1.971    Policy Loss: 9.077    Value Loss: 4.545    Reward Loss: 1.880    Consistency Loss: 0.000    ] Replay Episodes Collected: 1433612    Buffer Size: 15261      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00080 
[2022-02-20 16:58:14,981][train][INFO][train.py>_log] ==> #679000     Total Loss: 1.283    [weighted Loss:1.283    Policy Loss: 9.196    Value Loss: 4.301    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1435891    Buffer Size: 15241      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:01:15,739][train][INFO][train.py>_log] ==> #680000     Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 9.193    Value Loss: 4.528    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1438176    Buffer Size: 15224      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:04:14,690][train][INFO][train.py>_log] ==> #681000     Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 9.377    Value Loss: 4.437    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1440449    Buffer Size: 15212      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:07:11,922][train][INFO][train.py>_log] ==> #682000     Total Loss: 3.278    [weighted Loss:3.278    Policy Loss: 8.944    Value Loss: 4.322    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 1442669    Buffer Size: 15205      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:10:09,061][train][INFO][train.py>_log] ==> #683000     Total Loss: 0.961    [weighted Loss:0.961    Policy Loss: 9.268    Value Loss: 4.195    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 1444892    Buffer Size: 15203      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:13:09,604][train][INFO][train.py>_log] ==> #684000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 8.969    Value Loss: 4.128    Reward Loss: 1.861    Consistency Loss: 0.000    ] Replay Episodes Collected: 1447165    Buffer Size: 15189      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:16:08,451][train][INFO][train.py>_log] ==> #685000     Total Loss: 3.338    [weighted Loss:3.338    Policy Loss: 9.338    Value Loss: 4.123    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 1449411    Buffer Size: 15181      Transition Number: 1000.317k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:19:07,765][train][INFO][train.py>_log] ==> #686000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 9.688    Value Loss: 4.529    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451638    Buffer Size: 15159      Transition Number: 1000.042k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:22:08,928][train][INFO][train.py>_log] ==> #687000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 9.311    Value Loss: 4.585    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1453906    Buffer Size: 15148      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:25:11,718][train][INFO][train.py>_log] ==> #688000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 9.366    Value Loss: 4.589    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1456181    Buffer Size: 15122      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:28:08,977][train][INFO][train.py>_log] ==> #689000     Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 8.989    Value Loss: 4.732    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 1458436    Buffer Size: 15118      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:31:07,864][train][INFO][train.py>_log] ==> #690000     Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 9.162    Value Loss: 4.245    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1460694    Buffer Size: 15112      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:34:10,390][train][INFO][train.py>_log] ==> #691000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 9.714    Value Loss: 4.396    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1462991    Buffer Size: 15109      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:37:09,312][train][INFO][train.py>_log] ==> #692000     Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 9.395    Value Loss: 4.121    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1465221    Buffer Size: 15093      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:40:08,975][train][INFO][train.py>_log] ==> #693000     Total Loss: 1.424    [weighted Loss:1.424    Policy Loss: 8.754    Value Loss: 4.248    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 1467545    Buffer Size: 15093      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:43:07,618][train][INFO][train.py>_log] ==> #694000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 9.342    Value Loss: 4.275    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1469734    Buffer Size: 15088      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:46:09,032][train][INFO][train.py>_log] ==> #695000     Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 9.364    Value Loss: 4.505    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 1472022    Buffer Size: 15100      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:49:07,127][train][INFO][train.py>_log] ==> #696000     Total Loss: 1.045    [weighted Loss:1.045    Policy Loss: 9.187    Value Loss: 4.454    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1474272    Buffer Size: 15086      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:52:07,230][train][INFO][train.py>_log] ==> #697000     Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 9.662    Value Loss: 4.504    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1476554    Buffer Size: 15056      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:55:09,868][train][INFO][train.py>_log] ==> #698000     Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 9.221    Value Loss: 4.334    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 1478852    Buffer Size: 15048      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00080 
[2022-02-20 17:58:10,007][train][INFO][train.py>_log] ==> #699000     Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 9.353    Value Loss: 4.353    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 1481099    Buffer Size: 15054      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:01:09,343][train][INFO][train.py>_log] ==> #700000     Total Loss: 3.152    [weighted Loss:3.152    Policy Loss: 9.207    Value Loss: 4.355    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1483345    Buffer Size: 15053      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:04:08,363][train][INFO][train.py>_log] ==> #701000     Total Loss: 2.631    [weighted Loss:2.631    Policy Loss: 9.782    Value Loss: 4.350    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1485600    Buffer Size: 15054      Transition Number: 1000.646k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:07:10,195][train][INFO][train.py>_log] ==> #702000     Total Loss: 2.749    [weighted Loss:2.749    Policy Loss: 9.520    Value Loss: 4.457    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 1487859    Buffer Size: 15060      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:10:08,591][train][INFO][train.py>_log] ==> #703000     Total Loss: 2.654    [weighted Loss:2.654    Policy Loss: 9.434    Value Loss: 4.448    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1490073    Buffer Size: 15056      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:13:07,529][train][INFO][train.py>_log] ==> #704000     Total Loss: 3.021    [weighted Loss:3.021    Policy Loss: 9.002    Value Loss: 4.228    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1492309    Buffer Size: 15065      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:16:08,512][train][INFO][train.py>_log] ==> #705000     Total Loss: 4.466    [weighted Loss:4.466    Policy Loss: 9.625    Value Loss: 4.496    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1494547    Buffer Size: 15070      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:19:08,777][train][INFO][train.py>_log] ==> #706000     Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 9.626    Value Loss: 4.419    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 1496837    Buffer Size: 15088      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:22:11,530][train][INFO][train.py>_log] ==> #707000     Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 9.400    Value Loss: 4.610    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1499165    Buffer Size: 15103      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:25:12,566][train][INFO][train.py>_log] ==> #708000     Total Loss: 1.951    [weighted Loss:1.951    Policy Loss: 9.349    Value Loss: 4.976    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1501444    Buffer Size: 15106      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:28:12,224][train][INFO][train.py>_log] ==> #709000     Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 9.508    Value Loss: 4.438    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1503673    Buffer Size: 15105      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:31:13,123][train][INFO][train.py>_log] ==> #710000     Total Loss: 2.781    [weighted Loss:2.781    Policy Loss: 9.578    Value Loss: 4.824    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1505933    Buffer Size: 15105      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:34:15,928][train][INFO][train.py>_log] ==> #711000     Total Loss: 3.726    [weighted Loss:3.726    Policy Loss: 9.519    Value Loss: 4.550    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1508228    Buffer Size: 15113      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:37:19,420][train][INFO][train.py>_log] ==> #712000     Total Loss: 1.673    [weighted Loss:1.673    Policy Loss: 10.052   Value Loss: 4.335    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1510527    Buffer Size: 15100      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:40:20,730][train][INFO][train.py>_log] ==> #713000     Total Loss: 3.314    [weighted Loss:3.314    Policy Loss: 10.091   Value Loss: 4.483    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1512808    Buffer Size: 15112      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:43:21,972][train][INFO][train.py>_log] ==> #714000     Total Loss: 3.773    [weighted Loss:3.773    Policy Loss: 9.255    Value Loss: 4.579    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1515152    Buffer Size: 15099      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:46:21,899][train][INFO][train.py>_log] ==> #715000     Total Loss: 3.929    [weighted Loss:3.929    Policy Loss: 10.010   Value Loss: 4.596    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1517358    Buffer Size: 15090      Transition Number: 1000.166k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:49:24,516][train][INFO][train.py>_log] ==> #716000     Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 9.782    Value Loss: 4.582    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1519696    Buffer Size: 15101      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:52:25,425][train][INFO][train.py>_log] ==> #717000     Total Loss: 2.271    [weighted Loss:2.271    Policy Loss: 10.095   Value Loss: 4.266    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 1521956    Buffer Size: 15125      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:55:27,158][train][INFO][train.py>_log] ==> #718000     Total Loss: 2.207    [weighted Loss:2.207    Policy Loss: 9.466    Value Loss: 4.285    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524183    Buffer Size: 15138      Transition Number: 1000.311k Batch Size: 256        Lr: 0.00080 
[2022-02-20 18:58:28,335][train][INFO][train.py>_log] ==> #719000     Total Loss: 1.598    [weighted Loss:1.598    Policy Loss: 9.970    Value Loss: 4.826    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1526469    Buffer Size: 15172      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:01:28,429][train][INFO][train.py>_log] ==> #720000     Total Loss: 4.091    [weighted Loss:4.091    Policy Loss: 9.740    Value Loss: 4.645    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1528799    Buffer Size: 15176      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:04:28,654][train][INFO][train.py>_log] ==> #721000     Total Loss: 3.536    [weighted Loss:3.536    Policy Loss: 9.886    Value Loss: 4.515    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1531009    Buffer Size: 15200      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:07:28,290][train][INFO][train.py>_log] ==> #722000     Total Loss: 2.454    [weighted Loss:2.454    Policy Loss: 9.869    Value Loss: 4.047    Reward Loss: 1.849    Consistency Loss: 0.000    ] Replay Episodes Collected: 1533264    Buffer Size: 15216      Transition Number: 1000.205k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:10:27,184][train][INFO][train.py>_log] ==> #723000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 10.109   Value Loss: 4.525    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1535527    Buffer Size: 15210      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:13:25,159][train][INFO][train.py>_log] ==> #724000     Total Loss: 3.657    [weighted Loss:3.657    Policy Loss: 10.209   Value Loss: 4.189    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 1537710    Buffer Size: 15212      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:16:25,669][train][INFO][train.py>_log] ==> #725000     Total Loss: 3.043    [weighted Loss:3.043    Policy Loss: 9.707    Value Loss: 4.464    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 1540015    Buffer Size: 15201      Transition Number: 1000.133k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:19:25,146][train][INFO][train.py>_log] ==> #726000     Total Loss: 3.635    [weighted Loss:3.635    Policy Loss: 9.910    Value Loss: 4.230    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1542220    Buffer Size: 15196      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:22:27,141][train][INFO][train.py>_log] ==> #727000     Total Loss: 2.698    [weighted Loss:2.698    Policy Loss: 9.712    Value Loss: 4.444    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 1544500    Buffer Size: 15196      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:25:27,568][train][INFO][train.py>_log] ==> #728000     Total Loss: 3.376    [weighted Loss:3.376    Policy Loss: 10.118   Value Loss: 4.580    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 1546754    Buffer Size: 15200      Transition Number: 1000.166k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:28:29,039][train][INFO][train.py>_log] ==> #729000     Total Loss: 3.539    [weighted Loss:3.539    Policy Loss: 9.822    Value Loss: 4.616    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 1549001    Buffer Size: 15182      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:31:31,920][train][INFO][train.py>_log] ==> #730000     Total Loss: 3.369    [weighted Loss:3.369    Policy Loss: 9.999    Value Loss: 4.874    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 1551285    Buffer Size: 15199      Transition Number: 1000.545k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:34:32,693][train][INFO][train.py>_log] ==> #731000     Total Loss: 2.661    [weighted Loss:2.661    Policy Loss: 10.143   Value Loss: 4.199    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 1553628    Buffer Size: 15195      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:37:31,041][train][INFO][train.py>_log] ==> #732000     Total Loss: 3.278    [weighted Loss:3.278    Policy Loss: 9.770    Value Loss: 4.355    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1555813    Buffer Size: 15190      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:40:32,147][train][INFO][train.py>_log] ==> #733000     Total Loss: 2.724    [weighted Loss:2.724    Policy Loss: 9.822    Value Loss: 4.645    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1558047    Buffer Size: 15183      Transition Number: 1000.128k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:43:32,191][train][INFO][train.py>_log] ==> #734000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 10.010   Value Loss: 4.283    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 1560337    Buffer Size: 15186      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:46:35,514][train][INFO][train.py>_log] ==> #735000     Total Loss: 3.226    [weighted Loss:3.226    Policy Loss: 9.991    Value Loss: 4.328    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 1562638    Buffer Size: 15179      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:49:37,073][train][INFO][train.py>_log] ==> #736000     Total Loss: 3.351    [weighted Loss:3.351    Policy Loss: 10.082   Value Loss: 4.472    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 1564862    Buffer Size: 15190      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:52:37,950][train][INFO][train.py>_log] ==> #737000     Total Loss: 3.529    [weighted Loss:3.529    Policy Loss: 9.448    Value Loss: 4.261    Reward Loss: 1.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 1567152    Buffer Size: 15185      Transition Number: 1000.095k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:55:38,068][train][INFO][train.py>_log] ==> #738000     Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 10.013   Value Loss: 4.726    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1569421    Buffer Size: 15183      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00080 
[2022-02-20 19:58:44,651][train][INFO][train.py>_log] ==> #739000     Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 9.457    Value Loss: 4.401    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1571773    Buffer Size: 15194      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:01:46,999][train][INFO][train.py>_log] ==> #740000     Total Loss: 3.911    [weighted Loss:3.911    Policy Loss: 9.668    Value Loss: 4.610    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 1574108    Buffer Size: 15188      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:04:48,706][train][INFO][train.py>_log] ==> #741000     Total Loss: 2.720    [weighted Loss:2.720    Policy Loss: 9.183    Value Loss: 4.351    Reward Loss: 1.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 1576309    Buffer Size: 15190      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:07:51,226][train][INFO][train.py>_log] ==> #742000     Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 9.440    Value Loss: 4.521    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1578594    Buffer Size: 15194      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:10:53,121][train][INFO][train.py>_log] ==> #743000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 9.695    Value Loss: 4.456    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1580912    Buffer Size: 15192      Transition Number: 1000.342k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:13:55,093][train][INFO][train.py>_log] ==> #744000     Total Loss: 2.422    [weighted Loss:2.422    Policy Loss: 9.296    Value Loss: 4.411    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1583195    Buffer Size: 15195      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:16:57,662][train][INFO][train.py>_log] ==> #745000     Total Loss: 2.673    [weighted Loss:2.673    Policy Loss: 9.701    Value Loss: 4.265    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 1585502    Buffer Size: 15199      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:20:02,148][train][INFO][train.py>_log] ==> #746000     Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 9.889    Value Loss: 4.646    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1587801    Buffer Size: 15194      Transition Number: 1000.271k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:23:03,808][train][INFO][train.py>_log] ==> #747000     Total Loss: 1.122    [weighted Loss:1.122    Policy Loss: 9.800    Value Loss: 4.602    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 1590081    Buffer Size: 15212      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:26:02,958][train][INFO][train.py>_log] ==> #748000     Total Loss: 2.992    [weighted Loss:2.992    Policy Loss: 9.620    Value Loss: 4.750    Reward Loss: 1.863    Consistency Loss: 0.000    ] Replay Episodes Collected: 1592304    Buffer Size: 15222      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:29:06,628][train][INFO][train.py>_log] ==> #749000     Total Loss: 3.613    [weighted Loss:3.613    Policy Loss: 10.016   Value Loss: 4.682    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 1594598    Buffer Size: 15218      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:32:06,417][train][INFO][train.py>_log] ==> #750000     Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 9.791    Value Loss: 4.370    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 1596883    Buffer Size: 15224      Transition Number: 1000.285k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:35:10,732][train][INFO][train.py>_log] ==> #751000     Total Loss: 3.383    [weighted Loss:3.383    Policy Loss: 9.798    Value Loss: 4.287    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 1599154    Buffer Size: 15225      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:38:12,817][train][INFO][train.py>_log] ==> #752000     Total Loss: 1.356    [weighted Loss:1.356    Policy Loss: 9.920    Value Loss: 4.759    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1601403    Buffer Size: 15231      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:41:14,682][train][INFO][train.py>_log] ==> #753000     Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 9.448    Value Loss: 4.705    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 1603732    Buffer Size: 15215      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:44:18,044][train][INFO][train.py>_log] ==> #754000     Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 9.736    Value Loss: 4.644    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 1606010    Buffer Size: 15227      Transition Number: 1000.364k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:47:20,460][train][INFO][train.py>_log] ==> #755000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 9.798    Value Loss: 4.566    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 1608330    Buffer Size: 15228      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:50:19,044][train][INFO][train.py>_log] ==> #756000     Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 9.673    Value Loss: 4.434    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 1610549    Buffer Size: 15251      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:53:19,756][train][INFO][train.py>_log] ==> #757000     Total Loss: 2.112    [weighted Loss:2.112    Policy Loss: 10.005   Value Loss: 4.662    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 1612791    Buffer Size: 15258      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:56:24,126][train][INFO][train.py>_log] ==> #758000     Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 9.602    Value Loss: 4.782    Reward Loss: 1.913    Consistency Loss: 0.000    ] Replay Episodes Collected: 1615064    Buffer Size: 15254      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 20:59:24,419][train][INFO][train.py>_log] ==> #759000     Total Loss: 3.806    [weighted Loss:3.806    Policy Loss: 9.865    Value Loss: 4.412    Reward Loss: 1.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 1617364    Buffer Size: 15249      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:02:30,626][train][INFO][train.py>_log] ==> #760000     Total Loss: 2.240    [weighted Loss:2.240    Policy Loss: 9.606    Value Loss: 4.389    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 1619721    Buffer Size: 15257      Transition Number: 1000.487k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:05:34,609][train][INFO][train.py>_log] ==> #761000     Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 9.429    Value Loss: 4.467    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1622062    Buffer Size: 15233      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:08:38,410][train][INFO][train.py>_log] ==> #762000     Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 9.559    Value Loss: 4.484    Reward Loss: 1.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 1624370    Buffer Size: 15206      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:11:41,219][train][INFO][train.py>_log] ==> #763000     Total Loss: 2.931    [weighted Loss:2.931    Policy Loss: 9.563    Value Loss: 4.192    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1626621    Buffer Size: 15187      Transition Number: 1000.208k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:14:42,359][train][INFO][train.py>_log] ==> #764000     Total Loss: 3.408    [weighted Loss:3.408    Policy Loss: 9.941    Value Loss: 4.412    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1628883    Buffer Size: 15160      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:17:41,513][train][INFO][train.py>_log] ==> #765000     Total Loss: 2.912    [weighted Loss:2.912    Policy Loss: 9.916    Value Loss: 4.520    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 1631125    Buffer Size: 15155      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:20:42,575][train][INFO][train.py>_log] ==> #766000     Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 9.607    Value Loss: 4.488    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1633366    Buffer Size: 15152      Transition Number: 1000.353k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:23:43,777][train][INFO][train.py>_log] ==> #767000     Total Loss: 3.367    [weighted Loss:3.367    Policy Loss: 9.725    Value Loss: 4.236    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 1635631    Buffer Size: 15138      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:26:44,168][train][INFO][train.py>_log] ==> #768000     Total Loss: 3.484    [weighted Loss:3.484    Policy Loss: 9.577    Value Loss: 4.431    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1637879    Buffer Size: 15134      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:29:45,485][train][INFO][train.py>_log] ==> #769000     Total Loss: 3.252    [weighted Loss:3.252    Policy Loss: 9.627    Value Loss: 4.793    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 1640126    Buffer Size: 15152      Transition Number: 1000.207k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:32:49,770][train][INFO][train.py>_log] ==> #770000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 9.516    Value Loss: 4.573    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 1642482    Buffer Size: 15152      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:35:53,701][train][INFO][train.py>_log] ==> #771000     Total Loss: 3.729    [weighted Loss:3.729    Policy Loss: 9.445    Value Loss: 4.608    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1644791    Buffer Size: 15164      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:38:56,033][train][INFO][train.py>_log] ==> #772000     Total Loss: 2.756    [weighted Loss:2.756    Policy Loss: 9.371    Value Loss: 4.623    Reward Loss: 1.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 1647069    Buffer Size: 15183      Transition Number: 1000.615k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:41:58,806][train][INFO][train.py>_log] ==> #773000     Total Loss: 2.420    [weighted Loss:2.420    Policy Loss: 9.781    Value Loss: 4.610    Reward Loss: 1.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 1649422    Buffer Size: 15198      Transition Number: 1000.347k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:45:02,960][train][INFO][train.py>_log] ==> #774000     Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 9.323    Value Loss: 4.428    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 1651717    Buffer Size: 15207      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:48:06,079][train][INFO][train.py>_log] ==> #775000     Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 9.557    Value Loss: 4.367    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1654031    Buffer Size: 15248      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:51:09,261][train][INFO][train.py>_log] ==> #776000     Total Loss: 3.607    [weighted Loss:3.607    Policy Loss: 9.907    Value Loss: 4.449    Reward Loss: 1.834    Consistency Loss: 0.000    ] Replay Episodes Collected: 1656272    Buffer Size: 15273      Transition Number: 1000.183k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:54:08,933][train][INFO][train.py>_log] ==> #777000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 9.727    Value Loss: 4.439    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1658549    Buffer Size: 15286      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 21:57:08,655][train][INFO][train.py>_log] ==> #778000     Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 9.544    Value Loss: 4.709    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 1660805    Buffer Size: 15312      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:00:10,957][train][INFO][train.py>_log] ==> #779000     Total Loss: 3.428    [weighted Loss:3.428    Policy Loss: 9.869    Value Loss: 4.224    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1663079    Buffer Size: 15345      Transition Number: 1000.339k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:03:14,030][train][INFO][train.py>_log] ==> #780000     Total Loss: 3.035    [weighted Loss:3.035    Policy Loss: 10.310   Value Loss: 4.216    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1665380    Buffer Size: 15362      Transition Number: 1000.154k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:06:18,035][train][INFO][train.py>_log] ==> #781000     Total Loss: 1.072    [weighted Loss:1.072    Policy Loss: 10.213   Value Loss: 4.333    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 1667722    Buffer Size: 15377      Transition Number: 1000.400k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:09:22,562][train][INFO][train.py>_log] ==> #782000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 9.734    Value Loss: 4.499    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 1670036    Buffer Size: 15369      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:12:25,984][train][INFO][train.py>_log] ==> #783000     Total Loss: 2.416    [weighted Loss:2.416    Policy Loss: 10.077   Value Loss: 4.556    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 1672273    Buffer Size: 15371      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:15:27,646][train][INFO][train.py>_log] ==> #784000     Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 9.972    Value Loss: 4.381    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 1674549    Buffer Size: 15370      Transition Number: 1000.209k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:18:31,412][train][INFO][train.py>_log] ==> #785000     Total Loss: 1.511    [weighted Loss:1.511    Policy Loss: 10.147   Value Loss: 4.303    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 1676883    Buffer Size: 15367      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:21:33,365][train][INFO][train.py>_log] ==> #786000     Total Loss: 3.273    [weighted Loss:3.273    Policy Loss: 10.273   Value Loss: 4.466    Reward Loss: 1.854    Consistency Loss: 0.000    ] Replay Episodes Collected: 1679159    Buffer Size: 15353      Transition Number: 1000.442k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:24:34,259][train][INFO][train.py>_log] ==> #787000     Total Loss: 2.410    [weighted Loss:2.410    Policy Loss: 10.232   Value Loss: 4.421    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1681423    Buffer Size: 15349      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:27:37,761][train][INFO][train.py>_log] ==> #788000     Total Loss: 3.564    [weighted Loss:3.564    Policy Loss: 10.337   Value Loss: 4.607    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1683761    Buffer Size: 15343      Transition Number: 1000.405k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:30:41,761][train][INFO][train.py>_log] ==> #789000     Total Loss: 3.987    [weighted Loss:3.987    Policy Loss: 10.004   Value Loss: 4.279    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1686039    Buffer Size: 15325      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:33:44,112][train][INFO][train.py>_log] ==> #790000     Total Loss: 3.650    [weighted Loss:3.650    Policy Loss: 10.037   Value Loss: 4.195    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1688326    Buffer Size: 15331      Transition Number: 1000.236k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:36:47,764][train][INFO][train.py>_log] ==> #791000     Total Loss: 3.236    [weighted Loss:3.236    Policy Loss: 10.315   Value Loss: 4.530    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 1690646    Buffer Size: 15318      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:39:52,459][train][INFO][train.py>_log] ==> #792000     Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 10.294   Value Loss: 4.223    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 1692992    Buffer Size: 15308      Transition Number: 1000.230k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:42:55,654][train][INFO][train.py>_log] ==> #793000     Total Loss: 3.321    [weighted Loss:3.321    Policy Loss: 10.290   Value Loss: 4.247    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1695294    Buffer Size: 15287      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:45:58,975][train][INFO][train.py>_log] ==> #794000     Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 10.221   Value Loss: 4.103    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 1697622    Buffer Size: 15284      Transition Number: 1000.822k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:49:03,299][train][INFO][train.py>_log] ==> #795000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 10.112   Value Loss: 4.551    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 1699906    Buffer Size: 15285      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:52:06,199][train][INFO][train.py>_log] ==> #796000     Total Loss: 2.250    [weighted Loss:2.250    Policy Loss: 9.923    Value Loss: 4.295    Reward Loss: 1.848    Consistency Loss: 0.000    ] Replay Episodes Collected: 1702220    Buffer Size: 15277      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:55:09,436][train][INFO][train.py>_log] ==> #797000     Total Loss: 2.986    [weighted Loss:2.986    Policy Loss: 9.837    Value Loss: 4.471    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 1704516    Buffer Size: 15261      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00080 
[2022-02-20 22:58:12,738][train][INFO][train.py>_log] ==> #798000     Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 9.719    Value Loss: 4.430    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 1706867    Buffer Size: 15266      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00080 
[2022-02-20 23:01:13,062][train][INFO][train.py>_log] ==> #799000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 9.957    Value Loss: 4.339    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1709093    Buffer Size: 15273      Transition Number: 1000.297k Batch Size: 256        Lr: 0.00080 
[2022-02-20 23:04:15,040][train][INFO][train.py>_log] ==> #800000     Total Loss: 2.282    [weighted Loss:2.282    Policy Loss: 9.613    Value Loss: 4.223    Reward Loss: 1.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 1711422    Buffer Size: 15265      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00080 
[2022-02-20 23:07:20,614][train][INFO][train.py>_log] ==> #801000     Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 10.197   Value Loss: 4.347    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1713684    Buffer Size: 15244      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:10:20,917][train][INFO][train.py>_log] ==> #802000     Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 9.769    Value Loss: 4.490    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1715993    Buffer Size: 15225      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:13:24,622][train][INFO][train.py>_log] ==> #803000     Total Loss: 1.803    [weighted Loss:1.803    Policy Loss: 9.578    Value Loss: 4.531    Reward Loss: 1.931    Consistency Loss: 0.000    ] Replay Episodes Collected: 1718304    Buffer Size: 15224      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:16:27,218][train][INFO][train.py>_log] ==> #804000     Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 9.884    Value Loss: 4.296    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 1720606    Buffer Size: 15206      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:19:29,101][train][INFO][train.py>_log] ==> #805000     Total Loss: 2.687    [weighted Loss:2.687    Policy Loss: 9.564    Value Loss: 4.425    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 1722836    Buffer Size: 15204      Transition Number: 1000.650k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:22:31,014][train][INFO][train.py>_log] ==> #806000     Total Loss: 3.139    [weighted Loss:3.139    Policy Loss: 9.404    Value Loss: 4.687    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1725124    Buffer Size: 15165      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:25:35,567][train][INFO][train.py>_log] ==> #807000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 9.557    Value Loss: 4.601    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 1727442    Buffer Size: 15157      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:28:38,443][train][INFO][train.py>_log] ==> #808000     Total Loss: 3.150    [weighted Loss:3.150    Policy Loss: 9.554    Value Loss: 4.380    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1729712    Buffer Size: 15149      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:31:41,304][train][INFO][train.py>_log] ==> #809000     Total Loss: 2.729    [weighted Loss:2.729    Policy Loss: 9.384    Value Loss: 4.627    Reward Loss: 1.826    Consistency Loss: 0.000    ] Replay Episodes Collected: 1731988    Buffer Size: 15147      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:34:41,191][train][INFO][train.py>_log] ==> #810000     Total Loss: 2.962    [weighted Loss:2.962    Policy Loss: 9.228    Value Loss: 4.398    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 1734230    Buffer Size: 15150      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:37:42,100][train][INFO][train.py>_log] ==> #811000     Total Loss: 2.118    [weighted Loss:2.118    Policy Loss: 9.056    Value Loss: 4.625    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 1736448    Buffer Size: 15154      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:40:43,482][train][INFO][train.py>_log] ==> #812000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 9.385    Value Loss: 4.318    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 1738761    Buffer Size: 15140      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:43:46,571][train][INFO][train.py>_log] ==> #813000     Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 9.148    Value Loss: 4.142    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1741079    Buffer Size: 15146      Transition Number: 1000.564k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:46:48,371][train][INFO][train.py>_log] ==> #814000     Total Loss: 2.725    [weighted Loss:2.725    Policy Loss: 9.068    Value Loss: 4.447    Reward Loss: 1.822    Consistency Loss: 0.000    ] Replay Episodes Collected: 1743300    Buffer Size: 15145      Transition Number: 1000.116k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:49:53,323][train][INFO][train.py>_log] ==> #815000     Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 9.365    Value Loss: 4.519    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 1745605    Buffer Size: 15124      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:53:00,181][train][INFO][train.py>_log] ==> #816000     Total Loss: 1.844    [weighted Loss:1.844    Policy Loss: 8.631    Value Loss: 4.550    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 1747965    Buffer Size: 15120      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:56:03,262][train][INFO][train.py>_log] ==> #817000     Total Loss: 2.129    [weighted Loss:2.129    Policy Loss: 8.920    Value Loss: 4.460    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 1750261    Buffer Size: 15118      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00016 
[2022-02-20 23:59:06,063][train][INFO][train.py>_log] ==> #818000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 8.860    Value Loss: 4.461    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 1752570    Buffer Size: 15113      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:02:08,056][train][INFO][train.py>_log] ==> #819000     Total Loss: 2.468    [weighted Loss:2.468    Policy Loss: 8.847    Value Loss: 4.854    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1754827    Buffer Size: 15116      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:05:12,157][train][INFO][train.py>_log] ==> #820000     Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 8.957    Value Loss: 4.895    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1757132    Buffer Size: 15110      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:08:15,134][train][INFO][train.py>_log] ==> #821000     Total Loss: 3.186    [weighted Loss:3.186    Policy Loss: 8.840    Value Loss: 4.935    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 1759395    Buffer Size: 15113      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:11:18,066][train][INFO][train.py>_log] ==> #822000     Total Loss: 1.408    [weighted Loss:1.408    Policy Loss: 8.908    Value Loss: 4.413    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1761665    Buffer Size: 15117      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:14:21,566][train][INFO][train.py>_log] ==> #823000     Total Loss: 3.091    [weighted Loss:3.091    Policy Loss: 9.137    Value Loss: 4.306    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1763902    Buffer Size: 15128      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:17:25,761][train][INFO][train.py>_log] ==> #824000     Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 8.897    Value Loss: 4.911    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1766239    Buffer Size: 15103      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:20:28,360][train][INFO][train.py>_log] ==> #825000     Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 8.904    Value Loss: 4.647    Reward Loss: 1.806    Consistency Loss: 0.000    ] Replay Episodes Collected: 1768545    Buffer Size: 15099      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:23:34,275][train][INFO][train.py>_log] ==> #826000     Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 9.027    Value Loss: 4.687    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 1770865    Buffer Size: 15083      Transition Number: 1000.006k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:26:34,433][train][INFO][train.py>_log] ==> #827000     Total Loss: 2.896    [weighted Loss:2.896    Policy Loss: 9.015    Value Loss: 4.710    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 1773081    Buffer Size: 15084      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:29:40,122][train][INFO][train.py>_log] ==> #828000     Total Loss: 3.746    [weighted Loss:3.746    Policy Loss: 9.093    Value Loss: 4.944    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 1775442    Buffer Size: 15072      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:32:41,867][train][INFO][train.py>_log] ==> #829000     Total Loss: 2.095    [weighted Loss:2.095    Policy Loss: 8.843    Value Loss: 4.286    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1777717    Buffer Size: 15075      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:35:47,439][train][INFO][train.py>_log] ==> #830000     Total Loss: 2.097    [weighted Loss:2.097    Policy Loss: 8.595    Value Loss: 4.671    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 1779991    Buffer Size: 15065      Transition Number: 1000.227k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:38:52,792][train][INFO][train.py>_log] ==> #831000     Total Loss: 2.471    [weighted Loss:2.471    Policy Loss: 8.894    Value Loss: 4.585    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1782358    Buffer Size: 15060      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:41:57,914][train][INFO][train.py>_log] ==> #832000     Total Loss: 3.438    [weighted Loss:3.438    Policy Loss: 8.969    Value Loss: 4.366    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1784647    Buffer Size: 15070      Transition Number: 1000.130k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:45:03,865][train][INFO][train.py>_log] ==> #833000     Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 8.737    Value Loss: 4.531    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1786953    Buffer Size: 15082      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:48:07,911][train][INFO][train.py>_log] ==> #834000     Total Loss: 3.391    [weighted Loss:3.391    Policy Loss: 9.365    Value Loss: 4.282    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 1789249    Buffer Size: 15074      Transition Number: 1000.548k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:51:09,048][train][INFO][train.py>_log] ==> #835000     Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 8.900    Value Loss: 4.617    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1791531    Buffer Size: 15063      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:54:17,149][train][INFO][train.py>_log] ==> #836000     Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 8.850    Value Loss: 4.659    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 1793910    Buffer Size: 15070      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00016 
[2022-02-21 00:57:22,546][train][INFO][train.py>_log] ==> #837000     Total Loss: 3.345    [weighted Loss:3.345    Policy Loss: 9.042    Value Loss: 4.369    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 1796190    Buffer Size: 15067      Transition Number: 1000.255k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:00:30,100][train][INFO][train.py>_log] ==> #838000     Total Loss: 2.859    [weighted Loss:2.859    Policy Loss: 9.236    Value Loss: 4.278    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 1798548    Buffer Size: 15053      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:03:35,170][train][INFO][train.py>_log] ==> #839000     Total Loss: 1.718    [weighted Loss:1.718    Policy Loss: 9.158    Value Loss: 4.429    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 1800846    Buffer Size: 15041      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:06:39,973][train][INFO][train.py>_log] ==> #840000     Total Loss: 1.840    [weighted Loss:1.840    Policy Loss: 9.150    Value Loss: 4.281    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1803146    Buffer Size: 15049      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:09:41,266][train][INFO][train.py>_log] ==> #841000     Total Loss: 1.896    [weighted Loss:1.896    Policy Loss: 9.248    Value Loss: 4.399    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 1805435    Buffer Size: 15038      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:12:47,857][train][INFO][train.py>_log] ==> #842000     Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 8.895    Value Loss: 4.348    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 1807732    Buffer Size: 15042      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:15:56,227][train][INFO][train.py>_log] ==> #843000     Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 8.923    Value Loss: 4.539    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 1810181    Buffer Size: 15046      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:18:58,332][train][INFO][train.py>_log] ==> #844000     Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 8.870    Value Loss: 4.415    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 1812456    Buffer Size: 15052      Transition Number: 1000.261k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:22:01,431][train][INFO][train.py>_log] ==> #845000     Total Loss: 1.809    [weighted Loss:1.809    Policy Loss: 8.480    Value Loss: 4.416    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 1814719    Buffer Size: 15056      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:25:01,782][train][INFO][train.py>_log] ==> #846000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 9.003    Value Loss: 4.517    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1816955    Buffer Size: 15059      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:28:04,410][train][INFO][train.py>_log] ==> #847000     Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 8.670    Value Loss: 4.807    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 1819221    Buffer Size: 15066      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:31:10,953][train][INFO][train.py>_log] ==> #848000     Total Loss: 2.558    [weighted Loss:2.558    Policy Loss: 9.140    Value Loss: 4.686    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 1821525    Buffer Size: 15059      Transition Number: 1000.231k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:34:14,798][train][INFO][train.py>_log] ==> #849000     Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 8.847    Value Loss: 4.400    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 1823828    Buffer Size: 15057      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:37:19,676][train][INFO][train.py>_log] ==> #850000     Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 8.746    Value Loss: 4.672    Reward Loss: 1.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 1826154    Buffer Size: 15069      Transition Number: 1000.263k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:40:21,399][train][INFO][train.py>_log] ==> #851000     Total Loss: 1.962    [weighted Loss:1.962    Policy Loss: 9.038    Value Loss: 4.385    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1828437    Buffer Size: 15063      Transition Number: 1000.598k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:43:24,159][train][INFO][train.py>_log] ==> #852000     Total Loss: 2.563    [weighted Loss:2.563    Policy Loss: 8.749    Value Loss: 4.367    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1830708    Buffer Size: 15049      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:46:24,972][train][INFO][train.py>_log] ==> #853000     Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 8.937    Value Loss: 4.599    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1832923    Buffer Size: 15054      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:49:29,671][train][INFO][train.py>_log] ==> #854000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 8.735    Value Loss: 4.302    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 1835209    Buffer Size: 15041      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:52:32,358][train][INFO][train.py>_log] ==> #855000     Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 8.887    Value Loss: 4.841    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 1837445    Buffer Size: 15044      Transition Number: 1000.089k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:55:35,245][train][INFO][train.py>_log] ==> #856000     Total Loss: 2.770    [weighted Loss:2.770    Policy Loss: 9.036    Value Loss: 4.415    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 1839740    Buffer Size: 15041      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 01:58:40,187][train][INFO][train.py>_log] ==> #857000     Total Loss: 0.812    [weighted Loss:0.812    Policy Loss: 8.821    Value Loss: 4.549    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 1842048    Buffer Size: 15034      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:01:41,835][train][INFO][train.py>_log] ==> #858000     Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 9.035    Value Loss: 4.774    Reward Loss: 1.832    Consistency Loss: 0.000    ] Replay Episodes Collected: 1844333    Buffer Size: 15041      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:04:47,081][train][INFO][train.py>_log] ==> #859000     Total Loss: 3.735    [weighted Loss:3.735    Policy Loss: 8.829    Value Loss: 4.829    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 1846645    Buffer Size: 15044      Transition Number: 1000.323k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:07:53,691][train][INFO][train.py>_log] ==> #860000     Total Loss: 3.332    [weighted Loss:3.332    Policy Loss: 9.370    Value Loss: 4.661    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 1848939    Buffer Size: 15036      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:10:56,643][train][INFO][train.py>_log] ==> #861000     Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 9.181    Value Loss: 4.565    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1851265    Buffer Size: 15035      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:14:00,427][train][INFO][train.py>_log] ==> #862000     Total Loss: 3.089    [weighted Loss:3.089    Policy Loss: 8.867    Value Loss: 4.599    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 1853548    Buffer Size: 15037      Transition Number: 1000.152k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:17:07,551][train][INFO][train.py>_log] ==> #863000     Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 9.215    Value Loss: 5.166    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 1855886    Buffer Size: 15027      Transition Number: 1000.269k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:20:13,264][train][INFO][train.py>_log] ==> #864000     Total Loss: 1.277    [weighted Loss:1.277    Policy Loss: 9.100    Value Loss: 4.457    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 1858229    Buffer Size: 15010      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:23:18,267][train][INFO][train.py>_log] ==> #865000     Total Loss: 2.752    [weighted Loss:2.752    Policy Loss: 8.874    Value Loss: 4.539    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 1860520    Buffer Size: 15016      Transition Number: 1000.244k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:26:24,243][train][INFO][train.py>_log] ==> #866000     Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 8.937    Value Loss: 4.286    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 1862830    Buffer Size: 15020      Transition Number: 1000.234k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:29:27,226][train][INFO][train.py>_log] ==> #867000     Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 9.114    Value Loss: 4.654    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 1865139    Buffer Size: 15017      Transition Number: 1000.120k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:32:31,470][train][INFO][train.py>_log] ==> #868000     Total Loss: 3.280    [weighted Loss:3.280    Policy Loss: 9.433    Value Loss: 4.503    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 1867415    Buffer Size: 14991      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:35:35,133][train][INFO][train.py>_log] ==> #869000     Total Loss: 2.606    [weighted Loss:2.606    Policy Loss: 8.507    Value Loss: 4.731    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 1869709    Buffer Size: 14992      Transition Number: 1000.557k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:38:38,853][train][INFO][train.py>_log] ==> #870000     Total Loss: 1.801    [weighted Loss:1.801    Policy Loss: 9.178    Value Loss: 4.456    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 1872063    Buffer Size: 14965      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:41:41,125][train][INFO][train.py>_log] ==> #871000     Total Loss: 2.232    [weighted Loss:2.232    Policy Loss: 9.412    Value Loss: 4.385    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 1874320    Buffer Size: 14959      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:44:46,706][train][INFO][train.py>_log] ==> #872000     Total Loss: 3.593    [weighted Loss:3.593    Policy Loss: 8.815    Value Loss: 4.433    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 1876638    Buffer Size: 14943      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:47:51,684][train][INFO][train.py>_log] ==> #873000     Total Loss: 2.841    [weighted Loss:2.841    Policy Loss: 8.847    Value Loss: 4.442    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 1878933    Buffer Size: 14946      Transition Number: 1000.329k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:50:53,189][train][INFO][train.py>_log] ==> #874000     Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 9.057    Value Loss: 4.573    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 1881248    Buffer Size: 14951      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:54:01,266][train][INFO][train.py>_log] ==> #875000     Total Loss: 3.519    [weighted Loss:3.519    Policy Loss: 9.281    Value Loss: 4.841    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 1883584    Buffer Size: 14958      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 02:57:05,289][train][INFO][train.py>_log] ==> #876000     Total Loss: 3.113    [weighted Loss:3.113    Policy Loss: 8.711    Value Loss: 4.388    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1885907    Buffer Size: 14974      Transition Number: 1000.276k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:00:08,993][train][INFO][train.py>_log] ==> #877000     Total Loss: 2.809    [weighted Loss:2.809    Policy Loss: 8.900    Value Loss: 5.120    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 1888156    Buffer Size: 14971      Transition Number: 1000.153k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:03:14,303][train][INFO][train.py>_log] ==> #878000     Total Loss: 3.639    [weighted Loss:3.639    Policy Loss: 9.171    Value Loss: 4.415    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 1890526    Buffer Size: 14970      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:06:20,349][train][INFO][train.py>_log] ==> #879000     Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 8.770    Value Loss: 4.450    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 1892858    Buffer Size: 14964      Transition Number: 1000.323k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:09:30,360][train][INFO][train.py>_log] ==> #880000     Total Loss: 3.342    [weighted Loss:3.342    Policy Loss: 9.205    Value Loss: 4.539    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 1895277    Buffer Size: 14963      Transition Number: 1000.272k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:12:33,850][train][INFO][train.py>_log] ==> #881000     Total Loss: 2.325    [weighted Loss:2.325    Policy Loss: 8.781    Value Loss: 4.513    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 1897608    Buffer Size: 14948      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:15:41,438][train][INFO][train.py>_log] ==> #882000     Total Loss: 1.860    [weighted Loss:1.860    Policy Loss: 8.466    Value Loss: 4.899    Reward Loss: 1.761    Consistency Loss: 0.000    ] Replay Episodes Collected: 1899945    Buffer Size: 14943      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:18:44,598][train][INFO][train.py>_log] ==> #883000     Total Loss: 3.795    [weighted Loss:3.795    Policy Loss: 9.207    Value Loss: 4.758    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1902185    Buffer Size: 14954      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:21:51,819][train][INFO][train.py>_log] ==> #884000     Total Loss: 3.164    [weighted Loss:3.164    Policy Loss: 9.012    Value Loss: 4.572    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 1904551    Buffer Size: 14955      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:24:57,260][train][INFO][train.py>_log] ==> #885000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 9.124    Value Loss: 4.607    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 1906842    Buffer Size: 14970      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:28:03,453][train][INFO][train.py>_log] ==> #886000     Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 9.217    Value Loss: 4.542    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 1909208    Buffer Size: 14968      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:31:08,302][train][INFO][train.py>_log] ==> #887000     Total Loss: 2.755    [weighted Loss:2.755    Policy Loss: 8.812    Value Loss: 4.316    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 1911498    Buffer Size: 14968      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:34:15,940][train][INFO][train.py>_log] ==> #888000     Total Loss: 2.609    [weighted Loss:2.609    Policy Loss: 8.981    Value Loss: 4.320    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 1913831    Buffer Size: 14975      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:37:21,146][train][INFO][train.py>_log] ==> #889000     Total Loss: 3.521    [weighted Loss:3.521    Policy Loss: 8.837    Value Loss: 4.339    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 1916145    Buffer Size: 14978      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:40:24,934][train][INFO][train.py>_log] ==> #890000     Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 8.993    Value Loss: 4.088    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 1918458    Buffer Size: 14981      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:43:31,725][train][INFO][train.py>_log] ==> #891000     Total Loss: 2.865    [weighted Loss:2.865    Policy Loss: 8.798    Value Loss: 4.531    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 1920811    Buffer Size: 14980      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:46:36,420][train][INFO][train.py>_log] ==> #892000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 8.624    Value Loss: 4.358    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 1923117    Buffer Size: 14980      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:49:40,778][train][INFO][train.py>_log] ==> #893000     Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 9.188    Value Loss: 4.675    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 1925392    Buffer Size: 14974      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:52:45,825][train][INFO][train.py>_log] ==> #894000     Total Loss: 2.540    [weighted Loss:2.540    Policy Loss: 9.288    Value Loss: 4.327    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 1927757    Buffer Size: 14968      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:55:53,072][train][INFO][train.py>_log] ==> #895000     Total Loss: 3.071    [weighted Loss:3.071    Policy Loss: 8.940    Value Loss: 4.829    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 1930114    Buffer Size: 14965      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00016 
[2022-02-21 03:59:02,153][train][INFO][train.py>_log] ==> #896000     Total Loss: 3.502    [weighted Loss:3.502    Policy Loss: 9.448    Value Loss: 4.693    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 1932539    Buffer Size: 14970      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:02:08,397][train][INFO][train.py>_log] ==> #897000     Total Loss: 1.691    [weighted Loss:1.691    Policy Loss: 8.884    Value Loss: 4.716    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 1934858    Buffer Size: 14976      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:05:13,195][train][INFO][train.py>_log] ==> #898000     Total Loss: 2.645    [weighted Loss:2.645    Policy Loss: 8.966    Value Loss: 4.377    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 1937148    Buffer Size: 14979      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:08:20,006][train][INFO][train.py>_log] ==> #899000     Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 8.968    Value Loss: 4.549    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 1939476    Buffer Size: 14981      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:11:24,334][train][INFO][train.py>_log] ==> #900000     Total Loss: 3.225    [weighted Loss:3.225    Policy Loss: 8.695    Value Loss: 4.806    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 1941783    Buffer Size: 14988      Transition Number: 1000.399k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:14:28,903][train][INFO][train.py>_log] ==> #901000     Total Loss: 2.498    [weighted Loss:2.498    Policy Loss: 8.735    Value Loss: 4.286    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1944057    Buffer Size: 14973      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:17:38,773][train][INFO][train.py>_log] ==> #902000     Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 9.183    Value Loss: 4.570    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 1946484    Buffer Size: 14956      Transition Number: 1000.270k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:20:45,234][train][INFO][train.py>_log] ==> #903000     Total Loss: 1.816    [weighted Loss:1.816    Policy Loss: 9.027    Value Loss: 4.719    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 1948834    Buffer Size: 14953      Transition Number: 1000.220k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:23:55,414][train][INFO][train.py>_log] ==> #904000     Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 8.844    Value Loss: 4.512    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 1951196    Buffer Size: 14942      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:27:01,774][train][INFO][train.py>_log] ==> #905000     Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 8.878    Value Loss: 4.353    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 1953508    Buffer Size: 14917      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:30:07,803][train][INFO][train.py>_log] ==> #906000     Total Loss: 2.828    [weighted Loss:2.828    Policy Loss: 8.690    Value Loss: 4.613    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 1955839    Buffer Size: 14901      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:33:12,450][train][INFO][train.py>_log] ==> #907000     Total Loss: 1.416    [weighted Loss:1.416    Policy Loss: 8.535    Value Loss: 5.023    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1958094    Buffer Size: 14917      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:36:16,805][train][INFO][train.py>_log] ==> #908000     Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 9.016    Value Loss: 4.752    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 1960454    Buffer Size: 14937      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:39:22,879][train][INFO][train.py>_log] ==> #909000     Total Loss: 2.589    [weighted Loss:2.589    Policy Loss: 8.737    Value Loss: 4.336    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 1962706    Buffer Size: 14941      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:42:30,505][train][INFO][train.py>_log] ==> #910000     Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 8.655    Value Loss: 4.659    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 1965067    Buffer Size: 14931      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:45:36,661][train][INFO][train.py>_log] ==> #911000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 8.856    Value Loss: 4.252    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 1967508    Buffer Size: 14935      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:48:42,144][train][INFO][train.py>_log] ==> #912000     Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 9.140    Value Loss: 4.558    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 1969789    Buffer Size: 14951      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:51:47,652][train][INFO][train.py>_log] ==> #913000     Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 8.459    Value Loss: 4.689    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 1972095    Buffer Size: 14965      Transition Number: 1000.555k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:54:52,551][train][INFO][train.py>_log] ==> #914000     Total Loss: 1.697    [weighted Loss:1.697    Policy Loss: 9.197    Value Loss: 4.591    Reward Loss: 1.847    Consistency Loss: 0.000    ] Replay Episodes Collected: 1974386    Buffer Size: 14948      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00016 
[2022-02-21 04:57:57,787][train][INFO][train.py>_log] ==> #915000     Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 8.685    Value Loss: 4.558    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 1976699    Buffer Size: 14952      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:01:03,163][train][INFO][train.py>_log] ==> #916000     Total Loss: 2.505    [weighted Loss:2.505    Policy Loss: 8.651    Value Loss: 4.328    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 1979049    Buffer Size: 14953      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:04:12,519][train][INFO][train.py>_log] ==> #917000     Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 8.511    Value Loss: 4.353    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 1981455    Buffer Size: 14949      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:07:19,122][train][INFO][train.py>_log] ==> #918000     Total Loss: 2.787    [weighted Loss:2.787    Policy Loss: 8.746    Value Loss: 4.796    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 1983768    Buffer Size: 14956      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:10:26,173][train][INFO][train.py>_log] ==> #919000     Total Loss: 3.077    [weighted Loss:3.077    Policy Loss: 8.967    Value Loss: 4.612    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 1986071    Buffer Size: 14970      Transition Number: 1000.462k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:13:36,009][train][INFO][train.py>_log] ==> #920000     Total Loss: 1.869    [weighted Loss:1.869    Policy Loss: 8.812    Value Loss: 4.441    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 1988403    Buffer Size: 14964      Transition Number: 1000.120k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:16:44,502][train][INFO][train.py>_log] ==> #921000     Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 8.866    Value Loss: 4.763    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 1990810    Buffer Size: 14967      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:19:49,991][train][INFO][train.py>_log] ==> #922000     Total Loss: 2.464    [weighted Loss:2.464    Policy Loss: 8.833    Value Loss: 4.333    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 1993129    Buffer Size: 14952      Transition Number: 1000.277k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:22:57,862][train][INFO][train.py>_log] ==> #923000     Total Loss: 2.592    [weighted Loss:2.592    Policy Loss: 8.666    Value Loss: 4.528    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 1995456    Buffer Size: 14971      Transition Number: 1000.415k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:25:58,496][train][INFO][train.py>_log] ==> #924000     Total Loss: 2.028    [weighted Loss:2.028    Policy Loss: 9.210    Value Loss: 4.330    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 1997744    Buffer Size: 14958      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:29:04,424][train][INFO][train.py>_log] ==> #925000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 9.261    Value Loss: 4.441    Reward Loss: 1.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 2000082    Buffer Size: 14970      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:32:11,233][train][INFO][train.py>_log] ==> #926000     Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 9.142    Value Loss: 4.669    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2002409    Buffer Size: 14983      Transition Number: 1001.143k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:35:18,291][train][INFO][train.py>_log] ==> #927000     Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 8.669    Value Loss: 4.409    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2004743    Buffer Size: 14984      Transition Number: 1000.349k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:38:28,245][train][INFO][train.py>_log] ==> #928000     Total Loss: 3.697    [weighted Loss:3.697    Policy Loss: 8.987    Value Loss: 4.544    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 2007135    Buffer Size: 15003      Transition Number: 1000.431k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:41:38,650][train][INFO][train.py>_log] ==> #929000     Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 8.675    Value Loss: 4.523    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 2009510    Buffer Size: 15001      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:44:44,342][train][INFO][train.py>_log] ==> #930000     Total Loss: 2.657    [weighted Loss:2.657    Policy Loss: 9.032    Value Loss: 4.427    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2011848    Buffer Size: 14986      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:47:47,268][train][INFO][train.py>_log] ==> #931000     Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 8.956    Value Loss: 4.556    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2014207    Buffer Size: 14998      Transition Number: 1000.480k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:50:59,317][train][INFO][train.py>_log] ==> #932000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 8.877    Value Loss: 4.578    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2016660    Buffer Size: 14995      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:54:04,082][train][INFO][train.py>_log] ==> #933000     Total Loss: 2.366    [weighted Loss:2.366    Policy Loss: 8.953    Value Loss: 4.628    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 2018967    Buffer Size: 15009      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 05:57:11,909][train][INFO][train.py>_log] ==> #934000     Total Loss: 2.507    [weighted Loss:2.507    Policy Loss: 8.810    Value Loss: 4.164    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2021267    Buffer Size: 14995      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:00:21,969][train][INFO][train.py>_log] ==> #935000     Total Loss: 1.190    [weighted Loss:1.190    Policy Loss: 9.229    Value Loss: 4.750    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 2023653    Buffer Size: 14991      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:03:29,843][train][INFO][train.py>_log] ==> #936000     Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 9.324    Value Loss: 4.686    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2025943    Buffer Size: 15010      Transition Number: 1000.250k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:06:37,861][train][INFO][train.py>_log] ==> #937000     Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 9.285    Value Loss: 4.853    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2028319    Buffer Size: 15031      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:09:47,850][train][INFO][train.py>_log] ==> #938000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 9.074    Value Loss: 4.359    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 2030748    Buffer Size: 15031      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:12:55,044][train][INFO][train.py>_log] ==> #939000     Total Loss: 2.064    [weighted Loss:2.064    Policy Loss: 9.002    Value Loss: 4.597    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 2033042    Buffer Size: 15031      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:16:02,741][train][INFO][train.py>_log] ==> #940000     Total Loss: 2.263    [weighted Loss:2.263    Policy Loss: 9.369    Value Loss: 4.550    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 2035423    Buffer Size: 15042      Transition Number: 1000.267k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:19:11,638][train][INFO][train.py>_log] ==> #941000     Total Loss: 1.257    [weighted Loss:1.257    Policy Loss: 8.879    Value Loss: 4.715    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 2037802    Buffer Size: 15051      Transition Number: 1000.351k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:22:17,219][train][INFO][train.py>_log] ==> #942000     Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 9.663    Value Loss: 4.466    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2040199    Buffer Size: 15064      Transition Number: 1000.150k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:25:26,453][train][INFO][train.py>_log] ==> #943000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 9.376    Value Loss: 4.541    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2042561    Buffer Size: 15058      Transition Number: 1000.413k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:28:33,393][train][INFO][train.py>_log] ==> #944000     Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 9.374    Value Loss: 4.706    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 2044907    Buffer Size: 15049      Transition Number: 1000.443k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:31:38,876][train][INFO][train.py>_log] ==> #945000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 9.161    Value Loss: 4.643    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 2047243    Buffer Size: 15048      Transition Number: 1000.224k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:34:48,302][train][INFO][train.py>_log] ==> #946000     Total Loss: 1.659    [weighted Loss:1.659    Policy Loss: 9.229    Value Loss: 4.562    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 2049634    Buffer Size: 15041      Transition Number: 1000.148k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:37:56,673][train][INFO][train.py>_log] ==> #947000     Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 9.142    Value Loss: 4.599    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2051979    Buffer Size: 15032      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:41:05,431][train][INFO][train.py>_log] ==> #948000     Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 9.299    Value Loss: 4.509    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 2054316    Buffer Size: 15016      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:44:11,937][train][INFO][train.py>_log] ==> #949000     Total Loss: 2.476    [weighted Loss:2.476    Policy Loss: 9.109    Value Loss: 4.481    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 2056695    Buffer Size: 15018      Transition Number: 1000.245k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:47:21,921][train][INFO][train.py>_log] ==> #950000     Total Loss: 2.354    [weighted Loss:2.354    Policy Loss: 9.117    Value Loss: 4.476    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2059058    Buffer Size: 15010      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:50:30,743][train][INFO][train.py>_log] ==> #951000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 8.958    Value Loss: 4.624    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 2061468    Buffer Size: 15016      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:53:41,546][train][INFO][train.py>_log] ==> #952000     Total Loss: 3.046    [weighted Loss:3.046    Policy Loss: 8.835    Value Loss: 4.368    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2063841    Buffer Size: 15011      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:56:50,130][train][INFO][train.py>_log] ==> #953000     Total Loss: 2.829    [weighted Loss:2.829    Policy Loss: 9.742    Value Loss: 4.266    Reward Loss: 1.812    Consistency Loss: 0.000    ] Replay Episodes Collected: 2066269    Buffer Size: 15016      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 06:59:55,298][train][INFO][train.py>_log] ==> #954000     Total Loss: 1.802    [weighted Loss:1.802    Policy Loss: 9.295    Value Loss: 4.593    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2068588    Buffer Size: 15011      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:03:02,733][train][INFO][train.py>_log] ==> #955000     Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 9.084    Value Loss: 4.288    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2070945    Buffer Size: 15013      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:06:12,088][train][INFO][train.py>_log] ==> #956000     Total Loss: 1.540    [weighted Loss:1.540    Policy Loss: 9.657    Value Loss: 4.454    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 2073275    Buffer Size: 15023      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:09:17,599][train][INFO][train.py>_log] ==> #957000     Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 9.318    Value Loss: 4.840    Reward Loss: 1.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 2075626    Buffer Size: 15023      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:12:26,063][train][INFO][train.py>_log] ==> #958000     Total Loss: 2.850    [weighted Loss:2.850    Policy Loss: 9.476    Value Loss: 4.549    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 2077914    Buffer Size: 15031      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:15:32,359][train][INFO][train.py>_log] ==> #959000     Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 9.234    Value Loss: 4.519    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 2080347    Buffer Size: 15036      Transition Number: 1000.316k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:18:37,664][train][INFO][train.py>_log] ==> #960000     Total Loss: 2.474    [weighted Loss:2.474    Policy Loss: 9.300    Value Loss: 4.500    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2082684    Buffer Size: 15052      Transition Number: 1000.455k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:21:45,004][train][INFO][train.py>_log] ==> #961000     Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 9.299    Value Loss: 4.185    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2085069    Buffer Size: 15049      Transition Number: 1000.325k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:24:52,717][train][INFO][train.py>_log] ==> #962000     Total Loss: 3.001    [weighted Loss:3.001    Policy Loss: 9.260    Value Loss: 4.172    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2087409    Buffer Size: 15033      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:28:01,015][train][INFO][train.py>_log] ==> #963000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 9.463    Value Loss: 4.539    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 2089767    Buffer Size: 15042      Transition Number: 1000.247k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:31:11,636][train][INFO][train.py>_log] ==> #964000     Total Loss: 2.796    [weighted Loss:2.796    Policy Loss: 9.374    Value Loss: 4.232    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2092157    Buffer Size: 15042      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:34:17,989][train][INFO][train.py>_log] ==> #965000     Total Loss: 3.720    [weighted Loss:3.720    Policy Loss: 9.268    Value Loss: 4.371    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2094533    Buffer Size: 15034      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:37:27,752][train][INFO][train.py>_log] ==> #966000     Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 9.189    Value Loss: 4.413    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 2096865    Buffer Size: 15044      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:40:34,363][train][INFO][train.py>_log] ==> #967000     Total Loss: 3.166    [weighted Loss:3.166    Policy Loss: 9.176    Value Loss: 4.590    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 2099145    Buffer Size: 15044      Transition Number: 1000.156k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:43:41,956][train][INFO][train.py>_log] ==> #968000     Total Loss: 2.873    [weighted Loss:2.873    Policy Loss: 9.732    Value Loss: 4.492    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2101578    Buffer Size: 15031      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:46:46,529][train][INFO][train.py>_log] ==> #969000     Total Loss: 2.084    [weighted Loss:2.084    Policy Loss: 9.169    Value Loss: 4.451    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 2103842    Buffer Size: 15036      Transition Number: 1000.390k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:49:55,205][train][INFO][train.py>_log] ==> #970000     Total Loss: 2.090    [weighted Loss:2.090    Policy Loss: 9.269    Value Loss: 4.849    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 2106239    Buffer Size: 15018      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:53:03,261][train][INFO][train.py>_log] ==> #971000     Total Loss: 2.839    [weighted Loss:2.839    Policy Loss: 9.124    Value Loss: 4.580    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 2108590    Buffer Size: 15012      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:56:11,489][train][INFO][train.py>_log] ==> #972000     Total Loss: 2.109    [weighted Loss:2.109    Policy Loss: 9.393    Value Loss: 4.239    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 2111007    Buffer Size: 15006      Transition Number: 1000.577k Batch Size: 256        Lr: 0.00016 
[2022-02-21 07:59:20,877][train][INFO][train.py>_log] ==> #973000     Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 9.084    Value Loss: 4.420    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 2113396    Buffer Size: 14996      Transition Number: 1000.283k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:02:27,686][train][INFO][train.py>_log] ==> #974000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 9.426    Value Loss: 4.573    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 2115749    Buffer Size: 14987      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:05:37,363][train][INFO][train.py>_log] ==> #975000     Total Loss: 2.887    [weighted Loss:2.887    Policy Loss: 9.283    Value Loss: 4.283    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2118112    Buffer Size: 14987      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:08:45,567][train][INFO][train.py>_log] ==> #976000     Total Loss: 2.633    [weighted Loss:2.633    Policy Loss: 9.404    Value Loss: 4.571    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 2120503    Buffer Size: 14972      Transition Number: 1000.138k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:11:53,025][train][INFO][train.py>_log] ==> #977000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 9.028    Value Loss: 4.315    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 2122841    Buffer Size: 14965      Transition Number: 1000.308k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:14:55,893][train][INFO][train.py>_log] ==> #978000     Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 8.911    Value Loss: 4.600    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 2125178    Buffer Size: 14945      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:18:02,581][train][INFO][train.py>_log] ==> #979000     Total Loss: 1.464    [weighted Loss:1.464    Policy Loss: 9.182    Value Loss: 4.594    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2127492    Buffer Size: 14950      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:21:13,512][train][INFO][train.py>_log] ==> #980000     Total Loss: 2.328    [weighted Loss:2.328    Policy Loss: 9.445    Value Loss: 5.219    Reward Loss: 1.798    Consistency Loss: 0.000    ] Replay Episodes Collected: 2129833    Buffer Size: 14941      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:24:22,009][train][INFO][train.py>_log] ==> #981000     Total Loss: 2.459    [weighted Loss:2.459    Policy Loss: 9.218    Value Loss: 4.975    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 2132247    Buffer Size: 14932      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:27:30,469][train][INFO][train.py>_log] ==> #982000     Total Loss: 2.847    [weighted Loss:2.847    Policy Loss: 9.026    Value Loss: 4.556    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 2134609    Buffer Size: 14937      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:30:39,470][train][INFO][train.py>_log] ==> #983000     Total Loss: 2.692    [weighted Loss:2.692    Policy Loss: 8.848    Value Loss: 4.318    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2137005    Buffer Size: 14929      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:33:51,686][train][INFO][train.py>_log] ==> #984000     Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 9.079    Value Loss: 4.615    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 2139400    Buffer Size: 14930      Transition Number: 1000.225k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:36:57,014][train][INFO][train.py>_log] ==> #985000     Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 9.226    Value Loss: 4.197    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 2141731    Buffer Size: 14922      Transition Number: 1000.339k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:40:06,978][train][INFO][train.py>_log] ==> #986000     Total Loss: 2.981    [weighted Loss:2.981    Policy Loss: 9.317    Value Loss: 4.645    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 2144110    Buffer Size: 14932      Transition Number: 1000.763k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:43:14,579][train][INFO][train.py>_log] ==> #987000     Total Loss: 2.533    [weighted Loss:2.533    Policy Loss: 9.176    Value Loss: 4.549    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 2146509    Buffer Size: 14915      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:46:21,905][train][INFO][train.py>_log] ==> #988000     Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 9.650    Value Loss: 4.496    Reward Loss: 1.853    Consistency Loss: 0.000    ] Replay Episodes Collected: 2148841    Buffer Size: 14918      Transition Number: 1000.317k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:49:28,272][train][INFO][train.py>_log] ==> #989000     Total Loss: 1.456    [weighted Loss:1.456    Policy Loss: 9.283    Value Loss: 4.324    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 2151169    Buffer Size: 14906      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:52:35,902][train][INFO][train.py>_log] ==> #990000     Total Loss: 3.290    [weighted Loss:3.290    Policy Loss: 9.641    Value Loss: 4.508    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 2153548    Buffer Size: 14915      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:55:45,196][train][INFO][train.py>_log] ==> #991000     Total Loss: 2.699    [weighted Loss:2.699    Policy Loss: 8.970    Value Loss: 4.529    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 2155982    Buffer Size: 14927      Transition Number: 1000.377k Batch Size: 256        Lr: 0.00016 
[2022-02-21 08:58:53,227][train][INFO][train.py>_log] ==> #992000     Total Loss: 1.078    [weighted Loss:1.078    Policy Loss: 8.998    Value Loss: 4.226    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 2158303    Buffer Size: 14934      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:01:58,161][train][INFO][train.py>_log] ==> #993000     Total Loss: 1.955    [weighted Loss:1.955    Policy Loss: 9.191    Value Loss: 4.785    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 2160643    Buffer Size: 14935      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:05:06,949][train][INFO][train.py>_log] ==> #994000     Total Loss: 2.601    [weighted Loss:2.601    Policy Loss: 9.245    Value Loss: 4.459    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 2163009    Buffer Size: 14950      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:08:14,056][train][INFO][train.py>_log] ==> #995000     Total Loss: 2.446    [weighted Loss:2.446    Policy Loss: 9.293    Value Loss: 4.441    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 2165335    Buffer Size: 14979      Transition Number: 1000.236k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:11:22,075][train][INFO][train.py>_log] ==> #996000     Total Loss: 0.786    [weighted Loss:0.786    Policy Loss: 9.029    Value Loss: 4.711    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 2167737    Buffer Size: 15002      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:14:30,195][train][INFO][train.py>_log] ==> #997000     Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 9.671    Value Loss: 4.566    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 2170092    Buffer Size: 14996      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:17:37,857][train][INFO][train.py>_log] ==> #998000     Total Loss: 1.994    [weighted Loss:1.994    Policy Loss: 9.303    Value Loss: 4.578    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 2172498    Buffer Size: 15007      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:20:43,999][train][INFO][train.py>_log] ==> #999000     Total Loss: 1.849    [weighted Loss:1.849    Policy Loss: 9.340    Value Loss: 4.480    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 2174848    Buffer Size: 14993      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:24:02,396][train][INFO][train.py>_log] ==> #1000000    Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 9.206    Value Loss: 4.257    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2177166    Buffer Size: 14979      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00016 
[2022-02-21 09:27:11,663][train][INFO][train.py>_log] ==> #1001000    Total Loss: 3.123    [weighted Loss:3.123    Policy Loss: 8.967    Value Loss: 4.666    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2179670    Buffer Size: 14982      Transition Number: 1000.200k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:30:19,218][train][INFO][train.py>_log] ==> #1002000    Total Loss: 2.160    [weighted Loss:2.160    Policy Loss: 9.574    Value Loss: 5.009    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 2181977    Buffer Size: 14968      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:33:29,757][train][INFO][train.py>_log] ==> #1003000    Total Loss: 2.055    [weighted Loss:2.055    Policy Loss: 9.060    Value Loss: 4.260    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 2184473    Buffer Size: 14957      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:36:38,089][train][INFO][train.py>_log] ==> #1004000    Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 9.327    Value Loss: 4.779    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2186850    Buffer Size: 14963      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:39:47,505][train][INFO][train.py>_log] ==> #1005000    Total Loss: 1.907    [weighted Loss:1.907    Policy Loss: 9.108    Value Loss: 4.890    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2189214    Buffer Size: 14959      Transition Number: 1000.344k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:42:54,337][train][INFO][train.py>_log] ==> #1006000    Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 9.298    Value Loss: 4.459    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 2191496    Buffer Size: 14950      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:46:03,918][train][INFO][train.py>_log] ==> #1007000    Total Loss: 1.608    [weighted Loss:1.608    Policy Loss: 9.087    Value Loss: 4.690    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 2193928    Buffer Size: 14951      Transition Number: 1000.155k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:49:13,420][train][INFO][train.py>_log] ==> #1008000    Total Loss: 2.349    [weighted Loss:2.349    Policy Loss: 9.237    Value Loss: 4.842    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 2196339    Buffer Size: 14912      Transition Number: 1000.117k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:52:20,994][train][INFO][train.py>_log] ==> #1009000    Total Loss: 1.582    [weighted Loss:1.582    Policy Loss: 9.533    Value Loss: 4.598    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 2198714    Buffer Size: 14899      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:55:26,233][train][INFO][train.py>_log] ==> #1010000    Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 9.214    Value Loss: 4.250    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2201025    Buffer Size: 14896      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00010 
[2022-02-21 09:58:30,979][train][INFO][train.py>_log] ==> #1011000    Total Loss: 2.960    [weighted Loss:2.960    Policy Loss: 9.411    Value Loss: 4.548    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 2203393    Buffer Size: 14887      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:01:39,735][train][INFO][train.py>_log] ==> #1012000    Total Loss: 3.405    [weighted Loss:3.405    Policy Loss: 9.563    Value Loss: 4.250    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2205748    Buffer Size: 14890      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:04:48,170][train][INFO][train.py>_log] ==> #1013000    Total Loss: 2.182    [weighted Loss:2.182    Policy Loss: 9.229    Value Loss: 4.502    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 2208063    Buffer Size: 14905      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:07:55,384][train][INFO][train.py>_log] ==> #1014000    Total Loss: 2.065    [weighted Loss:2.065    Policy Loss: 9.312    Value Loss: 4.891    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2210455    Buffer Size: 14919      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:11:03,070][train][INFO][train.py>_log] ==> #1015000    Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 8.969    Value Loss: 4.856    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2212837    Buffer Size: 14933      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:14:09,652][train][INFO][train.py>_log] ==> #1016000    Total Loss: 2.676    [weighted Loss:2.676    Policy Loss: 9.361    Value Loss: 4.590    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2215180    Buffer Size: 14935      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:17:14,726][train][INFO][train.py>_log] ==> #1017000    Total Loss: 2.188    [weighted Loss:2.188    Policy Loss: 9.504    Value Loss: 4.568    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2217514    Buffer Size: 14932      Transition Number: 1000.402k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:20:22,217][train][INFO][train.py>_log] ==> #1018000    Total Loss: 2.602    [weighted Loss:2.602    Policy Loss: 9.149    Value Loss: 5.011    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 2219809    Buffer Size: 14934      Transition Number: 1000.239k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:23:29,167][train][INFO][train.py>_log] ==> #1019000    Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 9.282    Value Loss: 4.275    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2222157    Buffer Size: 14931      Transition Number: 1000.835k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:26:38,651][train][INFO][train.py>_log] ==> #1020000    Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 9.490    Value Loss: 4.687    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 2224508    Buffer Size: 14918      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:29:45,812][train][INFO][train.py>_log] ==> #1021000    Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 9.107    Value Loss: 4.473    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2226874    Buffer Size: 14917      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:32:52,302][train][INFO][train.py>_log] ==> #1022000    Total Loss: 1.367    [weighted Loss:1.367    Policy Loss: 9.703    Value Loss: 4.367    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2229221    Buffer Size: 14926      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:36:00,254][train][INFO][train.py>_log] ==> #1023000    Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 9.974    Value Loss: 4.523    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2231513    Buffer Size: 14922      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:39:09,970][train][INFO][train.py>_log] ==> #1024000    Total Loss: 3.173    [weighted Loss:3.173    Policy Loss: 9.669    Value Loss: 4.467    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2233984    Buffer Size: 14928      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:42:20,410][train][INFO][train.py>_log] ==> #1025000    Total Loss: 2.719    [weighted Loss:2.719    Policy Loss: 9.499    Value Loss: 4.732    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2236433    Buffer Size: 14937      Transition Number: 1000.194k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:45:30,593][train][INFO][train.py>_log] ==> #1026000    Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 9.302    Value Loss: 4.737    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 2238840    Buffer Size: 14938      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:48:38,537][train][INFO][train.py>_log] ==> #1027000    Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 9.507    Value Loss: 4.356    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 2241130    Buffer Size: 14945      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:51:47,084][train][INFO][train.py>_log] ==> #1028000    Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 9.354    Value Loss: 4.548    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 2243500    Buffer Size: 14951      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:54:55,430][train][INFO][train.py>_log] ==> #1029000    Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 9.396    Value Loss: 4.726    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 2245922    Buffer Size: 14953      Transition Number: 1000.302k Batch Size: 256        Lr: 0.00010 
[2022-02-21 10:58:04,611][train][INFO][train.py>_log] ==> #1030000    Total Loss: 0.579    [weighted Loss:0.579    Policy Loss: 9.474    Value Loss: 4.624    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2248348    Buffer Size: 14961      Transition Number: 1000.251k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:01:13,673][train][INFO][train.py>_log] ==> #1031000    Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 9.328    Value Loss: 4.695    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2250739    Buffer Size: 14961      Transition Number: 999.931 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:04:23,402][train][INFO][train.py>_log] ==> #1032000    Total Loss: 2.233    [weighted Loss:2.233    Policy Loss: 9.541    Value Loss: 4.601    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2253079    Buffer Size: 14976      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:07:31,501][train][INFO][train.py>_log] ==> #1033000    Total Loss: 1.042    [weighted Loss:1.042    Policy Loss: 9.364    Value Loss: 4.516    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2255368    Buffer Size: 14980      Transition Number: 1000.285k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:10:40,061][train][INFO][train.py>_log] ==> #1034000    Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 9.909    Value Loss: 4.428    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 2257781    Buffer Size: 14981      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:13:46,998][train][INFO][train.py>_log] ==> #1035000    Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 9.760    Value Loss: 4.899    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2260136    Buffer Size: 14979      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:16:55,258][train][INFO][train.py>_log] ==> #1036000    Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 9.742    Value Loss: 4.357    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2262440    Buffer Size: 14984      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:20:04,193][train][INFO][train.py>_log] ==> #1037000    Total Loss: 3.500    [weighted Loss:3.500    Policy Loss: 9.513    Value Loss: 4.293    Reward Loss: 1.748    Consistency Loss: 0.000    ] Replay Episodes Collected: 2264850    Buffer Size: 14989      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:23:13,093][train][INFO][train.py>_log] ==> #1038000    Total Loss: 2.005    [weighted Loss:2.005    Policy Loss: 9.233    Value Loss: 4.467    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 2267301    Buffer Size: 14987      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:26:22,327][train][INFO][train.py>_log] ==> #1039000    Total Loss: 2.844    [weighted Loss:2.844    Policy Loss: 9.289    Value Loss: 4.420    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 2269669    Buffer Size: 15010      Transition Number: 1000.329k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:29:34,672][train][INFO][train.py>_log] ==> #1040000    Total Loss: 2.462    [weighted Loss:2.462    Policy Loss: 9.288    Value Loss: 4.792    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 2272042    Buffer Size: 15015      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:32:46,321][train][INFO][train.py>_log] ==> #1041000    Total Loss: 1.139    [weighted Loss:1.139    Policy Loss: 9.489    Value Loss: 4.437    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 2274472    Buffer Size: 15026      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:35:52,213][train][INFO][train.py>_log] ==> #1042000    Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 9.917    Value Loss: 4.668    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 2276861    Buffer Size: 15042      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:39:01,558][train][INFO][train.py>_log] ==> #1043000    Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 9.772    Value Loss: 4.636    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2279285    Buffer Size: 15024      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:42:10,039][train][INFO][train.py>_log] ==> #1044000    Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 9.599    Value Loss: 4.537    Reward Loss: 1.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 2281566    Buffer Size: 15008      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:45:18,889][train][INFO][train.py>_log] ==> #1045000    Total Loss: 2.624    [weighted Loss:2.624    Policy Loss: 9.917    Value Loss: 4.439    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 2283926    Buffer Size: 14987      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:48:28,195][train][INFO][train.py>_log] ==> #1046000    Total Loss: 1.655    [weighted Loss:1.655    Policy Loss: 9.747    Value Loss: 4.321    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 2286276    Buffer Size: 14979      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:51:38,885][train][INFO][train.py>_log] ==> #1047000    Total Loss: 2.206    [weighted Loss:2.206    Policy Loss: 9.100    Value Loss: 4.335    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2288695    Buffer Size: 14985      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:54:46,344][train][INFO][train.py>_log] ==> #1048000    Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 9.083    Value Loss: 4.828    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2291051    Buffer Size: 14976      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00010 
[2022-02-21 11:57:54,061][train][INFO][train.py>_log] ==> #1049000    Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 9.632    Value Loss: 4.630    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2293383    Buffer Size: 14963      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:01:03,525][train][INFO][train.py>_log] ==> #1050000    Total Loss: 2.341    [weighted Loss:2.341    Policy Loss: 9.755    Value Loss: 4.445    Reward Loss: 1.626    Consistency Loss: 0.000    ] Replay Episodes Collected: 2295791    Buffer Size: 14972      Transition Number: 1000.342k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:04:12,203][train][INFO][train.py>_log] ==> #1051000    Total Loss: 1.605    [weighted Loss:1.605    Policy Loss: 9.669    Value Loss: 4.432    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 2298217    Buffer Size: 14983      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:07:23,166][train][INFO][train.py>_log] ==> #1052000    Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 9.005    Value Loss: 4.717    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2300624    Buffer Size: 14996      Transition Number: 1000.456k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:10:34,675][train][INFO][train.py>_log] ==> #1053000    Total Loss: 0.733    [weighted Loss:0.733    Policy Loss: 9.616    Value Loss: 4.628    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2303045    Buffer Size: 14985      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:13:41,144][train][INFO][train.py>_log] ==> #1054000    Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 9.460    Value Loss: 4.676    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2305316    Buffer Size: 14989      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:16:48,031][train][INFO][train.py>_log] ==> #1055000    Total Loss: 3.117    [weighted Loss:3.117    Policy Loss: 9.516    Value Loss: 4.531    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2307725    Buffer Size: 14999      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:19:57,409][train][INFO][train.py>_log] ==> #1056000    Total Loss: 2.799    [weighted Loss:2.799    Policy Loss: 9.882    Value Loss: 4.390    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2310151    Buffer Size: 15000      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:23:08,603][train][INFO][train.py>_log] ==> #1057000    Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 9.378    Value Loss: 4.860    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 2312500    Buffer Size: 14998      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:26:18,268][train][INFO][train.py>_log] ==> #1058000    Total Loss: 3.527    [weighted Loss:3.527    Policy Loss: 9.394    Value Loss: 4.917    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2314857    Buffer Size: 14978      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:29:25,318][train][INFO][train.py>_log] ==> #1059000    Total Loss: 2.048    [weighted Loss:2.048    Policy Loss: 9.344    Value Loss: 4.694    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2317249    Buffer Size: 14976      Transition Number: 1000.276k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:32:33,335][train][INFO][train.py>_log] ==> #1060000    Total Loss: 2.196    [weighted Loss:2.196    Policy Loss: 9.580    Value Loss: 4.649    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 2319577    Buffer Size: 14974      Transition Number: 1000.663k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:35:44,034][train][INFO][train.py>_log] ==> #1061000    Total Loss: 2.728    [weighted Loss:2.728    Policy Loss: 9.826    Value Loss: 4.218    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2321973    Buffer Size: 14965      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:38:53,546][train][INFO][train.py>_log] ==> #1062000    Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 9.412    Value Loss: 4.754    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 2324337    Buffer Size: 14963      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:42:04,617][train][INFO][train.py>_log] ==> #1063000    Total Loss: 2.084    [weighted Loss:2.084    Policy Loss: 9.564    Value Loss: 4.447    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 2326797    Buffer Size: 14956      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:45:14,994][train][INFO][train.py>_log] ==> #1064000    Total Loss: 1.227    [weighted Loss:1.227    Policy Loss: 9.424    Value Loss: 4.413    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 2329141    Buffer Size: 14969      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:48:23,906][train][INFO][train.py>_log] ==> #1065000    Total Loss: 2.345    [weighted Loss:2.345    Policy Loss: 9.366    Value Loss: 4.462    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 2331531    Buffer Size: 14962      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:51:34,665][train][INFO][train.py>_log] ==> #1066000    Total Loss: 2.181    [weighted Loss:2.181    Policy Loss: 9.257    Value Loss: 4.532    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2333918    Buffer Size: 14971      Transition Number: 1000.529k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:54:43,817][train][INFO][train.py>_log] ==> #1067000    Total Loss: 3.155    [weighted Loss:3.155    Policy Loss: 9.141    Value Loss: 4.664    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2336266    Buffer Size: 14959      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 12:57:51,863][train][INFO][train.py>_log] ==> #1068000    Total Loss: 3.005    [weighted Loss:3.005    Policy Loss: 9.140    Value Loss: 4.752    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2338709    Buffer Size: 14978      Transition Number: 1000.215k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:01:00,173][train][INFO][train.py>_log] ==> #1069000    Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 9.535    Value Loss: 4.531    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 2341112    Buffer Size: 14986      Transition Number: 1000.293k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:04:13,360][train][INFO][train.py>_log] ==> #1070000    Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 9.531    Value Loss: 4.484    Reward Loss: 1.644    Consistency Loss: 0.000    ] Replay Episodes Collected: 2343497    Buffer Size: 14985      Transition Number: 1000.393k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:07:26,027][train][INFO][train.py>_log] ==> #1071000    Total Loss: 2.846    [weighted Loss:2.846    Policy Loss: 9.568    Value Loss: 4.680    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 2345887    Buffer Size: 14979      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:10:37,260][train][INFO][train.py>_log] ==> #1072000    Total Loss: 2.531    [weighted Loss:2.531    Policy Loss: 9.702    Value Loss: 4.312    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 2348304    Buffer Size: 14976      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:13:48,196][train][INFO][train.py>_log] ==> #1073000    Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 9.573    Value Loss: 4.414    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 2350693    Buffer Size: 14986      Transition Number: 1000.503k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:17:03,326][train][INFO][train.py>_log] ==> #1074000    Total Loss: 2.901    [weighted Loss:2.901    Policy Loss: 9.705    Value Loss: 4.246    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2353143    Buffer Size: 14983      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:20:18,219][train][INFO][train.py>_log] ==> #1075000    Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 8.840    Value Loss: 4.610    Reward Loss: 1.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 2355580    Buffer Size: 14965      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:23:30,976][train][INFO][train.py>_log] ==> #1076000    Total Loss: 2.412    [weighted Loss:2.412    Policy Loss: 9.405    Value Loss: 4.741    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 2357965    Buffer Size: 14960      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:26:41,256][train][INFO][train.py>_log] ==> #1077000    Total Loss: 2.719    [weighted Loss:2.719    Policy Loss: 9.004    Value Loss: 4.375    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 2360369    Buffer Size: 14958      Transition Number: 1000.145k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:29:56,065][train][INFO][train.py>_log] ==> #1078000    Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 9.379    Value Loss: 4.466    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2362681    Buffer Size: 14968      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:33:07,819][train][INFO][train.py>_log] ==> #1079000    Total Loss: 2.927    [weighted Loss:2.927    Policy Loss: 9.098    Value Loss: 4.581    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 2365162    Buffer Size: 14958      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:36:19,148][train][INFO][train.py>_log] ==> #1080000    Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 9.179    Value Loss: 4.673    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2367532    Buffer Size: 14946      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:39:30,544][train][INFO][train.py>_log] ==> #1081000    Total Loss: 1.931    [weighted Loss:1.931    Policy Loss: 9.577    Value Loss: 4.729    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2369879    Buffer Size: 14944      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:42:40,360][train][INFO][train.py>_log] ==> #1082000    Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 9.139    Value Loss: 4.300    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2372259    Buffer Size: 14950      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:45:50,832][train][INFO][train.py>_log] ==> #1083000    Total Loss: 3.730    [weighted Loss:3.730    Policy Loss: 9.598    Value Loss: 4.621    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2374566    Buffer Size: 14970      Transition Number: 1000.144k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:49:02,087][train][INFO][train.py>_log] ==> #1084000    Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 9.142    Value Loss: 4.392    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 2376987    Buffer Size: 14980      Transition Number: 1000.601k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:52:13,853][train][INFO][train.py>_log] ==> #1085000    Total Loss: 2.373    [weighted Loss:2.373    Policy Loss: 9.559    Value Loss: 4.737    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2379343    Buffer Size: 14985      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:55:28,583][train][INFO][train.py>_log] ==> #1086000    Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 9.463    Value Loss: 4.643    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 2381754    Buffer Size: 14992      Transition Number: 1000.010k Batch Size: 256        Lr: 0.00010 
[2022-02-21 13:58:40,028][train][INFO][train.py>_log] ==> #1087000    Total Loss: 2.435    [weighted Loss:2.435    Policy Loss: 9.385    Value Loss: 4.788    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2384161    Buffer Size: 14988      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:01:53,566][train][INFO][train.py>_log] ==> #1088000    Total Loss: 2.604    [weighted Loss:2.604    Policy Loss: 9.175    Value Loss: 4.521    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 2386572    Buffer Size: 14972      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:05:05,509][train][INFO][train.py>_log] ==> #1089000    Total Loss: 2.801    [weighted Loss:2.801    Policy Loss: 8.667    Value Loss: 4.472    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 2388915    Buffer Size: 14968      Transition Number: 1000.296k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:08:19,147][train][INFO][train.py>_log] ==> #1090000    Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 9.142    Value Loss: 4.491    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 2391423    Buffer Size: 14952      Transition Number: 1000.133k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:11:33,291][train][INFO][train.py>_log] ==> #1091000    Total Loss: 1.911    [weighted Loss:1.911    Policy Loss: 9.453    Value Loss: 4.447    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2393785    Buffer Size: 14950      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:14:48,467][train][INFO][train.py>_log] ==> #1092000    Total Loss: 3.675    [weighted Loss:3.675    Policy Loss: 9.286    Value Loss: 4.666    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 2396234    Buffer Size: 14940      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:18:04,226][train][INFO][train.py>_log] ==> #1093000    Total Loss: 3.004    [weighted Loss:3.004    Policy Loss: 8.983    Value Loss: 4.646    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 2398577    Buffer Size: 14939      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:21:18,058][train][INFO][train.py>_log] ==> #1094000    Total Loss: 1.972    [weighted Loss:1.972    Policy Loss: 9.331    Value Loss: 4.581    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2401009    Buffer Size: 14950      Transition Number: 1000.024k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:24:31,808][train][INFO][train.py>_log] ==> #1095000    Total Loss: 3.679    [weighted Loss:3.679    Policy Loss: 9.244    Value Loss: 4.308    Reward Loss: 1.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 2403443    Buffer Size: 14950      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:27:45,817][train][INFO][train.py>_log] ==> #1096000    Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 8.875    Value Loss: 4.492    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2405802    Buffer Size: 14953      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:31:02,133][train][INFO][train.py>_log] ==> #1097000    Total Loss: 2.230    [weighted Loss:2.230    Policy Loss: 9.107    Value Loss: 4.400    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 2408289    Buffer Size: 14957      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:34:15,508][train][INFO][train.py>_log] ==> #1098000    Total Loss: 1.979    [weighted Loss:1.979    Policy Loss: 8.913    Value Loss: 4.575    Reward Loss: 1.489    Consistency Loss: 0.000    ] Replay Episodes Collected: 2410679    Buffer Size: 14958      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:37:27,015][train][INFO][train.py>_log] ==> #1099000    Total Loss: 3.100    [weighted Loss:3.100    Policy Loss: 9.675    Value Loss: 4.529    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 2413058    Buffer Size: 14971      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:40:38,775][train][INFO][train.py>_log] ==> #1100000    Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 9.246    Value Loss: 4.275    Reward Loss: 1.691    Consistency Loss: 0.000    ] Replay Episodes Collected: 2415461    Buffer Size: 14986      Transition Number: 1000.125k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:43:51,875][train][INFO][train.py>_log] ==> #1101000    Total Loss: 1.293    [weighted Loss:1.293    Policy Loss: 9.433    Value Loss: 4.478    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2417904    Buffer Size: 14983      Transition Number: 1000.218k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:47:06,672][train][INFO][train.py>_log] ==> #1102000    Total Loss: 1.296    [weighted Loss:1.296    Policy Loss: 8.602    Value Loss: 4.963    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 2420253    Buffer Size: 14997      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:50:20,367][train][INFO][train.py>_log] ==> #1103000    Total Loss: 2.219    [weighted Loss:2.219    Policy Loss: 9.091    Value Loss: 4.403    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2422698    Buffer Size: 15001      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:53:34,267][train][INFO][train.py>_log] ==> #1104000    Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 9.039    Value Loss: 4.623    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 2425157    Buffer Size: 15002      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 14:56:48,289][train][INFO][train.py>_log] ==> #1105000    Total Loss: 2.452    [weighted Loss:2.452    Policy Loss: 9.179    Value Loss: 4.178    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2427494    Buffer Size: 15015      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:00:01,844][train][INFO][train.py>_log] ==> #1106000    Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 9.062    Value Loss: 4.581    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2429962    Buffer Size: 15011      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:03:12,286][train][INFO][train.py>_log] ==> #1107000    Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 8.962    Value Loss: 4.585    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2432327    Buffer Size: 15020      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:06:20,921][train][INFO][train.py>_log] ==> #1108000    Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 9.335    Value Loss: 4.601    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 2434695    Buffer Size: 15033      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:09:35,322][train][INFO][train.py>_log] ==> #1109000    Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 9.568    Value Loss: 4.688    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 2437220    Buffer Size: 15056      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:12:46,272][train][INFO][train.py>_log] ==> #1110000    Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 9.532    Value Loss: 4.334    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 2439640    Buffer Size: 15066      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:15:57,840][train][INFO][train.py>_log] ==> #1111000    Total Loss: 2.900    [weighted Loss:2.900    Policy Loss: 9.369    Value Loss: 4.798    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2442073    Buffer Size: 15101      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:19:10,885][train][INFO][train.py>_log] ==> #1112000    Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 9.049    Value Loss: 4.519    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 2444399    Buffer Size: 15113      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:22:22,607][train][INFO][train.py>_log] ==> #1113000    Total Loss: 3.393    [weighted Loss:3.393    Policy Loss: 9.664    Value Loss: 4.380    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2446912    Buffer Size: 15136      Transition Number: 1000.182k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:25:36,407][train][INFO][train.py>_log] ==> #1114000    Total Loss: 2.788    [weighted Loss:2.788    Policy Loss: 8.968    Value Loss: 4.421    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 2449356    Buffer Size: 15139      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:28:49,711][train][INFO][train.py>_log] ==> #1115000    Total Loss: 2.264    [weighted Loss:2.264    Policy Loss: 9.590    Value Loss: 4.552    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2451832    Buffer Size: 15158      Transition Number: 1000.119k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:32:04,833][train][INFO][train.py>_log] ==> #1116000    Total Loss: 1.825    [weighted Loss:1.825    Policy Loss: 9.237    Value Loss: 4.536    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 2454228    Buffer Size: 15187      Transition Number: 1000.277k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:35:18,460][train][INFO][train.py>_log] ==> #1117000    Total Loss: 2.402    [weighted Loss:2.402    Policy Loss: 9.534    Value Loss: 4.875    Reward Loss: 1.789    Consistency Loss: 0.000    ] Replay Episodes Collected: 2456695    Buffer Size: 15191      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:38:33,951][train][INFO][train.py>_log] ==> #1118000    Total Loss: 2.898    [weighted Loss:2.898    Policy Loss: 9.509    Value Loss: 4.401    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 2459176    Buffer Size: 15220      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:41:45,114][train][INFO][train.py>_log] ==> #1119000    Total Loss: 2.381    [weighted Loss:2.381    Policy Loss: 9.674    Value Loss: 4.697    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 2461637    Buffer Size: 15254      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:44:56,930][train][INFO][train.py>_log] ==> #1120000    Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 9.730    Value Loss: 4.478    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 2464015    Buffer Size: 15256      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:48:08,803][train][INFO][train.py>_log] ==> #1121000    Total Loss: 1.742    [weighted Loss:1.742    Policy Loss: 9.300    Value Loss: 4.486    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2466477    Buffer Size: 15292      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:51:18,701][train][INFO][train.py>_log] ==> #1122000    Total Loss: 2.045    [weighted Loss:2.045    Policy Loss: 9.329    Value Loss: 4.330    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 2468872    Buffer Size: 15317      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:54:29,911][train][INFO][train.py>_log] ==> #1123000    Total Loss: 2.783    [weighted Loss:2.783    Policy Loss: 9.410    Value Loss: 4.468    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2471289    Buffer Size: 15338      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00010 
[2022-02-21 15:57:38,701][train][INFO][train.py>_log] ==> #1124000    Total Loss: 1.265    [weighted Loss:1.265    Policy Loss: 9.781    Value Loss: 4.524    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2473706    Buffer Size: 15356      Transition Number: 1000.333k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:00:49,399][train][INFO][train.py>_log] ==> #1125000    Total Loss: 2.129    [weighted Loss:2.129    Policy Loss: 9.239    Value Loss: 4.560    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 2476210    Buffer Size: 15333      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:04:02,289][train][INFO][train.py>_log] ==> #1126000    Total Loss: 1.289    [weighted Loss:1.289    Policy Loss: 9.565    Value Loss: 4.371    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2478624    Buffer Size: 15345      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:07:16,582][train][INFO][train.py>_log] ==> #1127000    Total Loss: 3.289    [weighted Loss:3.289    Policy Loss: 9.509    Value Loss: 4.467    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2481011    Buffer Size: 15340      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:10:28,180][train][INFO][train.py>_log] ==> #1128000    Total Loss: 1.575    [weighted Loss:1.575    Policy Loss: 9.484    Value Loss: 4.644    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2483436    Buffer Size: 15318      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:13:39,520][train][INFO][train.py>_log] ==> #1129000    Total Loss: 2.342    [weighted Loss:2.342    Policy Loss: 9.842    Value Loss: 4.457    Reward Loss: 1.801    Consistency Loss: 0.000    ] Replay Episodes Collected: 2485861    Buffer Size: 15299      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:16:52,477][train][INFO][train.py>_log] ==> #1130000    Total Loss: 2.777    [weighted Loss:2.777    Policy Loss: 9.508    Value Loss: 4.230    Reward Loss: 1.811    Consistency Loss: 0.000    ] Replay Episodes Collected: 2488330    Buffer Size: 15291      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:20:04,710][train][INFO][train.py>_log] ==> #1131000    Total Loss: 1.609    [weighted Loss:1.609    Policy Loss: 8.952    Value Loss: 4.490    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 2490740    Buffer Size: 15284      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:23:19,857][train][INFO][train.py>_log] ==> #1132000    Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 8.997    Value Loss: 4.097    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2493185    Buffer Size: 15279      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:26:29,788][train][INFO][train.py>_log] ==> #1133000    Total Loss: 1.561    [weighted Loss:1.561    Policy Loss: 9.437    Value Loss: 4.038    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2495636    Buffer Size: 15276      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:29:41,668][train][INFO][train.py>_log] ==> #1134000    Total Loss: 1.855    [weighted Loss:1.855    Policy Loss: 9.449    Value Loss: 4.467    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 2498086    Buffer Size: 15281      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:32:55,484][train][INFO][train.py>_log] ==> #1135000    Total Loss: 1.904    [weighted Loss:1.904    Policy Loss: 9.788    Value Loss: 4.443    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 2500565    Buffer Size: 15279      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:36:09,174][train][INFO][train.py>_log] ==> #1136000    Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 9.503    Value Loss: 4.594    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 2502973    Buffer Size: 15290      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:39:22,646][train][INFO][train.py>_log] ==> #1137000    Total Loss: 2.983    [weighted Loss:2.983    Policy Loss: 9.190    Value Loss: 4.238    Reward Loss: 1.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 2505414    Buffer Size: 15271      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:42:34,942][train][INFO][train.py>_log] ==> #1138000    Total Loss: 2.818    [weighted Loss:2.818    Policy Loss: 9.583    Value Loss: 4.501    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2507942    Buffer Size: 15275      Transition Number: 1000.220k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:45:44,473][train][INFO][train.py>_log] ==> #1139000    Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 9.370    Value Loss: 4.418    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 2510286    Buffer Size: 15274      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:49:00,246][train][INFO][train.py>_log] ==> #1140000    Total Loss: 1.893    [weighted Loss:1.893    Policy Loss: 9.528    Value Loss: 4.660    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 2512734    Buffer Size: 15272      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:52:12,006][train][INFO][train.py>_log] ==> #1141000    Total Loss: 1.777    [weighted Loss:1.777    Policy Loss: 9.506    Value Loss: 4.061    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 2515195    Buffer Size: 15266      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:55:24,518][train][INFO][train.py>_log] ==> #1142000    Total Loss: 1.415    [weighted Loss:1.415    Policy Loss: 9.518    Value Loss: 4.347    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 2517726    Buffer Size: 15251      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 16:58:37,332][train][INFO][train.py>_log] ==> #1143000    Total Loss: 2.244    [weighted Loss:2.244    Policy Loss: 9.690    Value Loss: 4.408    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 2520211    Buffer Size: 15259      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:01:46,450][train][INFO][train.py>_log] ==> #1144000    Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 9.812    Value Loss: 4.162    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 2522522    Buffer Size: 15249      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:04:58,479][train][INFO][train.py>_log] ==> #1145000    Total Loss: 1.210    [weighted Loss:1.210    Policy Loss: 9.365    Value Loss: 3.914    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 2524996    Buffer Size: 15239      Transition Number: 1000.102k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:08:12,818][train][INFO][train.py>_log] ==> #1146000    Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 9.506    Value Loss: 3.891    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2527441    Buffer Size: 15246      Transition Number: 1000.267k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:11:25,031][train][INFO][train.py>_log] ==> #1147000    Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 9.556    Value Loss: 4.588    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2529907    Buffer Size: 15233      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:14:37,955][train][INFO][train.py>_log] ==> #1148000    Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 9.163    Value Loss: 4.425    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 2532333    Buffer Size: 15237      Transition Number: 1000.507k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:17:52,145][train][INFO][train.py>_log] ==> #1149000    Total Loss: 2.762    [weighted Loss:2.762    Policy Loss: 9.411    Value Loss: 4.219    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 2534739    Buffer Size: 15228      Transition Number: 1000.332k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:21:05,787][train][INFO][train.py>_log] ==> #1150000    Total Loss: 1.698    [weighted Loss:1.698    Policy Loss: 9.191    Value Loss: 4.432    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2537281    Buffer Size: 15237      Transition Number: 1000.416k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:24:20,000][train][INFO][train.py>_log] ==> #1151000    Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 9.303    Value Loss: 4.624    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2539776    Buffer Size: 15243      Transition Number: 1000.448k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:27:33,065][train][INFO][train.py>_log] ==> #1152000    Total Loss: 2.063    [weighted Loss:2.063    Policy Loss: 9.788    Value Loss: 4.382    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2542266    Buffer Size: 15233      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:30:43,357][train][INFO][train.py>_log] ==> #1153000    Total Loss: 1.642    [weighted Loss:1.642    Policy Loss: 9.230    Value Loss: 4.155    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 2544621    Buffer Size: 15237      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:33:55,747][train][INFO][train.py>_log] ==> #1154000    Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 9.599    Value Loss: 4.592    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2547046    Buffer Size: 15242      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:37:13,998][train][INFO][train.py>_log] ==> #1155000    Total Loss: 2.792    [weighted Loss:2.792    Policy Loss: 9.198    Value Loss: 4.398    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2549608    Buffer Size: 15242      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:40:29,599][train][INFO][train.py>_log] ==> #1156000    Total Loss: 2.258    [weighted Loss:2.258    Policy Loss: 9.391    Value Loss: 4.247    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 2552052    Buffer Size: 15235      Transition Number: 1000.549k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:43:42,590][train][INFO][train.py>_log] ==> #1157000    Total Loss: 1.336    [weighted Loss:1.336    Policy Loss: 9.238    Value Loss: 4.647    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2554507    Buffer Size: 15211      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:46:57,152][train][INFO][train.py>_log] ==> #1158000    Total Loss: 2.202    [weighted Loss:2.202    Policy Loss: 9.645    Value Loss: 4.483    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 2557004    Buffer Size: 15212      Transition Number: 1000.218k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:50:09,084][train][INFO][train.py>_log] ==> #1159000    Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 9.368    Value Loss: 4.614    Reward Loss: 1.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 2559494    Buffer Size: 15194      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:53:22,374][train][INFO][train.py>_log] ==> #1160000    Total Loss: 1.212    [weighted Loss:1.212    Policy Loss: 9.250    Value Loss: 4.393    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 2562002    Buffer Size: 15187      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:56:37,169][train][INFO][train.py>_log] ==> #1161000    Total Loss: 2.760    [weighted Loss:2.760    Policy Loss: 9.587    Value Loss: 4.530    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 2564476    Buffer Size: 15194      Transition Number: 1000.492k Batch Size: 256        Lr: 0.00010 
[2022-02-21 17:59:48,031][train][INFO][train.py>_log] ==> #1162000    Total Loss: 1.593    [weighted Loss:1.593    Policy Loss: 9.301    Value Loss: 4.590    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2566858    Buffer Size: 15203      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:03:01,136][train][INFO][train.py>_log] ==> #1163000    Total Loss: 1.284    [weighted Loss:1.284    Policy Loss: 9.231    Value Loss: 4.462    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 2569372    Buffer Size: 15198      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:06:15,132][train][INFO][train.py>_log] ==> #1164000    Total Loss: 2.875    [weighted Loss:2.875    Policy Loss: 9.381    Value Loss: 4.941    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 2571822    Buffer Size: 15194      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:09:29,898][train][INFO][train.py>_log] ==> #1165000    Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 8.851    Value Loss: 4.604    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2574278    Buffer Size: 15199      Transition Number: 1000.161k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:12:44,303][train][INFO][train.py>_log] ==> #1166000    Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 8.809    Value Loss: 4.345    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 2576737    Buffer Size: 15197      Transition Number: 1000.296k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:15:55,233][train][INFO][train.py>_log] ==> #1167000    Total Loss: 1.207    [weighted Loss:1.207    Policy Loss: 9.000    Value Loss: 4.546    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 2579214    Buffer Size: 15180      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:19:09,743][train][INFO][train.py>_log] ==> #1168000    Total Loss: 1.809    [weighted Loss:1.809    Policy Loss: 9.249    Value Loss: 4.310    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2581638    Buffer Size: 15177      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:22:22,756][train][INFO][train.py>_log] ==> #1169000    Total Loss: 2.621    [weighted Loss:2.621    Policy Loss: 8.975    Value Loss: 4.237    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 2584083    Buffer Size: 15163      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:25:35,579][train][INFO][train.py>_log] ==> #1170000    Total Loss: 3.055    [weighted Loss:3.055    Policy Loss: 9.362    Value Loss: 4.546    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2586558    Buffer Size: 15165      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:28:49,601][train][INFO][train.py>_log] ==> #1171000    Total Loss: 2.098    [weighted Loss:2.098    Policy Loss: 8.715    Value Loss: 4.471    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 2589065    Buffer Size: 15158      Transition Number: 1000.212k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:32:01,615][train][INFO][train.py>_log] ==> #1172000    Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 8.645    Value Loss: 4.451    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 2591536    Buffer Size: 15165      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:35:17,982][train][INFO][train.py>_log] ==> #1173000    Total Loss: 3.260    [weighted Loss:3.260    Policy Loss: 9.204    Value Loss: 4.638    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2594014    Buffer Size: 15169      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:38:33,917][train][INFO][train.py>_log] ==> #1174000    Total Loss: 1.138    [weighted Loss:1.138    Policy Loss: 8.391    Value Loss: 4.127    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2596506    Buffer Size: 15166      Transition Number: 1000.088k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:41:46,416][train][INFO][train.py>_log] ==> #1175000    Total Loss: 3.313    [weighted Loss:3.313    Policy Loss: 9.118    Value Loss: 4.565    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 2598908    Buffer Size: 15172      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:44:57,717][train][INFO][train.py>_log] ==> #1176000    Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 8.988    Value Loss: 4.316    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 2601366    Buffer Size: 15170      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:48:10,708][train][INFO][train.py>_log] ==> #1177000    Total Loss: 3.210    [weighted Loss:3.210    Policy Loss: 9.558    Value Loss: 4.320    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 2603835    Buffer Size: 15168      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:51:23,321][train][INFO][train.py>_log] ==> #1178000    Total Loss: 1.289    [weighted Loss:1.289    Policy Loss: 9.310    Value Loss: 4.497    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2606237    Buffer Size: 15173      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:54:36,779][train][INFO][train.py>_log] ==> #1179000    Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 9.266    Value Loss: 4.467    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 2608691    Buffer Size: 15175      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 18:57:49,755][train][INFO][train.py>_log] ==> #1180000    Total Loss: 2.186    [weighted Loss:2.186    Policy Loss: 9.126    Value Loss: 4.423    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2611265    Buffer Size: 15182      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:01:06,227][train][INFO][train.py>_log] ==> #1181000    Total Loss: 1.740    [weighted Loss:1.740    Policy Loss: 9.361    Value Loss: 4.423    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 2613711    Buffer Size: 15181      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:04:17,922][train][INFO][train.py>_log] ==> #1182000    Total Loss: 1.831    [weighted Loss:1.831    Policy Loss: 9.008    Value Loss: 4.258    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2616065    Buffer Size: 15185      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:07:32,828][train][INFO][train.py>_log] ==> #1183000    Total Loss: 2.552    [weighted Loss:2.552    Policy Loss: 8.898    Value Loss: 4.139    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 2618602    Buffer Size: 15186      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:10:46,933][train][INFO][train.py>_log] ==> #1184000    Total Loss: 2.697    [weighted Loss:2.697    Policy Loss: 9.168    Value Loss: 4.550    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2621132    Buffer Size: 15205      Transition Number: 1000.182k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:13:59,991][train][INFO][train.py>_log] ==> #1185000    Total Loss: 1.684    [weighted Loss:1.684    Policy Loss: 8.910    Value Loss: 4.410    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2623572    Buffer Size: 15219      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:17:14,721][train][INFO][train.py>_log] ==> #1186000    Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 8.918    Value Loss: 4.333    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 2625976    Buffer Size: 15211      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:20:26,890][train][INFO][train.py>_log] ==> #1187000    Total Loss: 2.804    [weighted Loss:2.804    Policy Loss: 9.328    Value Loss: 4.615    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 2628401    Buffer Size: 15215      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:23:41,242][train][INFO][train.py>_log] ==> #1188000    Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 9.323    Value Loss: 4.455    Reward Loss: 1.770    Consistency Loss: 0.000    ] Replay Episodes Collected: 2630877    Buffer Size: 15223      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:26:52,548][train][INFO][train.py>_log] ==> #1189000    Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 9.173    Value Loss: 4.607    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 2633325    Buffer Size: 15228      Transition Number: 1000.207k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:30:05,658][train][INFO][train.py>_log] ==> #1190000    Total Loss: 1.389    [weighted Loss:1.389    Policy Loss: 9.164    Value Loss: 4.412    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 2635807    Buffer Size: 15225      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:33:16,097][train][INFO][train.py>_log] ==> #1191000    Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 9.100    Value Loss: 4.395    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 2638217    Buffer Size: 15213      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:36:29,400][train][INFO][train.py>_log] ==> #1192000    Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 9.520    Value Loss: 4.488    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 2640663    Buffer Size: 15211      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:39:43,170][train][INFO][train.py>_log] ==> #1193000    Total Loss: 1.640    [weighted Loss:1.640    Policy Loss: 9.478    Value Loss: 4.847    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 2643153    Buffer Size: 15215      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:42:57,692][train][INFO][train.py>_log] ==> #1194000    Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 9.024    Value Loss: 4.475    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 2645581    Buffer Size: 15234      Transition Number: 1000.122k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:46:10,419][train][INFO][train.py>_log] ==> #1195000    Total Loss: 2.783    [weighted Loss:2.783    Policy Loss: 9.460    Value Loss: 4.549    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 2647999    Buffer Size: 15231      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:49:30,062][train][INFO][train.py>_log] ==> #1196000    Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 9.447    Value Loss: 4.621    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 2650576    Buffer Size: 15226      Transition Number: 1000.259k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:52:42,458][train][INFO][train.py>_log] ==> #1197000    Total Loss: 2.786    [weighted Loss:2.786    Policy Loss: 9.266    Value Loss: 4.773    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 2653054    Buffer Size: 15242      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:55:54,555][train][INFO][train.py>_log] ==> #1198000    Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 9.014    Value Loss: 4.481    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 2655455    Buffer Size: 15247      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00010 
[2022-02-21 19:59:07,951][train][INFO][train.py>_log] ==> #1199000    Total Loss: 2.869    [weighted Loss:2.869    Policy Loss: 9.954    Value Loss: 4.683    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 2657879    Buffer Size: 15249      Transition Number: 1000.189k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:02:25,289][train][INFO][train.py>_log] ==> #1200000    Total Loss: 1.562    [weighted Loss:1.562    Policy Loss: 9.356    Value Loss: 4.337    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2660453    Buffer Size: 15246      Transition Number: 1000.398k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:05:40,729][train][INFO][train.py>_log] ==> #1201000    Total Loss: 1.088    [weighted Loss:1.088    Policy Loss: 9.732    Value Loss: 4.215    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 2662991    Buffer Size: 15249      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:08:52,025][train][INFO][train.py>_log] ==> #1202000    Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 9.495    Value Loss: 4.421    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 2665500    Buffer Size: 15262      Transition Number: 1000.165k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:12:08,178][train][INFO][train.py>_log] ==> #1203000    Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 9.355    Value Loss: 4.596    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 2667933    Buffer Size: 15266      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:15:18,852][train][INFO][train.py>_log] ==> #1204000    Total Loss: 3.257    [weighted Loss:3.257    Policy Loss: 9.833    Value Loss: 3.975    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 2670289    Buffer Size: 15274      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:18:31,517][train][INFO][train.py>_log] ==> #1205000    Total Loss: 2.211    [weighted Loss:2.211    Policy Loss: 9.838    Value Loss: 4.613    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2672776    Buffer Size: 15280      Transition Number: 1000.270k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:21:44,535][train][INFO][train.py>_log] ==> #1206000    Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 9.868    Value Loss: 4.472    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 2675266    Buffer Size: 15280      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:24:57,918][train][INFO][train.py>_log] ==> #1207000    Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 9.884    Value Loss: 4.469    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 2677710    Buffer Size: 15288      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:28:08,994][train][INFO][train.py>_log] ==> #1208000    Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 10.118   Value Loss: 4.381    Reward Loss: 1.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 2680132    Buffer Size: 15285      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:31:23,473][train][INFO][train.py>_log] ==> #1209000    Total Loss: 2.977    [weighted Loss:2.977    Policy Loss: 9.780    Value Loss: 4.520    Reward Loss: 1.712    Consistency Loss: 0.000    ] Replay Episodes Collected: 2682639    Buffer Size: 15299      Transition Number: 1000.332k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:34:38,690][train][INFO][train.py>_log] ==> #1210000    Total Loss: 2.941    [weighted Loss:2.941    Policy Loss: 9.625    Value Loss: 4.621    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 2685187    Buffer Size: 15303      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:37:50,823][train][INFO][train.py>_log] ==> #1211000    Total Loss: 2.541    [weighted Loss:2.541    Policy Loss: 9.422    Value Loss: 4.407    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2687602    Buffer Size: 15347      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:41:02,125][train][INFO][train.py>_log] ==> #1212000    Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 9.770    Value Loss: 4.888    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2690038    Buffer Size: 15381      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:44:17,393][train][INFO][train.py>_log] ==> #1213000    Total Loss: 2.111    [weighted Loss:2.111    Policy Loss: 9.917    Value Loss: 4.682    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 2692591    Buffer Size: 15400      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:47:29,510][train][INFO][train.py>_log] ==> #1214000    Total Loss: 2.890    [weighted Loss:2.890    Policy Loss: 9.997    Value Loss: 4.571    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2695019    Buffer Size: 15440      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:50:44,790][train][INFO][train.py>_log] ==> #1215000    Total Loss: 2.131    [weighted Loss:2.131    Policy Loss: 9.885    Value Loss: 4.306    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2697425    Buffer Size: 15488      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:53:57,913][train][INFO][train.py>_log] ==> #1216000    Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 10.033   Value Loss: 4.481    Reward Loss: 1.837    Consistency Loss: 0.000    ] Replay Episodes Collected: 2699945    Buffer Size: 15533      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00010 
[2022-02-21 20:57:14,854][train][INFO][train.py>_log] ==> #1217000    Total Loss: 2.982    [weighted Loss:2.982    Policy Loss: 10.141   Value Loss: 4.570    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 2702525    Buffer Size: 15578      Transition Number: 1000.320k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:00:29,837][train][INFO][train.py>_log] ==> #1218000    Total Loss: 1.692    [weighted Loss:1.692    Policy Loss: 9.748    Value Loss: 4.558    Reward Loss: 1.791    Consistency Loss: 0.000    ] Replay Episodes Collected: 2705010    Buffer Size: 15612      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:03:44,730][train][INFO][train.py>_log] ==> #1219000    Total Loss: 3.027    [weighted Loss:3.027    Policy Loss: 9.950    Value Loss: 4.616    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 2707535    Buffer Size: 15667      Transition Number: 1000.273k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:06:57,074][train][INFO][train.py>_log] ==> #1220000    Total Loss: 3.198    [weighted Loss:3.198    Policy Loss: 9.964    Value Loss: 4.361    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 2709942    Buffer Size: 15693      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:10:12,542][train][INFO][train.py>_log] ==> #1221000    Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 9.918    Value Loss: 4.335    Reward Loss: 1.835    Consistency Loss: 0.000    ] Replay Episodes Collected: 2712419    Buffer Size: 15732      Transition Number: 1000.199k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:13:24,538][train][INFO][train.py>_log] ==> #1222000    Total Loss: 2.261    [weighted Loss:2.261    Policy Loss: 9.681    Value Loss: 4.647    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 2714950    Buffer Size: 15748      Transition Number: 1000.334k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:16:38,672][train][INFO][train.py>_log] ==> #1223000    Total Loss: 2.164    [weighted Loss:2.164    Policy Loss: 9.654    Value Loss: 4.458    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 2717397    Buffer Size: 15750      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:19:52,702][train][INFO][train.py>_log] ==> #1224000    Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 9.862    Value Loss: 4.789    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 2719881    Buffer Size: 15752      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:23:05,701][train][INFO][train.py>_log] ==> #1225000    Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 10.338   Value Loss: 4.353    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 2722384    Buffer Size: 15724      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:26:19,981][train][INFO][train.py>_log] ==> #1226000    Total Loss: 2.610    [weighted Loss:2.610    Policy Loss: 9.625    Value Loss: 4.407    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2724814    Buffer Size: 15706      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:29:34,603][train][INFO][train.py>_log] ==> #1227000    Total Loss: 1.068    [weighted Loss:1.068    Policy Loss: 10.081   Value Loss: 4.473    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2727300    Buffer Size: 15675      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:32:51,435][train][INFO][train.py>_log] ==> #1228000    Total Loss: 1.658    [weighted Loss:1.658    Policy Loss: 9.952    Value Loss: 4.556    Reward Loss: 1.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 2729739    Buffer Size: 15653      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:36:05,007][train][INFO][train.py>_log] ==> #1229000    Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 10.019   Value Loss: 4.452    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2732296    Buffer Size: 15629      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:39:20,551][train][INFO][train.py>_log] ==> #1230000    Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 10.332   Value Loss: 4.520    Reward Loss: 1.774    Consistency Loss: 0.000    ] Replay Episodes Collected: 2734810    Buffer Size: 15625      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:42:39,203][train][INFO][train.py>_log] ==> #1231000    Total Loss: 1.713    [weighted Loss:1.713    Policy Loss: 9.960    Value Loss: 4.568    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2737349    Buffer Size: 15614      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:45:54,908][train][INFO][train.py>_log] ==> #1232000    Total Loss: 2.824    [weighted Loss:2.824    Policy Loss: 9.620    Value Loss: 4.451    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 2739869    Buffer Size: 15602      Transition Number: 999.937 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:49:11,385][train][INFO][train.py>_log] ==> #1233000    Total Loss: 1.042    [weighted Loss:1.042    Policy Loss: 10.034   Value Loss: 4.619    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2742375    Buffer Size: 15605      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:52:25,509][train][INFO][train.py>_log] ==> #1234000    Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 10.097   Value Loss: 4.021    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2744702    Buffer Size: 15599      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:55:39,820][train][INFO][train.py>_log] ==> #1235000    Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 9.852    Value Loss: 4.146    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 2747257    Buffer Size: 15595      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00010 
[2022-02-21 21:58:55,061][train][INFO][train.py>_log] ==> #1236000    Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 9.917    Value Loss: 4.350    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 2749783    Buffer Size: 15580      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:02:12,048][train][INFO][train.py>_log] ==> #1237000    Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 10.151   Value Loss: 4.346    Reward Loss: 1.883    Consistency Loss: 0.000    ] Replay Episodes Collected: 2752220    Buffer Size: 15570      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:05:25,636][train][INFO][train.py>_log] ==> #1238000    Total Loss: 1.975    [weighted Loss:1.975    Policy Loss: 9.735    Value Loss: 4.041    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 2754756    Buffer Size: 15543      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:08:39,963][train][INFO][train.py>_log] ==> #1239000    Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 10.358   Value Loss: 4.416    Reward Loss: 1.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 2757156    Buffer Size: 15536      Transition Number: 1000.286k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:11:54,839][train][INFO][train.py>_log] ==> #1240000    Total Loss: 2.524    [weighted Loss:2.524    Policy Loss: 9.973    Value Loss: 4.285    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 2759682    Buffer Size: 15506      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:15:08,905][train][INFO][train.py>_log] ==> #1241000    Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 9.731    Value Loss: 4.560    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 2762130    Buffer Size: 15483      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:18:22,676][train][INFO][train.py>_log] ==> #1242000    Total Loss: 3.263    [weighted Loss:3.263    Policy Loss: 9.822    Value Loss: 4.252    Reward Loss: 1.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 2764623    Buffer Size: 15457      Transition Number: 1000.079k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:21:40,907][train][INFO][train.py>_log] ==> #1243000    Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 10.141   Value Loss: 4.377    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 2767052    Buffer Size: 15440      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:24:53,451][train][INFO][train.py>_log] ==> #1244000    Total Loss: 3.828    [weighted Loss:3.828    Policy Loss: 9.950    Value Loss: 4.108    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 2769534    Buffer Size: 15427      Transition Number: 1000.131k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:28:08,022][train][INFO][train.py>_log] ==> #1245000    Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 10.306   Value Loss: 4.245    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2772048    Buffer Size: 15393      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:31:23,384][train][INFO][train.py>_log] ==> #1246000    Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 9.919    Value Loss: 4.038    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2774472    Buffer Size: 15386      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:34:36,658][train][INFO][train.py>_log] ==> #1247000    Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 9.205    Value Loss: 4.719    Reward Loss: 1.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 2776931    Buffer Size: 15360      Transition Number: 1000.204k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:37:53,653][train][INFO][train.py>_log] ==> #1248000    Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 9.989    Value Loss: 4.420    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 2779516    Buffer Size: 15327      Transition Number: 1000.002k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:41:11,841][train][INFO][train.py>_log] ==> #1249000    Total Loss: 3.094    [weighted Loss:3.094    Policy Loss: 9.819    Value Loss: 4.249    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 2781975    Buffer Size: 15320      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:44:26,560][train][INFO][train.py>_log] ==> #1250000    Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 10.017   Value Loss: 4.625    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 2784446    Buffer Size: 15304      Transition Number: 1000.197k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:47:42,610][train][INFO][train.py>_log] ==> #1251000    Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 9.971    Value Loss: 4.339    Reward Loss: 1.760    Consistency Loss: 0.000    ] Replay Episodes Collected: 2786987    Buffer Size: 15284      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:50:58,035][train][INFO][train.py>_log] ==> #1252000    Total Loss: 3.377    [weighted Loss:3.377    Policy Loss: 9.810    Value Loss: 4.620    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2789445    Buffer Size: 15276      Transition Number: 1000.401k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:54:12,195][train][INFO][train.py>_log] ==> #1253000    Total Loss: 2.417    [weighted Loss:2.417    Policy Loss: 9.323    Value Loss: 4.518    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 2791896    Buffer Size: 15262      Transition Number: 1000.295k Batch Size: 256        Lr: 0.00010 
[2022-02-21 22:57:29,082][train][INFO][train.py>_log] ==> #1254000    Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 10.025   Value Loss: 4.370    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 2794470    Buffer Size: 15233      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:00:45,659][train][INFO][train.py>_log] ==> #1255000    Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 9.911    Value Loss: 4.272    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2796848    Buffer Size: 15203      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:04:01,748][train][INFO][train.py>_log] ==> #1256000    Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 9.958    Value Loss: 4.599    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 2799383    Buffer Size: 15168      Transition Number: 1000.108k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:07:20,569][train][INFO][train.py>_log] ==> #1257000    Total Loss: 2.199    [weighted Loss:2.199    Policy Loss: 9.874    Value Loss: 4.278    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 2801998    Buffer Size: 15146      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:10:37,325][train][INFO][train.py>_log] ==> #1258000    Total Loss: 1.607    [weighted Loss:1.607    Policy Loss: 10.085   Value Loss: 4.447    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 2804455    Buffer Size: 15135      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:13:51,124][train][INFO][train.py>_log] ==> #1259000    Total Loss: 2.113    [weighted Loss:2.113    Policy Loss: 9.882    Value Loss: 4.507    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 2806867    Buffer Size: 15113      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:17:07,597][train][INFO][train.py>_log] ==> #1260000    Total Loss: 2.730    [weighted Loss:2.730    Policy Loss: 10.125   Value Loss: 4.248    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 2809470    Buffer Size: 15090      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:20:25,144][train][INFO][train.py>_log] ==> #1261000    Total Loss: 2.281    [weighted Loss:2.281    Policy Loss: 10.258   Value Loss: 4.488    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 2811919    Buffer Size: 15077      Transition Number: 1000.732k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:23:42,432][train][INFO][train.py>_log] ==> #1262000    Total Loss: 1.750    [weighted Loss:1.750    Policy Loss: 9.986    Value Loss: 4.549    Reward Loss: 1.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 2814405    Buffer Size: 15062      Transition Number: 1000.345k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:27:02,806][train][INFO][train.py>_log] ==> #1263000    Total Loss: 2.218    [weighted Loss:2.218    Policy Loss: 9.632    Value Loss: 4.469    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 2816981    Buffer Size: 15043      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:30:21,892][train][INFO][train.py>_log] ==> #1264000    Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 9.719    Value Loss: 4.418    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 2819448    Buffer Size: 15021      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:33:35,184][train][INFO][train.py>_log] ==> #1265000    Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 10.117   Value Loss: 4.042    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 2821892    Buffer Size: 15006      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:36:54,592][train][INFO][train.py>_log] ==> #1266000    Total Loss: 1.910    [weighted Loss:1.910    Policy Loss: 9.922    Value Loss: 4.199    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 2824458    Buffer Size: 15006      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:40:12,366][train][INFO][train.py>_log] ==> #1267000    Total Loss: 2.546    [weighted Loss:2.546    Policy Loss: 10.007   Value Loss: 4.470    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 2826982    Buffer Size: 15005      Transition Number: 1000.059k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:43:27,126][train][INFO][train.py>_log] ==> #1268000    Total Loss: 2.483    [weighted Loss:2.483    Policy Loss: 10.047   Value Loss: 4.624    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 2829533    Buffer Size: 14988      Transition Number: 1000.298k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:46:42,877][train][INFO][train.py>_log] ==> #1269000    Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 9.703    Value Loss: 4.307    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 2831987    Buffer Size: 14976      Transition Number: 1000.229k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:49:56,327][train][INFO][train.py>_log] ==> #1270000    Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 9.600    Value Loss: 4.345    Reward Loss: 1.747    Consistency Loss: 0.000    ] Replay Episodes Collected: 2834348    Buffer Size: 14971      Transition Number: 1000.383k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:53:13,732][train][INFO][train.py>_log] ==> #1271000    Total Loss: 1.556    [weighted Loss:1.556    Policy Loss: 10.098   Value Loss: 4.416    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 2836889    Buffer Size: 14941      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:56:32,159][train][INFO][train.py>_log] ==> #1272000    Total Loss: 2.432    [weighted Loss:2.432    Policy Loss: 9.768    Value Loss: 4.841    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2839433    Buffer Size: 14934      Transition Number: 1000.304k Batch Size: 256        Lr: 0.00010 
[2022-02-21 23:59:47,622][train][INFO][train.py>_log] ==> #1273000    Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 9.765    Value Loss: 4.785    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2841837    Buffer Size: 14923      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:03:01,948][train][INFO][train.py>_log] ==> #1274000    Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 9.741    Value Loss: 4.296    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 2844382    Buffer Size: 14912      Transition Number: 1000.458k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:06:19,522][train][INFO][train.py>_log] ==> #1275000    Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 9.746    Value Loss: 4.642    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 2846870    Buffer Size: 14898      Transition Number: 1000.316k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:09:36,765][train][INFO][train.py>_log] ==> #1276000    Total Loss: 2.797    [weighted Loss:2.797    Policy Loss: 9.524    Value Loss: 4.473    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 2849297    Buffer Size: 14884      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:12:55,295][train][INFO][train.py>_log] ==> #1277000    Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 9.892    Value Loss: 4.650    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2851875    Buffer Size: 14878      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:16:10,896][train][INFO][train.py>_log] ==> #1278000    Total Loss: 1.783    [weighted Loss:1.783    Policy Loss: 10.029   Value Loss: 4.322    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 2854326    Buffer Size: 14879      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:19:28,112][train][INFO][train.py>_log] ==> #1279000    Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 9.525    Value Loss: 4.644    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 2856824    Buffer Size: 14868      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:22:44,854][train][INFO][train.py>_log] ==> #1280000    Total Loss: 1.429    [weighted Loss:1.429    Policy Loss: 9.487    Value Loss: 4.680    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 2859395    Buffer Size: 14863      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:26:03,929][train][INFO][train.py>_log] ==> #1281000    Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 9.386    Value Loss: 4.589    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 2861955    Buffer Size: 14845      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:29:24,824][train][INFO][train.py>_log] ==> #1282000    Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 9.969    Value Loss: 4.462    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 2864410    Buffer Size: 14834      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:32:42,554][train][INFO][train.py>_log] ==> #1283000    Total Loss: 1.346    [weighted Loss:1.346    Policy Loss: 9.176    Value Loss: 4.662    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2866906    Buffer Size: 14816      Transition Number: 1000.223k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:35:58,518][train][INFO][train.py>_log] ==> #1284000    Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 9.321    Value Loss: 4.709    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 2869503    Buffer Size: 14788      Transition Number: 1000.371k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:39:17,678][train][INFO][train.py>_log] ==> #1285000    Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 9.329    Value Loss: 4.638    Reward Loss: 1.705    Consistency Loss: 0.000    ] Replay Episodes Collected: 2871947    Buffer Size: 14780      Transition Number: 1000.255k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:42:38,050][train][INFO][train.py>_log] ==> #1286000    Total Loss: 1.719    [weighted Loss:1.719    Policy Loss: 9.417    Value Loss: 4.519    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 2874511    Buffer Size: 14772      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:45:58,719][train][INFO][train.py>_log] ==> #1287000    Total Loss: 2.986    [weighted Loss:2.986    Policy Loss: 9.447    Value Loss: 4.224    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 2877036    Buffer Size: 14780      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:49:18,503][train][INFO][train.py>_log] ==> #1288000    Total Loss: 1.562    [weighted Loss:1.562    Policy Loss: 9.092    Value Loss: 4.698    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 2879515    Buffer Size: 14786      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:52:35,020][train][INFO][train.py>_log] ==> #1289000    Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 9.567    Value Loss: 4.727    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 2882038    Buffer Size: 14800      Transition Number: 1000.135k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:55:51,796][train][INFO][train.py>_log] ==> #1290000    Total Loss: 1.660    [weighted Loss:1.660    Policy Loss: 8.959    Value Loss: 4.556    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 2884593    Buffer Size: 14804      Transition Number: 1000.608k Batch Size: 256        Lr: 0.00010 
[2022-02-22 00:59:06,684][train][INFO][train.py>_log] ==> #1291000    Total Loss: 1.746    [weighted Loss:1.746    Policy Loss: 9.200    Value Loss: 4.448    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2887088    Buffer Size: 14793      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:02:23,543][train][INFO][train.py>_log] ==> #1292000    Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 9.345    Value Loss: 4.386    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 2889454    Buffer Size: 14804      Transition Number: 1000.679k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:05:44,329][train][INFO][train.py>_log] ==> #1293000    Total Loss: 1.569    [weighted Loss:1.569    Policy Loss: 8.710    Value Loss: 4.103    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 2892014    Buffer Size: 14812      Transition Number: 1000.455k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:09:02,314][train][INFO][train.py>_log] ==> #1294000    Total Loss: 2.193    [weighted Loss:2.193    Policy Loss: 9.196    Value Loss: 4.309    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 2894526    Buffer Size: 14792      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:12:24,287][train][INFO][train.py>_log] ==> #1295000    Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 9.288    Value Loss: 4.471    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 2897026    Buffer Size: 14791      Transition Number: 1000.398k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:15:43,500][train][INFO][train.py>_log] ==> #1296000    Total Loss: 1.576    [weighted Loss:1.576    Policy Loss: 8.646    Value Loss: 4.578    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 2899549    Buffer Size: 14787      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:19:01,532][train][INFO][train.py>_log] ==> #1297000    Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 8.618    Value Loss: 4.563    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 2901973    Buffer Size: 14770      Transition Number: 1000.329k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:22:22,984][train][INFO][train.py>_log] ==> #1298000    Total Loss: 1.345    [weighted Loss:1.345    Policy Loss: 8.550    Value Loss: 4.279    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 2904395    Buffer Size: 14757      Transition Number: 999.928 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:25:44,856][train][INFO][train.py>_log] ==> #1299000    Total Loss: 1.984    [weighted Loss:1.984    Policy Loss: 8.715    Value Loss: 4.365    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 2906949    Buffer Size: 14771      Transition Number: 1000.252k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:29:04,978][train][INFO][train.py>_log] ==> #1300000    Total Loss: 2.232    [weighted Loss:2.232    Policy Loss: 8.726    Value Loss: 4.634    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 2909491    Buffer Size: 14774      Transition Number: 1000.868k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:32:26,668][train][INFO][train.py>_log] ==> #1301000    Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 8.497    Value Loss: 4.829    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 2911996    Buffer Size: 14787      Transition Number: 1000.385k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:35:48,189][train][INFO][train.py>_log] ==> #1302000    Total Loss: 2.734    [weighted Loss:2.734    Policy Loss: 8.705    Value Loss: 4.795    Reward Loss: 1.592    Consistency Loss: 0.000    ] Replay Episodes Collected: 2914504    Buffer Size: 14798      Transition Number: 1000.203k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:39:08,422][train][INFO][train.py>_log] ==> #1303000    Total Loss: 1.454    [weighted Loss:1.454    Policy Loss: 8.471    Value Loss: 4.565    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 2917068    Buffer Size: 14808      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:42:32,859][train][INFO][train.py>_log] ==> #1304000    Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 8.794    Value Loss: 4.571    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 2919519    Buffer Size: 14830      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:45:55,095][train][INFO][train.py>_log] ==> #1305000    Total Loss: 1.549    [weighted Loss:1.549    Policy Loss: 8.410    Value Loss: 4.865    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 2922037    Buffer Size: 14805      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:49:17,035][train][INFO][train.py>_log] ==> #1306000    Total Loss: 1.969    [weighted Loss:1.969    Policy Loss: 8.491    Value Loss: 4.551    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 2924657    Buffer Size: 14809      Transition Number: 1000.564k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:52:37,167][train][INFO][train.py>_log] ==> #1307000    Total Loss: 2.394    [weighted Loss:2.394    Policy Loss: 8.518    Value Loss: 4.399    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 2927132    Buffer Size: 14786      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:55:59,018][train][INFO][train.py>_log] ==> #1308000    Total Loss: 1.303    [weighted Loss:1.303    Policy Loss: 8.376    Value Loss: 4.634    Reward Loss: 1.725    Consistency Loss: 0.000    ] Replay Episodes Collected: 2929526    Buffer Size: 14795      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 01:59:21,475][train][INFO][train.py>_log] ==> #1309000    Total Loss: 2.834    [weighted Loss:2.834    Policy Loss: 8.382    Value Loss: 4.430    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 2932159    Buffer Size: 14788      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:02:41,293][train][INFO][train.py>_log] ==> #1310000    Total Loss: 2.740    [weighted Loss:2.740    Policy Loss: 8.703    Value Loss: 4.706    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 2934658    Buffer Size: 14781      Transition Number: 1000.923k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:06:03,588][train][INFO][train.py>_log] ==> #1311000    Total Loss: 2.398    [weighted Loss:2.398    Policy Loss: 9.010    Value Loss: 4.378    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 2937086    Buffer Size: 14778      Transition Number: 1000.310k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:09:25,028][train][INFO][train.py>_log] ==> #1312000    Total Loss: 1.076    [weighted Loss:1.076    Policy Loss: 8.918    Value Loss: 4.840    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 2939639    Buffer Size: 14782      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:12:45,495][train][INFO][train.py>_log] ==> #1313000    Total Loss: 2.570    [weighted Loss:2.570    Policy Loss: 8.304    Value Loss: 4.918    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 2942108    Buffer Size: 14787      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:16:05,421][train][INFO][train.py>_log] ==> #1314000    Total Loss: 2.107    [weighted Loss:2.107    Policy Loss: 8.982    Value Loss: 4.413    Reward Loss: 1.666    Consistency Loss: 0.000    ] Replay Episodes Collected: 2944585    Buffer Size: 14788      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:19:26,154][train][INFO][train.py>_log] ==> #1315000    Total Loss: 1.904    [weighted Loss:1.904    Policy Loss: 8.736    Value Loss: 4.726    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 2947170    Buffer Size: 14787      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:22:47,502][train][INFO][train.py>_log] ==> #1316000    Total Loss: 2.158    [weighted Loss:2.158    Policy Loss: 8.804    Value Loss: 4.516    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 2949737    Buffer Size: 14795      Transition Number: 1000.481k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:26:06,533][train][INFO][train.py>_log] ==> #1317000    Total Loss: 2.308    [weighted Loss:2.308    Policy Loss: 8.940    Value Loss: 4.664    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 2952193    Buffer Size: 14798      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:29:22,098][train][INFO][train.py>_log] ==> #1318000    Total Loss: 2.742    [weighted Loss:2.742    Policy Loss: 8.443    Value Loss: 4.634    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 2954634    Buffer Size: 14810      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:32:40,613][train][INFO][train.py>_log] ==> #1319000    Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 8.761    Value Loss: 4.757    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 2957192    Buffer Size: 14803      Transition Number: 1000.394k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:36:00,748][train][INFO][train.py>_log] ==> #1320000    Total Loss: 1.882    [weighted Loss:1.882    Policy Loss: 8.639    Value Loss: 4.950    Reward Loss: 1.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 2959653    Buffer Size: 14798      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:39:21,544][train][INFO][train.py>_log] ==> #1321000    Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 8.736    Value Loss: 4.507    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2962163    Buffer Size: 14795      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:42:48,502][train][INFO][train.py>_log] ==> #1322000    Total Loss: 1.264    [weighted Loss:1.264    Policy Loss: 8.565    Value Loss: 4.636    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 2964827    Buffer Size: 14788      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:46:13,207][train][INFO][train.py>_log] ==> #1323000    Total Loss: 1.391    [weighted Loss:1.391    Policy Loss: 8.844    Value Loss: 4.669    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 2967420    Buffer Size: 14796      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:49:32,144][train][INFO][train.py>_log] ==> #1324000    Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 8.477    Value Loss: 4.705    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 2969799    Buffer Size: 14797      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:52:50,382][train][INFO][train.py>_log] ==> #1325000    Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 8.946    Value Loss: 4.770    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 2972339    Buffer Size: 14823      Transition Number: 1000.389k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:56:10,393][train][INFO][train.py>_log] ==> #1326000    Total Loss: 2.553    [weighted Loss:2.553    Policy Loss: 8.888    Value Loss: 4.517    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2974845    Buffer Size: 14843      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00010 
[2022-02-22 02:59:29,380][train][INFO][train.py>_log] ==> #1327000    Total Loss: 0.951    [weighted Loss:0.951    Policy Loss: 9.045    Value Loss: 4.487    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 2977340    Buffer Size: 14858      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:02:50,964][train][INFO][train.py>_log] ==> #1328000    Total Loss: 1.514    [weighted Loss:1.514    Policy Loss: 8.924    Value Loss: 4.880    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 2979955    Buffer Size: 14866      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:06:10,208][train][INFO][train.py>_log] ==> #1329000    Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 8.828    Value Loss: 4.312    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 2982432    Buffer Size: 14868      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:09:28,484][train][INFO][train.py>_log] ==> #1330000    Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 9.068    Value Loss: 4.887    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 2984908    Buffer Size: 14883      Transition Number: 1000.390k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:12:46,541][train][INFO][train.py>_log] ==> #1331000    Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 9.213    Value Loss: 4.392    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 2987375    Buffer Size: 14883      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:16:02,973][train][INFO][train.py>_log] ==> #1332000    Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 8.821    Value Loss: 4.686    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 2989896    Buffer Size: 14878      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:19:24,417][train][INFO][train.py>_log] ==> #1333000    Total Loss: 2.311    [weighted Loss:2.311    Policy Loss: 9.174    Value Loss: 4.819    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 2992439    Buffer Size: 14890      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:22:41,705][train][INFO][train.py>_log] ==> #1334000    Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 9.147    Value Loss: 4.474    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 2994919    Buffer Size: 14906      Transition Number: 1000.335k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:26:02,921][train][INFO][train.py>_log] ==> #1335000    Total Loss: 2.164    [weighted Loss:2.164    Policy Loss: 8.916    Value Loss: 4.497    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 2997484    Buffer Size: 14912      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:29:21,185][train][INFO][train.py>_log] ==> #1336000    Total Loss: 1.726    [weighted Loss:1.726    Policy Loss: 9.451    Value Loss: 4.494    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 2999957    Buffer Size: 14920      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:32:38,977][train][INFO][train.py>_log] ==> #1337000    Total Loss: 0.893    [weighted Loss:0.893    Policy Loss: 9.711    Value Loss: 4.448    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 3002504    Buffer Size: 14932      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:35:58,345][train][INFO][train.py>_log] ==> #1338000    Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 9.764    Value Loss: 4.377    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 3005000    Buffer Size: 14944      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:39:21,297][train][INFO][train.py>_log] ==> #1339000    Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 9.314    Value Loss: 4.305    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 3007564    Buffer Size: 14963      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:42:36,169][train][INFO][train.py>_log] ==> #1340000    Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 9.298    Value Loss: 4.372    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 3010008    Buffer Size: 15016      Transition Number: 1000.578k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:45:57,628][train][INFO][train.py>_log] ==> #1341000    Total Loss: 1.505    [weighted Loss:1.505    Policy Loss: 9.459    Value Loss: 4.544    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 3012546    Buffer Size: 15050      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:49:15,173][train][INFO][train.py>_log] ==> #1342000    Total Loss: 2.159    [weighted Loss:2.159    Policy Loss: 9.806    Value Loss: 4.337    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 3015048    Buffer Size: 15089      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:52:34,912][train][INFO][train.py>_log] ==> #1343000    Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 9.669    Value Loss: 4.533    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 3017625    Buffer Size: 15127      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:55:51,861][train][INFO][train.py>_log] ==> #1344000    Total Loss: 2.034    [weighted Loss:2.034    Policy Loss: 9.551    Value Loss: 4.677    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 3020082    Buffer Size: 15159      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 03:59:09,346][train][INFO][train.py>_log] ==> #1345000    Total Loss: 2.460    [weighted Loss:2.460    Policy Loss: 9.827    Value Loss: 4.560    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 3022584    Buffer Size: 15197      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:02:26,598][train][INFO][train.py>_log] ==> #1346000    Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 10.043   Value Loss: 4.543    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 3025143    Buffer Size: 15228      Transition Number: 1000.553k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:05:50,161][train][INFO][train.py>_log] ==> #1347000    Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 10.275   Value Loss: 4.441    Reward Loss: 1.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 3027708    Buffer Size: 15260      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:09:12,260][train][INFO][train.py>_log] ==> #1348000    Total Loss: 1.739    [weighted Loss:1.739    Policy Loss: 9.730    Value Loss: 4.639    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 3030256    Buffer Size: 15306      Transition Number: 1000.337k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:12:34,934][train][INFO][train.py>_log] ==> #1349000    Total Loss: 2.989    [weighted Loss:2.989    Policy Loss: 10.010   Value Loss: 4.284    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 3032769    Buffer Size: 15339      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:16:01,226][train][INFO][train.py>_log] ==> #1350000    Total Loss: 1.335    [weighted Loss:1.335    Policy Loss: 10.197   Value Loss: 4.169    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 3035383    Buffer Size: 15404      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:19:21,349][train][INFO][train.py>_log] ==> #1351000    Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 9.821    Value Loss: 4.332    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 3037945    Buffer Size: 15444      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:22:43,403][train][INFO][train.py>_log] ==> #1352000    Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 9.908    Value Loss: 4.215    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 3040457    Buffer Size: 15478      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:26:03,547][train][INFO][train.py>_log] ==> #1353000    Total Loss: 1.359    [weighted Loss:1.359    Policy Loss: 9.660    Value Loss: 4.428    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 3043043    Buffer Size: 15532      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:29:24,207][train][INFO][train.py>_log] ==> #1354000    Total Loss: 2.172    [weighted Loss:2.172    Policy Loss: 10.168   Value Loss: 4.359    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 3045606    Buffer Size: 15546      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:32:43,840][train][INFO][train.py>_log] ==> #1355000    Total Loss: 2.377    [weighted Loss:2.377    Policy Loss: 10.105   Value Loss: 4.397    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 3048104    Buffer Size: 15580      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:36:03,675][train][INFO][train.py>_log] ==> #1356000    Total Loss: 1.375    [weighted Loss:1.375    Policy Loss: 10.089   Value Loss: 4.575    Reward Loss: 1.773    Consistency Loss: 0.000    ] Replay Episodes Collected: 3050623    Buffer Size: 15597      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:39:26,948][train][INFO][train.py>_log] ==> #1357000    Total Loss: 2.100    [weighted Loss:2.100    Policy Loss: 10.183   Value Loss: 4.193    Reward Loss: 1.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 3053150    Buffer Size: 15609      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:42:49,766][train][INFO][train.py>_log] ==> #1358000    Total Loss: 2.306    [weighted Loss:2.306    Policy Loss: 10.194   Value Loss: 4.151    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 3055762    Buffer Size: 15621      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:46:11,748][train][INFO][train.py>_log] ==> #1359000    Total Loss: 1.806    [weighted Loss:1.806    Policy Loss: 10.083   Value Loss: 4.515    Reward Loss: 1.870    Consistency Loss: 0.000    ] Replay Episodes Collected: 3058315    Buffer Size: 15602      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:49:33,577][train][INFO][train.py>_log] ==> #1360000    Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 9.593    Value Loss: 4.572    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 3060820    Buffer Size: 15609      Transition Number: 1000.314k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:52:55,024][train][INFO][train.py>_log] ==> #1361000    Total Loss: 2.716    [weighted Loss:2.716    Policy Loss: 10.090   Value Loss: 4.136    Reward Loss: 1.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 3063456    Buffer Size: 15589      Transition Number: 1000.670k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:56:17,347][train][INFO][train.py>_log] ==> #1362000    Total Loss: 2.441    [weighted Loss:2.441    Policy Loss: 9.672    Value Loss: 4.148    Reward Loss: 1.800    Consistency Loss: 0.000    ] Replay Episodes Collected: 3065924    Buffer Size: 15549      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 04:59:39,886][train][INFO][train.py>_log] ==> #1363000    Total Loss: 2.351    [weighted Loss:2.351    Policy Loss: 9.755    Value Loss: 4.021    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 3068440    Buffer Size: 15521      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:03:02,826][train][INFO][train.py>_log] ==> #1364000    Total Loss: 1.188    [weighted Loss:1.188    Policy Loss: 10.111   Value Loss: 4.506    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 3071102    Buffer Size: 15494      Transition Number: 1000.170k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:06:26,198][train][INFO][train.py>_log] ==> #1365000    Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 10.201   Value Loss: 4.213    Reward Loss: 1.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 3073647    Buffer Size: 15463      Transition Number: 1000.130k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:09:48,124][train][INFO][train.py>_log] ==> #1366000    Total Loss: 1.154    [weighted Loss:1.154    Policy Loss: 9.905    Value Loss: 4.263    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 3076237    Buffer Size: 15414      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:13:13,175][train][INFO][train.py>_log] ==> #1367000    Total Loss: 1.965    [weighted Loss:1.965    Policy Loss: 9.682    Value Loss: 4.619    Reward Loss: 1.808    Consistency Loss: 0.000    ] Replay Episodes Collected: 3078792    Buffer Size: 15389      Transition Number: 1000.145k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:16:36,260][train][INFO][train.py>_log] ==> #1368000    Total Loss: 2.503    [weighted Loss:2.503    Policy Loss: 9.963    Value Loss: 4.310    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 3081359    Buffer Size: 15357      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:19:57,190][train][INFO][train.py>_log] ==> #1369000    Total Loss: 2.706    [weighted Loss:2.706    Policy Loss: 9.860    Value Loss: 4.052    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 3083956    Buffer Size: 15323      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:23:22,710][train][INFO][train.py>_log] ==> #1370000    Total Loss: 2.851    [weighted Loss:2.851    Policy Loss: 9.798    Value Loss: 4.352    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 3086490    Buffer Size: 15311      Transition Number: 1000.193k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:26:47,258][train][INFO][train.py>_log] ==> #1371000    Total Loss: 3.044    [weighted Loss:3.044    Policy Loss: 9.778    Value Loss: 4.108    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 3089148    Buffer Size: 15293      Transition Number: 1000.298k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:30:08,167][train][INFO][train.py>_log] ==> #1372000    Total Loss: 1.916    [weighted Loss:1.916    Policy Loss: 9.970    Value Loss: 4.198    Reward Loss: 1.776    Consistency Loss: 0.000    ] Replay Episodes Collected: 3091682    Buffer Size: 15253      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:33:31,408][train][INFO][train.py>_log] ==> #1373000    Total Loss: 2.313    [weighted Loss:2.313    Policy Loss: 9.708    Value Loss: 4.089    Reward Loss: 1.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 3094236    Buffer Size: 15253      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:36:54,238][train][INFO][train.py>_log] ==> #1374000    Total Loss: 3.221    [weighted Loss:3.221    Policy Loss: 9.983    Value Loss: 4.185    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 3096806    Buffer Size: 15247      Transition Number: 1000.279k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:40:19,044][train][INFO][train.py>_log] ==> #1375000    Total Loss: 1.273    [weighted Loss:1.273    Policy Loss: 9.875    Value Loss: 4.561    Reward Loss: 1.866    Consistency Loss: 0.000    ] Replay Episodes Collected: 3099346    Buffer Size: 15239      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:43:39,073][train][INFO][train.py>_log] ==> #1376000    Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 9.640    Value Loss: 4.496    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 3101962    Buffer Size: 15238      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:47:02,034][train][INFO][train.py>_log] ==> #1377000    Total Loss: 2.550    [weighted Loss:2.550    Policy Loss: 9.762    Value Loss: 4.371    Reward Loss: 1.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 3104563    Buffer Size: 15223      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:50:24,623][train][INFO][train.py>_log] ==> #1378000    Total Loss: 2.200    [weighted Loss:2.200    Policy Loss: 9.577    Value Loss: 4.384    Reward Loss: 1.780    Consistency Loss: 0.000    ] Replay Episodes Collected: 3107103    Buffer Size: 15223      Transition Number: 1000.211k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:53:48,933][train][INFO][train.py>_log] ==> #1379000    Total Loss: 2.722    [weighted Loss:2.722    Policy Loss: 10.048   Value Loss: 4.266    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 3109599    Buffer Size: 15214      Transition Number: 1000.220k Batch Size: 256        Lr: 0.00010 
[2022-02-22 05:57:14,554][train][INFO][train.py>_log] ==> #1380000    Total Loss: 0.552    [weighted Loss:0.552    Policy Loss: 10.147   Value Loss: 4.119    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 3112263    Buffer Size: 15193      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:00:38,194][train][INFO][train.py>_log] ==> #1381000    Total Loss: 2.649    [weighted Loss:2.649    Policy Loss: 9.503    Value Loss: 4.254    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 3114896    Buffer Size: 15165      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:04:03,442][train][INFO][train.py>_log] ==> #1382000    Total Loss: 2.032    [weighted Loss:2.032    Policy Loss: 9.739    Value Loss: 4.131    Reward Loss: 1.695    Consistency Loss: 0.000    ] Replay Episodes Collected: 3117407    Buffer Size: 15142      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:07:24,184][train][INFO][train.py>_log] ==> #1383000    Total Loss: 2.705    [weighted Loss:2.705    Policy Loss: 9.952    Value Loss: 4.101    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 3120044    Buffer Size: 15126      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:10:46,621][train][INFO][train.py>_log] ==> #1384000    Total Loss: 2.384    [weighted Loss:2.384    Policy Loss: 9.977    Value Loss: 4.348    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 3122560    Buffer Size: 15129      Transition Number: 1000.424k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:14:12,824][train][INFO][train.py>_log] ==> #1385000    Total Loss: 1.621    [weighted Loss:1.621    Policy Loss: 9.814    Value Loss: 3.939    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 3125182    Buffer Size: 15105      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:17:38,649][train][INFO][train.py>_log] ==> #1386000    Total Loss: 1.368    [weighted Loss:1.368    Policy Loss: 9.653    Value Loss: 4.564    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 3127820    Buffer Size: 15120      Transition Number: 1000.317k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:21:01,864][train][INFO][train.py>_log] ==> #1387000    Total Loss: 1.778    [weighted Loss:1.778    Policy Loss: 9.977    Value Loss: 4.032    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 3130424    Buffer Size: 15104      Transition Number: 1000.190k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:24:27,707][train][INFO][train.py>_log] ==> #1388000    Total Loss: 1.940    [weighted Loss:1.940    Policy Loss: 9.935    Value Loss: 4.180    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 3133034    Buffer Size: 15089      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:27:48,946][train][INFO][train.py>_log] ==> #1389000    Total Loss: 0.986    [weighted Loss:0.986    Policy Loss: 9.379    Value Loss: 4.293    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 3135501    Buffer Size: 15074      Transition Number: 1000.175k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:31:13,336][train][INFO][train.py>_log] ==> #1390000    Total Loss: 2.212    [weighted Loss:2.212    Policy Loss: 9.491    Value Loss: 4.326    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 3138146    Buffer Size: 15049      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:34:38,501][train][INFO][train.py>_log] ==> #1391000    Total Loss: 1.884    [weighted Loss:1.884    Policy Loss: 9.711    Value Loss: 4.305    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 3140698    Buffer Size: 15028      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:38:04,213][train][INFO][train.py>_log] ==> #1392000    Total Loss: 2.169    [weighted Loss:2.169    Policy Loss: 9.510    Value Loss: 4.268    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 3143373    Buffer Size: 14989      Transition Number: 1000.144k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:41:26,127][train][INFO][train.py>_log] ==> #1393000    Total Loss: 1.387    [weighted Loss:1.387    Policy Loss: 9.431    Value Loss: 4.172    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 3145850    Buffer Size: 14965      Transition Number: 1000.016k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:44:48,396][train][INFO][train.py>_log] ==> #1394000    Total Loss: 1.779    [weighted Loss:1.779    Policy Loss: 9.765    Value Loss: 4.180    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 3148443    Buffer Size: 14946      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:48:15,259][train][INFO][train.py>_log] ==> #1395000    Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 9.485    Value Loss: 4.304    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 3150957    Buffer Size: 14919      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:51:39,617][train][INFO][train.py>_log] ==> #1396000    Total Loss: 3.091    [weighted Loss:3.091    Policy Loss: 9.405    Value Loss: 4.554    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 3153595    Buffer Size: 14902      Transition Number: 1000.093k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:55:02,720][train][INFO][train.py>_log] ==> #1397000    Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 9.129    Value Loss: 4.059    Reward Loss: 1.718    Consistency Loss: 0.000    ] Replay Episodes Collected: 3156205    Buffer Size: 14889      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 06:58:28,528][train][INFO][train.py>_log] ==> #1398000    Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 9.430    Value Loss: 4.528    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 3158813    Buffer Size: 14883      Transition Number: 1000.187k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:01:52,311][train][INFO][train.py>_log] ==> #1399000    Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 9.360    Value Loss: 4.456    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 3161365    Buffer Size: 14868      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:05:15,348][train][INFO][train.py>_log] ==> #1400000    Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 8.889    Value Loss: 4.299    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 3163839    Buffer Size: 14865      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:08:41,955][train][INFO][train.py>_log] ==> #1401000    Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 9.523    Value Loss: 4.291    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 3166584    Buffer Size: 14868      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:12:05,496][train][INFO][train.py>_log] ==> #1402000    Total Loss: 2.170    [weighted Loss:2.170    Policy Loss: 9.089    Value Loss: 4.312    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 3169081    Buffer Size: 14867      Transition Number: 1000.357k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:15:28,403][train][INFO][train.py>_log] ==> #1403000    Total Loss: 2.470    [weighted Loss:2.470    Policy Loss: 9.644    Value Loss: 4.381    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 3171665    Buffer Size: 14852      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:18:53,100][train][INFO][train.py>_log] ==> #1404000    Total Loss: 2.457    [weighted Loss:2.457    Policy Loss: 9.352    Value Loss: 4.251    Reward Loss: 1.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 3174197    Buffer Size: 14848      Transition Number: 1000.203k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:22:17,943][train][INFO][train.py>_log] ==> #1405000    Total Loss: 2.769    [weighted Loss:2.769    Policy Loss: 9.457    Value Loss: 4.354    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 3176737    Buffer Size: 14846      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:25:43,935][train][INFO][train.py>_log] ==> #1406000    Total Loss: 2.413    [weighted Loss:2.413    Policy Loss: 9.249    Value Loss: 4.302    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 3179310    Buffer Size: 14852      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:29:05,526][train][INFO][train.py>_log] ==> #1407000    Total Loss: 1.237    [weighted Loss:1.237    Policy Loss: 9.261    Value Loss: 4.561    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 3181924    Buffer Size: 14833      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:32:27,434][train][INFO][train.py>_log] ==> #1408000    Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 9.386    Value Loss: 4.134    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 3184512    Buffer Size: 14842      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:35:48,115][train][INFO][train.py>_log] ==> #1409000    Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 9.354    Value Loss: 4.579    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 3187029    Buffer Size: 14855      Transition Number: 1000.346k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:39:09,064][train][INFO][train.py>_log] ==> #1410000    Total Loss: 1.132    [weighted Loss:1.132    Policy Loss: 8.905    Value Loss: 4.528    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 3189615    Buffer Size: 14846      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:42:28,988][train][INFO][train.py>_log] ==> #1411000    Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 9.160    Value Loss: 4.325    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 3192148    Buffer Size: 14831      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:45:50,607][train][INFO][train.py>_log] ==> #1412000    Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 8.546    Value Loss: 4.417    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 3194679    Buffer Size: 14828      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:49:14,292][train][INFO][train.py>_log] ==> #1413000    Total Loss: 1.294    [weighted Loss:1.294    Policy Loss: 8.754    Value Loss: 4.748    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 3197291    Buffer Size: 14830      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:52:36,399][train][INFO][train.py>_log] ==> #1414000    Total Loss: 1.717    [weighted Loss:1.717    Policy Loss: 8.974    Value Loss: 4.433    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 3199803    Buffer Size: 14803      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:55:59,199][train][INFO][train.py>_log] ==> #1415000    Total Loss: 2.020    [weighted Loss:2.020    Policy Loss: 8.584    Value Loss: 4.275    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 3202423    Buffer Size: 14798      Transition Number: 1000.295k Batch Size: 256        Lr: 0.00010 
[2022-02-22 07:59:17,736][train][INFO][train.py>_log] ==> #1416000    Total Loss: 0.624    [weighted Loss:0.624    Policy Loss: 8.871    Value Loss: 4.408    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 3204961    Buffer Size: 14776      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:02:39,304][train][INFO][train.py>_log] ==> #1417000    Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 8.810    Value Loss: 4.420    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 3207490    Buffer Size: 14759      Transition Number: 1000.133k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:06:05,499][train][INFO][train.py>_log] ==> #1418000    Total Loss: 1.804    [weighted Loss:1.804    Policy Loss: 8.914    Value Loss: 4.175    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 3210095    Buffer Size: 14761      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:09:24,775][train][INFO][train.py>_log] ==> #1419000    Total Loss: 0.945    [weighted Loss:0.945    Policy Loss: 8.567    Value Loss: 4.567    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 3212616    Buffer Size: 14748      Transition Number: 1000.509k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:12:47,277][train][INFO][train.py>_log] ==> #1420000    Total Loss: 1.828    [weighted Loss:1.828    Policy Loss: 8.763    Value Loss: 4.446    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 3215203    Buffer Size: 14737      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:16:09,823][train][INFO][train.py>_log] ==> #1421000    Total Loss: 2.361    [weighted Loss:2.361    Policy Loss: 8.645    Value Loss: 4.437    Reward Loss: 1.611    Consistency Loss: 0.000    ] Replay Episodes Collected: 3217781    Buffer Size: 14711      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:19:31,867][train][INFO][train.py>_log] ==> #1422000    Total Loss: 2.655    [weighted Loss:2.655    Policy Loss: 8.528    Value Loss: 4.548    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 3220265    Buffer Size: 14712      Transition Number: 1000.193k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:22:54,434][train][INFO][train.py>_log] ==> #1423000    Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 8.225    Value Loss: 4.704    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 3222856    Buffer Size: 14709      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:26:16,760][train][INFO][train.py>_log] ==> #1424000    Total Loss: 1.887    [weighted Loss:1.887    Policy Loss: 8.074    Value Loss: 4.922    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 3225427    Buffer Size: 14707      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:29:37,460][train][INFO][train.py>_log] ==> #1425000    Total Loss: 1.011    [weighted Loss:1.011    Policy Loss: 8.044    Value Loss: 4.549    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 3227981    Buffer Size: 14709      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:33:00,528][train][INFO][train.py>_log] ==> #1426000    Total Loss: 1.887    [weighted Loss:1.887    Policy Loss: 8.513    Value Loss: 4.588    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 3230572    Buffer Size: 14725      Transition Number: 1000.421k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:36:21,184][train][INFO][train.py>_log] ==> #1427000    Total Loss: 0.529    [weighted Loss:0.529    Policy Loss: 8.464    Value Loss: 4.642    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 3233086    Buffer Size: 14735      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:39:41,172][train][INFO][train.py>_log] ==> #1428000    Total Loss: 1.411    [weighted Loss:1.411    Policy Loss: 8.400    Value Loss: 4.405    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 3235680    Buffer Size: 14742      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:43:02,372][train][INFO][train.py>_log] ==> #1429000    Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 8.273    Value Loss: 4.528    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 3238155    Buffer Size: 14743      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:46:26,627][train][INFO][train.py>_log] ==> #1430000    Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 8.252    Value Loss: 4.677    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 3240750    Buffer Size: 14745      Transition Number: 1000.038k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:49:48,292][train][INFO][train.py>_log] ==> #1431000    Total Loss: 1.020    [weighted Loss:1.020    Policy Loss: 7.939    Value Loss: 4.555    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 3243363    Buffer Size: 14763      Transition Number: 1000.009k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:53:08,587][train][INFO][train.py>_log] ==> #1432000    Total Loss: 1.981    [weighted Loss:1.981    Policy Loss: 8.621    Value Loss: 4.940    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 3245885    Buffer Size: 14778      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:56:28,998][train][INFO][train.py>_log] ==> #1433000    Total Loss: 1.408    [weighted Loss:1.408    Policy Loss: 8.305    Value Loss: 4.731    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 3248448    Buffer Size: 14803      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00010 
[2022-02-22 08:59:51,146][train][INFO][train.py>_log] ==> #1434000    Total Loss: 2.564    [weighted Loss:2.564    Policy Loss: 8.282    Value Loss: 4.875    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 3250999    Buffer Size: 14822      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:03:12,670][train][INFO][train.py>_log] ==> #1435000    Total Loss: 2.489    [weighted Loss:2.489    Policy Loss: 8.671    Value Loss: 4.725    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 3253528    Buffer Size: 14862      Transition Number: 1000.138k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:06:36,331][train][INFO][train.py>_log] ==> #1436000    Total Loss: 2.639    [weighted Loss:2.639    Policy Loss: 8.375    Value Loss: 5.057    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 3256114    Buffer Size: 14873      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:09:58,587][train][INFO][train.py>_log] ==> #1437000    Total Loss: 1.724    [weighted Loss:1.724    Policy Loss: 8.264    Value Loss: 4.860    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 3258688    Buffer Size: 14884      Transition Number: 1000.115k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:13:20,232][train][INFO][train.py>_log] ==> #1438000    Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 8.001    Value Loss: 4.630    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 3261296    Buffer Size: 14867      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:16:45,452][train][INFO][train.py>_log] ==> #1439000    Total Loss: 1.867    [weighted Loss:1.867    Policy Loss: 8.226    Value Loss: 4.626    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 3263774    Buffer Size: 14862      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:20:08,857][train][INFO][train.py>_log] ==> #1440000    Total Loss: 1.821    [weighted Loss:1.821    Policy Loss: 8.212    Value Loss: 4.504    Reward Loss: 1.531    Consistency Loss: 0.000    ] Replay Episodes Collected: 3266352    Buffer Size: 14840      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:23:32,450][train][INFO][train.py>_log] ==> #1441000    Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 8.062    Value Loss: 4.861    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 3268900    Buffer Size: 14827      Transition Number: 1000.602k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:26:53,273][train][INFO][train.py>_log] ==> #1442000    Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 8.237    Value Loss: 4.529    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 3271512    Buffer Size: 14810      Transition Number: 1000.196k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:30:15,779][train][INFO][train.py>_log] ==> #1443000    Total Loss: 0.876    [weighted Loss:0.876    Policy Loss: 8.007    Value Loss: 4.345    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 3274048    Buffer Size: 14790      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:33:38,323][train][INFO][train.py>_log] ==> #1444000    Total Loss: 1.382    [weighted Loss:1.382    Policy Loss: 7.923    Value Loss: 4.852    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 3276591    Buffer Size: 14790      Transition Number: 1000.228k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:37:01,896][train][INFO][train.py>_log] ==> #1445000    Total Loss: 1.687    [weighted Loss:1.687    Policy Loss: 7.468    Value Loss: 5.004    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 3279142    Buffer Size: 14787      Transition Number: 1000.013k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:40:25,535][train][INFO][train.py>_log] ==> #1446000    Total Loss: 1.446    [weighted Loss:1.446    Policy Loss: 7.999    Value Loss: 4.530    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 3281737    Buffer Size: 14780      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:43:47,953][train][INFO][train.py>_log] ==> #1447000    Total Loss: 2.128    [weighted Loss:2.128    Policy Loss: 7.794    Value Loss: 4.686    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 3284237    Buffer Size: 14799      Transition Number: 1000.249k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:47:09,025][train][INFO][train.py>_log] ==> #1448000    Total Loss: 1.815    [weighted Loss:1.815    Policy Loss: 8.125    Value Loss: 4.528    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 3286797    Buffer Size: 14776      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:50:31,773][train][INFO][train.py>_log] ==> #1449000    Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 8.070    Value Loss: 4.933    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 3289392    Buffer Size: 14789      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:53:54,901][train][INFO][train.py>_log] ==> #1450000    Total Loss: 1.984    [weighted Loss:1.984    Policy Loss: 8.070    Value Loss: 4.925    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 3291977    Buffer Size: 14804      Transition Number: 999.963 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 09:57:15,410][train][INFO][train.py>_log] ==> #1451000    Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 7.748    Value Loss: 4.680    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 3294514    Buffer Size: 14799      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:00:40,162][train][INFO][train.py>_log] ==> #1452000    Total Loss: 1.320    [weighted Loss:1.320    Policy Loss: 7.749    Value Loss: 4.845    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 3297078    Buffer Size: 14801      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:03:59,464][train][INFO][train.py>_log] ==> #1453000    Total Loss: 1.959    [weighted Loss:1.959    Policy Loss: 7.976    Value Loss: 4.588    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 3299625    Buffer Size: 14783      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:07:21,117][train][INFO][train.py>_log] ==> #1454000    Total Loss: 1.007    [weighted Loss:1.007    Policy Loss: 8.008    Value Loss: 4.573    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 3302181    Buffer Size: 14778      Transition Number: 1000.074k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:10:44,184][train][INFO][train.py>_log] ==> #1455000    Total Loss: 1.950    [weighted Loss:1.950    Policy Loss: 7.936    Value Loss: 4.585    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 3304780    Buffer Size: 14765      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:14:07,952][train][INFO][train.py>_log] ==> #1456000    Total Loss: 2.104    [weighted Loss:2.104    Policy Loss: 7.752    Value Loss: 4.741    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 3307370    Buffer Size: 14740      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:17:28,057][train][INFO][train.py>_log] ==> #1457000    Total Loss: 0.855    [weighted Loss:0.855    Policy Loss: 7.309    Value Loss: 4.614    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 3309824    Buffer Size: 14727      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:20:51,091][train][INFO][train.py>_log] ==> #1458000    Total Loss: 0.932    [weighted Loss:0.932    Policy Loss: 7.694    Value Loss: 4.530    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 3312410    Buffer Size: 14747      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:24:13,677][train][INFO][train.py>_log] ==> #1459000    Total Loss: 1.600    [weighted Loss:1.600    Policy Loss: 7.703    Value Loss: 4.333    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 3314979    Buffer Size: 14756      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:27:38,058][train][INFO][train.py>_log] ==> #1460000    Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 7.988    Value Loss: 4.365    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 3317630    Buffer Size: 14748      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:31:03,367][train][INFO][train.py>_log] ==> #1461000    Total Loss: 1.794    [weighted Loss:1.794    Policy Loss: 7.616    Value Loss: 4.884    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 3320168    Buffer Size: 14754      Transition Number: 1000.297k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:34:27,715][train][INFO][train.py>_log] ==> #1462000    Total Loss: 1.006    [weighted Loss:1.006    Policy Loss: 7.352    Value Loss: 4.696    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 3322776    Buffer Size: 14766      Transition Number: 1000.225k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:37:50,499][train][INFO][train.py>_log] ==> #1463000    Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 7.794    Value Loss: 4.670    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 3325359    Buffer Size: 14772      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:41:14,037][train][INFO][train.py>_log] ==> #1464000    Total Loss: 2.133    [weighted Loss:2.133    Policy Loss: 7.935    Value Loss: 4.382    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 3327868    Buffer Size: 14774      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:44:39,272][train][INFO][train.py>_log] ==> #1465000    Total Loss: 1.803    [weighted Loss:1.803    Policy Loss: 7.406    Value Loss: 4.696    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 3330601    Buffer Size: 14763      Transition Number: 1000.416k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:48:03,535][train][INFO][train.py>_log] ==> #1466000    Total Loss: 0.866    [weighted Loss:0.866    Policy Loss: 7.606    Value Loss: 4.629    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 3333121    Buffer Size: 14754      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:51:28,702][train][INFO][train.py>_log] ==> #1467000    Total Loss: 1.914    [weighted Loss:1.914    Policy Loss: 7.656    Value Loss: 4.619    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 3335743    Buffer Size: 14768      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:54:51,850][train][INFO][train.py>_log] ==> #1468000    Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 8.181    Value Loss: 4.486    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 3338345    Buffer Size: 14762      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 10:58:15,332][train][INFO][train.py>_log] ==> #1469000    Total Loss: 2.304    [weighted Loss:2.304    Policy Loss: 8.146    Value Loss: 4.557    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 3340841    Buffer Size: 14772      Transition Number: 1000.361k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:01:36,392][train][INFO][train.py>_log] ==> #1470000    Total Loss: 1.452    [weighted Loss:1.452    Policy Loss: 7.913    Value Loss: 4.839    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 3343372    Buffer Size: 14767      Transition Number: 1000.432k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:04:58,438][train][INFO][train.py>_log] ==> #1471000    Total Loss: 1.586    [weighted Loss:1.586    Policy Loss: 8.279    Value Loss: 4.581    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 3346004    Buffer Size: 14753      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:08:22,067][train][INFO][train.py>_log] ==> #1472000    Total Loss: 1.295    [weighted Loss:1.295    Policy Loss: 8.171    Value Loss: 4.503    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 3348513    Buffer Size: 14763      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:11:43,352][train][INFO][train.py>_log] ==> #1473000    Total Loss: 1.644    [weighted Loss:1.644    Policy Loss: 8.437    Value Loss: 4.783    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 3351060    Buffer Size: 14758      Transition Number: 1000.100k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:15:05,439][train][INFO][train.py>_log] ==> #1474000    Total Loss: 1.656    [weighted Loss:1.656    Policy Loss: 8.088    Value Loss: 4.474    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 3353659    Buffer Size: 14738      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:18:28,076][train][INFO][train.py>_log] ==> #1475000    Total Loss: 2.816    [weighted Loss:2.816    Policy Loss: 8.785    Value Loss: 4.371    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 3356129    Buffer Size: 14749      Transition Number: 1000.229k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:21:50,773][train][INFO][train.py>_log] ==> #1476000    Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 8.134    Value Loss: 4.490    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 3358791    Buffer Size: 14766      Transition Number: 1000.517k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:25:10,761][train][INFO][train.py>_log] ==> #1477000    Total Loss: 0.784    [weighted Loss:0.784    Policy Loss: 7.904    Value Loss: 4.264    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 3361339    Buffer Size: 14754      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:28:28,792][train][INFO][train.py>_log] ==> #1478000    Total Loss: 2.047    [weighted Loss:2.047    Policy Loss: 8.673    Value Loss: 4.472    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 3363742    Buffer Size: 14758      Transition Number: 1000.162k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:31:50,831][train][INFO][train.py>_log] ==> #1479000    Total Loss: 2.278    [weighted Loss:2.278    Policy Loss: 8.637    Value Loss: 4.523    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 3366308    Buffer Size: 14796      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:35:13,244][train][INFO][train.py>_log] ==> #1480000    Total Loss: 1.874    [weighted Loss:1.874    Policy Loss: 8.616    Value Loss: 4.277    Reward Loss: 1.685    Consistency Loss: 0.000    ] Replay Episodes Collected: 3368868    Buffer Size: 14815      Transition Number: 1000.031k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:38:37,299][train][INFO][train.py>_log] ==> #1481000    Total Loss: 2.365    [weighted Loss:2.365    Policy Loss: 8.624    Value Loss: 4.649    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 3371430    Buffer Size: 14866      Transition Number: 1000.181k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:41:59,487][train][INFO][train.py>_log] ==> #1482000    Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 9.060    Value Loss: 4.438    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 3374018    Buffer Size: 14915      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:45:22,738][train][INFO][train.py>_log] ==> #1483000    Total Loss: 2.380    [weighted Loss:2.380    Policy Loss: 9.435    Value Loss: 4.581    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 3376618    Buffer Size: 14983      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:48:44,933][train][INFO][train.py>_log] ==> #1484000    Total Loss: 1.992    [weighted Loss:1.992    Policy Loss: 9.159    Value Loss: 4.703    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 3379145    Buffer Size: 15041      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:52:09,790][train][INFO][train.py>_log] ==> #1485000    Total Loss: 2.340    [weighted Loss:2.340    Policy Loss: 9.474    Value Loss: 4.658    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 3381795    Buffer Size: 15105      Transition Number: 1000.045k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:55:29,922][train][INFO][train.py>_log] ==> #1486000    Total Loss: 1.996    [weighted Loss:1.996    Policy Loss: 9.225    Value Loss: 4.589    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 3384336    Buffer Size: 15193      Transition Number: 1000.186k Batch Size: 256        Lr: 0.00010 
[2022-02-22 11:58:55,475][train][INFO][train.py>_log] ==> #1487000    Total Loss: 1.146    [weighted Loss:1.146    Policy Loss: 9.597    Value Loss: 4.527    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 3386907    Buffer Size: 15277      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:02:19,644][train][INFO][train.py>_log] ==> #1488000    Total Loss: 1.659    [weighted Loss:1.659    Policy Loss: 9.242    Value Loss: 4.046    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 3389523    Buffer Size: 15363      Transition Number: 1000.074k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:05:39,989][train][INFO][train.py>_log] ==> #1489000    Total Loss: 2.066    [weighted Loss:2.066    Policy Loss: 9.875    Value Loss: 4.434    Reward Loss: 1.888    Consistency Loss: 0.000    ] Replay Episodes Collected: 3392126    Buffer Size: 15469      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:09:03,755][train][INFO][train.py>_log] ==> #1490000    Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 9.857    Value Loss: 4.693    Reward Loss: 1.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 3394746    Buffer Size: 15588      Transition Number: 1000.191k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:12:24,935][train][INFO][train.py>_log] ==> #1491000    Total Loss: 0.497    [weighted Loss:0.497    Policy Loss: 9.936    Value Loss: 4.591    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 3397340    Buffer Size: 15695      Transition Number: 1000.001k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:15:49,922][train][INFO][train.py>_log] ==> #1492000    Total Loss: 1.733    [weighted Loss:1.733    Policy Loss: 9.815    Value Loss: 4.485    Reward Loss: 1.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 3400005    Buffer Size: 15787      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:19:11,129][train][INFO][train.py>_log] ==> #1493000    Total Loss: 2.613    [weighted Loss:2.613    Policy Loss: 9.556    Value Loss: 4.253    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 3402520    Buffer Size: 15866      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:22:35,557][train][INFO][train.py>_log] ==> #1494000    Total Loss: 2.042    [weighted Loss:2.042    Policy Loss: 9.997    Value Loss: 4.506    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 3405135    Buffer Size: 15937      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:25:59,595][train][INFO][train.py>_log] ==> #1495000    Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 9.739    Value Loss: 4.240    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 3407768    Buffer Size: 15987      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:29:22,240][train][INFO][train.py>_log] ==> #1496000    Total Loss: 1.944    [weighted Loss:1.944    Policy Loss: 9.876    Value Loss: 4.486    Reward Loss: 1.825    Consistency Loss: 0.000    ] Replay Episodes Collected: 3410544    Buffer Size: 16042      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:32:42,809][train][INFO][train.py>_log] ==> #1497000    Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 9.449    Value Loss: 4.242    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 3413080    Buffer Size: 16069      Transition Number: 1000.079k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:36:04,962][train][INFO][train.py>_log] ==> #1498000    Total Loss: 2.562    [weighted Loss:2.562    Policy Loss: 10.110   Value Loss: 4.374    Reward Loss: 1.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 3415647    Buffer Size: 16081      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:39:26,758][train][INFO][train.py>_log] ==> #1499000    Total Loss: 2.223    [weighted Loss:2.223    Policy Loss: 9.614    Value Loss: 4.610    Reward Loss: 1.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 3418304    Buffer Size: 16070      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:42:49,730][train][INFO][train.py>_log] ==> #1500000    Total Loss: 1.513    [weighted Loss:1.513    Policy Loss: 9.977    Value Loss: 4.676    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 3420902    Buffer Size: 16082      Transition Number: 1000.068k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:46:13,129][train][INFO][train.py>_log] ==> #1501000    Total Loss: 1.601    [weighted Loss:1.601    Policy Loss: 9.990    Value Loss: 4.426    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 3423536    Buffer Size: 16070      Transition Number: 1000.106k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:49:38,134][train][INFO][train.py>_log] ==> #1502000    Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 9.968    Value Loss: 4.399    Reward Loss: 1.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 3426194    Buffer Size: 16055      Transition Number: 1000.167k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:53:04,039][train][INFO][train.py>_log] ==> #1503000    Total Loss: 2.573    [weighted Loss:2.573    Policy Loss: 10.146   Value Loss: 4.651    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 3428946    Buffer Size: 16059      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:56:29,201][train][INFO][train.py>_log] ==> #1504000    Total Loss: 2.277    [weighted Loss:2.277    Policy Loss: 9.906    Value Loss: 4.662    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 3431472    Buffer Size: 16065      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00010 
[2022-02-22 12:59:49,424][train][INFO][train.py>_log] ==> #1505000    Total Loss: 2.039    [weighted Loss:2.039    Policy Loss: 9.719    Value Loss: 4.479    Reward Loss: 1.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 3434014    Buffer Size: 16077      Transition Number: 1000.235k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:03:11,791][train][INFO][train.py>_log] ==> #1506000    Total Loss: 2.014    [weighted Loss:2.014    Policy Loss: 9.770    Value Loss: 4.541    Reward Loss: 1.736    Consistency Loss: 0.000    ] Replay Episodes Collected: 3436714    Buffer Size: 16068      Transition Number: 1000.378k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:06:31,832][train][INFO][train.py>_log] ==> #1507000    Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 10.055   Value Loss: 4.659    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 3439300    Buffer Size: 16060      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:09:55,043][train][INFO][train.py>_log] ==> #1508000    Total Loss: 2.423    [weighted Loss:2.423    Policy Loss: 9.710    Value Loss: 4.380    Reward Loss: 1.803    Consistency Loss: 0.000    ] Replay Episodes Collected: 3441892    Buffer Size: 16067      Transition Number: 1000.379k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:13:14,305][train][INFO][train.py>_log] ==> #1509000    Total Loss: 1.293    [weighted Loss:1.293    Policy Loss: 9.659    Value Loss: 4.680    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 3444502    Buffer Size: 16033      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:16:36,539][train][INFO][train.py>_log] ==> #1510000    Total Loss: 2.051    [weighted Loss:2.051    Policy Loss: 9.877    Value Loss: 4.443    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 3447100    Buffer Size: 16032      Transition Number: 1000.240k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:20:02,014][train][INFO][train.py>_log] ==> #1511000    Total Loss: 2.652    [weighted Loss:2.652    Policy Loss: 9.830    Value Loss: 4.400    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 3449746    Buffer Size: 16039      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:23:26,173][train][INFO][train.py>_log] ==> #1512000    Total Loss: 2.199    [weighted Loss:2.199    Policy Loss: 9.866    Value Loss: 4.498    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 3452409    Buffer Size: 16040      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:26:49,006][train][INFO][train.py>_log] ==> #1513000    Total Loss: 2.123    [weighted Loss:2.123    Policy Loss: 9.567    Value Loss: 4.358    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 3455029    Buffer Size: 16038      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:30:13,775][train][INFO][train.py>_log] ==> #1514000    Total Loss: 2.858    [weighted Loss:2.858    Policy Loss: 9.941    Value Loss: 4.547    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 3457715    Buffer Size: 16031      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:33:40,760][train][INFO][train.py>_log] ==> #1515000    Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 9.598    Value Loss: 4.506    Reward Loss: 1.583    Consistency Loss: 0.000    ] Replay Episodes Collected: 3460423    Buffer Size: 16044      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:37:02,644][train][INFO][train.py>_log] ==> #1516000    Total Loss: 2.200    [weighted Loss:2.200    Policy Loss: 9.910    Value Loss: 4.441    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 3462905    Buffer Size: 16059      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:40:24,946][train][INFO][train.py>_log] ==> #1517000    Total Loss: 0.539    [weighted Loss:0.539    Policy Loss: 9.888    Value Loss: 4.964    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 3465561    Buffer Size: 16043      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:43:49,422][train][INFO][train.py>_log] ==> #1518000    Total Loss: 1.169    [weighted Loss:1.169    Policy Loss: 10.026   Value Loss: 4.737    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 3468225    Buffer Size: 16018      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:47:14,079][train][INFO][train.py>_log] ==> #1519000    Total Loss: 2.210    [weighted Loss:2.210    Policy Loss: 9.445    Value Loss: 4.583    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 3470782    Buffer Size: 16027      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:50:38,797][train][INFO][train.py>_log] ==> #1520000    Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 9.455    Value Loss: 4.438    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 3473557    Buffer Size: 16020      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:54:02,593][train][INFO][train.py>_log] ==> #1521000    Total Loss: 1.665    [weighted Loss:1.665    Policy Loss: 10.077   Value Loss: 4.404    Reward Loss: 1.641    Consistency Loss: 0.000    ] Replay Episodes Collected: 3476159    Buffer Size: 16007      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00010 
[2022-02-22 13:57:27,978][train][INFO][train.py>_log] ==> #1522000    Total Loss: 2.551    [weighted Loss:2.551    Policy Loss: 9.789    Value Loss: 4.758    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 3478725    Buffer Size: 15986      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:00:50,986][train][INFO][train.py>_log] ==> #1523000    Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 10.072   Value Loss: 4.278    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 3481402    Buffer Size: 15974      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:04:14,872][train][INFO][train.py>_log] ==> #1524000    Total Loss: 2.519    [weighted Loss:2.519    Policy Loss: 9.693    Value Loss: 4.476    Reward Loss: 1.807    Consistency Loss: 0.000    ] Replay Episodes Collected: 3483999    Buffer Size: 15977      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:07:40,111][train][INFO][train.py>_log] ==> #1525000    Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 9.759    Value Loss: 4.545    Reward Loss: 1.827    Consistency Loss: 0.000    ] Replay Episodes Collected: 3486653    Buffer Size: 15949      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:11:04,456][train][INFO][train.py>_log] ==> #1526000    Total Loss: 0.878    [weighted Loss:0.878    Policy Loss: 9.403    Value Loss: 4.367    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 3489360    Buffer Size: 15917      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:14:29,242][train][INFO][train.py>_log] ==> #1527000    Total Loss: 2.037    [weighted Loss:2.037    Policy Loss: 9.761    Value Loss: 4.763    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 3491936    Buffer Size: 15899      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:17:54,184][train][INFO][train.py>_log] ==> #1528000    Total Loss: 1.681    [weighted Loss:1.681    Policy Loss: 9.831    Value Loss: 4.399    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 3494497    Buffer Size: 15877      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:21:15,676][train][INFO][train.py>_log] ==> #1529000    Total Loss: 1.693    [weighted Loss:1.693    Policy Loss: 9.314    Value Loss: 4.462    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 3497113    Buffer Size: 15855      Transition Number: 1000.214k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:24:40,551][train][INFO][train.py>_log] ==> #1530000    Total Loss: 1.486    [weighted Loss:1.486    Policy Loss: 9.516    Value Loss: 4.431    Reward Loss: 1.677    Consistency Loss: 0.000    ] Replay Episodes Collected: 3499750    Buffer Size: 15834      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:28:03,150][train][INFO][train.py>_log] ==> #1531000    Total Loss: 1.897    [weighted Loss:1.897    Policy Loss: 9.356    Value Loss: 4.469    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 3502349    Buffer Size: 15816      Transition Number: 1000.548k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:31:27,384][train][INFO][train.py>_log] ==> #1532000    Total Loss: 2.538    [weighted Loss:2.538    Policy Loss: 9.385    Value Loss: 4.300    Reward Loss: 1.693    Consistency Loss: 0.000    ] Replay Episodes Collected: 3504960    Buffer Size: 15810      Transition Number: 1000.273k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:34:50,363][train][INFO][train.py>_log] ==> #1533000    Total Loss: 2.619    [weighted Loss:2.619    Policy Loss: 9.706    Value Loss: 4.506    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 3507543    Buffer Size: 15813      Transition Number: 1000.258k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:38:14,548][train][INFO][train.py>_log] ==> #1534000    Total Loss: 1.917    [weighted Loss:1.917    Policy Loss: 9.396    Value Loss: 4.546    Reward Loss: 1.728    Consistency Loss: 0.000    ] Replay Episodes Collected: 3510108    Buffer Size: 15819      Transition Number: 1000.120k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:41:38,994][train][INFO][train.py>_log] ==> #1535000    Total Loss: 2.705    [weighted Loss:2.705    Policy Loss: 9.310    Value Loss: 4.576    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 3512822    Buffer Size: 15817      Transition Number: 1000.302k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:45:03,567][train][INFO][train.py>_log] ==> #1536000    Total Loss: 0.925    [weighted Loss:0.925    Policy Loss: 9.448    Value Loss: 4.390    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 3515441    Buffer Size: 15817      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:48:27,796][train][INFO][train.py>_log] ==> #1537000    Total Loss: 1.820    [weighted Loss:1.820    Policy Loss: 9.418    Value Loss: 4.420    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 3518110    Buffer Size: 15815      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:51:55,224][train][INFO][train.py>_log] ==> #1538000    Total Loss: 1.504    [weighted Loss:1.504    Policy Loss: 9.485    Value Loss: 4.382    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 3520652    Buffer Size: 15809      Transition Number: 1000.431k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:55:21,267][train][INFO][train.py>_log] ==> #1539000    Total Loss: 1.805    [weighted Loss:1.805    Policy Loss: 9.165    Value Loss: 4.516    Reward Loss: 1.757    Consistency Loss: 0.000    ] Replay Episodes Collected: 3523336    Buffer Size: 15791      Transition Number: 1000.308k Batch Size: 256        Lr: 0.00010 
[2022-02-22 14:58:45,248][train][INFO][train.py>_log] ==> #1540000    Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 9.358    Value Loss: 4.819    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 3526001    Buffer Size: 15775      Transition Number: 1000.765k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:02:09,649][train][INFO][train.py>_log] ==> #1541000    Total Loss: 2.081    [weighted Loss:2.081    Policy Loss: 9.590    Value Loss: 4.214    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 3528645    Buffer Size: 15748      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:05:33,185][train][INFO][train.py>_log] ==> #1542000    Total Loss: 2.490    [weighted Loss:2.490    Policy Loss: 9.578    Value Loss: 4.432    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 3531236    Buffer Size: 15715      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:08:59,152][train][INFO][train.py>_log] ==> #1543000    Total Loss: 1.360    [weighted Loss:1.360    Policy Loss: 9.334    Value Loss: 4.523    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 3533868    Buffer Size: 15701      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:12:26,466][train][INFO][train.py>_log] ==> #1544000    Total Loss: 2.067    [weighted Loss:2.067    Policy Loss: 9.549    Value Loss: 4.267    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 3536531    Buffer Size: 15686      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:15:50,317][train][INFO][train.py>_log] ==> #1545000    Total Loss: 0.682    [weighted Loss:0.682    Policy Loss: 9.620    Value Loss: 4.403    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 3539114    Buffer Size: 15661      Transition Number: 1000.418k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:19:17,526][train][INFO][train.py>_log] ==> #1546000    Total Loss: 0.854    [weighted Loss:0.854    Policy Loss: 8.991    Value Loss: 4.221    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 3541774    Buffer Size: 15642      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:22:44,315][train][INFO][train.py>_log] ==> #1547000    Total Loss: 1.745    [weighted Loss:1.745    Policy Loss: 9.961    Value Loss: 4.388    Reward Loss: 1.788    Consistency Loss: 0.000    ] Replay Episodes Collected: 3544465    Buffer Size: 15626      Transition Number: 1000.261k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:26:09,681][train][INFO][train.py>_log] ==> #1548000    Total Loss: 2.142    [weighted Loss:2.142    Policy Loss: 9.547    Value Loss: 4.292    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 3547091    Buffer Size: 15597      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:29:35,990][train][INFO][train.py>_log] ==> #1549000    Total Loss: 1.032    [weighted Loss:1.032    Policy Loss: 9.700    Value Loss: 4.504    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 3549636    Buffer Size: 15581      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:33:01,628][train][INFO][train.py>_log] ==> #1550000    Total Loss: 1.863    [weighted Loss:1.863    Policy Loss: 9.506    Value Loss: 4.334    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 3552273    Buffer Size: 15555      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:36:25,617][train][INFO][train.py>_log] ==> #1551000    Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 9.477    Value Loss: 4.264    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 3554953    Buffer Size: 15522      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:39:50,870][train][INFO][train.py>_log] ==> #1552000    Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 9.368    Value Loss: 4.318    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 3557494    Buffer Size: 15495      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:43:12,672][train][INFO][train.py>_log] ==> #1553000    Total Loss: 0.464    [weighted Loss:0.464    Policy Loss: 9.683    Value Loss: 4.478    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 3560110    Buffer Size: 15469      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:46:38,141][train][INFO][train.py>_log] ==> #1554000    Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 9.662    Value Loss: 4.283    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 3562741    Buffer Size: 15435      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:49:58,766][train][INFO][train.py>_log] ==> #1555000    Total Loss: 1.707    [weighted Loss:1.707    Policy Loss: 9.861    Value Loss: 4.694    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 3565249    Buffer Size: 15403      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:53:24,429][train][INFO][train.py>_log] ==> #1556000    Total Loss: 1.288    [weighted Loss:1.288    Policy Loss: 9.632    Value Loss: 4.546    Reward Loss: 1.657    Consistency Loss: 0.000    ] Replay Episodes Collected: 3567866    Buffer Size: 15396      Transition Number: 1000.247k Batch Size: 256        Lr: 0.00010 
[2022-02-22 15:56:47,221][train][INFO][train.py>_log] ==> #1557000    Total Loss: 1.968    [weighted Loss:1.968    Policy Loss: 9.249    Value Loss: 4.051    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 3570510    Buffer Size: 15372      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:00:09,480][train][INFO][train.py>_log] ==> #1558000    Total Loss: 2.268    [weighted Loss:2.268    Policy Loss: 9.557    Value Loss: 4.367    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 3573072    Buffer Size: 15336      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:03:33,288][train][INFO][train.py>_log] ==> #1559000    Total Loss: 1.040    [weighted Loss:1.040    Policy Loss: 9.688    Value Loss: 4.347    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 3575666    Buffer Size: 15284      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:06:59,602][train][INFO][train.py>_log] ==> #1560000    Total Loss: 1.342    [weighted Loss:1.342    Policy Loss: 9.509    Value Loss: 4.220    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 3578281    Buffer Size: 15259      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:10:23,452][train][INFO][train.py>_log] ==> #1561000    Total Loss: 2.579    [weighted Loss:2.579    Policy Loss: 9.582    Value Loss: 4.323    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 3580844    Buffer Size: 15205      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:13:46,198][train][INFO][train.py>_log] ==> #1562000    Total Loss: 1.704    [weighted Loss:1.704    Policy Loss: 8.767    Value Loss: 4.483    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 3583484    Buffer Size: 15155      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:17:09,283][train][INFO][train.py>_log] ==> #1563000    Total Loss: 1.394    [weighted Loss:1.394    Policy Loss: 8.981    Value Loss: 4.198    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 3585990    Buffer Size: 15076      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:20:32,613][train][INFO][train.py>_log] ==> #1564000    Total Loss: 1.462    [weighted Loss:1.462    Policy Loss: 9.012    Value Loss: 4.317    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 3588596    Buffer Size: 14999      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:23:59,164][train][INFO][train.py>_log] ==> #1565000    Total Loss: 2.062    [weighted Loss:2.062    Policy Loss: 9.341    Value Loss: 4.214    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 3591256    Buffer Size: 14926      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:27:28,484][train][INFO][train.py>_log] ==> #1566000    Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 9.042    Value Loss: 3.975    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 3593879    Buffer Size: 14847      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:30:57,169][train][INFO][train.py>_log] ==> #1567000    Total Loss: 1.779    [weighted Loss:1.779    Policy Loss: 8.981    Value Loss: 4.227    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 3596446    Buffer Size: 14785      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:34:22,407][train][INFO][train.py>_log] ==> #1568000    Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 8.858    Value Loss: 4.341    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 3599158    Buffer Size: 14734      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:37:47,683][train][INFO][train.py>_log] ==> #1569000    Total Loss: 1.407    [weighted Loss:1.407    Policy Loss: 8.978    Value Loss: 4.299    Reward Loss: 1.620    Consistency Loss: 0.000    ] Replay Episodes Collected: 3601750    Buffer Size: 14699      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:41:10,877][train][INFO][train.py>_log] ==> #1570000    Total Loss: 1.494    [weighted Loss:1.494    Policy Loss: 8.264    Value Loss: 4.079    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 3604256    Buffer Size: 14692      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:44:37,703][train][INFO][train.py>_log] ==> #1571000    Total Loss: 2.557    [weighted Loss:2.557    Policy Loss: 9.211    Value Loss: 4.095    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 3606970    Buffer Size: 14687      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:48:04,032][train][INFO][train.py>_log] ==> #1572000    Total Loss: 1.450    [weighted Loss:1.450    Policy Loss: 9.105    Value Loss: 4.489    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 3609518    Buffer Size: 14690      Transition Number: 1000.077k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:51:28,323][train][INFO][train.py>_log] ==> #1573000    Total Loss: 0.690    [weighted Loss:0.690    Policy Loss: 8.385    Value Loss: 4.324    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 3612113    Buffer Size: 14708      Transition Number: 1000.361k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:54:52,250][train][INFO][train.py>_log] ==> #1574000    Total Loss: 2.642    [weighted Loss:2.642    Policy Loss: 8.615    Value Loss: 4.252    Reward Loss: 1.755    Consistency Loss: 0.000    ] Replay Episodes Collected: 3614635    Buffer Size: 14711      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00010 
[2022-02-22 16:58:17,477][train][INFO][train.py>_log] ==> #1575000    Total Loss: 1.196    [weighted Loss:1.196    Policy Loss: 8.447    Value Loss: 4.279    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 3617236    Buffer Size: 14720      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:01:39,870][train][INFO][train.py>_log] ==> #1576000    Total Loss: 1.976    [weighted Loss:1.976    Policy Loss: 8.063    Value Loss: 4.462    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 3619799    Buffer Size: 14726      Transition Number: 1000.348k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:05:05,307][train][INFO][train.py>_log] ==> #1577000    Total Loss: 1.378    [weighted Loss:1.378    Policy Loss: 7.868    Value Loss: 4.253    Reward Loss: 1.556    Consistency Loss: 0.000    ] Replay Episodes Collected: 3622379    Buffer Size: 14729      Transition Number: 1000.161k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:08:30,069][train][INFO][train.py>_log] ==> #1578000    Total Loss: 0.495    [weighted Loss:0.495    Policy Loss: 8.156    Value Loss: 4.826    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 3625011    Buffer Size: 14734      Transition Number: 999.984 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:11:54,580][train][INFO][train.py>_log] ==> #1579000    Total Loss: 1.657    [weighted Loss:1.657    Policy Loss: 7.868    Value Loss: 4.416    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 3627566    Buffer Size: 14739      Transition Number: 1000.399k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:15:20,576][train][INFO][train.py>_log] ==> #1580000    Total Loss: 2.174    [weighted Loss:2.174    Policy Loss: 8.096    Value Loss: 4.692    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 3630175    Buffer Size: 14746      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:18:48,212][train][INFO][train.py>_log] ==> #1581000    Total Loss: 2.194    [weighted Loss:2.194    Policy Loss: 8.390    Value Loss: 4.621    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 3632832    Buffer Size: 14765      Transition Number: 1000.539k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:22:14,783][train][INFO][train.py>_log] ==> #1582000    Total Loss: 1.409    [weighted Loss:1.409    Policy Loss: 7.984    Value Loss: 4.733    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 3635504    Buffer Size: 14773      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:25:39,412][train][INFO][train.py>_log] ==> #1583000    Total Loss: 0.992    [weighted Loss:0.992    Policy Loss: 7.941    Value Loss: 4.600    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 3638083    Buffer Size: 14782      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:29:06,165][train][INFO][train.py>_log] ==> #1584000    Total Loss: 2.359    [weighted Loss:2.359    Policy Loss: 7.979    Value Loss: 4.427    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 3640626    Buffer Size: 14801      Transition Number: 1000.246k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:32:30,471][train][INFO][train.py>_log] ==> #1585000    Total Loss: 1.915    [weighted Loss:1.915    Policy Loss: 7.992    Value Loss: 4.712    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 3643271    Buffer Size: 14806      Transition Number: 1000.439k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:35:54,731][train][INFO][train.py>_log] ==> #1586000    Total Loss: 0.855    [weighted Loss:0.855    Policy Loss: 7.573    Value Loss: 4.607    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 3645896    Buffer Size: 14814      Transition Number: 1000.209k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:39:21,999][train][INFO][train.py>_log] ==> #1587000    Total Loss: 1.382    [weighted Loss:1.382    Policy Loss: 7.913    Value Loss: 4.693    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 3648507    Buffer Size: 14817      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:42:48,646][train][INFO][train.py>_log] ==> #1588000    Total Loss: 1.380    [weighted Loss:1.380    Policy Loss: 7.652    Value Loss: 5.146    Reward Loss: 1.402    Consistency Loss: 0.000    ] Replay Episodes Collected: 3651088    Buffer Size: 14828      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:46:16,560][train][INFO][train.py>_log] ==> #1589000    Total Loss: 2.255    [weighted Loss:2.255    Policy Loss: 7.945    Value Loss: 4.574    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 3653727    Buffer Size: 14840      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:49:41,022][train][INFO][train.py>_log] ==> #1590000    Total Loss: 1.118    [weighted Loss:1.118    Policy Loss: 7.503    Value Loss: 4.934    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 3656330    Buffer Size: 14845      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:53:05,710][train][INFO][train.py>_log] ==> #1591000    Total Loss: 2.203    [weighted Loss:2.203    Policy Loss: 7.633    Value Loss: 5.047    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 3658962    Buffer Size: 14842      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:56:30,384][train][INFO][train.py>_log] ==> #1592000    Total Loss: 0.950    [weighted Loss:0.950    Policy Loss: 7.827    Value Loss: 5.263    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 3661601    Buffer Size: 14845      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00010 
[2022-02-22 17:59:57,242][train][INFO][train.py>_log] ==> #1593000    Total Loss: 1.374    [weighted Loss:1.374    Policy Loss: 7.858    Value Loss: 4.709    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 3664171    Buffer Size: 14843      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:03:24,602][train][INFO][train.py>_log] ==> #1594000    Total Loss: 1.614    [weighted Loss:1.614    Policy Loss: 7.575    Value Loss: 5.158    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 3666766    Buffer Size: 14859      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:06:53,468][train][INFO][train.py>_log] ==> #1595000    Total Loss: 1.116    [weighted Loss:1.116    Policy Loss: 7.667    Value Loss: 4.885    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 3669440    Buffer Size: 14851      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:10:19,209][train][INFO][train.py>_log] ==> #1596000    Total Loss: 1.308    [weighted Loss:1.308    Policy Loss: 7.612    Value Loss: 4.628    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 3672069    Buffer Size: 14859      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:13:43,852][train][INFO][train.py>_log] ==> #1597000    Total Loss: 1.947    [weighted Loss:1.947    Policy Loss: 7.633    Value Loss: 5.071    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 3674662    Buffer Size: 14842      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:17:09,347][train][INFO][train.py>_log] ==> #1598000    Total Loss: 1.234    [weighted Loss:1.234    Policy Loss: 8.064    Value Loss: 4.735    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 3677227    Buffer Size: 14821      Transition Number: 1000.038k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:20:37,085][train][INFO][train.py>_log] ==> #1599000    Total Loss: 1.238    [weighted Loss:1.238    Policy Loss: 7.500    Value Loss: 5.249    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 3679917    Buffer Size: 14787      Transition Number: 999.931 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:24:03,775][train][INFO][train.py>_log] ==> #1600000    Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 7.721    Value Loss: 4.676    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 3682557    Buffer Size: 14759      Transition Number: 1000.004k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:27:27,763][train][INFO][train.py>_log] ==> #1601000    Total Loss: 1.339    [weighted Loss:1.339    Policy Loss: 7.650    Value Loss: 4.711    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 3685104    Buffer Size: 14742      Transition Number: 1000.153k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:30:56,119][train][INFO][train.py>_log] ==> #1602000    Total Loss: 1.431    [weighted Loss:1.431    Policy Loss: 7.494    Value Loss: 4.994    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 3687739    Buffer Size: 14722      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:34:20,760][train][INFO][train.py>_log] ==> #1603000    Total Loss: 1.680    [weighted Loss:1.680    Policy Loss: 7.322    Value Loss: 5.028    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 3690317    Buffer Size: 14703      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:37:45,234][train][INFO][train.py>_log] ==> #1604000    Total Loss: 1.280    [weighted Loss:1.280    Policy Loss: 8.065    Value Loss: 4.943    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 3692894    Buffer Size: 14679      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:41:12,097][train][INFO][train.py>_log] ==> #1605000    Total Loss: 1.929    [weighted Loss:1.929    Policy Loss: 8.037    Value Loss: 4.593    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 3695556    Buffer Size: 14675      Transition Number: 1000.145k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:44:36,793][train][INFO][train.py>_log] ==> #1606000    Total Loss: 1.358    [weighted Loss:1.358    Policy Loss: 7.934    Value Loss: 4.786    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 3698101    Buffer Size: 14677      Transition Number: 1000.220k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:48:03,265][train][INFO][train.py>_log] ==> #1607000    Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 7.367    Value Loss: 4.419    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 3700742    Buffer Size: 14660      Transition Number: 1000.201k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:51:27,683][train][INFO][train.py>_log] ==> #1608000    Total Loss: 2.274    [weighted Loss:2.274    Policy Loss: 7.785    Value Loss: 4.862    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 3703331    Buffer Size: 14650      Transition Number: 1000.074k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:54:54,297][train][INFO][train.py>_log] ==> #1609000    Total Loss: 1.306    [weighted Loss:1.306    Policy Loss: 7.448    Value Loss: 4.508    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 3705914    Buffer Size: 14656      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00010 
[2022-02-22 18:58:20,805][train][INFO][train.py>_log] ==> #1610000    Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 7.822    Value Loss: 4.555    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 3708604    Buffer Size: 14650      Transition Number: 999.958 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:01:43,448][train][INFO][train.py>_log] ==> #1611000    Total Loss: 1.866    [weighted Loss:1.866    Policy Loss: 7.307    Value Loss: 4.602    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 3711140    Buffer Size: 14649      Transition Number: 1000.297k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:05:12,571][train][INFO][train.py>_log] ==> #1612000    Total Loss: 2.400    [weighted Loss:2.400    Policy Loss: 7.716    Value Loss: 4.451    Reward Loss: 1.472    Consistency Loss: 0.000    ] Replay Episodes Collected: 3713757    Buffer Size: 14637      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:08:37,903][train][INFO][train.py>_log] ==> #1613000    Total Loss: 1.537    [weighted Loss:1.537    Policy Loss: 7.612    Value Loss: 4.510    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 3716415    Buffer Size: 14632      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:12:07,939][train][INFO][train.py>_log] ==> #1614000    Total Loss: 2.291    [weighted Loss:2.291    Policy Loss: 7.402    Value Loss: 4.595    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 3719064    Buffer Size: 14640      Transition Number: 1000.057k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:15:36,259][train][INFO][train.py>_log] ==> #1615000    Total Loss: 1.040    [weighted Loss:1.040    Policy Loss: 7.029    Value Loss: 4.387    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 3721687    Buffer Size: 14625      Transition Number: 1000.557k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:19:03,166][train][INFO][train.py>_log] ==> #1616000    Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 7.019    Value Loss: 4.709    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 3724238    Buffer Size: 14639      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:22:30,325][train][INFO][train.py>_log] ==> #1617000    Total Loss: 1.157    [weighted Loss:1.157    Policy Loss: 7.836    Value Loss: 4.410    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 3726981    Buffer Size: 14626      Transition Number: 1000.207k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:25:55,256][train][INFO][train.py>_log] ==> #1618000    Total Loss: 1.195    [weighted Loss:1.195    Policy Loss: 7.844    Value Loss: 4.345    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 3729501    Buffer Size: 14628      Transition Number: 1000.160k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:29:22,504][train][INFO][train.py>_log] ==> #1619000    Total Loss: 0.969    [weighted Loss:0.969    Policy Loss: 7.277    Value Loss: 4.202    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 3732047    Buffer Size: 14628      Transition Number: 1000.333k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:32:48,230][train][INFO][train.py>_log] ==> #1620000    Total Loss: 1.842    [weighted Loss:1.842    Policy Loss: 7.182    Value Loss: 4.543    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 3734714    Buffer Size: 14620      Transition Number: 1000.038k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:36:14,961][train][INFO][train.py>_log] ==> #1621000    Total Loss: 0.677    [weighted Loss:0.677    Policy Loss: 7.550    Value Loss: 4.723    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 3737293    Buffer Size: 14620      Transition Number: 1000.121k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:39:42,415][train][INFO][train.py>_log] ==> #1622000    Total Loss: 1.173    [weighted Loss:1.173    Policy Loss: 7.303    Value Loss: 4.707    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 3739925    Buffer Size: 14641      Transition Number: 1000.457k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:43:08,519][train][INFO][train.py>_log] ==> #1623000    Total Loss: 1.620    [weighted Loss:1.620    Policy Loss: 7.680    Value Loss: 4.697    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 3742605    Buffer Size: 14651      Transition Number: 1000.229k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:46:35,834][train][INFO][train.py>_log] ==> #1624000    Total Loss: 1.369    [weighted Loss:1.369    Policy Loss: 7.624    Value Loss: 4.397    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 3745177    Buffer Size: 14675      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:50:01,273][train][INFO][train.py>_log] ==> #1625000    Total Loss: 1.879    [weighted Loss:1.879    Policy Loss: 7.347    Value Loss: 4.688    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 3747758    Buffer Size: 14669      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:53:27,047][train][INFO][train.py>_log] ==> #1626000    Total Loss: 1.421    [weighted Loss:1.421    Policy Loss: 7.684    Value Loss: 4.664    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 3750463    Buffer Size: 14669      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 19:56:52,904][train][INFO][train.py>_log] ==> #1627000    Total Loss: 1.437    [weighted Loss:1.437    Policy Loss: 7.440    Value Loss: 4.227    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 3752959    Buffer Size: 14669      Transition Number: 1000.263k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:00:22,330][train][INFO][train.py>_log] ==> #1628000    Total Loss: 0.909    [weighted Loss:0.909    Policy Loss: 7.789    Value Loss: 4.430    Reward Loss: 1.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 3755653    Buffer Size: 14657      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:03:51,544][train][INFO][train.py>_log] ==> #1629000    Total Loss: 2.013    [weighted Loss:2.013    Policy Loss: 7.421    Value Loss: 4.632    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 3758269    Buffer Size: 14664      Transition Number: 1000.400k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:07:19,274][train][INFO][train.py>_log] ==> #1630000    Total Loss: 1.436    [weighted Loss:1.436    Policy Loss: 7.387    Value Loss: 4.283    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 3760914    Buffer Size: 14642      Transition Number: 1000.080k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:10:47,088][train][INFO][train.py>_log] ==> #1631000    Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 7.380    Value Loss: 4.825    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 3763574    Buffer Size: 14653      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:14:13,519][train][INFO][train.py>_log] ==> #1632000    Total Loss: 0.643    [weighted Loss:0.643    Policy Loss: 7.963    Value Loss: 4.345    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 3766132    Buffer Size: 14652      Transition Number: 1000.686k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:17:40,313][train][INFO][train.py>_log] ==> #1633000    Total Loss: 1.365    [weighted Loss:1.365    Policy Loss: 7.328    Value Loss: 4.433    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 3768789    Buffer Size: 14638      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:21:09,690][train][INFO][train.py>_log] ==> #1634000    Total Loss: 0.790    [weighted Loss:0.790    Policy Loss: 7.420    Value Loss: 4.568    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 3771390    Buffer Size: 14645      Transition Number: 1000.231k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:24:34,514][train][INFO][train.py>_log] ==> #1635000    Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 7.643    Value Loss: 4.784    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 3774038    Buffer Size: 14634      Transition Number: 1000.363k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:28:05,874][train][INFO][train.py>_log] ==> #1636000    Total Loss: 1.454    [weighted Loss:1.454    Policy Loss: 7.651    Value Loss: 4.545    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 3776733    Buffer Size: 14615      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:31:31,719][train][INFO][train.py>_log] ==> #1637000    Total Loss: 1.589    [weighted Loss:1.589    Policy Loss: 7.294    Value Loss: 4.507    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 3779257    Buffer Size: 14617      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:34:59,943][train][INFO][train.py>_log] ==> #1638000    Total Loss: 1.546    [weighted Loss:1.546    Policy Loss: 7.137    Value Loss: 4.610    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 3781969    Buffer Size: 14624      Transition Number: 1000.328k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:38:28,402][train][INFO][train.py>_log] ==> #1639000    Total Loss: 1.665    [weighted Loss:1.665    Policy Loss: 7.637    Value Loss: 4.437    Reward Loss: 1.495    Consistency Loss: 0.000    ] Replay Episodes Collected: 3784621    Buffer Size: 14602      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:41:57,161][train][INFO][train.py>_log] ==> #1640000    Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 7.825    Value Loss: 4.342    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 3787133    Buffer Size: 14598      Transition Number: 999.990 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:45:21,733][train][INFO][train.py>_log] ==> #1641000    Total Loss: 1.250    [weighted Loss:1.250    Policy Loss: 7.665    Value Loss: 4.418    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 3789850    Buffer Size: 14609      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:48:51,032][train][INFO][train.py>_log] ==> #1642000    Total Loss: 1.302    [weighted Loss:1.302    Policy Loss: 7.589    Value Loss: 4.274    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 3792539    Buffer Size: 14615      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:52:15,621][train][INFO][train.py>_log] ==> #1643000    Total Loss: 2.085    [weighted Loss:2.085    Policy Loss: 7.782    Value Loss: 4.374    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 3795084    Buffer Size: 14626      Transition Number: 1000.281k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:55:41,860][train][INFO][train.py>_log] ==> #1644000    Total Loss: 1.093    [weighted Loss:1.093    Policy Loss: 7.336    Value Loss: 4.202    Reward Loss: 1.511    Consistency Loss: 0.000    ] Replay Episodes Collected: 3797675    Buffer Size: 14627      Transition Number: 1000.103k Batch Size: 256        Lr: 0.00010 
[2022-02-22 20:59:09,179][train][INFO][train.py>_log] ==> #1645000    Total Loss: 2.072    [weighted Loss:2.072    Policy Loss: 7.579    Value Loss: 4.544    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 3800331    Buffer Size: 14606      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:02:35,773][train][INFO][train.py>_log] ==> #1646000    Total Loss: 1.747    [weighted Loss:1.747    Policy Loss: 7.495    Value Loss: 4.375    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 3802922    Buffer Size: 14606      Transition Number: 1000.176k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:06:05,226][train][INFO][train.py>_log] ==> #1647000    Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 7.611    Value Loss: 4.542    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 3805618    Buffer Size: 14610      Transition Number: 1000.386k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:09:34,742][train][INFO][train.py>_log] ==> #1648000    Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 7.906    Value Loss: 4.400    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 3808289    Buffer Size: 14587      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:13:03,146][train][INFO][train.py>_log] ==> #1649000    Total Loss: 2.504    [weighted Loss:2.504    Policy Loss: 7.682    Value Loss: 4.694    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 3810921    Buffer Size: 14582      Transition Number: 1000.340k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:16:33,206][train][INFO][train.py>_log] ==> #1650000    Total Loss: 1.510    [weighted Loss:1.510    Policy Loss: 7.581    Value Loss: 4.666    Reward Loss: 1.450    Consistency Loss: 0.000    ] Replay Episodes Collected: 3813514    Buffer Size: 14590      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:19:59,347][train][INFO][train.py>_log] ==> #1651000    Total Loss: 1.494    [weighted Loss:1.494    Policy Loss: 7.360    Value Loss: 4.468    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 3816256    Buffer Size: 14606      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:23:24,451][train][INFO][train.py>_log] ==> #1652000    Total Loss: 1.512    [weighted Loss:1.512    Policy Loss: 7.724    Value Loss: 4.233    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 3818763    Buffer Size: 14599      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:26:50,949][train][INFO][train.py>_log] ==> #1653000    Total Loss: 1.408    [weighted Loss:1.408    Policy Loss: 7.299    Value Loss: 4.412    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 3821343    Buffer Size: 14595      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:30:21,697][train][INFO][train.py>_log] ==> #1654000    Total Loss: 1.676    [weighted Loss:1.676    Policy Loss: 7.189    Value Loss: 4.661    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 3824078    Buffer Size: 14597      Transition Number: 1000.071k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:33:54,428][train][INFO][train.py>_log] ==> #1655000    Total Loss: 1.239    [weighted Loss:1.239    Policy Loss: 7.438    Value Loss: 4.387    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 3826714    Buffer Size: 14598      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:37:18,702][train][INFO][train.py>_log] ==> #1656000    Total Loss: 1.761    [weighted Loss:1.761    Policy Loss: 7.404    Value Loss: 4.137    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 3829329    Buffer Size: 14586      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:40:45,378][train][INFO][train.py>_log] ==> #1657000    Total Loss: 1.261    [weighted Loss:1.261    Policy Loss: 7.620    Value Loss: 4.381    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 3831871    Buffer Size: 14584      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:44:11,944][train][INFO][train.py>_log] ==> #1658000    Total Loss: 1.584    [weighted Loss:1.584    Policy Loss: 7.636    Value Loss: 4.615    Reward Loss: 1.810    Consistency Loss: 0.000    ] Replay Episodes Collected: 3834570    Buffer Size: 14577      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:47:44,412][train][INFO][train.py>_log] ==> #1659000    Total Loss: 1.104    [weighted Loss:1.104    Policy Loss: 7.604    Value Loss: 4.599    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 3837311    Buffer Size: 14571      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:51:10,626][train][INFO][train.py>_log] ==> #1660000    Total Loss: 1.545    [weighted Loss:1.545    Policy Loss: 7.160    Value Loss: 4.424    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 3839868    Buffer Size: 14579      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:54:42,687][train][INFO][train.py>_log] ==> #1661000    Total Loss: 0.562    [weighted Loss:0.562    Policy Loss: 7.485    Value Loss: 4.398    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 3842553    Buffer Size: 14570      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 21:58:11,187][train][INFO][train.py>_log] ==> #1662000    Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 7.455    Value Loss: 4.424    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 3845141    Buffer Size: 14579      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:01:37,793][train][INFO][train.py>_log] ==> #1663000    Total Loss: 1.482    [weighted Loss:1.482    Policy Loss: 7.380    Value Loss: 4.400    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 3847853    Buffer Size: 14581      Transition Number: 1000.069k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:05:08,840][train][INFO][train.py>_log] ==> #1664000    Total Loss: 1.515    [weighted Loss:1.515    Policy Loss: 7.826    Value Loss: 4.159    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 3850564    Buffer Size: 14595      Transition Number: 1000.223k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:08:36,477][train][INFO][train.py>_log] ==> #1665000    Total Loss: 1.795    [weighted Loss:1.795    Policy Loss: 8.031    Value Loss: 4.350    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 3853186    Buffer Size: 14594      Transition Number: 1000.049k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:12:05,095][train][INFO][train.py>_log] ==> #1666000    Total Loss: 2.149    [weighted Loss:2.149    Policy Loss: 7.667    Value Loss: 4.339    Reward Loss: 1.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 3855819    Buffer Size: 14602      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:15:35,794][train][INFO][train.py>_log] ==> #1667000    Total Loss: 1.843    [weighted Loss:1.843    Policy Loss: 7.929    Value Loss: 4.485    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 3858461    Buffer Size: 14613      Transition Number: 1000.053k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:19:03,975][train][INFO][train.py>_log] ==> #1668000    Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 7.658    Value Loss: 4.496    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 3861179    Buffer Size: 14614      Transition Number: 1000.096k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:22:30,995][train][INFO][train.py>_log] ==> #1669000    Total Loss: 1.229    [weighted Loss:1.229    Policy Loss: 7.505    Value Loss: 4.443    Reward Loss: 1.485    Consistency Loss: 0.000    ] Replay Episodes Collected: 3863655    Buffer Size: 14619      Transition Number: 1000.465k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:25:58,385][train][INFO][train.py>_log] ==> #1670000    Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 8.029    Value Loss: 4.219    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 3866366    Buffer Size: 14600      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:29:25,879][train][INFO][train.py>_log] ==> #1671000    Total Loss: 1.567    [weighted Loss:1.567    Policy Loss: 8.022    Value Loss: 4.330    Reward Loss: 1.622    Consistency Loss: 0.000    ] Replay Episodes Collected: 3869017    Buffer Size: 14610      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:32:54,775][train][INFO][train.py>_log] ==> #1672000    Total Loss: 1.923    [weighted Loss:1.923    Policy Loss: 7.588    Value Loss: 4.308    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 3871620    Buffer Size: 14620      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:36:23,623][train][INFO][train.py>_log] ==> #1673000    Total Loss: 1.925    [weighted Loss:1.925    Policy Loss: 8.039    Value Loss: 4.381    Reward Loss: 1.707    Consistency Loss: 0.000    ] Replay Episodes Collected: 3874347    Buffer Size: 14627      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:39:50,829][train][INFO][train.py>_log] ==> #1674000    Total Loss: 1.949    [weighted Loss:1.949    Policy Loss: 7.765    Value Loss: 4.469    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 3876852    Buffer Size: 14649      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:43:18,239][train][INFO][train.py>_log] ==> #1675000    Total Loss: 1.038    [weighted Loss:1.038    Policy Loss: 7.495    Value Loss: 4.057    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 3879528    Buffer Size: 14686      Transition Number: 1000.450k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:46:47,883][train][INFO][train.py>_log] ==> #1676000    Total Loss: 0.315    [weighted Loss:0.315    Policy Loss: 7.977    Value Loss: 4.199    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 3882273    Buffer Size: 14707      Transition Number: 1000.133k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:50:15,742][train][INFO][train.py>_log] ==> #1677000    Total Loss: 1.325    [weighted Loss:1.325    Policy Loss: 7.879    Value Loss: 4.238    Reward Loss: 1.758    Consistency Loss: 0.000    ] Replay Episodes Collected: 3884896    Buffer Size: 14737      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:53:41,877][train][INFO][train.py>_log] ==> #1678000    Total Loss: 1.795    [weighted Loss:1.795    Policy Loss: 7.792    Value Loss: 4.386    Reward Loss: 1.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 3887475    Buffer Size: 14756      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 22:57:14,710][train][INFO][train.py>_log] ==> #1679000    Total Loss: 1.498    [weighted Loss:1.498    Policy Loss: 8.495    Value Loss: 4.243    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 3890142    Buffer Size: 14775      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:00:43,436][train][INFO][train.py>_log] ==> #1680000    Total Loss: 1.759    [weighted Loss:1.759    Policy Loss: 8.114    Value Loss: 4.199    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 3892875    Buffer Size: 14796      Transition Number: 1000.215k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:04:15,673][train][INFO][train.py>_log] ==> #1681000    Total Loss: 1.637    [weighted Loss:1.637    Policy Loss: 8.631    Value Loss: 4.183    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 3895491    Buffer Size: 14817      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:07:44,406][train][INFO][train.py>_log] ==> #1682000    Total Loss: 1.575    [weighted Loss:1.575    Policy Loss: 8.341    Value Loss: 4.491    Reward Loss: 1.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 3898228    Buffer Size: 14831      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:11:13,195][train][INFO][train.py>_log] ==> #1683000    Total Loss: 1.685    [weighted Loss:1.685    Policy Loss: 8.295    Value Loss: 4.067    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 3900820    Buffer Size: 14856      Transition Number: 1000.300k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:14:37,598][train][INFO][train.py>_log] ==> #1684000    Total Loss: 1.524    [weighted Loss:1.524    Policy Loss: 8.759    Value Loss: 4.341    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 3903348    Buffer Size: 14883      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:18:07,351][train][INFO][train.py>_log] ==> #1685000    Total Loss: 1.765    [weighted Loss:1.765    Policy Loss: 8.839    Value Loss: 4.077    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 3906081    Buffer Size: 14942      Transition Number: 1000.164k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:21:35,066][train][INFO][train.py>_log] ==> #1686000    Total Loss: 2.346    [weighted Loss:2.346    Policy Loss: 8.752    Value Loss: 4.210    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 3908680    Buffer Size: 14993      Transition Number: 1000.528k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:25:01,368][train][INFO][train.py>_log] ==> #1687000    Total Loss: 1.139    [weighted Loss:1.139    Policy Loss: 8.324    Value Loss: 4.286    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 3911322    Buffer Size: 15018      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:28:31,600][train][INFO][train.py>_log] ==> #1688000    Total Loss: 0.799    [weighted Loss:0.799    Policy Loss: 9.074    Value Loss: 4.201    Reward Loss: 1.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 3913992    Buffer Size: 15058      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:31:57,985][train][INFO][train.py>_log] ==> #1689000    Total Loss: 2.954    [weighted Loss:2.954    Policy Loss: 9.024    Value Loss: 4.110    Reward Loss: 1.721    Consistency Loss: 0.000    ] Replay Episodes Collected: 3916625    Buffer Size: 15111      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:35:27,790][train][INFO][train.py>_log] ==> #1690000    Total Loss: 1.985    [weighted Loss:1.985    Policy Loss: 9.472    Value Loss: 4.350    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 3919226    Buffer Size: 15154      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:38:55,564][train][INFO][train.py>_log] ==> #1691000    Total Loss: 0.297    [weighted Loss:0.297    Policy Loss: 9.216    Value Loss: 4.278    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 3921877    Buffer Size: 15184      Transition Number: 1000.233k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:42:25,244][train][INFO][train.py>_log] ==> #1692000    Total Loss: 1.710    [weighted Loss:1.710    Policy Loss: 8.682    Value Loss: 4.288    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 3924664    Buffer Size: 15220      Transition Number: 1000.130k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:45:53,022][train][INFO][train.py>_log] ==> #1693000    Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 8.812    Value Loss: 4.358    Reward Loss: 1.799    Consistency Loss: 0.000    ] Replay Episodes Collected: 3927248    Buffer Size: 15272      Transition Number: 999.994 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:49:20,242][train][INFO][train.py>_log] ==> #1694000    Total Loss: 0.945    [weighted Loss:0.945    Policy Loss: 9.244    Value Loss: 4.323    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 3929931    Buffer Size: 15315      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:52:49,911][train][INFO][train.py>_log] ==> #1695000    Total Loss: 1.133    [weighted Loss:1.133    Policy Loss: 8.968    Value Loss: 4.373    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 3932668    Buffer Size: 15333      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:56:19,415][train][INFO][train.py>_log] ==> #1696000    Total Loss: 0.853    [weighted Loss:0.853    Policy Loss: 9.217    Value Loss: 4.098    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 3935291    Buffer Size: 15365      Transition Number: 1000.110k Batch Size: 256        Lr: 0.00010 
[2022-02-22 23:59:45,822][train][INFO][train.py>_log] ==> #1697000    Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 9.103    Value Loss: 4.356    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 3937964    Buffer Size: 15385      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:03:17,446][train][INFO][train.py>_log] ==> #1698000    Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 9.349    Value Loss: 4.280    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 3940640    Buffer Size: 15411      Transition Number: 1000.241k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:06:44,846][train][INFO][train.py>_log] ==> #1699000    Total Loss: 1.618    [weighted Loss:1.618    Policy Loss: 9.793    Value Loss: 4.405    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 3943322    Buffer Size: 15419      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:10:13,099][train][INFO][train.py>_log] ==> #1700000    Total Loss: 1.489    [weighted Loss:1.489    Policy Loss: 9.265    Value Loss: 4.665    Reward Loss: 1.804    Consistency Loss: 0.000    ] Replay Episodes Collected: 3946009    Buffer Size: 15446      Transition Number: 1000.156k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:13:42,078][train][INFO][train.py>_log] ==> #1701000    Total Loss: 1.126    [weighted Loss:1.126    Policy Loss: 9.361    Value Loss: 4.337    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 3948750    Buffer Size: 15477      Transition Number: 1000.364k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:17:06,687][train][INFO][train.py>_log] ==> #1702000    Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 9.546    Value Loss: 4.340    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 3951418    Buffer Size: 15499      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:20:39,067][train][INFO][train.py>_log] ==> #1703000    Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 9.736    Value Loss: 4.584    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 3954025    Buffer Size: 15546      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:24:10,069][train][INFO][train.py>_log] ==> #1704000    Total Loss: 1.926    [weighted Loss:1.926    Policy Loss: 9.435    Value Loss: 4.545    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 3956713    Buffer Size: 15583      Transition Number: 1000.270k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:27:39,471][train][INFO][train.py>_log] ==> #1705000    Total Loss: 1.626    [weighted Loss:1.626    Policy Loss: 9.243    Value Loss: 4.598    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 3959552    Buffer Size: 15610      Transition Number: 1000.239k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:31:07,091][train][INFO][train.py>_log] ==> #1706000    Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 9.588    Value Loss: 4.586    Reward Loss: 1.818    Consistency Loss: 0.000    ] Replay Episodes Collected: 3962174    Buffer Size: 15624      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:34:38,746][train][INFO][train.py>_log] ==> #1707000    Total Loss: 2.314    [weighted Loss:2.314    Policy Loss: 9.276    Value Loss: 4.325    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 3965005    Buffer Size: 15630      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:38:08,409][train][INFO][train.py>_log] ==> #1708000    Total Loss: 1.348    [weighted Loss:1.348    Policy Loss: 9.593    Value Loss: 4.386    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 3967566    Buffer Size: 15640      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:41:38,357][train][INFO][train.py>_log] ==> #1709000    Total Loss: 2.121    [weighted Loss:2.121    Policy Loss: 9.369    Value Loss: 4.758    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 3970273    Buffer Size: 15627      Transition Number: 1000.250k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:45:09,740][train][INFO][train.py>_log] ==> #1710000    Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 9.495    Value Loss: 4.467    Reward Loss: 1.619    Consistency Loss: 0.000    ] Replay Episodes Collected: 3973084    Buffer Size: 15617      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:48:38,255][train][INFO][train.py>_log] ==> #1711000    Total Loss: 1.262    [weighted Loss:1.262    Policy Loss: 9.697    Value Loss: 4.323    Reward Loss: 1.727    Consistency Loss: 0.000    ] Replay Episodes Collected: 3975787    Buffer Size: 15623      Transition Number: 1000.251k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:52:06,181][train][INFO][train.py>_log] ==> #1712000    Total Loss: 0.574    [weighted Loss:0.574    Policy Loss: 9.918    Value Loss: 4.461    Reward Loss: 1.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 3978450    Buffer Size: 15616      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:55:37,646][train][INFO][train.py>_log] ==> #1713000    Total Loss: 1.859    [weighted Loss:1.859    Policy Loss: 9.557    Value Loss: 4.281    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 3981186    Buffer Size: 15607      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 00:59:07,469][train][INFO][train.py>_log] ==> #1714000    Total Loss: 2.353    [weighted Loss:2.353    Policy Loss: 9.991    Value Loss: 4.353    Reward Loss: 1.759    Consistency Loss: 0.000    ] Replay Episodes Collected: 3983832    Buffer Size: 15609      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:02:39,178][train][INFO][train.py>_log] ==> #1715000    Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 9.836    Value Loss: 4.762    Reward Loss: 1.720    Consistency Loss: 0.000    ] Replay Episodes Collected: 3986605    Buffer Size: 15619      Transition Number: 1000.209k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:06:08,536][train][INFO][train.py>_log] ==> #1716000    Total Loss: 2.081    [weighted Loss:2.081    Policy Loss: 9.997    Value Loss: 4.221    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 3989342    Buffer Size: 15638      Transition Number: 1000.185k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:09:38,952][train][INFO][train.py>_log] ==> #1717000    Total Loss: 2.089    [weighted Loss:2.089    Policy Loss: 9.761    Value Loss: 4.602    Reward Loss: 1.778    Consistency Loss: 0.000    ] Replay Episodes Collected: 3991944    Buffer Size: 15615      Transition Number: 999.931 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:13:11,142][train][INFO][train.py>_log] ==> #1718000    Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 9.938    Value Loss: 4.774    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 3994670    Buffer Size: 15625      Transition Number: 1000.144k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:16:38,859][train][INFO][train.py>_log] ==> #1719000    Total Loss: 1.905    [weighted Loss:1.905    Policy Loss: 10.149   Value Loss: 4.271    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 3997423    Buffer Size: 15609      Transition Number: 1000.128k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:20:08,024][train][INFO][train.py>_log] ==> #1720000    Total Loss: 1.864    [weighted Loss:1.864    Policy Loss: 9.983    Value Loss: 4.223    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 4000087    Buffer Size: 15596      Transition Number: 1000.386k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:23:36,733][train][INFO][train.py>_log] ==> #1721000    Total Loss: 2.015    [weighted Loss:2.015    Policy Loss: 9.654    Value Loss: 4.518    Reward Loss: 1.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 4002744    Buffer Size: 15614      Transition Number: 1000.726k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:27:03,660][train][INFO][train.py>_log] ==> #1722000    Total Loss: 0.977    [weighted Loss:0.977    Policy Loss: 10.073   Value Loss: 4.157    Reward Loss: 1.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 4005350    Buffer Size: 15567      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:30:34,884][train][INFO][train.py>_log] ==> #1723000    Total Loss: 1.798    [weighted Loss:1.798    Policy Loss: 9.794    Value Loss: 4.279    Reward Loss: 1.802    Consistency Loss: 0.000    ] Replay Episodes Collected: 4008108    Buffer Size: 15570      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:34:01,599][train][INFO][train.py>_log] ==> #1724000    Total Loss: 1.384    [weighted Loss:1.384    Policy Loss: 10.422   Value Loss: 4.382    Reward Loss: 1.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 4010819    Buffer Size: 15547      Transition Number: 1000.150k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:37:32,761][train][INFO][train.py>_log] ==> #1725000    Total Loss: 1.716    [weighted Loss:1.716    Policy Loss: 9.853    Value Loss: 4.384    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 4013533    Buffer Size: 15538      Transition Number: 1000.446k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:41:03,381][train][INFO][train.py>_log] ==> #1726000    Total Loss: 2.669    [weighted Loss:2.669    Policy Loss: 10.329   Value Loss: 4.421    Reward Loss: 1.640    Consistency Loss: 0.000    ] Replay Episodes Collected: 4016171    Buffer Size: 15528      Transition Number: 1000.180k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:44:30,401][train][INFO][train.py>_log] ==> #1727000    Total Loss: 0.536    [weighted Loss:0.536    Policy Loss: 9.884    Value Loss: 4.238    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 4018802    Buffer Size: 15482      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:47:58,487][train][INFO][train.py>_log] ==> #1728000    Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 10.333   Value Loss: 4.265    Reward Loss: 1.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 4021524    Buffer Size: 15460      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:51:30,183][train][INFO][train.py>_log] ==> #1729000    Total Loss: 1.118    [weighted Loss:1.118    Policy Loss: 9.857    Value Loss: 4.491    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 4024191    Buffer Size: 15450      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:55:00,225][train][INFO][train.py>_log] ==> #1730000    Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 10.128   Value Loss: 4.284    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 4026938    Buffer Size: 15421      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 01:58:29,927][train][INFO][train.py>_log] ==> #1731000    Total Loss: 1.773    [weighted Loss:1.773    Policy Loss: 9.817    Value Loss: 4.488    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 4029597    Buffer Size: 15398      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:01:58,052][train][INFO][train.py>_log] ==> #1732000    Total Loss: 2.830    [weighted Loss:2.830    Policy Loss: 9.815    Value Loss: 4.501    Reward Loss: 1.751    Consistency Loss: 0.000    ] Replay Episodes Collected: 4032274    Buffer Size: 15376      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:05:27,552][train][INFO][train.py>_log] ==> #1733000    Total Loss: 2.231    [weighted Loss:2.231    Policy Loss: 10.153   Value Loss: 4.146    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 4034917    Buffer Size: 15369      Transition Number: 1000.073k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:08:59,051][train][INFO][train.py>_log] ==> #1734000    Total Loss: 2.404    [weighted Loss:2.404    Policy Loss: 10.303   Value Loss: 4.380    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 4037585    Buffer Size: 15345      Transition Number: 1000.123k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:12:27,482][train][INFO][train.py>_log] ==> #1735000    Total Loss: 0.850    [weighted Loss:0.850    Policy Loss: 10.203   Value Loss: 4.429    Reward Loss: 1.649    Consistency Loss: 0.000    ] Replay Episodes Collected: 4040306    Buffer Size: 15323      Transition Number: 1000.282k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:15:59,528][train][INFO][train.py>_log] ==> #1736000    Total Loss: 1.470    [weighted Loss:1.470    Policy Loss: 10.231   Value Loss: 4.379    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 4043033    Buffer Size: 15320      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:19:29,883][train][INFO][train.py>_log] ==> #1737000    Total Loss: 2.877    [weighted Loss:2.877    Policy Loss: 10.257   Value Loss: 4.399    Reward Loss: 1.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 4045721    Buffer Size: 15308      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:23:04,270][train][INFO][train.py>_log] ==> #1738000    Total Loss: 1.638    [weighted Loss:1.638    Policy Loss: 10.234   Value Loss: 4.441    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 4048350    Buffer Size: 15288      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:26:34,390][train][INFO][train.py>_log] ==> #1739000    Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 9.626    Value Loss: 4.570    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 4051165    Buffer Size: 15281      Transition Number: 1000.429k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:30:05,828][train][INFO][train.py>_log] ==> #1740000    Total Loss: 1.590    [weighted Loss:1.590    Policy Loss: 9.799    Value Loss: 4.082    Reward Loss: 1.687    Consistency Loss: 0.000    ] Replay Episodes Collected: 4053897    Buffer Size: 15283      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:33:36,093][train][INFO][train.py>_log] ==> #1741000    Total Loss: 1.987    [weighted Loss:1.987    Policy Loss: 9.882    Value Loss: 4.284    Reward Loss: 1.632    Consistency Loss: 0.000    ] Replay Episodes Collected: 4056521    Buffer Size: 15277      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:37:04,767][train][INFO][train.py>_log] ==> #1742000    Total Loss: 1.081    [weighted Loss:1.081    Policy Loss: 10.103   Value Loss: 4.420    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 4059155    Buffer Size: 15264      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:40:35,355][train][INFO][train.py>_log] ==> #1743000    Total Loss: 1.604    [weighted Loss:1.604    Policy Loss: 9.415    Value Loss: 4.335    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 4061909    Buffer Size: 15264      Transition Number: 999.964 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:44:06,766][train][INFO][train.py>_log] ==> #1744000    Total Loss: 2.198    [weighted Loss:2.198    Policy Loss: 9.908    Value Loss: 4.294    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 4064592    Buffer Size: 15261      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:47:35,025][train][INFO][train.py>_log] ==> #1745000    Total Loss: 2.369    [weighted Loss:2.369    Policy Loss: 9.789    Value Loss: 4.317    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 4067189    Buffer Size: 15265      Transition Number: 1000.250k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:51:04,835][train][INFO][train.py>_log] ==> #1746000    Total Loss: 2.155    [weighted Loss:2.155    Policy Loss: 9.845    Value Loss: 4.224    Reward Loss: 1.723    Consistency Loss: 0.000    ] Replay Episodes Collected: 4069937    Buffer Size: 15266      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:54:33,384][train][INFO][train.py>_log] ==> #1747000    Total Loss: 2.933    [weighted Loss:2.933    Policy Loss: 9.852    Value Loss: 4.539    Reward Loss: 1.746    Consistency Loss: 0.000    ] Replay Episodes Collected: 4072625    Buffer Size: 15259      Transition Number: 1000.141k Batch Size: 256        Lr: 0.00010 
[2022-02-23 02:58:03,152][train][INFO][train.py>_log] ==> #1748000    Total Loss: 1.756    [weighted Loss:1.756    Policy Loss: 9.846    Value Loss: 4.092    Reward Loss: 1.714    Consistency Loss: 0.000    ] Replay Episodes Collected: 4075345    Buffer Size: 15259      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:01:35,248][train][INFO][train.py>_log] ==> #1749000    Total Loss: 0.745    [weighted Loss:0.745    Policy Loss: 9.719    Value Loss: 4.195    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 4078036    Buffer Size: 15270      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:05:05,664][train][INFO][train.py>_log] ==> #1750000    Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 9.820    Value Loss: 4.126    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 4080700    Buffer Size: 15259      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:08:37,077][train][INFO][train.py>_log] ==> #1751000    Total Loss: 1.702    [weighted Loss:1.702    Policy Loss: 9.972    Value Loss: 4.227    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 4083436    Buffer Size: 15271      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:12:04,748][train][INFO][train.py>_log] ==> #1752000    Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 9.465    Value Loss: 4.374    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 4086098    Buffer Size: 15233      Transition Number: 999.954 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:15:33,781][train][INFO][train.py>_log] ==> #1753000    Total Loss: 1.674    [weighted Loss:1.674    Policy Loss: 9.761    Value Loss: 4.115    Reward Loss: 1.659    Consistency Loss: 0.000    ] Replay Episodes Collected: 4088761    Buffer Size: 15240      Transition Number: 1000.329k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:19:03,508][train][INFO][train.py>_log] ==> #1754000    Total Loss: 0.415    [weighted Loss:0.415    Policy Loss: 9.676    Value Loss: 4.159    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 4091418    Buffer Size: 15207      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:22:35,317][train][INFO][train.py>_log] ==> #1755000    Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 9.820    Value Loss: 4.273    Reward Loss: 1.635    Consistency Loss: 0.000    ] Replay Episodes Collected: 4094118    Buffer Size: 15195      Transition Number: 1000.326k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:26:04,988][train][INFO][train.py>_log] ==> #1756000    Total Loss: 1.450    [weighted Loss:1.450    Policy Loss: 9.636    Value Loss: 4.374    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 4096825    Buffer Size: 15166      Transition Number: 999.976 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:29:36,078][train][INFO][train.py>_log] ==> #1757000    Total Loss: 1.459    [weighted Loss:1.459    Policy Loss: 9.068    Value Loss: 4.470    Reward Loss: 1.688    Consistency Loss: 0.000    ] Replay Episodes Collected: 4099530    Buffer Size: 15152      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:33:07,967][train][INFO][train.py>_log] ==> #1758000    Total Loss: 1.652    [weighted Loss:1.652    Policy Loss: 9.409    Value Loss: 4.421    Reward Loss: 1.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 4102331    Buffer Size: 15155      Transition Number: 1000.644k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:36:39,381][train][INFO][train.py>_log] ==> #1759000    Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 9.984    Value Loss: 4.315    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 4104893    Buffer Size: 15146      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:40:10,845][train][INFO][train.py>_log] ==> #1760000    Total Loss: 1.541    [weighted Loss:1.541    Policy Loss: 9.607    Value Loss: 4.564    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 4107615    Buffer Size: 15152      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:43:41,249][train][INFO][train.py>_log] ==> #1761000    Total Loss: 1.880    [weighted Loss:1.880    Policy Loss: 10.333   Value Loss: 4.193    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 4110357    Buffer Size: 15137      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:47:09,988][train][INFO][train.py>_log] ==> #1762000    Total Loss: 1.085    [weighted Loss:1.085    Policy Loss: 9.787    Value Loss: 4.321    Reward Loss: 1.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 4113053    Buffer Size: 15134      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:50:41,109][train][INFO][train.py>_log] ==> #1763000    Total Loss: 1.174    [weighted Loss:1.174    Policy Loss: 9.542    Value Loss: 4.341    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 4115754    Buffer Size: 15123      Transition Number: 1000.129k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:54:13,839][train][INFO][train.py>_log] ==> #1764000    Total Loss: 0.816    [weighted Loss:0.816    Policy Loss: 9.486    Value Loss: 4.350    Reward Loss: 1.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 4118482    Buffer Size: 15107      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00010 
[2022-02-23 03:57:44,081][train][INFO][train.py>_log] ==> #1765000    Total Loss: 1.762    [weighted Loss:1.762    Policy Loss: 9.613    Value Loss: 4.651    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 4121105    Buffer Size: 15101      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:01:14,846][train][INFO][train.py>_log] ==> #1766000    Total Loss: 0.612    [weighted Loss:0.612    Policy Loss: 9.670    Value Loss: 4.533    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 4123875    Buffer Size: 15094      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:04:43,331][train][INFO][train.py>_log] ==> #1767000    Total Loss: 1.454    [weighted Loss:1.454    Policy Loss: 9.469    Value Loss: 4.265    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 4126645    Buffer Size: 15074      Transition Number: 1000.220k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:08:12,933][train][INFO][train.py>_log] ==> #1768000    Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 9.851    Value Loss: 4.038    Reward Loss: 1.764    Consistency Loss: 0.000    ] Replay Episodes Collected: 4129230    Buffer Size: 15065      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:11:45,530][train][INFO][train.py>_log] ==> #1769000    Total Loss: 1.366    [weighted Loss:1.366    Policy Loss: 9.453    Value Loss: 4.361    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 4131932    Buffer Size: 15052      Transition Number: 1000.217k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:15:16,096][train][INFO][train.py>_log] ==> #1770000    Total Loss: 0.861    [weighted Loss:0.861    Policy Loss: 9.499    Value Loss: 4.340    Reward Loss: 1.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 4134681    Buffer Size: 15045      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:18:51,736][train][INFO][train.py>_log] ==> #1771000    Total Loss: 1.978    [weighted Loss:1.978    Policy Loss: 9.066    Value Loss: 4.385    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 4137493    Buffer Size: 15033      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:22:22,814][train][INFO][train.py>_log] ==> #1772000    Total Loss: 1.861    [weighted Loss:1.861    Policy Loss: 9.711    Value Loss: 4.329    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 4140117    Buffer Size: 15031      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:25:52,550][train][INFO][train.py>_log] ==> #1773000    Total Loss: 1.873    [weighted Loss:1.873    Policy Loss: 9.699    Value Loss: 4.625    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 4142758    Buffer Size: 15042      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:29:21,081][train][INFO][train.py>_log] ==> #1774000    Total Loss: 1.227    [weighted Loss:1.227    Policy Loss: 9.484    Value Loss: 4.363    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 4145430    Buffer Size: 15059      Transition Number: 1000.265k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:32:54,261][train][INFO][train.py>_log] ==> #1775000    Total Loss: 1.305    [weighted Loss:1.305    Policy Loss: 9.708    Value Loss: 4.480    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 4148235    Buffer Size: 15043      Transition Number: 1000.257k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:36:21,752][train][INFO][train.py>_log] ==> #1776000    Total Loss: 1.647    [weighted Loss:1.647    Policy Loss: 9.496    Value Loss: 4.327    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 4150905    Buffer Size: 15033      Transition Number: 1000.138k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:39:52,494][train][INFO][train.py>_log] ==> #1777000    Total Loss: 1.540    [weighted Loss:1.540    Policy Loss: 9.129    Value Loss: 4.358    Reward Loss: 1.672    Consistency Loss: 0.000    ] Replay Episodes Collected: 4153501    Buffer Size: 15021      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:43:27,544][train][INFO][train.py>_log] ==> #1778000    Total Loss: 1.612    [weighted Loss:1.612    Policy Loss: 9.487    Value Loss: 4.258    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 4156272    Buffer Size: 15014      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:47:02,065][train][INFO][train.py>_log] ==> #1779000    Total Loss: 0.775    [weighted Loss:0.775    Policy Loss: 9.379    Value Loss: 4.529    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 4159051    Buffer Size: 14985      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:50:34,989][train][INFO][train.py>_log] ==> #1780000    Total Loss: 2.312    [weighted Loss:2.312    Policy Loss: 9.506    Value Loss: 4.689    Reward Loss: 1.785    Consistency Loss: 0.000    ] Replay Episodes Collected: 4161771    Buffer Size: 14971      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:54:07,174][train][INFO][train.py>_log] ==> #1781000    Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 9.543    Value Loss: 4.172    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 4164439    Buffer Size: 14978      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00010 
[2022-02-23 04:57:38,045][train][INFO][train.py>_log] ==> #1782000    Total Loss: 2.748    [weighted Loss:2.748    Policy Loss: 9.103    Value Loss: 4.251    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 4167213    Buffer Size: 14967      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:01:09,316][train][INFO][train.py>_log] ==> #1783000    Total Loss: 1.070    [weighted Loss:1.070    Policy Loss: 9.316    Value Loss: 4.271    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 4169889    Buffer Size: 14970      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:04:40,713][train][INFO][train.py>_log] ==> #1784000    Total Loss: 1.723    [weighted Loss:1.723    Policy Loss: 9.894    Value Loss: 4.840    Reward Loss: 1.821    Consistency Loss: 0.000    ] Replay Episodes Collected: 4172571    Buffer Size: 14985      Transition Number: 1000.435k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:08:15,966][train][INFO][train.py>_log] ==> #1785000    Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 9.129    Value Loss: 4.289    Reward Loss: 1.730    Consistency Loss: 0.000    ] Replay Episodes Collected: 4175286    Buffer Size: 14978      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:11:46,689][train][INFO][train.py>_log] ==> #1786000    Total Loss: 1.166    [weighted Loss:1.166    Policy Loss: 9.475    Value Loss: 4.262    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 4177940    Buffer Size: 14983      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:15:23,086][train][INFO][train.py>_log] ==> #1787000    Total Loss: 1.877    [weighted Loss:1.877    Policy Loss: 9.256    Value Loss: 4.185    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 4180750    Buffer Size: 15010      Transition Number: 1000.474k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:18:53,471][train][INFO][train.py>_log] ==> #1788000    Total Loss: 2.431    [weighted Loss:2.431    Policy Loss: 9.671    Value Loss: 4.490    Reward Loss: 1.658    Consistency Loss: 0.000    ] Replay Episodes Collected: 4183565    Buffer Size: 15007      Transition Number: 1000.124k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:22:27,185][train][INFO][train.py>_log] ==> #1789000    Total Loss: 0.846    [weighted Loss:0.846    Policy Loss: 9.526    Value Loss: 4.152    Reward Loss: 1.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 4186186    Buffer Size: 14998      Transition Number: 1000.379k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:25:56,296][train][INFO][train.py>_log] ==> #1790000    Total Loss: 2.348    [weighted Loss:2.348    Policy Loss: 9.440    Value Loss: 4.710    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 4188826    Buffer Size: 14995      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:29:27,076][train][INFO][train.py>_log] ==> #1791000    Total Loss: 2.007    [weighted Loss:2.007    Policy Loss: 9.312    Value Loss: 4.131    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 4191523    Buffer Size: 15009      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:32:59,947][train][INFO][train.py>_log] ==> #1792000    Total Loss: 1.813    [weighted Loss:1.813    Policy Loss: 9.691    Value Loss: 4.080    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 4194207    Buffer Size: 15009      Transition Number: 1000.327k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:36:33,494][train][INFO][train.py>_log] ==> #1793000    Total Loss: 1.892    [weighted Loss:1.892    Policy Loss: 9.589    Value Loss: 4.019    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 4197026    Buffer Size: 14973      Transition Number: 1000.041k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:40:04,042][train][INFO][train.py>_log] ==> #1794000    Total Loss: 1.617    [weighted Loss:1.617    Policy Loss: 9.555    Value Loss: 4.295    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 4199658    Buffer Size: 14981      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:43:34,176][train][INFO][train.py>_log] ==> #1795000    Total Loss: 1.752    [weighted Loss:1.752    Policy Loss: 9.503    Value Loss: 4.491    Reward Loss: 1.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 4202319    Buffer Size: 14977      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:47:07,101][train][INFO][train.py>_log] ==> #1796000    Total Loss: 1.573    [weighted Loss:1.573    Policy Loss: 9.354    Value Loss: 4.551    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 4205070    Buffer Size: 14973      Transition Number: 1000.196k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:50:33,971][train][INFO][train.py>_log] ==> #1797000    Total Loss: 1.266    [weighted Loss:1.266    Policy Loss: 9.435    Value Loss: 4.462    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 4207740    Buffer Size: 14953      Transition Number: 999.961 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:54:06,153][train][INFO][train.py>_log] ==> #1798000    Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 9.300    Value Loss: 4.288    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 4210396    Buffer Size: 14960      Transition Number: 1000.310k Batch Size: 256        Lr: 0.00010 
[2022-02-23 05:57:35,875][train][INFO][train.py>_log] ==> #1799000    Total Loss: 0.951    [weighted Loss:0.951    Policy Loss: 9.484    Value Loss: 4.247    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 4213036    Buffer Size: 14954      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:01:07,773][train][INFO][train.py>_log] ==> #1800000    Total Loss: 1.784    [weighted Loss:1.784    Policy Loss: 9.762    Value Loss: 4.331    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 4215749    Buffer Size: 14958      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:04:39,062][train][INFO][train.py>_log] ==> #1801000    Total Loss: 1.698    [weighted Loss:1.698    Policy Loss: 9.500    Value Loss: 4.193    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 4218490    Buffer Size: 14963      Transition Number: 1000.455k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:08:06,900][train][INFO][train.py>_log] ==> #1802000    Total Loss: 0.823    [weighted Loss:0.823    Policy Loss: 9.044    Value Loss: 4.183    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 4221117    Buffer Size: 14949      Transition Number: 1000.284k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:11:40,334][train][INFO][train.py>_log] ==> #1803000    Total Loss: 0.585    [weighted Loss:0.585    Policy Loss: 8.873    Value Loss: 4.406    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 4223905    Buffer Size: 14959      Transition Number: 1000.290k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:15:12,845][train][INFO][train.py>_log] ==> #1804000    Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 9.180    Value Loss: 4.180    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 4226523    Buffer Size: 14956      Transition Number: 1000.287k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:18:46,526][train][INFO][train.py>_log] ==> #1805000    Total Loss: 2.944    [weighted Loss:2.944    Policy Loss: 9.817    Value Loss: 4.354    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 4229324    Buffer Size: 14956      Transition Number: 1000.457k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:22:19,204][train][INFO][train.py>_log] ==> #1806000    Total Loss: 1.497    [weighted Loss:1.497    Policy Loss: 9.230    Value Loss: 4.342    Reward Loss: 1.698    Consistency Loss: 0.000    ] Replay Episodes Collected: 4232079    Buffer Size: 14952      Transition Number: 1000.332k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:25:47,897][train][INFO][train.py>_log] ==> #1807000    Total Loss: 1.398    [weighted Loss:1.398    Policy Loss: 9.443    Value Loss: 4.106    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 4234749    Buffer Size: 14947      Transition Number: 1000.029k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:29:18,056][train][INFO][train.py>_log] ==> #1808000    Total Loss: 0.500    [weighted Loss:0.500    Policy Loss: 9.588    Value Loss: 4.189    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 4237313    Buffer Size: 14967      Transition Number: 999.981 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:32:45,888][train][INFO][train.py>_log] ==> #1809000    Total Loss: 1.264    [weighted Loss:1.264    Policy Loss: 9.159    Value Loss: 4.263    Reward Loss: 1.692    Consistency Loss: 0.000    ] Replay Episodes Collected: 4240116    Buffer Size: 14970      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:36:23,133][train][INFO][train.py>_log] ==> #1810000    Total Loss: 0.836    [weighted Loss:0.836    Policy Loss: 9.263    Value Loss: 4.468    Reward Loss: 1.585    Consistency Loss: 0.000    ] Replay Episodes Collected: 4242834    Buffer Size: 14981      Transition Number: 1000.325k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:39:53,293][train][INFO][train.py>_log] ==> #1811000    Total Loss: 0.517    [weighted Loss:0.517    Policy Loss: 9.444    Value Loss: 4.383    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 4245543    Buffer Size: 14979      Transition Number: 1000.274k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:43:24,288][train][INFO][train.py>_log] ==> #1812000    Total Loss: 1.860    [weighted Loss:1.860    Policy Loss: 9.489    Value Loss: 4.364    Reward Loss: 1.586    Consistency Loss: 0.000    ] Replay Episodes Collected: 4248262    Buffer Size: 14975      Transition Number: 1000.159k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:46:59,247][train][INFO][train.py>_log] ==> #1813000    Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 9.684    Value Loss: 4.276    Reward Loss: 1.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 4250959    Buffer Size: 14949      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:50:30,469][train][INFO][train.py>_log] ==> #1814000    Total Loss: 2.284    [weighted Loss:2.284    Policy Loss: 9.544    Value Loss: 4.197    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 4253720    Buffer Size: 14915      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:53:58,894][train][INFO][train.py>_log] ==> #1815000    Total Loss: 1.323    [weighted Loss:1.323    Policy Loss: 9.235    Value Loss: 4.383    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 4256312    Buffer Size: 14912      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00010 
[2022-02-23 06:57:30,261][train][INFO][train.py>_log] ==> #1816000    Total Loss: 2.481    [weighted Loss:2.481    Policy Loss: 9.285    Value Loss: 4.276    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 4259073    Buffer Size: 14906      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:01:02,067][train][INFO][train.py>_log] ==> #1817000    Total Loss: 2.283    [weighted Loss:2.283    Policy Loss: 9.379    Value Loss: 4.575    Reward Loss: 1.594    Consistency Loss: 0.000    ] Replay Episodes Collected: 4261695    Buffer Size: 14897      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:04:34,156][train][INFO][train.py>_log] ==> #1818000    Total Loss: 1.361    [weighted Loss:1.361    Policy Loss: 9.486    Value Loss: 4.061    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 4264429    Buffer Size: 14910      Transition Number: 1000.138k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:08:08,366][train][INFO][train.py>_log] ==> #1819000    Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 9.106    Value Loss: 4.419    Reward Loss: 1.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 4267176    Buffer Size: 14914      Transition Number: 1000.283k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:11:37,706][train][INFO][train.py>_log] ==> #1820000    Total Loss: 1.748    [weighted Loss:1.748    Policy Loss: 9.582    Value Loss: 4.335    Reward Loss: 1.497    Consistency Loss: 0.000    ] Replay Episodes Collected: 4269846    Buffer Size: 14915      Transition Number: 1000.331k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:15:06,786][train][INFO][train.py>_log] ==> #1821000    Total Loss: 1.035    [weighted Loss:1.035    Policy Loss: 9.425    Value Loss: 4.384    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 4272513    Buffer Size: 14898      Transition Number: 1000.118k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:18:40,890][train][INFO][train.py>_log] ==> #1822000    Total Loss: 2.012    [weighted Loss:2.012    Policy Loss: 9.368    Value Loss: 4.380    Reward Loss: 1.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 4275227    Buffer Size: 14905      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:22:13,139][train][INFO][train.py>_log] ==> #1823000    Total Loss: 1.746    [weighted Loss:1.746    Policy Loss: 9.168    Value Loss: 4.277    Reward Loss: 1.767    Consistency Loss: 0.000    ] Replay Episodes Collected: 4277997    Buffer Size: 14896      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:25:44,695][train][INFO][train.py>_log] ==> #1824000    Total Loss: 2.421    [weighted Loss:2.421    Policy Loss: 9.935    Value Loss: 4.368    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 4280713    Buffer Size: 14886      Transition Number: 1000.495k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:29:20,455][train][INFO][train.py>_log] ==> #1825000    Total Loss: 1.216    [weighted Loss:1.216    Policy Loss: 9.122    Value Loss: 4.364    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 4283299    Buffer Size: 14889      Transition Number: 999.962 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:32:51,509][train][INFO][train.py>_log] ==> #1826000    Total Loss: 1.357    [weighted Loss:1.357    Policy Loss: 9.592    Value Loss: 4.439    Reward Loss: 1.597    Consistency Loss: 0.000    ] Replay Episodes Collected: 4286147    Buffer Size: 14891      Transition Number: 1000.697k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:36:23,633][train][INFO][train.py>_log] ==> #1827000    Total Loss: 1.180    [weighted Loss:1.180    Policy Loss: 9.448    Value Loss: 4.085    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 4288823    Buffer Size: 14865      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:39:55,976][train][INFO][train.py>_log] ==> #1828000    Total Loss: 1.903    [weighted Loss:1.903    Policy Loss: 9.267    Value Loss: 4.226    Reward Loss: 1.754    Consistency Loss: 0.000    ] Replay Episodes Collected: 4291554    Buffer Size: 14844      Transition Number: 999.941 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:43:28,889][train][INFO][train.py>_log] ==> #1829000    Total Loss: 1.528    [weighted Loss:1.528    Policy Loss: 9.349    Value Loss: 4.162    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 4294210    Buffer Size: 14857      Transition Number: 1000.216k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:47:02,564][train][INFO][train.py>_log] ==> #1830000    Total Loss: 1.322    [weighted Loss:1.322    Policy Loss: 9.774    Value Loss: 4.312    Reward Loss: 1.634    Consistency Loss: 0.000    ] Replay Episodes Collected: 4296942    Buffer Size: 14853      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:50:36,689][train][INFO][train.py>_log] ==> #1831000    Total Loss: 1.257    [weighted Loss:1.257    Policy Loss: 9.070    Value Loss: 4.305    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 4299654    Buffer Size: 14849      Transition Number: 1000.092k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:54:07,721][train][INFO][train.py>_log] ==> #1832000    Total Loss: 1.114    [weighted Loss:1.114    Policy Loss: 9.511    Value Loss: 4.372    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 4302471    Buffer Size: 14862      Transition Number: 1000.516k Batch Size: 256        Lr: 0.00010 
[2022-02-23 07:57:40,140][train][INFO][train.py>_log] ==> #1833000    Total Loss: 1.093    [weighted Loss:1.093    Policy Loss: 9.125    Value Loss: 4.335    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 4305071    Buffer Size: 14877      Transition Number: 999.969 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:01:14,206][train][INFO][train.py>_log] ==> #1834000    Total Loss: 2.119    [weighted Loss:2.119    Policy Loss: 8.979    Value Loss: 4.503    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 4307804    Buffer Size: 14880      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:04:48,566][train][INFO][train.py>_log] ==> #1835000    Total Loss: 1.279    [weighted Loss:1.279    Policy Loss: 9.560    Value Loss: 4.573    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 4310575    Buffer Size: 14880      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:08:20,121][train][INFO][train.py>_log] ==> #1836000    Total Loss: 1.268    [weighted Loss:1.268    Policy Loss: 9.247    Value Loss: 4.280    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 4313335    Buffer Size: 14888      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:11:50,780][train][INFO][train.py>_log] ==> #1837000    Total Loss: 0.998    [weighted Loss:0.998    Policy Loss: 9.200    Value Loss: 4.301    Reward Loss: 1.814    Consistency Loss: 0.000    ] Replay Episodes Collected: 4315953    Buffer Size: 14885      Transition Number: 1000.229k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:15:22,617][train][INFO][train.py>_log] ==> #1838000    Total Loss: 1.273    [weighted Loss:1.273    Policy Loss: 9.001    Value Loss: 4.066    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 4318641    Buffer Size: 14869      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:18:54,691][train][INFO][train.py>_log] ==> #1839000    Total Loss: 0.816    [weighted Loss:0.816    Policy Loss: 9.096    Value Loss: 4.282    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 4321395    Buffer Size: 14872      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:22:27,290][train][INFO][train.py>_log] ==> #1840000    Total Loss: 1.566    [weighted Loss:1.566    Policy Loss: 9.105    Value Loss: 4.318    Reward Loss: 1.681    Consistency Loss: 0.000    ] Replay Episodes Collected: 4324047    Buffer Size: 14877      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:26:01,386][train][INFO][train.py>_log] ==> #1841000    Total Loss: 1.574    [weighted Loss:1.574    Policy Loss: 9.195    Value Loss: 4.146    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 4326813    Buffer Size: 14874      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:29:32,029][train][INFO][train.py>_log] ==> #1842000    Total Loss: 1.025    [weighted Loss:1.025    Policy Loss: 9.162    Value Loss: 4.293    Reward Loss: 1.752    Consistency Loss: 0.000    ] Replay Episodes Collected: 4329508    Buffer Size: 14892      Transition Number: 1000.040k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:33:02,427][train][INFO][train.py>_log] ==> #1843000    Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 9.383    Value Loss: 4.513    Reward Loss: 1.671    Consistency Loss: 0.000    ] Replay Episodes Collected: 4332200    Buffer Size: 14894      Transition Number: 1000.183k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:36:33,756][train][INFO][train.py>_log] ==> #1844000    Total Loss: 2.165    [weighted Loss:2.165    Policy Loss: 9.106    Value Loss: 4.209    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 4334903    Buffer Size: 14892      Transition Number: 1000.173k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:40:04,885][train][INFO][train.py>_log] ==> #1845000    Total Loss: 1.024    [weighted Loss:1.024    Policy Loss: 8.971    Value Loss: 4.220    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 4337656    Buffer Size: 14885      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:43:39,152][train][INFO][train.py>_log] ==> #1846000    Total Loss: 1.127    [weighted Loss:1.127    Policy Loss: 9.348    Value Loss: 4.282    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 4340340    Buffer Size: 14886      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:47:15,705][train][INFO][train.py>_log] ==> #1847000    Total Loss: 0.622    [weighted Loss:0.622    Policy Loss: 9.842    Value Loss: 4.305    Reward Loss: 1.682    Consistency Loss: 0.000    ] Replay Episodes Collected: 4343078    Buffer Size: 14874      Transition Number: 999.965 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:50:45,787][train][INFO][train.py>_log] ==> #1848000    Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 9.460    Value Loss: 4.611    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 4345782    Buffer Size: 14863      Transition Number: 1000.131k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:54:18,849][train][INFO][train.py>_log] ==> #1849000    Total Loss: 2.396    [weighted Loss:2.396    Policy Loss: 9.531    Value Loss: 4.399    Reward Loss: 1.630    Consistency Loss: 0.000    ] Replay Episodes Collected: 4348584    Buffer Size: 14865      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 08:57:49,448][train][INFO][train.py>_log] ==> #1850000    Total Loss: 0.373    [weighted Loss:0.373    Policy Loss: 9.322    Value Loss: 4.278    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 4351164    Buffer Size: 14873      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:01:22,928][train][INFO][train.py>_log] ==> #1851000    Total Loss: 1.872    [weighted Loss:1.872    Policy Loss: 9.182    Value Loss: 4.707    Reward Loss: 1.553    Consistency Loss: 0.000    ] Replay Episodes Collected: 4353930    Buffer Size: 14872      Transition Number: 1000.390k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:04:55,475][train][INFO][train.py>_log] ==> #1852000    Total Loss: 2.393    [weighted Loss:2.393    Policy Loss: 9.528    Value Loss: 4.318    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 4356618    Buffer Size: 14869      Transition Number: 1000.231k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:08:27,938][train][INFO][train.py>_log] ==> #1853000    Total Loss: 1.085    [weighted Loss:1.085    Policy Loss: 9.758    Value Loss: 4.255    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 4359379    Buffer Size: 14873      Transition Number: 1000.037k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:11:59,086][train][INFO][train.py>_log] ==> #1854000    Total Loss: 0.863    [weighted Loss:0.863    Policy Loss: 9.059    Value Loss: 4.179    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 4362083    Buffer Size: 14874      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:15:31,851][train][INFO][train.py>_log] ==> #1855000    Total Loss: 1.370    [weighted Loss:1.370    Policy Loss: 9.286    Value Loss: 4.300    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 4364810    Buffer Size: 14859      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:19:00,022][train][INFO][train.py>_log] ==> #1856000    Total Loss: 1.531    [weighted Loss:1.531    Policy Loss: 8.890    Value Loss: 4.101    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 4367387    Buffer Size: 14859      Transition Number: 999.936 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:22:31,830][train][INFO][train.py>_log] ==> #1857000    Total Loss: 0.801    [weighted Loss:0.801    Policy Loss: 9.178    Value Loss: 4.355    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 4370064    Buffer Size: 14855      Transition Number: 1000.043k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:26:05,662][train][INFO][train.py>_log] ==> #1858000    Total Loss: 1.321    [weighted Loss:1.321    Policy Loss: 9.539    Value Loss: 4.471    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 4372831    Buffer Size: 14862      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:29:36,894][train][INFO][train.py>_log] ==> #1859000    Total Loss: 1.286    [weighted Loss:1.286    Policy Loss: 9.738    Value Loss: 4.361    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 4375533    Buffer Size: 14836      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:33:11,877][train][INFO][train.py>_log] ==> #1860000    Total Loss: 1.344    [weighted Loss:1.344    Policy Loss: 9.353    Value Loss: 4.494    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 4378317    Buffer Size: 14852      Transition Number: 1000.356k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:36:45,016][train][INFO][train.py>_log] ==> #1861000    Total Loss: 1.818    [weighted Loss:1.818    Policy Loss: 9.571    Value Loss: 4.410    Reward Loss: 1.636    Consistency Loss: 0.000    ] Replay Episodes Collected: 4381027    Buffer Size: 14844      Transition Number: 1000.101k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:40:17,667][train][INFO][train.py>_log] ==> #1862000    Total Loss: 0.673    [weighted Loss:0.673    Policy Loss: 9.150    Value Loss: 4.287    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 4383761    Buffer Size: 14833      Transition Number: 1000.057k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:43:51,610][train][INFO][train.py>_log] ==> #1863000    Total Loss: 1.507    [weighted Loss:1.507    Policy Loss: 9.482    Value Loss: 4.041    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 4386458    Buffer Size: 14831      Transition Number: 1000.163k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:47:26,787][train][INFO][train.py>_log] ==> #1864000    Total Loss: 1.634    [weighted Loss:1.634    Policy Loss: 9.209    Value Loss: 3.992    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 4389157    Buffer Size: 14846      Transition Number: 1000.367k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:51:02,241][train][INFO][train.py>_log] ==> #1865000    Total Loss: 1.357    [weighted Loss:1.357    Policy Loss: 9.299    Value Loss: 3.969    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 4391977    Buffer Size: 14855      Transition Number: 999.983 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:54:38,412][train][INFO][train.py>_log] ==> #1866000    Total Loss: 2.288    [weighted Loss:2.288    Policy Loss: 9.358    Value Loss: 4.048    Reward Loss: 1.709    Consistency Loss: 0.000    ] Replay Episodes Collected: 4394702    Buffer Size: 14861      Transition Number: 1000.396k Batch Size: 256        Lr: 0.00010 
[2022-02-23 09:58:11,159][train][INFO][train.py>_log] ==> #1867000    Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 9.785    Value Loss: 4.244    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 4397386    Buffer Size: 14863      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:01:48,084][train][INFO][train.py>_log] ==> #1868000    Total Loss: 1.583    [weighted Loss:1.583    Policy Loss: 9.518    Value Loss: 4.130    Reward Loss: 1.708    Consistency Loss: 0.000    ] Replay Episodes Collected: 4400213    Buffer Size: 14879      Transition Number: 1000.282k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:05:22,737][train][INFO][train.py>_log] ==> #1869000    Total Loss: 0.685    [weighted Loss:0.685    Policy Loss: 9.315    Value Loss: 4.201    Reward Loss: 1.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 4402909    Buffer Size: 14882      Transition Number: 1000.355k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:08:58,408][train][INFO][train.py>_log] ==> #1870000    Total Loss: 1.223    [weighted Loss:1.223    Policy Loss: 9.262    Value Loss: 4.182    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 4405654    Buffer Size: 14874      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:12:29,903][train][INFO][train.py>_log] ==> #1871000    Total Loss: 1.019    [weighted Loss:1.019    Policy Loss: 9.807    Value Loss: 4.138    Reward Loss: 1.555    Consistency Loss: 0.000    ] Replay Episodes Collected: 4408378    Buffer Size: 14875      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:16:03,441][train][INFO][train.py>_log] ==> #1872000    Total Loss: 1.136    [weighted Loss:1.136    Policy Loss: 9.376    Value Loss: 4.301    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 4411101    Buffer Size: 14876      Transition Number: 1000.459k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:19:37,816][train][INFO][train.py>_log] ==> #1873000    Total Loss: 1.850    [weighted Loss:1.850    Policy Loss: 9.070    Value Loss: 4.158    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 4413858    Buffer Size: 14874      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:23:12,680][train][INFO][train.py>_log] ==> #1874000    Total Loss: 2.001    [weighted Loss:2.001    Policy Loss: 9.983    Value Loss: 4.154    Reward Loss: 1.683    Consistency Loss: 0.000    ] Replay Episodes Collected: 4416539    Buffer Size: 14892      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:26:48,545][train][INFO][train.py>_log] ==> #1875000    Total Loss: 1.172    [weighted Loss:1.172    Policy Loss: 9.757    Value Loss: 4.183    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 4419384    Buffer Size: 14888      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:30:22,730][train][INFO][train.py>_log] ==> #1876000    Total Loss: 1.309    [weighted Loss:1.309    Policy Loss: 9.309    Value Loss: 4.127    Reward Loss: 1.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 4422036    Buffer Size: 14889      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:33:55,366][train][INFO][train.py>_log] ==> #1877000    Total Loss: 1.047    [weighted Loss:1.047    Policy Loss: 9.007    Value Loss: 4.001    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 4424819    Buffer Size: 14887      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:37:26,618][train][INFO][train.py>_log] ==> #1878000    Total Loss: 0.840    [weighted Loss:0.840    Policy Loss: 9.680    Value Loss: 4.357    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 4427413    Buffer Size: 14895      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:41:02,161][train][INFO][train.py>_log] ==> #1879000    Total Loss: 1.026    [weighted Loss:1.026    Policy Loss: 9.487    Value Loss: 4.499    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 4430262    Buffer Size: 14879      Transition Number: 1000.019k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:44:39,784][train][INFO][train.py>_log] ==> #1880000    Total Loss: 1.166    [weighted Loss:1.166    Policy Loss: 9.221    Value Loss: 4.591    Reward Loss: 1.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 4432967    Buffer Size: 14884      Transition Number: 999.993 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:48:13,552][train][INFO][train.py>_log] ==> #1881000    Total Loss: 1.426    [weighted Loss:1.426    Policy Loss: 9.225    Value Loss: 4.192    Reward Loss: 1.605    Consistency Loss: 0.000    ] Replay Episodes Collected: 4435754    Buffer Size: 14880      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:51:50,334][train][INFO][train.py>_log] ==> #1882000    Total Loss: 1.412    [weighted Loss:1.412    Policy Loss: 9.119    Value Loss: 4.046    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 4438438    Buffer Size: 14872      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:55:22,836][train][INFO][train.py>_log] ==> #1883000    Total Loss: 1.920    [weighted Loss:1.920    Policy Loss: 9.625    Value Loss: 4.234    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 4441234    Buffer Size: 14862      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 10:58:57,754][train][INFO][train.py>_log] ==> #1884000    Total Loss: 1.974    [weighted Loss:1.974    Policy Loss: 9.237    Value Loss: 4.265    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 4443971    Buffer Size: 14873      Transition Number: 1000.540k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:02:34,085][train][INFO][train.py>_log] ==> #1885000    Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 9.479    Value Loss: 4.465    Reward Loss: 1.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 4446719    Buffer Size: 14863      Transition Number: 1000.169k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:06:09,707][train][INFO][train.py>_log] ==> #1886000    Total Loss: 1.791    [weighted Loss:1.791    Policy Loss: 9.419    Value Loss: 4.085    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 4449426    Buffer Size: 14870      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:09:43,810][train][INFO][train.py>_log] ==> #1887000    Total Loss: 1.248    [weighted Loss:1.248    Policy Loss: 9.216    Value Loss: 4.081    Reward Loss: 1.607    Consistency Loss: 0.000    ] Replay Episodes Collected: 4452238    Buffer Size: 14870      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:13:19,052][train][INFO][train.py>_log] ==> #1888000    Total Loss: 1.755    [weighted Loss:1.755    Policy Loss: 9.803    Value Loss: 4.410    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 4454933    Buffer Size: 14875      Transition Number: 1000.291k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:16:53,246][train][INFO][train.py>_log] ==> #1889000    Total Loss: 1.819    [weighted Loss:1.819    Policy Loss: 9.552    Value Loss: 4.156    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 4457681    Buffer Size: 14868      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:20:26,266][train][INFO][train.py>_log] ==> #1890000    Total Loss: 1.068    [weighted Loss:1.068    Policy Loss: 9.533    Value Loss: 4.195    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 4460435    Buffer Size: 14874      Transition Number: 1000.696k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:24:00,966][train][INFO][train.py>_log] ==> #1891000    Total Loss: 1.071    [weighted Loss:1.071    Policy Loss: 9.568    Value Loss: 4.090    Reward Loss: 1.633    Consistency Loss: 0.000    ] Replay Episodes Collected: 4463112    Buffer Size: 14851      Transition Number: 1000.213k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:27:35,116][train][INFO][train.py>_log] ==> #1892000    Total Loss: 1.453    [weighted Loss:1.453    Policy Loss: 9.398    Value Loss: 4.128    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 4465826    Buffer Size: 14831      Transition Number: 999.938 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:31:11,618][train][INFO][train.py>_log] ==> #1893000    Total Loss: 0.770    [weighted Loss:0.770    Policy Loss: 9.958    Value Loss: 4.449    Reward Loss: 1.543    Consistency Loss: 0.000    ] Replay Episodes Collected: 4468616    Buffer Size: 14830      Transition Number: 1000.163k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:34:45,584][train][INFO][train.py>_log] ==> #1894000    Total Loss: 1.763    [weighted Loss:1.763    Policy Loss: 9.113    Value Loss: 4.292    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 4471306    Buffer Size: 14825      Transition Number: 1000.303k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:38:20,360][train][INFO][train.py>_log] ==> #1895000    Total Loss: 1.092    [weighted Loss:1.092    Policy Loss: 9.423    Value Loss: 4.180    Reward Loss: 1.670    Consistency Loss: 0.000    ] Replay Episodes Collected: 4474167    Buffer Size: 14828      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:41:54,493][train][INFO][train.py>_log] ==> #1896000    Total Loss: 2.021    [weighted Loss:2.021    Policy Loss: 9.542    Value Loss: 4.049    Reward Loss: 1.564    Consistency Loss: 0.000    ] Replay Episodes Collected: 4476792    Buffer Size: 14840      Transition Number: 1000.266k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:45:27,713][train][INFO][train.py>_log] ==> #1897000    Total Loss: 2.334    [weighted Loss:2.334    Policy Loss: 9.559    Value Loss: 4.410    Reward Loss: 1.787    Consistency Loss: 0.000    ] Replay Episodes Collected: 4479615    Buffer Size: 14846      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:49:02,931][train][INFO][train.py>_log] ==> #1898000    Total Loss: 1.770    [weighted Loss:1.770    Policy Loss: 9.037    Value Loss: 4.319    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 4482253    Buffer Size: 14849      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:52:36,371][train][INFO][train.py>_log] ==> #1899000    Total Loss: 1.824    [weighted Loss:1.824    Policy Loss: 9.590    Value Loss: 4.525    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 4485029    Buffer Size: 14854      Transition Number: 999.950 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:56:10,133][train][INFO][train.py>_log] ==> #1900000    Total Loss: 1.862    [weighted Loss:1.862    Policy Loss: 9.540    Value Loss: 4.238    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 4487757    Buffer Size: 14858      Transition Number: 1000.285k Batch Size: 256        Lr: 0.00010 
[2022-02-23 11:59:45,616][train][INFO][train.py>_log] ==> #1901000    Total Loss: 1.007    [weighted Loss:1.007    Policy Loss: 9.829    Value Loss: 4.195    Reward Loss: 1.638    Consistency Loss: 0.000    ] Replay Episodes Collected: 4490484    Buffer Size: 14845      Transition Number: 1000.200k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:03:20,337][train][INFO][train.py>_log] ==> #1902000    Total Loss: 1.610    [weighted Loss:1.610    Policy Loss: 9.537    Value Loss: 4.398    Reward Loss: 1.602    Consistency Loss: 0.000    ] Replay Episodes Collected: 4493335    Buffer Size: 14824      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:06:52,544][train][INFO][train.py>_log] ==> #1903000    Total Loss: 2.167    [weighted Loss:2.167    Policy Loss: 9.508    Value Loss: 4.441    Reward Loss: 1.614    Consistency Loss: 0.000    ] Replay Episodes Collected: 4495985    Buffer Size: 14829      Transition Number: 999.960 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:10:22,766][train][INFO][train.py>_log] ==> #1904000    Total Loss: 0.932    [weighted Loss:0.932    Policy Loss: 9.152    Value Loss: 4.244    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 4498655    Buffer Size: 14826      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:13:56,867][train][INFO][train.py>_log] ==> #1905000    Total Loss: 0.958    [weighted Loss:0.958    Policy Loss: 9.323    Value Loss: 4.207    Reward Loss: 1.566    Consistency Loss: 0.000    ] Replay Episodes Collected: 4501267    Buffer Size: 14827      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:17:31,795][train][INFO][train.py>_log] ==> #1906000    Total Loss: 0.910    [weighted Loss:0.910    Policy Loss: 9.478    Value Loss: 4.321    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 4504154    Buffer Size: 14827      Transition Number: 1000.113k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:21:09,529][train][INFO][train.py>_log] ==> #1907000    Total Loss: 2.059    [weighted Loss:2.059    Policy Loss: 9.388    Value Loss: 4.231    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 4506832    Buffer Size: 14841      Transition Number: 1000.508k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:24:46,968][train][INFO][train.py>_log] ==> #1908000    Total Loss: 2.117    [weighted Loss:2.117    Policy Loss: 9.373    Value Loss: 4.244    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 4509692    Buffer Size: 14831      Transition Number: 1000.066k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:28:21,618][train][INFO][train.py>_log] ==> #1909000    Total Loss: 0.972    [weighted Loss:0.972    Policy Loss: 9.215    Value Loss: 4.334    Reward Loss: 1.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 4512440    Buffer Size: 14835      Transition Number: 1001.010k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:31:55,901][train][INFO][train.py>_log] ==> #1910000    Total Loss: 1.983    [weighted Loss:1.983    Policy Loss: 9.954    Value Loss: 4.352    Reward Loss: 1.606    Consistency Loss: 0.000    ] Replay Episodes Collected: 4515154    Buffer Size: 14811      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:35:31,995][train][INFO][train.py>_log] ==> #1911000    Total Loss: 1.121    [weighted Loss:1.121    Policy Loss: 9.051    Value Loss: 4.255    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 4517886    Buffer Size: 14810      Transition Number: 999.955 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:39:06,826][train][INFO][train.py>_log] ==> #1912000    Total Loss: 2.425    [weighted Loss:2.425    Policy Loss: 9.848    Value Loss: 4.290    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 4520616    Buffer Size: 14792      Transition Number: 1000.172k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:42:43,064][train][INFO][train.py>_log] ==> #1913000    Total Loss: 1.703    [weighted Loss:1.703    Policy Loss: 9.268    Value Loss: 4.668    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 4523409    Buffer Size: 14802      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:46:18,856][train][INFO][train.py>_log] ==> #1914000    Total Loss: 0.991    [weighted Loss:0.991    Policy Loss: 9.589    Value Loss: 4.330    Reward Loss: 1.738    Consistency Loss: 0.000    ] Replay Episodes Collected: 4526099    Buffer Size: 14797      Transition Number: 1000.163k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:49:53,174][train][INFO][train.py>_log] ==> #1915000    Total Loss: 1.499    [weighted Loss:1.499    Policy Loss: 9.418    Value Loss: 4.479    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 4528841    Buffer Size: 14799      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:53:27,205][train][INFO][train.py>_log] ==> #1916000    Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 9.363    Value Loss: 4.392    Reward Loss: 1.784    Consistency Loss: 0.000    ] Replay Episodes Collected: 4531606    Buffer Size: 14799      Transition Number: 999.982 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 12:57:03,189][train][INFO][train.py>_log] ==> #1917000    Total Loss: 0.315    [weighted Loss:0.315    Policy Loss: 9.311    Value Loss: 4.573    Reward Loss: 1.574    Consistency Loss: 0.000    ] Replay Episodes Collected: 4534320    Buffer Size: 14813      Transition Number: 1000.301k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:00:37,430][train][INFO][train.py>_log] ==> #1918000    Total Loss: 1.129    [weighted Loss:1.129    Policy Loss: 9.528    Value Loss: 4.380    Reward Loss: 1.696    Consistency Loss: 0.000    ] Replay Episodes Collected: 4537058    Buffer Size: 14797      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:04:12,683][train][INFO][train.py>_log] ==> #1919000    Total Loss: 2.003    [weighted Loss:2.003    Policy Loss: 9.603    Value Loss: 4.524    Reward Loss: 1.739    Consistency Loss: 0.000    ] Replay Episodes Collected: 4539765    Buffer Size: 14795      Transition Number: 1000.377k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:07:44,615][train][INFO][train.py>_log] ==> #1920000    Total Loss: 1.970    [weighted Loss:1.970    Policy Loss: 9.735    Value Loss: 4.506    Reward Loss: 1.604    Consistency Loss: 0.000    ] Replay Episodes Collected: 4542464    Buffer Size: 14776      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:11:16,990][train][INFO][train.py>_log] ==> #1921000    Total Loss: 1.653    [weighted Loss:1.653    Policy Loss: 9.978    Value Loss: 4.431    Reward Loss: 1.668    Consistency Loss: 0.000    ] Replay Episodes Collected: 4545117    Buffer Size: 14776      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:14:53,687][train][INFO][train.py>_log] ==> #1922000    Total Loss: 2.197    [weighted Loss:2.197    Policy Loss: 8.971    Value Loss: 4.041    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 4547902    Buffer Size: 14759      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:18:30,230][train][INFO][train.py>_log] ==> #1923000    Total Loss: 1.550    [weighted Loss:1.550    Policy Loss: 9.685    Value Loss: 4.331    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 4550757    Buffer Size: 14781      Transition Number: 1000.985k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:22:06,698][train][INFO][train.py>_log] ==> #1924000    Total Loss: 0.708    [weighted Loss:0.708    Policy Loss: 9.165    Value Loss: 4.542    Reward Loss: 1.676    Consistency Loss: 0.000    ] Replay Episodes Collected: 4553399    Buffer Size: 14757      Transition Number: 999.951 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:25:41,872][train][INFO][train.py>_log] ==> #1925000    Total Loss: 1.370    [weighted Loss:1.370    Policy Loss: 9.197    Value Loss: 4.183    Reward Loss: 1.591    Consistency Loss: 0.000    ] Replay Episodes Collected: 4556212    Buffer Size: 14746      Transition Number: 1000.220k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:29:16,202][train][INFO][train.py>_log] ==> #1926000    Total Loss: 0.921    [weighted Loss:0.921    Policy Loss: 9.337    Value Loss: 4.361    Reward Loss: 1.742    Consistency Loss: 0.000    ] Replay Episodes Collected: 4558898    Buffer Size: 14738      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:32:49,369][train][INFO][train.py>_log] ==> #1927000    Total Loss: 1.534    [weighted Loss:1.534    Policy Loss: 8.890    Value Loss: 4.236    Reward Loss: 1.734    Consistency Loss: 0.000    ] Replay Episodes Collected: 4561629    Buffer Size: 14730      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:36:23,999][train][INFO][train.py>_log] ==> #1928000    Total Loss: 1.188    [weighted Loss:1.188    Policy Loss: 9.452    Value Loss: 4.752    Reward Loss: 1.596    Consistency Loss: 0.000    ] Replay Episodes Collected: 4564332    Buffer Size: 14738      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:39:59,899][train][INFO][train.py>_log] ==> #1929000    Total Loss: 1.581    [weighted Loss:1.581    Policy Loss: 9.204    Value Loss: 4.015    Reward Loss: 1.610    Consistency Loss: 0.000    ] Replay Episodes Collected: 4567038    Buffer Size: 14731      Transition Number: 1000.055k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:43:37,803][train][INFO][train.py>_log] ==> #1930000    Total Loss: 1.343    [weighted Loss:1.343    Policy Loss: 9.715    Value Loss: 4.288    Reward Loss: 1.629    Consistency Loss: 0.000    ] Replay Episodes Collected: 4569856    Buffer Size: 14738      Transition Number: 1000.052k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:47:13,296][train][INFO][train.py>_log] ==> #1931000    Total Loss: 1.502    [weighted Loss:1.502    Policy Loss: 9.371    Value Loss: 4.479    Reward Loss: 1.717    Consistency Loss: 0.000    ] Replay Episodes Collected: 4572576    Buffer Size: 14757      Transition Number: 1000.085k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:50:49,646][train][INFO][train.py>_log] ==> #1932000    Total Loss: 1.689    [weighted Loss:1.689    Policy Loss: 9.134    Value Loss: 4.426    Reward Loss: 1.661    Consistency Loss: 0.000    ] Replay Episodes Collected: 4575402    Buffer Size: 14765      Transition Number: 1000.198k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:54:23,446][train][INFO][train.py>_log] ==> #1933000    Total Loss: 2.273    [weighted Loss:2.273    Policy Loss: 9.489    Value Loss: 4.307    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 4577957    Buffer Size: 14765      Transition Number: 999.947 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 13:57:59,391][train][INFO][train.py>_log] ==> #1934000    Total Loss: 0.849    [weighted Loss:0.849    Policy Loss: 9.555    Value Loss: 4.362    Reward Loss: 1.623    Consistency Loss: 0.000    ] Replay Episodes Collected: 4580805    Buffer Size: 14768      Transition Number: 1000.305k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:01:38,252][train][INFO][train.py>_log] ==> #1935000    Total Loss: 0.768    [weighted Loss:0.768    Policy Loss: 9.295    Value Loss: 4.530    Reward Loss: 1.613    Consistency Loss: 0.000    ] Replay Episodes Collected: 4583519    Buffer Size: 14787      Transition Number: 1000.227k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:05:15,803][train][INFO][train.py>_log] ==> #1936000    Total Loss: 1.474    [weighted Loss:1.474    Policy Loss: 9.515    Value Loss: 4.521    Reward Loss: 1.598    Consistency Loss: 0.000    ] Replay Episodes Collected: 4586293    Buffer Size: 14776      Transition Number: 1000.416k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:08:47,342][train][INFO][train.py>_log] ==> #1937000    Total Loss: 1.034    [weighted Loss:1.034    Policy Loss: 9.698    Value Loss: 4.608    Reward Loss: 1.724    Consistency Loss: 0.000    ] Replay Episodes Collected: 4588988    Buffer Size: 14761      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:12:24,230][train][INFO][train.py>_log] ==> #1938000    Total Loss: 2.243    [weighted Loss:2.243    Policy Loss: 9.124    Value Loss: 4.646    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 4591768    Buffer Size: 14747      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:15:59,353][train][INFO][train.py>_log] ==> #1939000    Total Loss: 1.293    [weighted Loss:1.293    Policy Loss: 9.227    Value Loss: 4.753    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 4594496    Buffer Size: 14748      Transition Number: 999.934 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:19:35,348][train][INFO][train.py>_log] ==> #1940000    Total Loss: 1.260    [weighted Loss:1.260    Policy Loss: 8.918    Value Loss: 4.427    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 4597211    Buffer Size: 14742      Transition Number: 1000.458k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:23:10,230][train][INFO][train.py>_log] ==> #1941000    Total Loss: 1.199    [weighted Loss:1.199    Policy Loss: 9.400    Value Loss: 4.402    Reward Loss: 1.515    Consistency Loss: 0.000    ] Replay Episodes Collected: 4600020    Buffer Size: 14725      Transition Number: 999.979 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:26:46,659][train][INFO][train.py>_log] ==> #1942000    Total Loss: 0.886    [weighted Loss:0.886    Policy Loss: 9.430    Value Loss: 4.311    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 4602674    Buffer Size: 14726      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:30:21,592][train][INFO][train.py>_log] ==> #1943000    Total Loss: 1.480    [weighted Loss:1.480    Policy Loss: 9.307    Value Loss: 4.528    Reward Loss: 1.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 4605450    Buffer Size: 14729      Transition Number: 999.985 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:33:55,312][train][INFO][train.py>_log] ==> #1944000    Total Loss: 1.179    [weighted Loss:1.179    Policy Loss: 9.003    Value Loss: 4.718    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 4608238    Buffer Size: 14730      Transition Number: 1000.247k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:37:31,936][train][INFO][train.py>_log] ==> #1945000    Total Loss: 2.539    [weighted Loss:2.539    Policy Loss: 9.133    Value Loss: 4.501    Reward Loss: 1.716    Consistency Loss: 0.000    ] Replay Episodes Collected: 4610895    Buffer Size: 14733      Transition Number: 999.959 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:41:05,196][train][INFO][train.py>_log] ==> #1946000    Total Loss: 1.457    [weighted Loss:1.457    Policy Loss: 9.577    Value Loss: 4.527    Reward Loss: 1.766    Consistency Loss: 0.000    ] Replay Episodes Collected: 4613572    Buffer Size: 14738      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:44:39,552][train][INFO][train.py>_log] ==> #1947000    Total Loss: 1.208    [weighted Loss:1.208    Policy Loss: 9.581    Value Loss: 4.410    Reward Loss: 1.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 4616386    Buffer Size: 14726      Transition Number: 1000.136k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:48:14,939][train][INFO][train.py>_log] ==> #1948000    Total Loss: 1.860    [weighted Loss:1.860    Policy Loss: 9.581    Value Loss: 4.575    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 4619106    Buffer Size: 14738      Transition Number: 1000.256k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:51:53,198][train][INFO][train.py>_log] ==> #1949000    Total Loss: 1.773    [weighted Loss:1.773    Policy Loss: 9.361    Value Loss: 4.467    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 4621825    Buffer Size: 14743      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:55:34,521][train][INFO][train.py>_log] ==> #1950000    Total Loss: 1.766    [weighted Loss:1.766    Policy Loss: 9.359    Value Loss: 4.460    Reward Loss: 1.740    Consistency Loss: 0.000    ] Replay Episodes Collected: 4624734    Buffer Size: 14749      Transition Number: 1000.109k Batch Size: 256        Lr: 0.00010 
[2022-02-23 14:59:09,658][train][INFO][train.py>_log] ==> #1951000    Total Loss: 1.070    [weighted Loss:1.070    Policy Loss: 9.213    Value Loss: 4.484    Reward Loss: 1.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 4627454    Buffer Size: 14744      Transition Number: 999.949 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:02:47,506][train][INFO][train.py>_log] ==> #1952000    Total Loss: 0.672    [weighted Loss:0.672    Policy Loss: 9.399    Value Loss: 4.161    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 4630123    Buffer Size: 14763      Transition Number: 1000.122k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:06:21,903][train][INFO][train.py>_log] ==> #1953000    Total Loss: 0.516    [weighted Loss:0.516    Policy Loss: 9.498    Value Loss: 4.359    Reward Loss: 1.637    Consistency Loss: 0.000    ] Replay Episodes Collected: 4632931    Buffer Size: 14764      Transition Number: 1000.008k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:09:58,158][train][INFO][train.py>_log] ==> #1954000    Total Loss: 1.405    [weighted Loss:1.405    Policy Loss: 9.197    Value Loss: 4.418    Reward Loss: 1.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 4635676    Buffer Size: 14769      Transition Number: 1000.184k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:13:38,413][train][INFO][train.py>_log] ==> #1955000    Total Loss: 1.709    [weighted Loss:1.709    Policy Loss: 9.664    Value Loss: 4.180    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 4638449    Buffer Size: 14757      Transition Number: 999.997 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:17:09,593][train][INFO][train.py>_log] ==> #1956000    Total Loss: 0.501    [weighted Loss:0.501    Policy Loss: 8.842    Value Loss: 4.407    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 4641146    Buffer Size: 14761      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:20:43,821][train][INFO][train.py>_log] ==> #1957000    Total Loss: 1.287    [weighted Loss:1.287    Policy Loss: 9.352    Value Loss: 4.332    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 4643856    Buffer Size: 14762      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:24:19,546][train][INFO][train.py>_log] ==> #1958000    Total Loss: 1.192    [weighted Loss:1.192    Policy Loss: 9.542    Value Loss: 4.289    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 4646569    Buffer Size: 14764      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:27:54,527][train][INFO][train.py>_log] ==> #1959000    Total Loss: 0.486    [weighted Loss:0.486    Policy Loss: 9.658    Value Loss: 4.322    Reward Loss: 1.651    Consistency Loss: 0.000    ] Replay Episodes Collected: 4649402    Buffer Size: 14752      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:31:30,360][train][INFO][train.py>_log] ==> #1960000    Total Loss: 0.549    [weighted Loss:0.549    Policy Loss: 9.382    Value Loss: 4.518    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 4652067    Buffer Size: 14763      Transition Number: 999.974 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:35:09,335][train][INFO][train.py>_log] ==> #1961000    Total Loss: 1.418    [weighted Loss:1.418    Policy Loss: 9.227    Value Loss: 4.187    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 4654879    Buffer Size: 14775      Transition Number: 1000.057k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:38:44,969][train][INFO][train.py>_log] ==> #1962000    Total Loss: 1.902    [weighted Loss:1.902    Policy Loss: 9.853    Value Loss: 4.555    Reward Loss: 1.608    Consistency Loss: 0.000    ] Replay Episodes Collected: 4657639    Buffer Size: 14776      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:42:21,335][train][INFO][train.py>_log] ==> #1963000    Total Loss: 2.157    [weighted Loss:2.157    Policy Loss: 9.182    Value Loss: 4.486    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 4660309    Buffer Size: 14780      Transition Number: 1000.164k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:45:58,833][train][INFO][train.py>_log] ==> #1964000    Total Loss: 2.166    [weighted Loss:2.166    Policy Loss: 9.369    Value Loss: 4.483    Reward Loss: 1.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 4663062    Buffer Size: 14800      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:49:37,014][train][INFO][train.py>_log] ==> #1965000    Total Loss: 0.540    [weighted Loss:0.540    Policy Loss: 9.380    Value Loss: 4.215    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 4665809    Buffer Size: 14805      Transition Number: 999.988 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:53:13,649][train][INFO][train.py>_log] ==> #1966000    Total Loss: 2.270    [weighted Loss:2.270    Policy Loss: 9.310    Value Loss: 4.667    Reward Loss: 1.573    Consistency Loss: 0.000    ] Replay Episodes Collected: 4668597    Buffer Size: 14796      Transition Number: 1000.058k Batch Size: 256        Lr: 0.00010 
[2022-02-23 15:56:53,236][train][INFO][train.py>_log] ==> #1967000    Total Loss: 1.737    [weighted Loss:1.737    Policy Loss: 9.523    Value Loss: 4.146    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 4671334    Buffer Size: 14814      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00010 
[2022-02-23 16:00:27,369][train][INFO][train.py>_log] ==> #1968000    Total Loss: 0.903    [weighted Loss:0.903    Policy Loss: 9.136    Value Loss: 4.359    Reward Loss: 1.678    Consistency Loss: 0.000    ] Replay Episodes Collected: 4674098    Buffer Size: 14822      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00010 
[2022-02-23 16:04:02,421][train][INFO][train.py>_log] ==> #1969000    Total Loss: 1.554    [weighted Loss:1.554    Policy Loss: 9.670    Value Loss: 4.284    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 4676892    Buffer Size: 14829      Transition Number: 1000.005k Batch Size: 256        Lr: 0.00010 
[2022-02-23 16:07:39,862][train][INFO][train.py>_log] ==> #1970000    Total Loss: 2.102    [weighted Loss:2.102    Policy Loss: 9.677    Value Loss: 4.343    Reward Loss: 1.647    Consistency Loss: 0.000    ] Replay Episodes Collected: 4679573    Buffer Size: 14846      Transition Number: 999.939 k Batch Size: 256        Lr: 0.00010 
[2022-02-23 16:11:17,206][train][INFO][train.py>_log] ==> #1971000    Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 9.759    Value Loss: 4.644    Reward Loss: 1.749    Consistency Loss: 0.000    ] Replay Episodes Collected: 4682407    Buffer Size: 14874      Transition Number: 1000.217k Batch Size: 256        Lr: 0.00010 
