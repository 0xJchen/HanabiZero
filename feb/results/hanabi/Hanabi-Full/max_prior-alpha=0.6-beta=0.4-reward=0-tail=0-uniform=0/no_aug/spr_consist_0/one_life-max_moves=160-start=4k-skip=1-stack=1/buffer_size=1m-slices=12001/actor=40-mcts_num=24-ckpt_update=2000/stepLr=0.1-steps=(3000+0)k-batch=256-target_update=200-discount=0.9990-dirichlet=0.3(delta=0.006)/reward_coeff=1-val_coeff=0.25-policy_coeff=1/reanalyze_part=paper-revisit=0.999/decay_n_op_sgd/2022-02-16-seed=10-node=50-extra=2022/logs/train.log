[2022-02-16 16:52:44,761][train][INFO][train.py>_log] ==> #0          Total Loss: 47.918   [weighted Loss:47.918   Policy Loss: 13.446   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1132       Buffer Size: 1132       Transition Number: 11.436  k Batch Size: 256        Lr: 0.00000 
[2022-02-16 16:55:41,333][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.279    [weighted Loss:7.279    Policy Loss: 14.065   Value Loss: 4.574    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 12636      Buffer Size: 12636      Transition Number: 156.006 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 16:58:16,478][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.938    [weighted Loss:5.938    Policy Loss: 13.393   Value Loss: 4.417    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 22310      Buffer Size: 22310      Transition Number: 276.522 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:00:53,689][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.451    [weighted Loss:6.451    Policy Loss: 12.806   Value Loss: 4.385    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 33235      Buffer Size: 33235      Transition Number: 390.348 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:03:34,372][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.822    [weighted Loss:4.822    Policy Loss: 10.227   Value Loss: 4.124    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 44192      Buffer Size: 44192      Transition Number: 510.335 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:06:11,225][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.865    [weighted Loss:4.865    Policy Loss: 11.473   Value Loss: 4.361    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 48739      Buffer Size: 48739      Transition Number: 619.763 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:08:47,841][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.362    [weighted Loss:4.362    Policy Loss: 10.151   Value Loss: 4.067    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 53015      Buffer Size: 53015      Transition Number: 725.327 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:11:28,830][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.833    [weighted Loss:4.833    Policy Loss: 9.285    Value Loss: 4.198    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 60595      Buffer Size: 60595      Transition Number: 833.183 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:14:04,294][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.463    [weighted Loss:3.463    Policy Loss: 7.837    Value Loss: 4.034    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 68174      Buffer Size: 68174      Transition Number: 947.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:16:39,487][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.419    [weighted Loss:3.419    Policy Loss: 7.040    Value Loss: 4.437    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 71935      Buffer Size: 67549      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:19:16,034][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 6.618    Value Loss: 4.258    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 75676      Buffer Size: 63249      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:21:55,600][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 5.649    Value Loss: 4.261    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 78837      Buffer Size: 58010      Transition Number: 1000.409k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:24:31,085][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 4.701    Value Loss: 4.371    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 81925      Buffer Size: 50803      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:27:11,078][train][INFO][train.py>_log] ==> #13000      Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 4.677    Value Loss: 4.548    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 84643      Buffer Size: 44018      Transition Number: 1000.170k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:29:48,670][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 4.433    Value Loss: 4.624    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 87276      Buffer Size: 39995      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:32:25,061][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 4.573    Value Loss: 4.645    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 90023      Buffer Size: 38307      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:35:05,461][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 4.043    Value Loss: 4.464    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 92827      Buffer Size: 35198      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:37:42,046][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 4.210    Value Loss: 5.010    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 95190      Buffer Size: 30709      Transition Number: 1000.298k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:40:20,329][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 4.771    Value Loss: 4.428    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 97551      Buffer Size: 27142      Transition Number: 1000.149k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:43:01,838][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 3.912    Value Loss: 4.739    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 99819      Buffer Size: 25360      Transition Number: 1000.480k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:45:43,573][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.919    [weighted Loss:1.919    Policy Loss: 3.705    Value Loss: 4.836    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 102085     Buffer Size: 24259      Transition Number: 1000.079k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:48:24,551][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 3.279    Value Loss: 4.491    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 104493     Buffer Size: 23679      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:51:07,385][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 3.758    Value Loss: 4.427    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 106985     Buffer Size: 23156      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:53:47,753][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.782    [weighted Loss:1.782    Policy Loss: 3.497    Value Loss: 4.318    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 109195     Buffer Size: 22701      Transition Number: 1000.274k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:56:26,805][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.837    [weighted Loss:1.837    Policy Loss: 3.544    Value Loss: 4.148    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 111384     Buffer Size: 22214      Transition Number: 1000.126k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:59:12,556][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.223    [weighted Loss:1.223    Policy Loss: 3.784    Value Loss: 4.350    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 113499     Buffer Size: 21569      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:01:54,423][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 3.681    Value Loss: 4.446    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 115653     Buffer Size: 21001      Transition Number: 1000.299k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:04:35,803][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.567    [weighted Loss:1.567    Policy Loss: 3.987    Value Loss: 4.397    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 117721     Buffer Size: 20571      Transition Number: 1000.230k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:07:17,420][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 3.885    Value Loss: 4.330    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 119700     Buffer Size: 20243      Transition Number: 1000.274k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:09:56,603][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 3.823    Value Loss: 4.691    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 121859     Buffer Size: 20080      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:12:36,548][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 3.558    Value Loss: 4.628    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 124018     Buffer Size: 19787      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:15:15,938][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.414    [weighted Loss:1.414    Policy Loss: 3.507    Value Loss: 4.995    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 125724     Buffer Size: 19119      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:17:59,689][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 3.716    Value Loss: 4.690    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 127540     Buffer Size: 18477      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:20:39,271][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.616    [weighted Loss:1.616    Policy Loss: 3.379    Value Loss: 5.165    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 129180     Buffer Size: 17796      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:23:18,958][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 3.170    Value Loss: 5.006    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 130960     Buffer Size: 17260      Transition Number: 1000.273k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:25:59,092][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 3.229    Value Loss: 4.890    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 132615     Buffer Size: 16813      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:28:41,148][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 3.533    Value Loss: 4.680    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 134328     Buffer Size: 16411      Transition Number: 999.927 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:31:21,958][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 4.371    Value Loss: 5.144    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 136076     Buffer Size: 15943      Transition Number: 1000.688k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:33:59,297][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 5.554    Value Loss: 4.697    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 137727     Buffer Size: 15384      Transition Number: 1000.131k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:36:35,726][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 5.816    Value Loss: 4.709    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 139414     Buffer Size: 14905      Transition Number: 1000.025k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:39:16,330][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 6.647    Value Loss: 4.499    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 141070     Buffer Size: 14794      Transition Number: 1000.136k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:41:53,209][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.557    [weighted Loss:3.557    Policy Loss: 8.035    Value Loss: 4.679    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 142945     Buffer Size: 14716      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:44:29,288][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.727    [weighted Loss:3.727    Policy Loss: 8.528    Value Loss: 4.413    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 144423     Buffer Size: 14715      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:47:10,503][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.621    [weighted Loss:3.621    Policy Loss: 8.449    Value Loss: 4.458    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 146328     Buffer Size: 14672      Transition Number: 1000.180k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:49:46,434][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 8.859    Value Loss: 4.648    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 147917     Buffer Size: 14692      Transition Number: 1000.132k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:52:24,124][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.236    [weighted Loss:4.236    Policy Loss: 9.520    Value Loss: 4.680    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 149730     Buffer Size: 14633      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:55:01,162][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.816    [weighted Loss:4.816    Policy Loss: 9.195    Value Loss: 4.824    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 151419     Buffer Size: 14593      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:57:43,564][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.900    [weighted Loss:4.900    Policy Loss: 9.616    Value Loss: 4.646    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 153156     Buffer Size: 14566      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:00:20,758][train][INFO][train.py>_log] ==> #48000      Total Loss: 5.064    [weighted Loss:5.064    Policy Loss: 9.361    Value Loss: 4.629    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 154919     Buffer Size: 14542      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:03:00,312][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.966    [weighted Loss:3.966    Policy Loss: 8.424    Value Loss: 4.383    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 156664     Buffer Size: 14509      Transition Number: 1000.312k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:05:39,727][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 8.036    Value Loss: 4.545    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 158381     Buffer Size: 14445      Transition Number: 1000.303k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:08:17,153][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 8.245    Value Loss: 4.354    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 160166     Buffer Size: 14363      Transition Number: 1000.256k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:10:58,079][train][INFO][train.py>_log] ==> #52000      Total Loss: 4.333    [weighted Loss:4.333    Policy Loss: 8.631    Value Loss: 4.238    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 161934     Buffer Size: 14310      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:13:35,959][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.513    [weighted Loss:3.513    Policy Loss: 8.557    Value Loss: 4.523    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 163680     Buffer Size: 14286      Transition Number: 1000.192k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:16:14,163][train][INFO][train.py>_log] ==> #54000      Total Loss: 4.353    [weighted Loss:4.353    Policy Loss: 8.748    Value Loss: 4.458    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 165520     Buffer Size: 14256      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:18:55,971][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 8.933    Value Loss: 4.697    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 167371     Buffer Size: 14395      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:21:34,077][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 9.222    Value Loss: 5.105    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 169191     Buffer Size: 14529      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:24:11,360][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 9.018    Value Loss: 4.770    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 171003     Buffer Size: 14638      Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:26:48,400][train][INFO][train.py>_log] ==> #58000      Total Loss: 4.305    [weighted Loss:4.305    Policy Loss: 9.196    Value Loss: 4.985    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 172797     Buffer Size: 14773      Transition Number: 1000.076k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:29:28,749][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.122    [weighted Loss:3.122    Policy Loss: 9.945    Value Loss: 5.069    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 174539     Buffer Size: 14854      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:32:07,100][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 10.086   Value Loss: 5.224    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 176309     Buffer Size: 14930      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:34:47,518][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.272    [weighted Loss:4.272    Policy Loss: 10.078   Value Loss: 5.183    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 178063     Buffer Size: 14976      Transition Number: 1000.318k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:37:26,243][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.404    [weighted Loss:3.404    Policy Loss: 9.928    Value Loss: 5.377    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 179864     Buffer Size: 15033      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:40:03,645][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.321    [weighted Loss:4.321    Policy Loss: 10.422   Value Loss: 5.035    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 181724     Buffer Size: 15059      Transition Number: 1000.328k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:42:44,960][train][INFO][train.py>_log] ==> #64000      Total Loss: 5.365    [weighted Loss:5.365    Policy Loss: 10.833   Value Loss: 5.483    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 183491     Buffer Size: 15022      Transition Number: 1000.200k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:45:20,994][train][INFO][train.py>_log] ==> #65000      Total Loss: 6.527    [weighted Loss:6.527    Policy Loss: 11.017   Value Loss: 5.203    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 185304     Buffer Size: 15063      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:48:00,831][train][INFO][train.py>_log] ==> #66000      Total Loss: 5.933    [weighted Loss:5.933    Policy Loss: 11.221   Value Loss: 5.118    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 187188     Buffer Size: 15079      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:50:41,494][train][INFO][train.py>_log] ==> #67000      Total Loss: 6.200    [weighted Loss:6.200    Policy Loss: 11.279   Value Loss: 5.311    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 188952     Buffer Size: 15167      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:53:19,018][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.850    [weighted Loss:4.850    Policy Loss: 11.449   Value Loss: 5.338    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 190807     Buffer Size: 15245      Transition Number: 1000.135k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:55:56,057][train][INFO][train.py>_log] ==> #69000      Total Loss: 4.642    [weighted Loss:4.642    Policy Loss: 11.479   Value Loss: 5.313    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 192666     Buffer Size: 15442      Transition Number: 1000.183k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:58:32,570][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 11.781   Value Loss: 5.200    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 194551     Buffer Size: 15646      Transition Number: 1000.262k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:01:13,608][train][INFO][train.py>_log] ==> #71000      Total Loss: 5.036    [weighted Loss:5.036    Policy Loss: 11.593   Value Loss: 5.412    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 196414     Buffer Size: 15794      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:03:50,532][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.898    [weighted Loss:3.898    Policy Loss: 11.092   Value Loss: 5.445    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 198287     Buffer Size: 15914      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:06:28,575][train][INFO][train.py>_log] ==> #73000      Total Loss: 5.452    [weighted Loss:5.452    Policy Loss: 11.086   Value Loss: 5.475    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 200278     Buffer Size: 16060      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:09:09,596][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.893    [weighted Loss:3.893    Policy Loss: 10.908   Value Loss: 5.666    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 202174     Buffer Size: 16215      Transition Number: 1000.465k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:11:46,908][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.175    [weighted Loss:4.175    Policy Loss: 11.362   Value Loss: 5.865    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 203991     Buffer Size: 16210      Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:14:29,160][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.633    [weighted Loss:4.633    Policy Loss: 11.189   Value Loss: 5.766    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 205874     Buffer Size: 16197      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:17:07,455][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.166    [weighted Loss:4.166    Policy Loss: 11.041   Value Loss: 5.523    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 207650     Buffer Size: 16186      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:19:46,510][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.748    [weighted Loss:5.748    Policy Loss: 10.987   Value Loss: 6.017    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 209561     Buffer Size: 16075      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:22:27,515][train][INFO][train.py>_log] ==> #79000      Total Loss: 5.169    [weighted Loss:5.169    Policy Loss: 10.942   Value Loss: 5.556    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 211351     Buffer Size: 16008      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:25:03,922][train][INFO][train.py>_log] ==> #80000      Total Loss: 4.631    [weighted Loss:4.631    Policy Loss: 10.500   Value Loss: 5.430    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 213176     Buffer Size: 15902      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:27:41,910][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.601    [weighted Loss:4.601    Policy Loss: 10.445   Value Loss: 5.419    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 215108     Buffer Size: 15964      Transition Number: 1000.102k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:30:20,812][train][INFO][train.py>_log] ==> #82000      Total Loss: 5.802    [weighted Loss:5.802    Policy Loss: 10.528   Value Loss: 5.367    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 217025     Buffer Size: 15969      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:33:01,329][train][INFO][train.py>_log] ==> #83000      Total Loss: 5.229    [weighted Loss:5.229    Policy Loss: 10.672   Value Loss: 5.395    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 218908     Buffer Size: 15878      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:35:38,736][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.608    [weighted Loss:4.608    Policy Loss: 10.576   Value Loss: 5.214    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 220648     Buffer Size: 15909      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:38:18,459][train][INFO][train.py>_log] ==> #85000      Total Loss: 5.676    [weighted Loss:5.676    Policy Loss: 10.885   Value Loss: 5.448    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 222512     Buffer Size: 15885      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:40:57,938][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.700    [weighted Loss:4.700    Policy Loss: 10.361   Value Loss: 5.679    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 224271     Buffer Size: 15919      Transition Number: 1000.106k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:43:36,692][train][INFO][train.py>_log] ==> #87000      Total Loss: 5.076    [weighted Loss:5.076    Policy Loss: 10.578   Value Loss: 5.752    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 226205     Buffer Size: 15997      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:46:16,858][train][INFO][train.py>_log] ==> #88000      Total Loss: 6.095    [weighted Loss:6.095    Policy Loss: 10.876   Value Loss: 5.947    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 228111     Buffer Size: 16116      Transition Number: 1000.160k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:48:54,063][train][INFO][train.py>_log] ==> #89000      Total Loss: 4.734    [weighted Loss:4.734    Policy Loss: 10.041   Value Loss: 6.196    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 229893     Buffer Size: 16185      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:51:31,371][train][INFO][train.py>_log] ==> #90000      Total Loss: 5.452    [weighted Loss:5.452    Policy Loss: 10.787   Value Loss: 5.581    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 231714     Buffer Size: 16144      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:54:13,020][train][INFO][train.py>_log] ==> #91000      Total Loss: 4.217    [weighted Loss:4.217    Policy Loss: 10.865   Value Loss: 5.803    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 233591     Buffer Size: 16126      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:56:50,290][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.639    [weighted Loss:4.639    Policy Loss: 10.421   Value Loss: 5.844    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 235379     Buffer Size: 16212      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:59:31,266][train][INFO][train.py>_log] ==> #93000      Total Loss: 4.424    [weighted Loss:4.424    Policy Loss: 11.039   Value Loss: 6.156    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 237316     Buffer Size: 16273      Transition Number: 1000.001k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:02:11,431][train][INFO][train.py>_log] ==> #94000      Total Loss: 5.533    [weighted Loss:5.533    Policy Loss: 10.746   Value Loss: 6.029    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 239046     Buffer Size: 16366      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:04:52,034][train][INFO][train.py>_log] ==> #95000      Total Loss: 5.744    [weighted Loss:5.744    Policy Loss: 10.338   Value Loss: 6.170    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 242378     Buffer Size: 17774      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:07:29,986][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.646    [weighted Loss:5.646    Policy Loss: 10.251   Value Loss: 6.067    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 245662     Buffer Size: 19275      Transition Number: 1000.220k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:10:07,872][train][INFO][train.py>_log] ==> #97000      Total Loss: 5.335    [weighted Loss:5.335    Policy Loss: 10.197   Value Loss: 6.014    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 247902     Buffer Size: 19738      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:12:45,623][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.852    [weighted Loss:3.852    Policy Loss: 9.995    Value Loss: 6.011    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 250081     Buffer Size: 20191      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:15:22,720][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.019    [weighted Loss:3.019    Policy Loss: 9.521    Value Loss: 6.221    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 252018     Buffer Size: 20306      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:18:01,703][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 9.306    Value Loss: 6.067    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 253893     Buffer Size: 20413      Transition Number: 1000.357k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:20:40,291][train][INFO][train.py>_log] ==> #101000     Total Loss: 4.248    [weighted Loss:4.248    Policy Loss: 9.713    Value Loss: 5.924    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 255747     Buffer Size: 20474      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:23:20,856][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 9.395    Value Loss: 5.970    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 257645     Buffer Size: 20537      Transition Number: 1000.118k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:26:02,386][train][INFO][train.py>_log] ==> #103000     Total Loss: 5.313    [weighted Loss:5.313    Policy Loss: 9.810    Value Loss: 5.899    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 259474     Buffer Size: 20560      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:28:40,805][train][INFO][train.py>_log] ==> #104000     Total Loss: 5.326    [weighted Loss:5.326    Policy Loss: 10.196   Value Loss: 6.175    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 261305     Buffer Size: 19368      Transition Number: 1000.236k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:31:20,922][train][INFO][train.py>_log] ==> #105000     Total Loss: 6.138    [weighted Loss:6.138    Policy Loss: 9.812    Value Loss: 5.776    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 263027     Buffer Size: 17938      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:34:00,927][train][INFO][train.py>_log] ==> #106000     Total Loss: 4.009    [weighted Loss:4.009    Policy Loss: 9.808    Value Loss: 5.707    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 264890     Buffer Size: 17158      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:36:40,143][train][INFO][train.py>_log] ==> #107000     Total Loss: 5.174    [weighted Loss:5.174    Policy Loss: 9.627    Value Loss: 5.967    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 266779     Buffer Size: 16825      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:39:20,016][train][INFO][train.py>_log] ==> #108000     Total Loss: 5.268    [weighted Loss:5.268    Policy Loss: 9.657    Value Loss: 5.760    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 268774     Buffer Size: 16779      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:41:59,784][train][INFO][train.py>_log] ==> #109000     Total Loss: 5.604    [weighted Loss:5.604    Policy Loss: 9.937    Value Loss: 6.074    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 270574     Buffer Size: 16738      Transition Number: 1000.116k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:44:41,419][train][INFO][train.py>_log] ==> #110000     Total Loss: 4.323    [weighted Loss:4.323    Policy Loss: 9.932    Value Loss: 5.905    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 272435     Buffer Size: 16692      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:47:19,481][train][INFO][train.py>_log] ==> #111000     Total Loss: 5.117    [weighted Loss:5.117    Policy Loss: 9.024    Value Loss: 6.203    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 274174     Buffer Size: 16597      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:49:59,196][train][INFO][train.py>_log] ==> #112000     Total Loss: 4.329    [weighted Loss:4.329    Policy Loss: 9.033    Value Loss: 6.360    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 275985     Buffer Size: 16546      Transition Number: 1000.154k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:52:35,967][train][INFO][train.py>_log] ==> #113000     Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 8.444    Value Loss: 6.554    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 277868     Buffer Size: 16682      Transition Number: 1000.018k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:55:16,019][train][INFO][train.py>_log] ==> #114000     Total Loss: 4.709    [weighted Loss:4.709    Policy Loss: 8.449    Value Loss: 5.887    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 279850     Buffer Size: 16873      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:57:56,888][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.128    [weighted Loss:4.128    Policy Loss: 8.520    Value Loss: 5.714    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 281746     Buffer Size: 17052      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:00:36,684][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.677    [weighted Loss:3.677    Policy Loss: 7.481    Value Loss: 6.347    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 283694     Buffer Size: 17100      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:03:17,813][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.053    [weighted Loss:4.053    Policy Loss: 7.628    Value Loss: 6.014    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 285514     Buffer Size: 16985      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:05:58,157][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.902    [weighted Loss:3.902    Policy Loss: 7.774    Value Loss: 6.397    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 287321     Buffer Size: 16891      Transition Number: 1000.229k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:08:38,068][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.676    [weighted Loss:4.676    Policy Loss: 7.924    Value Loss: 5.574    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 288988     Buffer Size: 16796      Transition Number: 1000.264k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:11:17,875][train][INFO][train.py>_log] ==> #120000     Total Loss: 4.104    [weighted Loss:4.104    Policy Loss: 7.359    Value Loss: 5.712    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 290778     Buffer Size: 16740      Transition Number: 1000.249k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:13:59,747][train][INFO][train.py>_log] ==> #121000     Total Loss: 4.734    [weighted Loss:4.734    Policy Loss: 8.009    Value Loss: 5.665    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 292593     Buffer Size: 16737      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:16:40,778][train][INFO][train.py>_log] ==> #122000     Total Loss: 4.149    [weighted Loss:4.149    Policy Loss: 8.227    Value Loss: 5.943    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 294368     Buffer Size: 16592      Transition Number: 1000.195k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:19:19,558][train][INFO][train.py>_log] ==> #123000     Total Loss: 5.441    [weighted Loss:5.441    Policy Loss: 8.517    Value Loss: 5.930    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 296160     Buffer Size: 16361      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:22:02,233][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.279    [weighted Loss:4.279    Policy Loss: 8.527    Value Loss: 5.308    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 297963     Buffer Size: 16145      Transition Number: 1000.194k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:24:43,528][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 8.965    Value Loss: 5.239    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 299822     Buffer Size: 15999      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:27:24,646][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.544    [weighted Loss:4.544    Policy Loss: 8.630    Value Loss: 5.659    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 301670     Buffer Size: 15978      Transition Number: 1000.122k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:30:05,765][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 9.055    Value Loss: 5.721    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 303381     Buffer Size: 15904      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:32:43,769][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 8.640    Value Loss: 5.286    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 305228     Buffer Size: 15859      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:35:25,521][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.327    [weighted Loss:3.327    Policy Loss: 8.334    Value Loss: 5.543    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 306948     Buffer Size: 15842      Transition Number: 1000.333k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:38:06,946][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 8.306    Value Loss: 5.321    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 308828     Buffer Size: 15724      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:40:47,980][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 7.977    Value Loss: 5.265    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 310618     Buffer Size: 15768      Transition Number: 1000.291k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:43:28,036][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.148    [weighted Loss:3.148    Policy Loss: 8.769    Value Loss: 5.244    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 312510     Buffer Size: 15809      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:46:09,869][train][INFO][train.py>_log] ==> #133000     Total Loss: 3.908    [weighted Loss:3.908    Policy Loss: 7.479    Value Loss: 5.631    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 314415     Buffer Size: 15843      Transition Number: 1000.076k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:48:52,896][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 6.970    Value Loss: 5.452    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 316317     Buffer Size: 15850      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:51:33,706][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.551    [weighted Loss:3.551    Policy Loss: 7.283    Value Loss: 5.755    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 318084     Buffer Size: 15832      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:54:16,463][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.694    [weighted Loss:3.694    Policy Loss: 6.824    Value Loss: 5.613    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 319962     Buffer Size: 15875      Transition Number: 1000.070k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:56:56,873][train][INFO][train.py>_log] ==> #137000     Total Loss: 4.055    [weighted Loss:4.055    Policy Loss: 7.225    Value Loss: 5.613    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 321751     Buffer Size: 15950      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:59:38,156][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 6.994    Value Loss: 4.982    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 323649     Buffer Size: 16069      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:02:18,915][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.971    [weighted Loss:2.971    Policy Loss: 6.362    Value Loss: 5.723    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 325353     Buffer Size: 16117      Transition Number: 1000.765k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:05:00,510][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 6.517    Value Loss: 5.376    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 327213     Buffer Size: 16017      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:07:41,008][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 6.704    Value Loss: 5.321    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 329146     Buffer Size: 16078      Transition Number: 1000.119k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:10:24,815][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 6.561    Value Loss: 5.277    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 331086     Buffer Size: 16145      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:13:05,862][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 6.767    Value Loss: 5.383    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 332791     Buffer Size: 16084      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:15:46,514][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.649    [weighted Loss:3.649    Policy Loss: 6.769    Value Loss: 5.421    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 334651     Buffer Size: 16035      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:18:30,701][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 6.683    Value Loss: 5.344    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 336504     Buffer Size: 15972      Transition Number: 1000.288k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:21:11,345][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.424    [weighted Loss:3.424    Policy Loss: 6.710    Value Loss: 5.281    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 338339     Buffer Size: 15903      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:23:53,797][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 6.608    Value Loss: 5.362    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 340201     Buffer Size: 15836      Transition Number: 1000.103k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:26:35,972][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.222    [weighted Loss:2.222    Policy Loss: 6.742    Value Loss: 5.828    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 342050     Buffer Size: 15825      Transition Number: 1000.114k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:29:17,614][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.736    [weighted Loss:3.736    Policy Loss: 7.601    Value Loss: 5.861    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 343811     Buffer Size: 15703      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:32:01,056][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 7.861    Value Loss: 5.295    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 345581     Buffer Size: 15504      Transition Number: 1000.301k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:34:42,897][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 7.711    Value Loss: 4.994    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 347455     Buffer Size: 15373      Transition Number: 1000.468k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:37:24,369][train][INFO][train.py>_log] ==> #152000     Total Loss: 3.715    [weighted Loss:3.715    Policy Loss: 7.733    Value Loss: 4.794    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 349202     Buffer Size: 15370      Transition Number: 999.959 k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:40:05,273][train][INFO][train.py>_log] ==> #153000     Total Loss: 3.827    [weighted Loss:3.827    Policy Loss: 7.650    Value Loss: 4.818    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 350974     Buffer Size: 15325      Transition Number: 1000.004k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:42:48,577][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.101    [weighted Loss:3.101    Policy Loss: 7.876    Value Loss: 5.016    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 352878     Buffer Size: 15261      Transition Number: 1000.224k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:45:29,945][train][INFO][train.py>_log] ==> #155000     Total Loss: 4.023    [weighted Loss:4.023    Policy Loss: 8.001    Value Loss: 5.545    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 354546     Buffer Size: 15165      Transition Number: 1000.293k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:48:11,452][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 7.889    Value Loss: 4.875    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 356397     Buffer Size: 15047      Transition Number: 1000.184k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:50:53,574][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 8.255    Value Loss: 4.917    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 358104     Buffer Size: 14988      Transition Number: 999.981 k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:53:34,425][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 8.182    Value Loss: 4.590    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 359841     Buffer Size: 14943      Transition Number: 999.948 k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:56:15,155][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 7.920    Value Loss: 4.344    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 361690     Buffer Size: 14894      Transition Number: 999.965 k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:58:56,813][train][INFO][train.py>_log] ==> #160000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 8.012    Value Loss: 5.066    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 363411     Buffer Size: 14851      Transition Number: 1000.383k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:01:38,317][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.768    [weighted Loss:3.768    Policy Loss: 7.596    Value Loss: 4.714    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 365170     Buffer Size: 14787      Transition Number: 999.943 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:04:20,277][train][INFO][train.py>_log] ==> #162000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 7.791    Value Loss: 4.342    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 366992     Buffer Size: 14760      Transition Number: 999.969 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:07:02,010][train][INFO][train.py>_log] ==> #163000     Total Loss: 4.089    [weighted Loss:4.089    Policy Loss: 7.856    Value Loss: 4.419    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 368747     Buffer Size: 14745      Transition Number: 1000.077k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:09:43,864][train][INFO][train.py>_log] ==> #164000     Total Loss: 3.933    [weighted Loss:3.933    Policy Loss: 7.615    Value Loss: 4.482    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 370525     Buffer Size: 14746      Transition Number: 1000.114k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:12:27,343][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.261    [weighted Loss:3.261    Policy Loss: 7.334    Value Loss: 4.507    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 372391     Buffer Size: 14754      Transition Number: 1000.112k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:15:10,400][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.420    [weighted Loss:3.420    Policy Loss: 6.703    Value Loss: 4.547    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 374144     Buffer Size: 14750      Transition Number: 1000.154k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:17:51,417][train][INFO][train.py>_log] ==> #167000     Total Loss: 4.196    [weighted Loss:4.196    Policy Loss: 7.203    Value Loss: 4.569    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 375943     Buffer Size: 14730      Transition Number: 1000.103k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:20:34,218][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 6.641    Value Loss: 4.621    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 377678     Buffer Size: 14706      Transition Number: 999.985 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:23:17,678][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 6.613    Value Loss: 4.597    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 379511     Buffer Size: 14702      Transition Number: 1000.105k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:25:58,423][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 6.468    Value Loss: 4.385    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 381270     Buffer Size: 14685      Transition Number: 1000.000k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:28:40,819][train][INFO][train.py>_log] ==> #171000     Total Loss: 4.189    [weighted Loss:4.189    Policy Loss: 6.337    Value Loss: 4.854    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 383106     Buffer Size: 14687      Transition Number: 999.940 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:31:25,307][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 6.580    Value Loss: 4.727    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 384980     Buffer Size: 14671      Transition Number: 1000.135k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:34:09,561][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.601    [weighted Loss:1.601    Policy Loss: 6.104    Value Loss: 4.652    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 386689     Buffer Size: 14642      Transition Number: 999.992 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:36:51,802][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.456    [weighted Loss:2.456    Policy Loss: 6.094    Value Loss: 4.645    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 388585     Buffer Size: 14626      Transition Number: 999.998 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:39:36,206][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 6.375    Value Loss: 4.763    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 390429     Buffer Size: 14629      Transition Number: 1000.056k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:42:18,235][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 6.306    Value Loss: 4.871    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 392177     Buffer Size: 14642      Transition Number: 1000.208k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:45:01,006][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.686    [weighted Loss:3.686    Policy Loss: 6.340    Value Loss: 4.705    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 394035     Buffer Size: 14625      Transition Number: 1000.069k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:47:45,197][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.446    [weighted Loss:3.446    Policy Loss: 6.645    Value Loss: 4.595    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 395827     Buffer Size: 14630      Transition Number: 1000.128k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:50:26,725][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 6.715    Value Loss: 4.770    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 397645     Buffer Size: 14636      Transition Number: 1000.232k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:53:12,064][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 6.644    Value Loss: 4.789    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 399420     Buffer Size: 14635      Transition Number: 999.934 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:55:54,297][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 7.093    Value Loss: 4.574    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 401366     Buffer Size: 14660      Transition Number: 1000.086k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:58:36,283][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 7.058    Value Loss: 4.990    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 403162     Buffer Size: 14686      Transition Number: 999.948 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:01:19,840][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 7.206    Value Loss: 4.732    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 405027     Buffer Size: 14708      Transition Number: 1000.073k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:04:03,613][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.526    [weighted Loss:3.526    Policy Loss: 6.829    Value Loss: 4.507    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 406918     Buffer Size: 14726      Transition Number: 1000.133k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:06:46,253][train][INFO][train.py>_log] ==> #185000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 7.023    Value Loss: 4.943    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 408741     Buffer Size: 14750      Transition Number: 999.949 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:09:29,200][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.667    [weighted Loss:3.667    Policy Loss: 7.487    Value Loss: 4.511    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 410575     Buffer Size: 14765      Transition Number: 999.982 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:12:14,317][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.477    [weighted Loss:3.477    Policy Loss: 7.246    Value Loss: 4.673    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 412469     Buffer Size: 14765      Transition Number: 999.940 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:14:57,960][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 7.555    Value Loss: 4.403    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 414241     Buffer Size: 14760      Transition Number: 1000.081k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:17:41,393][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.918    [weighted Loss:2.918    Policy Loss: 7.324    Value Loss: 4.963    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 416172     Buffer Size: 14740      Transition Number: 1000.220k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:20:25,943][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 7.157    Value Loss: 4.642    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 418036     Buffer Size: 14714      Transition Number: 1000.262k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:23:08,195][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 7.303    Value Loss: 4.686    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 419890     Buffer Size: 14692      Transition Number: 1000.331k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:25:52,354][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.841    [weighted Loss:2.841    Policy Loss: 7.181    Value Loss: 4.777    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 421690     Buffer Size: 14663      Transition Number: 1000.080k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:28:36,955][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 7.052    Value Loss: 4.351    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 423615     Buffer Size: 14649      Transition Number: 1000.009k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:31:19,269][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.538    [weighted Loss:3.538    Policy Loss: 7.406    Value Loss: 4.694    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 425453     Buffer Size: 14633      Transition Number: 1000.012k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:34:01,770][train][INFO][train.py>_log] ==> #195000     Total Loss: 3.853    [weighted Loss:3.853    Policy Loss: 6.838    Value Loss: 4.539    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 427294     Buffer Size: 14647      Transition Number: 1000.437k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:36:43,671][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 7.216    Value Loss: 4.588    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 429194     Buffer Size: 14653      Transition Number: 999.944 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:39:25,738][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.246    [weighted Loss:3.246    Policy Loss: 7.225    Value Loss: 4.859    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 431112     Buffer Size: 14674      Transition Number: 1000.006k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:42:09,093][train][INFO][train.py>_log] ==> #198000     Total Loss: 4.087    [weighted Loss:4.087    Policy Loss: 7.379    Value Loss: 4.676    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 432963     Buffer Size: 14697      Transition Number: 999.969 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:44:52,299][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 7.716    Value Loss: 5.188    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 434838     Buffer Size: 14740      Transition Number: 1000.906k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:47:47,651][train][INFO][train.py>_log] ==> #200000     Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 7.270    Value Loss: 4.871    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 436719     Buffer Size: 14753      Transition Number: 1000.118k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:50:30,128][train][INFO][train.py>_log] ==> #201000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 7.420    Value Loss: 4.971    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 438743     Buffer Size: 14768      Transition Number: 1000.094k Batch Size: 256        Lr: 0.01000 
