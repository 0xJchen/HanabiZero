[2022-02-16 16:52:44,761][train][INFO][train.py>_log] ==> #0          Total Loss: 47.918   [weighted Loss:47.918   Policy Loss: 13.446   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1132       Buffer Size: 1132       Transition Number: 11.436  k Batch Size: 256        Lr: 0.00000 
[2022-02-16 16:55:41,333][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.279    [weighted Loss:7.279    Policy Loss: 14.065   Value Loss: 4.574    Reward Loss: 1.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 12636      Buffer Size: 12636      Transition Number: 156.006 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 16:58:16,478][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.938    [weighted Loss:5.938    Policy Loss: 13.393   Value Loss: 4.417    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 22310      Buffer Size: 22310      Transition Number: 276.522 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:00:53,689][train][INFO][train.py>_log] ==> #3000       Total Loss: 6.451    [weighted Loss:6.451    Policy Loss: 12.806   Value Loss: 4.385    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 33235      Buffer Size: 33235      Transition Number: 390.348 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:03:34,372][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.822    [weighted Loss:4.822    Policy Loss: 10.227   Value Loss: 4.124    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 44192      Buffer Size: 44192      Transition Number: 510.335 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:06:11,225][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.865    [weighted Loss:4.865    Policy Loss: 11.473   Value Loss: 4.361    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 48739      Buffer Size: 48739      Transition Number: 619.763 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:08:47,841][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.362    [weighted Loss:4.362    Policy Loss: 10.151   Value Loss: 4.067    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 53015      Buffer Size: 53015      Transition Number: 725.327 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:11:28,830][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.833    [weighted Loss:4.833    Policy Loss: 9.285    Value Loss: 4.198    Reward Loss: 1.148    Consistency Loss: 0.000    ] Replay Episodes Collected: 60595      Buffer Size: 60595      Transition Number: 833.183 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:14:04,294][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.463    [weighted Loss:3.463    Policy Loss: 7.837    Value Loss: 4.034    Reward Loss: 1.009    Consistency Loss: 0.000    ] Replay Episodes Collected: 68174      Buffer Size: 68174      Transition Number: 947.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:16:39,487][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.419    [weighted Loss:3.419    Policy Loss: 7.040    Value Loss: 4.437    Reward Loss: 1.074    Consistency Loss: 0.000    ] Replay Episodes Collected: 71935      Buffer Size: 67549      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:19:16,034][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.790    [weighted Loss:2.790    Policy Loss: 6.618    Value Loss: 4.258    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 75676      Buffer Size: 63249      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:21:55,600][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.323    [weighted Loss:2.323    Policy Loss: 5.649    Value Loss: 4.261    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 78837      Buffer Size: 58010      Transition Number: 1000.409k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:24:31,085][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 4.701    Value Loss: 4.371    Reward Loss: 0.889    Consistency Loss: 0.000    ] Replay Episodes Collected: 81925      Buffer Size: 50803      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:27:11,078][train][INFO][train.py>_log] ==> #13000      Total Loss: 1.982    [weighted Loss:1.982    Policy Loss: 4.677    Value Loss: 4.548    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 84643      Buffer Size: 44018      Transition Number: 1000.170k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:29:48,670][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.466    [weighted Loss:2.466    Policy Loss: 4.433    Value Loss: 4.624    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 87276      Buffer Size: 39995      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:32:25,061][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.743    [weighted Loss:2.743    Policy Loss: 4.573    Value Loss: 4.645    Reward Loss: 0.909    Consistency Loss: 0.000    ] Replay Episodes Collected: 90023      Buffer Size: 38307      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:35:05,461][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.886    [weighted Loss:1.886    Policy Loss: 4.043    Value Loss: 4.464    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 92827      Buffer Size: 35198      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:37:42,046][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 4.210    Value Loss: 5.010    Reward Loss: 1.039    Consistency Loss: 0.000    ] Replay Episodes Collected: 95190      Buffer Size: 30709      Transition Number: 1000.298k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:40:20,329][train][INFO][train.py>_log] ==> #18000      Total Loss: 1.797    [weighted Loss:1.797    Policy Loss: 4.771    Value Loss: 4.428    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 97551      Buffer Size: 27142      Transition Number: 1000.149k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:43:01,838][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.176    [weighted Loss:2.176    Policy Loss: 3.912    Value Loss: 4.739    Reward Loss: 1.035    Consistency Loss: 0.000    ] Replay Episodes Collected: 99819      Buffer Size: 25360      Transition Number: 1000.480k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:45:43,573][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.919    [weighted Loss:1.919    Policy Loss: 3.705    Value Loss: 4.836    Reward Loss: 0.882    Consistency Loss: 0.000    ] Replay Episodes Collected: 102085     Buffer Size: 24259      Transition Number: 1000.079k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:48:24,551][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.993    [weighted Loss:1.993    Policy Loss: 3.279    Value Loss: 4.491    Reward Loss: 0.902    Consistency Loss: 0.000    ] Replay Episodes Collected: 104493     Buffer Size: 23679      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:51:07,385][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.790    [weighted Loss:1.790    Policy Loss: 3.758    Value Loss: 4.427    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 106985     Buffer Size: 23156      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:53:47,753][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.782    [weighted Loss:1.782    Policy Loss: 3.497    Value Loss: 4.318    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 109195     Buffer Size: 22701      Transition Number: 1000.274k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:56:26,805][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.837    [weighted Loss:1.837    Policy Loss: 3.544    Value Loss: 4.148    Reward Loss: 0.704    Consistency Loss: 0.000    ] Replay Episodes Collected: 111384     Buffer Size: 22214      Transition Number: 1000.126k Batch Size: 256        Lr: 0.10000 
[2022-02-16 17:59:12,556][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.223    [weighted Loss:1.223    Policy Loss: 3.784    Value Loss: 4.350    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 113499     Buffer Size: 21569      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:01:54,423][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.141    [weighted Loss:2.141    Policy Loss: 3.681    Value Loss: 4.446    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 115653     Buffer Size: 21001      Transition Number: 1000.299k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:04:35,803][train][INFO][train.py>_log] ==> #27000      Total Loss: 1.567    [weighted Loss:1.567    Policy Loss: 3.987    Value Loss: 4.397    Reward Loss: 0.729    Consistency Loss: 0.000    ] Replay Episodes Collected: 117721     Buffer Size: 20571      Transition Number: 1000.230k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:07:17,420][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 3.885    Value Loss: 4.330    Reward Loss: 0.703    Consistency Loss: 0.000    ] Replay Episodes Collected: 119700     Buffer Size: 20243      Transition Number: 1000.274k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:09:56,603][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.000    [weighted Loss:2.000    Policy Loss: 3.823    Value Loss: 4.691    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 121859     Buffer Size: 20080      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:12:36,548][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.011    [weighted Loss:2.011    Policy Loss: 3.558    Value Loss: 4.628    Reward Loss: 0.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 124018     Buffer Size: 19787      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:15:15,938][train][INFO][train.py>_log] ==> #31000      Total Loss: 1.414    [weighted Loss:1.414    Policy Loss: 3.507    Value Loss: 4.995    Reward Loss: 0.817    Consistency Loss: 0.000    ] Replay Episodes Collected: 125724     Buffer Size: 19119      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:17:59,689][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.921    [weighted Loss:1.921    Policy Loss: 3.716    Value Loss: 4.690    Reward Loss: 0.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 127540     Buffer Size: 18477      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:20:39,271][train][INFO][train.py>_log] ==> #33000      Total Loss: 1.616    [weighted Loss:1.616    Policy Loss: 3.379    Value Loss: 5.165    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 129180     Buffer Size: 17796      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:23:18,958][train][INFO][train.py>_log] ==> #34000      Total Loss: 2.213    [weighted Loss:2.213    Policy Loss: 3.170    Value Loss: 5.006    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 130960     Buffer Size: 17260      Transition Number: 1000.273k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:25:59,092][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.322    [weighted Loss:2.322    Policy Loss: 3.229    Value Loss: 4.890    Reward Loss: 0.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 132615     Buffer Size: 16813      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:28:41,148][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 3.533    Value Loss: 4.680    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 134328     Buffer Size: 16411      Transition Number: 999.927 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:31:21,958][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.701    [weighted Loss:1.701    Policy Loss: 4.371    Value Loss: 5.144    Reward Loss: 0.845    Consistency Loss: 0.000    ] Replay Episodes Collected: 136076     Buffer Size: 15943      Transition Number: 1000.688k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:33:59,297][train][INFO][train.py>_log] ==> #38000      Total Loss: 1.900    [weighted Loss:1.900    Policy Loss: 5.554    Value Loss: 4.697    Reward Loss: 0.998    Consistency Loss: 0.000    ] Replay Episodes Collected: 137727     Buffer Size: 15384      Transition Number: 1000.131k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:36:35,726][train][INFO][train.py>_log] ==> #39000      Total Loss: 2.148    [weighted Loss:2.148    Policy Loss: 5.816    Value Loss: 4.709    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 139414     Buffer Size: 14905      Transition Number: 1000.025k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:39:16,330][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.925    [weighted Loss:2.925    Policy Loss: 6.647    Value Loss: 4.499    Reward Loss: 0.829    Consistency Loss: 0.000    ] Replay Episodes Collected: 141070     Buffer Size: 14794      Transition Number: 1000.136k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:41:53,209][train][INFO][train.py>_log] ==> #41000      Total Loss: 3.557    [weighted Loss:3.557    Policy Loss: 8.035    Value Loss: 4.679    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 142945     Buffer Size: 14716      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:44:29,288][train][INFO][train.py>_log] ==> #42000      Total Loss: 3.727    [weighted Loss:3.727    Policy Loss: 8.528    Value Loss: 4.413    Reward Loss: 0.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 144423     Buffer Size: 14715      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:47:10,503][train][INFO][train.py>_log] ==> #43000      Total Loss: 3.621    [weighted Loss:3.621    Policy Loss: 8.449    Value Loss: 4.458    Reward Loss: 0.929    Consistency Loss: 0.000    ] Replay Episodes Collected: 146328     Buffer Size: 14672      Transition Number: 1000.180k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:49:46,434][train][INFO][train.py>_log] ==> #44000      Total Loss: 3.549    [weighted Loss:3.549    Policy Loss: 8.859    Value Loss: 4.648    Reward Loss: 0.796    Consistency Loss: 0.000    ] Replay Episodes Collected: 147917     Buffer Size: 14692      Transition Number: 1000.132k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:52:24,124][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.236    [weighted Loss:4.236    Policy Loss: 9.520    Value Loss: 4.680    Reward Loss: 0.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 149730     Buffer Size: 14633      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:55:01,162][train][INFO][train.py>_log] ==> #46000      Total Loss: 4.816    [weighted Loss:4.816    Policy Loss: 9.195    Value Loss: 4.824    Reward Loss: 0.904    Consistency Loss: 0.000    ] Replay Episodes Collected: 151419     Buffer Size: 14593      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 18:57:43,564][train][INFO][train.py>_log] ==> #47000      Total Loss: 4.900    [weighted Loss:4.900    Policy Loss: 9.616    Value Loss: 4.646    Reward Loss: 0.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 153156     Buffer Size: 14566      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:00:20,758][train][INFO][train.py>_log] ==> #48000      Total Loss: 5.064    [weighted Loss:5.064    Policy Loss: 9.361    Value Loss: 4.629    Reward Loss: 0.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 154919     Buffer Size: 14542      Transition Number: 999.949 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:03:00,312][train][INFO][train.py>_log] ==> #49000      Total Loss: 3.966    [weighted Loss:3.966    Policy Loss: 8.424    Value Loss: 4.383    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 156664     Buffer Size: 14509      Transition Number: 1000.312k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:05:39,727][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.064    [weighted Loss:3.064    Policy Loss: 8.036    Value Loss: 4.545    Reward Loss: 0.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 158381     Buffer Size: 14445      Transition Number: 1000.303k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:08:17,153][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.382    [weighted Loss:3.382    Policy Loss: 8.245    Value Loss: 4.354    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 160166     Buffer Size: 14363      Transition Number: 1000.256k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:10:58,079][train][INFO][train.py>_log] ==> #52000      Total Loss: 4.333    [weighted Loss:4.333    Policy Loss: 8.631    Value Loss: 4.238    Reward Loss: 0.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 161934     Buffer Size: 14310      Transition Number: 999.948 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:13:35,959][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.513    [weighted Loss:3.513    Policy Loss: 8.557    Value Loss: 4.523    Reward Loss: 1.063    Consistency Loss: 0.000    ] Replay Episodes Collected: 163680     Buffer Size: 14286      Transition Number: 1000.192k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:16:14,163][train][INFO][train.py>_log] ==> #54000      Total Loss: 4.353    [weighted Loss:4.353    Policy Loss: 8.748    Value Loss: 4.458    Reward Loss: 1.058    Consistency Loss: 0.000    ] Replay Episodes Collected: 165520     Buffer Size: 14256      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:18:55,971][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 8.933    Value Loss: 4.697    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 167371     Buffer Size: 14395      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:21:34,077][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.391    [weighted Loss:2.391    Policy Loss: 9.222    Value Loss: 5.105    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 169191     Buffer Size: 14529      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:24:11,360][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 9.018    Value Loss: 4.770    Reward Loss: 0.968    Consistency Loss: 0.000    ] Replay Episodes Collected: 171003     Buffer Size: 14638      Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:26:48,400][train][INFO][train.py>_log] ==> #58000      Total Loss: 4.305    [weighted Loss:4.305    Policy Loss: 9.196    Value Loss: 4.985    Reward Loss: 1.061    Consistency Loss: 0.000    ] Replay Episodes Collected: 172797     Buffer Size: 14773      Transition Number: 1000.076k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:29:28,749][train][INFO][train.py>_log] ==> #59000      Total Loss: 3.122    [weighted Loss:3.122    Policy Loss: 9.945    Value Loss: 5.069    Reward Loss: 1.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 174539     Buffer Size: 14854      Transition Number: 999.985 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:32:07,100][train][INFO][train.py>_log] ==> #60000      Total Loss: 3.825    [weighted Loss:3.825    Policy Loss: 10.086   Value Loss: 5.224    Reward Loss: 1.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 176309     Buffer Size: 14930      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:34:47,518][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.272    [weighted Loss:4.272    Policy Loss: 10.078   Value Loss: 5.183    Reward Loss: 0.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 178063     Buffer Size: 14976      Transition Number: 1000.318k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:37:26,243][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.404    [weighted Loss:3.404    Policy Loss: 9.928    Value Loss: 5.377    Reward Loss: 1.069    Consistency Loss: 0.000    ] Replay Episodes Collected: 179864     Buffer Size: 15033      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:40:03,645][train][INFO][train.py>_log] ==> #63000      Total Loss: 4.321    [weighted Loss:4.321    Policy Loss: 10.422   Value Loss: 5.035    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 181724     Buffer Size: 15059      Transition Number: 1000.328k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:42:44,960][train][INFO][train.py>_log] ==> #64000      Total Loss: 5.365    [weighted Loss:5.365    Policy Loss: 10.833   Value Loss: 5.483    Reward Loss: 1.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 183491     Buffer Size: 15022      Transition Number: 1000.200k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:45:20,994][train][INFO][train.py>_log] ==> #65000      Total Loss: 6.527    [weighted Loss:6.527    Policy Loss: 11.017   Value Loss: 5.203    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 185304     Buffer Size: 15063      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:48:00,831][train][INFO][train.py>_log] ==> #66000      Total Loss: 5.933    [weighted Loss:5.933    Policy Loss: 11.221   Value Loss: 5.118    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 187188     Buffer Size: 15079      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:50:41,494][train][INFO][train.py>_log] ==> #67000      Total Loss: 6.200    [weighted Loss:6.200    Policy Loss: 11.279   Value Loss: 5.311    Reward Loss: 1.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 188952     Buffer Size: 15167      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:53:19,018][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.850    [weighted Loss:4.850    Policy Loss: 11.449   Value Loss: 5.338    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 190807     Buffer Size: 15245      Transition Number: 1000.135k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:55:56,057][train][INFO][train.py>_log] ==> #69000      Total Loss: 4.642    [weighted Loss:4.642    Policy Loss: 11.479   Value Loss: 5.313    Reward Loss: 1.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 192666     Buffer Size: 15442      Transition Number: 1000.183k Batch Size: 256        Lr: 0.10000 
[2022-02-16 19:58:32,570][train][INFO][train.py>_log] ==> #70000      Total Loss: 3.255    [weighted Loss:3.255    Policy Loss: 11.781   Value Loss: 5.200    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 194551     Buffer Size: 15646      Transition Number: 1000.262k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:01:13,608][train][INFO][train.py>_log] ==> #71000      Total Loss: 5.036    [weighted Loss:5.036    Policy Loss: 11.593   Value Loss: 5.412    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 196414     Buffer Size: 15794      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:03:50,532][train][INFO][train.py>_log] ==> #72000      Total Loss: 3.898    [weighted Loss:3.898    Policy Loss: 11.092   Value Loss: 5.445    Reward Loss: 1.107    Consistency Loss: 0.000    ] Replay Episodes Collected: 198287     Buffer Size: 15914      Transition Number: 999.959 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:06:28,575][train][INFO][train.py>_log] ==> #73000      Total Loss: 5.452    [weighted Loss:5.452    Policy Loss: 11.086   Value Loss: 5.475    Reward Loss: 1.294    Consistency Loss: 0.000    ] Replay Episodes Collected: 200278     Buffer Size: 16060      Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:09:09,596][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.893    [weighted Loss:3.893    Policy Loss: 10.908   Value Loss: 5.666    Reward Loss: 1.078    Consistency Loss: 0.000    ] Replay Episodes Collected: 202174     Buffer Size: 16215      Transition Number: 1000.465k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:11:46,908][train][INFO][train.py>_log] ==> #75000      Total Loss: 4.175    [weighted Loss:4.175    Policy Loss: 11.362   Value Loss: 5.865    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 203991     Buffer Size: 16210      Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:14:29,160][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.633    [weighted Loss:4.633    Policy Loss: 11.189   Value Loss: 5.766    Reward Loss: 1.200    Consistency Loss: 0.000    ] Replay Episodes Collected: 205874     Buffer Size: 16197      Transition Number: 1000.021k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:17:07,455][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.166    [weighted Loss:4.166    Policy Loss: 11.041   Value Loss: 5.523    Reward Loss: 1.144    Consistency Loss: 0.000    ] Replay Episodes Collected: 207650     Buffer Size: 16186      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:19:46,510][train][INFO][train.py>_log] ==> #78000      Total Loss: 5.748    [weighted Loss:5.748    Policy Loss: 10.987   Value Loss: 6.017    Reward Loss: 1.223    Consistency Loss: 0.000    ] Replay Episodes Collected: 209561     Buffer Size: 16075      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:22:27,515][train][INFO][train.py>_log] ==> #79000      Total Loss: 5.169    [weighted Loss:5.169    Policy Loss: 10.942   Value Loss: 5.556    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 211351     Buffer Size: 16008      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:25:03,922][train][INFO][train.py>_log] ==> #80000      Total Loss: 4.631    [weighted Loss:4.631    Policy Loss: 10.500   Value Loss: 5.430    Reward Loss: 1.226    Consistency Loss: 0.000    ] Replay Episodes Collected: 213176     Buffer Size: 15902      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:27:41,910][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.601    [weighted Loss:4.601    Policy Loss: 10.445   Value Loss: 5.419    Reward Loss: 1.218    Consistency Loss: 0.000    ] Replay Episodes Collected: 215108     Buffer Size: 15964      Transition Number: 1000.102k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:30:20,812][train][INFO][train.py>_log] ==> #82000      Total Loss: 5.802    [weighted Loss:5.802    Policy Loss: 10.528   Value Loss: 5.367    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 217025     Buffer Size: 15969      Transition Number: 1000.062k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:33:01,329][train][INFO][train.py>_log] ==> #83000      Total Loss: 5.229    [weighted Loss:5.229    Policy Loss: 10.672   Value Loss: 5.395    Reward Loss: 1.155    Consistency Loss: 0.000    ] Replay Episodes Collected: 218908     Buffer Size: 15878      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:35:38,736][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.608    [weighted Loss:4.608    Policy Loss: 10.576   Value Loss: 5.214    Reward Loss: 1.245    Consistency Loss: 0.000    ] Replay Episodes Collected: 220648     Buffer Size: 15909      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:38:18,459][train][INFO][train.py>_log] ==> #85000      Total Loss: 5.676    [weighted Loss:5.676    Policy Loss: 10.885   Value Loss: 5.448    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 222512     Buffer Size: 15885      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:40:57,938][train][INFO][train.py>_log] ==> #86000      Total Loss: 4.700    [weighted Loss:4.700    Policy Loss: 10.361   Value Loss: 5.679    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 224271     Buffer Size: 15919      Transition Number: 1000.106k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:43:36,692][train][INFO][train.py>_log] ==> #87000      Total Loss: 5.076    [weighted Loss:5.076    Policy Loss: 10.578   Value Loss: 5.752    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 226205     Buffer Size: 15997      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:46:16,858][train][INFO][train.py>_log] ==> #88000      Total Loss: 6.095    [weighted Loss:6.095    Policy Loss: 10.876   Value Loss: 5.947    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 228111     Buffer Size: 16116      Transition Number: 1000.160k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:48:54,063][train][INFO][train.py>_log] ==> #89000      Total Loss: 4.734    [weighted Loss:4.734    Policy Loss: 10.041   Value Loss: 6.196    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 229893     Buffer Size: 16185      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:51:31,371][train][INFO][train.py>_log] ==> #90000      Total Loss: 5.452    [weighted Loss:5.452    Policy Loss: 10.787   Value Loss: 5.581    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 231714     Buffer Size: 16144      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:54:13,020][train][INFO][train.py>_log] ==> #91000      Total Loss: 4.217    [weighted Loss:4.217    Policy Loss: 10.865   Value Loss: 5.803    Reward Loss: 1.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 233591     Buffer Size: 16126      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:56:50,290][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.639    [weighted Loss:4.639    Policy Loss: 10.421   Value Loss: 5.844    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 235379     Buffer Size: 16212      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 20:59:31,266][train][INFO][train.py>_log] ==> #93000      Total Loss: 4.424    [weighted Loss:4.424    Policy Loss: 11.039   Value Loss: 6.156    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 237316     Buffer Size: 16273      Transition Number: 1000.001k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:02:11,431][train][INFO][train.py>_log] ==> #94000      Total Loss: 5.533    [weighted Loss:5.533    Policy Loss: 10.746   Value Loss: 6.029    Reward Loss: 1.417    Consistency Loss: 0.000    ] Replay Episodes Collected: 239046     Buffer Size: 16366      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:04:52,034][train][INFO][train.py>_log] ==> #95000      Total Loss: 5.744    [weighted Loss:5.744    Policy Loss: 10.338   Value Loss: 6.170    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 242378     Buffer Size: 17774      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:07:29,986][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.646    [weighted Loss:5.646    Policy Loss: 10.251   Value Loss: 6.067    Reward Loss: 1.458    Consistency Loss: 0.000    ] Replay Episodes Collected: 245662     Buffer Size: 19275      Transition Number: 1000.220k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:10:07,872][train][INFO][train.py>_log] ==> #97000      Total Loss: 5.335    [weighted Loss:5.335    Policy Loss: 10.197   Value Loss: 6.014    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 247902     Buffer Size: 19738      Transition Number: 999.935 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:12:45,623][train][INFO][train.py>_log] ==> #98000      Total Loss: 3.852    [weighted Loss:3.852    Policy Loss: 9.995    Value Loss: 6.011    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 250081     Buffer Size: 20191      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:15:22,720][train][INFO][train.py>_log] ==> #99000      Total Loss: 3.019    [weighted Loss:3.019    Policy Loss: 9.521    Value Loss: 6.221    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 252018     Buffer Size: 20306      Transition Number: 999.940 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:18:01,703][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 9.306    Value Loss: 6.067    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 253893     Buffer Size: 20413      Transition Number: 1000.357k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:20:40,291][train][INFO][train.py>_log] ==> #101000     Total Loss: 4.248    [weighted Loss:4.248    Policy Loss: 9.713    Value Loss: 5.924    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 255747     Buffer Size: 20474      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:23:20,856][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.951    [weighted Loss:2.951    Policy Loss: 9.395    Value Loss: 5.970    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 257645     Buffer Size: 20537      Transition Number: 1000.118k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:26:02,386][train][INFO][train.py>_log] ==> #103000     Total Loss: 5.313    [weighted Loss:5.313    Policy Loss: 9.810    Value Loss: 5.899    Reward Loss: 1.359    Consistency Loss: 0.000    ] Replay Episodes Collected: 259474     Buffer Size: 20560      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:28:40,805][train][INFO][train.py>_log] ==> #104000     Total Loss: 5.326    [weighted Loss:5.326    Policy Loss: 10.196   Value Loss: 6.175    Reward Loss: 1.413    Consistency Loss: 0.000    ] Replay Episodes Collected: 261305     Buffer Size: 19368      Transition Number: 1000.236k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:31:20,922][train][INFO][train.py>_log] ==> #105000     Total Loss: 6.138    [weighted Loss:6.138    Policy Loss: 9.812    Value Loss: 5.776    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 263027     Buffer Size: 17938      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:34:00,927][train][INFO][train.py>_log] ==> #106000     Total Loss: 4.009    [weighted Loss:4.009    Policy Loss: 9.808    Value Loss: 5.707    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 264890     Buffer Size: 17158      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:36:40,143][train][INFO][train.py>_log] ==> #107000     Total Loss: 5.174    [weighted Loss:5.174    Policy Loss: 9.627    Value Loss: 5.967    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 266779     Buffer Size: 16825      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:39:20,016][train][INFO][train.py>_log] ==> #108000     Total Loss: 5.268    [weighted Loss:5.268    Policy Loss: 9.657    Value Loss: 5.760    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 268774     Buffer Size: 16779      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:41:59,784][train][INFO][train.py>_log] ==> #109000     Total Loss: 5.604    [weighted Loss:5.604    Policy Loss: 9.937    Value Loss: 6.074    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 270574     Buffer Size: 16738      Transition Number: 1000.116k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:44:41,419][train][INFO][train.py>_log] ==> #110000     Total Loss: 4.323    [weighted Loss:4.323    Policy Loss: 9.932    Value Loss: 5.905    Reward Loss: 1.334    Consistency Loss: 0.000    ] Replay Episodes Collected: 272435     Buffer Size: 16692      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:47:19,481][train][INFO][train.py>_log] ==> #111000     Total Loss: 5.117    [weighted Loss:5.117    Policy Loss: 9.024    Value Loss: 6.203    Reward Loss: 1.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 274174     Buffer Size: 16597      Transition Number: 999.969 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:49:59,196][train][INFO][train.py>_log] ==> #112000     Total Loss: 4.329    [weighted Loss:4.329    Policy Loss: 9.033    Value Loss: 6.360    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 275985     Buffer Size: 16546      Transition Number: 1000.154k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:52:35,967][train][INFO][train.py>_log] ==> #113000     Total Loss: 3.776    [weighted Loss:3.776    Policy Loss: 8.444    Value Loss: 6.554    Reward Loss: 1.479    Consistency Loss: 0.000    ] Replay Episodes Collected: 277868     Buffer Size: 16682      Transition Number: 1000.018k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:55:16,019][train][INFO][train.py>_log] ==> #114000     Total Loss: 4.709    [weighted Loss:4.709    Policy Loss: 8.449    Value Loss: 5.887    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 279850     Buffer Size: 16873      Transition Number: 999.968 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 21:57:56,888][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.128    [weighted Loss:4.128    Policy Loss: 8.520    Value Loss: 5.714    Reward Loss: 1.355    Consistency Loss: 0.000    ] Replay Episodes Collected: 281746     Buffer Size: 17052      Transition Number: 999.931 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:00:36,684][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.677    [weighted Loss:3.677    Policy Loss: 7.481    Value Loss: 6.347    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 283694     Buffer Size: 17100      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:03:17,813][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.053    [weighted Loss:4.053    Policy Loss: 7.628    Value Loss: 6.014    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 285514     Buffer Size: 16985      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:05:58,157][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.902    [weighted Loss:3.902    Policy Loss: 7.774    Value Loss: 6.397    Reward Loss: 1.326    Consistency Loss: 0.000    ] Replay Episodes Collected: 287321     Buffer Size: 16891      Transition Number: 1000.229k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:08:38,068][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.676    [weighted Loss:4.676    Policy Loss: 7.924    Value Loss: 5.574    Reward Loss: 1.347    Consistency Loss: 0.000    ] Replay Episodes Collected: 288988     Buffer Size: 16796      Transition Number: 1000.264k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:11:17,875][train][INFO][train.py>_log] ==> #120000     Total Loss: 4.104    [weighted Loss:4.104    Policy Loss: 7.359    Value Loss: 5.712    Reward Loss: 1.281    Consistency Loss: 0.000    ] Replay Episodes Collected: 290778     Buffer Size: 16740      Transition Number: 1000.249k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:13:59,747][train][INFO][train.py>_log] ==> #121000     Total Loss: 4.734    [weighted Loss:4.734    Policy Loss: 8.009    Value Loss: 5.665    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 292593     Buffer Size: 16737      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:16:40,778][train][INFO][train.py>_log] ==> #122000     Total Loss: 4.149    [weighted Loss:4.149    Policy Loss: 8.227    Value Loss: 5.943    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 294368     Buffer Size: 16592      Transition Number: 1000.195k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:19:19,558][train][INFO][train.py>_log] ==> #123000     Total Loss: 5.441    [weighted Loss:5.441    Policy Loss: 8.517    Value Loss: 5.930    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 296160     Buffer Size: 16361      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:22:02,233][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.279    [weighted Loss:4.279    Policy Loss: 8.527    Value Loss: 5.308    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 297963     Buffer Size: 16145      Transition Number: 1000.194k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:24:43,528][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.559    [weighted Loss:3.559    Policy Loss: 8.965    Value Loss: 5.239    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 299822     Buffer Size: 15999      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:27:24,646][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.544    [weighted Loss:4.544    Policy Loss: 8.630    Value Loss: 5.659    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 301670     Buffer Size: 15978      Transition Number: 1000.122k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:30:05,765][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 9.055    Value Loss: 5.721    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 303381     Buffer Size: 15904      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:32:43,769][train][INFO][train.py>_log] ==> #128000     Total Loss: 2.634    [weighted Loss:2.634    Policy Loss: 8.640    Value Loss: 5.286    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 305228     Buffer Size: 15859      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:35:25,521][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.327    [weighted Loss:3.327    Policy Loss: 8.334    Value Loss: 5.543    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 306948     Buffer Size: 15842      Transition Number: 1000.333k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:38:06,946][train][INFO][train.py>_log] ==> #130000     Total Loss: 3.832    [weighted Loss:3.832    Policy Loss: 8.306    Value Loss: 5.321    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 308828     Buffer Size: 15724      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:40:47,980][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.578    [weighted Loss:3.578    Policy Loss: 7.977    Value Loss: 5.265    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 310618     Buffer Size: 15768      Transition Number: 1000.291k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:43:28,036][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.148    [weighted Loss:3.148    Policy Loss: 8.769    Value Loss: 5.244    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 312510     Buffer Size: 15809      Transition Number: 1000.243k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:46:09,869][train][INFO][train.py>_log] ==> #133000     Total Loss: 3.908    [weighted Loss:3.908    Policy Loss: 7.479    Value Loss: 5.631    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 314415     Buffer Size: 15843      Transition Number: 1000.076k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:48:52,896][train][INFO][train.py>_log] ==> #134000     Total Loss: 1.664    [weighted Loss:1.664    Policy Loss: 6.970    Value Loss: 5.452    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 316317     Buffer Size: 15850      Transition Number: 999.951 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:51:33,706][train][INFO][train.py>_log] ==> #135000     Total Loss: 3.551    [weighted Loss:3.551    Policy Loss: 7.283    Value Loss: 5.755    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 318084     Buffer Size: 15832      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:54:16,463][train][INFO][train.py>_log] ==> #136000     Total Loss: 3.694    [weighted Loss:3.694    Policy Loss: 6.824    Value Loss: 5.613    Reward Loss: 1.475    Consistency Loss: 0.000    ] Replay Episodes Collected: 319962     Buffer Size: 15875      Transition Number: 1000.070k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:56:56,873][train][INFO][train.py>_log] ==> #137000     Total Loss: 4.055    [weighted Loss:4.055    Policy Loss: 7.225    Value Loss: 5.613    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 321751     Buffer Size: 15950      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-02-16 22:59:38,156][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.374    [weighted Loss:3.374    Policy Loss: 6.994    Value Loss: 4.982    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 323649     Buffer Size: 16069      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:02:18,915][train][INFO][train.py>_log] ==> #139000     Total Loss: 2.971    [weighted Loss:2.971    Policy Loss: 6.362    Value Loss: 5.723    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 325353     Buffer Size: 16117      Transition Number: 1000.765k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:05:00,510][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.357    [weighted Loss:3.357    Policy Loss: 6.517    Value Loss: 5.376    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 327213     Buffer Size: 16017      Transition Number: 999.979 k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:07:41,008][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.831    [weighted Loss:2.831    Policy Loss: 6.704    Value Loss: 5.321    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 329146     Buffer Size: 16078      Transition Number: 1000.119k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:10:24,815][train][INFO][train.py>_log] ==> #142000     Total Loss: 2.044    [weighted Loss:2.044    Policy Loss: 6.561    Value Loss: 5.277    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 331086     Buffer Size: 16145      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:13:05,862][train][INFO][train.py>_log] ==> #143000     Total Loss: 1.810    [weighted Loss:1.810    Policy Loss: 6.767    Value Loss: 5.383    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 332791     Buffer Size: 16084      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:15:46,514][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.649    [weighted Loss:3.649    Policy Loss: 6.769    Value Loss: 5.421    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 334651     Buffer Size: 16035      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:18:30,701][train][INFO][train.py>_log] ==> #145000     Total Loss: 2.671    [weighted Loss:2.671    Policy Loss: 6.683    Value Loss: 5.344    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 336504     Buffer Size: 15972      Transition Number: 1000.288k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:21:11,345][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.424    [weighted Loss:3.424    Policy Loss: 6.710    Value Loss: 5.281    Reward Loss: 1.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 338339     Buffer Size: 15903      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:23:53,797][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.737    [weighted Loss:2.737    Policy Loss: 6.608    Value Loss: 5.362    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 340201     Buffer Size: 15836      Transition Number: 1000.103k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:26:35,972][train][INFO][train.py>_log] ==> #148000     Total Loss: 2.222    [weighted Loss:2.222    Policy Loss: 6.742    Value Loss: 5.828    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 342050     Buffer Size: 15825      Transition Number: 1000.114k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:29:17,614][train][INFO][train.py>_log] ==> #149000     Total Loss: 3.736    [weighted Loss:3.736    Policy Loss: 7.601    Value Loss: 5.861    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 343811     Buffer Size: 15703      Transition Number: 1000.068k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:32:01,056][train][INFO][train.py>_log] ==> #150000     Total Loss: 2.711    [weighted Loss:2.711    Policy Loss: 7.861    Value Loss: 5.295    Reward Loss: 1.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 345581     Buffer Size: 15504      Transition Number: 1000.301k Batch Size: 256        Lr: 0.10000 
[2022-02-16 23:34:42,897][train][INFO][train.py>_log] ==> #151000     Total Loss: 2.691    [weighted Loss:2.691    Policy Loss: 7.711    Value Loss: 4.994    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 347455     Buffer Size: 15373      Transition Number: 1000.468k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:37:24,369][train][INFO][train.py>_log] ==> #152000     Total Loss: 3.715    [weighted Loss:3.715    Policy Loss: 7.733    Value Loss: 4.794    Reward Loss: 1.173    Consistency Loss: 0.000    ] Replay Episodes Collected: 349202     Buffer Size: 15370      Transition Number: 999.959 k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:40:05,273][train][INFO][train.py>_log] ==> #153000     Total Loss: 3.827    [weighted Loss:3.827    Policy Loss: 7.650    Value Loss: 4.818    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 350974     Buffer Size: 15325      Transition Number: 1000.004k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:42:48,577][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.101    [weighted Loss:3.101    Policy Loss: 7.876    Value Loss: 5.016    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 352878     Buffer Size: 15261      Transition Number: 1000.224k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:45:29,945][train][INFO][train.py>_log] ==> #155000     Total Loss: 4.023    [weighted Loss:4.023    Policy Loss: 8.001    Value Loss: 5.545    Reward Loss: 1.296    Consistency Loss: 0.000    ] Replay Episodes Collected: 354546     Buffer Size: 15165      Transition Number: 1000.293k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:48:11,452][train][INFO][train.py>_log] ==> #156000     Total Loss: 3.068    [weighted Loss:3.068    Policy Loss: 7.889    Value Loss: 4.875    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 356397     Buffer Size: 15047      Transition Number: 1000.184k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:50:53,574][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.692    [weighted Loss:3.692    Policy Loss: 8.255    Value Loss: 4.917    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 358104     Buffer Size: 14988      Transition Number: 999.981 k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:53:34,425][train][INFO][train.py>_log] ==> #158000     Total Loss: 2.502    [weighted Loss:2.502    Policy Loss: 8.182    Value Loss: 4.590    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 359841     Buffer Size: 14943      Transition Number: 999.948 k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:56:15,155][train][INFO][train.py>_log] ==> #159000     Total Loss: 3.506    [weighted Loss:3.506    Policy Loss: 7.920    Value Loss: 4.344    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 361690     Buffer Size: 14894      Transition Number: 999.965 k Batch Size: 256        Lr: 0.01000 
[2022-02-16 23:58:56,813][train][INFO][train.py>_log] ==> #160000     Total Loss: 3.515    [weighted Loss:3.515    Policy Loss: 8.012    Value Loss: 5.066    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 363411     Buffer Size: 14851      Transition Number: 1000.383k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:01:38,317][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.768    [weighted Loss:3.768    Policy Loss: 7.596    Value Loss: 4.714    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 365170     Buffer Size: 14787      Transition Number: 999.943 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:04:20,277][train][INFO][train.py>_log] ==> #162000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 7.791    Value Loss: 4.342    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 366992     Buffer Size: 14760      Transition Number: 999.969 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:07:02,010][train][INFO][train.py>_log] ==> #163000     Total Loss: 4.089    [weighted Loss:4.089    Policy Loss: 7.856    Value Loss: 4.419    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 368747     Buffer Size: 14745      Transition Number: 1000.077k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:09:43,864][train][INFO][train.py>_log] ==> #164000     Total Loss: 3.933    [weighted Loss:3.933    Policy Loss: 7.615    Value Loss: 4.482    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 370525     Buffer Size: 14746      Transition Number: 1000.114k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:12:27,343][train][INFO][train.py>_log] ==> #165000     Total Loss: 3.261    [weighted Loss:3.261    Policy Loss: 7.334    Value Loss: 4.507    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 372391     Buffer Size: 14754      Transition Number: 1000.112k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:15:10,400][train][INFO][train.py>_log] ==> #166000     Total Loss: 3.420    [weighted Loss:3.420    Policy Loss: 6.703    Value Loss: 4.547    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 374144     Buffer Size: 14750      Transition Number: 1000.154k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:17:51,417][train][INFO][train.py>_log] ==> #167000     Total Loss: 4.196    [weighted Loss:4.196    Policy Loss: 7.203    Value Loss: 4.569    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 375943     Buffer Size: 14730      Transition Number: 1000.103k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:20:34,218][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 6.641    Value Loss: 4.621    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 377678     Buffer Size: 14706      Transition Number: 999.985 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:23:17,678][train][INFO][train.py>_log] ==> #169000     Total Loss: 1.675    [weighted Loss:1.675    Policy Loss: 6.613    Value Loss: 4.597    Reward Loss: 1.419    Consistency Loss: 0.000    ] Replay Episodes Collected: 379511     Buffer Size: 14702      Transition Number: 1000.105k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:25:58,423][train][INFO][train.py>_log] ==> #170000     Total Loss: 2.403    [weighted Loss:2.403    Policy Loss: 6.468    Value Loss: 4.385    Reward Loss: 1.248    Consistency Loss: 0.000    ] Replay Episodes Collected: 381270     Buffer Size: 14685      Transition Number: 1000.000k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:28:40,819][train][INFO][train.py>_log] ==> #171000     Total Loss: 4.189    [weighted Loss:4.189    Policy Loss: 6.337    Value Loss: 4.854    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 383106     Buffer Size: 14687      Transition Number: 999.940 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:31:25,307][train][INFO][train.py>_log] ==> #172000     Total Loss: 2.718    [weighted Loss:2.718    Policy Loss: 6.580    Value Loss: 4.727    Reward Loss: 1.350    Consistency Loss: 0.000    ] Replay Episodes Collected: 384980     Buffer Size: 14671      Transition Number: 1000.135k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:34:09,561][train][INFO][train.py>_log] ==> #173000     Total Loss: 1.601    [weighted Loss:1.601    Policy Loss: 6.104    Value Loss: 4.652    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 386689     Buffer Size: 14642      Transition Number: 999.992 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:36:51,802][train][INFO][train.py>_log] ==> #174000     Total Loss: 2.456    [weighted Loss:2.456    Policy Loss: 6.094    Value Loss: 4.645    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 388585     Buffer Size: 14626      Transition Number: 999.998 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:39:36,206][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.923    [weighted Loss:2.923    Policy Loss: 6.375    Value Loss: 4.763    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 390429     Buffer Size: 14629      Transition Number: 1000.056k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:42:18,235][train][INFO][train.py>_log] ==> #176000     Total Loss: 3.031    [weighted Loss:3.031    Policy Loss: 6.306    Value Loss: 4.871    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 392177     Buffer Size: 14642      Transition Number: 1000.208k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:45:01,006][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.686    [weighted Loss:3.686    Policy Loss: 6.340    Value Loss: 4.705    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 394035     Buffer Size: 14625      Transition Number: 1000.069k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:47:45,197][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.446    [weighted Loss:3.446    Policy Loss: 6.645    Value Loss: 4.595    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 395827     Buffer Size: 14630      Transition Number: 1000.128k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:50:26,725][train][INFO][train.py>_log] ==> #179000     Total Loss: 2.449    [weighted Loss:2.449    Policy Loss: 6.715    Value Loss: 4.770    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 397645     Buffer Size: 14636      Transition Number: 1000.232k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:53:12,064][train][INFO][train.py>_log] ==> #180000     Total Loss: 2.739    [weighted Loss:2.739    Policy Loss: 6.644    Value Loss: 4.789    Reward Loss: 1.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 399420     Buffer Size: 14635      Transition Number: 999.934 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:55:54,297][train][INFO][train.py>_log] ==> #181000     Total Loss: 2.868    [weighted Loss:2.868    Policy Loss: 7.093    Value Loss: 4.574    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 401366     Buffer Size: 14660      Transition Number: 1000.086k Batch Size: 256        Lr: 0.01000 
[2022-02-17 00:58:36,283][train][INFO][train.py>_log] ==> #182000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 7.058    Value Loss: 4.990    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 403162     Buffer Size: 14686      Transition Number: 999.948 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:01:19,840][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.154    [weighted Loss:3.154    Policy Loss: 7.206    Value Loss: 4.732    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 405027     Buffer Size: 14708      Transition Number: 1000.073k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:04:03,613][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.526    [weighted Loss:3.526    Policy Loss: 6.829    Value Loss: 4.507    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 406918     Buffer Size: 14726      Transition Number: 1000.133k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:06:46,253][train][INFO][train.py>_log] ==> #185000     Total Loss: 3.178    [weighted Loss:3.178    Policy Loss: 7.023    Value Loss: 4.943    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 408741     Buffer Size: 14750      Transition Number: 999.949 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:09:29,200][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.667    [weighted Loss:3.667    Policy Loss: 7.487    Value Loss: 4.511    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 410575     Buffer Size: 14765      Transition Number: 999.982 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:12:14,317][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.477    [weighted Loss:3.477    Policy Loss: 7.246    Value Loss: 4.673    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 412469     Buffer Size: 14765      Transition Number: 999.940 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:14:57,960][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.118    [weighted Loss:3.118    Policy Loss: 7.555    Value Loss: 4.403    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 414241     Buffer Size: 14760      Transition Number: 1000.081k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:17:41,393][train][INFO][train.py>_log] ==> #189000     Total Loss: 2.918    [weighted Loss:2.918    Policy Loss: 7.324    Value Loss: 4.963    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 416172     Buffer Size: 14740      Transition Number: 1000.220k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:20:25,943][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 7.157    Value Loss: 4.642    Reward Loss: 1.518    Consistency Loss: 0.000    ] Replay Episodes Collected: 418036     Buffer Size: 14714      Transition Number: 1000.262k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:23:08,195][train][INFO][train.py>_log] ==> #191000     Total Loss: 3.012    [weighted Loss:3.012    Policy Loss: 7.303    Value Loss: 4.686    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 419890     Buffer Size: 14692      Transition Number: 1000.331k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:25:52,354][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.841    [weighted Loss:2.841    Policy Loss: 7.181    Value Loss: 4.777    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 421690     Buffer Size: 14663      Transition Number: 1000.080k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:28:36,955][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.187    [weighted Loss:3.187    Policy Loss: 7.052    Value Loss: 4.351    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 423615     Buffer Size: 14649      Transition Number: 1000.009k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:31:19,269][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.538    [weighted Loss:3.538    Policy Loss: 7.406    Value Loss: 4.694    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 425453     Buffer Size: 14633      Transition Number: 1000.012k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:34:01,770][train][INFO][train.py>_log] ==> #195000     Total Loss: 3.853    [weighted Loss:3.853    Policy Loss: 6.838    Value Loss: 4.539    Reward Loss: 1.394    Consistency Loss: 0.000    ] Replay Episodes Collected: 427294     Buffer Size: 14647      Transition Number: 1000.437k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:36:43,671][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.691    [weighted Loss:3.691    Policy Loss: 7.216    Value Loss: 4.588    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 429194     Buffer Size: 14653      Transition Number: 999.944 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:39:25,738][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.246    [weighted Loss:3.246    Policy Loss: 7.225    Value Loss: 4.859    Reward Loss: 1.319    Consistency Loss: 0.000    ] Replay Episodes Collected: 431112     Buffer Size: 14674      Transition Number: 1000.006k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:42:09,093][train][INFO][train.py>_log] ==> #198000     Total Loss: 4.087    [weighted Loss:4.087    Policy Loss: 7.379    Value Loss: 4.676    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 432963     Buffer Size: 14697      Transition Number: 999.969 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:44:52,299][train][INFO][train.py>_log] ==> #199000     Total Loss: 2.453    [weighted Loss:2.453    Policy Loss: 7.716    Value Loss: 5.188    Reward Loss: 1.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 434838     Buffer Size: 14740      Transition Number: 1000.906k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:47:47,651][train][INFO][train.py>_log] ==> #200000     Total Loss: 3.704    [weighted Loss:3.704    Policy Loss: 7.270    Value Loss: 4.871    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 436719     Buffer Size: 14753      Transition Number: 1000.118k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:50:30,128][train][INFO][train.py>_log] ==> #201000     Total Loss: 3.276    [weighted Loss:3.276    Policy Loss: 7.420    Value Loss: 4.971    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 438743     Buffer Size: 14768      Transition Number: 1000.094k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:53:16,207][train][INFO][train.py>_log] ==> #202000     Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 6.957    Value Loss: 4.729    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 440603     Buffer Size: 14774      Transition Number: 1000.170k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:56:01,272][train][INFO][train.py>_log] ==> #203000     Total Loss: 2.518    [weighted Loss:2.518    Policy Loss: 7.372    Value Loss: 4.898    Reward Loss: 1.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 442576     Buffer Size: 14773      Transition Number: 1000.164k Batch Size: 256        Lr: 0.01000 
[2022-02-17 01:58:45,697][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.069    [weighted Loss:3.069    Policy Loss: 7.259    Value Loss: 4.679    Reward Loss: 1.383    Consistency Loss: 0.000    ] Replay Episodes Collected: 444524     Buffer Size: 14763      Transition Number: 999.954 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:01:30,056][train][INFO][train.py>_log] ==> #205000     Total Loss: 2.134    [weighted Loss:2.134    Policy Loss: 7.610    Value Loss: 5.107    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 446334     Buffer Size: 14767      Transition Number: 1000.118k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:04:13,120][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.388    [weighted Loss:3.388    Policy Loss: 7.022    Value Loss: 4.857    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 448209     Buffer Size: 14758      Transition Number: 1000.005k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:06:57,653][train][INFO][train.py>_log] ==> #207000     Total Loss: 3.925    [weighted Loss:3.925    Policy Loss: 7.138    Value Loss: 4.850    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 450116     Buffer Size: 14749      Transition Number: 1000.048k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:09:41,906][train][INFO][train.py>_log] ==> #208000     Total Loss: 2.814    [weighted Loss:2.814    Policy Loss: 7.618    Value Loss: 5.047    Reward Loss: 1.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 452026     Buffer Size: 14734      Transition Number: 999.941 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:12:26,215][train][INFO][train.py>_log] ==> #209000     Total Loss: 2.217    [weighted Loss:2.217    Policy Loss: 7.384    Value Loss: 5.016    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 453890     Buffer Size: 14731      Transition Number: 1000.023k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:15:10,851][train][INFO][train.py>_log] ==> #210000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 7.402    Value Loss: 4.795    Reward Loss: 1.400    Consistency Loss: 0.000    ] Replay Episodes Collected: 455787     Buffer Size: 14730      Transition Number: 1000.087k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:17:56,569][train][INFO][train.py>_log] ==> #211000     Total Loss: 4.080    [weighted Loss:4.080    Policy Loss: 7.502    Value Loss: 5.033    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 457690     Buffer Size: 14709      Transition Number: 1000.304k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:20:42,355][train][INFO][train.py>_log] ==> #212000     Total Loss: 3.358    [weighted Loss:3.358    Policy Loss: 6.961    Value Loss: 4.859    Reward Loss: 1.448    Consistency Loss: 0.000    ] Replay Episodes Collected: 459609     Buffer Size: 14697      Transition Number: 1000.022k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:23:27,644][train][INFO][train.py>_log] ==> #213000     Total Loss: 3.759    [weighted Loss:3.759    Policy Loss: 6.834    Value Loss: 4.994    Reward Loss: 1.309    Consistency Loss: 0.000    ] Replay Episodes Collected: 461494     Buffer Size: 14691      Transition Number: 999.975 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:26:12,421][train][INFO][train.py>_log] ==> #214000     Total Loss: 3.667    [weighted Loss:3.667    Policy Loss: 7.112    Value Loss: 5.124    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 463360     Buffer Size: 14679      Transition Number: 999.960 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:28:55,881][train][INFO][train.py>_log] ==> #215000     Total Loss: 3.235    [weighted Loss:3.235    Policy Loss: 7.081    Value Loss: 5.283    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 465213     Buffer Size: 14641      Transition Number: 1000.153k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:31:38,605][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.988    [weighted Loss:2.988    Policy Loss: 6.814    Value Loss: 5.060    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 467077     Buffer Size: 14613      Transition Number: 999.995 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:34:21,480][train][INFO][train.py>_log] ==> #217000     Total Loss: 3.217    [weighted Loss:3.217    Policy Loss: 6.392    Value Loss: 4.879    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 468943     Buffer Size: 14593      Transition Number: 1000.378k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:37:06,123][train][INFO][train.py>_log] ==> #218000     Total Loss: 3.503    [weighted Loss:3.503    Policy Loss: 6.438    Value Loss: 5.104    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 470738     Buffer Size: 14585      Transition Number: 1000.101k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:39:50,568][train][INFO][train.py>_log] ==> #219000     Total Loss: 2.820    [weighted Loss:2.820    Policy Loss: 7.006    Value Loss: 5.194    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 472604     Buffer Size: 14593      Transition Number: 1000.044k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:42:33,932][train][INFO][train.py>_log] ==> #220000     Total Loss: 2.852    [weighted Loss:2.852    Policy Loss: 6.392    Value Loss: 5.130    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 474515     Buffer Size: 14589      Transition Number: 999.933 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:45:15,939][train][INFO][train.py>_log] ==> #221000     Total Loss: 3.189    [weighted Loss:3.189    Policy Loss: 6.640    Value Loss: 4.833    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 476355     Buffer Size: 14579      Transition Number: 1000.187k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:48:01,296][train][INFO][train.py>_log] ==> #222000     Total Loss: 1.891    [weighted Loss:1.891    Policy Loss: 6.856    Value Loss: 4.946    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 478207     Buffer Size: 14562      Transition Number: 1000.023k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:50:45,752][train][INFO][train.py>_log] ==> #223000     Total Loss: 3.184    [weighted Loss:3.184    Policy Loss: 6.557    Value Loss: 4.992    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 480089     Buffer Size: 14606      Transition Number: 999.992 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:53:29,602][train][INFO][train.py>_log] ==> #224000     Total Loss: 2.227    [weighted Loss:2.227    Policy Loss: 6.717    Value Loss: 5.385    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 481859     Buffer Size: 14658      Transition Number: 1000.188k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:56:12,635][train][INFO][train.py>_log] ==> #225000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 6.544    Value Loss: 5.032    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 483705     Buffer Size: 14635      Transition Number: 1000.021k Batch Size: 256        Lr: 0.01000 
[2022-02-17 02:58:58,072][train][INFO][train.py>_log] ==> #226000     Total Loss: 2.585    [weighted Loss:2.585    Policy Loss: 6.707    Value Loss: 5.235    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 485662     Buffer Size: 14627      Transition Number: 999.988 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:01:39,874][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 6.490    Value Loss: 4.869    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 487383     Buffer Size: 14599      Transition Number: 999.977 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:04:22,215][train][INFO][train.py>_log] ==> #228000     Total Loss: 3.149    [weighted Loss:3.149    Policy Loss: 6.726    Value Loss: 4.939    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 489290     Buffer Size: 14560      Transition Number: 999.959 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:07:08,264][train][INFO][train.py>_log] ==> #229000     Total Loss: 2.500    [weighted Loss:2.500    Policy Loss: 6.518    Value Loss: 5.131    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 491111     Buffer Size: 14577      Transition Number: 1000.348k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:09:50,989][train][INFO][train.py>_log] ==> #230000     Total Loss: 3.116    [weighted Loss:3.116    Policy Loss: 7.170    Value Loss: 4.694    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 492839     Buffer Size: 14579      Transition Number: 1000.289k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:12:33,342][train][INFO][train.py>_log] ==> #231000     Total Loss: 3.993    [weighted Loss:3.993    Policy Loss: 7.204    Value Loss: 5.190    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 494716     Buffer Size: 14590      Transition Number: 999.954 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:15:17,757][train][INFO][train.py>_log] ==> #232000     Total Loss: 3.545    [weighted Loss:3.545    Policy Loss: 7.748    Value Loss: 5.264    Reward Loss: 1.349    Consistency Loss: 0.000    ] Replay Episodes Collected: 496431     Buffer Size: 14608      Transition Number: 999.961 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:18:03,310][train][INFO][train.py>_log] ==> #233000     Total Loss: 3.465    [weighted Loss:3.465    Policy Loss: 7.037    Value Loss: 5.132    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 498450     Buffer Size: 14696      Transition Number: 1000.136k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:20:49,029][train][INFO][train.py>_log] ==> #234000     Total Loss: 2.136    [weighted Loss:2.136    Policy Loss: 7.140    Value Loss: 5.179    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 500236     Buffer Size: 14763      Transition Number: 1000.397k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:23:35,470][train][INFO][train.py>_log] ==> #235000     Total Loss: 1.309    [weighted Loss:1.309    Policy Loss: 7.261    Value Loss: 4.880    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 502108     Buffer Size: 14813      Transition Number: 1000.086k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:26:21,710][train][INFO][train.py>_log] ==> #236000     Total Loss: 2.534    [weighted Loss:2.534    Policy Loss: 6.973    Value Loss: 4.736    Reward Loss: 1.317    Consistency Loss: 0.000    ] Replay Episodes Collected: 504045     Buffer Size: 14880      Transition Number: 1000.066k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:29:07,434][train][INFO][train.py>_log] ==> #237000     Total Loss: 3.664    [weighted Loss:3.664    Policy Loss: 7.358    Value Loss: 5.222    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 505823     Buffer Size: 14917      Transition Number: 1000.038k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:31:54,127][train][INFO][train.py>_log] ==> #238000     Total Loss: 2.999    [weighted Loss:2.999    Policy Loss: 6.531    Value Loss: 4.950    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 507738     Buffer Size: 14957      Transition Number: 1000.312k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:34:38,547][train][INFO][train.py>_log] ==> #239000     Total Loss: 3.319    [weighted Loss:3.319    Policy Loss: 7.344    Value Loss: 5.031    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 509678     Buffer Size: 14961      Transition Number: 999.930 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:37:24,010][train][INFO][train.py>_log] ==> #240000     Total Loss: 3.204    [weighted Loss:3.204    Policy Loss: 7.033    Value Loss: 5.049    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 511532     Buffer Size: 14959      Transition Number: 1000.244k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:40:08,429][train][INFO][train.py>_log] ==> #241000     Total Loss: 3.875    [weighted Loss:3.875    Policy Loss: 7.311    Value Loss: 5.343    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 513471     Buffer Size: 14954      Transition Number: 999.998 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:42:53,318][train][INFO][train.py>_log] ==> #242000     Total Loss: 3.641    [weighted Loss:3.641    Policy Loss: 7.167    Value Loss: 5.317    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 515410     Buffer Size: 14980      Transition Number: 999.976 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:45:40,811][train][INFO][train.py>_log] ==> #243000     Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 7.546    Value Loss: 5.325    Reward Loss: 1.504    Consistency Loss: 0.000    ] Replay Episodes Collected: 517299     Buffer Size: 14999      Transition Number: 999.990 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:48:27,203][train][INFO][train.py>_log] ==> #244000     Total Loss: 3.503    [weighted Loss:3.503    Policy Loss: 7.078    Value Loss: 5.251    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 519129     Buffer Size: 15010      Transition Number: 999.954 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:51:12,262][train][INFO][train.py>_log] ==> #245000     Total Loss: 3.416    [weighted Loss:3.416    Policy Loss: 6.484    Value Loss: 4.931    Reward Loss: 1.351    Consistency Loss: 0.000    ] Replay Episodes Collected: 520983     Buffer Size: 14984      Transition Number: 1000.020k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:53:59,034][train][INFO][train.py>_log] ==> #246000     Total Loss: 2.668    [weighted Loss:2.668    Policy Loss: 6.717    Value Loss: 5.402    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 522858     Buffer Size: 14966      Transition Number: 1000.039k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:56:43,793][train][INFO][train.py>_log] ==> #247000     Total Loss: 2.842    [weighted Loss:2.842    Policy Loss: 6.430    Value Loss: 5.167    Reward Loss: 1.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 524682     Buffer Size: 14904      Transition Number: 1000.089k Batch Size: 256        Lr: 0.01000 
[2022-02-17 03:59:30,777][train][INFO][train.py>_log] ==> #248000     Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 6.962    Value Loss: 5.112    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 526573     Buffer Size: 14857      Transition Number: 1000.118k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:02:18,614][train][INFO][train.py>_log] ==> #249000     Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 7.033    Value Loss: 4.915    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 528490     Buffer Size: 14786      Transition Number: 1000.060k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:05:05,017][train][INFO][train.py>_log] ==> #250000     Total Loss: 3.112    [weighted Loss:3.112    Policy Loss: 7.194    Value Loss: 5.210    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 530318     Buffer Size: 14712      Transition Number: 999.990 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:07:50,041][train][INFO][train.py>_log] ==> #251000     Total Loss: 2.936    [weighted Loss:2.936    Policy Loss: 6.685    Value Loss: 5.007    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 532146     Buffer Size: 14664      Transition Number: 1000.542k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:10:34,524][train][INFO][train.py>_log] ==> #252000     Total Loss: 2.823    [weighted Loss:2.823    Policy Loss: 6.377    Value Loss: 4.878    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 534004     Buffer Size: 14601      Transition Number: 1000.041k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:13:22,262][train][INFO][train.py>_log] ==> #253000     Total Loss: 2.930    [weighted Loss:2.930    Policy Loss: 6.657    Value Loss: 4.881    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 535977     Buffer Size: 14578      Transition Number: 999.964 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:16:09,514][train][INFO][train.py>_log] ==> #254000     Total Loss: 2.083    [weighted Loss:2.083    Policy Loss: 6.462    Value Loss: 4.867    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 537939     Buffer Size: 14581      Transition Number: 999.959 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:18:55,894][train][INFO][train.py>_log] ==> #255000     Total Loss: 2.591    [weighted Loss:2.591    Policy Loss: 6.453    Value Loss: 5.098    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 539820     Buffer Size: 14588      Transition Number: 1000.292k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:21:38,022][train][INFO][train.py>_log] ==> #256000     Total Loss: 2.957    [weighted Loss:2.957    Policy Loss: 6.499    Value Loss: 4.738    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 541611     Buffer Size: 14586      Transition Number: 1000.105k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:24:22,263][train][INFO][train.py>_log] ==> #257000     Total Loss: 3.230    [weighted Loss:3.230    Policy Loss: 6.510    Value Loss: 5.186    Reward Loss: 1.360    Consistency Loss: 0.000    ] Replay Episodes Collected: 543468     Buffer Size: 14573      Transition Number: 1000.046k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:27:08,200][train][INFO][train.py>_log] ==> #258000     Total Loss: 2.998    [weighted Loss:2.998    Policy Loss: 6.191    Value Loss: 4.823    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 545364     Buffer Size: 14579      Transition Number: 1000.365k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:29:54,219][train][INFO][train.py>_log] ==> #259000     Total Loss: 1.977    [weighted Loss:1.977    Policy Loss: 6.189    Value Loss: 5.278    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 547280     Buffer Size: 14583      Transition Number: 1000.113k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:32:38,676][train][INFO][train.py>_log] ==> #260000     Total Loss: 2.267    [weighted Loss:2.267    Policy Loss: 6.249    Value Loss: 5.190    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 549121     Buffer Size: 14559      Transition Number: 999.939 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:35:26,169][train][INFO][train.py>_log] ==> #261000     Total Loss: 3.033    [weighted Loss:3.033    Policy Loss: 6.030    Value Loss: 4.732    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 551023     Buffer Size: 14565      Transition Number: 1000.181k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:38:12,691][train][INFO][train.py>_log] ==> #262000     Total Loss: 2.863    [weighted Loss:2.863    Policy Loss: 5.971    Value Loss: 4.727    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 553031     Buffer Size: 14548      Transition Number: 1000.211k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:40:58,725][train][INFO][train.py>_log] ==> #263000     Total Loss: 2.029    [weighted Loss:2.029    Policy Loss: 6.257    Value Loss: 4.815    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 554854     Buffer Size: 14553      Transition Number: 999.973 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:43:45,139][train][INFO][train.py>_log] ==> #264000     Total Loss: 2.994    [weighted Loss:2.994    Policy Loss: 6.503    Value Loss: 5.171    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 556652     Buffer Size: 14565      Transition Number: 1000.286k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:46:28,896][train][INFO][train.py>_log] ==> #265000     Total Loss: 2.428    [weighted Loss:2.428    Policy Loss: 6.298    Value Loss: 5.401    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 558570     Buffer Size: 14569      Transition Number: 999.987 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:49:14,368][train][INFO][train.py>_log] ==> #266000     Total Loss: 3.349    [weighted Loss:3.349    Policy Loss: 6.312    Value Loss: 4.707    Reward Loss: 1.483    Consistency Loss: 0.000    ] Replay Episodes Collected: 560452     Buffer Size: 14569      Transition Number: 999.943 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:52:01,674][train][INFO][train.py>_log] ==> #267000     Total Loss: 3.355    [weighted Loss:3.355    Policy Loss: 6.320    Value Loss: 4.698    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 562376     Buffer Size: 14615      Transition Number: 1000.071k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:54:46,883][train][INFO][train.py>_log] ==> #268000     Total Loss: 2.685    [weighted Loss:2.685    Policy Loss: 6.464    Value Loss: 4.935    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 564222     Buffer Size: 14657      Transition Number: 999.973 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 04:57:32,200][train][INFO][train.py>_log] ==> #269000     Total Loss: 3.310    [weighted Loss:3.310    Policy Loss: 6.552    Value Loss: 5.228    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 566067     Buffer Size: 14695      Transition Number: 999.971 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:00:18,247][train][INFO][train.py>_log] ==> #270000     Total Loss: 0.950    [weighted Loss:0.950    Policy Loss: 6.192    Value Loss: 4.784    Reward Loss: 1.435    Consistency Loss: 0.000    ] Replay Episodes Collected: 568023     Buffer Size: 14735      Transition Number: 999.998 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:03:03,203][train][INFO][train.py>_log] ==> #271000     Total Loss: 3.466    [weighted Loss:3.466    Policy Loss: 6.354    Value Loss: 4.725    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 569874     Buffer Size: 14772      Transition Number: 1000.445k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:05:48,577][train][INFO][train.py>_log] ==> #272000     Total Loss: 2.525    [weighted Loss:2.525    Policy Loss: 6.322    Value Loss: 4.663    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 571775     Buffer Size: 14778      Transition Number: 999.986 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:08:32,624][train][INFO][train.py>_log] ==> #273000     Total Loss: 3.298    [weighted Loss:3.298    Policy Loss: 6.550    Value Loss: 4.620    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 573607     Buffer Size: 14798      Transition Number: 1000.132k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:11:19,524][train][INFO][train.py>_log] ==> #274000     Total Loss: 3.445    [weighted Loss:3.445    Policy Loss: 6.884    Value Loss: 5.086    Reward Loss: 1.516    Consistency Loss: 0.000    ] Replay Episodes Collected: 575419     Buffer Size: 14805      Transition Number: 999.986 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:14:05,097][train][INFO][train.py>_log] ==> #275000     Total Loss: 2.036    [weighted Loss:2.036    Policy Loss: 6.555    Value Loss: 4.530    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 577403     Buffer Size: 14812      Transition Number: 1000.163k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:16:49,401][train][INFO][train.py>_log] ==> #276000     Total Loss: 3.716    [weighted Loss:3.716    Policy Loss: 6.566    Value Loss: 4.950    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 579320     Buffer Size: 14836      Transition Number: 1000.062k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:19:35,132][train][INFO][train.py>_log] ==> #277000     Total Loss: 1.871    [weighted Loss:1.871    Policy Loss: 6.819    Value Loss: 4.293    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 581216     Buffer Size: 14852      Transition Number: 1000.483k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:22:21,513][train][INFO][train.py>_log] ==> #278000     Total Loss: 3.638    [weighted Loss:3.638    Policy Loss: 6.925    Value Loss: 4.352    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 583171     Buffer Size: 14846      Transition Number: 1000.186k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:25:04,841][train][INFO][train.py>_log] ==> #279000     Total Loss: 2.378    [weighted Loss:2.378    Policy Loss: 7.163    Value Loss: 4.620    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 585038     Buffer Size: 14870      Transition Number: 1000.132k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:27:51,350][train][INFO][train.py>_log] ==> #280000     Total Loss: 3.468    [weighted Loss:3.468    Policy Loss: 7.508    Value Loss: 4.807    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 586998     Buffer Size: 14884      Transition Number: 999.962 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:30:39,593][train][INFO][train.py>_log] ==> #281000     Total Loss: 2.666    [weighted Loss:2.666    Policy Loss: 7.508    Value Loss: 4.729    Reward Loss: 1.452    Consistency Loss: 0.000    ] Replay Episodes Collected: 588881     Buffer Size: 14906      Transition Number: 999.940 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:33:27,514][train][INFO][train.py>_log] ==> #282000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 7.247    Value Loss: 4.700    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 590797     Buffer Size: 14931      Transition Number: 999.990 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:36:16,742][train][INFO][train.py>_log] ==> #283000     Total Loss: 2.810    [weighted Loss:2.810    Policy Loss: 7.528    Value Loss: 5.072    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 592677     Buffer Size: 14943      Transition Number: 999.937 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:39:01,814][train][INFO][train.py>_log] ==> #284000     Total Loss: 3.285    [weighted Loss:3.285    Policy Loss: 7.464    Value Loss: 4.865    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 594706     Buffer Size: 14946      Transition Number: 1000.087k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:41:46,298][train][INFO][train.py>_log] ==> #285000     Total Loss: 3.213    [weighted Loss:3.213    Policy Loss: 7.241    Value Loss: 4.920    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 596560     Buffer Size: 14978      Transition Number: 999.995 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:44:33,000][train][INFO][train.py>_log] ==> #286000     Total Loss: 3.698    [weighted Loss:3.698    Policy Loss: 7.377    Value Loss: 4.730    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 598392     Buffer Size: 14999      Transition Number: 1000.248k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:47:16,401][train][INFO][train.py>_log] ==> #287000     Total Loss: 2.932    [weighted Loss:2.932    Policy Loss: 7.514    Value Loss: 4.745    Reward Loss: 1.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 600284     Buffer Size: 15003      Transition Number: 999.970 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:50:02,858][train][INFO][train.py>_log] ==> #288000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 7.201    Value Loss: 4.951    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 602277     Buffer Size: 15036      Transition Number: 1000.134k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:52:49,014][train][INFO][train.py>_log] ==> #289000     Total Loss: 2.450    [weighted Loss:2.450    Policy Loss: 7.020    Value Loss: 4.808    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 604135     Buffer Size: 15060      Transition Number: 999.979 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:55:35,507][train][INFO][train.py>_log] ==> #290000     Total Loss: 2.221    [weighted Loss:2.221    Policy Loss: 7.245    Value Loss: 4.749    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 605963     Buffer Size: 15072      Transition Number: 999.991 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 05:58:20,334][train][INFO][train.py>_log] ==> #291000     Total Loss: 3.937    [weighted Loss:3.937    Policy Loss: 7.236    Value Loss: 4.722    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 607812     Buffer Size: 15066      Transition Number: 999.979 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:01:07,563][train][INFO][train.py>_log] ==> #292000     Total Loss: 2.936    [weighted Loss:2.936    Policy Loss: 7.412    Value Loss: 4.948    Reward Loss: 1.645    Consistency Loss: 0.000    ] Replay Episodes Collected: 609795     Buffer Size: 15079      Transition Number: 1000.030k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:03:54,147][train][INFO][train.py>_log] ==> #293000     Total Loss: 2.588    [weighted Loss:2.588    Policy Loss: 7.216    Value Loss: 4.857    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 611592     Buffer Size: 15091      Transition Number: 1000.058k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:06:25,395][train][INFO][train.py>_log] ==> #294000     Total Loss: 2.515    [weighted Loss:2.515    Policy Loss: 7.020    Value Loss: 4.593    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 613526     Buffer Size: 15079      Transition Number: 1000.024k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:08:59,535][train][INFO][train.py>_log] ==> #295000     Total Loss: 4.413    [weighted Loss:4.413    Policy Loss: 7.620    Value Loss: 5.042    Reward Loss: 1.523    Consistency Loss: 0.000    ] Replay Episodes Collected: 615428     Buffer Size: 15097      Transition Number: 1000.144k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:11:31,242][train][INFO][train.py>_log] ==> #296000     Total Loss: 3.595    [weighted Loss:3.595    Policy Loss: 7.283    Value Loss: 4.905    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 617368     Buffer Size: 15101      Transition Number: 999.947 k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:14:01,865][train][INFO][train.py>_log] ==> #297000     Total Loss: 3.598    [weighted Loss:3.598    Policy Loss: 7.571    Value Loss: 4.938    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 619140     Buffer Size: 15089      Transition Number: 1000.015k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:16:39,904][train][INFO][train.py>_log] ==> #298000     Total Loss: 3.898    [weighted Loss:3.898    Policy Loss: 7.477    Value Loss: 5.314    Reward Loss: 1.587    Consistency Loss: 0.000    ] Replay Episodes Collected: 621083     Buffer Size: 15074      Transition Number: 1000.044k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:19:26,342][train][INFO][train.py>_log] ==> #299000     Total Loss: 3.753    [weighted Loss:3.753    Policy Loss: 7.622    Value Loss: 5.214    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 622987     Buffer Size: 15077      Transition Number: 1000.100k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:22:14,253][train][INFO][train.py>_log] ==> #300000     Total Loss: 2.237    [weighted Loss:2.237    Policy Loss: 7.756    Value Loss: 4.975    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 624877     Buffer Size: 15079      Transition Number: 1000.341k Batch Size: 256        Lr: 0.01000 
[2022-02-17 06:25:04,917][train][INFO][train.py>_log] ==> #301000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 6.677    Value Loss: 4.973    Reward Loss: 1.509    Consistency Loss: 0.000    ] Replay Episodes Collected: 626761     Buffer Size: 15069      Transition Number: 1000.318k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:27:49,991][train][INFO][train.py>_log] ==> #302000     Total Loss: 2.714    [weighted Loss:2.714    Policy Loss: 6.561    Value Loss: 5.052    Reward Loss: 1.562    Consistency Loss: 0.000    ] Replay Episodes Collected: 628676     Buffer Size: 15087      Transition Number: 1000.035k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:30:35,448][train][INFO][train.py>_log] ==> #303000     Total Loss: 3.781    [weighted Loss:3.781    Policy Loss: 6.963    Value Loss: 4.844    Reward Loss: 1.588    Consistency Loss: 0.000    ] Replay Episodes Collected: 630569     Buffer Size: 15067      Transition Number: 999.989 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:33:23,473][train][INFO][train.py>_log] ==> #304000     Total Loss: 3.203    [weighted Loss:3.203    Policy Loss: 6.718    Value Loss: 4.729    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 632446     Buffer Size: 15047      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:36:10,696][train][INFO][train.py>_log] ==> #305000     Total Loss: 1.961    [weighted Loss:1.961    Policy Loss: 6.648    Value Loss: 4.795    Reward Loss: 1.411    Consistency Loss: 0.000    ] Replay Episodes Collected: 634343     Buffer Size: 15024      Transition Number: 1000.076k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:38:56,214][train][INFO][train.py>_log] ==> #306000     Total Loss: 2.603    [weighted Loss:2.603    Policy Loss: 6.625    Value Loss: 4.899    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 636301     Buffer Size: 15006      Transition Number: 999.946 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:41:42,837][train][INFO][train.py>_log] ==> #307000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 6.691    Value Loss: 4.839    Reward Loss: 1.536    Consistency Loss: 0.000    ] Replay Episodes Collected: 638180     Buffer Size: 14981      Transition Number: 1000.489k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:44:29,584][train][INFO][train.py>_log] ==> #308000     Total Loss: 2.179    [weighted Loss:2.179    Policy Loss: 6.596    Value Loss: 4.822    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 640022     Buffer Size: 14936      Transition Number: 999.973 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:47:18,330][train][INFO][train.py>_log] ==> #309000     Total Loss: 3.266    [weighted Loss:3.266    Policy Loss: 6.594    Value Loss: 4.881    Reward Loss: 1.486    Consistency Loss: 0.000    ] Replay Episodes Collected: 641951     Buffer Size: 14889      Transition Number: 1000.065k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:50:02,954][train][INFO][train.py>_log] ==> #310000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 7.047    Value Loss: 4.833    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 643802     Buffer Size: 14840      Transition Number: 1000.258k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:52:49,573][train][INFO][train.py>_log] ==> #311000     Total Loss: 2.220    [weighted Loss:2.220    Policy Loss: 6.825    Value Loss: 5.024    Reward Loss: 1.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 645747     Buffer Size: 14810      Transition Number: 1000.014k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:55:39,064][train][INFO][train.py>_log] ==> #312000     Total Loss: 2.052    [weighted Loss:2.052    Policy Loss: 6.846    Value Loss: 4.893    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 647630     Buffer Size: 14795      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00100 
[2022-02-17 06:58:28,549][train][INFO][train.py>_log] ==> #313000     Total Loss: 2.933    [weighted Loss:2.933    Policy Loss: 6.629    Value Loss: 5.007    Reward Loss: 1.552    Consistency Loss: 0.000    ] Replay Episodes Collected: 649563     Buffer Size: 14782      Transition Number: 1000.225k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:01:14,145][train][INFO][train.py>_log] ==> #314000     Total Loss: 2.183    [weighted Loss:2.183    Policy Loss: 7.047    Value Loss: 4.967    Reward Loss: 1.457    Consistency Loss: 0.000    ] Replay Episodes Collected: 651457     Buffer Size: 14774      Transition Number: 1000.036k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:03:59,227][train][INFO][train.py>_log] ==> #315000     Total Loss: 2.665    [weighted Loss:2.665    Policy Loss: 6.749    Value Loss: 4.799    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 653313     Buffer Size: 14778      Transition Number: 999.935 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:06:46,975][train][INFO][train.py>_log] ==> #316000     Total Loss: 3.201    [weighted Loss:3.201    Policy Loss: 6.774    Value Loss: 5.087    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 655279     Buffer Size: 14779      Transition Number: 1000.007k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:09:34,712][train][INFO][train.py>_log] ==> #317000     Total Loss: 2.310    [weighted Loss:2.310    Policy Loss: 6.462    Value Loss: 4.726    Reward Loss: 1.517    Consistency Loss: 0.000    ] Replay Episodes Collected: 657160     Buffer Size: 14785      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:12:24,774][train][INFO][train.py>_log] ==> #318000     Total Loss: 2.156    [weighted Loss:2.156    Policy Loss: 6.476    Value Loss: 5.034    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 659085     Buffer Size: 14790      Transition Number: 1000.512k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:15:11,811][train][INFO][train.py>_log] ==> #319000     Total Loss: 3.110    [weighted Loss:3.110    Policy Loss: 6.674    Value Loss: 4.870    Reward Loss: 1.469    Consistency Loss: 0.000    ] Replay Episodes Collected: 661033     Buffer Size: 14794      Transition Number: 1000.028k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:17:56,700][train][INFO][train.py>_log] ==> #320000     Total Loss: 3.365    [weighted Loss:3.365    Policy Loss: 6.450    Value Loss: 5.172    Reward Loss: 1.477    Consistency Loss: 0.000    ] Replay Episodes Collected: 662886     Buffer Size: 14799      Transition Number: 1000.121k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:20:41,959][train][INFO][train.py>_log] ==> #321000     Total Loss: 2.758    [weighted Loss:2.758    Policy Loss: 6.590    Value Loss: 4.951    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 664820     Buffer Size: 14806      Transition Number: 1000.266k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:23:29,268][train][INFO][train.py>_log] ==> #322000     Total Loss: 2.238    [weighted Loss:2.238    Policy Loss: 6.444    Value Loss: 4.720    Reward Loss: 1.535    Consistency Loss: 0.000    ] Replay Episodes Collected: 666679     Buffer Size: 14815      Transition Number: 1000.111k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:26:15,041][train][INFO][train.py>_log] ==> #323000     Total Loss: 1.591    [weighted Loss:1.591    Policy Loss: 6.889    Value Loss: 4.773    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 668672     Buffer Size: 14826      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:29:03,180][train][INFO][train.py>_log] ==> #324000     Total Loss: 2.779    [weighted Loss:2.779    Policy Loss: 6.583    Value Loss: 4.843    Reward Loss: 1.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 670593     Buffer Size: 14817      Transition Number: 999.932 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:31:49,753][train][INFO][train.py>_log] ==> #325000     Total Loss: 2.390    [weighted Loss:2.390    Policy Loss: 6.693    Value Loss: 4.763    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 672501     Buffer Size: 14839      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:34:35,613][train][INFO][train.py>_log] ==> #326000     Total Loss: 3.339    [weighted Loss:3.339    Policy Loss: 6.634    Value Loss: 4.455    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 674389     Buffer Size: 14854      Transition Number: 999.952 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:37:22,468][train][INFO][train.py>_log] ==> #327000     Total Loss: 2.638    [weighted Loss:2.638    Policy Loss: 6.259    Value Loss: 4.859    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 676341     Buffer Size: 14873      Transition Number: 1000.132k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:40:10,462][train][INFO][train.py>_log] ==> #328000     Total Loss: 2.374    [weighted Loss:2.374    Policy Loss: 6.432    Value Loss: 4.725    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 678266     Buffer Size: 14885      Transition Number: 1000.449k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:42:58,307][train][INFO][train.py>_log] ==> #329000     Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 6.371    Value Loss: 4.973    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 680181     Buffer Size: 14890      Transition Number: 1000.198k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:45:46,523][train][INFO][train.py>_log] ==> #330000     Total Loss: 1.603    [weighted Loss:1.603    Policy Loss: 7.016    Value Loss: 5.126    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 682118     Buffer Size: 14878      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:48:34,312][train][INFO][train.py>_log] ==> #331000     Total Loss: 1.932    [weighted Loss:1.932    Policy Loss: 6.422    Value Loss: 4.912    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 684024     Buffer Size: 14883      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:51:22,851][train][INFO][train.py>_log] ==> #332000     Total Loss: 2.587    [weighted Loss:2.587    Policy Loss: 6.495    Value Loss: 4.691    Reward Loss: 1.578    Consistency Loss: 0.000    ] Replay Episodes Collected: 685979     Buffer Size: 14887      Transition Number: 1000.446k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:54:08,638][train][INFO][train.py>_log] ==> #333000     Total Loss: 3.087    [weighted Loss:3.087    Policy Loss: 6.613    Value Loss: 4.699    Reward Loss: 1.684    Consistency Loss: 0.000    ] Replay Episodes Collected: 687853     Buffer Size: 14861      Transition Number: 1000.118k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:56:55,498][train][INFO][train.py>_log] ==> #334000     Total Loss: 2.327    [weighted Loss:2.327    Policy Loss: 6.570    Value Loss: 4.880    Reward Loss: 1.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 689807     Buffer Size: 14837      Transition Number: 1000.026k Batch Size: 256        Lr: 0.00100 
[2022-02-17 07:59:42,771][train][INFO][train.py>_log] ==> #335000     Total Loss: 3.364    [weighted Loss:3.364    Policy Loss: 6.435    Value Loss: 4.664    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 691773     Buffer Size: 14809      Transition Number: 1000.283k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:02:29,978][train][INFO][train.py>_log] ==> #336000     Total Loss: 2.295    [weighted Loss:2.295    Policy Loss: 6.487    Value Loss: 4.856    Reward Loss: 1.527    Consistency Loss: 0.000    ] Replay Episodes Collected: 693672     Buffer Size: 14800      Transition Number: 1000.020k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:05:18,385][train][INFO][train.py>_log] ==> #337000     Total Loss: 2.357    [weighted Loss:2.357    Policy Loss: 6.327    Value Loss: 4.545    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 695587     Buffer Size: 14780      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:08:04,669][train][INFO][train.py>_log] ==> #338000     Total Loss: 2.996    [weighted Loss:2.996    Policy Loss: 6.634    Value Loss: 5.120    Reward Loss: 1.522    Consistency Loss: 0.000    ] Replay Episodes Collected: 697579     Buffer Size: 14775      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:10:49,737][train][INFO][train.py>_log] ==> #339000     Total Loss: 2.967    [weighted Loss:2.967    Policy Loss: 6.528    Value Loss: 4.801    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 699447     Buffer Size: 14743      Transition Number: 1000.134k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:13:39,035][train][INFO][train.py>_log] ==> #340000     Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 6.227    Value Loss: 4.783    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 701413     Buffer Size: 14732      Transition Number: 1000.346k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:16:27,233][train][INFO][train.py>_log] ==> #341000     Total Loss: 2.815    [weighted Loss:2.815    Policy Loss: 6.192    Value Loss: 4.976    Reward Loss: 1.430    Consistency Loss: 0.000    ] Replay Episodes Collected: 703356     Buffer Size: 14726      Transition Number: 1000.056k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:19:14,081][train][INFO][train.py>_log] ==> #342000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 6.285    Value Loss: 4.684    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 705255     Buffer Size: 14703      Transition Number: 1000.079k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:22:01,160][train][INFO][train.py>_log] ==> #343000     Total Loss: 2.528    [weighted Loss:2.528    Policy Loss: 6.379    Value Loss: 4.638    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 707179     Buffer Size: 14692      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:24:49,044][train][INFO][train.py>_log] ==> #344000     Total Loss: 3.501    [weighted Loss:3.501    Policy Loss: 6.425    Value Loss: 4.539    Reward Loss: 1.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 709175     Buffer Size: 14677      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:27:36,813][train][INFO][train.py>_log] ==> #345000     Total Loss: 2.946    [weighted Loss:2.946    Policy Loss: 6.223    Value Loss: 4.790    Reward Loss: 1.437    Consistency Loss: 0.000    ] Replay Episodes Collected: 711166     Buffer Size: 14665      Transition Number: 999.945 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:30:24,256][train][INFO][train.py>_log] ==> #346000     Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 6.198    Value Loss: 4.526    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 712962     Buffer Size: 14668      Transition Number: 1000.620k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:33:10,935][train][INFO][train.py>_log] ==> #347000     Total Loss: 3.717    [weighted Loss:3.717    Policy Loss: 6.349    Value Loss: 4.783    Reward Loss: 1.337    Consistency Loss: 0.000    ] Replay Episodes Collected: 714853     Buffer Size: 14644      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:35:56,294][train][INFO][train.py>_log] ==> #348000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 6.391    Value Loss: 5.011    Reward Loss: 1.449    Consistency Loss: 0.000    ] Replay Episodes Collected: 716833     Buffer Size: 14631      Transition Number: 999.956 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:38:44,364][train][INFO][train.py>_log] ==> #349000     Total Loss: 3.018    [weighted Loss:3.018    Policy Loss: 6.510    Value Loss: 4.874    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 718836     Buffer Size: 14615      Transition Number: 999.948 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:41:30,601][train][INFO][train.py>_log] ==> #350000     Total Loss: 2.934    [weighted Loss:2.934    Policy Loss: 6.340    Value Loss: 4.744    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 720717     Buffer Size: 14621      Transition Number: 1000.092k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:44:18,947][train][INFO][train.py>_log] ==> #351000     Total Loss: 3.385    [weighted Loss:3.385    Policy Loss: 6.312    Value Loss: 4.388    Reward Loss: 1.363    Consistency Loss: 0.000    ] Replay Episodes Collected: 722555     Buffer Size: 14634      Transition Number: 1000.429k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:47:09,256][train][INFO][train.py>_log] ==> #352000     Total Loss: 1.642    [weighted Loss:1.642    Policy Loss: 6.368    Value Loss: 4.673    Reward Loss: 1.341    Consistency Loss: 0.000    ] Replay Episodes Collected: 724543     Buffer Size: 14625      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:49:58,144][train][INFO][train.py>_log] ==> #353000     Total Loss: 2.970    [weighted Loss:2.970    Policy Loss: 6.402    Value Loss: 4.410    Reward Loss: 1.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 726546     Buffer Size: 14620      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:52:44,239][train][INFO][train.py>_log] ==> #354000     Total Loss: 1.918    [weighted Loss:1.918    Policy Loss: 6.508    Value Loss: 5.155    Reward Loss: 1.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 728501     Buffer Size: 14622      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:55:31,319][train][INFO][train.py>_log] ==> #355000     Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 6.250    Value Loss: 4.654    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 730409     Buffer Size: 14645      Transition Number: 1000.090k Batch Size: 256        Lr: 0.00100 
[2022-02-17 08:58:19,919][train][INFO][train.py>_log] ==> #356000     Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 6.561    Value Loss: 4.791    Reward Loss: 1.454    Consistency Loss: 0.000    ] Replay Episodes Collected: 732296     Buffer Size: 14644      Transition Number: 1000.015k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:01:06,915][train][INFO][train.py>_log] ==> #357000     Total Loss: 2.990    [weighted Loss:2.990    Policy Loss: 6.592    Value Loss: 4.978    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 734284     Buffer Size: 14632      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:03:57,136][train][INFO][train.py>_log] ==> #358000     Total Loss: 1.696    [weighted Loss:1.696    Policy Loss: 6.057    Value Loss: 4.736    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 736278     Buffer Size: 14632      Transition Number: 1000.097k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:06:43,518][train][INFO][train.py>_log] ==> #359000     Total Loss: 2.693    [weighted Loss:2.693    Policy Loss: 6.526    Value Loss: 4.981    Reward Loss: 1.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 738196     Buffer Size: 14630      Transition Number: 1000.313k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:09:30,210][train][INFO][train.py>_log] ==> #360000     Total Loss: 2.567    [weighted Loss:2.567    Policy Loss: 6.217    Value Loss: 4.776    Reward Loss: 1.466    Consistency Loss: 0.000    ] Replay Episodes Collected: 740137     Buffer Size: 14634      Transition Number: 1000.322k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:12:17,562][train][INFO][train.py>_log] ==> #361000     Total Loss: 3.379    [weighted Loss:3.379    Policy Loss: 6.214    Value Loss: 4.936    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 742062     Buffer Size: 14635      Transition Number: 1000.369k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:15:05,976][train][INFO][train.py>_log] ==> #362000     Total Loss: 3.135    [weighted Loss:3.135    Policy Loss: 6.138    Value Loss: 4.574    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 744039     Buffer Size: 14614      Transition Number: 1000.034k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:17:51,410][train][INFO][train.py>_log] ==> #363000     Total Loss: 3.384    [weighted Loss:3.384    Policy Loss: 6.547    Value Loss: 4.693    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 745924     Buffer Size: 14615      Transition Number: 999.968 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:20:39,072][train][INFO][train.py>_log] ==> #364000     Total Loss: 3.046    [weighted Loss:3.046    Policy Loss: 6.504    Value Loss: 5.099    Reward Loss: 1.426    Consistency Loss: 0.000    ] Replay Episodes Collected: 747850     Buffer Size: 14644      Transition Number: 1000.252k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:23:27,408][train][INFO][train.py>_log] ==> #365000     Total Loss: 3.302    [weighted Loss:3.302    Policy Loss: 6.540    Value Loss: 4.681    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 749827     Buffer Size: 14641      Transition Number: 999.953 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:26:15,706][train][INFO][train.py>_log] ==> #366000     Total Loss: 1.809    [weighted Loss:1.809    Policy Loss: 6.816    Value Loss: 4.590    Reward Loss: 1.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 751830     Buffer Size: 14656      Transition Number: 999.977 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:29:07,608][train][INFO][train.py>_log] ==> #367000     Total Loss: 2.408    [weighted Loss:2.408    Policy Loss: 6.471    Value Loss: 4.716    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 753848     Buffer Size: 14673      Transition Number: 1000.311k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:31:56,998][train][INFO][train.py>_log] ==> #368000     Total Loss: 2.907    [weighted Loss:2.907    Policy Loss: 6.761    Value Loss: 4.483    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 755851     Buffer Size: 14675      Transition Number: 999.944 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:34:43,950][train][INFO][train.py>_log] ==> #369000     Total Loss: 3.109    [weighted Loss:3.109    Policy Loss: 6.644    Value Loss: 4.469    Reward Loss: 1.295    Consistency Loss: 0.000    ] Replay Episodes Collected: 757818     Buffer Size: 14706      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:37:33,451][train][INFO][train.py>_log] ==> #370000     Total Loss: 2.572    [weighted Loss:2.572    Policy Loss: 6.564    Value Loss: 4.831    Reward Loss: 1.392    Consistency Loss: 0.000    ] Replay Episodes Collected: 759781     Buffer Size: 14741      Transition Number: 1000.254k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:40:22,074][train][INFO][train.py>_log] ==> #371000     Total Loss: 2.343    [weighted Loss:2.343    Policy Loss: 6.684    Value Loss: 4.160    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 761784     Buffer Size: 14751      Transition Number: 1000.539k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:43:09,193][train][INFO][train.py>_log] ==> #372000     Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 6.795    Value Loss: 4.480    Reward Loss: 1.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 763745     Buffer Size: 14756      Transition Number: 999.940 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:45:58,390][train][INFO][train.py>_log] ==> #373000     Total Loss: 3.609    [weighted Loss:3.609    Policy Loss: 6.509    Value Loss: 4.505    Reward Loss: 1.361    Consistency Loss: 0.000    ] Replay Episodes Collected: 765810     Buffer Size: 14773      Transition Number: 999.996 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:48:45,591][train][INFO][train.py>_log] ==> #374000     Total Loss: 2.776    [weighted Loss:2.776    Policy Loss: 6.779    Value Loss: 4.471    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 767841     Buffer Size: 14773      Transition Number: 1000.033k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:51:33,386][train][INFO][train.py>_log] ==> #375000     Total Loss: 3.009    [weighted Loss:3.009    Policy Loss: 6.655    Value Loss: 4.446    Reward Loss: 1.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 769804     Buffer Size: 14791      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:54:23,944][train][INFO][train.py>_log] ==> #376000     Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 6.758    Value Loss: 4.518    Reward Loss: 1.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 771739     Buffer Size: 14806      Transition Number: 999.992 k Batch Size: 256        Lr: 0.00100 
[2022-02-17 09:57:12,347][train][INFO][train.py>_log] ==> #377000     Total Loss: 3.003    [weighted Loss:3.003    Policy Loss: 6.737    Value Loss: 4.626    Reward Loss: 1.532    Consistency Loss: 0.000    ] Replay Episodes Collected: 773750     Buffer Size: 14830      Transition Number: 1000.022k Batch Size: 256        Lr: 0.00100 
