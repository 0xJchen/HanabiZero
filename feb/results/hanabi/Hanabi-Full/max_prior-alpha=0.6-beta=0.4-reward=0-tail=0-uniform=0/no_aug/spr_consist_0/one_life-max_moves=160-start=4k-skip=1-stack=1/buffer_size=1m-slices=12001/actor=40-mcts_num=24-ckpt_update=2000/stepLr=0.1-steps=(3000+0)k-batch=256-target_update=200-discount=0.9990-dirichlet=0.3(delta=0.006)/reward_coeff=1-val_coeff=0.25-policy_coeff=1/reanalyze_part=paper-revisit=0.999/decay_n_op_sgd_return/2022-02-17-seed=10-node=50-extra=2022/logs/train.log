[2022-02-17 16:38:48,809][train][INFO][train.py>_log] ==> #0          Total Loss: 47.742   [weighted Loss:47.742   Policy Loss: 13.271   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 955        Buffer Size: 955        Transition Number: 9.025   k Batch Size: 256        Lr: 0.00000 
[2022-02-17 16:41:29,911][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.484    [weighted Loss:5.484    Policy Loss: 14.292   Value Loss: 4.722    Reward Loss: 1.487    Consistency Loss: 0.000    ] Replay Episodes Collected: 11404      Buffer Size: 11404      Transition Number: 140.651 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 16:44:10,537][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.155    [weighted Loss:5.155    Policy Loss: 13.131   Value Loss: 4.134    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 21403      Buffer Size: 21403      Transition Number: 265.890 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 16:46:51,893][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.689    [weighted Loss:5.689    Policy Loss: 11.894   Value Loss: 4.494    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 31010      Buffer Size: 31010      Transition Number: 385.607 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 16:49:36,104][train][INFO][train.py>_log] ==> #4000       Total Loss: 4.996    [weighted Loss:4.996    Policy Loss: 12.091   Value Loss: 4.358    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 40914      Buffer Size: 40914      Transition Number: 511.389 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 16:52:17,659][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.591    [weighted Loss:4.591    Policy Loss: 9.567    Value Loss: 4.341    Reward Loss: 1.225    Consistency Loss: 0.000    ] Replay Episodes Collected: 47351      Buffer Size: 47351      Transition Number: 633.586 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 16:54:56,418][train][INFO][train.py>_log] ==> #6000       Total Loss: 3.963    [weighted Loss:3.963    Policy Loss: 9.265    Value Loss: 4.290    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 53398      Buffer Size: 53398      Transition Number: 747.284 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 16:57:40,795][train][INFO][train.py>_log] ==> #7000       Total Loss: 4.160    [weighted Loss:4.160    Policy Loss: 8.898    Value Loss: 4.474    Reward Loss: 1.068    Consistency Loss: 0.000    ] Replay Episodes Collected: 57568      Buffer Size: 57568      Transition Number: 856.541 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:00:20,876][train][INFO][train.py>_log] ==> #8000       Total Loss: 4.938    [weighted Loss:4.938    Policy Loss: 8.258    Value Loss: 4.273    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 61765      Buffer Size: 61765      Transition Number: 971.445 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:03:00,402][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.688    [weighted Loss:2.688    Policy Loss: 6.466    Value Loss: 4.227    Reward Loss: 0.960    Consistency Loss: 0.000    ] Replay Episodes Collected: 67056      Buffer Size: 59590      Transition Number: 1000.033k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:05:42,111][train][INFO][train.py>_log] ==> #10000      Total Loss: 2.684    [weighted Loss:2.684    Policy Loss: 5.401    Value Loss: 4.365    Reward Loss: 1.122    Consistency Loss: 0.000    ] Replay Episodes Collected: 72508      Buffer Size: 55791      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:08:25,093][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 5.732    Value Loss: 4.438    Reward Loss: 1.019    Consistency Loss: 0.000    ] Replay Episodes Collected: 75938      Buffer Size: 50801      Transition Number: 1000.008k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:11:05,308][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 4.882    Value Loss: 4.226    Reward Loss: 1.029    Consistency Loss: 0.000    ] Replay Episodes Collected: 79385      Buffer Size: 45560      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:13:48,501][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.171    [weighted Loss:2.171    Policy Loss: 4.213    Value Loss: 4.727    Reward Loss: 1.008    Consistency Loss: 0.000    ] Replay Episodes Collected: 82074      Buffer Size: 39877      Transition Number: 1000.079k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:16:28,947][train][INFO][train.py>_log] ==> #14000      Total Loss: 1.913    [weighted Loss:1.913    Policy Loss: 3.111    Value Loss: 4.546    Reward Loss: 0.961    Consistency Loss: 0.000    ] Replay Episodes Collected: 84740      Buffer Size: 36907      Transition Number: 1000.065k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:19:09,564][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.792    [weighted Loss:1.792    Policy Loss: 2.987    Value Loss: 4.416    Reward Loss: 0.926    Consistency Loss: 0.000    ] Replay Episodes Collected: 86688      Buffer Size: 33508      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:21:51,573][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.454    [weighted Loss:1.454    Policy Loss: 2.680    Value Loss: 4.282    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 88688      Buffer Size: 31315      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:24:33,088][train][INFO][train.py>_log] ==> #17000      Total Loss: 1.383    [weighted Loss:1.383    Policy Loss: 2.730    Value Loss: 4.406    Reward Loss: 0.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 90458      Buffer Size: 29248      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:27:17,868][train][INFO][train.py>_log] ==> #18000      Total Loss: 0.738    [weighted Loss:0.738    Policy Loss: 2.915    Value Loss: 4.412    Reward Loss: 0.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 92402      Buffer Size: 26101      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:30:02,257][train][INFO][train.py>_log] ==> #19000      Total Loss: 1.149    [weighted Loss:1.149    Policy Loss: 2.659    Value Loss: 4.049    Reward Loss: 0.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 94231      Buffer Size: 22289      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:32:46,109][train][INFO][train.py>_log] ==> #20000      Total Loss: 1.334    [weighted Loss:1.334    Policy Loss: 3.003    Value Loss: 4.066    Reward Loss: 0.701    Consistency Loss: 0.000    ] Replay Episodes Collected: 95978      Buffer Size: 20305      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:35:29,283][train][INFO][train.py>_log] ==> #21000      Total Loss: 1.690    [weighted Loss:1.690    Policy Loss: 3.149    Value Loss: 4.213    Reward Loss: 0.737    Consistency Loss: 0.000    ] Replay Episodes Collected: 97877      Buffer Size: 18593      Transition Number: 1000.311k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:38:14,330][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.743    [weighted Loss:1.743    Policy Loss: 3.067    Value Loss: 4.080    Reward Loss: 0.713    Consistency Loss: 0.000    ] Replay Episodes Collected: 99689      Buffer Size: 17598      Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:40:54,413][train][INFO][train.py>_log] ==> #23000      Total Loss: 1.594    [weighted Loss:1.594    Policy Loss: 3.192    Value Loss: 4.217    Reward Loss: 0.603    Consistency Loss: 0.000    ] Replay Episodes Collected: 101649     Buffer Size: 16812      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:43:33,978][train][INFO][train.py>_log] ==> #24000      Total Loss: 1.420    [weighted Loss:1.420    Policy Loss: 3.748    Value Loss: 3.916    Reward Loss: 0.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 103618     Buffer Size: 16649      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:46:17,797][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.181    [weighted Loss:1.181    Policy Loss: 3.225    Value Loss: 4.288    Reward Loss: 0.663    Consistency Loss: 0.000    ] Replay Episodes Collected: 105478     Buffer Size: 16569      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:48:59,835][train][INFO][train.py>_log] ==> #26000      Total Loss: 1.885    [weighted Loss:1.885    Policy Loss: 3.853    Value Loss: 4.315    Reward Loss: 0.686    Consistency Loss: 0.000    ] Replay Episodes Collected: 107420     Buffer Size: 16660      Transition Number: 1000.135k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:51:38,028][train][INFO][train.py>_log] ==> #27000      Total Loss: 2.135    [weighted Loss:2.135    Policy Loss: 4.282    Value Loss: 4.334    Reward Loss: 0.665    Consistency Loss: 0.000    ] Replay Episodes Collected: 109371     Buffer Size: 16765      Transition Number: 1000.212k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:54:20,508][train][INFO][train.py>_log] ==> #28000      Total Loss: 2.056    [weighted Loss:2.056    Policy Loss: 4.021    Value Loss: 4.628    Reward Loss: 0.662    Consistency Loss: 0.000    ] Replay Episodes Collected: 111302     Buffer Size: 16955      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:57:00,586][train][INFO][train.py>_log] ==> #29000      Total Loss: 1.662    [weighted Loss:1.662    Policy Loss: 3.807    Value Loss: 4.638    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 113237     Buffer Size: 17210      Transition Number: 1000.352k Batch Size: 256        Lr: 0.10000 
[2022-02-17 17:59:40,138][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 3.622    Value Loss: 4.719    Reward Loss: 0.732    Consistency Loss: 0.000    ] Replay Episodes Collected: 115242     Buffer Size: 17402      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:02:21,593][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.073    [weighted Loss:2.073    Policy Loss: 3.904    Value Loss: 4.659    Reward Loss: 0.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 117266     Buffer Size: 17676      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:05:07,175][train][INFO][train.py>_log] ==> #32000      Total Loss: 1.994    [weighted Loss:1.994    Policy Loss: 4.043    Value Loss: 5.064    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 119375     Buffer Size: 17820      Transition Number: 1000.004k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:07:49,673][train][INFO][train.py>_log] ==> #33000      Total Loss: 2.027    [weighted Loss:2.027    Policy Loss: 3.693    Value Loss: 4.970    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 121210     Buffer Size: 17698      Transition Number: 999.974 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:10:33,799][train][INFO][train.py>_log] ==> #34000      Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 3.802    Value Loss: 4.819    Reward Loss: 0.868    Consistency Loss: 0.000    ] Replay Episodes Collected: 123029     Buffer Size: 17557      Transition Number: 1000.174k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:13:15,040][train][INFO][train.py>_log] ==> #35000      Total Loss: 2.290    [weighted Loss:2.290    Policy Loss: 3.766    Value Loss: 4.833    Reward Loss: 0.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 124793     Buffer Size: 17354      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:15:56,212][train][INFO][train.py>_log] ==> #36000      Total Loss: 2.303    [weighted Loss:2.303    Policy Loss: 4.058    Value Loss: 5.041    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 126529     Buffer Size: 17174      Transition Number: 1000.345k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:18:41,728][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 3.644    Value Loss: 5.072    Reward Loss: 0.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 128379     Buffer Size: 16958      Transition Number: 1000.032k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:21:23,109][train][INFO][train.py>_log] ==> #38000      Total Loss: 2.033    [weighted Loss:2.033    Policy Loss: 4.042    Value Loss: 5.578    Reward Loss: 0.828    Consistency Loss: 0.000    ] Replay Episodes Collected: 130230     Buffer Size: 16656      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:24:04,982][train][INFO][train.py>_log] ==> #39000      Total Loss: 1.307    [weighted Loss:1.307    Policy Loss: 3.776    Value Loss: 5.032    Reward Loss: 0.745    Consistency Loss: 0.000    ] Replay Episodes Collected: 131870     Buffer Size: 16342      Transition Number: 999.957 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:26:46,485][train][INFO][train.py>_log] ==> #40000      Total Loss: 2.146    [weighted Loss:2.146    Policy Loss: 3.704    Value Loss: 5.417    Reward Loss: 0.905    Consistency Loss: 0.000    ] Replay Episodes Collected: 133689     Buffer Size: 15893      Transition Number: 999.952 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:29:31,295][train][INFO][train.py>_log] ==> #41000      Total Loss: 1.812    [weighted Loss:1.812    Policy Loss: 4.029    Value Loss: 5.300    Reward Loss: 1.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 135306     Buffer Size: 15517      Transition Number: 1000.119k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:32:12,743][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.252    [weighted Loss:2.252    Policy Loss: 3.909    Value Loss: 4.789    Reward Loss: 0.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 137153     Buffer Size: 15254      Transition Number: 1000.078k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:34:56,684][train][INFO][train.py>_log] ==> #43000      Total Loss: 1.045    [weighted Loss:1.045    Policy Loss: 4.198    Value Loss: 4.899    Reward Loss: 0.896    Consistency Loss: 0.000    ] Replay Episodes Collected: 138787     Buffer Size: 15077      Transition Number: 1000.202k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:37:39,665][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.367    [weighted Loss:2.367    Policy Loss: 5.259    Value Loss: 4.901    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 140467     Buffer Size: 14903      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:40:22,433][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.717    [weighted Loss:2.717    Policy Loss: 5.461    Value Loss: 4.723    Reward Loss: 0.809    Consistency Loss: 0.000    ] Replay Episodes Collected: 142281     Buffer Size: 14682      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:43:07,249][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.300    [weighted Loss:2.300    Policy Loss: 5.452    Value Loss: 4.859    Reward Loss: 0.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 144019     Buffer Size: 14499      Transition Number: 1000.211k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:45:49,086][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 5.623    Value Loss: 4.948    Reward Loss: 0.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 145756     Buffer Size: 14327      Transition Number: 1000.058k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:48:29,438][train][INFO][train.py>_log] ==> #48000      Total Loss: 2.658    [weighted Loss:2.658    Policy Loss: 6.195    Value Loss: 4.586    Reward Loss: 0.843    Consistency Loss: 0.000    ] Replay Episodes Collected: 147420     Buffer Size: 14203      Transition Number: 999.972 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:51:13,780][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.506    [weighted Loss:2.506    Policy Loss: 5.946    Value Loss: 4.608    Reward Loss: 0.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 149195     Buffer Size: 14121      Transition Number: 1000.197k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:53:56,849][train][INFO][train.py>_log] ==> #50000      Total Loss: 3.106    [weighted Loss:3.106    Policy Loss: 6.058    Value Loss: 4.514    Reward Loss: 0.890    Consistency Loss: 0.000    ] Replay Episodes Collected: 150936     Buffer Size: 14064      Transition Number: 1000.160k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:56:39,151][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.217    [weighted Loss:3.217    Policy Loss: 5.705    Value Loss: 4.565    Reward Loss: 0.793    Consistency Loss: 0.000    ] Replay Episodes Collected: 152642     Buffer Size: 14025      Transition Number: 999.962 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 18:59:22,647][train][INFO][train.py>_log] ==> #52000      Total Loss: 2.899    [weighted Loss:2.899    Policy Loss: 6.961    Value Loss: 4.513    Reward Loss: 0.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 154445     Buffer Size: 14013      Transition Number: 1000.196k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:02:08,018][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.461    [weighted Loss:3.461    Policy Loss: 6.605    Value Loss: 4.410    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 156202     Buffer Size: 13987      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:04:50,954][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.481    [weighted Loss:3.481    Policy Loss: 7.223    Value Loss: 4.573    Reward Loss: 0.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 158141     Buffer Size: 13940      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:07:38,198][train][INFO][train.py>_log] ==> #55000      Total Loss: 3.123    [weighted Loss:3.123    Policy Loss: 5.808    Value Loss: 4.398    Reward Loss: 0.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 160169     Buffer Size: 14124      Transition Number: 1000.414k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:10:19,808][train][INFO][train.py>_log] ==> #56000      Total Loss: 2.837    [weighted Loss:2.837    Policy Loss: 6.333    Value Loss: 4.368    Reward Loss: 0.899    Consistency Loss: 0.000    ] Replay Episodes Collected: 162057     Buffer Size: 14348      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:13:02,225][train][INFO][train.py>_log] ==> #57000      Total Loss: 2.259    [weighted Loss:2.259    Policy Loss: 5.270    Value Loss: 4.614    Reward Loss: 0.903    Consistency Loss: 0.000    ] Replay Episodes Collected: 163882     Buffer Size: 14375      Transition Number: 1000.023k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:15:49,754][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.204    [weighted Loss:2.204    Policy Loss: 6.047    Value Loss: 4.570    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 165799     Buffer Size: 14388      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:18:33,479][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.904    [weighted Loss:2.904    Policy Loss: 6.365    Value Loss: 4.098    Reward Loss: 0.943    Consistency Loss: 0.000    ] Replay Episodes Collected: 167654     Buffer Size: 14428      Transition Number: 1000.265k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:21:16,045][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.299    [weighted Loss:2.299    Policy Loss: 5.775    Value Loss: 4.137    Reward Loss: 0.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 169501     Buffer Size: 14456      Transition Number: 999.932 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:24:00,640][train][INFO][train.py>_log] ==> #61000      Total Loss: 3.569    [weighted Loss:3.569    Policy Loss: 5.736    Value Loss: 4.197    Reward Loss: 0.885    Consistency Loss: 0.000    ] Replay Episodes Collected: 171488     Buffer Size: 14532      Transition Number: 1000.002k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:26:46,670][train][INFO][train.py>_log] ==> #62000      Total Loss: 2.972    [weighted Loss:2.972    Policy Loss: 5.592    Value Loss: 4.587    Reward Loss: 0.894    Consistency Loss: 0.000    ] Replay Episodes Collected: 173266     Buffer Size: 14579      Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:29:30,658][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.060    [weighted Loss:2.060    Policy Loss: 4.965    Value Loss: 4.338    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 175140     Buffer Size: 14363      Transition Number: 999.998 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:32:18,292][train][INFO][train.py>_log] ==> #64000      Total Loss: 2.163    [weighted Loss:2.163    Policy Loss: 4.906    Value Loss: 4.050    Reward Loss: 0.970    Consistency Loss: 0.000    ] Replay Episodes Collected: 177095     Buffer Size: 14249      Transition Number: 1000.112k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:35:01,435][train][INFO][train.py>_log] ==> #65000      Total Loss: 2.536    [weighted Loss:2.536    Policy Loss: 5.334    Value Loss: 3.936    Reward Loss: 1.013    Consistency Loss: 0.000    ] Replay Episodes Collected: 178929     Buffer Size: 14239      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:37:44,471][train][INFO][train.py>_log] ==> #66000      Total Loss: 1.137    [weighted Loss:1.137    Policy Loss: 4.647    Value Loss: 4.191    Reward Loss: 0.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 180809     Buffer Size: 14214      Transition Number: 999.950 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:40:31,257][train][INFO][train.py>_log] ==> #67000      Total Loss: 1.729    [weighted Loss:1.729    Policy Loss: 4.589    Value Loss: 4.020    Reward Loss: 0.823    Consistency Loss: 0.000    ] Replay Episodes Collected: 182821     Buffer Size: 14221      Transition Number: 1000.172k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:43:16,130][train][INFO][train.py>_log] ==> #68000      Total Loss: 2.385    [weighted Loss:2.385    Policy Loss: 4.413    Value Loss: 3.977    Reward Loss: 1.059    Consistency Loss: 0.000    ] Replay Episodes Collected: 184655     Buffer Size: 14231      Transition Number: 999.981 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:45:58,677][train][INFO][train.py>_log] ==> #69000      Total Loss: 1.909    [weighted Loss:1.909    Policy Loss: 4.561    Value Loss: 4.129    Reward Loss: 0.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 186637     Buffer Size: 14193      Transition Number: 1000.026k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:48:44,817][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.246    [weighted Loss:2.246    Policy Loss: 5.202    Value Loss: 3.972    Reward Loss: 0.988    Consistency Loss: 0.000    ] Replay Episodes Collected: 188541     Buffer Size: 14187      Transition Number: 1000.204k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:51:31,459][train][INFO][train.py>_log] ==> #71000      Total Loss: 1.587    [weighted Loss:1.587    Policy Loss: 5.096    Value Loss: 3.937    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 190406     Buffer Size: 14219      Transition Number: 1000.152k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:54:15,674][train][INFO][train.py>_log] ==> #72000      Total Loss: 2.679    [weighted Loss:2.679    Policy Loss: 5.504    Value Loss: 4.316    Reward Loss: 1.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 192282     Buffer Size: 14255      Transition Number: 1000.324k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:57:03,142][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.189    [weighted Loss:2.189    Policy Loss: 5.840    Value Loss: 4.242    Reward Loss: 1.018    Consistency Loss: 0.000    ] Replay Episodes Collected: 194240     Buffer Size: 14399      Transition Number: 1000.339k Batch Size: 256        Lr: 0.10000 
[2022-02-17 19:59:47,671][train][INFO][train.py>_log] ==> #74000      Total Loss: 2.338    [weighted Loss:2.338    Policy Loss: 5.654    Value Loss: 4.008    Reward Loss: 1.117    Consistency Loss: 0.000    ] Replay Episodes Collected: 196128     Buffer Size: 14508      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:02:31,303][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.855    [weighted Loss:2.855    Policy Loss: 6.905    Value Loss: 4.316    Reward Loss: 1.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 197996     Buffer Size: 14594      Transition Number: 999.996 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:05:13,149][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.331    [weighted Loss:3.331    Policy Loss: 7.135    Value Loss: 4.447    Reward Loss: 1.162    Consistency Loss: 0.000    ] Replay Episodes Collected: 199908     Buffer Size: 14679      Transition Number: 1000.164k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:07:59,442][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.903    [weighted Loss:3.903    Policy Loss: 7.300    Value Loss: 4.821    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 201836     Buffer Size: 14813      Transition Number: 999.947 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:10:43,121][train][INFO][train.py>_log] ==> #78000      Total Loss: 2.445    [weighted Loss:2.445    Policy Loss: 7.361    Value Loss: 4.465    Reward Loss: 1.055    Consistency Loss: 0.000    ] Replay Episodes Collected: 203704     Buffer Size: 14947      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:13:29,285][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.672    [weighted Loss:3.672    Policy Loss: 7.847    Value Loss: 4.778    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 205615     Buffer Size: 15039      Transition Number: 999.994 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:16:14,527][train][INFO][train.py>_log] ==> #80000      Total Loss: 3.664    [weighted Loss:3.664    Policy Loss: 7.813    Value Loss: 4.896    Reward Loss: 1.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 207525     Buffer Size: 15125      Transition Number: 1000.196k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:18:57,774][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.218    [weighted Loss:3.218    Policy Loss: 9.118    Value Loss: 4.861    Reward Loss: 1.031    Consistency Loss: 0.000    ] Replay Episodes Collected: 209411     Buffer Size: 15120      Transition Number: 999.938 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:21:44,676][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.780    [weighted Loss:3.780    Policy Loss: 9.390    Value Loss: 4.985    Reward Loss: 1.251    Consistency Loss: 0.000    ] Replay Episodes Collected: 211251     Buffer Size: 15129      Transition Number: 1000.023k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:24:27,668][train][INFO][train.py>_log] ==> #83000      Total Loss: 4.226    [weighted Loss:4.226    Policy Loss: 8.952    Value Loss: 4.995    Reward Loss: 1.028    Consistency Loss: 0.000    ] Replay Episodes Collected: 213236     Buffer Size: 15265      Transition Number: 999.973 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:27:08,345][train][INFO][train.py>_log] ==> #84000      Total Loss: 4.623    [weighted Loss:4.623    Policy Loss: 9.820    Value Loss: 4.744    Reward Loss: 0.976    Consistency Loss: 0.000    ] Replay Episodes Collected: 215153     Buffer Size: 15437      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:29:50,607][train][INFO][train.py>_log] ==> #85000      Total Loss: 4.340    [weighted Loss:4.340    Policy Loss: 9.421    Value Loss: 4.753    Reward Loss: 1.131    Consistency Loss: 0.000    ] Replay Episodes Collected: 217004     Buffer Size: 15522      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:32:37,811][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.514    [weighted Loss:3.514    Policy Loss: 9.642    Value Loss: 5.397    Reward Loss: 1.163    Consistency Loss: 0.000    ] Replay Episodes Collected: 218931     Buffer Size: 15571      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:35:19,725][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.806    [weighted Loss:3.806    Policy Loss: 10.056   Value Loss: 4.853    Reward Loss: 1.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 220831     Buffer Size: 15631      Transition Number: 999.929 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:38:06,896][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.906    [weighted Loss:4.906    Policy Loss: 9.818    Value Loss: 5.313    Reward Loss: 1.057    Consistency Loss: 0.000    ] Replay Episodes Collected: 222681     Buffer Size: 15714      Transition Number: 1000.036k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:40:49,468][train][INFO][train.py>_log] ==> #89000      Total Loss: 4.618    [weighted Loss:4.618    Policy Loss: 9.667    Value Loss: 5.017    Reward Loss: 1.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 224516     Buffer Size: 15753      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:43:34,629][train][INFO][train.py>_log] ==> #90000      Total Loss: 4.839    [weighted Loss:4.839    Policy Loss: 10.096   Value Loss: 5.226    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 226452     Buffer Size: 15799      Transition Number: 1000.526k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:46:20,097][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.907    [weighted Loss:3.907    Policy Loss: 9.189    Value Loss: 5.325    Reward Loss: 1.151    Consistency Loss: 0.000    ] Replay Episodes Collected: 228360     Buffer Size: 15811      Transition Number: 1000.495k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:49:03,004][train][INFO][train.py>_log] ==> #92000      Total Loss: 3.794    [weighted Loss:3.794    Policy Loss: 9.595    Value Loss: 5.147    Reward Loss: 1.167    Consistency Loss: 0.000    ] Replay Episodes Collected: 230171     Buffer Size: 15717      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:51:46,649][train][INFO][train.py>_log] ==> #93000      Total Loss: 4.418    [weighted Loss:4.418    Policy Loss: 9.183    Value Loss: 4.954    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 232098     Buffer Size: 15691      Transition Number: 1000.300k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:54:29,136][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.876    [weighted Loss:3.876    Policy Loss: 9.506    Value Loss: 4.952    Reward Loss: 1.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 233958     Buffer Size: 15699      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:57:13,668][train][INFO][train.py>_log] ==> #95000      Total Loss: 4.299    [weighted Loss:4.299    Policy Loss: 8.947    Value Loss: 5.237    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 237017     Buffer Size: 16860      Transition Number: 1000.270k Batch Size: 256        Lr: 0.10000 
[2022-02-17 20:59:55,946][train][INFO][train.py>_log] ==> #96000      Total Loss: 4.861    [weighted Loss:4.861    Policy Loss: 8.543    Value Loss: 6.220    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 240027     Buffer Size: 18018      Transition Number: 1000.191k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:02:40,864][train][INFO][train.py>_log] ==> #97000      Total Loss: 3.944    [weighted Loss:3.944    Policy Loss: 7.935    Value Loss: 5.889    Reward Loss: 1.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 242161     Buffer Size: 18417      Transition Number: 1000.206k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:05:23,412][train][INFO][train.py>_log] ==> #98000      Total Loss: 4.673    [weighted Loss:4.673    Policy Loss: 9.065    Value Loss: 5.626    Reward Loss: 1.241    Consistency Loss: 0.000    ] Replay Episodes Collected: 244300     Buffer Size: 18769      Transition Number: 1000.013k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:08:07,116][train][INFO][train.py>_log] ==> #99000      Total Loss: 4.022    [weighted Loss:4.022    Policy Loss: 8.716    Value Loss: 5.980    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 246193     Buffer Size: 18927      Transition Number: 1000.149k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:10:53,625][train][INFO][train.py>_log] ==> #100000     Total Loss: 4.940    [weighted Loss:4.940    Policy Loss: 8.317    Value Loss: 5.866    Reward Loss: 1.236    Consistency Loss: 0.000    ] Replay Episodes Collected: 248143     Buffer Size: 19014      Transition Number: 1000.178k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:13:35,705][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.229    [weighted Loss:3.229    Policy Loss: 8.665    Value Loss: 5.915    Reward Loss: 1.260    Consistency Loss: 0.000    ] Replay Episodes Collected: 250055     Buffer Size: 19157      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:16:18,249][train][INFO][train.py>_log] ==> #102000     Total Loss: 3.174    [weighted Loss:3.174    Policy Loss: 7.872    Value Loss: 5.992    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 251934     Buffer Size: 19263      Transition Number: 999.986 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:19:02,970][train][INFO][train.py>_log] ==> #103000     Total Loss: 4.406    [weighted Loss:4.406    Policy Loss: 8.531    Value Loss: 5.962    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 253974     Buffer Size: 19257      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:21:47,362][train][INFO][train.py>_log] ==> #104000     Total Loss: 5.310    [weighted Loss:5.310    Policy Loss: 8.735    Value Loss: 6.124    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 255966     Buffer Size: 18289      Transition Number: 1000.060k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:24:29,153][train][INFO][train.py>_log] ==> #105000     Total Loss: 4.305    [weighted Loss:4.305    Policy Loss: 8.878    Value Loss: 6.560    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 258000     Buffer Size: 17564      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:27:15,355][train][INFO][train.py>_log] ==> #106000     Total Loss: 3.742    [weighted Loss:3.742    Policy Loss: 8.234    Value Loss: 5.971    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 260062     Buffer Size: 17518      Transition Number: 1000.006k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:29:58,177][train][INFO][train.py>_log] ==> #107000     Total Loss: 3.751    [weighted Loss:3.751    Policy Loss: 8.298    Value Loss: 5.825    Reward Loss: 1.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 262222     Buffer Size: 17607      Transition Number: 1000.081k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:32:40,351][train][INFO][train.py>_log] ==> #108000     Total Loss: 4.066    [weighted Loss:4.066    Policy Loss: 8.470    Value Loss: 5.936    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 264384     Buffer Size: 17877      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:35:25,569][train][INFO][train.py>_log] ==> #109000     Total Loss: 2.018    [weighted Loss:2.018    Policy Loss: 8.573    Value Loss: 6.138    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 266367     Buffer Size: 18061      Transition Number: 1000.158k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:38:08,502][train][INFO][train.py>_log] ==> #110000     Total Loss: 3.912    [weighted Loss:3.912    Policy Loss: 7.926    Value Loss: 5.962    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 268467     Buffer Size: 18200      Transition Number: 1000.020k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:40:50,762][train][INFO][train.py>_log] ==> #111000     Total Loss: 3.677    [weighted Loss:3.677    Policy Loss: 8.265    Value Loss: 6.166    Reward Loss: 1.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 270633     Buffer Size: 18461      Transition Number: 1000.167k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:43:33,463][train][INFO][train.py>_log] ==> #112000     Total Loss: 5.033    [weighted Loss:5.033    Policy Loss: 7.629    Value Loss: 6.289    Reward Loss: 1.287    Consistency Loss: 0.000    ] Replay Episodes Collected: 272806     Buffer Size: 18696      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:46:18,054][train][INFO][train.py>_log] ==> #113000     Total Loss: 4.372    [weighted Loss:4.372    Policy Loss: 7.784    Value Loss: 6.100    Reward Loss: 1.256    Consistency Loss: 0.000    ] Replay Episodes Collected: 274896     Buffer Size: 18743      Transition Number: 1000.113k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:49:00,499][train][INFO][train.py>_log] ==> #114000     Total Loss: 2.289    [weighted Loss:2.289    Policy Loss: 7.341    Value Loss: 5.943    Reward Loss: 1.386    Consistency Loss: 0.000    ] Replay Episodes Collected: 276901     Buffer Size: 18718      Transition Number: 1000.112k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:51:46,127][train][INFO][train.py>_log] ==> #115000     Total Loss: 4.161    [weighted Loss:4.161    Policy Loss: 7.522    Value Loss: 6.146    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 278939     Buffer Size: 18684      Transition Number: 1000.215k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:54:29,248][train][INFO][train.py>_log] ==> #116000     Total Loss: 3.982    [weighted Loss:3.982    Policy Loss: 8.125    Value Loss: 6.029    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 280997     Buffer Size: 18529      Transition Number: 1000.083k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:57:10,806][train][INFO][train.py>_log] ==> #117000     Total Loss: 3.833    [weighted Loss:3.833    Policy Loss: 8.047    Value Loss: 5.826    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 283260     Buffer Size: 18697      Transition Number: 1000.303k Batch Size: 256        Lr: 0.10000 
[2022-02-17 21:59:57,289][train][INFO][train.py>_log] ==> #118000     Total Loss: 3.111    [weighted Loss:3.111    Policy Loss: 8.376    Value Loss: 6.008    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 285683     Buffer Size: 19039      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:02:39,636][train][INFO][train.py>_log] ==> #119000     Total Loss: 4.529    [weighted Loss:4.529    Policy Loss: 8.243    Value Loss: 6.654    Reward Loss: 1.378    Consistency Loss: 0.000    ] Replay Episodes Collected: 288046     Buffer Size: 19291      Transition Number: 1000.266k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:05:23,984][train][INFO][train.py>_log] ==> #120000     Total Loss: 3.643    [weighted Loss:3.643    Policy Loss: 8.172    Value Loss: 5.870    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 290405     Buffer Size: 19450      Transition Number: 1000.072k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:08:09,418][train][INFO][train.py>_log] ==> #121000     Total Loss: 3.486    [weighted Loss:3.486    Policy Loss: 9.039    Value Loss: 6.265    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 292676     Buffer Size: 19484      Transition Number: 1000.085k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:10:51,797][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.240    [weighted Loss:3.240    Policy Loss: 8.480    Value Loss: 6.346    Reward Loss: 1.381    Consistency Loss: 0.000    ] Replay Episodes Collected: 294936     Buffer Size: 19748      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:13:34,006][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.075    [weighted Loss:3.075    Policy Loss: 8.020    Value Loss: 6.212    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 296950     Buffer Size: 19828      Transition Number: 1000.139k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:16:19,954][train][INFO][train.py>_log] ==> #124000     Total Loss: 3.451    [weighted Loss:3.451    Policy Loss: 8.321    Value Loss: 6.690    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 299004     Buffer Size: 19821      Transition Number: 999.984 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:19:01,808][train][INFO][train.py>_log] ==> #125000     Total Loss: 5.076    [weighted Loss:5.076    Policy Loss: 9.421    Value Loss: 6.027    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 301309     Buffer Size: 20087      Transition Number: 999.976 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:21:44,138][train][INFO][train.py>_log] ==> #126000     Total Loss: 3.913    [weighted Loss:3.913    Policy Loss: 8.441    Value Loss: 6.397    Reward Loss: 1.331    Consistency Loss: 0.000    ] Replay Episodes Collected: 303655     Buffer Size: 20047      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:24:29,873][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.495    [weighted Loss:3.495    Policy Loss: 8.529    Value Loss: 6.226    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 305449     Buffer Size: 19584      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:27:12,767][train][INFO][train.py>_log] ==> #128000     Total Loss: 4.320    [weighted Loss:4.320    Policy Loss: 8.043    Value Loss: 6.011    Reward Loss: 1.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 307361     Buffer Size: 19158      Transition Number: 1000.139k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:29:55,994][train][INFO][train.py>_log] ==> #129000     Total Loss: 3.947    [weighted Loss:3.947    Policy Loss: 7.864    Value Loss: 6.049    Reward Loss: 1.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 309249     Buffer Size: 18644      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:32:40,765][train][INFO][train.py>_log] ==> #130000     Total Loss: 4.015    [weighted Loss:4.015    Policy Loss: 8.308    Value Loss: 5.661    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 311028     Buffer Size: 18222      Transition Number: 1000.208k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:35:26,522][train][INFO][train.py>_log] ==> #131000     Total Loss: 4.498    [weighted Loss:4.498    Policy Loss: 8.061    Value Loss: 5.600    Reward Loss: 1.306    Consistency Loss: 0.000    ] Replay Episodes Collected: 317411     Buffer Size: 21994      Transition Number: 1000.149k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:38:10,202][train][INFO][train.py>_log] ==> #132000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 7.779    Value Loss: 5.834    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 323882     Buffer Size: 26356      Transition Number: 1000.498k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:40:58,512][train][INFO][train.py>_log] ==> #133000     Total Loss: 4.087    [weighted Loss:4.087    Policy Loss: 7.727    Value Loss: 6.048    Reward Loss: 1.416    Consistency Loss: 0.000    ] Replay Episodes Collected: 326485     Buffer Size: 27000      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:43:42,617][train][INFO][train.py>_log] ==> #134000     Total Loss: 3.214    [weighted Loss:3.214    Policy Loss: 6.334    Value Loss: 6.320    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 329140     Buffer Size: 27168      Transition Number: 999.988 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:46:25,913][train][INFO][train.py>_log] ==> #135000     Total Loss: 2.302    [weighted Loss:2.302    Policy Loss: 6.146    Value Loss: 5.364    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 331181     Buffer Size: 26891      Transition Number: 1000.025k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:49:08,873][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 6.517    Value Loss: 5.447    Reward Loss: 1.414    Consistency Loss: 0.000    ] Replay Episodes Collected: 333053     Buffer Size: 26945      Transition Number: 1000.120k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:51:55,888][train][INFO][train.py>_log] ==> #137000     Total Loss: 2.721    [weighted Loss:2.721    Policy Loss: 6.486    Value Loss: 5.646    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 334938     Buffer Size: 26870      Transition Number: 1000.261k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:54:38,989][train][INFO][train.py>_log] ==> #138000     Total Loss: 3.424    [weighted Loss:3.424    Policy Loss: 6.351    Value Loss: 5.368    Reward Loss: 1.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 336800     Buffer Size: 26854      Transition Number: 999.961 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 22:57:28,008][train][INFO][train.py>_log] ==> #139000     Total Loss: 3.425    [weighted Loss:3.425    Policy Loss: 6.848    Value Loss: 5.360    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 338789     Buffer Size: 25643      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:00:11,654][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.509    [weighted Loss:3.509    Policy Loss: 7.410    Value Loss: 5.208    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 340784     Buffer Size: 21153      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:02:53,806][train][INFO][train.py>_log] ==> #141000     Total Loss: 2.613    [weighted Loss:2.613    Policy Loss: 6.726    Value Loss: 5.302    Reward Loss: 1.358    Consistency Loss: 0.000    ] Replay Episodes Collected: 342847     Buffer Size: 17862      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:05:40,864][train][INFO][train.py>_log] ==> #142000     Total Loss: 3.498    [weighted Loss:3.498    Policy Loss: 7.572    Value Loss: 5.314    Reward Loss: 1.333    Consistency Loss: 0.000    ] Replay Episodes Collected: 344794     Buffer Size: 17232      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:08:23,526][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.628    [weighted Loss:3.628    Policy Loss: 7.654    Value Loss: 5.688    Reward Loss: 1.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 348449     Buffer Size: 18436      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:11:07,042][train][INFO][train.py>_log] ==> #144000     Total Loss: 3.188    [weighted Loss:3.188    Policy Loss: 7.507    Value Loss: 6.113    Reward Loss: 1.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 352028     Buffer Size: 20092      Transition Number: 1000.065k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:13:51,613][train][INFO][train.py>_log] ==> #145000     Total Loss: 4.221    [weighted Loss:4.221    Policy Loss: 7.257    Value Loss: 5.737    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 354651     Buffer Size: 20706      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:16:37,721][train][INFO][train.py>_log] ==> #146000     Total Loss: 3.582    [weighted Loss:3.582    Policy Loss: 7.308    Value Loss: 5.813    Reward Loss: 1.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 357193     Buffer Size: 21335      Transition Number: 999.958 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:19:19,899][train][INFO][train.py>_log] ==> #147000     Total Loss: 2.746    [weighted Loss:2.746    Policy Loss: 7.447    Value Loss: 5.317    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 359750     Buffer Size: 21981      Transition Number: 1000.015k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:22:06,798][train][INFO][train.py>_log] ==> #148000     Total Loss: 3.641    [weighted Loss:3.641    Policy Loss: 7.163    Value Loss: 5.636    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 362435     Buffer Size: 22724      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:24:49,970][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.696    [weighted Loss:2.696    Policy Loss: 7.201    Value Loss: 5.842    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 364516     Buffer Size: 22830      Transition Number: 1000.167k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:27:32,631][train][INFO][train.py>_log] ==> #150000     Total Loss: 3.823    [weighted Loss:3.823    Policy Loss: 7.347    Value Loss: 5.475    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 366592     Buffer Size: 22893      Transition Number: 1000.136k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:30:18,947][train][INFO][train.py>_log] ==> #151000     Total Loss: 3.584    [weighted Loss:3.584    Policy Loss: 7.575    Value Loss: 5.288    Reward Loss: 1.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 368733     Buffer Size: 22322      Transition Number: 1000.189k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:33:03,371][train][INFO][train.py>_log] ==> #152000     Total Loss: 5.312    [weighted Loss:5.312    Policy Loss: 8.643    Value Loss: 5.472    Reward Loss: 1.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 370751     Buffer Size: 20798      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:35:46,202][train][INFO][train.py>_log] ==> #153000     Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 7.983    Value Loss: 5.676    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 372796     Buffer Size: 19548      Transition Number: 1000.028k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:38:29,895][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.419    [weighted Loss:3.419    Policy Loss: 7.759    Value Loss: 5.675    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 374751     Buffer Size: 19113      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:41:13,806][train][INFO][train.py>_log] ==> #155000     Total Loss: 3.671    [weighted Loss:3.671    Policy Loss: 8.445    Value Loss: 5.686    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 377281     Buffer Size: 19047      Transition Number: 1000.010k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:43:57,787][train][INFO][train.py>_log] ==> #156000     Total Loss: 4.508    [weighted Loss:4.508    Policy Loss: 9.597    Value Loss: 5.953    Reward Loss: 1.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 379834     Buffer Size: 18932      Transition Number: 1000.274k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:46:44,227][train][INFO][train.py>_log] ==> #157000     Total Loss: 2.168    [weighted Loss:2.168    Policy Loss: 8.532    Value Loss: 5.341    Reward Loss: 1.529    Consistency Loss: 0.000    ] Replay Episodes Collected: 381953     Buffer Size: 18617      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:49:26,953][train][INFO][train.py>_log] ==> #158000     Total Loss: 3.381    [weighted Loss:3.381    Policy Loss: 8.300    Value Loss: 5.591    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 384087     Buffer Size: 18630      Transition Number: 999.977 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:52:10,323][train][INFO][train.py>_log] ==> #159000     Total Loss: 4.366    [weighted Loss:4.366    Policy Loss: 8.854    Value Loss: 5.884    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 386008     Buffer Size: 18560      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:54:58,432][train][INFO][train.py>_log] ==> #160000     Total Loss: 5.677    [weighted Loss:5.677    Policy Loss: 9.208    Value Loss: 5.620    Reward Loss: 1.460    Consistency Loss: 0.000    ] Replay Episodes Collected: 388012     Buffer Size: 18474      Transition Number: 999.964 k Batch Size: 256        Lr: 0.10000 
[2022-02-17 23:57:41,394][train][INFO][train.py>_log] ==> #161000     Total Loss: 3.752    [weighted Loss:3.752    Policy Loss: 9.009    Value Loss: 5.022    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 390092     Buffer Size: 18454      Transition Number: 1000.024k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:00:25,883][train][INFO][train.py>_log] ==> #162000     Total Loss: 3.796    [weighted Loss:3.796    Policy Loss: 8.967    Value Loss: 5.918    Reward Loss: 1.512    Consistency Loss: 0.000    ] Replay Episodes Collected: 392099     Buffer Size: 18414      Transition Number: 1000.064k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:03:11,834][train][INFO][train.py>_log] ==> #163000     Total Loss: 4.858    [weighted Loss:4.858    Policy Loss: 9.175    Value Loss: 5.542    Reward Loss: 1.377    Consistency Loss: 0.000    ] Replay Episodes Collected: 394101     Buffer Size: 18172      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:05:55,414][train][INFO][train.py>_log] ==> #164000     Total Loss: 4.230    [weighted Loss:4.230    Policy Loss: 9.574    Value Loss: 5.273    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 396093     Buffer Size: 17686      Transition Number: 1000.165k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:08:39,271][train][INFO][train.py>_log] ==> #165000     Total Loss: 4.291    [weighted Loss:4.291    Policy Loss: 9.113    Value Loss: 5.593    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 398126     Buffer Size: 17295      Transition Number: 1000.129k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:11:26,661][train][INFO][train.py>_log] ==> #166000     Total Loss: 4.567    [weighted Loss:4.567    Policy Loss: 8.647    Value Loss: 5.719    Reward Loss: 1.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 400179     Buffer Size: 17166      Transition Number: 1000.154k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:14:10,772][train][INFO][train.py>_log] ==> #167000     Total Loss: 4.841    [weighted Loss:4.841    Policy Loss: 8.793    Value Loss: 5.383    Reward Loss: 1.371    Consistency Loss: 0.000    ] Replay Episodes Collected: 402189     Buffer Size: 17106      Transition Number: 999.942 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:16:54,667][train][INFO][train.py>_log] ==> #168000     Total Loss: 4.001    [weighted Loss:4.001    Policy Loss: 8.574    Value Loss: 5.426    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 404195     Buffer Size: 17133      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:19:37,715][train][INFO][train.py>_log] ==> #169000     Total Loss: 2.821    [weighted Loss:2.821    Policy Loss: 8.710    Value Loss: 5.642    Reward Loss: 1.468    Consistency Loss: 0.000    ] Replay Episodes Collected: 406078     Buffer Size: 17061      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:22:22,825][train][INFO][train.py>_log] ==> #170000     Total Loss: 3.435    [weighted Loss:3.435    Policy Loss: 8.654    Value Loss: 5.284    Reward Loss: 1.290    Consistency Loss: 0.000    ] Replay Episodes Collected: 408053     Buffer Size: 16993      Transition Number: 999.936 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:25:12,642][train][INFO][train.py>_log] ==> #171000     Total Loss: 2.555    [weighted Loss:2.555    Policy Loss: 7.972    Value Loss: 5.301    Reward Loss: 1.503    Consistency Loss: 0.000    ] Replay Episodes Collected: 422112     Buffer Size: 28498      Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:28:04,565][train][INFO][train.py>_log] ==> #172000     Total Loss: 3.194    [weighted Loss:3.194    Policy Loss: 7.977    Value Loss: 5.872    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 437403     Buffer Size: 41473      Transition Number: 1000.145k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:30:48,030][train][INFO][train.py>_log] ==> #173000     Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 6.908    Value Loss: 5.755    Reward Loss: 1.593    Consistency Loss: 0.000    ] Replay Episodes Collected: 440753     Buffer Size: 42996      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:33:31,241][train][INFO][train.py>_log] ==> #174000     Total Loss: 3.757    [weighted Loss:3.757    Policy Loss: 7.190    Value Loss: 5.885    Reward Loss: 1.700    Consistency Loss: 0.000    ] Replay Episodes Collected: 444098     Buffer Size: 44415      Transition Number: 999.944 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:36:18,889][train][INFO][train.py>_log] ==> #175000     Total Loss: 2.950    [weighted Loss:2.950    Policy Loss: 7.080    Value Loss: 5.668    Reward Loss: 1.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 445986     Buffer Size: 44364      Transition Number: 1000.272k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:39:02,053][train][INFO][train.py>_log] ==> #176000     Total Loss: 2.543    [weighted Loss:2.543    Policy Loss: 7.189    Value Loss: 5.785    Reward Loss: 1.542    Consistency Loss: 0.000    ] Replay Episodes Collected: 447853     Buffer Size: 44267      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:41:43,672][train][INFO][train.py>_log] ==> #177000     Total Loss: 3.755    [weighted Loss:3.755    Policy Loss: 7.399    Value Loss: 5.383    Reward Loss: 1.639    Consistency Loss: 0.000    ] Replay Episodes Collected: 449760     Buffer Size: 44245      Transition Number: 1000.466k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:44:29,522][train][INFO][train.py>_log] ==> #178000     Total Loss: 3.713    [weighted Loss:3.713    Policy Loss: 6.633    Value Loss: 5.536    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 451630     Buffer Size: 44243      Transition Number: 1000.009k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:47:14,674][train][INFO][train.py>_log] ==> #179000     Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 6.718    Value Loss: 5.973    Reward Loss: 1.621    Consistency Loss: 0.000    ] Replay Episodes Collected: 453662     Buffer Size: 39850      Transition Number: 999.997 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:49:58,549][train][INFO][train.py>_log] ==> #180000     Total Loss: 4.198    [weighted Loss:4.198    Policy Loss: 6.728    Value Loss: 5.805    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 455680     Buffer Size: 28818      Transition Number: 1000.131k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:52:44,719][train][INFO][train.py>_log] ==> #181000     Total Loss: 3.955    [weighted Loss:3.955    Policy Loss: 7.334    Value Loss: 5.751    Reward Loss: 1.506    Consistency Loss: 0.000    ] Replay Episodes Collected: 457575     Buffer Size: 19421      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:55:28,590][train][INFO][train.py>_log] ==> #182000     Total Loss: 2.605    [weighted Loss:2.605    Policy Loss: 7.481    Value Loss: 5.293    Reward Loss: 1.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 459481     Buffer Size: 17856      Transition Number: 999.967 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 00:58:11,289][train][INFO][train.py>_log] ==> #183000     Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 7.751    Value Loss: 5.442    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 461501     Buffer Size: 16855      Transition Number: 1000.305k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:00:54,053][train][INFO][train.py>_log] ==> #184000     Total Loss: 3.292    [weighted Loss:3.292    Policy Loss: 7.327    Value Loss: 5.671    Reward Loss: 1.467    Consistency Loss: 0.000    ] Replay Episodes Collected: 463511     Buffer Size: 17006      Transition Number: 1000.065k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:03:40,850][train][INFO][train.py>_log] ==> #185000     Total Loss: 4.487    [weighted Loss:4.487    Policy Loss: 8.300    Value Loss: 5.963    Reward Loss: 1.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 465651     Buffer Size: 17238      Transition Number: 999.939 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:06:25,605][train][INFO][train.py>_log] ==> #186000     Total Loss: 2.331    [weighted Loss:2.331    Policy Loss: 8.201    Value Loss: 6.159    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 467871     Buffer Size: 17486      Transition Number: 1000.144k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:09:10,542][train][INFO][train.py>_log] ==> #187000     Total Loss: 3.380    [weighted Loss:3.380    Policy Loss: 8.024    Value Loss: 5.649    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 469850     Buffer Size: 17535      Transition Number: 1000.194k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:11:57,643][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 7.592    Value Loss: 5.713    Reward Loss: 1.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 471869     Buffer Size: 17460      Transition Number: 999.963 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:14:42,043][train][INFO][train.py>_log] ==> #189000     Total Loss: 3.798    [weighted Loss:3.798    Policy Loss: 6.993    Value Loss: 6.244    Reward Loss: 1.537    Consistency Loss: 0.000    ] Replay Episodes Collected: 473790     Buffer Size: 17380      Transition Number: 1000.356k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:17:29,420][train][INFO][train.py>_log] ==> #190000     Total Loss: 3.251    [weighted Loss:3.251    Policy Loss: 7.565    Value Loss: 5.810    Reward Loss: 1.656    Consistency Loss: 0.000    ] Replay Episodes Collected: 475721     Buffer Size: 17357      Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:20:12,813][train][INFO][train.py>_log] ==> #191000     Total Loss: 4.446    [weighted Loss:4.446    Policy Loss: 8.172    Value Loss: 5.898    Reward Loss: 1.482    Consistency Loss: 0.000    ] Replay Episodes Collected: 477622     Buffer Size: 17341      Transition Number: 1000.264k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:22:56,008][train][INFO][train.py>_log] ==> #192000     Total Loss: 2.754    [weighted Loss:2.754    Policy Loss: 8.110    Value Loss: 5.889    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 479537     Buffer Size: 17218      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:25:38,577][train][INFO][train.py>_log] ==> #193000     Total Loss: 2.208    [weighted Loss:2.208    Policy Loss: 7.153    Value Loss: 5.641    Reward Loss: 1.502    Consistency Loss: 0.000    ] Replay Episodes Collected: 481596     Buffer Size: 17183      Transition Number: 1000.041k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:28:25,815][train][INFO][train.py>_log] ==> #194000     Total Loss: 3.916    [weighted Loss:3.916    Policy Loss: 7.454    Value Loss: 5.826    Reward Loss: 1.646    Consistency Loss: 0.000    ] Replay Episodes Collected: 483725     Buffer Size: 17064      Transition Number: 1000.153k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:31:08,279][train][INFO][train.py>_log] ==> #195000     Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 7.352    Value Loss: 5.878    Reward Loss: 1.461    Consistency Loss: 0.000    ] Replay Episodes Collected: 485650     Buffer Size: 16915      Transition Number: 1000.137k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:33:55,394][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 8.820    Value Loss: 5.627    Reward Loss: 1.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 487604     Buffer Size: 16909      Transition Number: 999.971 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:36:38,379][train][INFO][train.py>_log] ==> #197000     Total Loss: 3.410    [weighted Loss:3.410    Policy Loss: 8.208    Value Loss: 5.864    Reward Loss: 1.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 489949     Buffer Size: 17263      Transition Number: 999.991 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:39:21,420][train][INFO][train.py>_log] ==> #198000     Total Loss: 4.238    [weighted Loss:4.238    Policy Loss: 8.531    Value Loss: 6.007    Reward Loss: 1.699    Consistency Loss: 0.000    ] Replay Episodes Collected: 492270     Buffer Size: 17625      Transition Number: 999.954 k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:42:07,613][train][INFO][train.py>_log] ==> #199000     Total Loss: 3.036    [weighted Loss:3.036    Policy Loss: 7.768    Value Loss: 6.219    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 494509     Buffer Size: 18012      Transition Number: 1000.082k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:45:03,821][train][INFO][train.py>_log] ==> #200000     Total Loss: 4.090    [weighted Loss:4.090    Policy Loss: 8.751    Value Loss: 5.806    Reward Loss: 1.521    Consistency Loss: 0.000    ] Replay Episodes Collected: 496734     Buffer Size: 18300      Transition Number: 1000.119k Batch Size: 256        Lr: 0.10000 
[2022-02-18 01:47:50,436][train][INFO][train.py>_log] ==> #201000     Total Loss: 4.664    [weighted Loss:4.664    Policy Loss: 9.320    Value Loss: 5.457    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 499081     Buffer Size: 18428      Transition Number: 1000.017k Batch Size: 256        Lr: 0.01000 
[2022-02-18 01:50:34,853][train][INFO][train.py>_log] ==> #202000     Total Loss: 1.868    [weighted Loss:1.868    Policy Loss: 9.157    Value Loss: 5.654    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 501078     Buffer Size: 18441      Transition Number: 1000.087k Batch Size: 256        Lr: 0.01000 
[2022-02-18 01:53:21,312][train][INFO][train.py>_log] ==> #203000     Total Loss: 5.509    [weighted Loss:5.509    Policy Loss: 8.968    Value Loss: 5.585    Reward Loss: 1.519    Consistency Loss: 0.000    ] Replay Episodes Collected: 502992     Buffer Size: 18357      Transition Number: 999.937 k Batch Size: 256        Lr: 0.01000 
[2022-02-18 01:56:04,710][train][INFO][train.py>_log] ==> #204000     Total Loss: 4.635    [weighted Loss:4.635    Policy Loss: 9.323    Value Loss: 5.607    Reward Loss: 1.579    Consistency Loss: 0.000    ] Replay Episodes Collected: 504936     Buffer Size: 18286      Transition Number: 1000.087k Batch Size: 256        Lr: 0.01000 
[2022-02-18 01:58:53,253][train][INFO][train.py>_log] ==> #205000     Total Loss: 3.855    [weighted Loss:3.855    Policy Loss: 8.969    Value Loss: 5.332    Reward Loss: 1.480    Consistency Loss: 0.000    ] Replay Episodes Collected: 506900     Buffer Size: 18053      Transition Number: 999.982 k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:01:39,389][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.809    [weighted Loss:3.809    Policy Loss: 8.979    Value Loss: 5.454    Reward Loss: 1.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 508755     Buffer Size: 17594      Transition Number: 1000.080k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:04:26,425][train][INFO][train.py>_log] ==> #207000     Total Loss: 5.057    [weighted Loss:5.057    Policy Loss: 8.935    Value Loss: 5.663    Reward Loss: 1.653    Consistency Loss: 0.000    ] Replay Episodes Collected: 510665     Buffer Size: 17165      Transition Number: 999.954 k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:07:18,412][train][INFO][train.py>_log] ==> #208000     Total Loss: 4.550    [weighted Loss:4.550    Policy Loss: 9.051    Value Loss: 5.040    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 512712     Buffer Size: 16677      Transition Number: 1000.040k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:10:04,724][train][INFO][train.py>_log] ==> #209000     Total Loss: 4.351    [weighted Loss:4.351    Policy Loss: 8.738    Value Loss: 5.146    Reward Loss: 1.446    Consistency Loss: 0.000    ] Replay Episodes Collected: 514471     Buffer Size: 16365      Transition Number: 999.948 k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:12:48,381][train][INFO][train.py>_log] ==> #210000     Total Loss: 3.594    [weighted Loss:3.594    Policy Loss: 8.802    Value Loss: 4.874    Reward Loss: 1.397    Consistency Loss: 0.000    ] Replay Episodes Collected: 516326     Buffer Size: 16130      Transition Number: 1000.093k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:15:33,242][train][INFO][train.py>_log] ==> #211000     Total Loss: 4.283    [weighted Loss:4.283    Policy Loss: 8.305    Value Loss: 4.805    Reward Loss: 1.409    Consistency Loss: 0.000    ] Replay Episodes Collected: 518157     Buffer Size: 15945      Transition Number: 1000.198k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:18:17,950][train][INFO][train.py>_log] ==> #212000     Total Loss: 4.202    [weighted Loss:4.202    Policy Loss: 8.379    Value Loss: 4.907    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 520018     Buffer Size: 15857      Transition Number: 999.975 k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:21:01,982][train][INFO][train.py>_log] ==> #213000     Total Loss: 3.524    [weighted Loss:3.524    Policy Loss: 8.240    Value Loss: 4.924    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 521919     Buffer Size: 15793      Transition Number: 1000.178k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:23:47,482][train][INFO][train.py>_log] ==> #214000     Total Loss: 2.870    [weighted Loss:2.870    Policy Loss: 7.904    Value Loss: 4.743    Reward Loss: 1.513    Consistency Loss: 0.000    ] Replay Episodes Collected: 523718     Buffer Size: 15724      Transition Number: 1000.028k Batch Size: 256        Lr: 0.01000 
[2022-02-18 02:26:32,347][train][INFO][train.py>_log] ==> #215000     Total Loss: 2.276    [weighted Loss:2.276    Policy Loss: 8.014    Value Loss: 4.619    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 525641     Buffer Size: 15704      Transition Number: 999.940 k Batch Size: 256        Lr: 0.01000 
