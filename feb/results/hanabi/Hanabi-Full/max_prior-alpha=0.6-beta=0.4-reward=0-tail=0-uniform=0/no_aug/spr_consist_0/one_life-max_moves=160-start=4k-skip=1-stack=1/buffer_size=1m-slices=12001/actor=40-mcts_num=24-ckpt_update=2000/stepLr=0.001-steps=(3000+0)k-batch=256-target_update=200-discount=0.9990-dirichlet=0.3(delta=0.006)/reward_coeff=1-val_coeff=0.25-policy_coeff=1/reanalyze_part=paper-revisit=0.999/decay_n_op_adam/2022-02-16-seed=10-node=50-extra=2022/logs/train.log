[2022-02-16 03:12:54,287][train][INFO][train.py>_log] ==> #0          Total Loss: 48.246   [weighted Loss:48.246   Policy Loss: 13.774   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1187       Buffer Size: 1187       Transition Number: 12.127  k Batch Size: 256        Lr: 0.00000 
[2022-02-16 03:15:26,732][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.473    [weighted Loss:5.473    Policy Loss: 14.887   Value Loss: 4.639    Reward Loss: 1.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 11413      Buffer Size: 11413      Transition Number: 141.268 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:18:00,965][train][INFO][train.py>_log] ==> #2000       Total Loss: 5.121    [weighted Loss:5.121    Policy Loss: 13.242   Value Loss: 4.680    Reward Loss: 1.470    Consistency Loss: 0.000    ] Replay Episodes Collected: 21421      Buffer Size: 21421      Transition Number: 264.894 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:20:34,541][train][INFO][train.py>_log] ==> #3000       Total Loss: 3.918    [weighted Loss:3.918    Policy Loss: 12.435   Value Loss: 4.730    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 28889      Buffer Size: 28889      Transition Number: 376.783 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:23:12,307][train][INFO][train.py>_log] ==> #4000       Total Loss: 5.969    [weighted Loss:5.969    Policy Loss: 12.479   Value Loss: 4.391    Reward Loss: 1.062    Consistency Loss: 0.000    ] Replay Episodes Collected: 36427      Buffer Size: 36427      Transition Number: 496.959 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:25:44,403][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.748    [weighted Loss:4.748    Policy Loss: 11.816   Value Loss: 4.439    Reward Loss: 1.149    Consistency Loss: 0.000    ] Replay Episodes Collected: 40431      Buffer Size: 40431      Transition Number: 604.265 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:28:17,741][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.895    [weighted Loss:4.895    Policy Loss: 11.833   Value Loss: 3.816    Reward Loss: 0.782    Consistency Loss: 0.000    ] Replay Episodes Collected: 44493      Buffer Size: 44493      Transition Number: 707.257 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:30:54,736][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.330    [weighted Loss:5.330    Policy Loss: 10.393   Value Loss: 4.077    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 48492      Buffer Size: 48492      Transition Number: 803.120 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:33:27,998][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 9.992    Value Loss: 3.783    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 52547      Buffer Size: 52547      Transition Number: 913.068 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:36:02,005][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.340    [weighted Loss:4.340    Policy Loss: 9.240    Value Loss: 4.103    Reward Loss: 0.838    Consistency Loss: 0.000    ] Replay Episodes Collected: 56367      Buffer Size: 54282      Transition Number: 1000.222k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:38:41,603][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.714    [weighted Loss:3.714    Policy Loss: 9.424    Value Loss: 4.047    Reward Loss: 0.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 60258      Buffer Size: 50069      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:41:20,307][train][INFO][train.py>_log] ==> #11000      Total Loss: 3.013    [weighted Loss:3.013    Policy Loss: 7.310    Value Loss: 3.827    Reward Loss: 0.819    Consistency Loss: 0.000    ] Replay Episodes Collected: 63887      Buffer Size: 45351      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:44:00,717][train][INFO][train.py>_log] ==> #12000      Total Loss: 2.664    [weighted Loss:2.664    Policy Loss: 7.757    Value Loss: 3.753    Reward Loss: 0.680    Consistency Loss: 0.000    ] Replay Episodes Collected: 67470      Buffer Size: 41340      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:46:37,390][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.847    [weighted Loss:2.847    Policy Loss: 6.445    Value Loss: 3.913    Reward Loss: 0.762    Consistency Loss: 0.000    ] Replay Episodes Collected: 71223      Buffer Size: 38214      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:49:16,162][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.070    [weighted Loss:2.070    Policy Loss: 6.330    Value Loss: 4.087    Reward Loss: 0.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 74779      Buffer Size: 36063      Transition Number: 1000.060k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:51:52,536][train][INFO][train.py>_log] ==> #15000      Total Loss: 2.491    [weighted Loss:2.491    Policy Loss: 5.782    Value Loss: 4.054    Reward Loss: 0.743    Consistency Loss: 0.000    ] Replay Episodes Collected: 77933      Buffer Size: 34842      Transition Number: 1000.012k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:54:32,144][train][INFO][train.py>_log] ==> #16000      Total Loss: 1.760    [weighted Loss:1.760    Policy Loss: 5.963    Value Loss: 3.785    Reward Loss: 0.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 81006      Buffer Size: 33850      Transition Number: 1000.062k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:57:09,262][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.549    [weighted Loss:2.549    Policy Loss: 5.287    Value Loss: 4.291    Reward Loss: 0.775    Consistency Loss: 0.000    ] Replay Episodes Collected: 84092      Buffer Size: 33151      Transition Number: 999.998 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 03:59:46,136][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.209    [weighted Loss:2.209    Policy Loss: 5.223    Value Loss: 4.255    Reward Loss: 0.642    Consistency Loss: 0.000    ] Replay Episodes Collected: 87125      Buffer Size: 31786      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:02:28,243][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 5.778    Value Loss: 4.386    Reward Loss: 0.726    Consistency Loss: 0.000    ] Replay Episodes Collected: 89959      Buffer Size: 30397      Transition Number: 1000.001k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:05:06,819][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.272    [weighted Loss:2.272    Policy Loss: 5.713    Value Loss: 4.343    Reward Loss: 0.733    Consistency Loss: 0.000    ] Replay Episodes Collected: 92724      Buffer Size: 29221      Transition Number: 999.991 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:07:49,696][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.546    [weighted Loss:2.546    Policy Loss: 5.780    Value Loss: 4.656    Reward Loss: 0.772    Consistency Loss: 0.000    ] Replay Episodes Collected: 95285      Buffer Size: 28129      Transition Number: 1000.114k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:10:32,499][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 6.551    Value Loss: 4.293    Reward Loss: 0.795    Consistency Loss: 0.000    ] Replay Episodes Collected: 97788      Buffer Size: 27004      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:13:11,526][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.520    [weighted Loss:2.520    Policy Loss: 5.594    Value Loss: 4.383    Reward Loss: 0.756    Consistency Loss: 0.000    ] Replay Episodes Collected: 100647     Buffer Size: 25933      Transition Number: 999.967 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:15:50,053][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.463    [weighted Loss:2.463    Policy Loss: 5.690    Value Loss: 4.426    Reward Loss: 0.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 103559     Buffer Size: 25504      Transition Number: 1000.001k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:18:28,790][train][INFO][train.py>_log] ==> #25000      Total Loss: 3.386    [weighted Loss:3.386    Policy Loss: 7.116    Value Loss: 5.346    Reward Loss: 1.066    Consistency Loss: 0.000    ] Replay Episodes Collected: 106768     Buffer Size: 25479      Transition Number: 1000.139k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:21:10,064][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.423    [weighted Loss:3.423    Policy Loss: 7.180    Value Loss: 4.918    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 110032     Buffer Size: 25627      Transition Number: 1000.075k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:23:47,465][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.914    [weighted Loss:3.914    Policy Loss: 7.979    Value Loss: 5.257    Reward Loss: 1.037    Consistency Loss: 0.000    ] Replay Episodes Collected: 113067     Buffer Size: 25522      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:26:26,663][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.277    [weighted Loss:3.277    Policy Loss: 7.838    Value Loss: 4.994    Reward Loss: 0.959    Consistency Loss: 0.000    ] Replay Episodes Collected: 116018     Buffer Size: 25685      Transition Number: 999.971 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:29:06,023][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.880    [weighted Loss:3.880    Policy Loss: 8.511    Value Loss: 5.224    Reward Loss: 0.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 118807     Buffer Size: 25662      Transition Number: 1000.027k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:31:47,045][train][INFO][train.py>_log] ==> #30000      Total Loss: 2.507    [weighted Loss:2.507    Policy Loss: 8.508    Value Loss: 5.395    Reward Loss: 0.919    Consistency Loss: 0.000    ] Replay Episodes Collected: 121566     Buffer Size: 25826      Transition Number: 1000.099k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:34:24,288][train][INFO][train.py>_log] ==> #31000      Total Loss: 3.177    [weighted Loss:3.177    Policy Loss: 8.684    Value Loss: 5.766    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 124142     Buffer Size: 25956      Transition Number: 1000.168k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:37:06,294][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.180    [weighted Loss:3.180    Policy Loss: 9.285    Value Loss: 5.376    Reward Loss: 1.032    Consistency Loss: 0.000    ] Replay Episodes Collected: 126911     Buffer Size: 25751      Transition Number: 1000.420k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:39:49,871][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.296    [weighted Loss:4.296    Policy Loss: 8.953    Value Loss: 5.803    Reward Loss: 1.054    Consistency Loss: 0.000    ] Replay Episodes Collected: 130468     Buffer Size: 26091      Transition Number: 1000.147k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:42:32,272][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.176    [weighted Loss:4.176    Policy Loss: 9.399    Value Loss: 5.734    Reward Loss: 1.106    Consistency Loss: 0.000    ] Replay Episodes Collected: 133854     Buffer Size: 26232      Transition Number: 999.966 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:45:13,448][train][INFO][train.py>_log] ==> #35000      Total Loss: 5.520    [weighted Loss:5.520    Policy Loss: 10.111   Value Loss: 5.739    Reward Loss: 1.329    Consistency Loss: 0.000    ] Replay Episodes Collected: 136707     Buffer Size: 25774      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:47:54,657][train][INFO][train.py>_log] ==> #36000      Total Loss: 5.126    [weighted Loss:5.126    Policy Loss: 10.217   Value Loss: 5.973    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 139454     Buffer Size: 25440      Transition Number: 1000.046k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:50:35,588][train][INFO][train.py>_log] ==> #37000      Total Loss: 5.105    [weighted Loss:5.105    Policy Loss: 10.614   Value Loss: 5.977    Reward Loss: 1.222    Consistency Loss: 0.000    ] Replay Episodes Collected: 141857     Buffer Size: 25000      Transition Number: 1000.000k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:53:12,892][train][INFO][train.py>_log] ==> #38000      Total Loss: 6.699    [weighted Loss:6.699    Policy Loss: 11.535   Value Loss: 6.201    Reward Loss: 1.119    Consistency Loss: 0.000    ] Replay Episodes Collected: 144190     Buffer Size: 24610      Transition Number: 1000.179k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:55:51,884][train][INFO][train.py>_log] ==> #39000      Total Loss: 6.083    [weighted Loss:6.083    Policy Loss: 11.367   Value Loss: 5.686    Reward Loss: 1.189    Consistency Loss: 0.000    ] Replay Episodes Collected: 146255     Buffer Size: 24021      Transition Number: 1000.270k Batch Size: 256        Lr: 0.00100 
[2022-02-16 04:58:32,262][train][INFO][train.py>_log] ==> #40000      Total Loss: 6.079    [weighted Loss:6.079    Policy Loss: 11.484   Value Loss: 5.747    Reward Loss: 1.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 148323     Buffer Size: 23432      Transition Number: 999.978 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:01:11,163][train][INFO][train.py>_log] ==> #41000      Total Loss: 6.086    [weighted Loss:6.086    Policy Loss: 10.987   Value Loss: 5.778    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 150095     Buffer Size: 22533      Transition Number: 1000.011k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:03:50,480][train][INFO][train.py>_log] ==> #42000      Total Loss: 6.013    [weighted Loss:6.013    Policy Loss: 11.235   Value Loss: 5.855    Reward Loss: 1.050    Consistency Loss: 0.000    ] Replay Episodes Collected: 151980     Buffer Size: 20942      Transition Number: 1000.223k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:06:29,899][train][INFO][train.py>_log] ==> #43000      Total Loss: 6.789    [weighted Loss:6.789    Policy Loss: 11.532   Value Loss: 5.948    Reward Loss: 1.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 153852     Buffer Size: 19469      Transition Number: 999.987 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:09:10,882][train][INFO][train.py>_log] ==> #44000      Total Loss: 6.456    [weighted Loss:6.456    Policy Loss: 11.846   Value Loss: 5.700    Reward Loss: 0.928    Consistency Loss: 0.000    ] Replay Episodes Collected: 155657     Buffer Size: 18473      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:11:49,535][train][INFO][train.py>_log] ==> #45000      Total Loss: 5.304    [weighted Loss:5.304    Policy Loss: 11.831   Value Loss: 5.638    Reward Loss: 0.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 157690     Buffer Size: 17629      Transition Number: 1000.067k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:14:31,481][train][INFO][train.py>_log] ==> #46000      Total Loss: 5.547    [weighted Loss:5.547    Policy Loss: 11.578   Value Loss: 4.985    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 159557     Buffer Size: 17148      Transition Number: 999.943 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:17:11,066][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.391    [weighted Loss:3.391    Policy Loss: 11.920   Value Loss: 4.929    Reward Loss: 0.859    Consistency Loss: 0.000    ] Replay Episodes Collected: 161524     Buffer Size: 16762      Transition Number: 999.970 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:19:53,490][train][INFO][train.py>_log] ==> #48000      Total Loss: 5.888    [weighted Loss:5.888    Policy Loss: 11.686   Value Loss: 5.172    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 163546     Buffer Size: 16540      Transition Number: 1000.003k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:22:35,983][train][INFO][train.py>_log] ==> #49000      Total Loss: 4.573    [weighted Loss:4.573    Policy Loss: 11.688   Value Loss: 5.593    Reward Loss: 0.924    Consistency Loss: 0.000    ] Replay Episodes Collected: 165585     Buffer Size: 16591      Transition Number: 1000.317k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:25:16,781][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.987    [weighted Loss:2.987    Policy Loss: 11.926   Value Loss: 5.110    Reward Loss: 0.867    Consistency Loss: 0.000    ] Replay Episodes Collected: 167627     Buffer Size: 16808      Transition Number: 999.975 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:27:59,403][train][INFO][train.py>_log] ==> #51000      Total Loss: 5.031    [weighted Loss:5.031    Policy Loss: 11.805   Value Loss: 5.165    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 169694     Buffer Size: 17016      Transition Number: 999.933 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:30:41,645][train][INFO][train.py>_log] ==> #52000      Total Loss: 6.320    [weighted Loss:6.320    Policy Loss: 11.469   Value Loss: 5.637    Reward Loss: 1.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 171800     Buffer Size: 17310      Transition Number: 1000.127k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:33:23,324][train][INFO][train.py>_log] ==> #53000      Total Loss: 3.836    [weighted Loss:3.836    Policy Loss: 11.205   Value Loss: 5.200    Reward Loss: 1.079    Consistency Loss: 0.000    ] Replay Episodes Collected: 174127     Buffer Size: 17708      Transition Number: 1000.464k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:36:03,474][train][INFO][train.py>_log] ==> #54000      Total Loss: 5.302    [weighted Loss:5.302    Policy Loss: 11.680   Value Loss: 5.125    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 176365     Buffer Size: 18069      Transition Number: 1000.328k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:38:42,467][train][INFO][train.py>_log] ==> #55000      Total Loss: 6.222    [weighted Loss:6.222    Policy Loss: 11.696   Value Loss: 5.469    Reward Loss: 1.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 178858     Buffer Size: 18619      Transition Number: 1000.233k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:41:23,080][train][INFO][train.py>_log] ==> #56000      Total Loss: 4.483    [weighted Loss:4.483    Policy Loss: 11.663   Value Loss: 5.535    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 181396     Buffer Size: 19238      Transition Number: 1000.278k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:44:03,192][train][INFO][train.py>_log] ==> #57000      Total Loss: 4.626    [weighted Loss:4.626    Policy Loss: 12.038   Value Loss: 5.567    Reward Loss: 1.203    Consistency Loss: 0.000    ] Replay Episodes Collected: 185054     Buffer Size: 20863      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:46:43,234][train][INFO][train.py>_log] ==> #58000      Total Loss: 4.971    [weighted Loss:4.971    Policy Loss: 11.891   Value Loss: 5.682    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 188627     Buffer Size: 22322      Transition Number: 999.986 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:49:25,084][train][INFO][train.py>_log] ==> #59000      Total Loss: 4.772    [weighted Loss:4.772    Policy Loss: 11.863   Value Loss: 6.222    Reward Loss: 1.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 192868     Buffer Size: 24375      Transition Number: 1000.195k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:52:07,626][train][INFO][train.py>_log] ==> #60000      Total Loss: 5.282    [weighted Loss:5.282    Policy Loss: 11.741   Value Loss: 6.563    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 197111     Buffer Size: 26477      Transition Number: 999.972 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:54:49,475][train][INFO][train.py>_log] ==> #61000      Total Loss: 7.027    [weighted Loss:7.027    Policy Loss: 12.138   Value Loss: 6.553    Reward Loss: 1.424    Consistency Loss: 0.000    ] Replay Episodes Collected: 201009     Buffer Size: 28087      Transition Number: 1000.021k Batch Size: 256        Lr: 0.00100 
[2022-02-16 05:57:30,334][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.147    [weighted Loss:3.147    Policy Loss: 10.968   Value Loss: 6.837    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 204882     Buffer Size: 29613      Transition Number: 1000.219k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:00:13,854][train][INFO][train.py>_log] ==> #63000      Total Loss: 6.265    [weighted Loss:6.265    Policy Loss: 10.971   Value Loss: 6.524    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 207853     Buffer Size: 30113      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:02:54,538][train][INFO][train.py>_log] ==> #64000      Total Loss: 3.615    [weighted Loss:3.615    Policy Loss: 10.285   Value Loss: 6.649    Reward Loss: 1.478    Consistency Loss: 0.000    ] Replay Episodes Collected: 210772     Buffer Size: 30479      Transition Number: 1000.257k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:05:34,042][train][INFO][train.py>_log] ==> #65000      Total Loss: 5.231    [weighted Loss:5.231    Policy Loss: 10.393   Value Loss: 6.448    Reward Loss: 1.427    Consistency Loss: 0.000    ] Replay Episodes Collected: 213294     Buffer Size: 30075      Transition Number: 999.980 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:08:16,718][train][INFO][train.py>_log] ==> #66000      Total Loss: 6.068    [weighted Loss:6.068    Policy Loss: 10.517   Value Loss: 6.504    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 215890     Buffer Size: 28977      Transition Number: 1000.078k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:11:00,351][train][INFO][train.py>_log] ==> #67000      Total Loss: 5.872    [weighted Loss:5.872    Policy Loss: 10.630   Value Loss: 6.680    Reward Loss: 1.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 218939     Buffer Size: 28083      Transition Number: 1000.096k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:13:42,084][train][INFO][train.py>_log] ==> #68000      Total Loss: 6.094    [weighted Loss:6.094    Policy Loss: 10.787   Value Loss: 6.411    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 222031     Buffer Size: 27009      Transition Number: 1000.091k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:16:24,298][train][INFO][train.py>_log] ==> #69000      Total Loss: 7.021    [weighted Loss:7.021    Policy Loss: 11.418   Value Loss: 6.498    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 225357     Buffer Size: 26313      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:19:06,772][train][INFO][train.py>_log] ==> #70000      Total Loss: 7.167    [weighted Loss:7.167    Policy Loss: 10.869   Value Loss: 6.906    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 228673     Buffer Size: 25765      Transition Number: 1000.107k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:21:47,157][train][INFO][train.py>_log] ==> #71000      Total Loss: 5.492    [weighted Loss:5.492    Policy Loss: 10.881   Value Loss: 7.045    Reward Loss: 1.364    Consistency Loss: 0.000    ] Replay Episodes Collected: 232329     Buffer Size: 25960      Transition Number: 1000.205k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:24:29,331][train][INFO][train.py>_log] ==> #72000      Total Loss: 5.650    [weighted Loss:5.650    Policy Loss: 11.185   Value Loss: 6.772    Reward Loss: 1.404    Consistency Loss: 0.000    ] Replay Episodes Collected: 236069     Buffer Size: 26665      Transition Number: 999.942 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:27:13,311][train][INFO][train.py>_log] ==> #73000      Total Loss: 7.538    [weighted Loss:7.538    Policy Loss: 11.658   Value Loss: 7.180    Reward Loss: 1.491    Consistency Loss: 0.000    ] Replay Episodes Collected: 239795     Buffer Size: 27479      Transition Number: 1000.025k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:29:56,890][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.859    [weighted Loss:4.859    Policy Loss: 12.007   Value Loss: 7.386    Reward Loss: 1.492    Consistency Loss: 0.000    ] Replay Episodes Collected: 243487     Buffer Size: 28502      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:32:37,394][train][INFO][train.py>_log] ==> #75000      Total Loss: 3.783    [weighted Loss:3.783    Policy Loss: 11.724   Value Loss: 6.900    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 246723     Buffer Size: 28817      Transition Number: 1000.094k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:35:17,987][train][INFO][train.py>_log] ==> #76000      Total Loss: 7.788    [weighted Loss:7.788    Policy Loss: 12.186   Value Loss: 7.099    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 249821     Buffer Size: 28895      Transition Number: 1000.174k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:38:01,340][train][INFO][train.py>_log] ==> #77000      Total Loss: 3.860    [weighted Loss:3.860    Policy Loss: 11.767   Value Loss: 6.996    Reward Loss: 1.311    Consistency Loss: 0.000    ] Replay Episodes Collected: 252660     Buffer Size: 28522      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:40:42,706][train][INFO][train.py>_log] ==> #78000      Total Loss: 7.776    [weighted Loss:7.776    Policy Loss: 11.698   Value Loss: 7.007    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 255534     Buffer Size: 28010      Transition Number: 1000.039k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:43:24,683][train][INFO][train.py>_log] ==> #79000      Total Loss: 7.032    [weighted Loss:7.032    Policy Loss: 12.097   Value Loss: 7.261    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 258087     Buffer Size: 27305      Transition Number: 1000.023k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:46:08,249][train][INFO][train.py>_log] ==> #80000      Total Loss: 6.090    [weighted Loss:6.090    Policy Loss: 12.209   Value Loss: 7.480    Reward Loss: 1.310    Consistency Loss: 0.000    ] Replay Episodes Collected: 260663     Buffer Size: 26273      Transition Number: 1000.112k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:48:51,939][train][INFO][train.py>_log] ==> #81000      Total Loss: 4.428    [weighted Loss:4.428    Policy Loss: 12.048   Value Loss: 6.644    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 263503     Buffer Size: 25394      Transition Number: 1000.160k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:51:36,626][train][INFO][train.py>_log] ==> #82000      Total Loss: 7.172    [weighted Loss:7.172    Policy Loss: 11.659   Value Loss: 6.471    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 266312     Buffer Size: 24596      Transition Number: 1000.018k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:54:18,903][train][INFO][train.py>_log] ==> #83000      Total Loss: 5.734    [weighted Loss:5.734    Policy Loss: 12.670   Value Loss: 6.333    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 269303     Buffer Size: 24147      Transition Number: 1000.253k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:57:02,166][train][INFO][train.py>_log] ==> #84000      Total Loss: 6.453    [weighted Loss:6.453    Policy Loss: 12.050   Value Loss: 6.608    Reward Loss: 1.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 272239     Buffer Size: 23932      Transition Number: 1000.081k Batch Size: 256        Lr: 0.00100 
[2022-02-16 06:59:46,912][train][INFO][train.py>_log] ==> #85000      Total Loss: 4.878    [weighted Loss:4.878    Policy Loss: 12.194   Value Loss: 7.042    Reward Loss: 1.380    Consistency Loss: 0.000    ] Replay Episodes Collected: 275092     Buffer Size: 23811      Transition Number: 1000.032k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:02:28,539][train][INFO][train.py>_log] ==> #86000      Total Loss: 6.767    [weighted Loss:6.767    Policy Loss: 11.821   Value Loss: 6.612    Reward Loss: 1.418    Consistency Loss: 0.000    ] Replay Episodes Collected: 277926     Buffer Size: 23830      Transition Number: 1000.147k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:05:11,452][train][INFO][train.py>_log] ==> #87000      Total Loss: 6.968    [weighted Loss:6.968    Policy Loss: 11.540   Value Loss: 6.662    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 280906     Buffer Size: 23989      Transition Number: 1000.130k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:07:55,947][train][INFO][train.py>_log] ==> #88000      Total Loss: 6.491    [weighted Loss:6.491    Policy Loss: 11.249   Value Loss: 6.818    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 283986     Buffer Size: 24438      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:10:40,189][train][INFO][train.py>_log] ==> #89000      Total Loss: 4.536    [weighted Loss:4.536    Policy Loss: 10.998   Value Loss: 6.942    Reward Loss: 1.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 287691     Buffer Size: 25305      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:13:21,821][train][INFO][train.py>_log] ==> #90000      Total Loss: 5.753    [weighted Loss:5.753    Policy Loss: 11.174   Value Loss: 6.376    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 291303     Buffer Size: 26106      Transition Number: 1000.125k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:16:03,185][train][INFO][train.py>_log] ==> #91000      Total Loss: 7.106    [weighted Loss:7.106    Policy Loss: 11.834   Value Loss: 6.990    Reward Loss: 1.439    Consistency Loss: 0.000    ] Replay Episodes Collected: 294832     Buffer Size: 26813      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:18:46,280][train][INFO][train.py>_log] ==> #92000      Total Loss: 7.042    [weighted Loss:7.042    Policy Loss: 11.838   Value Loss: 6.853    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 298499     Buffer Size: 27407      Transition Number: 1000.131k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:21:26,955][train][INFO][train.py>_log] ==> #93000      Total Loss: 2.710    [weighted Loss:2.710    Policy Loss: 12.269   Value Loss: 7.223    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 301497     Buffer Size: 27589      Transition Number: 1000.051k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:24:10,442][train][INFO][train.py>_log] ==> #94000      Total Loss: 3.216    [weighted Loss:3.216    Policy Loss: 13.131   Value Loss: 7.443    Reward Loss: 1.484    Consistency Loss: 0.000    ] Replay Episodes Collected: 304483     Buffer Size: 27711      Transition Number: 1000.070k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:26:50,940][train][INFO][train.py>_log] ==> #95000      Total Loss: 6.130    [weighted Loss:6.130    Policy Loss: 13.286   Value Loss: 7.358    Reward Loss: 1.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 306748     Buffer Size: 27262      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:29:32,578][train][INFO][train.py>_log] ==> #96000      Total Loss: 7.683    [weighted Loss:7.683    Policy Loss: 13.458   Value Loss: 5.994    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 309083     Buffer Size: 26563      Transition Number: 1000.269k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:32:14,723][train][INFO][train.py>_log] ==> #97000      Total Loss: 7.168    [weighted Loss:7.168    Policy Loss: 13.378   Value Loss: 6.041    Reward Loss: 1.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 311295     Buffer Size: 25471      Transition Number: 1000.401k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:34:55,486][train][INFO][train.py>_log] ==> #98000      Total Loss: 7.077    [weighted Loss:7.077    Policy Loss: 13.201   Value Loss: 5.792    Reward Loss: 1.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 313409     Buffer Size: 24030      Transition Number: 1000.201k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:37:37,261][train][INFO][train.py>_log] ==> #99000      Total Loss: 6.382    [weighted Loss:6.382    Policy Loss: 13.561   Value Loss: 5.750    Reward Loss: 0.955    Consistency Loss: 0.000    ] Replay Episodes Collected: 316138     Buffer Size: 22893      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:40:35,329][train][INFO][train.py>_log] ==> #100000     Total Loss: 5.796    [weighted Loss:5.796    Policy Loss: 13.804   Value Loss: 6.839    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 318850     Buffer Size: 21961      Transition Number: 1000.063k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:43:17,765][train][INFO][train.py>_log] ==> #101000     Total Loss: 5.263    [weighted Loss:5.263    Policy Loss: 13.288   Value Loss: 5.320    Reward Loss: 0.892    Consistency Loss: 0.000    ] Replay Episodes Collected: 322298     Buffer Size: 21595      Transition Number: 1000.260k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:45:59,046][train][INFO][train.py>_log] ==> #102000     Total Loss: 5.793    [weighted Loss:5.793    Policy Loss: 13.014   Value Loss: 5.527    Reward Loss: 0.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 325474     Buffer Size: 21587      Transition Number: 1000.121k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:48:41,013][train][INFO][train.py>_log] ==> #103000     Total Loss: 6.038    [weighted Loss:6.038    Policy Loss: 12.518   Value Loss: 5.818    Reward Loss: 0.846    Consistency Loss: 0.000    ] Replay Episodes Collected: 328821     Buffer Size: 22304      Transition Number: 1000.205k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:51:23,864][train][INFO][train.py>_log] ==> #104000     Total Loss: 4.001    [weighted Loss:4.001    Policy Loss: 12.522   Value Loss: 6.278    Reward Loss: 0.879    Consistency Loss: 0.000    ] Replay Episodes Collected: 332237     Buffer Size: 23182      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:54:08,357][train][INFO][train.py>_log] ==> #105000     Total Loss: 5.880    [weighted Loss:5.880    Policy Loss: 12.586   Value Loss: 7.097    Reward Loss: 0.917    Consistency Loss: 0.000    ] Replay Episodes Collected: 335278     Buffer Size: 23967      Transition Number: 1000.082k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:56:50,715][train][INFO][train.py>_log] ==> #106000     Total Loss: 6.420    [weighted Loss:6.420    Policy Loss: 12.157   Value Loss: 7.911    Reward Loss: 0.930    Consistency Loss: 0.000    ] Replay Episodes Collected: 338145     Buffer Size: 24606      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00100 
[2022-02-16 07:59:31,102][train][INFO][train.py>_log] ==> #107000     Total Loss: 5.617    [weighted Loss:5.617    Policy Loss: 11.133   Value Loss: 8.140    Reward Loss: 1.011    Consistency Loss: 0.000    ] Replay Episodes Collected: 341025     Buffer Size: 24903      Transition Number: 999.995 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:02:13,006][train][INFO][train.py>_log] ==> #108000     Total Loss: 6.285    [weighted Loss:6.285    Policy Loss: 11.428   Value Loss: 7.845    Reward Loss: 1.016    Consistency Loss: 0.000    ] Replay Episodes Collected: 343968     Buffer Size: 25187      Transition Number: 1000.140k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:04:55,083][train][INFO][train.py>_log] ==> #109000     Total Loss: 6.984    [weighted Loss:6.984    Policy Loss: 10.987   Value Loss: 7.582    Reward Loss: 1.154    Consistency Loss: 0.000    ] Replay Episodes Collected: 347773     Buffer Size: 25855      Transition Number: 1000.084k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:07:38,065][train][INFO][train.py>_log] ==> #110000     Total Loss: 7.056    [weighted Loss:7.056    Policy Loss: 11.451   Value Loss: 6.894    Reward Loss: 1.006    Consistency Loss: 0.000    ] Replay Episodes Collected: 351709     Buffer Size: 26604      Transition Number: 1000.218k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:10:20,482][train][INFO][train.py>_log] ==> #111000     Total Loss: 5.933    [weighted Loss:5.933    Policy Loss: 11.513   Value Loss: 7.799    Reward Loss: 1.228    Consistency Loss: 0.000    ] Replay Episodes Collected: 355924     Buffer Size: 27511      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:13:03,779][train][INFO][train.py>_log] ==> #112000     Total Loss: 7.094    [weighted Loss:7.094    Policy Loss: 11.744   Value Loss: 7.273    Reward Loss: 1.318    Consistency Loss: 0.000    ] Replay Episodes Collected: 360285     Buffer Size: 28589      Transition Number: 1000.268k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:15:46,595][train][INFO][train.py>_log] ==> #113000     Total Loss: 6.129    [weighted Loss:6.129    Policy Loss: 10.849   Value Loss: 7.529    Reward Loss: 1.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 365186     Buffer Size: 30404      Transition Number: 1000.061k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:18:27,812][train][INFO][train.py>_log] ==> #114000     Total Loss: 6.702    [weighted Loss:6.702    Policy Loss: 11.246   Value Loss: 8.382    Reward Loss: 1.366    Consistency Loss: 0.000    ] Replay Episodes Collected: 369948     Buffer Size: 32258      Transition Number: 999.999 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:21:10,986][train][INFO][train.py>_log] ==> #115000     Total Loss: 5.774    [weighted Loss:5.774    Policy Loss: 10.682   Value Loss: 8.139    Reward Loss: 1.342    Consistency Loss: 0.000    ] Replay Episodes Collected: 374405     Buffer Size: 33754      Transition Number: 1000.054k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:23:52,569][train][INFO][train.py>_log] ==> #116000     Total Loss: 6.558    [weighted Loss:6.558    Policy Loss: 11.813   Value Loss: 11.450   Reward Loss: 1.307    Consistency Loss: 0.000    ] Replay Episodes Collected: 378806     Buffer Size: 35074      Transition Number: 1000.143k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:26:37,485][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.581    [weighted Loss:4.581    Policy Loss: 9.755    Value Loss: 7.310    Reward Loss: 1.500    Consistency Loss: 0.000    ] Replay Episodes Collected: 383665     Buffer Size: 36174      Transition Number: 1000.146k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:29:20,650][train][INFO][train.py>_log] ==> #118000     Total Loss: 5.778    [weighted Loss:5.778    Policy Loss: 9.997    Value Loss: 6.959    Reward Loss: 1.425    Consistency Loss: 0.000    ] Replay Episodes Collected: 388524     Buffer Size: 37201      Transition Number: 1000.258k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:32:07,332][train][INFO][train.py>_log] ==> #119000     Total Loss: 5.105    [weighted Loss:5.105    Policy Loss: 9.450    Value Loss: 7.169    Reward Loss: 1.675    Consistency Loss: 0.000    ] Replay Episodes Collected: 396163     Buffer Size: 40178      Transition Number: 999.957 k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:34:53,823][train][INFO][train.py>_log] ==> #120000     Total Loss: 4.412    [weighted Loss:4.412    Policy Loss: 9.275    Value Loss: 6.838    Reward Loss: 1.750    Consistency Loss: 0.000    ] Replay Episodes Collected: 403827     Buffer Size: 43183      Transition Number: 1000.180k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:37:40,519][train][INFO][train.py>_log] ==> #121000     Total Loss: 4.880    [weighted Loss:4.880    Policy Loss: 9.625    Value Loss: 6.648    Reward Loss: 1.925    Consistency Loss: 0.000    ] Replay Episodes Collected: 411869     Buffer Size: 45855      Transition Number: 1000.077k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:40:27,642][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.426    [weighted Loss:3.426    Policy Loss: 9.412    Value Loss: 6.529    Reward Loss: 1.833    Consistency Loss: 0.000    ] Replay Episodes Collected: 419881     Buffer Size: 48791      Transition Number: 1000.248k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:43:15,361][train][INFO][train.py>_log] ==> #123000     Total Loss: 5.454    [weighted Loss:5.454    Policy Loss: 9.324    Value Loss: 6.677    Reward Loss: 2.088    Consistency Loss: 0.000    ] Replay Episodes Collected: 428053     Buffer Size: 52125      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:46:04,150][train][INFO][train.py>_log] ==> #124000     Total Loss: 4.815    [weighted Loss:4.815    Policy Loss: 9.442    Value Loss: 6.781    Reward Loss: 2.126    Consistency Loss: 0.000    ] Replay Episodes Collected: 436144     Buffer Size: 55347      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:48:52,036][train][INFO][train.py>_log] ==> #125000     Total Loss: 5.109    [weighted Loss:5.109    Policy Loss: 9.173    Value Loss: 6.308    Reward Loss: 2.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 445085     Buffer Size: 58947      Transition Number: 1000.083k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:51:39,410][train][INFO][train.py>_log] ==> #126000     Total Loss: 5.490    [weighted Loss:5.490    Policy Loss: 9.270    Value Loss: 6.387    Reward Loss: 2.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 453923     Buffer Size: 61570      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:54:28,057][train][INFO][train.py>_log] ==> #127000     Total Loss: 3.539    [weighted Loss:3.539    Policy Loss: 9.058    Value Loss: 6.169    Reward Loss: 2.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 463279     Buffer Size: 63090      Transition Number: 1000.224k Batch Size: 256        Lr: 0.00100 
[2022-02-16 08:57:17,171][train][INFO][train.py>_log] ==> #128000     Total Loss: 4.639    [weighted Loss:4.639    Policy Loss: 9.656    Value Loss: 6.469    Reward Loss: 2.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 472734     Buffer Size: 64352      Transition Number: 1000.104k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:00:06,233][train][INFO][train.py>_log] ==> #129000     Total Loss: 4.125    [weighted Loss:4.125    Policy Loss: 8.733    Value Loss: 6.093    Reward Loss: 2.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 482096     Buffer Size: 65588      Transition Number: 1000.304k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:02:57,455][train][INFO][train.py>_log] ==> #130000     Total Loss: 4.621    [weighted Loss:4.621    Policy Loss: 9.139    Value Loss: 6.320    Reward Loss: 2.356    Consistency Loss: 0.000    ] Replay Episodes Collected: 491641     Buffer Size: 66766      Transition Number: 1000.339k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:05:48,017][train][INFO][train.py>_log] ==> #131000     Total Loss: 3.908    [weighted Loss:3.908    Policy Loss: 9.271    Value Loss: 6.692    Reward Loss: 2.255    Consistency Loss: 0.000    ] Replay Episodes Collected: 501388     Buffer Size: 68220      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:08:38,712][train][INFO][train.py>_log] ==> #132000     Total Loss: 4.631    [weighted Loss:4.631    Policy Loss: 9.010    Value Loss: 6.482    Reward Loss: 2.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 511255     Buffer Size: 69330      Transition Number: 1000.072k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:11:32,871][train][INFO][train.py>_log] ==> #133000     Total Loss: 4.848    [weighted Loss:4.848    Policy Loss: 8.769    Value Loss: 6.286    Reward Loss: 2.321    Consistency Loss: 0.000    ] Replay Episodes Collected: 524006     Buffer Size: 72573      Transition Number: 1000.086k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:14:28,974][train][INFO][train.py>_log] ==> #134000     Total Loss: 4.454    [weighted Loss:4.454    Policy Loss: 8.664    Value Loss: 6.100    Reward Loss: 2.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 536788     Buffer Size: 75576      Transition Number: 1000.221k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:17:27,086][train][INFO][train.py>_log] ==> #135000     Total Loss: 4.515    [weighted Loss:4.515    Policy Loss: 8.461    Value Loss: 6.145    Reward Loss: 2.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 550688     Buffer Size: 79273      Transition Number: 1000.126k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:20:23,540][train][INFO][train.py>_log] ==> #136000     Total Loss: 2.286    [weighted Loss:2.286    Policy Loss: 7.974    Value Loss: 5.982    Reward Loss: 2.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 564304     Buffer Size: 82869      Transition Number: 1000.096k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:23:22,310][train][INFO][train.py>_log] ==> #137000     Total Loss: 5.119    [weighted Loss:5.119    Policy Loss: 8.264    Value Loss: 6.227    Reward Loss: 2.375    Consistency Loss: 0.000    ] Replay Episodes Collected: 577523     Buffer Size: 85974      Transition Number: 1000.030k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:26:19,790][train][INFO][train.py>_log] ==> #138000     Total Loss: 4.453    [weighted Loss:4.453    Policy Loss: 8.294    Value Loss: 6.210    Reward Loss: 2.488    Consistency Loss: 0.000    ] Replay Episodes Collected: 590632     Buffer Size: 88745      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:29:23,543][train][INFO][train.py>_log] ==> #139000     Total Loss: 5.234    [weighted Loss:5.234    Policy Loss: 8.265    Value Loss: 6.526    Reward Loss: 2.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 604108     Buffer Size: 91379      Transition Number: 1000.048k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:32:21,558][train][INFO][train.py>_log] ==> #140000     Total Loss: 3.246    [weighted Loss:3.246    Policy Loss: 8.293    Value Loss: 6.393    Reward Loss: 2.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 617342     Buffer Size: 91485      Transition Number: 1000.047k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:35:21,128][train][INFO][train.py>_log] ==> #141000     Total Loss: 4.215    [weighted Loss:4.215    Policy Loss: 8.184    Value Loss: 6.234    Reward Loss: 2.544    Consistency Loss: 0.000    ] Replay Episodes Collected: 629917     Buffer Size: 90865      Transition Number: 1000.044k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:38:26,527][train][INFO][train.py>_log] ==> #142000     Total Loss: 4.528    [weighted Loss:4.528    Policy Loss: 8.397    Value Loss: 6.537    Reward Loss: 2.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 642860     Buffer Size: 89508      Transition Number: 1000.188k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:41:28,518][train][INFO][train.py>_log] ==> #143000     Total Loss: 5.070    [weighted Loss:5.070    Policy Loss: 8.810    Value Loss: 6.485    Reward Loss: 2.493    Consistency Loss: 0.000    ] Replay Episodes Collected: 655844     Buffer Size: 88603      Transition Number: 1000.177k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:44:27,832][train][INFO][train.py>_log] ==> #144000     Total Loss: 2.519    [weighted Loss:2.519    Policy Loss: 8.126    Value Loss: 5.923    Reward Loss: 2.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 668716     Buffer Size: 88088      Transition Number: 1000.157k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:47:30,328][train][INFO][train.py>_log] ==> #145000     Total Loss: 3.733    [weighted Loss:3.733    Policy Loss: 8.493    Value Loss: 6.564    Reward Loss: 2.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 679534     Buffer Size: 85895      Transition Number: 1000.087k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:50:31,305][train][INFO][train.py>_log] ==> #146000     Total Loss: 4.368    [weighted Loss:4.368    Policy Loss: 8.411    Value Loss: 6.384    Reward Loss: 2.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 690136     Buffer Size: 83288      Transition Number: 1000.257k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:53:31,565][train][INFO][train.py>_log] ==> #147000     Total Loss: 4.210    [weighted Loss:4.210    Policy Loss: 9.011    Value Loss: 6.267    Reward Loss: 2.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 699642     Buffer Size: 79787      Transition Number: 1000.105k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:56:29,429][train][INFO][train.py>_log] ==> #148000     Total Loss: 4.724    [weighted Loss:4.724    Policy Loss: 9.218    Value Loss: 6.631    Reward Loss: 2.285    Consistency Loss: 0.000    ] Replay Episodes Collected: 708805     Buffer Size: 76909      Transition Number: 1000.167k Batch Size: 256        Lr: 0.00100 
[2022-02-16 09:59:25,767][train][INFO][train.py>_log] ==> #149000     Total Loss: 2.031    [weighted Loss:2.031    Policy Loss: 9.628    Value Loss: 6.817    Reward Loss: 2.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 717673     Buffer Size: 73760      Transition Number: 1000.207k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:02:23,863][train][INFO][train.py>_log] ==> #150000     Total Loss: 5.017    [weighted Loss:5.017    Policy Loss: 9.173    Value Loss: 6.623    Reward Loss: 2.240    Consistency Loss: 0.000    ] Replay Episodes Collected: 726801     Buffer Size: 70365      Transition Number: 1000.098k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:05:21,662][train][INFO][train.py>_log] ==> #151000     Total Loss: 5.747    [weighted Loss:5.747    Policy Loss: 9.266    Value Loss: 6.879    Reward Loss: 2.338    Consistency Loss: 0.000    ] Replay Episodes Collected: 735528     Buffer Size: 66904      Transition Number: 1000.151k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:08:18,303][train][INFO][train.py>_log] ==> #152000     Total Loss: 4.656    [weighted Loss:4.656    Policy Loss: 9.232    Value Loss: 6.608    Reward Loss: 2.136    Consistency Loss: 0.000    ] Replay Episodes Collected: 744254     Buffer Size: 64994      Transition Number: 1000.017k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:11:14,006][train][INFO][train.py>_log] ==> #153000     Total Loss: 2.833    [weighted Loss:2.833    Policy Loss: 8.789    Value Loss: 6.642    Reward Loss: 2.224    Consistency Loss: 0.000    ] Replay Episodes Collected: 753230     Buffer Size: 63731      Transition Number: 1000.150k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:14:10,375][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.729    [weighted Loss:3.729    Policy Loss: 9.035    Value Loss: 7.047    Reward Loss: 2.177    Consistency Loss: 0.000    ] Replay Episodes Collected: 762093     Buffer Size: 63194      Transition Number: 1000.137k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:17:07,416][train][INFO][train.py>_log] ==> #155000     Total Loss: 5.347    [weighted Loss:5.347    Policy Loss: 8.842    Value Loss: 6.308    Reward Loss: 2.166    Consistency Loss: 0.000    ] Replay Episodes Collected: 771205     Buffer Size: 63102      Transition Number: 1000.050k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:20:03,375][train][INFO][train.py>_log] ==> #156000     Total Loss: 2.866    [weighted Loss:2.866    Policy Loss: 8.883    Value Loss: 6.760    Reward Loss: 2.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 780324     Buffer Size: 63247      Transition Number: 1000.142k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:23:00,861][train][INFO][train.py>_log] ==> #157000     Total Loss: 3.758    [weighted Loss:3.758    Policy Loss: 8.705    Value Loss: 6.487    Reward Loss: 2.247    Consistency Loss: 0.000    ] Replay Episodes Collected: 789779     Buffer Size: 63632      Transition Number: 1000.064k Batch Size: 256        Lr: 0.00100 
[2022-02-16 10:25:57,441][train][INFO][train.py>_log] ==> #158000     Total Loss: 5.554    [weighted Loss:5.554    Policy Loss: 9.201    Value Loss: 6.989    Reward Loss: 2.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 799297     Buffer Size: 64274      Transition Number: 1000.138k Batch Size: 256        Lr: 0.00100 
