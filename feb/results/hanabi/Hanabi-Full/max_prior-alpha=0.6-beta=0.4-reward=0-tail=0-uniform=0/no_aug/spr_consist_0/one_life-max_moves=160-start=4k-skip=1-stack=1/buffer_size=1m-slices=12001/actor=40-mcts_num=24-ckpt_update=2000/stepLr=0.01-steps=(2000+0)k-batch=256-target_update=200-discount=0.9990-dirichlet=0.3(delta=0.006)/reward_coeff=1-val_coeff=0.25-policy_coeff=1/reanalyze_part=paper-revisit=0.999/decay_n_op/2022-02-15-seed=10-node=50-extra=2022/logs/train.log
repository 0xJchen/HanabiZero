[2022-02-15 16:19:41,134][train][INFO][train.py>_log] ==> #0          Total Loss: 48.363   [weighted Loss:48.363   Policy Loss: 13.891   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1040       Buffer Size: 1040       Transition Number: 10.151  k Batch Size: 256        Lr: 0.00000 
[2022-02-15 16:22:15,710][train][INFO][train.py>_log] ==> #1000       Total Loss: 7.207    [weighted Loss:7.207    Policy Loss: 14.589   Value Loss: 5.194    Reward Loss: 1.631    Consistency Loss: 0.000    ] Replay Episodes Collected: 11462      Buffer Size: 11462      Transition Number: 141.101 k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:24:48,546][train][INFO][train.py>_log] ==> #2000       Total Loss: 7.848    [weighted Loss:7.848    Policy Loss: 14.892   Value Loss: 5.606    Reward Loss: 1.816    Consistency Loss: 0.000    ] Replay Episodes Collected: 21360      Buffer Size: 21360      Transition Number: 264.163 k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:27:21,852][train][INFO][train.py>_log] ==> #3000       Total Loss: 4.034    [weighted Loss:4.034    Policy Loss: 6.526    Value Loss: 5.776    Reward Loss: 2.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 34922      Buffer Size: 34922      Transition Number: 401.064 k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:29:56,195][train][INFO][train.py>_log] ==> #4000       Total Loss: 2.976    [weighted Loss:2.976    Policy Loss: 5.695    Value Loss: 5.974    Reward Loss: 2.300    Consistency Loss: 0.000    ] Replay Episodes Collected: 48586      Buffer Size: 48586      Transition Number: 537.710 k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:32:38,071][train][INFO][train.py>_log] ==> #5000       Total Loss: 2.795    [weighted Loss:2.795    Policy Loss: 6.913    Value Loss: 5.014    Reward Loss: 2.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 76777      Buffer Size: 76777      Transition Number: 689.379 k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:35:52,158][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.724    [weighted Loss:5.724    Policy Loss: 10.422   Value Loss: 4.542    Reward Loss: 2.403    Consistency Loss: 0.000    ] Replay Episodes Collected: 111061     Buffer Size: 111061     Transition Number: 870.119 k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:38:39,260][train][INFO][train.py>_log] ==> #7000       Total Loss: 5.891    [weighted Loss:5.891    Policy Loss: 11.456   Value Loss: 5.397    Reward Loss: 2.369    Consistency Loss: 0.000    ] Replay Episodes Collected: 122395     Buffer Size: 121624     Transition Number: 1000.074k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:41:32,350][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.084    [weighted Loss:5.084    Policy Loss: 11.612   Value Loss: 4.742    Reward Loss: 2.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 134238     Buffer Size: 121648     Transition Number: 1000.150k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:44:20,016][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.097    [weighted Loss:3.097    Policy Loss: 5.616    Value Loss: 4.626    Reward Loss: 1.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 141450     Buffer Size: 118688     Transition Number: 1000.345k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:47:11,160][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.544    [weighted Loss:5.544    Policy Loss: 13.125   Value Loss: 4.644    Reward Loss: 2.116    Consistency Loss: 0.000    ] Replay Episodes Collected: 148664     Buffer Size: 113099     Transition Number: 1000.151k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:50:07,529][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.634    [weighted Loss:5.634    Policy Loss: 10.894   Value Loss: 4.835    Reward Loss: 2.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 159831     Buffer Size: 106643     Transition Number: 1000.226k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:53:10,272][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.350    [weighted Loss:6.350    Policy Loss: 13.056   Value Loss: 4.913    Reward Loss: 1.945    Consistency Loss: 0.000    ] Replay Episodes Collected: 171695     Buffer Size: 88241      Transition Number: 1000.107k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:56:20,423][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.109    [weighted Loss:5.109    Policy Loss: 13.728   Value Loss: 5.594    Reward Loss: 1.949    Consistency Loss: 0.000    ] Replay Episodes Collected: 187682     Buffer Size: 73877      Transition Number: 1000.021k Batch Size: 256        Lr: 0.01000 
[2022-02-15 16:59:27,533][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.816    [weighted Loss:5.816    Policy Loss: 12.291   Value Loss: 5.376    Reward Loss: 2.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 203313     Buffer Size: 76104      Transition Number: 1000.169k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:03:06,283][train][INFO][train.py>_log] ==> #15000      Total Loss: 4.269    [weighted Loss:4.269    Policy Loss: 9.732    Value Loss: 5.671    Reward Loss: 2.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 232013     Buffer Size: 91692      Transition Number: 1000.131k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:06:39,017][train][INFO][train.py>_log] ==> #16000      Total Loss: 6.764    [weighted Loss:6.764    Policy Loss: 12.419   Value Loss: 4.815    Reward Loss: 2.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 259805     Buffer Size: 109260     Transition Number: 1000.108k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:10:19,193][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.467    [weighted Loss:2.467    Policy Loss: 3.313    Value Loss: 4.816    Reward Loss: 2.303    Consistency Loss: 0.000    ] Replay Episodes Collected: 289482     Buffer Size: 125022     Transition Number: 1000.104k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:14:06,048][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.243    [weighted Loss:2.243    Policy Loss: 1.284    Value Loss: 4.708    Reward Loss: 2.813    Consistency Loss: 0.000    ] Replay Episodes Collected: 319875     Buffer Size: 139467     Transition Number: 1000.264k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:17:49,014][train][INFO][train.py>_log] ==> #19000      Total Loss: 8.733    [weighted Loss:8.733    Policy Loss: 17.931   Value Loss: 6.676    Reward Loss: 2.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 347811     Buffer Size: 149796     Transition Number: 1000.125k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:21:36,135][train][INFO][train.py>_log] ==> #20000      Total Loss: 4.067    [weighted Loss:4.067    Policy Loss: 11.843   Value Loss: 5.457    Reward Loss: 2.507    Consistency Loss: 0.000    ] Replay Episodes Collected: 376278     Buffer Size: 152947     Transition Number: 1000.118k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:26:02,246][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.314    [weighted Loss:5.314    Policy Loss: 12.910   Value Loss: 4.795    Reward Loss: 2.710    Consistency Loss: 0.000    ] Replay Episodes Collected: 416749     Buffer Size: 158313     Transition Number: 1000.160k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:30:30,625][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.325    [weighted Loss:4.325    Policy Loss: 12.250   Value Loss: 4.391    Reward Loss: 2.820    Consistency Loss: 0.000    ] Replay Episodes Collected: 457311     Buffer Size: 162271     Transition Number: 1000.193k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:33:51,068][train][INFO][train.py>_log] ==> #23000      Total Loss: 6.028    [weighted Loss:6.028    Policy Loss: 11.560   Value Loss: 5.065    Reward Loss: 2.508    Consistency Loss: 0.000    ] Replay Episodes Collected: 473219     Buffer Size: 152366     Transition Number: 1000.158k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:37:06,444][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.395    [weighted Loss:4.395    Policy Loss: 8.164    Value Loss: 5.639    Reward Loss: 2.741    Consistency Loss: 0.000    ] Replay Episodes Collected: 488638     Buffer Size: 143899     Transition Number: 1000.184k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:41:20,458][train][INFO][train.py>_log] ==> #25000      Total Loss: 1.615    [weighted Loss:1.615    Policy Loss: 5.319    Value Loss: 5.059    Reward Loss: 2.086    Consistency Loss: 0.000    ] Replay Episodes Collected: 522088     Buffer Size: 138279     Transition Number: 1000.266k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:45:53,322][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.553    [weighted Loss:5.553    Policy Loss: 10.419   Value Loss: 4.779    Reward Loss: 1.815    Consistency Loss: 0.000    ] Replay Episodes Collected: 558623     Buffer Size: 126496     Transition Number: 1000.236k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:50:01,375][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.286    [weighted Loss:3.286    Policy Loss: 8.049    Value Loss: 4.545    Reward Loss: 1.952    Consistency Loss: 0.000    ] Replay Episodes Collected: 589342     Buffer Size: 123811     Transition Number: 1000.169k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:53:59,276][train][INFO][train.py>_log] ==> #28000      Total Loss: 7.087    [weighted Loss:7.087    Policy Loss: 13.269   Value Loss: 5.593    Reward Loss: 2.570    Consistency Loss: 0.000    ] Replay Episodes Collected: 618818     Buffer Size: 132759     Transition Number: 1000.180k Batch Size: 256        Lr: 0.01000 
[2022-02-15 17:57:36,416][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.161    [weighted Loss:3.161    Policy Loss: 6.889    Value Loss: 4.849    Reward Loss: 2.087    Consistency Loss: 0.000    ] Replay Episodes Collected: 640783     Buffer Size: 131270     Transition Number: 1000.154k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:01:17,748][train][INFO][train.py>_log] ==> #30000      Total Loss: 4.557    [weighted Loss:4.557    Policy Loss: 8.592    Value Loss: 5.461    Reward Loss: 2.024    Consistency Loss: 0.000    ] Replay Episodes Collected: 663310     Buffer Size: 128144     Transition Number: 1000.095k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:04:34,577][train][INFO][train.py>_log] ==> #31000      Total Loss: 2.473    [weighted Loss:2.473    Policy Loss: 4.942    Value Loss: 5.301    Reward Loss: 2.004    Consistency Loss: 0.000    ] Replay Episodes Collected: 675038     Buffer Size: 119681     Transition Number: 1000.091k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:07:46,774][train][INFO][train.py>_log] ==> #32000      Total Loss: 3.646    [weighted Loss:3.646    Policy Loss: 8.668    Value Loss: 4.646    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 686838     Buffer Size: 110563     Transition Number: 1000.042k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:10:51,561][train][INFO][train.py>_log] ==> #33000      Total Loss: 6.045    [weighted Loss:6.045    Policy Loss: 10.528   Value Loss: 5.050    Reward Loss: 1.993    Consistency Loss: 0.000    ] Replay Episodes Collected: 697597     Buffer Size: 101287     Transition Number: 1000.224k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:13:58,129][train][INFO][train.py>_log] ==> #34000      Total Loss: 5.156    [weighted Loss:5.156    Policy Loss: 10.877   Value Loss: 5.149    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 708620     Buffer Size: 92038      Transition Number: 1000.048k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:17:58,542][train][INFO][train.py>_log] ==> #35000      Total Loss: 6.410    [weighted Loss:6.410    Policy Loss: 13.308   Value Loss: 5.286    Reward Loss: 1.744    Consistency Loss: 0.000    ] Replay Episodes Collected: 738434     Buffer Size: 96116      Transition Number: 1000.289k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:22:02,233][train][INFO][train.py>_log] ==> #36000      Total Loss: 4.102    [weighted Loss:4.102    Policy Loss: 7.062    Value Loss: 4.742    Reward Loss: 1.884    Consistency Loss: 0.000    ] Replay Episodes Collected: 768801     Buffer Size: 102321     Transition Number: 1000.144k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:27:02,043][train][INFO][train.py>_log] ==> #37000      Total Loss: 1.595    [weighted Loss:1.595    Policy Loss: 2.368    Value Loss: 4.424    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 817948     Buffer Size: 130360     Transition Number: 1000.063k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:31:57,881][train][INFO][train.py>_log] ==> #38000      Total Loss: 3.940    [weighted Loss:3.940    Policy Loss: 11.806   Value Loss: 4.599    Reward Loss: 2.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 866843     Buffer Size: 158773     Transition Number: 1000.069k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:36:47,388][train][INFO][train.py>_log] ==> #39000      Total Loss: 3.737    [weighted Loss:3.737    Policy Loss: 7.727    Value Loss: 4.407    Reward Loss: 2.440    Consistency Loss: 0.000    ] Replay Episodes Collected: 913941     Buffer Size: 171570     Transition Number: 1000.182k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:41:44,093][train][INFO][train.py>_log] ==> #40000      Total Loss: 5.409    [weighted Loss:5.409    Policy Loss: 15.790   Value Loss: 5.023    Reward Loss: 3.673    Consistency Loss: 0.000    ] Replay Episodes Collected: 962195     Buffer Size: 181076     Transition Number: 1000.159k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:47:01,741][train][INFO][train.py>_log] ==> #41000      Total Loss: 5.155    [weighted Loss:5.155    Policy Loss: 8.642    Value Loss: 4.156    Reward Loss: 2.357    Consistency Loss: 0.000    ] Replay Episodes Collected: 1016754    Buffer Size: 187771     Transition Number: 1000.137k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:52:34,409][train][INFO][train.py>_log] ==> #42000      Total Loss: 4.249    [weighted Loss:4.249    Policy Loss: 12.378   Value Loss: 4.109    Reward Loss: 2.979    Consistency Loss: 0.000    ] Replay Episodes Collected: 1073962    Buffer Size: 194205     Transition Number: 1000.107k Batch Size: 256        Lr: 0.01000 
[2022-02-15 18:56:35,749][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.627    [weighted Loss:2.627    Policy Loss: 5.056    Value Loss: 4.790    Reward Loss: 2.563    Consistency Loss: 0.000    ] Replay Episodes Collected: 1101271    Buffer Size: 183862     Transition Number: 1000.122k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:00:44,455][train][INFO][train.py>_log] ==> #44000      Total Loss: 4.989    [weighted Loss:4.989    Policy Loss: 9.131    Value Loss: 4.761    Reward Loss: 2.581    Consistency Loss: 0.000    ] Replay Episodes Collected: 1129418    Buffer Size: 172925     Transition Number: 1000.299k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:04:18,913][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.822    [weighted Loss:2.822    Policy Loss: 7.713    Value Loss: 4.751    Reward Loss: 2.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 1147910    Buffer Size: 156348     Transition Number: 1000.236k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:07:52,740][train][INFO][train.py>_log] ==> #46000      Total Loss: 6.479    [weighted Loss:6.479    Policy Loss: 13.928   Value Loss: 4.891    Reward Loss: 2.150    Consistency Loss: 0.000    ] Replay Episodes Collected: 1166195    Buffer Size: 138877     Transition Number: 1000.160k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:16:47,513][train][INFO][train.py>_log] ==> #47000      Total Loss: 3.347    [weighted Loss:3.347    Policy Loss: 6.672    Value Loss: 4.011    Reward Loss: 2.202    Consistency Loss: 0.000    ] Replay Episodes Collected: 1282386    Buffer Size: 167237     Transition Number: 1000.122k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:24:56,881][train][INFO][train.py>_log] ==> #48000      Total Loss: 4.722    [weighted Loss:4.722    Policy Loss: 8.218    Value Loss: 3.619    Reward Loss: 2.343    Consistency Loss: 0.000    ] Replay Episodes Collected: 1390010    Buffer Size: 217851     Transition Number: 1000.170k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:29:00,995][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.195    [weighted Loss:2.195    Policy Loss: 6.394    Value Loss: 4.438    Reward Loss: 2.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 1414909    Buffer Size: 189872     Transition Number: 1000.264k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:32:50,983][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.961    [weighted Loss:2.961    Policy Loss: 7.731    Value Loss: 3.822    Reward Loss: 1.978    Consistency Loss: 0.000    ] Replay Episodes Collected: 1438368    Buffer Size: 163086     Transition Number: 1000.289k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:36:14,257][train][INFO][train.py>_log] ==> #51000      Total Loss: 2.636    [weighted Loss:2.636    Policy Loss: 7.911    Value Loss: 4.134    Reward Loss: 2.048    Consistency Loss: 0.000    ] Replay Episodes Collected: 1451056    Buffer Size: 137624     Transition Number: 1000.221k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:39:28,683][train][INFO][train.py>_log] ==> #52000      Total Loss: 1.574    [weighted Loss:1.574    Policy Loss: 2.367    Value Loss: 4.614    Reward Loss: 1.869    Consistency Loss: 0.000    ] Replay Episodes Collected: 1462937    Buffer Size: 111858     Transition Number: 1000.333k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:42:35,337][train][INFO][train.py>_log] ==> #53000      Total Loss: 2.772    [weighted Loss:2.772    Policy Loss: 4.402    Value Loss: 4.622    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1467612    Buffer Size: 87470      Transition Number: 1000.208k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:45:36,225][train][INFO][train.py>_log] ==> #54000      Total Loss: 3.047    [weighted Loss:3.047    Policy Loss: 5.140    Value Loss: 5.073    Reward Loss: 1.731    Consistency Loss: 0.000    ] Replay Episodes Collected: 1472249    Buffer Size: 72867      Transition Number: 1000.261k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:51:18,229][train][INFO][train.py>_log] ==> #55000      Total Loss: 4.751    [weighted Loss:4.751    Policy Loss: 10.270   Value Loss: 4.551    Reward Loss: 2.100    Consistency Loss: 0.000    ] Replay Episodes Collected: 1533567    Buffer Size: 100484     Transition Number: 1000.119k Batch Size: 256        Lr: 0.01000 
[2022-02-15 19:57:02,778][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.142    [weighted Loss:3.142    Policy Loss: 8.874    Value Loss: 4.090    Reward Loss: 2.335    Consistency Loss: 0.000    ] Replay Episodes Collected: 1595614    Buffer Size: 138111     Transition Number: 1000.151k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:00:59,432][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.247    [weighted Loss:3.247    Policy Loss: 6.731    Value Loss: 4.161    Reward Loss: 1.983    Consistency Loss: 0.000    ] Replay Episodes Collected: 1621528    Buffer Size: 154323     Transition Number: 1000.114k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:04:48,649][train][INFO][train.py>_log] ==> #58000      Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 7.826    Value Loss: 4.549    Reward Loss: 2.299    Consistency Loss: 0.000    ] Replay Episodes Collected: 1645898    Buffer Size: 168114     Transition Number: 1000.167k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:08:20,281][train][INFO][train.py>_log] ==> #59000      Total Loss: 4.409    [weighted Loss:4.409    Policy Loss: 10.059   Value Loss: 5.748    Reward Loss: 2.049    Consistency Loss: 0.000    ] Replay Episodes Collected: 1660170    Buffer Size: 147298     Transition Number: 1000.220k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:11:42,440][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.953    [weighted Loss:2.953    Policy Loss: 3.827    Value Loss: 5.100    Reward Loss: 2.434    Consistency Loss: 0.000    ] Replay Episodes Collected: 1673793    Buffer Size: 126946     Transition Number: 1000.126k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:15:14,815][train][INFO][train.py>_log] ==> #61000      Total Loss: 5.437    [weighted Loss:5.437    Policy Loss: 11.977   Value Loss: 5.073    Reward Loss: 2.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 1688043    Buffer Size: 105820     Transition Number: 1000.158k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:18:33,714][train][INFO][train.py>_log] ==> #62000      Total Loss: 5.182    [weighted Loss:5.182    Policy Loss: 10.460   Value Loss: 5.000    Reward Loss: 1.895    Consistency Loss: 0.000    ] Replay Episodes Collected: 1701427    Buffer Size: 92506      Transition Number: 1000.042k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:24:43,317][train][INFO][train.py>_log] ==> #63000      Total Loss: 2.614    [weighted Loss:2.614    Policy Loss: 3.753    Value Loss: 5.290    Reward Loss: 2.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 1771306    Buffer Size: 120295     Transition Number: 1000.154k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:31:42,596][train][INFO][train.py>_log] ==> #64000      Total Loss: 1.960    [weighted Loss:1.960    Policy Loss: 3.112    Value Loss: 3.928    Reward Loss: 2.401    Consistency Loss: 0.000    ] Replay Episodes Collected: 1851761    Buffer Size: 169596     Transition Number: 1000.105k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:35:17,820][train][INFO][train.py>_log] ==> #65000      Total Loss: 4.157    [weighted Loss:4.157    Policy Loss: 12.719   Value Loss: 5.305    Reward Loss: 2.571    Consistency Loss: 0.000    ] Replay Episodes Collected: 1870419    Buffer Size: 174956     Transition Number: 1000.051k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:38:52,279][train][INFO][train.py>_log] ==> #66000      Total Loss: 2.903    [weighted Loss:2.903    Policy Loss: 8.782    Value Loss: 3.923    Reward Loss: 2.510    Consistency Loss: 0.000    ] Replay Episodes Collected: 1889576    Buffer Size: 167963     Transition Number: 1000.200k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:42:01,094][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.199    [weighted Loss:3.199    Policy Loss: 9.600    Value Loss: 4.903    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 1895456    Buffer Size: 146108     Transition Number: 1000.254k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:45:10,102][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.630    [weighted Loss:4.630    Policy Loss: 10.792   Value Loss: 4.575    Reward Loss: 1.783    Consistency Loss: 0.000    ] Replay Episodes Collected: 1901392    Buffer Size: 122874     Transition Number: 1000.017k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:49:33,943][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.713    [weighted Loss:2.713    Policy Loss: 7.397    Value Loss: 4.750    Reward Loss: 1.786    Consistency Loss: 0.000    ] Replay Episodes Collected: 1937197    Buffer Size: 110262     Transition Number: 1000.148k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:54:04,974][train][INFO][train.py>_log] ==> #70000      Total Loss: 4.629    [weighted Loss:4.629    Policy Loss: 14.803   Value Loss: 5.766    Reward Loss: 2.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 1974236    Buffer Size: 109467     Transition Number: 1000.160k Batch Size: 256        Lr: 0.01000 
[2022-02-15 20:59:16,121][train][INFO][train.py>_log] ==> #71000      Total Loss: 4.206    [weighted Loss:4.206    Policy Loss: 8.371    Value Loss: 4.726    Reward Loss: 2.249    Consistency Loss: 0.000    ] Replay Episodes Collected: 2025313    Buffer Size: 134834     Transition Number: 1000.132k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:04:36,845][train][INFO][train.py>_log] ==> #72000      Total Loss: 4.462    [weighted Loss:4.462    Policy Loss: 10.677   Value Loss: 5.107    Reward Loss: 3.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 2078001    Buffer Size: 176703     Transition Number: 1000.055k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:08:26,987][train][INFO][train.py>_log] ==> #73000      Total Loss: 4.936    [weighted Loss:4.936    Policy Loss: 11.183   Value Loss: 4.446    Reward Loss: 2.213    Consistency Loss: 0.000    ] Replay Episodes Collected: 2099428    Buffer Size: 170694     Transition Number: 1000.129k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:12:06,628][train][INFO][train.py>_log] ==> #74000      Total Loss: 4.000    [weighted Loss:4.000    Policy Loss: 11.954   Value Loss: 4.777    Reward Loss: 2.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 2119780    Buffer Size: 162513     Transition Number: 1000.112k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:16:28,617][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 9.087    Value Loss: 4.718    Reward Loss: 2.455    Consistency Loss: 0.000    ] Replay Episodes Collected: 2153453    Buffer Size: 156077     Transition Number: 1000.187k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:20:48,006][train][INFO][train.py>_log] ==> #76000      Total Loss: 3.240    [weighted Loss:3.240    Policy Loss: 10.487   Value Loss: 5.082    Reward Loss: 2.274    Consistency Loss: 0.000    ] Replay Episodes Collected: 2186890    Buffer Size: 145235     Transition Number: 1000.159k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:26:33,882][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.512    [weighted Loss:4.512    Policy Loss: 12.009   Value Loss: 4.904    Reward Loss: 2.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 2248024    Buffer Size: 156389     Transition Number: 1000.059k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:32:36,810][train][INFO][train.py>_log] ==> #78000      Total Loss: 1.607    [weighted Loss:1.607    Policy Loss: 6.922    Value Loss: 3.865    Reward Loss: 2.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 2312430    Buffer Size: 183487     Transition Number: 1000.170k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:37:35,099][train][INFO][train.py>_log] ==> #79000      Total Loss: 2.667    [weighted Loss:2.667    Policy Loss: 4.713    Value Loss: 4.150    Reward Loss: 2.580    Consistency Loss: 0.000    ] Replay Episodes Collected: 2356902    Buffer Size: 191166     Transition Number: 1000.051k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:42:23,274][train][INFO][train.py>_log] ==> #80000      Total Loss: 5.456    [weighted Loss:5.456    Policy Loss: 9.481    Value Loss: 3.958    Reward Loss: 2.520    Consistency Loss: 0.000    ] Replay Episodes Collected: 2399645    Buffer Size: 193419     Transition Number: 1000.239k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:46:33,922][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.140    [weighted Loss:3.140    Policy Loss: 4.720    Value Loss: 4.717    Reward Loss: 2.956    Consistency Loss: 0.000    ] Replay Episodes Collected: 2428383    Buffer Size: 180948     Transition Number: 1000.091k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:50:47,445][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.191    [weighted Loss:3.191    Policy Loss: 7.278    Value Loss: 4.703    Reward Loss: 2.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 2457290    Buffer Size: 168222     Transition Number: 1000.146k Batch Size: 256        Lr: 0.01000 
[2022-02-15 21:57:50,206][train][INFO][train.py>_log] ==> #83000      Total Loss: 2.964    [weighted Loss:2.964    Policy Loss: 5.975    Value Loss: 4.608    Reward Loss: 2.353    Consistency Loss: 0.000    ] Replay Episodes Collected: 2538060    Buffer Size: 166590     Transition Number: 1000.249k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:05:32,601][train][INFO][train.py>_log] ==> #84000      Total Loss: 7.217    [weighted Loss:7.217    Policy Loss: 13.525   Value Loss: 3.814    Reward Loss: 2.135    Consistency Loss: 0.000    ] Replay Episodes Collected: 2626916    Buffer Size: 181419     Transition Number: 1000.134k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:15:08,615][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.133    [weighted Loss:3.133    Policy Loss: 3.660    Value Loss: 3.534    Reward Loss: 2.301    Consistency Loss: 0.000    ] Replay Episodes Collected: 2757217    Buffer Size: 206896     Transition Number: 1000.121k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:26:10,718][train][INFO][train.py>_log] ==> #86000      Total Loss: 1.988    [weighted Loss:1.988    Policy Loss: 3.702    Value Loss: 3.182    Reward Loss: 2.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 2907220    Buffer Size: 222579     Transition Number: 1000.108k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:32:20,461][train][INFO][train.py>_log] ==> #87000      Total Loss: 1.833    [weighted Loss:1.833    Policy Loss: 6.433    Value Loss: 2.989    Reward Loss: 2.114    Consistency Loss: 0.000    ] Replay Episodes Collected: 2968978    Buffer Size: 210861     Transition Number: 1000.102k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:38:37,444][train][INFO][train.py>_log] ==> #88000      Total Loss: 3.396    [weighted Loss:3.396    Policy Loss: 9.284    Value Loss: 3.631    Reward Loss: 2.415    Consistency Loss: 0.000    ] Replay Episodes Collected: 3031386    Buffer Size: 199097     Transition Number: 1000.094k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:42:39,393][train][INFO][train.py>_log] ==> #89000      Total Loss: 3.311    [weighted Loss:3.311    Policy Loss: 6.649    Value Loss: 4.477    Reward Loss: 3.085    Consistency Loss: 0.000    ] Replay Episodes Collected: 3053758    Buffer Size: 174837     Transition Number: 1000.146k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:46:38,279][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.223    [weighted Loss:3.223    Policy Loss: 4.434    Value Loss: 4.730    Reward Loss: 2.332    Consistency Loss: 0.000    ] Replay Episodes Collected: 3075852    Buffer Size: 153189     Transition Number: 1000.101k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:50:13,829][train][INFO][train.py>_log] ==> #91000      Total Loss: 5.084    [weighted Loss:5.084    Policy Loss: 13.863   Value Loss: 5.238    Reward Loss: 2.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 3090720    Buffer Size: 132260     Transition Number: 1000.130k Batch Size: 256        Lr: 0.01000 
[2022-02-15 22:53:44,862][train][INFO][train.py>_log] ==> #92000      Total Loss: 1.597    [weighted Loss:1.597    Policy Loss: 1.660    Value Loss: 4.950    Reward Loss: 2.143    Consistency Loss: 0.000    ] Replay Episodes Collected: 3105354    Buffer Size: 111420     Transition Number: 1000.114k Batch Size: 256        Lr: 0.01000 
[2022-02-15 23:02:24,468][train][INFO][train.py>_log] ==> #93000      Total Loss: 1.534    [weighted Loss:1.534    Policy Loss: 1.297    Value Loss: 4.073    Reward Loss: 1.862    Consistency Loss: 0.000    ] Replay Episodes Collected: 3212897    Buffer Size: 146768     Transition Number: 1000.096k Batch Size: 256        Lr: 0.01000 
[2022-02-15 23:11:23,020][train][INFO][train.py>_log] ==> #94000      Total Loss: 7.880    [weighted Loss:7.880    Policy Loss: 16.138   Value Loss: 3.833    Reward Loss: 2.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 3325300    Buffer Size: 206080     Transition Number: 1000.101k Batch Size: 256        Lr: 0.01000 
[2022-02-15 23:24:38,464][train][INFO][train.py>_log] ==> #95000      Total Loss: 2.656    [weighted Loss:2.656    Policy Loss: 4.547    Value Loss: 3.807    Reward Loss: 2.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 3514303    Buffer Size: 225477     Transition Number: 1000.138k Batch Size: 256        Lr: 0.01000 
