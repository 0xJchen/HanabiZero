[2022-03-07 12:31:10,950][train][INFO][train.py>_log] ==> #0          Total Loss: 48.608   [weighted Loss:48.608   Policy Loss: 14.136   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1371       Buffer Size: 1371       Transition Number: 15.291  k Batch Size: 256        Lr: 0.00000 
[2022-03-07 12:34:05,285][train][INFO][train.py>_log] ==> #1000       Total Loss: 6.339    [weighted Loss:6.339    Policy Loss: 12.697   Value Loss: 5.213    Reward Loss: 2.407    Consistency Loss: 0.000    ] Replay Episodes Collected: 12794      Buffer Size: 12794      Transition Number: 126.124 k Batch Size: 256        Lr: 0.05000 
[2022-03-07 12:36:58,621][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.311    [weighted Loss:6.311    Policy Loss: 12.553   Value Loss: 5.155    Reward Loss: 2.551    Consistency Loss: 0.000    ] Replay Episodes Collected: 28599      Buffer Size: 28599      Transition Number: 239.076 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 12:39:53,931][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.984    [weighted Loss:5.984    Policy Loss: 11.198   Value Loss: 4.798    Reward Loss: 2.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 44807      Buffer Size: 44807      Transition Number: 351.612 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 12:42:50,349][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.323    [weighted Loss:6.323    Policy Loss: 10.437   Value Loss: 4.878    Reward Loss: 2.554    Consistency Loss: 0.000    ] Replay Episodes Collected: 61537      Buffer Size: 61537      Transition Number: 461.441 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 12:45:46,881][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.017    [weighted Loss:5.017    Policy Loss: 9.036    Value Loss: 4.483    Reward Loss: 2.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 81237      Buffer Size: 81237      Transition Number: 572.231 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 12:48:43,552][train][INFO][train.py>_log] ==> #6000       Total Loss: 4.134    [weighted Loss:4.134    Policy Loss: 6.884    Value Loss: 4.370    Reward Loss: 2.498    Consistency Loss: 0.000    ] Replay Episodes Collected: 104521     Buffer Size: 104521     Transition Number: 682.793 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 12:51:48,537][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.018    [weighted Loss:3.018    Policy Loss: 3.625    Value Loss: 4.064    Reward Loss: 2.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 130472     Buffer Size: 130472     Transition Number: 798.382 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 12:55:01,581][train][INFO][train.py>_log] ==> #8000       Total Loss: 2.554    [weighted Loss:2.554    Policy Loss: 3.318    Value Loss: 4.016    Reward Loss: 2.445    Consistency Loss: 0.000    ] Replay Episodes Collected: 156121     Buffer Size: 156121     Transition Number: 921.817 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 12:58:20,493][train][INFO][train.py>_log] ==> #9000       Total Loss: 2.662    [weighted Loss:2.662    Policy Loss: 4.175    Value Loss: 4.336    Reward Loss: 2.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 175590     Buffer Size: 171826     Transition Number: 1000.225k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:01:49,957][train][INFO][train.py>_log] ==> #10000      Total Loss: 4.654    [weighted Loss:4.654    Policy Loss: 9.358    Value Loss: 5.202    Reward Loss: 2.312    Consistency Loss: 0.000    ] Replay Episodes Collected: 193611     Buffer Size: 173600     Transition Number: 1000.138k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:05:03,496][train][INFO][train.py>_log] ==> #11000      Total Loss: 5.443    [weighted Loss:5.443    Policy Loss: 11.248   Value Loss: 5.172    Reward Loss: 2.208    Consistency Loss: 0.000    ] Replay Episodes Collected: 206067     Buffer Size: 168026     Transition Number: 1000.003k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:08:18,562][train][INFO][train.py>_log] ==> #12000      Total Loss: 6.339    [weighted Loss:6.339    Policy Loss: 11.811   Value Loss: 5.358    Reward Loss: 1.953    Consistency Loss: 0.000    ] Replay Episodes Collected: 217897     Buffer Size: 160770     Transition Number: 1000.000k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:11:35,276][train][INFO][train.py>_log] ==> #13000      Total Loss: 5.560    [weighted Loss:5.560    Policy Loss: 11.904   Value Loss: 5.618    Reward Loss: 2.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 229980     Buffer Size: 150940     Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:14:50,573][train][INFO][train.py>_log] ==> #14000      Total Loss: 5.290    [weighted Loss:5.290    Policy Loss: 12.846   Value Loss: 6.059    Reward Loss: 2.003    Consistency Loss: 0.000    ] Replay Episodes Collected: 240254     Buffer Size: 134851     Transition Number: 1000.128k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:18:06,758][train][INFO][train.py>_log] ==> #15000      Total Loss: 7.434    [weighted Loss:7.434    Policy Loss: 13.412   Value Loss: 5.592    Reward Loss: 1.901    Consistency Loss: 0.000    ] Replay Episodes Collected: 249781     Buffer Size: 115480     Transition Number: 1000.113k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:21:24,878][train][INFO][train.py>_log] ==> #16000      Total Loss: 6.874    [weighted Loss:6.874    Policy Loss: 13.404   Value Loss: 5.540    Reward Loss: 1.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 259532     Buffer Size: 99035      Transition Number: 1000.242k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:24:36,105][train][INFO][train.py>_log] ==> #17000      Total Loss: 6.827    [weighted Loss:6.827    Policy Loss: 13.294   Value Loss: 5.512    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 269350     Buffer Size: 90756      Transition Number: 1000.106k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:27:45,687][train][INFO][train.py>_log] ==> #18000      Total Loss: 6.763    [weighted Loss:6.763    Policy Loss: 12.175   Value Loss: 5.491    Reward Loss: 1.674    Consistency Loss: 0.000    ] Replay Episodes Collected: 276568     Buffer Size: 82582      Transition Number: 1000.177k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:30:52,847][train][INFO][train.py>_log] ==> #19000      Total Loss: 6.888    [weighted Loss:6.888    Policy Loss: 13.517   Value Loss: 5.641    Reward Loss: 1.865    Consistency Loss: 0.000    ] Replay Episodes Collected: 283184     Buffer Size: 78158      Transition Number: 1000.156k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:34:03,411][train][INFO][train.py>_log] ==> #20000      Total Loss: 6.538    [weighted Loss:6.538    Policy Loss: 13.308   Value Loss: 5.005    Reward Loss: 1.711    Consistency Loss: 0.000    ] Replay Episodes Collected: 292044     Buffer Size: 76065      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:37:15,386][train][INFO][train.py>_log] ==> #21000      Total Loss: 5.553    [weighted Loss:5.553    Policy Loss: 13.447   Value Loss: 4.547    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 302814     Buffer Size: 75746      Transition Number: 1000.092k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:40:25,089][train][INFO][train.py>_log] ==> #22000      Total Loss: 4.294    [weighted Loss:4.294    Policy Loss: 11.926   Value Loss: 4.353    Reward Loss: 1.877    Consistency Loss: 0.000    ] Replay Episodes Collected: 311938     Buffer Size: 75123      Transition Number: 1000.039k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:43:33,919][train][INFO][train.py>_log] ==> #23000      Total Loss: 5.911    [weighted Loss:5.911    Policy Loss: 11.867   Value Loss: 3.978    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 319891     Buffer Size: 74717      Transition Number: 1000.116k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:46:41,703][train][INFO][train.py>_log] ==> #24000      Total Loss: 6.758    [weighted Loss:6.758    Policy Loss: 12.201   Value Loss: 4.359    Reward Loss: 1.667    Consistency Loss: 0.000    ] Replay Episodes Collected: 325147     Buffer Size: 72753      Transition Number: 1000.097k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:49:45,411][train][INFO][train.py>_log] ==> #25000      Total Loss: 5.852    [weighted Loss:5.852    Policy Loss: 13.078   Value Loss: 4.233    Reward Loss: 1.561    Consistency Loss: 0.000    ] Replay Episodes Collected: 329092     Buffer Size: 68455      Transition Number: 1000.151k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:52:51,296][train][INFO][train.py>_log] ==> #26000      Total Loss: 5.651    [weighted Loss:5.651    Policy Loss: 10.873   Value Loss: 3.942    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 333161     Buffer Size: 64052      Transition Number: 1000.099k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:55:53,850][train][INFO][train.py>_log] ==> #27000      Total Loss: 6.009    [weighted Loss:6.009    Policy Loss: 13.592   Value Loss: 3.596    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 336326     Buffer Size: 61072      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-03-07 13:59:00,012][train][INFO][train.py>_log] ==> #28000      Total Loss: 3.890    [weighted Loss:3.890    Policy Loss: 10.390   Value Loss: 3.915    Reward Loss: 1.373    Consistency Loss: 0.000    ] Replay Episodes Collected: 339596     Buffer Size: 58614      Transition Number: 1000.029k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:02:03,032][train][INFO][train.py>_log] ==> #29000      Total Loss: 2.911    [weighted Loss:2.911    Policy Loss: 6.322    Value Loss: 3.647    Reward Loss: 1.192    Consistency Loss: 0.000    ] Replay Episodes Collected: 342769     Buffer Size: 55106      Transition Number: 1000.102k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:05:06,751][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.174    [weighted Loss:3.174    Policy Loss: 9.760    Value Loss: 3.968    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 346343     Buffer Size: 50697      Transition Number: 1000.088k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:08:13,404][train][INFO][train.py>_log] ==> #31000      Total Loss: 6.476    [weighted Loss:6.476    Policy Loss: 12.086   Value Loss: 3.867    Reward Loss: 1.220    Consistency Loss: 0.000    ] Replay Episodes Collected: 351603     Buffer Size: 45235      Transition Number: 1000.189k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:11:19,971][train][INFO][train.py>_log] ==> #32000      Total Loss: 6.096    [weighted Loss:6.096    Policy Loss: 10.860   Value Loss: 4.070    Reward Loss: 1.276    Consistency Loss: 0.000    ] Replay Episodes Collected: 358209     Buffer Size: 43720      Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:14:27,595][train][INFO][train.py>_log] ==> #33000      Total Loss: 4.532    [weighted Loss:4.532    Policy Loss: 8.027    Value Loss: 6.135    Reward Loss: 1.272    Consistency Loss: 0.000    ] Replay Episodes Collected: 362749     Buffer Size: 41182      Transition Number: 1000.072k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:17:33,112][train][INFO][train.py>_log] ==> #34000      Total Loss: 6.030    [weighted Loss:6.030    Policy Loss: 11.433   Value Loss: 6.404    Reward Loss: 1.118    Consistency Loss: 0.000    ] Replay Episodes Collected: 367686     Buffer Size: 41528      Transition Number: 1000.174k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:20:37,939][train][INFO][train.py>_log] ==> #35000      Total Loss: 6.281    [weighted Loss:6.281    Policy Loss: 14.632   Value Loss: 5.931    Reward Loss: 1.161    Consistency Loss: 0.000    ] Replay Episodes Collected: 373124     Buffer Size: 42770      Transition Number: 1000.156k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:23:42,918][train][INFO][train.py>_log] ==> #36000      Total Loss: 5.775    [weighted Loss:5.775    Policy Loss: 10.950   Value Loss: 6.173    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 380971     Buffer Size: 46477      Transition Number: 1000.234k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:26:50,323][train][INFO][train.py>_log] ==> #37000      Total Loss: 6.222    [weighted Loss:6.222    Policy Loss: 13.196   Value Loss: 5.911    Reward Loss: 1.429    Consistency Loss: 0.000    ] Replay Episodes Collected: 388088     Buffer Size: 50197      Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:29:57,238][train][INFO][train.py>_log] ==> #38000      Total Loss: 6.518    [weighted Loss:6.518    Policy Loss: 12.682   Value Loss: 5.563    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 393351     Buffer Size: 52017      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:33:03,200][train][INFO][train.py>_log] ==> #39000      Total Loss: 5.096    [weighted Loss:5.096    Policy Loss: 12.088   Value Loss: 5.855    Reward Loss: 1.185    Consistency Loss: 0.000    ] Replay Episodes Collected: 397795     Buffer Size: 52909      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:36:12,043][train][INFO][train.py>_log] ==> #40000      Total Loss: 5.556    [weighted Loss:5.556    Policy Loss: 11.525   Value Loss: 5.898    Reward Loss: 1.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 401980     Buffer Size: 53357      Transition Number: 1000.282k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:39:19,183][train][INFO][train.py>_log] ==> #41000      Total Loss: 2.586    [weighted Loss:2.586    Policy Loss: 7.185    Value Loss: 4.450    Reward Loss: 1.182    Consistency Loss: 0.000    ] Replay Episodes Collected: 404781     Buffer Size: 50935      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:42:24,391][train][INFO][train.py>_log] ==> #42000      Total Loss: 2.201    [weighted Loss:2.201    Policy Loss: 6.585    Value Loss: 3.691    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 406448     Buffer Size: 47392      Transition Number: 1000.185k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:45:33,281][train][INFO][train.py>_log] ==> #43000      Total Loss: 2.363    [weighted Loss:2.363    Policy Loss: 5.636    Value Loss: 3.175    Reward Loss: 0.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 408185     Buffer Size: 45521      Transition Number: 1000.318k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:48:40,329][train][INFO][train.py>_log] ==> #44000      Total Loss: 2.143    [weighted Loss:2.143    Policy Loss: 5.781    Value Loss: 3.455    Reward Loss: 1.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 410325     Buffer Size: 43203      Transition Number: 1000.135k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:51:46,736][train][INFO][train.py>_log] ==> #45000      Total Loss: 2.256    [weighted Loss:2.256    Policy Loss: 5.744    Value Loss: 3.468    Reward Loss: 0.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 412504     Buffer Size: 40811      Transition Number: 1000.039k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:54:54,133][train][INFO][train.py>_log] ==> #46000      Total Loss: 2.590    [weighted Loss:2.590    Policy Loss: 5.587    Value Loss: 3.208    Reward Loss: 0.858    Consistency Loss: 0.000    ] Replay Episodes Collected: 414451     Buffer Size: 37258      Transition Number: 1000.244k Batch Size: 256        Lr: 0.10000 
[2022-03-07 14:58:02,016][train][INFO][train.py>_log] ==> #47000      Total Loss: 2.712    [weighted Loss:2.712    Policy Loss: 5.707    Value Loss: 3.263    Reward Loss: 0.765    Consistency Loss: 0.000    ] Replay Episodes Collected: 417237     Buffer Size: 32813      Transition Number: 999.990 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:01:07,115][train][INFO][train.py>_log] ==> #48000      Total Loss: 3.170    [weighted Loss:3.170    Policy Loss: 6.672    Value Loss: 3.244    Reward Loss: 0.887    Consistency Loss: 0.000    ] Replay Episodes Collected: 421746     Buffer Size: 30804      Transition Number: 1000.073k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:04:16,309][train][INFO][train.py>_log] ==> #49000      Total Loss: 2.362    [weighted Loss:2.362    Policy Loss: 5.446    Value Loss: 4.124    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 428418     Buffer Size: 32370      Transition Number: 1000.044k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:07:21,857][train][INFO][train.py>_log] ==> #50000      Total Loss: 2.889    [weighted Loss:2.889    Policy Loss: 5.535    Value Loss: 4.136    Reward Loss: 1.072    Consistency Loss: 0.000    ] Replay Episodes Collected: 436306     Buffer Size: 35649      Transition Number: 999.970 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:10:26,361][train][INFO][train.py>_log] ==> #51000      Total Loss: 3.069    [weighted Loss:3.069    Policy Loss: 6.028    Value Loss: 4.110    Reward Loss: 1.043    Consistency Loss: 0.000    ] Replay Episodes Collected: 444125     Buffer Size: 39733      Transition Number: 1000.017k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:13:34,618][train][INFO][train.py>_log] ==> #52000      Total Loss: 3.090    [weighted Loss:3.090    Policy Loss: 6.204    Value Loss: 4.246    Reward Loss: 1.053    Consistency Loss: 0.000    ] Replay Episodes Collected: 450889     Buffer Size: 44409      Transition Number: 1000.264k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:16:39,278][train][INFO][train.py>_log] ==> #53000      Total Loss: 1.715    [weighted Loss:1.715    Policy Loss: 3.927    Value Loss: 3.787    Reward Loss: 1.239    Consistency Loss: 0.000    ] Replay Episodes Collected: 459519     Buffer Size: 50822      Transition Number: 999.989 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:19:46,211][train][INFO][train.py>_log] ==> #54000      Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 4.487    Value Loss: 4.564    Reward Loss: 1.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 469632     Buffer Size: 58346      Transition Number: 1000.126k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:22:53,800][train][INFO][train.py>_log] ==> #55000      Total Loss: 2.598    [weighted Loss:2.598    Policy Loss: 4.382    Value Loss: 4.189    Reward Loss: 1.316    Consistency Loss: 0.000    ] Replay Episodes Collected: 479592     Buffer Size: 65668      Transition Number: 999.992 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:25:59,335][train][INFO][train.py>_log] ==> #56000      Total Loss: 3.750    [weighted Loss:3.750    Policy Loss: 8.060    Value Loss: 4.476    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 488958     Buffer Size: 72181      Transition Number: 1000.073k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:29:05,255][train][INFO][train.py>_log] ==> #57000      Total Loss: 3.527    [weighted Loss:3.527    Policy Loss: 7.388    Value Loss: 4.604    Reward Loss: 1.797    Consistency Loss: 0.000    ] Replay Episodes Collected: 497993     Buffer Size: 76524      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:32:11,229][train][INFO][train.py>_log] ==> #58000      Total Loss: 3.689    [weighted Loss:3.689    Policy Loss: 6.349    Value Loss: 4.306    Reward Loss: 1.660    Consistency Loss: 0.000    ] Replay Episodes Collected: 506728     Buffer Size: 78586      Transition Number: 1000.316k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:35:20,475][train][INFO][train.py>_log] ==> #59000      Total Loss: 2.251    [weighted Loss:2.251    Policy Loss: 6.618    Value Loss: 4.673    Reward Loss: 1.525    Consistency Loss: 0.000    ] Replay Episodes Collected: 515401     Buffer Size: 79137      Transition Number: 1000.046k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:38:25,892][train][INFO][train.py>_log] ==> #60000      Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 8.999    Value Loss: 4.289    Reward Loss: 1.599    Consistency Loss: 0.000    ] Replay Episodes Collected: 523924     Buffer Size: 79692      Transition Number: 1000.073k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:41:34,775][train][INFO][train.py>_log] ==> #61000      Total Loss: 4.693    [weighted Loss:4.693    Policy Loss: 9.947    Value Loss: 4.270    Reward Loss: 1.568    Consistency Loss: 0.000    ] Replay Episodes Collected: 532208     Buffer Size: 80784      Transition Number: 1000.101k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:44:44,123][train][INFO][train.py>_log] ==> #62000      Total Loss: 3.645    [weighted Loss:3.645    Policy Loss: 8.365    Value Loss: 4.206    Reward Loss: 1.702    Consistency Loss: 0.000    ] Replay Episodes Collected: 542243     Buffer Size: 81741      Transition Number: 1000.266k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:47:51,141][train][INFO][train.py>_log] ==> #63000      Total Loss: 3.813    [weighted Loss:3.813    Policy Loss: 8.565    Value Loss: 4.312    Reward Loss: 1.589    Consistency Loss: 0.000    ] Replay Episodes Collected: 551892     Buffer Size: 81193      Transition Number: 1000.113k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:51:03,910][train][INFO][train.py>_log] ==> #64000      Total Loss: 4.032    [weighted Loss:4.032    Policy Loss: 9.662    Value Loss: 4.272    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 560439     Buffer Size: 79679      Transition Number: 1000.145k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:54:09,658][train][INFO][train.py>_log] ==> #65000      Total Loss: 3.761    [weighted Loss:3.761    Policy Loss: 8.342    Value Loss: 4.413    Reward Loss: 1.584    Consistency Loss: 0.000    ] Replay Episodes Collected: 567539     Buffer Size: 77624      Transition Number: 1000.326k Batch Size: 256        Lr: 0.10000 
[2022-03-07 15:57:20,291][train][INFO][train.py>_log] ==> #66000      Total Loss: 4.005    [weighted Loss:4.005    Policy Loss: 7.403    Value Loss: 4.462    Reward Loss: 1.618    Consistency Loss: 0.000    ] Replay Episodes Collected: 575655     Buffer Size: 76542      Transition Number: 1000.177k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:00:29,040][train][INFO][train.py>_log] ==> #67000      Total Loss: 3.144    [weighted Loss:3.144    Policy Loss: 6.438    Value Loss: 4.391    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 585009     Buffer Size: 77003      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:03:38,146][train][INFO][train.py>_log] ==> #68000      Total Loss: 4.161    [weighted Loss:4.161    Policy Loss: 8.780    Value Loss: 4.529    Reward Loss: 1.547    Consistency Loss: 0.000    ] Replay Episodes Collected: 594515     Buffer Size: 77679      Transition Number: 1000.139k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:06:49,611][train][INFO][train.py>_log] ==> #69000      Total Loss: 2.376    [weighted Loss:2.376    Policy Loss: 5.843    Value Loss: 4.361    Reward Loss: 1.442    Consistency Loss: 0.000    ] Replay Episodes Collected: 602797     Buffer Size: 77202      Transition Number: 1000.124k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:09:58,858][train][INFO][train.py>_log] ==> #70000      Total Loss: 2.224    [weighted Loss:2.224    Policy Loss: 7.307    Value Loss: 4.595    Reward Loss: 1.395    Consistency Loss: 0.000    ] Replay Episodes Collected: 609192     Buffer Size: 75417      Transition Number: 1000.138k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:13:08,455][train][INFO][train.py>_log] ==> #71000      Total Loss: 3.774    [weighted Loss:3.774    Policy Loss: 9.300    Value Loss: 4.924    Reward Loss: 1.473    Consistency Loss: 0.000    ] Replay Episodes Collected: 614802     Buffer Size: 71631      Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:16:14,713][train][INFO][train.py>_log] ==> #72000      Total Loss: 5.746    [weighted Loss:5.746    Policy Loss: 11.827   Value Loss: 5.061    Reward Loss: 1.428    Consistency Loss: 0.000    ] Replay Episodes Collected: 619871     Buffer Size: 67838      Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:19:22,998][train][INFO][train.py>_log] ==> #73000      Total Loss: 2.214    [weighted Loss:2.214    Policy Loss: 7.609    Value Loss: 4.469    Reward Loss: 1.422    Consistency Loss: 0.000    ] Replay Episodes Collected: 626705     Buffer Size: 66266      Transition Number: 1000.074k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:22:33,667][train][INFO][train.py>_log] ==> #74000      Total Loss: 3.330    [weighted Loss:3.330    Policy Loss: 6.439    Value Loss: 4.650    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 635288     Buffer Size: 67334      Transition Number: 1000.250k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:25:43,815][train][INFO][train.py>_log] ==> #75000      Total Loss: 2.411    [weighted Loss:2.411    Policy Loss: 6.486    Value Loss: 4.967    Reward Loss: 1.308    Consistency Loss: 0.000    ] Replay Episodes Collected: 644605     Buffer Size: 68402      Transition Number: 1000.149k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:28:50,909][train][INFO][train.py>_log] ==> #76000      Total Loss: 4.594    [weighted Loss:4.594    Policy Loss: 8.041    Value Loss: 5.447    Reward Loss: 1.496    Consistency Loss: 0.000    ] Replay Episodes Collected: 653300     Buffer Size: 67889      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:31:59,904][train][INFO][train.py>_log] ==> #77000      Total Loss: 4.181    [weighted Loss:4.181    Policy Loss: 7.901    Value Loss: 4.690    Reward Loss: 1.421    Consistency Loss: 0.000    ] Replay Episodes Collected: 662259     Buffer Size: 67352      Transition Number: 1000.230k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:35:11,773][train][INFO][train.py>_log] ==> #78000      Total Loss: 3.585    [weighted Loss:3.585    Policy Loss: 8.530    Value Loss: 4.788    Reward Loss: 1.398    Consistency Loss: 0.000    ] Replay Episodes Collected: 670433     Buffer Size: 67315      Transition Number: 1000.165k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:38:19,954][train][INFO][train.py>_log] ==> #79000      Total Loss: 3.824    [weighted Loss:3.824    Policy Loss: 7.467    Value Loss: 5.177    Reward Loss: 1.541    Consistency Loss: 0.000    ] Replay Episodes Collected: 677427     Buffer Size: 67833      Transition Number: 1000.167k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:41:26,399][train][INFO][train.py>_log] ==> #80000      Total Loss: 2.352    [weighted Loss:2.352    Policy Loss: 11.199   Value Loss: 4.768    Reward Loss: 1.268    Consistency Loss: 0.000    ] Replay Episodes Collected: 680422     Buffer Size: 66265      Transition Number: 1000.028k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:44:31,943][train][INFO][train.py>_log] ==> #81000      Total Loss: 3.497    [weighted Loss:3.497    Policy Loss: 7.168    Value Loss: 4.343    Reward Loss: 1.291    Consistency Loss: 0.000    ] Replay Episodes Collected: 682021     Buffer Size: 63903      Transition Number: 999.987 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:47:40,331][train][INFO][train.py>_log] ==> #82000      Total Loss: 3.274    [weighted Loss:3.274    Policy Loss: 7.406    Value Loss: 4.594    Reward Loss: 1.121    Consistency Loss: 0.000    ] Replay Episodes Collected: 684130     Buffer Size: 61096      Transition Number: 1000.167k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:50:45,322][train][INFO][train.py>_log] ==> #83000      Total Loss: 3.622    [weighted Loss:3.622    Policy Loss: 5.957    Value Loss: 4.526    Reward Loss: 0.964    Consistency Loss: 0.000    ] Replay Episodes Collected: 685871     Buffer Size: 56776      Transition Number: 1000.211k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:53:51,054][train][INFO][train.py>_log] ==> #84000      Total Loss: 2.910    [weighted Loss:2.910    Policy Loss: 5.930    Value Loss: 4.379    Reward Loss: 1.067    Consistency Loss: 0.000    ] Replay Episodes Collected: 687187     Buffer Size: 51776      Transition Number: 1000.103k Batch Size: 256        Lr: 0.10000 
[2022-03-07 16:56:56,609][train][INFO][train.py>_log] ==> #85000      Total Loss: 3.939    [weighted Loss:3.939    Policy Loss: 5.956    Value Loss: 5.173    Reward Loss: 0.851    Consistency Loss: 0.000    ] Replay Episodes Collected: 689016     Buffer Size: 46206      Transition Number: 1000.038k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:00:05,795][train][INFO][train.py>_log] ==> #86000      Total Loss: 3.680    [weighted Loss:3.680    Policy Loss: 8.707    Value Loss: 5.337    Reward Loss: 1.168    Consistency Loss: 0.000    ] Replay Episodes Collected: 696581     Buffer Size: 44284      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:03:14,192][train][INFO][train.py>_log] ==> #87000      Total Loss: 3.324    [weighted Loss:3.324    Policy Loss: 7.324    Value Loss: 3.381    Reward Loss: 1.250    Consistency Loss: 0.000    ] Replay Episodes Collected: 705112     Buffer Size: 43994      Transition Number: 1000.234k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:06:22,720][train][INFO][train.py>_log] ==> #88000      Total Loss: 4.957    [weighted Loss:4.957    Policy Loss: 11.123   Value Loss: 3.989    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 712520     Buffer Size: 43388      Transition Number: 1000.324k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:09:31,102][train][INFO][train.py>_log] ==> #89000      Total Loss: 4.146    [weighted Loss:4.146    Policy Loss: 10.686   Value Loss: 4.631    Reward Loss: 1.841    Consistency Loss: 0.000    ] Replay Episodes Collected: 719768     Buffer Size: 43296      Transition Number: 1000.241k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:12:36,443][train][INFO][train.py>_log] ==> #90000      Total Loss: 3.633    [weighted Loss:3.633    Policy Loss: 10.839   Value Loss: 4.098    Reward Loss: 1.476    Consistency Loss: 0.000    ] Replay Episodes Collected: 726744     Buffer Size: 46135      Transition Number: 1000.251k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:15:41,726][train][INFO][train.py>_log] ==> #91000      Total Loss: 3.975    [weighted Loss:3.975    Policy Loss: 11.132   Value Loss: 4.246    Reward Loss: 1.576    Consistency Loss: 0.000    ] Replay Episodes Collected: 736779     Buffer Size: 53785      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:18:44,686][train][INFO][train.py>_log] ==> #92000      Total Loss: 4.562    [weighted Loss:4.562    Policy Loss: 11.161   Value Loss: 4.294    Reward Loss: 1.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 745618     Buffer Size: 60359      Transition Number: 1000.042k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:21:48,964][train][INFO][train.py>_log] ==> #93000      Total Loss: 4.640    [weighted Loss:4.640    Policy Loss: 10.443   Value Loss: 4.351    Reward Loss: 1.768    Consistency Loss: 0.000    ] Replay Episodes Collected: 755828     Buffer Size: 68722      Transition Number: 1000.130k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:24:54,534][train][INFO][train.py>_log] ==> #94000      Total Loss: 4.998    [weighted Loss:4.998    Policy Loss: 10.247   Value Loss: 4.390    Reward Loss: 1.779    Consistency Loss: 0.000    ] Replay Episodes Collected: 766619     Buffer Size: 76977      Transition Number: 1000.148k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:28:03,465][train][INFO][train.py>_log] ==> #95000      Total Loss: 4.049    [weighted Loss:4.049    Policy Loss: 11.384   Value Loss: 4.815    Reward Loss: 1.967    Consistency Loss: 0.000    ] Replay Episodes Collected: 776407     Buffer Size: 79084      Transition Number: 1000.149k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:31:18,439][train][INFO][train.py>_log] ==> #96000      Total Loss: 5.968    [weighted Loss:5.968    Policy Loss: 11.657   Value Loss: 4.897    Reward Loss: 1.982    Consistency Loss: 0.000    ] Replay Episodes Collected: 791127     Buffer Size: 84854      Transition Number: 1000.151k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:34:35,106][train][INFO][train.py>_log] ==> #97000      Total Loss: 4.721    [weighted Loss:4.721    Policy Loss: 10.137   Value Loss: 5.497    Reward Loss: 2.038    Consistency Loss: 0.000    ] Replay Episodes Collected: 807873     Buffer Size: 93616      Transition Number: 1000.175k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:38:00,018][train][INFO][train.py>_log] ==> #98000      Total Loss: 5.092    [weighted Loss:5.092    Policy Loss: 10.223   Value Loss: 5.776    Reward Loss: 2.110    Consistency Loss: 0.000    ] Replay Episodes Collected: 826820     Buffer Size: 104346     Transition Number: 1000.112k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:41:25,851][train][INFO][train.py>_log] ==> #99000      Total Loss: 4.532    [weighted Loss:4.532    Policy Loss: 8.984    Value Loss: 5.367    Reward Loss: 2.382    Consistency Loss: 0.000    ] Replay Episodes Collected: 846675     Buffer Size: 114417     Transition Number: 1000.303k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:44:55,399][train][INFO][train.py>_log] ==> #100000     Total Loss: 3.936    [weighted Loss:3.936    Policy Loss: 8.981    Value Loss: 5.279    Reward Loss: 2.370    Consistency Loss: 0.000    ] Replay Episodes Collected: 868526     Buffer Size: 125538     Transition Number: 1000.250k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:48:30,118][train][INFO][train.py>_log] ==> #101000     Total Loss: 3.594    [weighted Loss:3.594    Policy Loss: 7.786    Value Loss: 5.092    Reward Loss: 2.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 892270     Buffer Size: 137248     Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:52:04,395][train][INFO][train.py>_log] ==> #102000     Total Loss: 2.771    [weighted Loss:2.771    Policy Loss: 7.016    Value Loss: 5.087    Reward Loss: 2.289    Consistency Loss: 0.000    ] Replay Episodes Collected: 914606     Buffer Size: 146989     Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:55:38,694][train][INFO][train.py>_log] ==> #103000     Total Loss: 5.388    [weighted Loss:5.388    Policy Loss: 9.791    Value Loss: 5.477    Reward Loss: 2.514    Consistency Loss: 0.000    ] Replay Episodes Collected: 933435     Buffer Size: 153908     Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-03-07 17:59:01,020][train][INFO][train.py>_log] ==> #104000     Total Loss: 6.267    [weighted Loss:6.267    Policy Loss: 12.007   Value Loss: 5.800    Reward Loss: 2.323    Consistency Loss: 0.000    ] Replay Episodes Collected: 947369     Buffer Size: 151761     Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:02:19,745][train][INFO][train.py>_log] ==> #105000     Total Loss: 5.554    [weighted Loss:5.554    Policy Loss: 11.319   Value Loss: 5.853    Reward Loss: 2.263    Consistency Loss: 0.000    ] Replay Episodes Collected: 959158     Buffer Size: 146363     Transition Number: 1000.075k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:05:43,539][train][INFO][train.py>_log] ==> #106000     Total Loss: 5.243    [weighted Loss:5.243    Policy Loss: 11.526   Value Loss: 6.192    Reward Loss: 2.286    Consistency Loss: 0.000    ] Replay Episodes Collected: 971021     Buffer Size: 139459     Transition Number: 1000.061k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:09:02,098][train][INFO][train.py>_log] ==> #107000     Total Loss: 4.835    [weighted Loss:4.835    Policy Loss: 11.830   Value Loss: 6.068    Reward Loss: 2.201    Consistency Loss: 0.000    ] Replay Episodes Collected: 981959     Buffer Size: 130854     Transition Number: 1000.076k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:12:26,398][train][INFO][train.py>_log] ==> #108000     Total Loss: 3.855    [weighted Loss:3.855    Policy Loss: 10.722   Value Loss: 5.934    Reward Loss: 2.103    Consistency Loss: 0.000    ] Replay Episodes Collected: 996816     Buffer Size: 124363     Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:15:58,861][train][INFO][train.py>_log] ==> #109000     Total Loss: 5.218    [weighted Loss:5.218    Policy Loss: 9.421    Value Loss: 6.313    Reward Loss: 2.230    Consistency Loss: 0.000    ] Replay Episodes Collected: 1016033    Buffer Size: 119519     Transition Number: 1000.140k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:19:34,517][train][INFO][train.py>_log] ==> #110000     Total Loss: 4.337    [weighted Loss:4.337    Policy Loss: 9.416    Value Loss: 6.518    Reward Loss: 2.376    Consistency Loss: 0.000    ] Replay Episodes Collected: 1036640    Buffer Size: 117205     Transition Number: 1000.283k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:22:59,768][train][INFO][train.py>_log] ==> #111000     Total Loss: 5.446    [weighted Loss:5.446    Policy Loss: 10.011   Value Loss: 5.635    Reward Loss: 2.084    Consistency Loss: 0.000    ] Replay Episodes Collected: 1051601    Buffer Size: 114624     Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:26:16,596][train][INFO][train.py>_log] ==> #112000     Total Loss: 4.511    [weighted Loss:4.511    Policy Loss: 10.366   Value Loss: 5.773    Reward Loss: 1.985    Consistency Loss: 0.000    ] Replay Episodes Collected: 1061725    Buffer Size: 112194     Transition Number: 1000.106k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:29:33,891][train][INFO][train.py>_log] ==> #113000     Total Loss: 4.662    [weighted Loss:4.662    Policy Loss: 10.723   Value Loss: 5.367    Reward Loss: 1.824    Consistency Loss: 0.000    ] Replay Episodes Collected: 1072714    Buffer Size: 111723     Transition Number: 1000.077k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:32:53,289][train][INFO][train.py>_log] ==> #114000     Total Loss: 5.297    [weighted Loss:5.297    Policy Loss: 11.486   Value Loss: 5.846    Reward Loss: 2.060    Consistency Loss: 0.000    ] Replay Episodes Collected: 1082327    Buffer Size: 110084     Transition Number: 1000.161k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:36:12,519][train][INFO][train.py>_log] ==> #115000     Total Loss: 5.669    [weighted Loss:5.669    Policy Loss: 12.713   Value Loss: 5.991    Reward Loss: 2.020    Consistency Loss: 0.000    ] Replay Episodes Collected: 1092072    Buffer Size: 109077     Transition Number: 1000.071k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:39:33,179][train][INFO][train.py>_log] ==> #116000     Total Loss: 5.155    [weighted Loss:5.155    Policy Loss: 11.211   Value Loss: 5.495    Reward Loss: 2.034    Consistency Loss: 0.000    ] Replay Episodes Collected: 1103877    Buffer Size: 106259     Transition Number: 1000.214k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:42:59,034][train][INFO][train.py>_log] ==> #117000     Total Loss: 4.621    [weighted Loss:4.621    Policy Loss: 11.299   Value Loss: 5.268    Reward Loss: 2.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 1120057    Buffer Size: 104408     Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:46:46,880][train][INFO][train.py>_log] ==> #118000     Total Loss: 4.648    [weighted Loss:4.648    Policy Loss: 9.861    Value Loss: 5.375    Reward Loss: 2.081    Consistency Loss: 0.000    ] Replay Episodes Collected: 1144991    Buffer Size: 108251     Transition Number: 1000.182k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:50:24,790][train][INFO][train.py>_log] ==> #119000     Total Loss: 3.777    [weighted Loss:3.777    Policy Loss: 8.953    Value Loss: 5.596    Reward Loss: 2.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 1165678    Buffer Size: 113188     Transition Number: 1000.261k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:54:04,018][train][INFO][train.py>_log] ==> #120000     Total Loss: 4.692    [weighted Loss:4.692    Policy Loss: 9.032    Value Loss: 5.384    Reward Loss: 2.293    Consistency Loss: 0.000    ] Replay Episodes Collected: 1188888    Buffer Size: 124086     Transition Number: 1000.088k Batch Size: 256        Lr: 0.10000 
[2022-03-07 18:57:41,325][train][INFO][train.py>_log] ==> #121000     Total Loss: 4.009    [weighted Loss:4.009    Policy Loss: 9.142    Value Loss: 4.620    Reward Loss: 2.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 1211081    Buffer Size: 134754     Transition Number: 1000.155k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:01:20,790][train][INFO][train.py>_log] ==> #122000     Total Loss: 3.683    [weighted Loss:3.683    Policy Loss: 7.329    Value Loss: 4.237    Reward Loss: 2.267    Consistency Loss: 0.000    ] Replay Episodes Collected: 1233627    Buffer Size: 145757     Transition Number: 1000.118k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:04:49,752][train][INFO][train.py>_log] ==> #123000     Total Loss: 3.525    [weighted Loss:3.525    Policy Loss: 9.848    Value Loss: 4.743    Reward Loss: 2.431    Consistency Loss: 0.000    ] Replay Episodes Collected: 1251731    Buffer Size: 152312     Transition Number: 1000.190k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:08:23,237][train][INFO][train.py>_log] ==> #124000     Total Loss: 2.893    [weighted Loss:2.893    Policy Loss: 10.092   Value Loss: 4.601    Reward Loss: 2.432    Consistency Loss: 0.000    ] Replay Episodes Collected: 1270804    Buffer Size: 156588     Transition Number: 1000.174k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:11:56,586][train][INFO][train.py>_log] ==> #125000     Total Loss: 3.757    [weighted Loss:3.757    Policy Loss: 9.443    Value Loss: 3.935    Reward Loss: 2.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 1289598    Buffer Size: 153067     Transition Number: 1000.183k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:15:33,050][train][INFO][train.py>_log] ==> #126000     Total Loss: 4.307    [weighted Loss:4.307    Policy Loss: 9.550    Value Loss: 4.157    Reward Loss: 2.108    Consistency Loss: 0.000    ] Replay Episodes Collected: 1307482    Buffer Size: 150331     Transition Number: 1000.188k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:18:56,684][train][INFO][train.py>_log] ==> #127000     Total Loss: 4.371    [weighted Loss:4.371    Policy Loss: 10.822   Value Loss: 4.645    Reward Loss: 2.134    Consistency Loss: 0.000    ] Replay Episodes Collected: 1320684    Buffer Size: 143358     Transition Number: 1000.153k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:22:17,685][train][INFO][train.py>_log] ==> #128000     Total Loss: 4.094    [weighted Loss:4.094    Policy Loss: 12.058   Value Loss: 5.243    Reward Loss: 1.990    Consistency Loss: 0.000    ] Replay Episodes Collected: 1330722    Buffer Size: 134285     Transition Number: 1000.110k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:25:36,243][train][INFO][train.py>_log] ==> #129000     Total Loss: 4.788    [weighted Loss:4.788    Policy Loss: 11.784   Value Loss: 5.400    Reward Loss: 2.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 1339900    Buffer Size: 123371     Transition Number: 1000.016k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:28:57,470][train][INFO][train.py>_log] ==> #130000     Total Loss: 4.674    [weighted Loss:4.674    Policy Loss: 12.793   Value Loss: 5.605    Reward Loss: 1.989    Consistency Loss: 0.000    ] Replay Episodes Collected: 1350356    Buffer Size: 114685     Transition Number: 1000.116k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:32:18,483][train][INFO][train.py>_log] ==> #131000     Total Loss: 5.073    [weighted Loss:5.073    Policy Loss: 11.743   Value Loss: 5.722    Reward Loss: 2.138    Consistency Loss: 0.000    ] Replay Episodes Collected: 1360954    Buffer Size: 108200     Transition Number: 1000.173k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:35:39,808][train][INFO][train.py>_log] ==> #132000     Total Loss: 5.540    [weighted Loss:5.540    Policy Loss: 13.643   Value Loss: 5.562    Reward Loss: 1.860    Consistency Loss: 0.000    ] Replay Episodes Collected: 1372206    Buffer Size: 101335     Transition Number: 1000.101k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:38:53,477][train][INFO][train.py>_log] ==> #133000     Total Loss: 5.661    [weighted Loss:5.661    Policy Loss: 12.150   Value Loss: 5.820    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 1382780    Buffer Size: 95165      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:42:15,978][train][INFO][train.py>_log] ==> #134000     Total Loss: 5.661    [weighted Loss:5.661    Policy Loss: 12.452   Value Loss: 5.671    Reward Loss: 1.874    Consistency Loss: 0.000    ] Replay Episodes Collected: 1393199    Buffer Size: 89096      Transition Number: 1000.157k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:45:27,605][train][INFO][train.py>_log] ==> #135000     Total Loss: 5.910    [weighted Loss:5.910    Policy Loss: 12.929   Value Loss: 5.500    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 1400000    Buffer Size: 83134      Transition Number: 1000.023k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:48:45,403][train][INFO][train.py>_log] ==> #136000     Total Loss: 6.843    [weighted Loss:6.843    Policy Loss: 12.974   Value Loss: 5.689    Reward Loss: 1.927    Consistency Loss: 0.000    ] Replay Episodes Collected: 1411902    Buffer Size: 83843      Transition Number: 1000.069k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:52:07,681][train][INFO][train.py>_log] ==> #137000     Total Loss: 5.583    [weighted Loss:5.583    Policy Loss: 11.512   Value Loss: 5.084    Reward Loss: 1.864    Consistency Loss: 0.000    ] Replay Episodes Collected: 1427226    Buffer Size: 89341      Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:55:32,034][train][INFO][train.py>_log] ==> #138000     Total Loss: 5.465    [weighted Loss:5.465    Policy Loss: 11.964   Value Loss: 4.846    Reward Loss: 1.999    Consistency Loss: 0.000    ] Replay Episodes Collected: 1443391    Buffer Size: 95271      Transition Number: 1000.177k Batch Size: 256        Lr: 0.10000 
[2022-03-07 19:58:56,221][train][INFO][train.py>_log] ==> #139000     Total Loss: 5.714    [weighted Loss:5.714    Policy Loss: 11.849   Value Loss: 5.265    Reward Loss: 2.140    Consistency Loss: 0.000    ] Replay Episodes Collected: 1460111    Buffer Size: 100720     Transition Number: 1000.158k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:02:32,435][train][INFO][train.py>_log] ==> #140000     Total Loss: 4.894    [weighted Loss:4.894    Policy Loss: 11.561   Value Loss: 5.228    Reward Loss: 2.190    Consistency Loss: 0.000    ] Replay Episodes Collected: 1478259    Buffer Size: 106824     Transition Number: 1000.089k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:06:01,436][train][INFO][train.py>_log] ==> #141000     Total Loss: 5.857    [weighted Loss:5.857    Policy Loss: 12.067   Value Loss: 5.296    Reward Loss: 2.264    Consistency Loss: 0.000    ] Replay Episodes Collected: 1495340    Buffer Size: 112192     Transition Number: 1000.184k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:09:26,877][train][INFO][train.py>_log] ==> #142000     Total Loss: 4.519    [weighted Loss:4.519    Policy Loss: 11.471   Value Loss: 5.296    Reward Loss: 2.237    Consistency Loss: 0.000    ] Replay Episodes Collected: 1509578    Buffer Size: 115803     Transition Number: 1000.092k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:12:51,183][train][INFO][train.py>_log] ==> #143000     Total Loss: 3.797    [weighted Loss:3.797    Policy Loss: 11.422   Value Loss: 5.094    Reward Loss: 2.042    Consistency Loss: 0.000    ] Replay Episodes Collected: 1524257    Buffer Size: 122562     Transition Number: 1000.030k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:16:13,512][train][INFO][train.py>_log] ==> #144000     Total Loss: 4.846    [weighted Loss:4.846    Policy Loss: 11.989   Value Loss: 5.565    Reward Loss: 2.266    Consistency Loss: 0.000    ] Replay Episodes Collected: 1538843    Buffer Size: 123889     Transition Number: 1000.098k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:19:43,835][train][INFO][train.py>_log] ==> #145000     Total Loss: 4.055    [weighted Loss:4.055    Policy Loss: 10.915   Value Loss: 4.994    Reward Loss: 2.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 1553306    Buffer Size: 122384     Transition Number: 1000.157k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:23:08,487][train][INFO][train.py>_log] ==> #146000     Total Loss: 4.716    [weighted Loss:4.716    Policy Loss: 11.121   Value Loss: 5.192    Reward Loss: 2.204    Consistency Loss: 0.000    ] Replay Episodes Collected: 1566373    Buffer Size: 119377     Transition Number: 1000.224k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:26:34,885][train][INFO][train.py>_log] ==> #147000     Total Loss: 4.192    [weighted Loss:4.192    Policy Loss: 11.324   Value Loss: 5.670    Reward Loss: 2.133    Consistency Loss: 0.000    ] Replay Episodes Collected: 1579169    Buffer Size: 115344     Transition Number: 1000.272k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:30:06,762][train][INFO][train.py>_log] ==> #148000     Total Loss: 4.697    [weighted Loss:4.697    Policy Loss: 10.151   Value Loss: 5.189    Reward Loss: 2.212    Consistency Loss: 0.000    ] Replay Episodes Collected: 1596204    Buffer Size: 114486     Transition Number: 1000.118k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:33:42,870][train][INFO][train.py>_log] ==> #149000     Total Loss: 4.523    [weighted Loss:4.523    Policy Loss: 9.020    Value Loss: 5.103    Reward Loss: 2.073    Consistency Loss: 0.000    ] Replay Episodes Collected: 1614878    Buffer Size: 116181     Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:37:28,738][train][INFO][train.py>_log] ==> #150000     Total Loss: 4.235    [weighted Loss:4.235    Policy Loss: 8.388    Value Loss: 4.747    Reward Loss: 2.096    Consistency Loss: 0.000    ] Replay Episodes Collected: 1637997    Buffer Size: 123069     Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:41:11,829][train][INFO][train.py>_log] ==> #151000     Total Loss: 4.536    [weighted Loss:4.536    Policy Loss: 8.916    Value Loss: 4.802    Reward Loss: 2.146    Consistency Loss: 0.000    ] Replay Episodes Collected: 1661181    Buffer Size: 129851     Transition Number: 1000.177k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:44:50,368][train][INFO][train.py>_log] ==> #152000     Total Loss: 2.659    [weighted Loss:2.659    Policy Loss: 7.659    Value Loss: 4.444    Reward Loss: 2.113    Consistency Loss: 0.000    ] Replay Episodes Collected: 1682387    Buffer Size: 135398     Transition Number: 1000.198k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:48:33,544][train][INFO][train.py>_log] ==> #153000     Total Loss: 3.292    [weighted Loss:3.292    Policy Loss: 9.221    Value Loss: 4.876    Reward Loss: 2.443    Consistency Loss: 0.000    ] Replay Episodes Collected: 1704226    Buffer Size: 142920     Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:51:59,705][train][INFO][train.py>_log] ==> #154000     Total Loss: 3.702    [weighted Loss:3.702    Policy Loss: 8.446    Value Loss: 4.746    Reward Loss: 2.345    Consistency Loss: 0.000    ] Replay Episodes Collected: 1721401    Buffer Size: 147155     Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:55:35,586][train][INFO][train.py>_log] ==> #155000     Total Loss: 5.085    [weighted Loss:5.085    Policy Loss: 10.404   Value Loss: 4.892    Reward Loss: 2.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 1738437    Buffer Size: 148568     Transition Number: 1000.108k Batch Size: 256        Lr: 0.10000 
[2022-03-07 20:59:05,057][train][INFO][train.py>_log] ==> #156000     Total Loss: 5.010    [weighted Loss:5.010    Policy Loss: 10.397   Value Loss: 4.803    Reward Loss: 2.080    Consistency Loss: 0.000    ] Replay Episodes Collected: 1754335    Buffer Size: 147310     Transition Number: 1000.099k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:02:33,888][train][INFO][train.py>_log] ==> #157000     Total Loss: 4.704    [weighted Loss:4.704    Policy Loss: 12.118   Value Loss: 5.501    Reward Loss: 2.219    Consistency Loss: 0.000    ] Replay Episodes Collected: 1768575    Buffer Size: 141572     Transition Number: 1000.236k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:06:02,114][train][INFO][train.py>_log] ==> #158000     Total Loss: 4.012    [weighted Loss:4.012    Policy Loss: 11.758   Value Loss: 5.186    Reward Loss: 2.176    Consistency Loss: 0.000    ] Replay Episodes Collected: 1781447    Buffer Size: 133782     Transition Number: 1000.203k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:09:26,593][train][INFO][train.py>_log] ==> #159000     Total Loss: 5.669    [weighted Loss:5.669    Policy Loss: 12.395   Value Loss: 5.469    Reward Loss: 2.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 1795225    Buffer Size: 127150     Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:12:50,955][train][INFO][train.py>_log] ==> #160000     Total Loss: 5.576    [weighted Loss:5.576    Policy Loss: 12.163   Value Loss: 5.537    Reward Loss: 2.137    Consistency Loss: 0.000    ] Replay Episodes Collected: 1806976    Buffer Size: 119518     Transition Number: 1000.308k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:16:08,247][train][INFO][train.py>_log] ==> #161000     Total Loss: 4.641    [weighted Loss:4.641    Policy Loss: 11.761   Value Loss: 4.770    Reward Loss: 2.097    Consistency Loss: 0.000    ] Replay Episodes Collected: 1816485    Buffer Size: 110909     Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:19:28,732][train][INFO][train.py>_log] ==> #162000     Total Loss: 6.319    [weighted Loss:6.319    Policy Loss: 12.377   Value Loss: 4.600    Reward Loss: 1.954    Consistency Loss: 0.000    ] Replay Episodes Collected: 1824925    Buffer Size: 103260     Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:22:43,181][train][INFO][train.py>_log] ==> #163000     Total Loss: 5.083    [weighted Loss:5.083    Policy Loss: 12.461   Value Loss: 4.811    Reward Loss: 1.855    Consistency Loss: 0.000    ] Replay Episodes Collected: 1831854    Buffer Size: 95639      Transition Number: 1000.186k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:25:57,988][train][INFO][train.py>_log] ==> #164000     Total Loss: 2.980    [weighted Loss:2.980    Policy Loss: 11.752   Value Loss: 4.234    Reward Loss: 1.689    Consistency Loss: 0.000    ] Replay Episodes Collected: 1838000    Buffer Size: 87500      Transition Number: 1000.101k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:29:09,896][train][INFO][train.py>_log] ==> #165000     Total Loss: 5.699    [weighted Loss:5.699    Policy Loss: 12.670   Value Loss: 4.595    Reward Loss: 1.769    Consistency Loss: 0.000    ] Replay Episodes Collected: 1844776    Buffer Size: 80933      Transition Number: 1000.081k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:32:21,866][train][INFO][train.py>_log] ==> #166000     Total Loss: 4.852    [weighted Loss:4.852    Policy Loss: 13.022   Value Loss: 4.302    Reward Loss: 1.615    Consistency Loss: 0.000    ] Replay Episodes Collected: 1850536    Buffer Size: 74979      Transition Number: 1000.250k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:35:38,355][train][INFO][train.py>_log] ==> #167000     Total Loss: 6.000    [weighted Loss:6.000    Policy Loss: 12.974   Value Loss: 4.892    Reward Loss: 1.839    Consistency Loss: 0.000    ] Replay Episodes Collected: 1857155    Buffer Size: 69061      Transition Number: 1000.207k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:38:45,791][train][INFO][train.py>_log] ==> #168000     Total Loss: 2.521    [weighted Loss:2.521    Policy Loss: 11.719   Value Loss: 4.447    Reward Loss: 1.612    Consistency Loss: 0.000    ] Replay Episodes Collected: 1863373    Buffer Size: 63923      Transition Number: 1000.084k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:41:57,292][train][INFO][train.py>_log] ==> #169000     Total Loss: 5.092    [weighted Loss:5.092    Policy Loss: 12.486   Value Loss: 4.762    Reward Loss: 1.706    Consistency Loss: 0.000    ] Replay Episodes Collected: 1869757    Buffer Size: 60037      Transition Number: 1000.142k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:45:08,019][train][INFO][train.py>_log] ==> #170000     Total Loss: 5.108    [weighted Loss:5.108    Policy Loss: 12.041   Value Loss: 4.531    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 1875736    Buffer Size: 57268      Transition Number: 1000.063k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:48:18,133][train][INFO][train.py>_log] ==> #171000     Total Loss: 4.305    [weighted Loss:4.305    Policy Loss: 11.844   Value Loss: 4.548    Reward Loss: 1.505    Consistency Loss: 0.000    ] Replay Episodes Collected: 1881599    Buffer Size: 55395      Transition Number: 1000.200k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:51:26,030][train][INFO][train.py>_log] ==> #172000     Total Loss: 4.963    [weighted Loss:4.963    Policy Loss: 13.262   Value Loss: 4.962    Reward Loss: 1.565    Consistency Loss: 0.000    ] Replay Episodes Collected: 1887717    Buffer Size: 54811      Transition Number: 1000.011k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:54:32,041][train][INFO][train.py>_log] ==> #173000     Total Loss: 6.522    [weighted Loss:6.522    Policy Loss: 12.762   Value Loss: 5.036    Reward Loss: 1.664    Consistency Loss: 0.000    ] Replay Episodes Collected: 1893889    Buffer Size: 54966      Transition Number: 1000.066k Batch Size: 256        Lr: 0.10000 
[2022-03-07 21:57:38,918][train][INFO][train.py>_log] ==> #174000     Total Loss: 5.704    [weighted Loss:5.704    Policy Loss: 13.298   Value Loss: 4.783    Reward Loss: 1.348    Consistency Loss: 0.000    ] Replay Episodes Collected: 1900275    Buffer Size: 54701      Transition Number: 1000.135k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:00:45,297][train][INFO][train.py>_log] ==> #175000     Total Loss: 6.665    [weighted Loss:6.665    Policy Loss: 13.402   Value Loss: 4.956    Reward Loss: 1.540    Consistency Loss: 0.000    ] Replay Episodes Collected: 1906415    Buffer Size: 55208      Transition Number: 1000.014k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:03:51,461][train][INFO][train.py>_log] ==> #176000     Total Loss: 6.711    [weighted Loss:6.711    Policy Loss: 13.220   Value Loss: 5.109    Reward Loss: 1.654    Consistency Loss: 0.000    ] Replay Episodes Collected: 1912584    Buffer Size: 54978      Transition Number: 1000.145k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:06:58,202][train][INFO][train.py>_log] ==> #177000     Total Loss: 5.385    [weighted Loss:5.385    Policy Loss: 12.799   Value Loss: 5.026    Reward Loss: 1.719    Consistency Loss: 0.000    ] Replay Episodes Collected: 1919314    Buffer Size: 55386      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:10:07,639][train][INFO][train.py>_log] ==> #178000     Total Loss: 6.751    [weighted Loss:6.751    Policy Loss: 14.229   Value Loss: 5.680    Reward Loss: 1.447    Consistency Loss: 0.000    ] Replay Episodes Collected: 1926308    Buffer Size: 55952      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:13:14,337][train][INFO][train.py>_log] ==> #179000     Total Loss: 5.403    [weighted Loss:5.403    Policy Loss: 13.564   Value Loss: 5.293    Reward Loss: 1.539    Consistency Loss: 0.000    ] Replay Episodes Collected: 1932953    Buffer Size: 56663      Transition Number: 1000.152k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:16:23,929][train][INFO][train.py>_log] ==> #180000     Total Loss: 6.259    [weighted Loss:6.259    Policy Loss: 12.812   Value Loss: 5.219    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 1939415    Buffer Size: 57198      Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:19:30,131][train][INFO][train.py>_log] ==> #181000     Total Loss: 5.447    [weighted Loss:5.447    Policy Loss: 12.154   Value Loss: 4.883    Reward Loss: 1.526    Consistency Loss: 0.000    ] Replay Episodes Collected: 1945565    Buffer Size: 57324      Transition Number: 1000.156k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:22:37,856][train][INFO][train.py>_log] ==> #182000     Total Loss: 5.876    [weighted Loss:5.876    Policy Loss: 12.361   Value Loss: 4.760    Reward Loss: 1.577    Consistency Loss: 0.000    ] Replay Episodes Collected: 1951792    Buffer Size: 57299      Transition Number: 1000.053k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:25:45,461][train][INFO][train.py>_log] ==> #183000     Total Loss: 5.689    [weighted Loss:5.689    Policy Loss: 12.190   Value Loss: 4.946    Reward Loss: 1.694    Consistency Loss: 0.000    ] Replay Episodes Collected: 1958408    Buffer Size: 57494      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:28:52,405][train][INFO][train.py>_log] ==> #184000     Total Loss: 5.457    [weighted Loss:5.457    Policy Loss: 13.227   Value Loss: 5.489    Reward Loss: 1.600    Consistency Loss: 0.000    ] Replay Episodes Collected: 1965164    Buffer Size: 58066      Transition Number: 1000.093k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:31:55,971][train][INFO][train.py>_log] ==> #185000     Total Loss: 5.094    [weighted Loss:5.094    Policy Loss: 12.996   Value Loss: 5.212    Reward Loss: 1.560    Consistency Loss: 0.000    ] Replay Episodes Collected: 1971681    Buffer Size: 58550      Transition Number: 1000.199k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:35:03,178][train][INFO][train.py>_log] ==> #186000     Total Loss: 3.884    [weighted Loss:3.884    Policy Loss: 12.572   Value Loss: 5.147    Reward Loss: 1.624    Consistency Loss: 0.000    ] Replay Episodes Collected: 1977467    Buffer Size: 57711      Transition Number: 1000.104k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:38:12,201][train][INFO][train.py>_log] ==> #187000     Total Loss: 6.113    [weighted Loss:6.113    Policy Loss: 11.469   Value Loss: 4.857    Reward Loss: 1.559    Consistency Loss: 0.000    ] Replay Episodes Collected: 1983528    Buffer Size: 56773      Transition Number: 1000.176k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:41:19,963][train][INFO][train.py>_log] ==> #188000     Total Loss: 3.156    [weighted Loss:3.156    Policy Loss: 12.420   Value Loss: 5.267    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 1989806    Buffer Size: 56384      Transition Number: 1000.070k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:44:28,654][train][INFO][train.py>_log] ==> #189000     Total Loss: 4.864    [weighted Loss:4.864    Policy Loss: 13.209   Value Loss: 5.130    Reward Loss: 1.451    Consistency Loss: 0.000    ] Replay Episodes Collected: 1996385    Buffer Size: 56432      Transition Number: 1000.179k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:47:36,700][train][INFO][train.py>_log] ==> #190000     Total Loss: 4.986    [weighted Loss:4.986    Policy Loss: 12.751   Value Loss: 5.229    Reward Loss: 1.441    Consistency Loss: 0.000    ] Replay Episodes Collected: 2002984    Buffer Size: 56744      Transition Number: 1000.092k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:50:42,576][train][INFO][train.py>_log] ==> #191000     Total Loss: 5.394    [weighted Loss:5.394    Policy Loss: 12.474   Value Loss: 5.181    Reward Loss: 1.456    Consistency Loss: 0.000    ] Replay Episodes Collected: 2010051    Buffer Size: 57552      Transition Number: 1000.113k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:53:52,039][train][INFO][train.py>_log] ==> #192000     Total Loss: 5.089    [weighted Loss:5.089    Policy Loss: 12.203   Value Loss: 5.277    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 2016713    Buffer Size: 57576      Transition Number: 1000.094k Batch Size: 256        Lr: 0.10000 
[2022-03-07 22:57:01,822][train][INFO][train.py>_log] ==> #193000     Total Loss: 3.196    [weighted Loss:3.196    Policy Loss: 12.461   Value Loss: 4.565    Reward Loss: 1.549    Consistency Loss: 0.000    ] Replay Episodes Collected: 2023808    Buffer Size: 57642      Transition Number: 1000.052k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:00:10,569][train][INFO][train.py>_log] ==> #194000     Total Loss: 5.187    [weighted Loss:5.187    Policy Loss: 13.379   Value Loss: 5.400    Reward Loss: 1.462    Consistency Loss: 0.000    ] Replay Episodes Collected: 2030698    Buffer Size: 57938      Transition Number: 1000.080k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:03:17,715][train][INFO][train.py>_log] ==> #195000     Total Loss: 5.886    [weighted Loss:5.886    Policy Loss: 13.690   Value Loss: 6.103    Reward Loss: 1.582    Consistency Loss: 0.000    ] Replay Episodes Collected: 2037654    Buffer Size: 58989      Transition Number: 1000.110k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:06:24,586][train][INFO][train.py>_log] ==> #196000     Total Loss: 3.450    [weighted Loss:3.450    Policy Loss: 12.776   Value Loss: 5.520    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 2044526    Buffer Size: 59818      Transition Number: 999.993 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:09:30,863][train][INFO][train.py>_log] ==> #197000     Total Loss: 4.568    [weighted Loss:4.568    Policy Loss: 12.841   Value Loss: 6.026    Reward Loss: 1.655    Consistency Loss: 0.000    ] Replay Episodes Collected: 2051655    Buffer Size: 60729      Transition Number: 1000.105k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:12:37,803][train][INFO][train.py>_log] ==> #198000     Total Loss: 4.001    [weighted Loss:4.001    Policy Loss: 13.537   Value Loss: 6.326    Reward Loss: 1.771    Consistency Loss: 0.000    ] Replay Episodes Collected: 2058804    Buffer Size: 61390      Transition Number: 1000.194k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:15:45,200][train][INFO][train.py>_log] ==> #199000     Total Loss: 5.613    [weighted Loss:5.613    Policy Loss: 12.733   Value Loss: 5.396    Reward Loss: 1.627    Consistency Loss: 0.000    ] Replay Episodes Collected: 2066136    Buffer Size: 62026      Transition Number: 1000.056k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:18:52,071][train][INFO][train.py>_log] ==> #200000     Total Loss: 5.929    [weighted Loss:5.929    Policy Loss: 11.801   Value Loss: 5.130    Reward Loss: 1.690    Consistency Loss: 0.000    ] Replay Episodes Collected: 2072563    Buffer Size: 61470      Transition Number: 1000.100k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:22:00,255][train][INFO][train.py>_log] ==> #201000     Total Loss: 2.686    [weighted Loss:2.686    Policy Loss: 11.456   Value Loss: 4.713    Reward Loss: 1.650    Consistency Loss: 0.000    ] Replay Episodes Collected: 2078501    Buffer Size: 60681      Transition Number: 1000.071k Batch Size: 256        Lr: 0.10000 
[2022-03-07 23:25:10,463][train][INFO][train.py>_log] ==> #202000     Total Loss: 5.954    [weighted Loss:5.954    Policy Loss: 12.170   Value Loss: 4.716    Reward Loss: 1.669    Consistency Loss: 0.000    ] Replay Episodes Collected: 2084678    Buffer Size: 59852      Transition Number: 1000.170k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:28:21,803][train][INFO][train.py>_log] ==> #203000     Total Loss: 4.896    [weighted Loss:4.896    Policy Loss: 11.010   Value Loss: 4.107    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 2090629    Buffer Size: 58915      Transition Number: 1000.136k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:31:29,368][train][INFO][train.py>_log] ==> #204000     Total Loss: 3.212    [weighted Loss:3.212    Policy Loss: 10.513   Value Loss: 4.071    Reward Loss: 1.501    Consistency Loss: 0.000    ] Replay Episodes Collected: 2096361    Buffer Size: 57667      Transition Number: 1000.047k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:34:39,708][train][INFO][train.py>_log] ==> #205000     Total Loss: 3.981    [weighted Loss:3.981    Policy Loss: 9.995    Value Loss: 4.188    Reward Loss: 1.643    Consistency Loss: 0.000    ] Replay Episodes Collected: 2101885    Buffer Size: 56161      Transition Number: 1000.183k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:37:49,657][train][INFO][train.py>_log] ==> #206000     Total Loss: 3.831    [weighted Loss:3.831    Policy Loss: 9.975    Value Loss: 3.928    Reward Loss: 1.550    Consistency Loss: 0.000    ] Replay Episodes Collected: 2106633    Buffer Size: 53939      Transition Number: 1000.156k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:40:58,848][train][INFO][train.py>_log] ==> #207000     Total Loss: 4.232    [weighted Loss:4.232    Policy Loss: 10.929   Value Loss: 4.000    Reward Loss: 1.379    Consistency Loss: 0.000    ] Replay Episodes Collected: 2111394    Buffer Size: 51598      Transition Number: 1000.087k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:44:07,038][train][INFO][train.py>_log] ==> #208000     Total Loss: 4.106    [weighted Loss:4.106    Policy Loss: 11.516   Value Loss: 3.855    Reward Loss: 1.567    Consistency Loss: 0.000    ] Replay Episodes Collected: 2116159    Buffer Size: 49346      Transition Number: 1000.044k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:47:16,643][train][INFO][train.py>_log] ==> #209000     Total Loss: 4.608    [weighted Loss:4.608    Policy Loss: 10.615   Value Loss: 3.907    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 2121097    Buffer Size: 47916      Transition Number: 1000.111k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:50:24,260][train][INFO][train.py>_log] ==> #210000     Total Loss: 5.458    [weighted Loss:5.458    Policy Loss: 10.709   Value Loss: 4.097    Reward Loss: 1.463    Consistency Loss: 0.000    ] Replay Episodes Collected: 2126220    Buffer Size: 47204      Transition Number: 1000.149k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:53:37,029][train][INFO][train.py>_log] ==> #211000     Total Loss: 4.375    [weighted Loss:4.375    Policy Loss: 10.930   Value Loss: 4.123    Reward Loss: 1.304    Consistency Loss: 0.000    ] Replay Episodes Collected: 2132321    Buffer Size: 46911      Transition Number: 1000.290k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:56:49,506][train][INFO][train.py>_log] ==> #212000     Total Loss: 2.745    [weighted Loss:2.745    Policy Loss: 9.696    Value Loss: 3.948    Reward Loss: 1.524    Consistency Loss: 0.000    ] Replay Episodes Collected: 2139123    Buffer Size: 47678      Transition Number: 1000.184k Batch Size: 256        Lr: 0.01000 
[2022-03-07 23:59:56,751][train][INFO][train.py>_log] ==> #213000     Total Loss: 4.003    [weighted Loss:4.003    Policy Loss: 10.330   Value Loss: 4.478    Reward Loss: 1.595    Consistency Loss: 0.000    ] Replay Episodes Collected: 2146013    Buffer Size: 48870      Transition Number: 1000.088k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:03:05,198][train][INFO][train.py>_log] ==> #214000     Total Loss: 4.220    [weighted Loss:4.220    Policy Loss: 10.645   Value Loss: 4.201    Reward Loss: 1.617    Consistency Loss: 0.000    ] Replay Episodes Collected: 2153288    Buffer Size: 50743      Transition Number: 1000.008k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:06:12,699][train][INFO][train.py>_log] ==> #215000     Total Loss: 4.417    [weighted Loss:4.417    Policy Loss: 8.227    Value Loss: 4.318    Reward Loss: 1.494    Consistency Loss: 0.000    ] Replay Episodes Collected: 2160460    Buffer Size: 53149      Transition Number: 1000.018k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:09:18,971][train][INFO][train.py>_log] ==> #216000     Total Loss: 2.484    [weighted Loss:2.484    Policy Loss: 9.200    Value Loss: 4.291    Reward Loss: 1.548    Consistency Loss: 0.000    ] Replay Episodes Collected: 2167288    Buffer Size: 55274      Transition Number: 1000.175k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:12:27,686][train][INFO][train.py>_log] ==> #217000     Total Loss: 4.440    [weighted Loss:4.440    Policy Loss: 10.006   Value Loss: 4.725    Reward Loss: 1.652    Consistency Loss: 0.000    ] Replay Episodes Collected: 2172585    Buffer Size: 56078      Transition Number: 1000.053k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:15:36,872][train][INFO][train.py>_log] ==> #218000     Total Loss: 4.014    [weighted Loss:4.014    Policy Loss: 8.850    Value Loss: 3.958    Reward Loss: 1.436    Consistency Loss: 0.000    ] Replay Episodes Collected: 2175490    Buffer Size: 54549      Transition Number: 1000.026k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:18:46,761][train][INFO][train.py>_log] ==> #219000     Total Loss: 4.015    [weighted Loss:4.015    Policy Loss: 9.264    Value Loss: 4.236    Reward Loss: 1.722    Consistency Loss: 0.000    ] Replay Episodes Collected: 2178557    Buffer Size: 52899      Transition Number: 1000.157k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:21:52,997][train][INFO][train.py>_log] ==> #220000     Total Loss: 3.472    [weighted Loss:3.472    Policy Loss: 9.942    Value Loss: 3.856    Reward Loss: 1.292    Consistency Loss: 0.000    ] Replay Episodes Collected: 2181519    Buffer Size: 50775      Transition Number: 1000.069k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:25:03,440][train][INFO][train.py>_log] ==> #221000     Total Loss: 4.968    [weighted Loss:4.968    Policy Loss: 11.414   Value Loss: 4.000    Reward Loss: 1.530    Consistency Loss: 0.000    ] Replay Episodes Collected: 2185078    Buffer Size: 48183      Transition Number: 1000.088k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:28:10,821][train][INFO][train.py>_log] ==> #222000     Total Loss: 4.400    [weighted Loss:4.400    Policy Loss: 10.654   Value Loss: 3.905    Reward Loss: 1.374    Consistency Loss: 0.000    ] Replay Episodes Collected: 2188863    Buffer Size: 45449      Transition Number: 1000.124k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:31:20,431][train][INFO][train.py>_log] ==> #223000     Total Loss: 4.848    [weighted Loss:4.848    Policy Loss: 11.235   Value Loss: 3.790    Reward Loss: 1.270    Consistency Loss: 0.000    ] Replay Episodes Collected: 2192712    Buffer Size: 42573      Transition Number: 1000.185k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:34:29,799][train][INFO][train.py>_log] ==> #224000     Total Loss: 3.114    [weighted Loss:3.114    Policy Loss: 11.595   Value Loss: 3.814    Reward Loss: 1.339    Consistency Loss: 0.000    ] Replay Episodes Collected: 2196999    Buffer Size: 39751      Transition Number: 1000.215k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:37:37,426][train][INFO][train.py>_log] ==> #225000     Total Loss: 4.153    [weighted Loss:4.153    Policy Loss: 12.027   Value Loss: 3.862    Reward Loss: 1.372    Consistency Loss: 0.000    ] Replay Episodes Collected: 2201937    Buffer Size: 37550      Transition Number: 1000.299k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:40:45,611][train][INFO][train.py>_log] ==> #226000     Total Loss: 3.662    [weighted Loss:3.662    Policy Loss: 12.361   Value Loss: 3.596    Reward Loss: 1.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 2207153    Buffer Size: 36230      Transition Number: 1000.047k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:43:56,594][train][INFO][train.py>_log] ==> #227000     Total Loss: 2.906    [weighted Loss:2.906    Policy Loss: 12.813   Value Loss: 3.890    Reward Loss: 1.393    Consistency Loss: 0.000    ] Replay Episodes Collected: 2212634    Buffer Size: 37824      Transition Number: 1000.039k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:47:04,349][train][INFO][train.py>_log] ==> #228000     Total Loss: 5.747    [weighted Loss:5.747    Policy Loss: 12.472   Value Loss: 3.867    Reward Loss: 1.453    Consistency Loss: 0.000    ] Replay Episodes Collected: 2218003    Buffer Size: 39915      Transition Number: 1000.134k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:50:12,576][train][INFO][train.py>_log] ==> #229000     Total Loss: 4.338    [weighted Loss:4.338    Policy Loss: 11.651   Value Loss: 4.054    Reward Loss: 1.410    Consistency Loss: 0.000    ] Replay Episodes Collected: 2223484    Buffer Size: 42151      Transition Number: 1000.023k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:53:20,811][train][INFO][train.py>_log] ==> #230000     Total Loss: 5.320    [weighted Loss:5.320    Policy Loss: 12.535   Value Loss: 4.101    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 2228613    Buffer Size: 43591      Transition Number: 1000.172k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:56:26,918][train][INFO][train.py>_log] ==> #231000     Total Loss: 4.968    [weighted Loss:4.968    Policy Loss: 12.578   Value Loss: 4.235    Reward Loss: 1.438    Consistency Loss: 0.000    ] Replay Episodes Collected: 2233465    Buffer Size: 44595      Transition Number: 1000.185k Batch Size: 256        Lr: 0.01000 
[2022-03-08 00:59:34,906][train][INFO][train.py>_log] ==> #232000     Total Loss: 4.487    [weighted Loss:4.487    Policy Loss: 12.809   Value Loss: 4.044    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 2238366    Buffer Size: 45552      Transition Number: 1000.146k Batch Size: 256        Lr: 0.01000 
[2022-03-08 01:02:42,914][train][INFO][train.py>_log] ==> #233000     Total Loss: 5.912    [weighted Loss:5.912    Policy Loss: 12.551   Value Loss: 4.415    Reward Loss: 1.391    Consistency Loss: 0.000    ] Replay Episodes Collected: 2244136    Buffer Size: 46829      Transition Number: 1000.024k Batch Size: 256        Lr: 0.01000 
[2022-03-08 01:05:49,449][train][INFO][train.py>_log] ==> #234000     Total Loss: 4.198    [weighted Loss:4.198    Policy Loss: 12.001   Value Loss: 4.402    Reward Loss: 1.616    Consistency Loss: 0.000    ] Replay Episodes Collected: 2250058    Buffer Size: 47808      Transition Number: 1000.169k Batch Size: 256        Lr: 0.01000 
[2022-03-08 01:09:00,454][train][INFO][train.py>_log] ==> #235000     Total Loss: 3.787    [weighted Loss:3.787    Policy Loss: 11.371   Value Loss: 4.183    Reward Loss: 1.572    Consistency Loss: 0.000    ] Replay Episodes Collected: 2256856    Buffer Size: 49174      Transition Number: 1000.108k Batch Size: 256        Lr: 0.01000 
[2022-03-08 01:12:08,710][train][INFO][train.py>_log] ==> #236000     Total Loss: 4.989    [weighted Loss:4.989    Policy Loss: 9.963    Value Loss: 4.032    Reward Loss: 1.384    Consistency Loss: 0.000    ] Replay Episodes Collected: 2263297    Buffer Size: 50280      Transition Number: 1000.261k Batch Size: 256        Lr: 0.01000 
[2022-03-08 01:15:14,746][train][INFO][train.py>_log] ==> #237000     Total Loss: 5.423    [weighted Loss:5.423    Policy Loss: 10.639   Value Loss: 4.105    Reward Loss: 1.465    Consistency Loss: 0.000    ] Replay Episodes Collected: 2268717    Buffer Size: 50486      Transition Number: 1000.154k Batch Size: 256        Lr: 0.01000 
[2022-03-08 01:18:21,272][train][INFO][train.py>_log] ==> #238000     Total Loss: 4.436    [weighted Loss:4.436    Policy Loss: 9.994    Value Loss: 4.091    Reward Loss: 1.528    Consistency Loss: 0.000    ] Replay Episodes Collected: 2274206    Buffer Size: 50744      Transition Number: 1000.056k Batch Size: 256        Lr: 0.01000 
