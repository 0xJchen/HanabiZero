[2022-03-07 07:40:49,461][train][INFO][train.py>_log] ==> #0          Total Loss: 48.339   [weighted Loss:48.339   Policy Loss: 13.867   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1482       Buffer Size: 1482       Transition Number: 16.506  k Batch Size: 256        Lr: 0.00000 
[2022-03-07 07:43:51,707][train][INFO][train.py>_log] ==> #1000       Total Loss: 8.011    [weighted Loss:8.011    Policy Loss: 13.237   Value Loss: 5.597    Reward Loss: 2.601    Consistency Loss: 0.000    ] Replay Episodes Collected: 16371      Buffer Size: 16371      Transition Number: 131.251 k Batch Size: 256        Lr: 0.05000 
[2022-03-07 07:46:54,627][train][INFO][train.py>_log] ==> #2000       Total Loss: 4.030    [weighted Loss:4.030    Policy Loss: 11.537   Value Loss: 4.758    Reward Loss: 2.406    Consistency Loss: 0.000    ] Replay Episodes Collected: 31489      Buffer Size: 31489      Transition Number: 242.711 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 07:49:57,864][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.241    [weighted Loss:5.241    Policy Loss: 12.529   Value Loss: 4.949    Reward Loss: 2.545    Consistency Loss: 0.000    ] Replay Episodes Collected: 47695      Buffer Size: 47695      Transition Number: 352.786 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 07:53:02,279][train][INFO][train.py>_log] ==> #4000       Total Loss: 6.132    [weighted Loss:6.132    Policy Loss: 11.667   Value Loss: 4.855    Reward Loss: 2.271    Consistency Loss: 0.000    ] Replay Episodes Collected: 62136      Buffer Size: 62136      Transition Number: 461.171 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 07:56:06,548][train][INFO][train.py>_log] ==> #5000       Total Loss: 5.484    [weighted Loss:5.484    Policy Loss: 10.720   Value Loss: 4.619    Reward Loss: 2.242    Consistency Loss: 0.000    ] Replay Episodes Collected: 75133      Buffer Size: 75133      Transition Number: 569.779 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 07:59:10,585][train][INFO][train.py>_log] ==> #6000       Total Loss: 6.507    [weighted Loss:6.507    Policy Loss: 10.731   Value Loss: 4.377    Reward Loss: 2.183    Consistency Loss: 0.000    ] Replay Episodes Collected: 86440      Buffer Size: 86440      Transition Number: 676.933 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:02:15,944][train][INFO][train.py>_log] ==> #7000       Total Loss: 6.144    [weighted Loss:6.144    Policy Loss: 10.485   Value Loss: 4.614    Reward Loss: 2.209    Consistency Loss: 0.000    ] Replay Episodes Collected: 95471      Buffer Size: 95471      Transition Number: 778.420 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:05:21,604][train][INFO][train.py>_log] ==> #8000       Total Loss: 5.075    [weighted Loss:5.075    Policy Loss: 9.952    Value Loss: 4.429    Reward Loss: 1.886    Consistency Loss: 0.000    ] Replay Episodes Collected: 98439      Buffer Size: 98439      Transition Number: 871.756 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:08:26,120][train][INFO][train.py>_log] ==> #9000       Total Loss: 3.700    [weighted Loss:3.700    Policy Loss: 8.464    Value Loss: 4.001    Reward Loss: 1.753    Consistency Loss: 0.000    ] Replay Episodes Collected: 101446     Buffer Size: 101446     Transition Number: 969.346 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:11:32,900][train][INFO][train.py>_log] ==> #10000      Total Loss: 5.391    [weighted Loss:5.391    Policy Loss: 10.640   Value Loss: 4.143    Reward Loss: 1.735    Consistency Loss: 0.000    ] Replay Episodes Collected: 105553     Buffer Size: 96296      Transition Number: 1000.057k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:14:39,798][train][INFO][train.py>_log] ==> #11000      Total Loss: 4.466    [weighted Loss:4.466    Policy Loss: 10.679   Value Loss: 3.913    Reward Loss: 1.628    Consistency Loss: 0.000    ] Replay Episodes Collected: 109129     Buffer Size: 86757      Transition Number: 1000.043k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:17:45,869][train][INFO][train.py>_log] ==> #12000      Total Loss: 3.771    [weighted Loss:3.771    Policy Loss: 7.245    Value Loss: 3.252    Reward Loss: 1.244    Consistency Loss: 0.000    ] Replay Episodes Collected: 111469     Buffer Size: 76420      Transition Number: 1000.045k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:20:51,310][train][INFO][train.py>_log] ==> #13000      Total Loss: 4.475    [weighted Loss:4.475    Policy Loss: 9.451    Value Loss: 3.323    Reward Loss: 1.258    Consistency Loss: 0.000    ] Replay Episodes Collected: 113470     Buffer Size: 64839      Transition Number: 1000.232k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:23:56,243][train][INFO][train.py>_log] ==> #14000      Total Loss: 4.916    [weighted Loss:4.916    Policy Loss: 10.112   Value Loss: 3.382    Reward Loss: 1.305    Consistency Loss: 0.000    ] Replay Episodes Collected: 117439     Buffer Size: 54690      Transition Number: 1000.047k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:27:02,001][train][INFO][train.py>_log] ==> #15000      Total Loss: 3.848    [weighted Loss:3.848    Policy Loss: 6.946    Value Loss: 3.155    Reward Loss: 1.199    Consistency Loss: 0.000    ] Replay Episodes Collected: 121416     Buffer Size: 46646      Transition Number: 1000.059k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:30:08,902][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.538    [weighted Loss:3.538    Policy Loss: 9.494    Value Loss: 3.187    Reward Loss: 1.030    Consistency Loss: 0.000    ] Replay Episodes Collected: 125102     Buffer Size: 39574      Transition Number: 1000.034k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:33:14,544][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.937    [weighted Loss:2.937    Policy Loss: 6.264    Value Loss: 3.510    Reward Loss: 1.330    Consistency Loss: 0.000    ] Replay Episodes Collected: 127839     Buffer Size: 33077      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:36:22,160][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.061    [weighted Loss:2.061    Policy Loss: 5.689    Value Loss: 3.094    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 130931     Buffer Size: 32678      Transition Number: 999.966 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:39:31,219][train][INFO][train.py>_log] ==> #19000      Total Loss: 3.511    [weighted Loss:3.511    Policy Loss: 6.165    Value Loss: 3.002    Reward Loss: 1.090    Consistency Loss: 0.000    ] Replay Episodes Collected: 133218     Buffer Size: 32146      Transition Number: 999.995 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:42:40,412][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.900    [weighted Loss:2.900    Policy Loss: 9.483    Value Loss: 3.119    Reward Loss: 1.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 136944     Buffer Size: 31790      Transition Number: 1000.090k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:45:48,345][train][INFO][train.py>_log] ==> #21000      Total Loss: 3.487    [weighted Loss:3.487    Policy Loss: 6.664    Value Loss: 3.537    Reward Loss: 1.367    Consistency Loss: 0.000    ] Replay Episodes Collected: 140102     Buffer Size: 31680      Transition Number: 999.980 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:48:57,798][train][INFO][train.py>_log] ==> #22000      Total Loss: 2.285    [weighted Loss:2.285    Policy Loss: 6.272    Value Loss: 3.066    Reward Loss: 0.962    Consistency Loss: 0.000    ] Replay Episodes Collected: 142348     Buffer Size: 31347      Transition Number: 1000.252k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:52:05,131][train][INFO][train.py>_log] ==> #23000      Total Loss: 4.157    [weighted Loss:4.157    Policy Loss: 8.972    Value Loss: 3.449    Reward Loss: 1.234    Consistency Loss: 0.000    ] Replay Episodes Collected: 147120     Buffer Size: 33511      Transition Number: 1000.220k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:55:10,523][train][INFO][train.py>_log] ==> #24000      Total Loss: 4.632    [weighted Loss:4.632    Policy Loss: 10.916   Value Loss: 3.408    Reward Loss: 1.160    Consistency Loss: 0.000    ] Replay Episodes Collected: 150809     Buffer Size: 33577      Transition Number: 1000.076k Batch Size: 256        Lr: 0.10000 
[2022-03-07 08:58:17,123][train][INFO][train.py>_log] ==> #25000      Total Loss: 4.792    [weighted Loss:4.792    Policy Loss: 9.396    Value Loss: 3.893    Reward Loss: 1.459    Consistency Loss: 0.000    ] Replay Episodes Collected: 153947     Buffer Size: 32639      Transition Number: 1000.168k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:01:24,271][train][INFO][train.py>_log] ==> #26000      Total Loss: 3.272    [weighted Loss:3.272    Policy Loss: 7.029    Value Loss: 3.668    Reward Loss: 1.280    Consistency Loss: 0.000    ] Replay Episodes Collected: 157476     Buffer Size: 32540      Transition Number: 1000.127k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:04:31,097][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.287    [weighted Loss:3.287    Policy Loss: 7.675    Value Loss: 3.707    Reward Loss: 1.217    Consistency Loss: 0.000    ] Replay Episodes Collected: 160780     Buffer Size: 32922      Transition Number: 1000.134k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:07:38,594][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.407    [weighted Loss:4.407    Policy Loss: 8.646    Value Loss: 3.502    Reward Loss: 1.210    Consistency Loss: 0.000    ] Replay Episodes Collected: 163947     Buffer Size: 33406      Transition Number: 999.999 k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:10:45,212][train][INFO][train.py>_log] ==> #29000      Total Loss: 4.088    [weighted Loss:4.088    Policy Loss: 8.997    Value Loss: 3.006    Reward Loss: 1.021    Consistency Loss: 0.000    ] Replay Episodes Collected: 166845     Buffer Size: 33512      Transition Number: 1000.040k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:13:52,317][train][INFO][train.py>_log] ==> #30000      Total Loss: 3.526    [weighted Loss:3.526    Policy Loss: 7.871    Value Loss: 3.349    Reward Loss: 1.191    Consistency Loss: 0.000    ] Replay Episodes Collected: 168974     Buffer Size: 32808      Transition Number: 1000.031k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:17:01,000][train][INFO][train.py>_log] ==> #31000      Total Loss: 4.812    [weighted Loss:4.812    Policy Loss: 10.111   Value Loss: 3.161    Reward Loss: 1.127    Consistency Loss: 0.000    ] Replay Episodes Collected: 172521     Buffer Size: 32307      Transition Number: 1000.138k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:20:07,261][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.992    [weighted Loss:4.992    Policy Loss: 10.048   Value Loss: 3.471    Reward Loss: 1.181    Consistency Loss: 0.000    ] Replay Episodes Collected: 176046     Buffer Size: 33502      Transition Number: 1000.159k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:23:13,501][train][INFO][train.py>_log] ==> #33000      Total Loss: 5.386    [weighted Loss:5.386    Policy Loss: 9.522    Value Loss: 3.938    Reward Loss: 1.229    Consistency Loss: 0.000    ] Replay Episodes Collected: 179513     Buffer Size: 32596      Transition Number: 1000.037k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:26:20,536][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.107    [weighted Loss:4.107    Policy Loss: 9.743    Value Loss: 3.324    Reward Loss: 1.083    Consistency Loss: 0.000    ] Replay Episodes Collected: 183519     Buffer Size: 32568      Transition Number: 1000.187k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:29:27,753][train][INFO][train.py>_log] ==> #35000      Total Loss: 5.865    [weighted Loss:5.865    Policy Loss: 11.847   Value Loss: 3.410    Reward Loss: 1.111    Consistency Loss: 0.000    ] Replay Episodes Collected: 187573     Buffer Size: 33456      Transition Number: 1000.147k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:32:34,115][train][INFO][train.py>_log] ==> #36000      Total Loss: 5.225    [weighted Loss:5.225    Policy Loss: 12.063   Value Loss: 4.113    Reward Loss: 1.273    Consistency Loss: 0.000    ] Replay Episodes Collected: 191889     Buffer Size: 34064      Transition Number: 1000.054k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:35:40,641][train][INFO][train.py>_log] ==> #37000      Total Loss: 6.997    [weighted Loss:6.997    Policy Loss: 13.281   Value Loss: 4.021    Reward Loss: 1.344    Consistency Loss: 0.000    ] Replay Episodes Collected: 197316     Buffer Size: 35937      Transition Number: 1000.290k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:38:47,020][train][INFO][train.py>_log] ==> #38000      Total Loss: 6.174    [weighted Loss:6.174    Policy Loss: 11.438   Value Loss: 3.716    Reward Loss: 1.254    Consistency Loss: 0.000    ] Replay Episodes Collected: 202139     Buffer Size: 37548      Transition Number: 1000.190k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:41:52,082][train][INFO][train.py>_log] ==> #39000      Total Loss: 6.098    [weighted Loss:6.098    Policy Loss: 12.995   Value Loss: 4.167    Reward Loss: 1.390    Consistency Loss: 0.000    ] Replay Episodes Collected: 207330     Buffer Size: 39769      Transition Number: 1000.141k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:44:59,913][train][INFO][train.py>_log] ==> #40000      Total Loss: 7.107    [weighted Loss:7.107    Policy Loss: 12.258   Value Loss: 4.397    Reward Loss: 1.464    Consistency Loss: 0.000    ] Replay Episodes Collected: 212862     Buffer Size: 42947      Transition Number: 1000.049k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:48:04,476][train][INFO][train.py>_log] ==> #41000      Total Loss: 7.143    [weighted Loss:7.143    Policy Loss: 12.507   Value Loss: 4.415    Reward Loss: 1.340    Consistency Loss: 0.000    ] Replay Episodes Collected: 218324     Buffer Size: 44402      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:51:11,245][train][INFO][train.py>_log] ==> #42000      Total Loss: 5.739    [weighted Loss:5.739    Policy Loss: 12.781   Value Loss: 4.502    Reward Loss: 1.697    Consistency Loss: 0.000    ] Replay Episodes Collected: 223548     Buffer Size: 45898      Transition Number: 1000.067k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:54:18,479][train][INFO][train.py>_log] ==> #43000      Total Loss: 7.046    [weighted Loss:7.046    Policy Loss: 12.451   Value Loss: 4.245    Reward Loss: 1.368    Consistency Loss: 0.000    ] Replay Episodes Collected: 228894     Buffer Size: 47963      Transition Number: 1000.050k Batch Size: 256        Lr: 0.10000 
[2022-03-07 09:57:24,690][train][INFO][train.py>_log] ==> #44000      Total Loss: 5.021    [weighted Loss:5.021    Policy Loss: 12.225   Value Loss: 4.051    Reward Loss: 1.396    Consistency Loss: 0.000    ] Replay Episodes Collected: 234186     Buffer Size: 48950      Transition Number: 1000.123k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:00:29,647][train][INFO][train.py>_log] ==> #45000      Total Loss: 4.924    [weighted Loss:4.924    Policy Loss: 12.602   Value Loss: 4.352    Reward Loss: 1.609    Consistency Loss: 0.000    ] Replay Episodes Collected: 239282     Buffer Size: 50135      Transition Number: 1000.196k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:03:36,794][train][INFO][train.py>_log] ==> #46000      Total Loss: 6.619    [weighted Loss:6.619    Policy Loss: 12.790   Value Loss: 4.344    Reward Loss: 1.569    Consistency Loss: 0.000    ] Replay Episodes Collected: 244361     Buffer Size: 50360      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:06:42,022][train][INFO][train.py>_log] ==> #47000      Total Loss: 6.502    [weighted Loss:6.502    Policy Loss: 12.550   Value Loss: 4.185    Reward Loss: 1.324    Consistency Loss: 0.000    ] Replay Episodes Collected: 249165     Buffer Size: 49765      Transition Number: 1000.213k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:09:49,350][train][INFO][train.py>_log] ==> #48000      Total Loss: 5.130    [weighted Loss:5.130    Policy Loss: 12.466   Value Loss: 4.200    Reward Loss: 1.314    Consistency Loss: 0.000    ] Replay Episodes Collected: 253905     Buffer Size: 49731      Transition Number: 1000.051k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:12:54,661][train][INFO][train.py>_log] ==> #49000      Total Loss: 7.104    [weighted Loss:7.104    Policy Loss: 12.349   Value Loss: 4.308    Reward Loss: 1.558    Consistency Loss: 0.000    ] Replay Episodes Collected: 258525     Buffer Size: 49111      Transition Number: 1000.166k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:16:00,846][train][INFO][train.py>_log] ==> #50000      Total Loss: 6.205    [weighted Loss:6.205    Policy Loss: 12.823   Value Loss: 4.656    Reward Loss: 1.277    Consistency Loss: 0.000    ] Replay Episodes Collected: 263217     Buffer Size: 48398      Transition Number: 1000.151k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:19:06,393][train][INFO][train.py>_log] ==> #51000      Total Loss: 6.142    [weighted Loss:6.142    Policy Loss: 12.942   Value Loss: 4.443    Reward Loss: 1.534    Consistency Loss: 0.000    ] Replay Episodes Collected: 267957     Buffer Size: 47873      Transition Number: 1000.064k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:22:12,794][train][INFO][train.py>_log] ==> #52000      Total Loss: 7.208    [weighted Loss:7.208    Policy Loss: 12.768   Value Loss: 4.126    Reward Loss: 1.302    Consistency Loss: 0.000    ] Replay Episodes Collected: 272535     Buffer Size: 47195      Transition Number: 1000.091k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:25:18,139][train][INFO][train.py>_log] ==> #53000      Total Loss: 5.383    [weighted Loss:5.383    Policy Loss: 12.943   Value Loss: 4.937    Reward Loss: 1.474    Consistency Loss: 0.000    ] Replay Episodes Collected: 277476     Buffer Size: 46930      Transition Number: 1000.109k Batch Size: 256        Lr: 0.10000 
[2022-03-07 10:28:24,369][train][INFO][train.py>_log] ==> #54000      Total Loss: 6.398    [weighted Loss:6.398    Policy Loss: 12.177   Value Loss: 4.184    Reward Loss: 1.387    Consistency Loss: 0.000    ] Replay Episodes Collected: 282090     Buffer Size: 46371      Transition Number: 1000.095k Batch Size: 256        Lr: 0.10000 
