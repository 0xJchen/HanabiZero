[2022-03-04 02:22:54,799][train][INFO][train.py>_log] ==> #0          Total Loss: 48.398   [weighted Loss:48.398   Policy Loss: 13.926   Value Loss: 31.821   Reward Loss: 26.517   Consistency Loss: 0.000    ] Replay Episodes Collected: 1500       Buffer Size: 1500       Transition Number: 16.325  k Batch Size: 256        Lr: 0.00000 
[2022-03-04 02:26:48,845][train][INFO][train.py>_log] ==> #1000       Total Loss: 5.513    [weighted Loss:5.513    Policy Loss: 14.552   Value Loss: 4.899    Reward Loss: 1.836    Consistency Loss: 0.000    ] Replay Episodes Collected: 15956      Buffer Size: 15956      Transition Number: 197.974 k Batch Size: 256        Lr: 0.10000 
[2022-03-04 02:30:47,505][train][INFO][train.py>_log] ==> #2000       Total Loss: 6.635    [weighted Loss:6.635    Policy Loss: 13.636   Value Loss: 4.649    Reward Loss: 2.044    Consistency Loss: 0.000    ] Replay Episodes Collected: 30720      Buffer Size: 30720      Transition Number: 383.187 k Batch Size: 256        Lr: 0.20000 
[2022-03-04 02:34:47,943][train][INFO][train.py>_log] ==> #3000       Total Loss: 5.814    [weighted Loss:5.814    Policy Loss: 12.916   Value Loss: 4.550    Reward Loss: 1.910    Consistency Loss: 0.000    ] Replay Episodes Collected: 52097      Buffer Size: 52097      Transition Number: 574.090 k Batch Size: 256        Lr: 0.20000 
[2022-03-04 02:38:46,694][train][INFO][train.py>_log] ==> #4000       Total Loss: 3.842    [weighted Loss:3.842    Policy Loss: 12.205   Value Loss: 4.313    Reward Loss: 2.027    Consistency Loss: 0.000    ] Replay Episodes Collected: 73480      Buffer Size: 73480      Transition Number: 760.884 k Batch Size: 256        Lr: 0.20000 
[2022-03-04 02:42:48,817][train][INFO][train.py>_log] ==> #5000       Total Loss: 4.879    [weighted Loss:4.879    Policy Loss: 11.507   Value Loss: 4.111    Reward Loss: 2.075    Consistency Loss: 0.000    ] Replay Episodes Collected: 96665      Buffer Size: 96665      Transition Number: 949.410 k Batch Size: 256        Lr: 0.20000 
[2022-03-04 02:46:50,965][train][INFO][train.py>_log] ==> #6000       Total Loss: 5.992    [weighted Loss:5.992    Policy Loss: 10.377   Value Loss: 4.109    Reward Loss: 2.262    Consistency Loss: 0.000    ] Replay Episodes Collected: 120282     Buffer Size: 109142     Transition Number: 1000.276k Batch Size: 256        Lr: 0.20000 
[2022-03-04 02:50:47,945][train][INFO][train.py>_log] ==> #7000       Total Loss: 3.863    [weighted Loss:3.863    Policy Loss: 9.793    Value Loss: 3.862    Reward Loss: 2.022    Consistency Loss: 0.000    ] Replay Episodes Collected: 142856     Buffer Size: 116731     Transition Number: 1000.150k Batch Size: 256        Lr: 0.20000 
[2022-03-04 02:54:46,458][train][INFO][train.py>_log] ==> #8000       Total Loss: 3.268    [weighted Loss:3.268    Policy Loss: 8.884    Value Loss: 3.714    Reward Loss: 1.963    Consistency Loss: 0.000    ] Replay Episodes Collected: 165847     Buffer Size: 120502     Transition Number: 1000.296k Batch Size: 256        Lr: 0.20000 
[2022-03-04 02:58:47,363][train][INFO][train.py>_log] ==> #9000       Total Loss: 4.099    [weighted Loss:4.099    Policy Loss: 8.749    Value Loss: 3.719    Reward Loss: 2.158    Consistency Loss: 0.000    ] Replay Episodes Collected: 191796     Buffer Size: 124750     Transition Number: 1000.279k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:02:59,855][train][INFO][train.py>_log] ==> #10000      Total Loss: 3.434    [weighted Loss:3.434    Policy Loss: 8.819    Value Loss: 3.645    Reward Loss: 2.094    Consistency Loss: 0.000    ] Replay Episodes Collected: 218950     Buffer Size: 127837     Transition Number: 1000.323k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:07:10,195][train][INFO][train.py>_log] ==> #11000      Total Loss: 2.701    [weighted Loss:2.701    Policy Loss: 6.961    Value Loss: 3.778    Reward Loss: 2.399    Consistency Loss: 0.000    ] Replay Episodes Collected: 251858     Buffer Size: 135902     Transition Number: 1000.356k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:11:21,256][train][INFO][train.py>_log] ==> #12000      Total Loss: 1.772    [weighted Loss:1.772    Policy Loss: 4.687    Value Loss: 3.538    Reward Loss: 2.405    Consistency Loss: 0.000    ] Replay Episodes Collected: 285036     Buffer Size: 144439     Transition Number: 1000.344k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:15:47,323][train][INFO][train.py>_log] ==> #13000      Total Loss: 2.205    [weighted Loss:2.205    Policy Loss: 2.931    Value Loss: 3.289    Reward Loss: 2.322    Consistency Loss: 0.000    ] Replay Episodes Collected: 329068     Buffer Size: 161710     Transition Number: 1000.169k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:20:34,983][train][INFO][train.py>_log] ==> #14000      Total Loss: 2.374    [weighted Loss:2.374    Policy Loss: 4.118    Value Loss: 2.823    Reward Loss: 2.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 377183     Buffer Size: 177527     Transition Number: 1000.254k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:24:58,837][train][INFO][train.py>_log] ==> #15000      Total Loss: 1.931    [weighted Loss:1.931    Policy Loss: 4.138    Value Loss: 3.019    Reward Loss: 2.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 413620     Buffer Size: 183104     Transition Number: 1000.169k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:29:17,280][train][INFO][train.py>_log] ==> #16000      Total Loss: 3.409    [weighted Loss:3.409    Policy Loss: 6.366    Value Loss: 3.169    Reward Loss: 2.279    Consistency Loss: 0.000    ] Replay Episodes Collected: 449125     Buffer Size: 184242     Transition Number: 1000.256k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:33:27,677][train][INFO][train.py>_log] ==> #17000      Total Loss: 2.807    [weighted Loss:2.807    Policy Loss: 6.313    Value Loss: 2.992    Reward Loss: 2.171    Consistency Loss: 0.000    ] Replay Episodes Collected: 472489     Buffer Size: 173975     Transition Number: 1000.223k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:37:36,521][train][INFO][train.py>_log] ==> #18000      Total Loss: 2.803    [weighted Loss:2.803    Policy Loss: 6.707    Value Loss: 3.063    Reward Loss: 2.051    Consistency Loss: 0.000    ] Replay Episodes Collected: 495304     Buffer Size: 158006     Transition Number: 1000.236k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:41:47,853][train][INFO][train.py>_log] ==> #19000      Total Loss: 2.991    [weighted Loss:2.991    Policy Loss: 5.515    Value Loss: 3.044    Reward Loss: 1.856    Consistency Loss: 0.000    ] Replay Episodes Collected: 505536     Buffer Size: 135918     Transition Number: 1000.018k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:45:59,392][train][INFO][train.py>_log] ==> #20000      Total Loss: 2.622    [weighted Loss:2.622    Policy Loss: 6.955    Value Loss: 2.755    Reward Loss: 1.648    Consistency Loss: 0.000    ] Replay Episodes Collected: 515775     Buffer Size: 115281     Transition Number: 1000.075k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:50:05,763][train][INFO][train.py>_log] ==> #21000      Total Loss: 2.497    [weighted Loss:2.497    Policy Loss: 5.532    Value Loss: 2.664    Reward Loss: 1.354    Consistency Loss: 0.000    ] Replay Episodes Collected: 519298     Buffer Size: 92852      Transition Number: 1000.315k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:54:23,538][train][INFO][train.py>_log] ==> #22000      Total Loss: 1.899    [weighted Loss:1.899    Policy Loss: 6.640    Value Loss: 2.631    Reward Loss: 1.215    Consistency Loss: 0.000    ] Replay Episodes Collected: 522909     Buffer Size: 69521      Transition Number: 1000.398k Batch Size: 256        Lr: 0.20000 
[2022-03-04 03:58:33,122][train][INFO][train.py>_log] ==> #23000      Total Loss: 2.332    [weighted Loss:2.332    Policy Loss: 7.823    Value Loss: 1.725    Reward Loss: 0.781    Consistency Loss: 0.000    ] Replay Episodes Collected: 527022     Buffer Size: 54107      Transition Number: 1000.094k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:02:40,201][train][INFO][train.py>_log] ==> #24000      Total Loss: 2.678    [weighted Loss:2.678    Policy Loss: 9.379    Value Loss: 2.016    Reward Loss: 0.777    Consistency Loss: 0.000    ] Replay Episodes Collected: 531082     Buffer Size: 39005      Transition Number: 1000.019k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:06:51,801][train][INFO][train.py>_log] ==> #25000      Total Loss: 2.985    [weighted Loss:2.985    Policy Loss: 10.112   Value Loss: 2.906    Reward Loss: 0.912    Consistency Loss: 0.000    ] Replay Episodes Collected: 539388     Buffer Size: 33900      Transition Number: 1000.258k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:11:09,262][train][INFO][train.py>_log] ==> #26000      Total Loss: 2.874    [weighted Loss:2.874    Policy Loss: 11.594   Value Loss: 2.925    Reward Loss: 0.830    Consistency Loss: 0.000    ] Replay Episodes Collected: 548160     Buffer Size: 32010      Transition Number: 1000.097k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:15:26,045][train][INFO][train.py>_log] ==> #27000      Total Loss: 3.066    [weighted Loss:3.066    Policy Loss: 10.912   Value Loss: 3.283    Reward Loss: 1.164    Consistency Loss: 0.000    ] Replay Episodes Collected: 561798     Buffer Size: 41200      Transition Number: 1000.152k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:19:45,479][train][INFO][train.py>_log] ==> #28000      Total Loss: 4.281    [weighted Loss:4.281    Policy Loss: 12.787   Value Loss: 3.510    Reward Loss: 1.198    Consistency Loss: 0.000    ] Replay Episodes Collected: 575775     Buffer Size: 50560      Transition Number: 1000.214k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:24:04,613][train][INFO][train.py>_log] ==> #29000      Total Loss: 3.319    [weighted Loss:3.319    Policy Loss: 12.880   Value Loss: 3.814    Reward Loss: 1.385    Consistency Loss: 0.000    ] Replay Episodes Collected: 592949     Buffer Size: 62628      Transition Number: 1000.081k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:28:15,626][train][INFO][train.py>_log] ==> #30000      Total Loss: 5.362    [weighted Loss:5.362    Policy Loss: 13.105   Value Loss: 3.856    Reward Loss: 1.625    Consistency Loss: 0.000    ] Replay Episodes Collected: 609779     Buffer Size: 71332      Transition Number: 1000.250k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:32:34,809][train][INFO][train.py>_log] ==> #31000      Total Loss: 5.764    [weighted Loss:5.764    Policy Loss: 12.980   Value Loss: 4.111    Reward Loss: 1.679    Consistency Loss: 0.000    ] Replay Episodes Collected: 629565     Buffer Size: 81521      Transition Number: 1000.295k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:36:50,432][train][INFO][train.py>_log] ==> #32000      Total Loss: 4.932    [weighted Loss:4.932    Policy Loss: 11.828   Value Loss: 4.143    Reward Loss: 1.842    Consistency Loss: 0.000    ] Replay Episodes Collected: 649076     Buffer Size: 87761      Transition Number: 1000.349k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:40:57,829][train][INFO][train.py>_log] ==> #33000      Total Loss: 5.491    [weighted Loss:5.491    Policy Loss: 12.285   Value Loss: 4.496    Reward Loss: 1.763    Consistency Loss: 0.000    ] Replay Episodes Collected: 665995     Buffer Size: 91021      Transition Number: 1000.342k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:45:10,227][train][INFO][train.py>_log] ==> #34000      Total Loss: 4.645    [weighted Loss:4.645    Policy Loss: 12.557   Value Loss: 4.450    Reward Loss: 1.850    Consistency Loss: 0.000    ] Replay Episodes Collected: 682916     Buffer Size: 91687      Transition Number: 1000.078k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:49:21,890][train][INFO][train.py>_log] ==> #35000      Total Loss: 6.038    [weighted Loss:6.038    Policy Loss: 12.574   Value Loss: 4.436    Reward Loss: 1.805    Consistency Loss: 0.000    ] Replay Episodes Collected: 699918     Buffer Size: 91897      Transition Number: 1000.144k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:53:33,529][train][INFO][train.py>_log] ==> #36000      Total Loss: 4.426    [weighted Loss:4.426    Policy Loss: 12.508   Value Loss: 4.598    Reward Loss: 1.991    Consistency Loss: 0.000    ] Replay Episodes Collected: 717051     Buffer Size: 90195      Transition Number: 1000.207k Batch Size: 256        Lr: 0.20000 
[2022-03-04 04:57:49,742][train][INFO][train.py>_log] ==> #37000      Total Loss: 6.764    [weighted Loss:6.764    Policy Loss: 12.932   Value Loss: 4.503    Reward Loss: 1.941    Consistency Loss: 0.000    ] Replay Episodes Collected: 734129     Buffer Size: 87800      Transition Number: 1000.138k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:01:59,182][train][INFO][train.py>_log] ==> #38000      Total Loss: 5.945    [weighted Loss:5.945    Policy Loss: 12.876   Value Loss: 4.242    Reward Loss: 1.715    Consistency Loss: 0.000    ] Replay Episodes Collected: 750917     Buffer Size: 87118      Transition Number: 1000.180k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:06:10,858][train][INFO][train.py>_log] ==> #39000      Total Loss: 5.782    [weighted Loss:5.782    Policy Loss: 12.743   Value Loss: 4.634    Reward Loss: 1.921    Consistency Loss: 0.000    ] Replay Episodes Collected: 767102     Buffer Size: 86388      Transition Number: 1000.045k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:10:22,311][train][INFO][train.py>_log] ==> #40000      Total Loss: 6.157    [weighted Loss:6.157    Policy Loss: 12.873   Value Loss: 4.766    Reward Loss: 1.871    Consistency Loss: 0.000    ] Replay Episodes Collected: 783195     Buffer Size: 85678      Transition Number: 1000.126k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:14:34,061][train][INFO][train.py>_log] ==> #41000      Total Loss: 6.626    [weighted Loss:6.626    Policy Loss: 13.237   Value Loss: 4.506    Reward Loss: 1.918    Consistency Loss: 0.000    ] Replay Episodes Collected: 798453     Buffer Size: 84021      Transition Number: 1000.142k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:18:46,682][train][INFO][train.py>_log] ==> #42000      Total Loss: 7.019    [weighted Loss:7.019    Policy Loss: 12.955   Value Loss: 4.444    Reward Loss: 1.794    Consistency Loss: 0.000    ] Replay Episodes Collected: 813829     Buffer Size: 82506      Transition Number: 1000.301k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:22:57,871][train][INFO][train.py>_log] ==> #43000      Total Loss: 4.773    [weighted Loss:4.773    Policy Loss: 12.860   Value Loss: 4.272    Reward Loss: 1.878    Consistency Loss: 0.000    ] Replay Episodes Collected: 830389     Buffer Size: 82220      Transition Number: 1000.276k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:27:13,520][train][INFO][train.py>_log] ==> #44000      Total Loss: 4.978    [weighted Loss:4.978    Policy Loss: 12.776   Value Loss: 4.539    Reward Loss: 1.857    Consistency Loss: 0.000    ] Replay Episodes Collected: 847124     Buffer Size: 82492      Transition Number: 1000.217k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:31:25,015][train][INFO][train.py>_log] ==> #45000      Total Loss: 7.031    [weighted Loss:7.031    Policy Loss: 13.132   Value Loss: 4.888    Reward Loss: 1.872    Consistency Loss: 0.000    ] Replay Episodes Collected: 864465     Buffer Size: 83343      Transition Number: 1000.152k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:35:42,322][train][INFO][train.py>_log] ==> #46000      Total Loss: 6.035    [weighted Loss:6.035    Policy Loss: 12.591   Value Loss: 4.664    Reward Loss: 1.790    Consistency Loss: 0.000    ] Replay Episodes Collected: 882025     Buffer Size: 84987      Transition Number: 1000.166k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:39:54,305][train][INFO][train.py>_log] ==> #47000      Total Loss: 5.771    [weighted Loss:5.771    Policy Loss: 12.353   Value Loss: 4.432    Reward Loss: 1.935    Consistency Loss: 0.000    ] Replay Episodes Collected: 901512     Buffer Size: 88822      Transition Number: 1000.377k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:44:03,147][train][INFO][train.py>_log] ==> #48000      Total Loss: 5.028    [weighted Loss:5.028    Policy Loss: 11.878   Value Loss: 4.288    Reward Loss: 1.792    Consistency Loss: 0.000    ] Replay Episodes Collected: 920719     Buffer Size: 91515      Transition Number: 1000.131k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:48:16,894][train][INFO][train.py>_log] ==> #49000      Total Loss: 6.118    [weighted Loss:6.118    Policy Loss: 12.097   Value Loss: 5.382    Reward Loss: 2.388    Consistency Loss: 0.000    ] Replay Episodes Collected: 946427     Buffer Size: 99997      Transition Number: 1000.375k Batch Size: 256        Lr: 0.20000 
[2022-03-04 05:52:30,179][train][INFO][train.py>_log] ==> #50000      Total Loss: 5.818    [weighted Loss:5.818    Policy Loss: 11.533   Value Loss: 4.525    Reward Loss: 1.986    Consistency Loss: 0.000    ] Replay Episodes Collected: 972174     Buffer Size: 108020     Transition Number: 1000.430k Batch Size: 256        Lr: 0.20000 
